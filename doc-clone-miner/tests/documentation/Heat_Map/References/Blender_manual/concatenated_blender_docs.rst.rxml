<?xml version="1.0" encoding="utf-8" ?>
<plainxml>.. _about-build-index:

#########
Build
#########

The building process is different for each operating system, instructions have been written for:

.. toctree::
:maxdepth: 1

Linux &lt;linux.rst&gt;
macOS &lt;macos.rst&gt;
MS-Windows &lt;windows.rst&gt;
.. highlight:: sh

*****************
Building on Linux
*****************

Converting the rst files into pretty HTML pages.

Open a terminal to the folder ``~/blender_docs`` and simply run::

make

This is the command you will always use when building the docs.
The building process may take several minutes the first time (or after any major changes),
but the next time you build it should only take a few seconds.

Viewing the local manual
========================

Once the docs have been built, all the html files can be found inside ``~/blender_docs/build/html``.
Try opening ``build/html/contents.html`` in your web browser and read the manual::

xdg-open build/html/contents.html

Now that you are able to build the manual, the next paragraph is about an optional quick build.

Building a Single Chapter
=========================

If you are working on a specific chapter of the manual, you can build it quickly using::

make &lt;chapter name&gt;

For example, to build only the documentation for the modifiers, use ``make modifiers``.
You can then view this quick build by opening ``build/html/contents_quicky.html``.

This will build very quickly, but it will mean your next complete build of all the chapters will be slow.

------------------------

Continue with the next step: :doc:`Editing &lt;/about/contribute/editing&gt;`
.. highlight:: sh

*****************
Building on macOS
*****************

Converting the rst files into pretty HTML pages.

Open a terminal to the folder ``~/blender_docs`` and simply run::

make

This is the command you will always use when building the docs.
The building process may take several minutes the first time (or after any major changes),
but the next time you build it should only take a few seconds.

Viewing the local manual
========================

Once the docs have been built, all the HTML files can be found inside ``~/blender_docs/build/html``.
Try opening ``build/html/contents.html`` in your web browser and read the manual::

open build/html/contents.html

Now that you are able to build the manual, the next paragraph is about an optional quick build.

Building a Single Chapter
=========================

If you are working on a specific chapter of the manual, you can build it quickly using::

make &lt;chapter name&gt;

For example, to build only the documentation for the modifiers, use ``make modifiers``.
You can then view this quick build by opening ``build/html/contents_quicky.html``.

This will build very quickly, but it will mean your next complete build of all the chapters will be slow.

------------------------

Continue with the next step: :doc:`Editing &lt;/about/contribute/editing&gt;`
.. highlight:: sh

**********************
Building on MS-Windows
**********************

Converting the rst files into pretty HTML pages.
There are two ways to run the build process.

.. rubric:: File browser

Run ``make.bat`` in the ``C:\blender_docs`` folder.

.. tip::

Create a desktop shortcut to ``make``.

.. rubric:: Command prompt

#. Or open a command prompt and change to the repository with ``cd C:\blender_docs``.
#. Build using the following command::

make

The building process may take several minutes the first time (or after any major changes),
but the next time you build it should only take a few seconds.

.. note::

If you encounter an error ending with ``TypeError: an integer is required (got type str)``,
you may need to install an older version of *Babel* (the Python Internationalization Library).

To do this, simply run::

pip install sphinx "babel&lt;2.0"

Viewing the local manual
========================

Once the docs have been built, all the HTML files can be found inside ``C:\blender_docs\build\html``.
Try opening ``\build\html\contents.html`` in your web browser and read the manual.

------------------------

Continue with the next step: :doc:`Editing &lt;/about/contribute/editing&gt;`

******************
Editing the manual
******************

Update
======

Firstly, make sure that your local copy of the manual is up to date with the online repository using:

.. code-block:: sh

svn update

Writing
=======

You can now edit the documentation files, which are the ``.rst`` files inside the ``manual`` folder using
a text editor of your choice.

For instructions on using different editors,
see the `Editor Configuration &lt;https://wiki.blender.org/index.php/Dev:Doc/Tools/User_Reference_Manual&gt;`__
section of the community wiki.

Be sure to check the :doc:`/about/contribute/style_guides/writing_guide`
for conventions and :doc:`/about/contribute/style_guides/markup_guide`
to learn how to write in the reStructuredText markup language.

Happy writing!

Bigger Changes
--------------

If you are going to add or overhaul a section, be sure to check carefully that it does not already exist.
In some places, the docs are so disorganized that sections may be duplicated or in a strange location.
In the case that you find a duplicate or out of place section,
`create a task &lt;https://developer.blender.org/maniphest/task/edit/form/default/?project=PHID-PROJ-c4nvvrxuczix2326vlti&gt;`__
explaining the issue, and optionally include a revision (actual changes).

Before you make any edits that are not simple and plainly justified (for example, moving folders around),
you should verify with a manual maintainer that your contribution is along the community's vision for the manual.
This ensures the best use of your time and good will as it is otherwise possible that, for some reason,
your changes will conflict and be rejected or need time-consuming review.
For example, another person may be already working on the section you wish to change,
the section may be scheduled for deletion or to be updated according to a planned change to Blender.

:ref:`Communicating &lt;contribute-contact&gt;` early and frequently is the key to have a productive environment,
to not waste people's effort and to attain a better Blender manual as a result.

..
Communication is a very important step in community development.
Manual maintainers and the general community can also point to areas that are in need of big or small changes.

Getting help/answers
--------------------

If you are in doubt about functionality that you wish to document,
you should pose your questions to the Blender developers responsible for that area or ask at the unofficial user
support channel at ``#blender`` :ref:`IRC channel &lt;irc-channels&gt;`.

Blender has its own system of module owners with developer and artist members who are
responsible for the design and maintenance of the assigned Blender areas.
See the `module owners page &lt;https://wiki.blender.org/index.php/Dev:Doc/Process/Module_Owners/List&gt;`__
for more information.

Preview
=======

To view your changes, build the manual :doc:`as instructed &lt;/about/contribute/build/index&gt;`.
Keep in mind that you can also build only the chapter you just edited to view it quickly.
Open the generated ``.html`` files inside the ``build/html`` folder using your web browser,
or refresh the page if you have it open already.

Upload
======

When you are happy with your changes, you can upload them, so that they will be in the online manual.
At first, this is done by submitting patches so that someone can review your changes and give you feedback.
After, you can commit your changes directly. This process is described in detail in the next section.

##############
Contribute
##############

Whether you like to fix a tiny spelling mistake or rewrite an entire chapter,
your help with the Blender manual is most welcome!

How It Works
============

You can modify the manual by editing local text files.
These files are kept in sync with those online via a repository,
based on this the server will update the online manual.

The manual is written in the `reStructuredText &lt;http://www.sphinx-doc.org/en/stable/rest.html&gt;`__
(RST) markup language and can be edit using a plain text editor.
For a local preview, you convert (build) the manual source files from RST into HTML web pages.

.. _about-getting-started:

Getting Started
===============

The following guides lead you through the process.

.. toctree::
:maxdepth: 1

install/index.rst
build/index.rst
editing.rst
patch_commit.rst

Style Guides
============

.. toctree::
:maxdepth: 1

style_guides/markup_guide.rst
style_guides/writing_guide.rst

Translations
============

.. toctree::
:maxdepth: 1

translations/contribute.rst
translations/style_guide.rst

.. _contribute-contact:

Contacts
========

The Manual Teams `project page &lt;https://developer.blender.org/project/profile/53/&gt;`__.

- `Mailing list &lt;https://lists.blender.org/mailman/listinfo/bf-docboard&gt;`__
is our main way of distributing documents,
discussing ideas, and keeping track of progress.(Registration required).
- ``#blenderwiki`` channel in the :ref:`IRC chat &lt;irc-channels&gt;` for informal discussions in real-time.
- `Workboard &lt;https://developer.blender.org/project/board/53/&gt;`__ for tasks.
- `Patch tracker &lt;https://developer.blender.org/differential/&gt;`__ shared with the other Blender projects.
.. _about-install-index:

###########
Install
###########

This section documents how to install the software used to generate the manual.
The installation is different for each operating system, instructions have been written for:

.. toctree::
:maxdepth: 1

Linux &lt;linux.rst&gt;
macOS &lt;macos.rst&gt;
MS-Windows &lt;windows.rst&gt;
.. highlight:: sh

*********************
Installation on Linux
*********************

This guide covers the following topics:

#. `Installing Dependencies`_
#. `Downloading the Repository`_
#. `Setting up the Build Environment`_

Installing Dependencies
=======================

Below are listed the installation commands for popular Linux distributions.

For the appropriate system, run the command in a terminal:

Debian/Ubuntu
.. code-block:: sh

sudo apt-get install python python-pip subversion

Redhat/Fedora
.. code-block:: sh

sudo yum install python python-pip
Arch Linux
.. code-block:: sh

sudo pacman -S python python-pip subversion

Downloading the Repository
==========================

Simply check out the blender-manual repository using::

cd ~
svn checkout https://svn.blender.org/svnroot/bf-manual/trunk/blender_docs

The repository will now be downloaded which may take a few minutes depending on your internet connection.

Setting up the Build Environment
================================

In a terminal, enter the ``blender_docs`` folder which was just added by the SVN checkout::

cd ~/blender_docs

Inside that folder is a file called ``requirements.txt`` which contains a list of all the dependencies we need.
To install these dependencies, we can use the ``pip`` command::

sudo pip install -r requirements.txt

.. note::

Every now and then you may want to make sure your lib dependencies are up to date using::

sudo pip install -r requirements.txt --upgrade

------------------------

Continue with the next step: :doc:`Building &lt;/about/contribute/build/linux&gt;`
.. highlight:: sh

*********************
Installation on macOS
*********************

This guide covers the following topics:

#. `Installing Dependencies`_
#. `Downloading the Repository`_
#. `Setting up the Build Environment`_

.. note::

This guide relies heavily on command-line tools.
It assumes you are the least familiar with the macOS Terminal application.

Installing Dependencies
=======================

Install those packages or make sure you have them in your system.

- `Python &lt;https://www.python.org/&gt;`__
- `PIP &lt;https://pip.pypa.io/en/latest/installing/&gt;`__
- `Subversion &lt;https://subversion.apache.org/&gt;`__

Downloading the Repository
==========================

Simply check out the blender-manual repository using::

cd ~
svn checkout https://svn.blender.org/svnroot/bf-manual/trunk/blender_docs

The repository will now be downloaded which may take a few minutes depending on your internet connection.

Setting up the Build Environment
================================

In a terminal, enter the ``blender_docs`` folder which was just added by the SVN checkout::

cd ~/blender_docs

Inside that folder is a file called ``requirements.txt`` which contains a list of all the dependencies we need.
To install these dependencies, we can use the ``pip`` command::

sudo pip install -r requirements.txt

.. note::

Every now and then you may want to make sure your dependencies are up to date using::

sudo pip install -r requirements.txt --upgrade

------------------------

Continue with the next step: :doc:`Building &lt;/about/contribute/build/macos&gt;`

**************************
Installation on MS-Windows
**************************

This guide covers the following topics:

#. `Installing Python`_ (used to "convert" the source files to HTML)
#. `Installing SVN and Downloading the Repository`_
#. `Setting up the Build Environment`_

Installing Python
=================

#. Download the `Python installation package &lt;https://www.python.org/downloads/&gt;`__ for MS-Windows.
In this guide version 3.5.x is used.
#. Install Python with the installation wizard.
In this guide the default settings are used.

Installing SVN and Downloading the Repository
=============================================

In this guide, we will use TortoiseSVN though any Subversion client will do.

#. Download `TortoiseSVN &lt;https://tortoisesvn.net/downloads.html&gt;`__ for MS-Windows.
#. Install TortoiseSVN with the installation wizard. When choosing which features will be installed,
it is recommended that you enable *command line client tools* to give you access to SVN from the command line
(there is no harm in doing this, and it may be helpful if you ever run into any trouble).
#. Once the installation has finished, create a new folder that will contain everything related to the Blender Manual.
In this guide, we will use ``C:\blender_docs``.
#. Open the new folder, right click and choose *SVN Checkout...* from the context menu.
#. In the *URL of repository* field, enter: ``https://svn.blender.org/svnroot/bf-manual/trunk/blender_docs``.
#. In the *Checkout directory* field, enter: ``C:\blender_docs``.
#. Click *OK* - the repository will now be downloaded
which may take a few minutes depending on your internet connection.

Setting up the Build Environment
================================

- Open a command prompt and change to the repository folder using:

.. code-block:: sh

cd C:\blender_docs

- Install all the dependencies using Python's ``pip`` command:

.. code-block:: sh

pip install -r requirements.txt

- If all goes well, you should see the following message when it is finished:

.. code-block:: sh

Successfully installed Jinja2 MarkupSafe Pygments Sphinx docutils sphinx-rtd-theme Cleaning up...

During the setup, some warnings may be shown, but do not worry about them.
However, if any errors occur, they may cause some problems.

.. note::

Every now and then you may want to make sure your dependencies are up to date using:

.. code-block:: sh

pip install -r requirements.txt --upgrade

------------------------

Continue with the next step: :doc:`Building &lt;/about/contribute/build/windows&gt;`

.. highlight:: sh

**************
Patch &amp; Commit
**************

Submit Patches
==============

The first few times you make changes to the manual,
you will need to submit them as patches for the section owner to review.
This is just to make sure that we maintain a quality user manual,
and that you do not accidentally break anything vital before you get used to the system.

In order to submit a patch, follow this process:

#. Make any changes that you want
#. Create a patch file by running::

svn diff &gt; filename.diff

This creates a simple text file that shows what text was added,
removed or changed between your working files and the central repository.

If you have created or deleted files, you will need to run ``svn add /path/to/file``
or ``svn rm /path/to/file`` before creating the diff. To see a list of affected files, run ``svn status``.
#. `Upload the diff file here &lt;https://developer.blender.org/differential/diff/create/&gt;`__.
If you do not have an account already,
you can `register for one &lt;https://developer.blender.org/auth/register/&gt;`__.
#. After submitting the diff, you will be asked to "Create a new Revision"
before you can add a title and description of your changes.
#. If you know who the Section Owner
(see `Documentation Team &lt;https://developer.blender.org/project/profile/53&gt;`__) of that chapter is,
assign them as the *Reviewer* and they will be notified of your patch.
If you cannot find out who that is (or there is no one),
instead, mail the `bf-docboard &lt;https://lists.blender.org/mailman/listinfo/bf-docboard&gt;`__ mailing list,
or tell someone in ``#blenderwiki`` on :ref:`IRC &lt;irc-channels&gt;`.
#. They will review your patch and let you know about any changes you could make,
or commit the patch if it is accepted.

.. note::

If your patch includes changes to or additional images,
simply attach them when you are creating the revision.

Straight-forward patches are bound to be accepted very quickly.
Once you get accustomed to making changes and no longer need feedback,
we cut out the middle man and give you direct access to edit the manual.

Commit Directly
===============

Instead of creating a patch file, committing will submit the change directly to our central repository.

All you need to do now is run::

svn commit -m "This is what I did"

If you leave out ``-m "message"``, you will be prompted to type the message in a text editor.

Do not forget to always run ``svn update`` before committing.

Then you will be asked for your user name (from ``developer.blender.org``)
and password before the change is committed.

Your modified files are uploaded to the central repository for others to work with and continue collaborating.
Commits are tracked in the repositories `Diffusion &lt;https://developer.blender.org/diffusion/BM/&gt;`__.
Soon after your changes become visible in the online manual.
.. highlight:: rst

******************
Markup Style Guide
******************

.. Editors Note:
::
There are many detailed conventions, eg:
::
- when definition lists/bullet-points are used.
- word-ordering in filenames.
- how text is wrapped.
- the number of spaces between lines.
- when it is/is not okay to add in Unicode characters.
- should comments on a page be above or below titles :)
::
Having a lot of detailed text on this page is off-putting to new contributors,
so please avoid making this page into a wall-of-text,
many conventions can be noticed along the way by reading existing text.

This page covers the conventions for writing and use of the reStructuredText (RST) markup syntax.

Conventions
===========

- Three space indentation.
- Lines should be less than 120 characters long.
- Use italics for button/menu names.

Other loose conventions:

- Avoid Unicode characters.
- Avoid heavily wrapped text
(i.e. sentences can have their own lines).

Headings
========

.. code-block:: rst

################
Document Part
################

****************
Document Chapter
****************

Document Section
================

Document Subsection
-------------------

Document Subsubsection
^^^^^^^^^^^^^^^^^^^^^^

Document Paragraph
""""""""""""""""""

.. note:: *Parts* should only be used for contents or index pages.

.. note:: Each ``.rst`` file should only have one chapter heading (``*``) per file.

Text Styling
============

See the `overview on ReStructured Text &lt;http://www.sphinx-doc.org/en/stable/rest.html&gt;`__
for more information on how to style the various elements of the documentation and on how to add lists, tables,
pictures and code blocks.
The `Sphinx reference &lt;http://www.sphinx-doc.org/en/stable/markup/&gt;`__ provides more insight additional constructs.

The following are useful markups for text styling::

*italic*
**bold**
``literal``

Interface Elements
==================

- ``:kbd:`LMB``` -- keyboard and mouse shortcuts.
- ``*Mirror*`` -- interface labels.
- ``:menuselection:`3D View --&gt; Add --&gt; Mesh --&gt; Monkey``` -- menus.

Code Samples
============

There is support for syntax highlighting if the programming language is provided,
and line numbers can be optionally shown with the ``:linenos:`` option::

.. code-block:: python
:linenos:

import bpy
def some_function():
...

Images
======

Figures should be used to place images::

.. figure:: /images/editors_menu.png

Image Caption.

Files
-----

No Caps, No Gaps
Lower case filenames underscore between words.
Sort Usefully
Order naming with specific identifiers at the end.
Format
Use ``.png`` for images that have solid colors such as screenshots of the Blender interface,
and ``.jpg`` for images with a lot of color variances, such as sample renders and photographs.

Do not use animated ``.gif`` files, these are hard to maintain, can be distracting
and are usually large in file size. If a video is needed, use YouTube or Vimeo (see `Videos`_ below).
Location
Place the image in the ``manual/images`` folder. Use no other subfolders.
Naming
Image files should be named: ``chapter_subsection_id.png``, eg:

- ``render_cycles_lighting_example_01.jpg``
- ``interface_intro_splash.jpg``
- ``interface_ui_panel.jpg``

Do not use special characters or spaces

Usage Guides
------------

- Avoid specifying the resolution of the image or its alignment, so that the theme can handle the images consistently
and provide the best layout across different screen sizes.
- When documenting a panel or section of the UI,
it is better to use a single image that shows all of the relevant areas
(rather than multiple images for each icon or button) placed at the top of the section you are writing,
and then explain the features in the order that they appear in the image.

.. note::

It is important that the manual can be maintained long term,
UI and tool options change so try to avoid having a lot of images (when they are not especially necessary).
Otherwise, this becomes too much of a maintenance burden.

.. Editors Note:
In some cases, it is better to specify the image location e.g. tall and narrow images such as nodes.

Videos
======

Videos from YouTube and Vimeo can be embedded using::

.. youtube:: ID

.. vimeo:: ID

The ``ID`` is found in the video's URL, e.g:

- The ID for ``https://www.youtube.com/watch?v=Ge2Kwy5EGE0`` is ``Ge2Kwy5EGE0``
- The ID for ``https://vimeo.com/15837189`` is ``15837189``

Usage Guides
------------

- Avoid adding videos which rely on voice, as this is difficult to translate.
- Do not embed video tutorials as a means of explaining a feature, the writing itself should explain it adequately
(though you may include a link to the video at the bottom of the page under the heading ``Tutorials``).

Useful Constructs
=================

- ``|BLENDER_VERSION|`` -- Resolves to the current Blender version.
- ``:abbr:`SSAO (Screen Space Ambient Occlusion)``` --
Abbreviations display the full text as a tooltip for the reader.
- ``:term:`Manifold``` -- Links to an entry in the :doc:`Glossary &lt;/glossary/index&gt;`.

Cross References and Linkage
============================

You can link to another document in the manual with::

:doc:`The Title &lt;/section/path/to/file&gt;`

To link to a specific section in another document (or the same one), explicit labels are available::

.. _sample-label:

[section or image to reference]

Some text :ref:`Optional Title &lt;sample-label&gt;`

Linking to a title in the same file::

Titles are Targets
==================

Body text.

Implicit references, like `Titles are Targets`_

Linking to the outside world::

`Blender Website &lt;https://www.blender.org&gt;`__

Directory layout
================

Sections should be generally structured as follows:

- ``directory_name/``

- ``index.rst`` (contains links to internal files)
- ``introduction.rst``
- ``section_1.rst``
- ``section_2.rst``

For example:

- ``rendering/``

- ``index.rst``
- ``cycles/``

- ``index.rst``
- ``introduction.rst``
- ``materials/``

- ``index.rst``
- ``introduction.rst``
- ``volumes.rst``

The idea is to enclose all the content of a section inside of a folder. Ideally every section
should have an ``index.rst`` (containing the TOC for that section) and an ``introduction.rst``
(introducing) to the contents of the section.

Table of Contents
-----------------

By default, a table of contents should show two levels of depth::

.. toctree::
:maxdepth: 2

introduction.rst
perspective.rst
depth_of_field.rst

Further Reading
===============

To learn more about reStructuredText, see:

`Sphinx RST Primer &lt;http://www.sphinx-doc.org/en/stable/rest.html&gt;`__
Good basic introduction.
`Docutils reStructuredText reference &lt;http://docutils.sourceforge.net/rst.html&gt;`__
Links to reference and user documentation.
.. highlight:: rst

*******************
Writing Style Guide
*******************

Primary Goals
=============

The main goals for this manual are as follows.

User Focused
While some areas of computer graphics are highly technical,
this manual shall be kept understandable by non-technical users.
Complete
So there is a canonical source of truth for each of Blender's key areas.
This does not mean we have to document every small detail,
but users should not have to rely on searching elsewhere to find the purpose of key features.
Concise
Computer graphics is an incredibly interesting field,
there are many rules, exceptions to the rules and interesting details.
Expanding into details can add unnecessary content,
so keep the text concise and relevant to the topic at hand.
Maintainable
Keep in mind that Blender has frequent releases,
so try to write content that will not have to be redone
the moment some small change is made.
This also helps a small documentation community to maintain the manual.

Content Guidelines
==================

In order to maintain a consistent writing style within the manual,
please keep this page in mind and only deviate from it when you have a good reason to do so.

Rules of thumb:

- Spell checking is *strongly* recommended.
- Use American English (e.g: modeling and not modelling, color and not colour).
- Take care about grammar, appropriate wording and use simple English.
- Keep sentences short and clear, resulting in text that is easy to read, objective and to the point.
- Including why or how an option might be useful is a good idea.
- If you are unsure about how a feature works, ask someone else or find out who developed it and ask them.

To be avoided:

- Avoid writing in first person perspective, about yourself or your own opinions.
- Avoid `weasel words &lt;https://en.wikipedia.org/wiki/Weasel_word&gt;`__ and being unnecessarily vague, e.g:

| "Reloading the file will probably fix the problem"
| "Most people do not use this option because ..."
- Avoid including specific details such as:

| "Blender has 23 different kinds of modifiers."
| "Enabling previews adds 65536 bytes to the size of each Blend file
(unless it is compressed)."

These details are not useful for users to memorize and they become quickly outdated.
- Avoid documenting bugs.

Blender often has 100's of bugs fixed between releases, so it is not realistic to reference
even a fraction of them from the manual, while keeping this list up to date.

Issues which are known to the developers and are not going to be resolved before the next release
can be documented as *Known Limitations*.
In some cases, it may be best to include them in the :doc:`troubleshooting &lt;/troubleshooting/index&gt;` section.
- Avoid Product Placements, i.e. unnecessarily promoting software or hardware brands.
Keep content vendor-neutral where possible.
- Avoid technical explanations about the mathematical/algorithmic implementation of a feature
if there is a simpler way to explain it.

(e.g. explaining how mesh smoothing algorithms work is unnecessary,
but the blending types of a mix node do need a mathematical explanation).
- Avoid repetition of large portions of text. Simply explain it once, and from then on refer to that explanation.

For general terminology, consider defining a ``:term:`` in the :doc:`glossary &lt;/glossary/index&gt;`.
- Avoid enumerations of similar options, such as listing every preset or every frame-rate in a select menu.

Their contents may be summarized or simply omitted.
-- Such lists are only showing what is already *obvious* in the interface
and end up being a lot of text to read and maintain.
- Avoid documenting changes in Blender between releases, that is what the release notes are for.
We only need to document the current state of Blender.
- Unless the unit a value is measured in is obscure and unpredictable, there is no need to mention it.
- Do not simply copy the tool-tips from Blender.
-- People will come to the manual to learn *more* than is provided by the UI.

As a last resort you can add comment (which is not shown in the HTML page, but useful for other editors)::

.. TODO, how does this tool work? ask Joe Blogg's.

Glossary
--------

This section is specifically about the :doc:`Glossary &lt;/glossary/index&gt;` section,
where we define common terms in Blender and computer-graphics.

Rules of thumb:

- Define the term before providing any further information.
- Avoid using constructs such as "It is" or "xyz is" before the definition.
- Avoid repeating the term immediately or using it in the definition.
- Avoid adding terms not found in Blender's interface or the manual.
- Avoid overly long entries.
If an explanation of a complex term is needed, supplement with external links.
- Avoid duplicating documentation;
if explaining the term is the primary focus of another section of the manual
(e.g. if the term is the name of a tool),
either just link to that section, or avoid creating a glossary entry entirely.
- URL references are to be added at the end, formatted as follows, e.g::

See also `OpenGL &lt;https://en.wikipedia.org/wiki/OpenGL&gt;`__ on Wikipedia.

Examples
^^^^^^^^

This entry::

Displacement Mapping
Uses a grayscale heightmap, like Bump Mapping,
but the image is used to physically move the vertices of the mesh at render time.
This is of course only useful if the mesh has large amounts of vertices.

Would be written like this instead, putting a definition first::

Displacement Mapping
A method for distorting vertices based on an image.
Similar to Bump Mapping, but instead operates on the mesh's actual geometry.
This relies on the mesh having enough geometry.

----

This entry::

Doppler Effect
The Doppler effect is the change in pitch that occurs
when a sound has a velocity relative to the listener.

Would be written more like this, avoiding the immediate repetition of the term::

Doppler Effect
Perceived change in pitch that occurs
when the source of a sound is moving relative to the listener.

----

This entry::

Curve
It is a class of objects.
In Blender there are Bézier curves and NURBS curves.

Would be written more like this, avoiding the "it is"::

Curve
A type of object defined in terms of a line interpolated between Control Vertices.
Available types of curves include Bézier and NURBS.
.. highlight:: sh

**********
Contribute
**********

On this page French (``fr``) is used for examples, however, it can be replaced with other
`languages codes &lt;https://www.gnu.org/software/gettext/manual/html_node/Usual-Language-Codes.html&gt;`__.

To see which languages are currently available, you can browse the repository:
https://developer.blender.org/diffusion/BMT/browse/trunk/blender_docs/locale

.. note::

First of all, it is assumed that you have the manual already building.
If you have not done this already go back too the
:ref:`Getting Started &lt;about-getting-started&gt;` section.

Installing your Language Files
==============================

.. note::

Be sure to change the ``/fr`` suffixes to the language you are translating!

You can remove the suffix to check out all languages too, however, this will be a much larger download.

From the directory containing your checkout of the manual run::

svn checkout https://svn.blender.org/svnroot/bf-manual-translations/trunk/blender_docs/locale/fr locale/fr

This will create a ``locale/fr`` subdirectory.

You should have a directory layout like this::

blender_docs
|- locale/
|  |- fr/
|  |  |- LC_MESSAGES/
|- manual/

A PO Editor
===========

To make edit the PO files you will need to install a PO editor.
We recommended that you use `Poedit &lt;https://poedit.net/&gt;`__
however, any PO editor will do.

.. note::

For Linux users you will have to check with
your distribution's software center for a version of Poedit.

Building with Translations
==========================

.. note::

This is optional, translations are automatically built online, eg:
https://docs.blender.org/manual/fr/dev/

This is quite involved,
so it is not be expected that translators should be doing their own builds locally.

Now you can build the manual with the translation applied::

make -e SPHINXOPTS="-D language='fr'"

If you are on MS-Windows and do not have ``make``, run::

sphinx-build -b html -D language=fr ./manual ./build/html

Now you will have a build of the manual with translations applied.

Editing Translation Files
=========================

Now you can edit the PO translation files, eg:

Original RST File
``manual/getting_started/about_blender/introduction.rst``
Generated PO File
``locale/fr/LC_MESSAGES/getting_started/about_blender/introduction.po``

The modified ``.po`` files can be edited and committed back to svn.

Maintenance
===========

.. _translations-fuzzy-strings:

Keeping track of fuzzy strings
------------------------------

When the manual is updated, those translations which are outdated will be marked as fuzzy.
To keep track with that, you can use a tool we created for that task.

You can do this by running::

make report_po_progress

This will only give a quick summary however, you can get more information by running::

python tools/report_translation_progress.py locale/fr/

You should get a list of all the files with information about the number of empty and fuzzy strings.
For more options see::

python tools/report_translation_progress.py --help

.. seealso::

- Instructions on this page are based on
`Sphinx Intl documentation &lt;http://www.sphinx-doc.org/en/stable/intl.html&gt;`__
- The `translation design task &lt;https://developer.blender.org/T43083&gt;`__
for discussion on the process.

Updating PO Files
-----------------

As the original manual changes, the templates will need updating.
Note, doing this is not required,
as administrator usually update the files for all languages at once.
This allows all languages to be on the same version of the manual.
However, if you need to update the files yourself, it can be done as follows::

make update_po

The updated templates can then be committed to svn.

*TODO: document how to handle files being added/removed/moved.*

***********
Style Guide
***********

This page covers conventions concerning the translations.

.. note::

- We expect our readers to use the English version of Blender, not a translated one.
- The translations are licensed under the same :doc:`/about/license` as the original.

Should I translate\.\.\. ?
==========================

Maybe
-----

Hyperlinks
Can be translated, but only as an addition, not as a replacement.
See also `Adding Text`_

Technical Terms
Only translate these, when the localized expression is common!
See also `Technical Terms`_

Text you are not sure you understood
Simply mark the text as fuzzy and/or add a comment.
The next translator might understand it.

Never
-----

Images
You probably will not find the original scene if it is a screenshot of a file
and it is too much load on the server (and too much work for you).

Menu and button names
We expect our readers to use the English UI.

Text you do not understand
Do not translate it! It will do more harm than good!

Technical Terms
===============

.. Modified from https://wiki.blender.org/index.php/Meta:Guides/Translation_Guide

In general, the technical terms used in CG are quite new or even downright neologisms invented for the needs,
so they do not always have a translation in your language. Moreover,
a large part of Blender users use its English interface.

As a result, unless a term has an evident translation,
you should preferably use the English one, *putting it in italic*.
You can then find a translation for it, which you will use from times to times (e.g. to avoid repetitions...).
This is also valid in the other way: even when a term has a straightforward translation,
do not hesitate to use its English version from times to times, to get the reader used with it...

If a term is definitively not translatable, simply use the English one,
but make sure its manual entry is translated.

In the manual, the English term is written first (to maintain alphabetic order)
with the translated entry following in parenthesis, when appropriate.

Adding Text
===========

Generally, **you should always translate exactly what is in the text**,
and avoid providing updates or extra information.

But sometimes that is necessary, for example when talking about the manual
itself: To a foreign reader it is not clear, that he or she can contribute English text only,
whereas this is obvious to an English reader.

In these (rare) cases you can and should provide extra information.

Keeping Pages Up To Date
========================

When the manual is updated, those translations which are outdated will be marked as fuzzy.
To keep track with that, you can use a tool we created for that task,
see :ref:`How to install it &lt;translations-fuzzy-strings&gt;`.

.. seealso::

https://wiki.blender.org/index.php/Meta:Guides/Translation_Guide
.. _about-index:

####################
About this Manual
####################

.. toctree::
:maxdepth: 2

introduction.rst
license.rst
whats_new.rst
contribute/index.rst

**********************************
Introduction to the Blender Manual
**********************************

This manual aims to be a complete and concise source of information
to help you to become familiar with the application.

Conventions
===========

Keyboards
---------

Hotkey letters are shown in this manual like they appear on a keyboard; for example,

:kbd:`G`
refers to the lowercase ``g``.
:kbd:`Shift`, :kbd:`Ctrl`, :kbd:`Alt`
are specified as modifier keys.
:kbd:`Ctrl-W`, :kbd:`Shift-Alt-A`, ...
indicates that these keys should be pressed simultaneously
:kbd:`Numpad0` to :kbd:`Numpad9`, :kbd:`NumpadPlus`
refer to the keys on the separate numeric keypad.

Other keys are referred to by their names,
such as :kbd:`Esc`, :kbd:`Tab`, :kbd:`F1` to :kbd:`F12`.
Of special note are the arrow keys, :kbd:`Left`, :kbd:`Right` and so on.

Mice
----

This manual referrers to mouse buttons as:

:kbd:`LMB`
Left Mouse Button
:kbd:`RMB`
Right Mouse Button
:kbd:`MMB`
Middle Mouse Button
:kbd:`Wheel`
Scrolling the wheel.

.. _about-user-contribute:

Contribute
==========

The Blender Manual is a community driven effort to which anyone can contribute.
Either if you found a typo or if you want to improve the general quality of the documentation,
there are several options for helping out. You can:

#. Fix problems, improve the documentation and write new sections --
see how to :doc:`contribute &lt;/about/contribute/index&gt;`.
#. `Report problems
&lt;https://developer.blender.org/maniphest/task/edit/form/default/?project=PHID-PROJ-c4nvvrxuczix2326vlti&gt;`__
in the documentation.
#. Get involved in discussions through the `mailing list &lt;https://lists.blender.org/mailman/listinfo/bf-docboard&gt;`__
and ``#blenderwiki`` :ref:`IRC channel &lt;irc-channels&gt;`.

********
License
********

Blender itself is released under the
`GNU General Public License &lt;http://www.gnu.org/copyleft/gpl.html&gt;`__.
More info
`blender.org/about/license &lt;https://www.blender.org/about/license/&gt;`__.

Except where otherwise noted,
the content of the Blender Manual is available under a
`Creative Commons Attribution-ShareAlike 4.0 International License &lt;https://creativecommons.org/licenses/by-sa/4.0/&gt;`__
or any later version. Excluded from the CC-BY-SA are also the used logos,
trademarks, icons, source code and Python scripts.

Please attribute the "Blender Documentation Team" and
include a hyperlink (online) or URL (in print) to manual.
For example:

.. parsed-literal::

The |BLENDER_VER_MANUAL|_
by the `Blender Documentation Team &lt;https://developer.blender.org/project/profile/53/&gt;`__
is licensed under a |LICENSE|_.

.. |BLENDER_VER_MANUAL| replace:: Blender |version| Manual
.. _BLENDER_VER_MANUAL: https://docs.blender.org/manual/en/dev/
.. |LICENSE| replace:: CC-BY-SA v4.0
.. _LICENSE: https://creativecommons.org/licenses/by-sa/4.0/

See `Best practices for attribution &lt;https://wiki.creativecommons.org/wiki/Marking/Users&gt;`__ for further explanation.

It means, that when contributing to the manual you do not hold exclusive copyright to your text.
You are, of course, acknowledged and appreciated for your contribution.
However, others can change and improve your text in order to keep the manual consistent and up to date.

If you have questions about the license, feel free to contact the Blender Foundation:
foundation (at) blender (dot) org

Previous versions of the Blender Manual are made available under a
`Open Content License &lt;https://wiki.blender.org/index.php/BlenderWiki:Copyrights#Open_Content_License&gt;`__
v2.26 -- v2.77.
.. Editors note, only list large changes/additions limit the list to 20 items

**********
What's New
**********

This page lists major changes and additions to the manual.

- The new Version Switch is located at the bottom of the navigation (beta language switch only).
Please `report a bug 
&lt;https://developer.blender.org/maniphest/task/edit/form/default/?project=PHID-PROJ-c4nvvrxuczix2326vlti&gt;`__
if it behaves in unexpected manner.
(`rBM3490 &lt;https://developer.blender.org/rBM3490&gt;`__, Apr. 5).
- :doc:`Application Templates &lt;/advanced/app_templates&gt;`
(`rBM3462 &lt;https://developer.blender.org/rBM3462&gt;`__, Mar. 25).
- :doc:`Bendy Bones &lt;/rigging/armatures/bones/properties/bendy_bones&gt;`
(`rBM3215 &lt;https://developer.blender.org/rBM3215&gt;`__, Jan. 28).
- :doc:`Grease Pencil update &lt;/interface/grease_pencil/index&gt;`
(`rBM3188 &lt;https://developer.blender.org/rBM3188&gt;`__, Jan. 20).
- :doc:`New Pipeline Section &lt;/pipeline/index&gt;`
(`rBM3026 &lt;https://developer.blender.org/rBM3026&gt;`__, Dec. 7).
- :doc:`Track Position node &lt;/compositing/types/input/track_position&gt;`
(`rBM3014 &lt;https://developer.blender.org/rBM3014&gt;`__, Dec. 6).
- :doc:`Inpaint node &lt;/compositing/types/filter/inpaint&gt;`
(`rBM3011 &lt;https://developer.blender.org/rBM3011&gt;`__, Dec. 6).
- :doc:`Glare node &lt;/compositing/types/filter/glare&gt;`
(`rBM2998 &lt;https://developer.blender.org/rBM2998&gt;`__, Dec. 5).
- `Korean Translations &lt;https://docs.blender.org/manual/ko/dev/&gt;`__
(`rBM2980 &lt;https://developer.blender.org/rBM2980&gt;`__, Oct. 29).
- :doc:`Corner Pin node &lt;/compositing/types/distort/corner_pin&gt;`
(`rBM2978 &lt;https://developer.blender.org/rBM2978&gt;`__, Oct. 28).
- :doc:`Despeckle node &lt;/compositing/types/filter/despeckle&gt;` primer
(`rBM2975 &lt;https://developer.blender.org/rBM2975&gt;`__, Oct. 27).
- :doc:`Stabilizer panel &lt;/editors/movie_clip_editor/tracking/clip/properties/stabilization/index&gt;` update
(`rBM2840 &lt;https://developer.blender.org/rBM2840&gt;`__, Sep. 27).
- :doc:`Displacement controls &amp; bump mapping &lt;/render/cycles/materials/displacement&gt;`
(`rBM2776 &lt;https://developer.blender.org/rBM2776&gt;`__,
`rBM2773 &lt;https://developer.blender.org/rBM2773&gt;`__; Sep. 20).
- :doc:`Double edge mask node &lt;/compositing/types/matte/double_edge_mask&gt;`
(`rBM2775 &lt;https://developer.blender.org/rBM2475&gt;`__, Aug. 25).
- :doc:`Keying node &lt;/compositing/types/matte/keying&gt;`
(`rBM2773 &lt;https://developer.blender.org/rBM2473&gt;`__, Aug. 25).
- :doc:`Keying Screen node &lt;/compositing/types/matte/keying_screen&gt;`
(`rBM2772 &lt;https://developer.blender.org/rBM2472&gt;`__, Aug. 25).

*********************
Application Templates
*********************

Usage
=====

Application templates are a feature that allows you to define a re-usable configuration
that can be selected to replace the default configuration,
without requiring a separate Blender installation or overwriting your personal settings.

.. figure:: /images/advanced-app_template-file_menu.png
:align: right
:scale: 50 %

Using templates from the file menu.

.. figure:: /images/advanced-app_template-splash.png
:scale: 33 %

Selecting a template from the splash screen.

Application templates can be selected from the splash screen or the file menu *(as shown above)*.

When there are no templates found the menu will not be displayed on the splash screen.

New application-templates can be installed from the file menu.

If you would like to keep the current application-template active on restarting Blender, save your user-preferences.

Motivation
----------

In some cases its not enough to write a single script or add-on,
and expect someone to replace his user-preferences and startup file, install scripts and change his key-map.

The goal of application-templates is to support switching to a customized configuration
without disrupting your existing settings &amp; installation.

This means people can build their own *applications* on top of Blender that can be easily distributed.

Details
-------

An application-template may define its own:

Startup File
The default file to load with this template.
User Preferences
Only certain user-preferences from a template are used:

- Themes.
- Add-ons.
- Keymaps.
- Viewport lighting.
Splash Screen
Templates may provide their own splash screen image.
Python Scripts
While templates have access to the same functionality as any other scripts,
typical operations include:

- Modifying and replacing parts of the user-interface.
- Defining new menus, key-maps &amp; tools.
- Defining a custom add-on path for template specific add-ons.

Templates also have their own user configuration so saving startup while using a template
won't overwrite your default startup file.

Directory Layout
----------------

Templates may be located in one of two locations within the ``scripts`` directory.

Template locations:
| ``{BLENDER_USER_SCRIPTS}/startup/bl_app_templates_user``
| ``{BLENDER_SYSTEM_SCRIPTS}/startup/bl_app_templates_system``

User configuration is stored in a sub directory,

Without a template:
| ``./config/startup.blend``
| ``./config/userpref.blend``
With a template:
| ``./config/{APP_TEMPLATE_ID}/startup.blend``
| ``./config/{APP_TEMPLATE_ID}/userpref.blend``

See :ref:`getting-started_installing-config-directories` for details on script and configuration locations.

Template Contents
=================

Each of the following files can be used for application templates but are optional.

``startup.blend``
Factory startup file to use for this template.
``userpref.blend``
Factory user-preferences file to use for this template.

*(As noted previously, this is only used for a subset of preferences).*
``splash.png``, ``splash_2x.png``
Splash screen do override Blender's default artwork (not including header text).

Must be ``501x230`` or ``1002x460`` (used for HiDPI monitors).
``__init__.py``
A Python script which must contain ``register`` and ``unregister`` functions.

.. note::

Bundled blend files ``startup.blend`` and ``userpref.blend`` are considered *Factory Settings*
and are never overwritten.

The user may save his own startup/preferences while using this template which will override them.

The original template settings can be loaded using: *Load Template Factory Settings*
from the file menu in much the same way *Load Factory Settings* works.
.. DO NOT EDIT THIS FILE, GENERATED BY ``blender_help_extract.py``

**********************
Command Line Arguments
**********************

Blender |BLENDER_VERSION| Usage: blender [args ...] [file] [args ...]

Render Options
==============

``-b``, ``--background``
Run in background (often used for UI-less rendering).
``-a``, ``--render-anim``
Render frames from start to end (inclusive).
``-S``, ``--scene`` ``&lt;name&gt;``
Set the active scene ``&lt;name&gt;`` for rendering.
``-f``, ``--render-frame`` ``&lt;frame&gt;``
Render frame ``&lt;frame&gt;`` and save it.

* ``+&lt;frame&gt;`` start frame relative, ``-&lt;frame&gt;`` end frame relative.
* A comma separated list of frames can also be used (no spaces).
* A range of frames can be expressed using ``..`` seperator between the first and last frames (inclusive).

``-s``, ``--frame-start`` ``&lt;frame&gt;``
Set start to frame ``&lt;frame&gt;``, supports +/- for relative frames too.
``-e``, ``--frame-end`` ``&lt;frame&gt;``
Set end to frame ``&lt;frame&gt;``, supports +/- for relative frames too.
``-j``, ``--frame-jump`` ``&lt;frames&gt;``
Set number of frames to step forward after each rendered frame.
``-o``, ``--render-output`` ``&lt;path&gt;``
Set the render path and file name.
Use ``//`` at the start of the path to render relative to the blend-file.

The ``#`` characters are replaced by the frame number, and used to define zero padding.

* ``ani_##_test.png`` becomes ``ani_01_test.png``
* ``test-######.png`` becomes ``test-000001.png``

When the filename does not contain ``#``, The suffix ``####`` is added to the filename.

The frame number will be added at the end of the filename, eg:

.. code-block:: sh

blender -b foobar.blend -o //render_ -F PNG -x 1 -a

``//render_`` becomes ``//render_####``, writing frames as ``//render_0001.png``
``-E``, ``--engine`` ``&lt;engine&gt;``
Specify the render engine.
Use -E help to list available engines.
``-t``, ``--threads`` ``&lt;threads&gt;``
Use amount of ``&lt;threads&gt;`` for rendering and other operations
[1-64], 0 for systems processor count.

Format Options
==============

``-F``, ``--render-format`` ``&lt;format&gt;``
Set the render format. Valid options are ``TGA`` ``RAWTGA`` ``JPEG`` ``IRIS`` ``IRIZ`` ``AVIRAW`` ``AVIJPEG`` ``PNG`` 
``BMP``

Formats that can be compiled into Blender, not available on all systems: ``HDR`` ``TIFF`` ``EXR`` ``MULTILAYER`` 
``MPEG`` ``FRAMESERVER`` ``QUICKTIME`` ``CINEON`` ``DPX`` ``DDS`` ``JP2``
``-x``, ``--use-extension`` ``&lt;bool&gt;``
Set option to add the file extension to the end of the file.

Animation Playback Options
==========================

``-a`` ``&lt;options&gt;`` ``&lt;file(s)&gt;``
Playback ``&lt;file(s)&gt;``, only operates this way when not running in background.

``-p`` ``&lt;sx&gt;`` ``&lt;sy&gt;``   
Open with lower left corner at ``&lt;sx&gt;``, ``&lt;sy&gt;``.
``-m`` 
Read from disk (Do not buffer)
``-f`` ``&lt;fps&gt;`` ``&lt;fps-base&gt;``
Specify FPS to start with.
``-j`` ``&lt;frame&gt;``
Set frame step to ``&lt;frame&gt;``.
``-s`` ``&lt;frame&gt;``
Play from ``&lt;frame&gt;``.
``-e`` ``&lt;frame&gt;``
Play until ``&lt;frame&gt;``.

Window Options
==============

``-w``, ``--window-border``
Force opening with borders.
``-W``, ``--window-borderless``
Force opening without borders.
``-p``, ``--window-geometry`` ``&lt;sx&gt;`` ``&lt;sy&gt;`` ``&lt;w&gt;`` ``&lt;h&gt;``
Open with lower left corner at ``&lt;sx&gt;``, ``&lt;sy&gt;`` and width and height as ``&lt;w&gt;``, ``&lt;h&gt;``.
``-con``, ``--start-console``
Start with the console window open (ignored if -b is set), (Windows only).
``--no-native-pixels``
Do not use native pixel size, for high resolution displays (MacBook ``Retina``).

Game Engine Specific Options
============================

``-g`` Game Engine specific options

``fixedtime`` 
Run on 50 hertz without dropping frames.
``vertexarrays``
Use Vertex Arrays for rendering (usually faster).
``nomipmap``
No Texture Mipmapping.
``linearmipmap``
Linear Texture Mipmapping instead of Nearest (default).

Python Options
==============

``-y``, ``--enable-autoexec``
Enable automatic Python script execution (default).
``-Y``, ``--disable-autoexec``
Disable automatic Python script execution (pydrivers &amp; startup scripts).

``-P``, ``--python`` ``&lt;filename&gt;``
Run the given Python script file.
``--python-text`` ``&lt;name&gt;``
Run the given Python script text block.
``--python-expr`` ``&lt;expression&gt;``
Run the given expression as a Python script.
``--python-console``
Run blender with an interactive console.
``--python-exit-code``
Set the exit-code in [0..255] to exit if a Python exception is raised
(only for scripts executed from the command line), zero disables.
``--addons``
Comma separated list of add-ons (no spaces).

Debug Options
=============

``-d``, ``--debug``
Turn debugging on.

* Enables memory error detection
* Disables mouse grab (to interact with a debugger in some cases)
* Keeps Python's ``sys.stdin`` rather than setting it to None
``--debug-value`` ``&lt;value&gt;``
Set debug value of ``&lt;value&gt;`` on startup.

``--debug-events``
Enable debug messages for the event system.
``--debug-ffmpeg``
Enable debug messages from FFmpeg library.
``--debug-handlers``
Enable debug messages for event handling.
``--debug-libmv``
Enable debug messages from libmv library.
``--debug-cycles``
Enable debug messages from Cycles.
``--debug-memory``
Enable fully guarded memory allocation and debugging.
``--debug-jobs``
Enable time profiling for background jobs.
``--debug-python``
Enable debug messages for Python.
``--debug-depsgraph``
Enable debug messages from dependency graph.
``--debug-depsgraph-no-threads``
Switch dependency graph to a single threaded evaluation.
``--debug-gpumem``
Enable GPU memory stats in status bar.
``--debug-wm``
Enable debug messages for the window manager, also prints every operator call.
``--debug-all``
Enable all debug messages.

``--debug-fpe``
Enable floating point exceptions.
``--disable-crash-handler``
Disable the crash handler.

Misc Options
============

``--factory-startup``
Skip reading the startup.blend in the users home directory.

``--env-system-datafiles``
Set the ``BLENDER_SYSTEM_DATAFILES`` environment variable.
``--env-system-scripts``
Set the ``BLENDER_SYSTEM_SCRIPTS`` environment variable.
``--env-system-python``
Set the ``BLENDER_SYSTEM_PYTHON`` environment variable.

``-nojoystick``
Disable joystick support.
``-noglsl``
Disable GLSL shading.
``-noaudio``
Force sound system to None.
``-setaudio``
Force sound system to a specific device.
NULL SDL OPENAL JACK

``-h``, ``--help``
Print this help text and exit.
``-R``
Register blend-file extension, then exit (Windows only).
``-r``
Silently register blend-file extension, then exit (Windows only).
``-v``, ``--version``
Print Blender version and exit.
``--``
End option processing, following arguments passed unchanged. Access via Python's ``sys.argv``.

Experimental Features
=====================

``--enable-new-depsgraph``
Use new dependency graph.
``--enable-new-basic-shader-glsl``
Use new GLSL basic shader.

Other Options
=============

``/?``
Print this help text and exit (windows only).
``--debug-freestyle``
Enable debug messages for FreeStyle.
``--debug-gpu``
Enable gpu debug context and information for OpenGL 4.3+.
``--disable-abort-handler``
Disable the abort handler.
``--verbose`` ``&lt;verbose&gt;``
Set logging verbosity level.

Argument Parsing
================

Arguments must be separated by white space, eg:

.. code-block:: sh

blender -ba test.blend

...will ignore the ``a``.

.. code-block:: sh

blender -b test.blend -f8

...will ignore ``8`` because there is no space between the ``-f`` and the frame value.

Argument Order
==============

Arguments are executed in the order they are given. eg:

.. code-block:: sh

blender --background test.blend --render-frame 1 --render-output '/tmp'

...will not render to ``/tmp`` because ``--render-frame 1`` renders before the output path is set.

.. code-block:: sh

blender --background --render-output /tmp test.blend --render-frame 1

...will not render to ``/tmp`` because loading the blend-file overwrites the render output that was set.

.. code-block:: sh

blender --background test.blend --render-output /tmp --render-frame 1

...works as expected.

Environment Variables
=====================

:BLENDER_USER_CONFIG:      Directory for user configuration files.
:BLENDER_USER_SCRIPTS:     Directory for user scripts.
:BLENDER_SYSTEM_SCRIPTS:   Directory for system wide scripts.
:BLENDER_USER_DATAFILES:   Directory for user data files (icons, translations, ..).
:BLENDER_SYSTEM_DATAFILES: Directory for system wide data files.
:BLENDER_SYSTEM_PYTHON:    Directory for system python libraries.
:TEMP:                     Store temporary files here.
:TMP: or $TMPDIR           Store temporary files here.
:SDL_AUDIODRIVER:          LibSDL audio driver - alsa, esd, dma.
:PYTHONHOME:               Path to the python directory, eg. /usr/lib/python.

###############
Command Line
###############

.. toctree::
:maxdepth: 1

introduction.rst
arguments.rst
.. Information here should be shorter. For example, We do not need to explain what an .app is.

************
Introduction
************

The *Console Window* is an operating system text window that displays messages about
Blender operations, status, and internal errors.

Use Cases:

- For automation and batch processing which require launching Blender
with different :doc:`arguments &lt;/advanced/command_line/arguments&gt;`.
- For Python development, to see the output of the ``print()`` command.
- If Blender exits unexpectedly, the messages may indicate the cause or error.
- When troubleshooting, to see the output of ``--debug`` messages.

Platform Dependant Instructions
===============================

Linux
-----

.. figure:: /images/interface-window_system-console-linux.png
:align: right
:width: 360px

Starting Blender from a Linux console window.

The Blender *Console Window* in Linux will typically only be visible on the desktop
if Blender is manually started from a terminal, as Blender outputs to the
*Console Window* it is started from.

Depending on your desktop environment setup, a Blender icon may appear on your desktop or an
entry for Blender is added to your menu after you install Blender.
When you start Blender using a desktop icon or menu entry rather than a Terminal window, the
Blender *Console Window* text will most likely be hidden on the Terminal that your
`XWindow &lt;https://en.wikipedia.org/wiki/X_Window_System&gt;`__ server was started from.

This screenshot shows Blender started from a Linux Terminal and the
resulting console text being printed to it.

macOS
-----

.. figure:: /images/interface-window_system-console-mac.png
:align: right
:width: 360px

Starting Blender from a macOS console window.

macOS uses "files" with the ``.app`` extension called *applications*.
These files are actually folders that appear as files in Finder.
In order to run Blender you will have to specify that path to the Blender executable inside this folder,
to get all output printed to the terminal.
You can start a terminal from :menuselection:`Applications --&gt; Utilities`.
The path to the executable in the ``.app`` folder is ``./blender.app/Contents/MacOS/blender``.

If you have Blender installed in the Applications folder,
the following command can be used:

.. parsed-literal:: /Applications/blender-\ |BLENDER_VERSION|/blender.app/Contents/MacOS/blender

MS-Windows
----------

When Blender is started on a MS-Windows operating system,
the *Console Window* is first created as a separate window on the desktop.
The main Blender window will also appear and the *Console Window* will then be toggled off.
To display the console again, go to :menuselection:`Window --&gt; Toggle System Console`.

.. figure:: /images/interface_window_system-console_windows.png

Blender’s Console Window on MS-Windows.

The screenshot shows the Blender *Console Window* on MS-Windows
directly after starting Blender and then a short while later after opening a file along with
the relevant messages.

.. tip:: Closing the Blender Console Window

Closing the *Console Window* will also close Blender, losing any unsaved work.

To turn off the console without closing Blender,
just run *Toggle System Console* again from the menu (as mentioned above).

Console Window Status and Error Messages
========================================

The *Blender Console Window* can display many different types of Status and Error Messages.
Some messages simply inform the user what Blender is doing, but have no real impact on Blender's ability to function.
Other messages can indicate serious errors that will most likely prevent Blender carrying out a particular task and
may even make Blender non-responsive or shut down completely. The *Blender Console Window* messages can
also originate internally from within the Blender code or from external sources such as
:doc:`Python scripts &lt;/preferences/addons&gt;`.

Common Messages
---------------

- ``found bundled python: (FOLDER)``

This message indicates that Blender was able to find the :ref:`Python &lt;scripting-index&gt;`
library for the Python interpreter embedded within Blender.
If this folder is missing or unable to be found,
it is likely that an error will occur, and this message will not appear.

- ``malloc returns nil()``

When Blender carries out operations that require extra memory (RAM), it calls a function called malloc
(short for memory allocate) which tries to allocate a requested amount of memory for Blender.
If this cannot be satisfied, malloc will return nil/null/0 to indicate that it failed to carry out the request.
If this happens Blender will not be able to carry out the operation requested by the user.
This will most likely result in Blender operating very slowly or shutting down.
If you want to avoid running out of memory you can install more memory in your system,
reduce the amount of detail in your Blender models,
or shut down other programs and services which may be taking up memory that Blender could use.
.. _advanced-index:

###########
Advanced
###########

This chapter covers advanced use (topics which may not be required for typical usage).

.. toctree::
:maxdepth: 1

command_line/index.rst
scripting/index.rst
app_templates.rst
limits.rst

**************
Working Limits
**************

.. Note to editors:
Please excuse the complicated Python scripts on this page,
this is not something we do frequently in this manual,
Its just for such explicit technical details,
its useful to be able to validate its correct (or adjust the information shown).
- ideasman42

Space
=====

While object positions, vertex locations are not clamped, larger values become increasingly imprecise.

To get an idea of the precision you can work with using different scales.

Heres a table of scales and their associated accuracy.

.. # Python script used to generate the values below
import ctypes
from sys import platform as _platform
_libm = ctypes.cdll.LoadLibrary('libm.so.6')
_funcname_f = 'nextafterf'
_nextafterf = getattr(_libm, _funcname_f)
_nextafterf.restype = ctypes.c_float
_nextafterf.argtypes = [ctypes.c_float, ctypes.c_float]
i = 10
while i &lt; 10000000:
delta = _nextafterf(i, i + 1) - i
print(":{scale:,}: 1/{div:,}\\ :sup:`th`".format(scale=i, div=int(1 / delta)))
i = i * 10

:10: 1/1,048,576\ :sup:`th`
:100: 1/131,072\ :sup:`th`
:1,000: 1/16,384\ :sup:`th`
:10,000: 1/1,024\ :sup:`th`
:100,000: 1/128\ :sup:`th`
:1,000,000: 1/16\ :sup:`th`

.. hint::

For a rough rule of thumb, values within -5,000/+5,000 are typically reliable (range of 10,000).

Internally *single precision* floating point calculations are used.

Time
====

.. # Python script used to generate the values below
from datetime import timedelta
maxframe = 500000
for fps in (24, 25, 30, 60):
seconds = maxframe / fps
print(":%d fps: %d hours, %d seconds." %
(fps, seconds // 3600, seconds % 3600 // 60))

The maximum number of frames for each scene is currently 500,000, and allows for continuous shots for durations of:

:24 fps: 5 hours, 47 seconds.
:25 fps: 5 hours, 33 seconds.
:30 fps: 4 hours, 37 seconds.
:60 fps: 2 hours, 18 seconds.

.. note::

In practice, a finished work is typically composted of output from many scenes.
So this limit does not prevent you from creating longer works.

Text Fields
===========

Fixed strings are used internally, and while it is not useful to list all limits, here are some common limits.

:directory: 767
:file-name: 255
:file-path: 1023
:identifier: 63

*Used for data-block names, modifiers, vertex-groups, UV-layers...*

.. note::

Multi-byte encoding means some unicode characters use more than a single ASCII character.
.. _scripting-index:

################################
Scripting &amp; Extending Blender
################################

.. toctree::
:maxdepth: 2

introduction.rst
security.rst

************
Introduction
************

Python is an interpreted, interactive,
object-oriented programming language. It incorporates modules, exceptions, dynamic typing,
very high-level dynamic data types, and classes.
Python combines remarkable power with very clear syntax.

Python scripts are a powerful and versatile way to extend Blender functionality.
Most areas of Blender can be scripted, including Animation, Rendering, Import and Export,
Object Creation and the scripting of repetitive tasks.

To interact with Blender, scripts can make use of the tightly integrated API
(Application Programming Interface).

General information
===================

Links that are useful while writing scripts:

- `Python.org &lt;https://www.python.org/&gt;`__
- General information about Python.
- `Blender Python API &lt;https://www.blender.org/api/blender_python_api_current/&gt;`__
- Official API documentation. Use this for referencing while writing scripts.
- `API Introduction &lt;https://www.blender.org/api/blender_python_api_current/info_quickstart.html&gt;`__
- A short introduction to get you started with the API. Contains examples.
- `CookBook &lt;https://wiki.blender.org/index.php/Dev:Py/Scripts/Cookbook&gt;`__
- A section of handy code snippets (yet to be written).

Links that deal with distributing your scripts:

- `Sharing scripts &lt;https://wiki.blender.org/index.php/Dev:Doc/Process/Addons&gt;`__
- Information on how to share your scripts and get them included in the official Blender distribution.
- `Creating Add-ons &lt;https://wiki.blender.org/index.php/Dev:Py/Scripts/Guidelines/Addons&gt;`__
- Add-ons are used to encapsulate and distribute scripts.
- `Add-ons project &lt;https://developer.blender.org/project/profile/3/&gt;`__
- Project to maintain a central repository of extensions to Blender.

Getting Started
===============

.. rubric:: Manual links

The following links take you from the basics to the more advanced
concepts of Python scripting for Blender.

- :doc:`Text Editor &lt;/editors/text_editor&gt;`
- :doc:`Python Console &lt;/editors/python_console&gt;`
- Info Editors :ref:`info-report-console`

.. rubric:: External links

Here are external links containing a lot of good information to start learning how to write scripts for Blender:

- `Introductory tutorial by Satish Goda
&lt;https://sites.google.com/site/satishgoda/blender/learningblender25/introduction-to-blender-python-api&gt;`__
- Takes you from the beginning and teaches how to do basic API manipulations.
- `Ira Krakow's video tutorials &lt;https://www.youtube.com/watch?v=vmhU_whC6zw&gt;`__
- First video in a series of video tutorials.
- `Quickstart guide &lt;https://en.wikibooks.org/wiki/Blender_3D:_Blending_Into_Python/2.5_quickstart&gt;`__
- A quick start guide for people who already have some familiarity with Python and Blender.
- `Examples thread &lt;http://blenderartists.org/forum/showthread.php?t=164765&gt;`__
- A forum thread containing many short working script examples.
- `Introduction to Python
&lt;https://cgcookie.com/archive/introduction-to-scripting-with-python-in-blender/&gt;`__
- An one-hour video tutorial introducing Python and the Blender API.

Extending Blender
=================

Add-ons
-------

Add-ons are scripts you can enable to gain extra functionality within Blender,
they can be enabled from the User Preferences.

Outside of the Blender executable,
there are literally hundreds of add-ons written by many people:

- Officially supported add-ons are bundled with Blender.
- Other **Testing** add-ons are included in development builds but not official releases.
Many of them work reliably and are very useful but are not ensured to be stable for release.

For an overview of all add-ons available see the
`Scripts Catalog &lt;https://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts&gt;`__.

Scripts
-------

Apart from add-ons, there are also scripts you can use to extend Blender's functionality:

- Modules: Utility libraries for import into other scripts.
- Presets: Settings for Blender's tools and key configurations.
- Startup: These files are imported when starting Blender.
They define most of Blender's UI, as well as some additional core operators.
- Custom scripts: In contrast to add-ons they are typically intended for one-time execution via the
:doc:`Text Editor &lt;/editors/text_editor&gt;`.

Saving your own scripts
-----------------------

File location
^^^^^^^^^^^^^

All scripts are loaded from the ``scripts`` folder of the
:doc:`local, system and user paths &lt;/getting_started/installing/configuration/directories&gt;`.

You can setup an additional search path for scripts in
:ref:`prefs-file-paths` :menuselection:`User Preferences --&gt; File Paths`.

Installation
^^^^^^^^^^^^

Add-ons are conveniently installed through Blender in the :doc:`User Preferences &lt;/preferences/addons&gt;`.
Click the :menuselection:`Install from File...` button and select the ``.py`` or ``.zip`` file.

To manually install scripts or add-ons place them in the ``add-ons``,
``modules``, ``presets`` or ``startup`` directory according to their type.
See the description above.

You can also run scripts by loading them in the :doc:`Text Editor &lt;/editors/text_editor&gt;`.

********************
Scripting &amp; Security
********************

The ability to include Python scripts within blend-files is valuable for advanced tasks such
as rigging, automation and using the Game Engine.
However, it poses a security risk since Python does not restrict what a script can do.

Therefore, you should only run scripts from sources you know and trust.

Automatic execution is disabled by default,
however, some blend-files need this to function properly.

When a blend-file tries to execute a script and is not allowed, a message will appear in the
header with the option to **Reload Trusted** or **Ignore** the message.

.. figure:: /images/animation_drivers_troubleshooting_autorun-info-header.png

Info Header.

Scripts in Blend Files
======================

Auto Execution
--------------

Here are the different ways blend-files may automatically run scripts.

Registered Text-Blocks
A text block can have its *Register* option enabled which means it will load on start.
Animation Drivers
Python expressions can be used to *Drive* values and are often used in more advanced rigs and animations.
Game Engine Auto-Start
Scripts are often used for game logic, blend-files can have *Auto Start* enabled with runs the game on load.

Manual Execution
----------------

There are other ways scripts in a blend-file may execute that require user
interaction (therefore will run even when auto-execution is off),
but you should be aware that this is the case since it is not necessarily obvious.

- Running a script in the text editor.
- Rendering with FreeStyle, because FreeStyle uses scripts to control line styles.
- Running the Game Engine.

Controlling Script Execution
============================

Blender provides a number of ways to control whether scripts
from a blend-file are allowed to automatically execute.

First of all, the File Browser has the option **Trusted Source** which you can use on a
case-by-case basis to control auto-execution.

However, you may forget to set this,
or open a file without going through the File Browser --
so you can change the default (described next).

Setting Defaults
----------------

In the *File* tab of the User Preferences,
there is the toggle :ref:`Auto Run Python Scripts &lt;prefs-auto-execution&gt;`.

This means the **Trusted Source** option in the File Browser will be enabled by default,
and scripts can run when blend-files are loaded without using the File Browser.

Once enabled you have the option to exclude certain directories,
a typical configuration would be to trust all paths except for the download directory.

.. figure:: /images/animation_drivers_troubleshooting_autorun-user-preference.png

Auto Run Python Scripts

Command Line
------------

You may want to perform batch rendering or some other task from the command line --
running Blender without an interface.

In this case, the User Preferences are still used but you may want to override them:

- Enable with ``-y`` or ``--enable-autoexec``
- Disable with ``-Y`` or ``--disable-autoexec``

Example
^^^^^^^

Rendering an animation in background mode, allowing drivers and other scripts to run:

.. code-block:: sh

blender --background --enable-autoexec my_movie.blend --render-anim

.. note::

These command line arguments can be used to start a regular Blender instance and will
still override the User Preferences.

*******
Actions
*******

When animating objects and properties in Blender, Actions record and contain the data.
As everything else in Blender, Actions are data-blocks.

.. figure:: /images/animation_actions_data3.png

Actions.

So when you animate an object by changing its location with keyframes,
the animation is saved to the Action.

Each property has a channel which it is recorded to, for example,
Cube.location.x is recorded to Channel X Location.
The *X location* and *Y location* properties can be shared across multiple objects,
if all objects have *X location* and *Y location* properties beneath them.

.. figure:: /images/animation_actions_keyframes.png

Graph Editor. Each Channel has an F-Curve represented by the lines between the keyframes.

Actions
Record and contain animation data.
Groups
Are groups of channels.
Channels
Record properties.
F-Curves
:doc:`F-Curve &lt;/editors/graph_editor/fcurves/introduction&gt;` are used to
interpolate the difference between the keyframes.
Keyframes
:doc:`Keyframes &lt;/animation/keyframes/introduction&gt;` are used to
set the values of properties bound to a point in time.

.. The hierarchy is created with the RNA data paths,

.. _animation-basics-actions-working-with-actions:

Working with Actions
====================

.. figure:: /images/animation_actions_create.png
:align: right

The Action data-block menu.

When you first animate an object by adding keyframes,
Blender creates an *Action* to record the data.

*Actions* can be managed with the *Action data-block menu*
in the Dope Sheet :doc:`Action Editor &lt;/editors/dope_sheet/action&gt;` header,
or the properties region of the :doc:`NLA Editor &lt;/editors/nla/properties_modifiers&gt;`.

If you are making multiple actions for the same object,
press the *F* button for each action,
this will give the actions a *Fake User* and will make Blender save the unlinked actions.

Objects can only use one *Action* at a time for editing.
The :doc:`NLA Editor &lt;/editors/nla/index&gt;` is used to blend multiple actions together.

Bake Action
===========

.. admonition:: Reference
:class: refbox

| Mode:     Object and Pose Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Animation --&gt; Animation --&gt; Action: Bake Action`
| Menu:     :menuselection:`3D View --&gt; Object/Pose --&gt; Animation --&gt; Bake Action...`

The *Bake Action* tool will apply interpolated frames into individual key frames.

This can be useful for adding deviation to a cyclic action like a :term:`walk cycle`.
This can also useful for keyframe animations created from drivers or constraints.

*************
Drivers Panel
*************

.. figure:: /images/animation_panel_drivers.png
:align: right

Drivers Panel.

This panel is located in the :doc:`Graph Editor &lt;/editors/graph_editor/introduction&gt;` with the mode set to Drivers.

The drivers panel is for setting up *Driver Variables* or a *Scripted Expression* which
will determine the value of the *Driver Value*.

Settings
--------

Update Dependencies
This will force an update for the Driver Value dependencies.
Remove Driver
Removes the driver from the property.

Type
There are two categories of scripts: built-in (average, sum, minimum and maximum) and
custom scripts (Scripted Expressions).

Average Value
Uses the average value of the referenced Driver Variables.
Sum Values
Uses the sum of the referenced Driver Variables.
Scripted Expression
Uses a Scripted Expression. See Expression.
You must write a Python expression which performs your own calculations on the Driver Variables.
Minimum Value
Uses the lowest value from the referenced Driver Variables.
Maximum Value
Uses the highest value from the referenced Driver Variables.

Expression
Scripted Expression.
Here you can add variables, real numbers, math operators, math functions, Python properties, driver functions.
See Driver Expression below for some examples.
Use Self
This allows for drivers to references their own data using the variable ``self``.
Useful for objects, bones, to avoid having to create a variable pointing to its self.
Show Debug Info
Shows the *Driver Value*.
Driver Value
The output value of the driver script.

Driver Variables
----------------

.. list-table::

* - .. figure:: /images/animation_driver_transform_channel2.png

Transform Channel Setup.

- .. figure:: /images/animation_driver_distance.png

Distance Setup.

Variable are references to properties or delta transformations which are a reference to two properties.

Add Variable
Adds a new Driver Variable.
Copy/Paste
ToDo.
Name
Name to use for scripted expressions/functions.
No spaces or dots are allowed and must start with a letter.

Variable Type
The type of variable to use.

Single Property
Use the value from some RNA property.
For example, the Ambient shading color from a material.
First select the type of ID-block, then the ID of the ID-block, then copy and
paste an RNA property :kbd:`Ctrl-V`.
See also :doc:`/data_system/custom_properties`.

ID-Type
The ID-Block type. Example: Key, Image, Object, Material.
ID
The ID of the ID-Block type. Example: "Material.001".
RNA Path
The RNA id name of the property. Example: 'ambient' from material shading.

Transform Channel
Use one of the Transform channels from an object or bone.

ID
ID of the object. Example: Cube, Armature, Camera.
Bone
ID of the Armature bone. Example: "Bone", "Bone.002", "Arm.r".
This option is for armatures.
Type
Example, X Location, X Rotation, X Scale.
Space
World Space, Transform Space, Local Space.

Rotational Difference
Use the rotational difference between two objects or bones.
Distance
Use the distance between two objects or bones.

Value
Shows the value of the variable.

Example
^^^^^^^^^^

.. figure:: /images/animation_driver_single_property.jpg

Setup of a Single Property.

.. seealso::

- :ref:`Extending Blender with Python &lt;scripting-index&gt;`.

- `Python &lt;https://www.python.org&gt;`__ and its `documentation &lt;https://docs.python.org/&gt;`__.
- `functions.wolfram.com &lt;http://functions.wolfram.com/&gt;`__.

###########
Drivers
###########

.. toctree::
:maxdepth: 2

introduction.rst
drivers_panel.rst
workflow_examples.rst
troubleshooting.rst

************
Introduction
************

Drivers are scripts. Their main purpose is to control properties with other properties.
In example the rotation of one object is controlled with the location of another object.

Adding &amp; Removing
=================

There are some different ways to add drivers in Blender.
After adding drivers they are usually modified in the *Graph Editor* with the mode set to *Drivers*.

Add Driver
----------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Context menu --&gt; Add Driver`
| Hotkey:   :kbd:`Ctrl-D`

The common way to add a driver to a property is to :kbd:`RMB` click a property,
then add a driver via the context menu.
Drivers can also be added by pressing :kbd:`Ctrl-D` with the mouse over the property set.
The selected properties will be used as a destination (output) for the driver.

All from Target (properties icon)
This will add drivers to the set of properties used as a destination.
It creates a default curve with keyframes at (0, 0) and (1, 1),
For example, it will add drivers to X, Y, and Z for Location.
Single from Target
This will add a single driver to the selected property used as a destination.
Match Indices (palette icon)
Use the corresponding index to drive the corresponding property on a similar sized vector/array property.
This is useful for driving ``ob1.location`` with ``ob2.location``, or ``RGB color`` with ``XYZ location``.
Manually Create Later/(Single) (hand icon)
It adds a/set of driver(s), each with a single variable (but not filled in). No eyedropper will appear.

The source/target (input) property can then be selected with an :ref:`ui-eye-dropper` (e.g. "Scale Y").

.. note::

Due to the way that Blender's UI Context works, you'll need *two* Properties editor instances open
(and to have pinned one of the two to show the properties for the unselected object).
This is necessary as the UI cannot be manipulated while using eyedroppers to pick data.
Therefore, you need to be able to see both the source and the destination properties when using the eyedropper.

Copy Paste
----------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Context menu --&gt; Copy/Paste Driver`

Drivers can be copied and pasted in the UI, via the context menu.
When adding drivers with the same settings, this can save time modifying settings.

Expression
----------

This is a quick way to add drivers with a scripted expression.
First click the property you want to add a driver to, then add a hash ``#`` and a scripted expression.

Some examples:

- ``#frame``
- ``#frame / 20.0``
- ``#sin(frame)``
- ``#cos(frame)``

Removing Drivers
----------------

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties region --&gt; Driver --&gt; Drivers --&gt; Remove Driver`
| Menu:     :menuselection:`Context menu --&gt; Delete (Single) Driver(s)`
| Hotkey:   :kbd:`Ctrl-Alt-D`

ToDo.

.. seealso::

:doc:`Auto run &lt;/advanced/scripting/security&gt;`

Graph View
===========

.. figure:: /images/animation_driver_fcurve.png
:align: right

Graph Editor: Driver example.

The main area of the :doc:`Graph editor &lt;/editors/graph_editor/index&gt;` in Driver Mode
shows a :doc:`F-Curve &lt;/editors/graph_editor/fcurves/introduction&gt;` that maps the Driver Value to
the target property. The Driver Value is the output of the driver script.
The X-axis represents the Driver Value and the Y-axis is the value of the target property.
In the example image, if the Driver Value is 2.0 the property will be 0.5.

The default F-curve is an identity map i.e. the value is not changed.
It can be used to create corrective drivers.

***************
Troubleshooting
***************

Some common problems people may run into when using drivers.

Scripted Expression
===================

.. figure:: /images/animation_drivers_troubleshooting_autorun-graph-editor.png

:menuselection:`Graph Editor --&gt; Properties --&gt; Drivers`

.. figure:: /images/animation_drivers_troubleshooting_autorun-info-header.png

Info Header.

By default Blender will not autorun Python scripts.

If using a *Scripted Expression* Driver Type, you will have to open the file as *Trusted Source*,
or set *Auto Run Python Scripts* in :menuselection:`User Preferences --&gt; File --&gt; Auto Execution`.

.. list-table::
:widths: 40 60

* - .. figure:: /images/animation_drivers_troubleshooting_autorun-file-browser.png

File Browser.

- .. figure:: /images/animation_drivers_troubleshooting_autorun-user-preference.png

:menuselection:`User Preference --&gt; File --&gt; Auto Execution`

Rotational Properties are Radians
=================================

Parts of the User Interface may use different units of measurements for angles, rotation.
In the Graph Editor, while working with Drivers, all angles are Radians.

Intra-armature Bone Drivers Can Misbehave
=========================================

There is a `well-known limitation &lt;https://developer.blender.org/T40301&gt;`__
with drivers on bones that refer to another bone in the same armature. Their values can be
incorrectly calculated based on the position of the other bone as it was *before* you adjust
the current_frame. This can lead to obvious shape glitches when the rendering of frames has
a jump in the frame number (either because the blend-file is currently on a different frame
number or because you are skipping already rendered frames).

*******************
Workflow &amp; Examples
*******************

These are some driver examples and workflow.

Workflow
========

Transform Driver
----------------

This example shows you how setup a transform driver.
First make sure you are in the Front Ortho view. :kbd:`Numpad5`, :kbd:`Numpad1`.

#. In object mode, select then duplicate the default Cube. :kbd:`Shift-D`. Move "Cube.001" to a new location.
#. With "Cube.001" selected, add a single driver to the *Rotation Y* property.
#. Open the *Graph Editor*, set the Mode to *Drivers*.
#. *Show Only Selected* is useful disabled for drivers, marked green in the picture.
#. In the channels region, select the *Y Euler Rotation* property.
#. Press :kbd:`N` to open the properties region, scroll down to Drivers panel.
#. Change the *Type* to *Averaged Value*, this will return the averaged value of the driver variables.
#. Modify the driver variable settings:

- Type -- Transform Channel
- Ob/Bone -- Cube
- Transform Type -- X Location
- Transform Space -- World Space

.. figure:: /images/animation_drivers_transform.jpg

When finished, "Cube.001" should rotate on the Y axis when moving "Cube" left to right.

Examples
========

Driver Expression
-----------------

Here are some examples using the scripted expression Expr to set the Driver Value.

.. figure:: /images/animation_driver_object_rotation.png

Object Rotation.

Orbit a Point
^^^^^^^^^^^^^

Here two drivers have been added to the Cube, X Location and Y Location.

The scripted expressions are being used to set the object location.

X Location Expr
``0 + (sin(frame / 8) * 4)``
``(frame/8)`` : is the current frame of the animation, divided by 8 to slow the orbit down.
``(sin( )*4)`` : This returns the sine of (frame/8), then multiplies by 4 for a bigger circle.
``0 +`` : is used to control the X Location offset of the orbit.

Y Location Expr
``0 + (cos(frame / 8) * 4)``
``(frame / 8)`` : is the current frame of the animation, divided by 8 to slow the orbit down.
``(cos( ) * 4)`` : This returns the cosine of (frame/8), then multiplies by 4 for a bigger circle.
``0 +`` : is used to control the Y Location offset of the orbit.

``frame`` is the same as bpy.context.scene.frame_current.

Driver Namespace
^^^^^^^^^^^^^^^^

There is a list of built-in driver functions and properties.
These can be displayed via the Python Console

.. code-block:: python

&gt;&gt;&gt; bpy.app.driver_namespace['
__builtins__']
__doc__']
__loader__']
__name__']
__package__']
acos']
acosh']
asin']
asinh']
atan']
atan2']
atanh']
bpy']
ceil']
copysign']
cos']
cosh']
..

This script will add a function to the driver namespace,
which can then be used in the expression ``driver_func(frame)``

.. code-block:: python

import bpy

def driver_func(val):
return val * val    # return val squared

# add function to driver_namespace
bpy.app.driver_namespace['driver_func'] = driver_func

.. _animation_drivers_shapekey_ex:

Shape Key Driver
^^^^^^^^^^^^^^^^

This example is a Shape Key Driver. The driver was added to the shape key Value.

.. figure:: /images/animation_driver_shape_key.png
:width: 400px

Shape Key Driver. Click to enlarge.

This example uses the Armature Bone "b" 's Z Rotation to control the Value of a Shape Key.
The bone rotation mode is set to XYZ Euler.

The Driver F-Curve is mapped like so:

- Bone Z Rotation 0.0 (0.0): Shape Key value 0.0
- Bone Z Rotation -2.09 (-120.0): Shape Key value 1.0

This kind of driver can also be setup with the Variable Type Rotational Difference.

See :doc:`Shape Keys &lt;/animation/shape_keys/index&gt;` for more info.

Drivers And Multiple Relative Shape Keys
========================================

The following screenshots illustrate combining shape keys, bones, and
drivers to make multiple chained relative shape keys sharing a single
root. While it lacks the convenience of the single Evaluation Time of
an absolute shape key, it allows you to have more complex
relationships between your shape keys.

.. list-table::

* - .. figure:: /images/animation_driver_workflow_for-multiple-shape-keys-key1.png

Key1 must handle conflicting values from the two bones.

- .. figure:: /images/animation_driver_workflow_for-multiple-shape-keys-key2a.png

Key2A has different generator coefficients so it is activated in a different range of the bone's position.

* - .. figure:: /images/animation_driver_workflow_for-multiple-shape-keys-key2b.png

Key2B is the same as Key2A, but is controlled by the second bone.

- .. figure:: /images/animation_driver_workflow_for-multiple-shape-keys-retracted.png

When both bones are low, Key2B and Key2A are deactivated and Key1 is at low influence.

* - .. figure:: /images/animation_driver_workflow_for-multiple-shape-keys-extended.png

- ..

The Basis shape key has the stacks fully retracted. Key1 has the base fully extended.
Key2A has the left stack fully extended. Key2B has the right stack fully extended.
Key2A and Key2B are both relative to Key1 (as you can see in the field
in the bottom right of the Shape Keys panel.

The value of Key1 is bound to the position of bones by a driver with
two variables. Each variable uses the world Z coordinate of a bone
and uses the maximum value to determine how much the base should be
extended. The generator polynomial is crafted such that the top of
the dominant stack should line up with the bone for that stack.

The value of Key2A is bound to the position of "Bone.L".
Its generator parameters are crafted such that when Key1's value reaches 1,
the value of Key2A starts increasing beyond zero. In this way,
the top of the left stack will move with bone.L (mostly).

The value of Key2B is bound to the position of "Bone.R". Its generator
parameters are similar to Key2A so that the top of the right stack
will move with bone.R (mostly).

Since it is quite easy for bone.L and bone.R to be in positions that
indicate conflicting values for Key1 there will be times when the
bones do not line up with the tops of their respective stacks. If the
driver for Key1 was to use Average or Minimum instead of Maximum to
determine the value of the shape key then "conflicts" between bone.L
and bone.R would be resolved differently. You will choose according to
the needs of your animation.

.. vimeo:: 173408647
.. _animation-index:

############
Animation
############

.. toctree::
:maxdepth: 2

introduction.rst
keyframes/index.rst
actions.rst
drivers/index.rst
markers.rst
shape_keys/index.rst
motion_paths.rst

************
Introduction
************

Animation is making an object move or change shape over time.
Objects can be animated in many ways:

Moving as a whole object
Changing their position, orientation or size in time;
Deforming them
Animating their vertices or control points;
Inherited animation
Causing the object to move based on the movement of another object (e.g. its parent, hook, armature, etc...).

In this chapter, we will cover the first two,
but the basics given here are actually vital for understanding the following chapters as well.

Animation is typically achieved with the use of :doc:`keyframes &lt;/animation/keyframes/introduction&gt;`.

Chapters
========

Animation Fundamentals
----------------------

:doc:`Actions &lt;/animation/actions&gt;`
Actions are used to record the animation of objects and properties.
:doc:`Drivers &lt;/animation/drivers/index&gt;`
Drivers are scripts used to control and animate properties.
:doc:`Keying Sets &lt;/animation/keyframes/keying_sets&gt;`
Keying Sets are used to record a set of properties at the same time.
:doc:`Markers &lt;/animation/markers&gt;`
Markers are used to mark key points/events within an animation.
:doc:`Motion Paths &lt;/animation/motion_paths&gt;`
Motion Paths are used to visualize an animation.
:doc:`Shape Keys &lt;/animation/shape_keys/index&gt;`
Shape Keys are used to deform objects into new shapes.

Animation Editors
-----------------

:doc:`Timeline &lt;/editors/timeline&gt;`
The Timeline Editor is a quick editor to set and control the time frame.
This also has some tools for animation.
:doc:`Graph Editor &lt;/editors/graph_editor/introduction&gt;`
The Graph Editor is mostly used to edit the F-Curves and Keyframes for Channels and Drivers.
:doc:`Dope Sheet &lt;/editors/dope_sheet/introduction&gt;`
The Dope Sheet contains a collection of animation editors.
:doc:`NLA Editor &lt;/editors/nla/index&gt;`
The NLA Editor is used to edit and blend Actions together.

Related Sections
----------------

:doc:`Rigging &lt;/rigging/introduction&gt;`
Rigging.
:doc:`Constraints &lt;/rigging/constraints/introduction&gt;`
Constraints are a way of connecting transformation properties (position, rotation and scale) between objects.
:doc:`Physical Simulation &lt;/physics/introduction&gt;`
This category covers various advanced Blender effects, often used to simulate real physical phenomena.
There is the Particle System for things like hair, grass, smoke, flocks.
Soft Bodies are useful for everything that tends to bend, deform, in reaction to forces like gravity or wind.
Cloth simulation, to simulate clothes or materials.
Rigid Bodies can simulate dynamic objects that are fairly rigid.
Fluids, which include liquids and gases, can be simulated, including Smoke.
Force Fields can modify the behavior of simulations.
:doc:`Motion Tracking &lt;/editors/movie_clip_editor/index&gt;`
Motion tracking is a technique available in Blender that supports basic operations for 2D motion tracking,
3D motion tracking, and camera solution.

.. _animation-state-colors:

State Colors
============

.. figure:: /images/animation_properties.png

State colors of properties.

Properties have different colors and menu items for different states.

.. object origin, 3d view overlay

.. list-table::

* - Gray
- Default
* - Yellow
- Keyframes
* - Green
- Animated
* - Purple
- Driver

*******
Editing
*******

Insert Keyframes
================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Animation --&gt; Animation --&gt; Keyframes: Insert`
| Menu:     :menuselection:`Object --&gt; Animation --&gt; Insert Keyframe...`
| Hotkey:   :kbd:`I`

There are several methods of adding new keys. Namely:

- In the 3D View, pressing :kbd:`I` will bring up a menu to choose what to add a keyframe to.
- Hovering over a property and pressing :kbd:`I` or
with the context menu by :kbd:`RMB` a property and
choose *Insert Keyframe* from the menu.

Auto Keyframe
-------------

.. figure:: /images/editors_info_keyframes-auto.png

Timeline Auto Keyframe.

Auto Keyframe is the red record button in the *Timeline* header. Auto Keyframe adds
keyframes automatically to the set frame if the value for transform type properties changes.

See :ref:`Timeline Keyframe Control &lt;animation-editors-timeline-autokeyframe&gt;` for more info.

Delete Keyframes
================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Animation --&gt; Animation --&gt; Keyframes: Remove`
| Menu:     :menuselection:`Object --&gt; Animation --&gt; Delete Keyframes...`
| Hotkey:   :kbd:`Alt-I`

There are several methods of removing keyframes:

- In the 3D View press :kbd:`Alt-I` to remove keys on the current frame for selected objects.
- When the mouse is over a value press :kbd:`Alt-I`.
- :kbd:`RMB` a value and choose *Delete Keyframe* from the menu.

Clear Keyframes
===============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Animation --&gt; Clear Keyframes...`

ToDo.

.. Removes all keyframes from the selected object.

Editing Keyframes
=================

Keyframes can be edited in two editors. To do so go to either the
:doc:`Graph Editor &lt;/editors/graph_editor/index&gt;`
or the :doc:`Dopesheet &lt;/editors/dope_sheet/index&gt;`.

Examples
========

Keyframe Animation
------------------

This example shows you how to animate a cubes location, rotation, and scale.

#. First, in the *Timeline*, or other animation editors, set the frame to 1.
#. With the *Cube* selected in *Object Mode*, press :kbd:`I` in the 3D View.
#. From the *Insert Keyframe Menu* select *LocRotScale*.
This will record the location, rotation, and scale, for the *Cube* on frame 1.
#. Set the frame to 100.
#. Use Grab/Move :kbd:`G`, Rotate :kbd:`R`, Scale :kbd:`S`, to transform the cube.
#. Press :kbd:`I` in the 3D View. From the *Insert Keyframe Menu* select *LocRotScale*.

.. figure:: /images/animation_keyframes_insert_keyframe_00.png
:width: 500px

Insert Keyframes.

To test the animation, press :kbd:`Alt-A` to play.

.. figure:: /images/animation_keyframes_insert_keyframe_01.png
:width: 500px

The animation on frames 1, 50, 100.

#############
Keyframes
#############

.. toctree::
:maxdepth: 2

introduction.rst
editing.rst
keying_sets.rst

************
Introduction
************

A *Keyframe* is simply a marker of time which stores the value of a property.

For example, a Keyframe might define that the horizontal position of a cube is at 3m on frame 1.

The purpose of a Keyframe is to allow for interpolated animation, meaning, for example,
that the user could then add another key on frame 10, specifying the cube's horizontal position at 20m,
and Blender will automatically determine the correct position of the cube for all the frames between frame 1 and 10
depending on the chosen interpolation method (e.g. Linear, Bézier, Quadratic, etc).

Visualization
=============

There are some important visualization features in the 3D Views that can help animation.

When the current frame is a keyframe for the current active object, the name of this object
(shown in the bottom left corner of the 3D Views) turns yellow.

.. figure:: /images/animation_keyframes_visualization.png

Buttom: Current frame at 0. Top: Current frame is a keyframe for Cube.

.. _keyframe-type:

Keyframe Types
==============

For visually distinguish regular keyframes from different animation events or states
(extremes, breakdowns, or other in betweens)
there is the possibility the applying different colors on them for visualization.

Keyframe (yellow diamond)
Normal keyframe.
Breakdown (cyan small diamond)
Breakdown state. e.g. for transitions between key poses.
Moving Hold (slight orange diamond)
A keyframe that adds a small amount of motion around a holding pose.
In the Dope Sheet it will also draw a bar between them.
Extreme (red big diamond)
An 'extreme' state, or some other purpose as needed.
Jitter (green tiny diamond)
A filler or baked keyframe for keying on ones, or some other purpose as needed.

***********
Keying Sets
***********

.. figure:: /images/editors_timeline_keying-sets.png
:align: right

Timeline Keying Sets.

Keying Sets are a collection of properties.

.. (alt) Keying Sets are a set of keyframe channels.

They are used to record multiple properties at the same time.
Now when you press :kbd:`I` in the 3D View,
Blender will add keyframes for all the properties in the active keying set.

There are some built in Keying Sets,
and also, custom Keying Sets called *Absolute Keying Sets*.

To select and use a Keying Set, set the *Active Keying Set* in the
:ref:`Timeline Header &lt;animation-editors-timeline-autokeyframe&gt;`,
or the Keying Set panel, or press :kbd:`Ctrl-Alt-Shift-I` in the 3D View.

Keying Set Panel
================

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Scene --&gt; Keying Set`

This panel is used to add, select, manage *Absolute Keying Sets*.

.. figure:: /images/animation_keyframes_keying-sets_scene-keying-set-panel.png

The Keying Set panel.

Active Keying Set
The :ref:`List View &lt;ui-list-view&gt;` of Keying Sets in the active Scene.

Add ``+``
Adds a empty Keying Set.

Properties
----------

Description
A short description of the keying set.
Export to File
Export Keying Set to a Python script ``File.py``.
To re-add the keying set from the ``File.py``, open then run the ``File.py`` from the Text Editor.

Keyframing Settings
These options control all properties in the Keying Set.
Note, the same settings in *User Preferences* override these settings if enabled.

Only Needed
Only insert keyframes where they are needed in the relevant F-Curves.
Visual Keying
Insert keyframes based on the visual transformation.
XYZ to RGB
For new F-Curves, set the colors to RGB for the property set, Location XYZ for example.

Active Keying Set Panel
=======================

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Scene --&gt; Active Keying Set`

This panel is used to add properties to the active Keying Set.

.. figure:: /images/animation_keyframes_keying-sets_scene-active-keying-set-panel.png

The Active Keying Set panel.

.. figure:: /images/editors_graph-editor_introduction_channels-region.png

The Graph Editors channels region with named groups.

Active Keying Set Paths
A collection of paths in a :ref:`List View &lt;ui-list-view&gt;` each with a *Data Path* to a property
to add to the active Keying Set.

Add ``+``
Adds a empty path.

Properties
----------

Target
ID-Block
Set the ID-Type and the *Object IDs* Data Path for the property.
Data Path
Set the rest of the Data Path for the property.
Array Target
Use *All Items* from the Data Path or select the array index for a specific property.

F-Curve Grouping
This controls what group to add the channels to.

Keying Set Name, None, Named Group

Keyframing Settings
These options control individual properties in the Keying Set.

Only Needed
Only insert keyframes where they are needed in the relevant F-Curves.
Visual Keying
Insert keyframes based on the visual transformation.
XYZ to RGB
For new F-Curves, set the colors to RGB for the property set, Location XYZ for example.

Adding Properties
=================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Context menu --&gt; Add All/Single to Keying Set`
| Hotkey:   :kbd:`K`

Some ways to add properties to keying sets.

:kbd:`RMB` the property in the *User Interface*, then select *Add Single to Keying Set* or *Add All to Keying Set*.
This will add the properties to the active keying set, or to a new keying set if none exist.

Hover the mouse over the properties, then press :kbd:`K`, to add *Add All to Keying Set*.

*******
Markers
*******

Markers are used to denote frames at which something significant happens,
e.g. it could be that a character's animation starts, the camera changes position, or a door opens.
Markers can be given names to make them more meaningful at a quick glance.
They are available in many of Blender's editors.

.. note::

Unlike keyframes, markers are always placed at a whole frame number, you cannot set a marker at frame 2.5.

Markers can be created and edited in the following editors:

- :doc:`Graph Editor &lt;/editors/graph_editor/introduction&gt;`
- :doc:`Dope Sheet &lt;/editors/dope_sheet/introduction&gt;`
- :doc:`NLA Editor &lt;/editors/nla/index&gt;`
- :doc:`Video Sequence Editor &lt;/editors/vse/index&gt;`
- :doc:`Timeline &lt;/editors/timeline&gt;`

.. note::

A marker created in one of these editors will also appear in all others that support them.

Types
=====

Next to the standard markers *Pose markers* are another type of markers,
which are specific to armatures and shape keys.
They are used to denote poses in the Action Editor mode and Shape Keys Editor of Dope Sheet.

Visualization
=============

Standard
--------

.. figure:: /images/animation_markers_standard.png
:align: right

Markers: small but useful.

Most of the editors visualize markers the same way: as small triangles at their bottom,
white if unselected or yellow if selected.

If they have a name, this is shown to their right, in white when the marker is selected.

.. container:: lead

.. clear

Sequencer
---------

.. figure:: /images/animation_markers_sequencer.png
:align: right

Markers in the Sequencer.

The *Video Sequence Editor* just adds a vertical dashed line to each marker
(gray if the marker is unselected, or white if it is selected).

.. container:: lead

.. clear

3D View
-------

.. figure:: /images/animation_markers_3d-view.png
:align: right

Marker in a 3D View.

The 3D View does not allow you to create, edit, and remove markers,
it just show their name in the Object Info in the bottom left corner,
when on their frame (see Marker in a 3D View).

.. container:: lead

.. clear

Pose Markers
------------

.. figure:: /images/animation_markers_pose.png
:align: right

Pose markers in the Action Editor.

Pose markers show a diamond-shaped icon in the Dope Sheet.
In the NLA editor the pose markers are shown as a red dashed line.

.. container:: lead

.. clear

Add Marker
==========

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Marker --&gt; Add Marker`
| Hotkey:   :kbd:`M` or :kbd:`Ctrl-Alt-M` in the VSE Editor

The simplest way to add a marker is to move to the frame where you would like it to appear,
and press :kbd:`M`.

.. hint::

Markers can also be added while playback.

.. _marker-pose-add:

Pose Markers
------------

If *Show Pose Markers* is checked a pose marker and
a new pose in the :doc:`Pose Library &lt;/rigging/armatures/properties/pose_library&gt;` are added.

Selecting
=========

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Hotkey:   :kbd:`RMB`

Click :kbd:`RMB` on the marker's triangle to select it.
Use :kbd:`Shift-RMB` to select multiple markers.

In the Graph Editor, Dope Sheet, NLA Editor, and Video Sequence Editor,
you can also select all markers with :kbd:`Ctrl-A`, and border-select them with :kbd:`Ctrl-B`
(as usual, :kbd:`LMB` to select, :kbd:`RMB` to deselect).
The corresponding options are found in the Select menu of these editors.

In the Timeline, you can select all markers with :kbd:`A`, and border select with :kbd:`B`.

Editing
=======

Duplicate Marker
----------------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Marker --&gt; Duplicate Marker`
| Hotkey:   :kbd:`Shift-D`

You can duplicate the selected markers by pressing :kbd:`Shift-D`. Once duplicated,
the new ones are automatically placed in grab mode, so you can move them to the desired location.

.. note::

Note that unlike most other duplications in Blender,
the names of the duplicated markers are not altered at all
(no ``.001`` numeric counter append).

Duplicate Marker to Scene
-------------------------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Marker --&gt; Duplicate Marker to Scene...`

ToDo.

Deleting Markers
----------------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Marker --&gt; Delete Marker`
| Hotkey:   :kbd:`X`

To delete the selected markers simply press :kbd:`X`,
and confirm the pop-up message with :kbd:`LMB`.

Rename Marker
-------------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Marker --&gt; Rename Marker`
| Hotkey:   :kbd:`Ctrl-M`

Having dozens of markers scattered throughout your scene's time will not help you much unless you
know what they stand for. You can name a marker by selecting it, pressing :kbd:`Ctrl-M`,
typing the name, and pressing the OK button.

Grab/Move Marker
----------------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Marker --&gt; Grab/Move Marker`
| Hotkey:   :kbd:`G`

Once you have one or more markers selected, press :kbd:`G`,
while hovering with the mouse over the marker bar,
to move them, and confirm the move with :kbd:`LMB` or :kbd:`Enter`
(as usual, cancel the move with :kbd:`RMB`, or :kbd:`Esc`).
Or drag them with the :kbd:`RMB`.

By default, you grab the markers in one-frame steps, but if you hold :kbd:`Ctrl`,
the markers will move in steps corresponding to one second (according to the scene's *FPS*).

Show Pose Markers
-----------------

.. admonition:: Reference
:class: refbox

| Mode:     Action Editor and Shape Keys Editor
| Menu:     :menuselection:`Marker --&gt; Show Pose Markers`

Only Pose markers are shown and editable in Action editor or Shape Keys editor by enabling
the :menuselection:`Marker --&gt; Show Pose Markers` checkbox.

Make Markers Local
------------------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Marker --&gt; Make Markers Local`

It is possible to convert standard markers into Pose markers with :menuselection:`Marker --&gt; Make Markers Local`.
Note that the original marker will be gone. If you want to keep it, make a duplicate before you convert.

Jump to Next/Previous Marker
----------------------------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Marker --&gt; Jump to Next/Previous Marker`

Moves the Time Cursor to the next/previous marker relative to the current Time Cursor position.

.. _marker-bind-camera:

Bind Camera to Marker
=====================

.. admonition:: Reference
:class: refbox

| Editor:   Timeline Editor
| Menu:     :menuselection:`View --&gt; Bind Camera to Marker`
| Hotkey:   :kbd:`Ctrl-B`

Switching cameras can be done with the *Timeline* operator *Bind Camera to Markers* by
having both the camera and marker selected.

The triangle above the camera will become shaded when active.

Workflow
--------

.. figure:: /images/animation_camera_switch.png

First in the Timeline, add a set of markers used to switch cameras.
Press :kbd:`M` to add marker, then :kbd:`Ctrl-M` to rename,
duplicated markers should retain the same name.

#. In the 3D View, select the Camera the Markers will switch to.
#. In the Timeline, select the Marker(s) to switch to the Camera.
#. In the Timeline, press :kbd:`Ctrl-B` to Bind Cameras to Markers.

************
Motion Paths
************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Animation --&gt; Animation --&gt; Motion Paths: Calculate`
| Panel:    :menuselection:`Properties editor --&gt; Object --&gt; Motion Paths`

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Pose Tools --&gt; Motion Paths: Calculate`
| Panel:    :menuselection:`Properties editor --&gt; Armature --&gt; Motion Paths`
| Menu:     :menuselection:`Pose --&gt; Motion Paths`

.. figure:: /images/animation_motion-path_example-object.png
:width: 400px

An animated cube with its motion path displayed.

This feature allows you to visualize the motion of points as paths over a series of frames.
These points can be object origins and bone joints.

Before we look at its options, let us first see how to display/hide these paths.
Unlike :doc:`/rigging/armatures/properties/ghost`, you have to do it manually
and you have to first select the bones you want to show/hide the motion paths. Then,

#. To show the paths (or update them, if needed), click on the *Calculate Path* button.
#. To hide the paths, click on the *Clear Paths* button.

.. note::

Remember that only selected bones and their paths are affected by these actions!

The paths are drawn in a light shade of gray for unselected points,
and a slightly blueish gray for selected ones.
Around the current frame a glow indicate the direction of movement:
blue towards future frames and green towards the past.
Each frame is displayed by a small white dot on the paths.

As with ghosts, the paths are automatically updated when you edit your poses/keyframes,
and they are also active during animation playback. :kbd:`Alt-A` is
only useful when the *Around Current Frame* option is enabled.

Options
=======

.. figure:: /images/animation_motion-paths-panel.png

The Motion Paths Panel in the Armature tab.

Type
Around Frame
Display paths of points within a fixed number of frames around the current frame.
When you enable this button, you get paths for a given number of frames before and after the current one
(again, as with ghosts).
In Range
Display paths of points within specified range.
Display Range
Before, After
Number of frames to show before and after the current frame
(only for *Around Current Frame* Onion-skinning method).
Start, End
Starting and Ending frame of range of paths to display/calculate
(not for *Around Current Frame* Onion-skinning method).
Step
This is the same as the *Step* for ghosts.
It allows you to only display on the path one frame for each *n* ones.
Mostly useful when you enable the frame number display (see below), to avoid cluttering the 3D Views.

Cache/Cache for Bone
From, To
These are the start/end frames of the range in which motion paths are drawn.
You cannot modify this range without deleting the motion path first.
Calculate/Update Paths
If no paths have been calculated, Calculate Paths will create a new motion path in cache based on
the options specified in the pop-up menu or Operator panel.

If a path has already been calculated, Update Paths will update the path shape to the current animation.
To change the frame range of the calculated path, you need to delete the path and calculate it again.

Start, End
These are the start/end frames of the range in which motion paths are drawn.
You have to *Calculate Paths* again if you modify this setting, to update the paths in the 3D Views.
Note that unlike with ghosts, the start frame is *inclusive*
(i.e. if you set *Start* to 1, you will really see the frame 1 as starting point of the paths...).
Bake Location
Bones only -- By default, you get the tips' paths.
By changing this setting to Tails, you will get the paths of the bone's roots
(remember that in Blender UI, bones' roots are called "heads"...).
You have to *Calculate Paths* again if you modify this setting,
to update the paths in the 3D Views.
Clear Paths ``X``
Clears paths on all objects/bones or just the selected ones when holding :kbd:`Shift`.

Show
----

Frame Numbers
When enabled, a small number appears next to each frame dot on the path,
which is of course the number of the corresponding frame.

Keyframes
When enabled, big yellow square dots are drawn on motion paths, showing the keyframes of their bones
(i.e. only the paths of keyed bones at a given frame get a yellow dot at this frame).
\+ Non-Grouped Keyframes
For bone motion paths, it searches the whole Action for keyframes instead of
in groups with matching name only (this is slower).
Keyframe Numbers
When enabled, you will see the numbers of the displayed keyframes,
so this option is obviously only valid when *Show Keys* is enabled.

Example
=======

.. figure:: /images/animation_motion-path_example-armature.png

An example of a motion path of a armature.

##############
Shape Keys
##############

.. toctree::
:maxdepth: 2

introduction.rst
shape_keys_panel.rst
workflow.rst

************
Introduction
************

*Shape Keys* are used on Objects like *Mesh*, *Curve*, *Surface*, *Lattice*.
They are used to animate deform the object vertices into a new shape.

.. figure:: /images/animation_shape-keys_example.png

Example of a mesh with different shape keys applied.

There are two types of Shape Keys:

Relative
Which are relative to the Basis or selected shape key.
They are mainly used as, for limb joints, muscles, or Facial Animation.
Absolute
Which are relative to the previous and next shape key.
They are mainly used to deform the objects into different shapes over time.

The shape key data, the deformation of the object's vertices,
is usually modified in the 3D View by selecting a shape key,
then moving the object vertices to a new position.

****************
Shape Keys Panel
****************

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Panel:    :menuselection:`Properties editor --&gt; Object Data --&gt; Shape Keys`

.. figure:: /images/animation_shape-keys_panel-basis.png

Shape Keys panel.

Active Shape Key Index
A :ref:`ui-list-view`.

Value
Current Value of the Shape Key (0.0 to 1.0).
Mute (eye icon)
This visually disables the shape key in the 3D View.

Specials
Transfer Shape Key
Transfer the active *Shape Key* from a different object.
Select two objects, the active Shape Key is copied to the active object.
Join as Shapes
Transfer the *Current Shape* from a different object.
Select two objects, the Shape is copied to the active object.
Mirror Shape Key
If your mesh is nice and symmetrical, in *Object Mode*, you can mirror the shape keys on the X axis.
This will not work unless the mesh vertices are perfectly symmetrical.
Use the :menuselection:`Mesh --&gt; Symmetrize` function in *Edit Mode*.
Mirror Shape Key (Topology)
This is the same as *Mirror Shape Key* though it detects
the mirrored vertices based on the topology of the mesh.
The mesh vertices do not have to be perfectly symmetrical for this one to work.
New Shape From Mix
Add a new shape key with the current deformed shape of the object.
Delete All Shapes
Delete all shape keys.

Relative
Set the shape keys to *Relative* or *Absolute*.

Show Only (pin icon)
Show the shape of the active shape key without interpolation in the 3D View.
*Show Only* is enabled while the object is in *Edit Mode*, unless the setting below is enabled.
Edit Mode
Modify the shape key while the object is in *Edit Mode*.

Relative Shape Keys
^^^^^^^^^^^^^^^^^^^

Relative shape keys deform from a selected shape key.
By default, all relative shape keys deform from the first shape key called the Basis shape key.

.. figure:: /images/animation_shape-keys_panel-relative.png

Relative Shape Keys options.

Clear Weights ``X``
Set all values to zero.

.. _animation-shapekey-relative-value:

Value
The value of the active shape key.
Range
Min and Max range of the active shape key value.
Blend
Vertex Group
Limit the active shape key deformation to a vertex group.
Relative
Select the shape key to deform from.

Absolute Shape Keys
^^^^^^^^^^^^^^^^^^^

Absolute shape keys deform from the previous and to the next shape key.
They are mainly used to deform the object into different shapes over time.

.. figure:: /images/animation_shape-keys_panel-absolute.png

Absolute Shape Keys options.

Reset Timing (clock icon)
Reset the timing for absolute shape keys.
Interpolation
This controls the interpolation between shape keys.

Linear, Cardinal, Catmull-Rom, B-Spline

.. _fig-interpolation-type:

.. figure:: /images/animation_shape-keys_interpolation-types.png

Different types of interpolation.

The red line represents interpolated values between keys (black dots).

Evaluation Time
This is used to control the shape key influence.

Examples
========

Reset Timing
------------

For example, if you have the shape keys, Basis, Key_1, Key_2, in that order.

Reset Timing will loop the shape keys, and set the shape keyframes to +0.1:

- Basis 0.1
- Key_1 0.2
- Key_2 0.3

Evaluation Time will show this as frame 100:

- Basis 10.0
- Key_1 20.0
- Key_2 30.0

Evaluation Time
---------------

For example, if you have the shape keys, Basis, Key_1, Key_2, in that order, and you reset timing:

- Basis 10.0
- Key_1 20.0
- Key_2 30.0

********
Workflow
********

Relative Shape Keys
===================

#. In *Object Mode*, add a new shape keys via the *Shape Key* panel with the ``+`` button.
#. "Basis" is the rest shape. "Key 1", "Key 2", etc. will be the new shapes.
#. Switch to *Edit Mode*, select "Key 1" in the *Shape Key* panel.
#. Deform mesh as you want (do not remove or add vertices).
#. Select "Key 2", the mesh will be changed to the rest shape.
#. Transform "Key 2" and keep going for other shape keys.
#. Switch back to *Object Mode*.
#. Set the *Value* for "Key 1", "Key 2", etc. to see the transformation between the shape keys.

In the figure below, from left to right shows: "Basis", "Key 1", "Key 2"
and mix ("Key 1" ``1.0`` and "Key 2" ``0.8``) shape keys in Object Mode.

.. figure:: /images/animation_shape-keys_workflow-relative.png

Relative Shape Keys example.

Absolute Shape Keys
===================

#. Add sequence of shape keys as described above for relative shape keys.
#. Uncheck the *Relative* checkbox.
#. Click the *Reset Timing* button.
#. Switch to *Object Mode*.
#. Drag *Evaluation Time* to see how the shapes succeed one to the next.

.. figure:: /images/animation_shape-keys_workflow-absolute.png

Absolute Shape Keys workflow.

By adding a :doc:`driver &lt;/animation/drivers/index&gt;` or
setting :doc:`keyframes &lt;/animation/keyframes/introduction&gt;`
to *Evaluation Time* you can create an animation.

.. seealso:: Shape Key Operators

There are two modeling tools used to control Shape Keys and are
found in :ref:`Edit Mode &lt;modeling-meshes-editing-vertices-shape-keys&gt;`.
.. _composite-nodes-index:

##############
Compositing
##############

.. toctree::
:maxdepth: 2

introduction.rst
properties.rst

Node Types
==========

.. toctree::
:maxdepth: 1

types/input/index.rst
types/output/index.rst
types/color/index.rst
types/converter/index.rst
types/filter/index.rst
types/vector/index.rst
types/matte/index.rst
types/distort/index.rst
types/groups.rst
types/layout/index.rst

************
Introduction
************

Compositing Nodes allow you to assemble and enhance an image (or movie). Using composition nodes,
you can glue two pieces of footage together and colorize the whole sequence all at once.
You can enhance the colors of a single image or an entire movie clip in a static manner or in a
dynamic way that changes over time (as the clip progresses). In this way,
you use composition nodes to both assemble video clips together and enhance them.

.. note:: Term: Image

The term *Image* may refer to a single picture, a picture in
a numbered sequence of images, or a frame of a movie clip.
The Compositor processes one image at a time, no matter what kind of input you provide.

To process your image, you use nodes to import the image into Blender, change it,
optionally merge it with other images, and finally, save it.

.. figure:: /images/compositing_nodes_distort_map-uv_example-2.png

An example of Composition.

.. figure:: /images/compositing_nodes_color_hue-saturation_example.jpg

An example of color correction.

Getting Started
===============

Access the :doc:`Node Editor &lt;/editors/node_editor/index&gt;` and enable
*Composite Nodes* by clicking on the *Image* icon.

To activate nodes for compositing, click the *Use Nodes* checkbox
(see :doc:`/compositing/properties`).

.. note::

After clicking *Use Nodes* the Compositor is enabled, however,
it can also be disabled in the :doc:`Post Processing Panel &lt;/render/post_process/panel&gt;`.

You now have your first node setup, from here you can add and connect many types of
:doc:`Compositing Nodes &lt;/compositing/index&gt;`, in a sort of map layout,
to your heart's content (or physical memory constraints, whichever comes first).

.. note::

Nodes and node concepts are explained in more detail in the :doc:`Node Editor &lt;/editors/node_editor/index&gt;`.

Examples
========

You can do just about anything with images using nodes.

Raw footage from a foreground actor in front of a blue screen,
or a rendered object doing something, can be layered on top of a background.
Composite both together, and you have composited footage.

You can change the mood of an image:

- To make an image 'feel' colder, a blue tinge is added.
- To convey a flashback or memory, the image may be softened.
- To convey hatred and frustration, add a red tinge or enhance the red.
- A startling event may be sharpened and contrast-enhanced.
- A happy feeling -- you guessed it -- add yellow (equal parts red and green, no blue) for bright and sunny.
- Dust and airborne dirt are often added as a cloud texture over the image to give a little more realism.

Image Size
==========

It is recommended to pay attention to image resolution and color depth when mixing and matching
images. Aliasing (rough edges), color *flatness*,
or distorted images can all be traced to mixing inappropriate resolutions and color depths.

The compositor can mix images with any size,
and will only perform operations on pixels where images have an overlap.
When nodes receive inputs with differently sized Images, these rules apply:

- The first/top Image input socket defines the output size.
- The composite is centered by default,
unless a translation has been assigned to a buffer using a *Translate* node.

So each node in a composite can operate on different sized images as defined by its inputs.
Only the *Composite* output node has a fixed size,
as defined by the settings in Properties Editor :menuselection:`Render --&gt; Dimensions`.
The *Viewer* node always shows the size from its input, but when not linked
(or linked to a value) it shows a small 320×256 pixel image.

Saving your Composite Image
===========================

The *Render* button renders a single frame or image.
Save your image using :menuselection:`Image --&gt; Save Image` or :kbd:`F3`.
The image will be saved using the image format settings on the Render panel.

To save a sequence of images, for example,
if you input a movie clip or used a Time node with each frame in its own file,
use the *Animation* button and its settings. If you might want to later overlay them,
be sure to use an image format that supports an Alpha channel (such as ``PNG``).
If you might want to later arrange them front to back or create a depth of field effect,
use a format that supports a Z-depth channel (such as ``EXR``).

To save a composition as a movie clip (all frames in a single file),
use an ``AVI`` or ``Quicktime`` format, and use the *Animation* button and its settings.

**********
Properties
**********

Header
======

.. figure:: /images/compositing_introduction_header.png

Compositing Specific Options.

Use Nodes
Enables basic compositing set up with a :doc:`Render Layer Node &lt;/compositing/types/input/render_layers&gt;`
and a :doc:`Composite Node &lt;/compositing/types/output/composite&gt;`.
Backdrop
Enables the use of a backdrop using a :doc:`Viewer Node &lt;/compositing/types/output/viewer&gt;`.

Backdrop Channels
See below.
Auto Render
Re-render and composite changed layer when edits to the 3D scene are made.

Backdrop
========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editors --&gt; Backdrop`

.. figure:: /images/compositing_introduction_backdrop.png
:align: right

Backdrop Options.

Backdrop Channels
Set the image to be displayed with *Color*, *Color and Alpha*, or just *Alpha*.
Zoom
Sets how big the backdrop image is.
Offset
Change the screen space position of the backdrop,
or click the *Move* button, or shortcut :kbd:`Alt-MMB` to manually move it.
Fit
Automatically scales the backdrop to fit the size of the Node editor.

Performance
===========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editors --&gt; Performance`

.. figure:: /images/compositing_introduction_performance.png
:align: right

Performance Settings.

This panel help you to tweak the performance of the compositor.

Render
Sets the quality when doing the final render.
Edit
Sets the quality when making edits.
Chunk Size
Max size of a title (smaller values give a better distribution of multiple threads, but more overhead).
OpenCL
This allows the use of an OpenCL platform to aid in rendering.
Generally, this should be enabled unless your hardware does not have good OpenCL support.
Buffer Groups
Enables buffering of group nodes to increase the speed at the cost of more memory.
Two Pass
Use two pass execution during editing: the first pass calculates fast nodes, the second pass calculates all nodes.
Viewer Border
This allows to set an area of interest for the backdrop and preview.
The border is started by :kbd:`Ctrl-B` and finished by selection of a rectangular area.
:kbd:`Ctrl-Alt-B` discards the border back to a full preview.
This is only a preview option, final compositing during a render ignores this border.
Highlight
Highlights the nodes that are being calculated by the compositor.
.. TODO: Split "Strange Halo" into properties and glossary

***************
Alpha Over Node
***************

.. figure:: /images/compositing_nodes_color_alpha-over.png
:align: right

Alpha Over Node.

Use this node to layer images on top of one another.
Alpha Over does not work on the colors of an image.

Inputs
======

Factor
Controls the amount of influence the node exerts on the output image.
Image
The background image.
Image
The foreground image. Where the image pixels has an alpha greater than 0,
the background image will be overlaid.

Properties
==========

Convert Premultiplied
`Strange Halos or Outlines`_.
Premultiply
Mix Factor. See :term:`Alpha Channel`.

Outputs
=======

Image
Standard image output.

Strange Halos or Outlines
=========================

This section clarifies the functionality of premultiplied-alpha button.
An alpha channel has a value of between 0 and 1.
To make an image transparent (to composite it over another one),
the RGB pixel values are multiplied by the alpha values
(making the image transparent (0) where the alpha is black (0),
and opaque (1) where it is white (1)).

To composite image A over image B, the alpha of image A gets multiplied by image A,
thus making the image part of A opaque and the rest transparent.
Then the alpha channel of A is inverted and multiplied by image B,
thus making image B transparent, where A is opaque and vice versa.
To get the final composite the resultant images are added.

A pre-multiplied alpha is, when the image (RGB)
pixels are already multiplied by the alpha channel,
therefore, the above compositing operation does not work too well,
and *Convert Premultiplied* has to be enabled.
This is only an issue in semi-transparent area and edges usually.
The issue normally occurs in a node setup,
in which two images previously combined with alpha,
then are combined again with yet another image.
The previously combined image was already multiplied (pre-multiplied)
and needs to be converted as such (hence, *Convert PreMul*).

If multiplied twice artifacts like a white or clear halo occur around
where the image meet, since the alpha value is being squared or cubed.
It also depends on whether or not the image has been rendered as a premultiplied,
or as a straight RGBA image.

Examples
========

In this example, an image of a Cube is superimposed on a cliff background.
Use the PreMultiply button, when the foreground image and background images have
a combined Alpha that is greater than 1.00; otherwise, you will see an unwanted halo effect.
The resulting image is a composite of the two source images.

.. list-table::

* - .. figure:: /images/compositing-alphaover-example.jpg
:width: 320px

Assembling a composite Image using Alpha Over.

- .. figure:: /images/compositing-alphaover-seethru.jpg
:width: 320px

Animated See-Through/Sheer SFX using Alpha Over on Frame 11.

In this example, we use the Factor control to make a sheer cloth or onion-skin effect.
This effect can be animate, allowing the observer to "see-through" walls
(or any foreground object) by hooking up a Time node to feed the Factor socket as shown below.
In this example, over the course of 30 frames, the Time node makes the Alpha Over node produce
a picture that starts with the background cliff image, and slowly bleeds through the cube.
This example shows frame 11 just as the cube starts to be revealed.
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/color/bright_contrast&gt;`

********************
Bright/Contrast Node
********************

.. figure:: /images/compositing_nodes_color_bright-contrast.png
:align: right

Bright/Contrast Node.

Inputs
======

Image
Standard image input.
Bright
A multiplier-type factor by which to increase the overall brightness
of the image. Use a negative number to darken an image.
Contrast
A scaling type factor by which to make brighter pixels brighter, but keeping the darker pixels dark.
Higher values make details stand out. Use a negative number to decrease the overall contrast in the image.

Properties
==========

This node has no properties.

Outputs
=======

Image
Standard image output.

Notes
=====

It is possible that this node will put out a value set that has values beyond the normal range,
i. e. values greater than one and less than zero.
If you will be using the output to mix with other images in the normal range,
you should clamp the values using the Map Value node (with the Min and Max enabled),
or put through a Color Ramp node (with all normal defaults).

.. figure:: /images/compositing_nodes_color_bright-contrast_clamp-values.png
:width: 600px

Clamp the values to normal range.

Either of these nodes will scale the values back to normal range. In the example image,
we want to amp up the specular pass.
The bottom thread shows what happens if we do not clamp the values;
the specular pass has valued much less than one in the dark areas;
when added to the medium gray, it makes black. Passing the brightened image through either the
Map Value or the Color Ramp node produces the desired effect.

Example
=======

.. figure:: /images/compositing_nodes_color_bright-contrast_basic-example.png
:width: 600px

A basic example.

******************
Color Balance Node
******************

The Color Balance node can adjust the color and values of an image.

.. figure:: /images/compositing_nodes_color_color-balance.png

Color Balance Node.

Inputs
======

Factor
Controls the amount of influence the node exerts on the output image
Color
Standard image input.

Properties
==========

Two different correction formulas could be selected.

Lift/Gamma/Gain
Lift
Increases the value of dark colors.
Gamma
Will adjust midtones.
Gain
Adjusts highlights.

Offset/Power/Slope (ASC-CDL)
Offset
A radial color offset from the white center (changes the overall image Hue).
Power
Over all exponent.
Slope
Multiplier.

Outputs
=======

Color
Standard output image.

Advanced
========

The Offset/Power/Slope formula
------------------------------

*out* = (*i* × *s* + *o*)\ :sup:`p`

where:

- *out*: The color graded pixel code value.
- *i*: The input pixel code value (0 to 1) (black to white).
- *s*: Slope (any number 0 or greater, nominal value is 1.0).
- *o*: Offset (any number, the nominal value is 0).
- *p*: Power (any number greater than 0, nominal value is 1.0).

*********************
Color Correction Node
*********************

.. figure:: /images/compositing_nodes_color_color-correction.png

Color Balance Node.

The Color Correction node can adjust the color of an image, separately in several tonal ranges
(highlights, midtones and shadows) and only affect the necessary RGB channels.

Properties
==========

Red, Green, Blue
Specifies which RGB-channels will be affected by correction.

Correction tools (columns)
--------------------------

Saturation
Adjusts the image's saturation.
Contrast
Adjust image contrast.
Gamma
Exponential gamma correction, affecting the midtones of the image. (Works like Power in the Color Balance node.).
Gain
Multiplier, stronger influence on the highlights. (Works like Slope in the Color Balance node).
Lift
This value (can be negative) will be added (+), linear lightens or darkens the image.
(Works like *Offset* in the Color Balance node).

Tonal ranges (rows)
-------------------

Master
these sliders affect the entire tonal range.
Highlights
these sliders only affect the highlights.
Midtones
these sliders only affect the midtones.
Shadows
Affects the dark tones of an image often affecting the shadows.

Midtones Start, Midtones End
Defines the start and the end of midtones range, i.e.
values where the whole tonal range is divided into the highlights, midtones and shadows.
(There is also a smooth transition between the ranges of width 0.2 units.)

Inputs
======

Image
Standard image input.
Mask
Controls the amount of influence the node exerts on the output image.

Outputs
=======

Color
Standard image output.
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/color/gamma&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/color/gamma&gt;`

**********
Gamma Node
**********

.. figure:: /images/compositing_nodes_color_gamma.png
:align: right

Gamma Node.

Use this node to apply a gamma correction.

Inputs
======

Image
Standard image input.
Gamma
An exponential brightness factor.

Properties
==========

This node has no properties.

Outputs
=======

Image
Standard image output.

Examples
========

.. figure:: /images/compositing_nodes_color_gamma_example.jpg
:width: 700px

Example of Gamma node.

****************
Hue Correct Node
****************

The Hue Correct node is able to adjust the Hue, Saturation, and Value of an image,
with an input curve.

.. figure:: /images/compositing_nodes_color_hue-correct.png

Color Balance Node.

Inputs
======

Factor
Controls the amount of influence the node exerts on the output image
Image
Standard image input.

Properties
==========

Level
H (Hue), S (Saturation), V (Value)
Curve
For the curve controls see: :ref:`Curve widget &lt;ui-curve-widget&gt;`.
By default, the curve is a straight line, meaning there is no change.
The spectrum allows you to raise or lower HSV levels for each range of pixel colors.
To change a H, S, or V level, move the curve points up or down. Pixels with hue values each
point in the horizontal position of the graph will be changed depending on the shape of the
curve.

Outputs
=======

Image
Standard image output.

.. TODO explain all options
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/color/hue_saturation&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/color/hue_saturation&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/textures/nodes/types/color/hue_saturation&gt;`

*************************
Hue Saturation Value Node
*************************

.. figure:: /images/compositing_nodes_color_hue-saturation-value.png
:align: right

Hue Saturation Node.

This node applies a color transformation in the HSV color space.
Called "Hue Saturation Value" in shader and texture context.

Inputs
======

Factor
Controls the amount of influence the node exerts on the output image.
Image
Standard image input.

Properties
==========

The transformations are relative shifts.
In the shader and texture context the following properties are available as input sockets.

Hue
Specifies how the hue rotation of the image. 360° are mapped to (0 to 1).
The hue shift of 0 (-180°) and 1 (+180°) have the same result.
Saturation
A saturation of 0 removes hues from the image, resulting in a grayscale image.
A shift greater 1.0 increases saturation.
Value
Value is the overall brightness of the image.
De/Increasing values shift an image darker/lighter.

Outputs
=======

Image
Standard image output.

Hue/Saturation Tips
===================

Some things to keep in mind that might help you use this node better:

Hues are vice versa
A blue image, with a Hue setting at either end of the spectrum (0 or 1),
is output as yellow (recall that white, minus blue, equals yellow).
A yellow image, with a Hue setting at 0 or 1, is blue.
Hue and Saturation work together.
So, a Hue of 0.5 keeps the blues the same shade of blue,
but *Saturation* can deepen or lighten the intensity of that color.
Gray &amp; White are neutral hues
A gray image, where the RGB values are equal, has no hue. Therefore,
this node can only affect it with *Value*. This applies to all shades of gray,
from black to white; wherever the values are equal.
Changing the effect over time
The Hue and Saturation values can be animated with a *Time Node* or by animating the property.

.. note:: Tinge

This HSV node simply shifts hues that are already there.
To colorize a gray image, or to add a tint to an image,
use a mix node to add in a static color from an RGB input node with your image.

HSV Example
===========

.. figure:: /images/compositing_nodes_color_hue-saturation_example.jpg
:width: 700px

A basic example.
.. _composite-nodes-color-index:

##############
Color Nodes
##############

These nodes adjust the image's colors, for example increasing the contrast, making it warmer,
overlaying another image, etc.

.. toctree::
:maxdepth: 1

alpha_over.rst
bright_contrast.rst
color_balance.rst
color_correction.rst
gamma.rst
hue_correct.rst
hue_saturation.rst
invert.rst
mix.rst
rgb_curves.rst
tone_map.rst
z_combine.rst
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/color/invert&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/blender_render/materials/nodes/types/color/invert&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/blender_render/textures/nodes/types/color/invert&gt;`

***********
Invert Node
***********

.. figure:: /images/compositing_nodes_color_invert.png
:align: right

Invert Node.

This node inverts the colors in the input image, producing a negative.

Inputs
======

Factor
Controls the amount of influence the node exerts on the output image.
Color
Standard image input.

Properties
==========

In the compositing context this node has the following properties.

RGB
De/activation of the color channel inversion.
Alpha
De/activation of the alpha channel inversion.

Outputs
=======

Color
Standard image output.
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/color/mix&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/color/mix_rgb&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/textures/nodes/types/color/mix_rgb&gt;`

********
Mix Node
********

.. figure:: /images/compositing_nodes_color_mix.png
:align: right

Mix Node.

This node mixes images by working on the individual and corresponding pixels
of the two input images.
Called "MixRGB" in the shader and texture context.

Inputs
======

Factor
Controls the amount of influence the node exerts on the output image.
Image
The background image. The image size and resolution sets the dimensions of the output image.
Image
The foreground image.

Properties
==========

Mix
The Blend types could be selected in the select menu.
See :term:`Color Blend Modes` for details on each blending mode.

Add, Subtract, Multiply, Screen, Divide, Difference,
Darken, Lighten, Overlay, Dodge, Burn,
Hue, Saturation, Value, Color, Soft Light, Linear Light

Use Alpha
If activated, by clicking on the *Color and Alpha* icon,
the Alpha channel of the second image is used for mixing.
When deactivated, the default, the icon background is a light gray.
The alpha channel of the base image is always used.
Clamp
Limit the highest color value to not exceed 1.

Outputs
=======

Image
Standard image output.

Examples
========

Below are samples of common mix modes and uses, mixing a color or checker with a mask.

.. figure:: /images/compositing_nodes_color_mix_blend-modes.png
:width: 700px

Some explanation of the mixing methods above might help you use the Mix node effectively:

Add
adding blue to blue keeps it blue, but adding blue to red makes purple.
White already has a full amount of blue, so it stays white.
Use this to shift a color of an image. Adding a blue tinge makes the image feel colder.
Subtract
Taking Blue away from white leaves Red and Green, which combined make Yellow.
Taking Blue away from Purple leaves Red. Use this to desaturate an image.
Taking away yellow makes an image bluer and more depressing.
Multiply
Black (0.00) times anything leaves black. Anything times White (1.00) is itself.
Use this to mask out garbage, or to colorize a black-and-white image.
Hue
Shows you how much of a color is in an image,
ignoring all colors except what is selected: makes a monochrome picture (style 'Black &amp; Hue').
Mix
Combines the two images, averaging the two.
Lighten
Like bleach makes your whites whiter. Use with a mask to lighten up a little.
Difference
Kinda cute in that it takes out a color. The color needed to turn Yellow into White is Blue.
Use this to compare two very similar images to see what had been done to one to make it the other;
sorta like a change log for images. You can use this to see a watermark (see `Watermark images`_)
you have placed in an image for theft detection.
Darken
with the colors set here, is like looking at the world through rose-colored glasses.

Contrast Enhancement
--------------------

Here is a small map showing the effects of two other common uses for the RGB Curve:
*Darken* and *Contrast Enhancement*.
You can see the effect each curve has independently,
and the combined effect when they are *mixed* equally.

.. figure:: /images/compositing_nodes_color_mix_contrast-enhancement.png
:width: 700px

Example node setup showing "Darken", "Enhance Contrast" and "Mix" nodes for composition.

As you can hopefully see, our original magic monkey was overexposed by too much light.
To cure an overexposure, you must both darken the image and enhance the contrast.

In the top RGB curve, *Darken*, only the right side of the curve was lowered; thus,
any X input along the bottom results in a geometrically less Y output.
The *Enhance Contrast* RGB (S shaped) curve scales the output such that middle values of X change dramatically;
namely, the middle brightness scale is expanded,
and thus, whiter whites and blacker blacks are output. To make this curve,
simply click on the curve and a new control point is added.
Drag the point around to bend the curve as you wish.
The Mix node combines these two effects equally, and Suzanne feels much better.

Watermark images
----------------

In the old days, a pattern was pressed into the paper mush as it dried,
creating a mark that identified who made the paper and where it came from.
The mark was barely perceptible except in just the right light.
Probably the first form of subliminal advertising. Nowadays,
people watermark their images to identify them as personal intellectual property,
for subliminal advertising of the author or hosting service,
or simply to track their image's proliferation throughout the web. Blender provides a complete
set of tools for you to both encode your watermark and to tell if an image has your watermark.

Encoding Your Watermark in an Image
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

First, construct your own personal watermark. You can use your name, a word,
or a shape or image not easily replicated.
While neutral gray works best using the encoding method suggested,
you are free to use other colors or patterns. It can be a single pixel or a whole gradient;
it is up to you. In the example below,
we are encoding the watermark in a specific location in the image using the *Translate* node;
this helps later because we only have to look at a specific location for the mark. We then use
the RGB to BW node to convert the image to numbers that the Map Value node can use to make the
image subliminal. In this case, it reduces the mark to one-tenth of its original intensity.
The Add node adds the corresponding pixels,
make the ones containing the mark ever-so-slightly brighter.

.. figure:: /images/compositing_nodes_color_mix_watermark-encode.png
:width: 700px

Embedding your mark in an Image using a Mark and Specific Position.

Of course, if you *want* people to notice your mark, do not scale it so much,
or make it a contrasting color. There are also many other ways,
using other mix settings and fancier rigs. Feel free to experiment!

.. note:: Additional uses

You can also use this technique, using settings that result in visible effects,
in title sequences to make the words appear to be cast on the water's surface,
or as a special effect to make words appear on the possessed girl's forearm. yuk.

Decoding an Image for your Watermark
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When you see an image that you think might be yours,
use the node map below to compare it to your stock image (pre-watermarked original).
In this map, the Mix node is set to Difference,
and the Map Value node amplifies any difference. The result is routed to a viewer,
and you can see how the original mark stands out, clear as a bell:

.. figure:: /images/compositing_nodes_color_mix_watermark-decode.png
:width: 700px

Checking an image for your watermark.

Various image compression algorithms lose some of the original; the difference shows as noise.
Experiment with different compression settings and marks to see which works best for you by
having the encoding map in one scene, and the decoding map in another.
Use them while changing Blender's image format settings,
reloading the watermarked image after saving, to get an acceptable result.
In the example above, the mark was clearly visible all the way up to ``JPEG`` compression of 50%.
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/color/rgb_curves&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/blender_render/materials/nodes/types/color/rgb_curves&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/blender_render/textures/nodes/types/color/rgb_curves&gt;`

***************
RGB Curves Node
***************

.. figure:: /images/compositing_nodes_color_rgb-curves.png
:align: right

RGB Curves Node.

This node allows color corrections for each color channel and levels adjustments in the compositing context.

Inputs
======

Factor
Controls the amount of influence the node exerts on the output image.
Image
Standard image input.
Black Level
Defines the input color that is (linear) mapped to black.
White Level
Defines the input color that is (linear) mapped to white.

.. container:: lead

.. clear

.. tip::

To define the levels, use the :ref:`eye dropper &lt;ui-eye-dropper&gt;` to select a color sample of a displayed image.

Properties
==========

Channel
Clicking on one of the channels displays the curve for each.

C (Combined RGB), R (Red), G (Green), B (Blue), L (Luminance)
Curve
A Bézier curve that varies the input levels (x-axis) to produce an output level (y-axis).
For the curve controls see: :ref:`Curve widget &lt;ui-curve-widget&gt;`.

Outputs
=======

Image
Standard image output.

Examples
========

Here are some common curves you can use to achieve desired effects:

.. figure:: /images/compositing_nodes_color_rgb-curves_example-common-use.png
:width: 600px

From left to right: 1. Lighten 2. Negative 3. Decrease Contrast 4. Posterize.

Color correction using Curves
-----------------------------

.. figure:: /images/compositing_nodes_color_rgb-curves_example-rgb.jpg
:width: 600px

Color correction with curves.

In this example, the image has way too much red in it,
so we run it through an RGB node and reduce the Red channel by about half.

We added a middle dot so we could make the line into a sideways exponential curve.
This kind of curve evens out the amount of a color in an image as it reaches saturation. Also,
read on for examples of the Darken and Contrast Enhancement curves.

Color correction using Black/White Levels
-----------------------------------------

.. figure:: /images/compositing_nodes_color_rgb-curves_black-white-levels.png
:width: 600px

Color correction with Black/White Levels.

Manually adjusting the RGB curves for color correction can be difficult.
Another option for color correction is to use the Black and White Levels instead,
which really might be their main purpose.

In this example,
the White Level is set to the color of a bright spot of the sand in the background,
and the Black Level to the color in the center of the fish's eye.
To do this efficiently it is best to bring up the UV/Image editor showing the original input image.
You can then use the levels' color picker to easily choose
the appropriate colors from the input image, zooming into pixel level if necessary.
The result can be fine-tuned with the R, G, and B curves like in the previous example.

The curve for C is used to compensate for the increased contrast that is a side-effect of
setting Black and White Levels.

Effects
-------

.. figure:: /images/compositing_nodes_color_rgb-curves_ex.jpg
:width: 600px

Changing colors.

Curves and Black/White Levels can also be used to completely change the colors of an image.

Note that e.g. setting Black Level to red and White Level to blue does not simply substitute
black with red and white with blue as the example image might suggest.
Levels do color scaling, not substitution,
but depending on the settings they can result in the described color substitution.

(What really happens when setting Black Level to pure red and White Level to pure blue
is that the red channel gets inverted, green gets reduced to zero and blue remains unchanged.)

Because of this, the results of setting arbitrary Black/White Levels or RGB curves is hard to
predict, but can be fun to play with.

*************
Tone Map Node
*************

.. figure:: /images/compositing_nodes_color_tone-map.png
:align: right

Tone Map Node.

Tone mapping is a technique used in image processing and computer graphics to map one set of
colors to another in order to approximate the appearance of high dynamic range images in a
medium that has a more limited dynamic range.

Essentially, tone mapping addresses the problem of strong contrast reduction from the scene values
(radiance) to the displayable range, while preserving the image details and color appearance.
This is important to appreciate the original scene content.

Inputs
======

Image
:abbr:`HDR (High Dynamic Range)` image.

Properties
==========

Type
Rh Simple
Key
The value the average luminance is mapped to.
Offset
Normally always 1, but can be used as an extra control to alter the brightness curve.
Gamma
If not used, set to 1.

R/D Photoreceptor
Intensity
If less than zero, darkens image; otherwise, makes it brighter.
Contrast
Set to 0 to use estimate from input image.
Adaptation
If 0, global; if 1, based on pixel intensity.
Color Correction
If 0, same for all channels; if 1, each independent.

Outputs
=======

Image
:abbr:`LDR (Low Dynamic Range)` image.

**************
Z-Combine Node
**************

.. figure:: /images/compositing_nodes_color_z-combine.png
:align: right

Z Combine Node.

The Z-Combine node combines two images based on their Z-depth maps.
It overlays the images using the provided Z values to
detect which parts of one image are in front of the other.

Inputs
======

Image
The background image.
Z
Z-depth of the background image.
Image
The foreground image.
Z
Z-depth of the foreground image.

Properties
==========

Use Alpha
The chosen Image pixel alpha channel is also carried over.
If a pixel is partially or totally transparent,
the result of the Z-Combine will also be partially transparent;
in which case the background image will show through the foreground (chosen) pixel.
Anti-Alias Z
Applies :term:`Anti-Aliasing` to avoid artifacts at sharp edges or areas with a high contrast.

Outputs
=======

Image
If both Z values are equal, it uses the foreground image.
Whichever Z-value is less decides which image pixel is used.
See :term:`Z-buffer`.
Z
The combined Z-depth, which allows to thread multiple Z-combines together.

Examples
========

.. figure:: /images/compositing_nodes_color_z-combine_example-1.png
:width: 700px

Choosing closest pixels.

In the example above, render output from two scenes are mixed using the Z-Offset node,
one from a sphere of size 1.30, and the other a cube of size 1.00.
The sphere and square are located at the same place. The cube is tipped forward,
so the corner in the center is closer to the camera than the sphere surface;
so Z-Offset chooses to use the cube's pixels. But the sphere is slightly larger
(a size of 1.30 versus 1.00), so it does not fit totally inside the cube. At some point,
as the cube's sides recede back away from the camera, the sphere's sides are closer.
When this happens, Z-offset uses the sphere's pixels to form the resulting picture.

This node can be used to combine a foreground with a background matte painting.
Walt Disney pioneered the use of multi-plane mattes, where three or four partial mattes were
painted on glass and placed on the left and right at different Z positions; minimal camera
moves to the right created the illusion of depth as Bambi moved through the forest.

.. note:: Valid Input

Z Input Sockets do not accept fixed values; they must get a vector set (see Map Value node).
Image Input Sockets will not accept a color since it does not have UV coordinates.

.. figure:: /images/compositing_nodes_color_z-combine_example-2.png
:width: 700px

Mix and Match Images.

The Z-Combine can be used to merge two images as well,
using the Z-values put out by two render layers.
Using the Z-values from the sphere and cube scenes above, but threading different images,
yields the example to the right.

.. figure:: /images/compositing_nodes_color_z-combine_example-3.png
:width: 700px

Z-Combine in action.

In this node setup a render scene is mixed with a flat image. In the side view of the scene,
the purple cube is 10 units away from the camera, and the gray ball is 20.
The 3D cursor is about 15 units away from the camera. The image is Z-in at a location of 15,
thus inserting it in-between the cube and the ball.
The resulting image appears to have the cube on the table.

.. note:: Invisible Man Effect

If a foreground image with a higher Alpha than the background,
is then mixed in the Z-combine with a slightly magnified background,
the outline of the transparent area will distort the background,
enough to make it look like seeing a part of the background through
an invisible yet Fresnel-lens object.

******************
Alpha Convert Node
******************

.. figure:: /images/compositing_nodes_converter_alpha-convert.png
:align: right

Alpha Convert Node.

This node converts the alpha channel interpretation of an image.

Inputs
======

Image
Standard image input.

Properties
==========

Mapping
Straight to Premul, Premul to Straight
Conversion in both directions. Premul. stands for Premultiplied.
For details on the difference between both way to store alpha values see :term:`Alpha Channel`.

Outputs
=======

Image
Standard image output.

.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/converter/color_ramp&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/converter/color_ramp&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/textures/nodes/types/converter/color_ramp&gt;`

***************
Color Ramp Node
***************

.. figure:: /images/compositing_nodes_converter_color-ramp.png
:align: right

Color Ramp Node.

The Color Ramp Node is used for mapping values to colors with the use of a gradient.

Inputs
======

Factor
The Factor input is used as an index for the color ramp.

Properties
==========

Color Ramp
For controls see :ref:`ui-color-ramp-widget`.

Outputs
=======

Image
Standard image output.
Alpha
Standard alpha output.

Examples
========

Creating an Alpha Mask
----------------------

A powerful but often overlooked feature of the Color Ramp is to create an Alpha Mask,
or a mask that is overlaid on top of another image, and, like a mask,
allows some of the background to show through.
The example map below shows how to use the Color Ramp node to do this:

.. figure:: /images/compositing_nodes_converter_color-ramp_create-alpha-mask.png
:width: 600px

Using the Color Ramp node to create an alpha mask.

In the map above, a black and white swirl image, which is lacking an alpha channel,
is fed into the Color Ramp node as a *Factor*. (Technically,
we should have converted the image to a value using the RGB-to-BW node, buy hey,
this works just as well since we are using a BW image as input.)

We have set the Color Ramp node to a purely transparent color on the left end of the spectrum,
and a fully Red color on the right. As seen in the viewer,
the Color Ramp node puts out a mask that is fully transparent where the image is black.
Black is zero, so Color Ramp uses the color at the left end of the spectrum,
which we have set to transparent.
The Color Ramp image is fully red and opaque where the image is white (1.00).

We verify that the output image mask is indeed transparent
by overlaying it on top of a other image.

Colorizing an Image
-------------------

The real power of Color Ramp is that multiple colors can be added to the color spectrum.
This example compositing map takes a boring BW image and makes it a flaming swirl!

.. figure:: /images/compositing_nodes_converter_color-ramp_colorizing-image.png
:width: 600px

In this example, we have mapped the shades of gray in the input image to three colors, blue,
yellow, and red, all fully opaque (Alpha of 1.00). Where the image is black,
Color Ramp substitutes blue, the currently selected color. Where it is some shade of gray,
Color Ramp chooses a corresponding color from the spectrum (bluish, yellow, to reddish).
Where the image is fully white, Color Ramp chooses red.
.. Editors Note: This page gets copied into
:doc:`&lt;/render/cycles/nodes/types/converter/combine_separate&gt;`
.. Editors Note: This page gets copied into
:doc:`&lt;/render/blender_render/materials/nodes/types/converter/combine_separate&gt;`
.. Editors Note: This page gets copied into
:doc:`&lt;/render/blender_render/textures/nodes/types/converter/combine_separate&gt;`
.. TODO Cycles vector (XYZ) nodes

**********************
Combine/Separate Nodes
**********************

All of these nodes do essentially the same thing:

- Separate: Split out an image into its composite color channels.
- Combine: Re/combine an image from it is composite color channels.

This nodes could be use this to manipulate on each color channel independently.
Each type is differentiate in the applied :term:`color space`.

In compositing and texture context each node supports the Alpha channel.
In the texture context only RGB color space is available.
In the shading context of the Blender internal adds HSV and
the Cycles shading context offers an additional pair of nodes to combine/separate a vector (XYZ).

The Combine nodes could also be used to input single color values.
For RGBA and HSVA color spaces it is recommended to use the :doc:`/compositing/types/input/rgb`.
Some common operation could easier executed with the  :doc:`/compositing/types/color/index`.

Separate/Combine RGBA Node
==========================

.. figure:: /images/compositing_nodes_converter_combine-rgba.png
:align: right

Combine RGBA Node.

.. figure:: /images/compositing_nodes_converter_separate-rgba.png
:align: right

Separate RGBA Node.

Input/ Output
-------------

Image
Standard image in/output.

- R (Red)
- G (Green)
- B (Blue)
- A (Alpha)

Properties
----------

This node has no properties.

Examples
--------

.. figure:: /images/compositing-covert-combinergba.jpg
:width: 600px

In this first example, we take the Alpha channel and blur it,
and then combine it back with the colors. When placed in a scene,
the edges of it will blend in, instead of having a hard edge.
This is almost like anti-aliasing but in a three-dimensional sense.
Use this node setup, when adding CG elements to live action to remove any hard edges.
Animating this effect on a broader scale will make the object appear to "phase" in and out,
as an "out-of-phase" time-traveling sync effect.

.. figure:: /images/compositing_nodes_converter_combine-separate_rgba-example-2.jpg

In this node set up, we make all the reds become green,
and all the green both Red and Blue, and remove Blue from the image completely.

Separate/Combine HSVA Nodes
===========================

.. figure:: /images/compositing_nodes_converter_combine-hsva.png
:align: right

Combine HSVA Node.

.. figure:: /images/compositing_nodes_converter_separate-hsva.png
:align: right

Separate HSVA Node.

Input/ Output
-------------

Image
Standard image in/output.

- H (Hue)
- S (Saturation)
- V (Value)
- A (Alpha)

Properties
----------

This node has no properties.

Separate/Combine YUVA Node
==========================

.. figure:: /images/compositing_nodes_converter_combine-yuva.png
:align: right

Combine YUVA Node.

.. figure:: /images/compositing_nodes_converter_separate-yuva.png
:align: right

Separate YUVA Node.

Input/ Output
-------------

Image
Standard image in/output.

- Y (Luminance)
- U (U chrominance)
- V (V chrominance)
- A (Alpha)

Properties
----------

This node has no properties.

Separate/Combine YCbCrA Node
============================

.. figure:: /images/compositing_nodes_converter_combine-ycbcra.png
:align: right

Combine YCbCrA Node.

.. figure:: /images/compositing_nodes_converter_separate-ycbcra.png
:align: right

Separate YCbCrA Node.

Input/ Output
-------------

Image
Standard image in/output.

- Y (Luminance)
- Cb (Chrominance Blue)
- Cr (Chrominance Red)
- A (Alpha)

Properties
----------

Mode
ITU 601, ITU 709, Jpeg

.. tip::

If running these channels through a Color Ramp node to adjust value,
use the Cardinal scale for accurate representation.
Using the Exponential scale on the luminance channel gives high-contrast effect.

************
ID Mask Node
************

.. figure:: /images/compositing_nodes_converter_id-mask.png
:align: right

ID Mask Node.

This node can be used to access an alpha mask per object or per material.

Inputs
======

ID value
Input for the *Object Index* or *Material Index* render pass.
Which is an output of the :doc:`Render Layers node &lt;/compositing/types/input/render_layers&gt;` or
the :doc:`Image node &lt;/compositing/types/input/render_layers&gt;` with a multilayer format.

Properties
==========

Index
Selection of the preciously specified index.
Anti-Aliased
This post-process function refines the mask. See :term:`anti-aliasing`.

Outputs
=======

Alpha
The mask is white where the object is and black where it is not.
If the object is transparent, the alpha mask represent that with gray values.

.. note::

In Blender Internal if a transparent object in front of another,
the mask will not reflect partial visibility of the object behind.

Setup
=====

An index can be specify for any object or material in the scene.
The Object Index can be set in Properties Editor :menuselection:`Object --&gt; Relations --&gt; Pass Index`
and :menuselection:`Material --&gt; Options --&gt; Pass Index` for the Material Index.
To be accessible after rendering, *Object Index* or *Material Index* render pass has to be enabled.

.. figure:: /images/editors_3dview_layers_relations-panel.png

Object Pass Index.

Example
=======

In this example, the left rear red cube is assigned Pass Index 1, and the right cube Pass Index 2.
Where the two cubes intersect, there is going to be noticeable pixelation because they come together
at a sharp angle and are different colors. Using the mask from object 1,
which is smoothed (antialiased) at the edges, we use a *Mix Node* set on *Multiply*
to multiply the smoothed edges of the image, thus removing those nasty lines, thus, being smoothed out.

.. figure:: /images/compositing_nodes_converter_id-mask_example.png

Id Mask node example.
.. _composite-nodes-converter-index:

##################
Converter Nodes
##################

As the name implies, these nodes convert the colors or other properties of various data
(e.g. transparency) in some way.

They also split out or re-combine the different color channels that make up an image,
allowing you to work on each channel independently.
Various color channel arrangements are supported, including traditional RGB, HSV
and High Definition Media Interface (HDMI) formats.

.. toctree::
:maxdepth: 1

alpha_convert.rst
color_ramp.rst
combine_separate.rst
id_mask.rst
math.rst
rgb_to_bw.rst
set_alpha.rst
switch_view.rst
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/converter/math&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/converter/math&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/textures/nodes/types/converter/math&gt;`

*********
Math Node
*********

.. figure:: /images/compositing_nodes_converter_math.png
:align: right

Math node.

This node performs math operations.

Inputs
======

Value
First numerical value. The trigonometric functions accept values in radians.

Value
Second numerical value.
This value is **not** used in functions that accept only one parameter
like the trigonometric functions, Round and Absolute.

Properties
==========

Operation
Add, Subtract, Multiply, Divide, Sine, Cosine, Tangent, Arcsine, Arccosine, Arctangent,
Power, Logarithm, Minimum, Maximum, Round, Less Than, Greater Than, Modulo, Absolute.
Clamp
Limits the output to the range (0 to 1). See :term:`clamp`.

Outputs
=======

Value
Numerical value output.

Examples
========

Manual Z-Mask
-------------

.. figure:: /images/compositing_nodes_converter_math_manual-z-mask.png

Example.

This example has one scene input by the top *Render Layer* node,
which has a cube that is about 10 BU from the camera.
The bottom Render Layer node inputs a scene (FlyCam)
with a plane that covers the left half of the view and is 7 BU from the camera.
Both are fed through their respective Map Value nodes to divide the Z buffer by 20
(multiply by 0.05, as shown in the Size field)
and clamped to be a min/ max of 0.0/ 1.0 respectively.

For the minimum function,
the node selects those Z values where the corresponding pixel is closer to the camera;
so it chooses the Z values for the plane and part of the cube.
The background has an infinite Z value, so it is clamped to 1.0 (shown as white).
In the maximum example, the Z values of the cube are greater than the plane,
so they are chosen for the left side, but the plane (FlyCam) Render layers Z are infinite
(mapped to 1.0) for the right side, so they are chosen.

Using Sine Function to Pulsate
------------------------------

.. figure:: /images/compositing-node-math_sine.jpg

This example has a *Time* node putting out a linear sequence from 0 to 1 over the course of 101
frames. The green vertical line in the curve widget shows that frame 25 is being put out,
or a value of 0.25. That value is multiplied by 2 × pi and converted to 1.0 by the Sine function,
since we all know that :math:`sin(2 × pi/ 4) = sin(pi/ 2) = +1.0`
Since the sine function can put out values between (-1.0 to 1.0),
the *Map Value* node scales that to 0.0 to 1.0 by taking the input (-1 to 1), adding 1
(making 0 to 2), and multiplying the result by one-half (thus scaling the output between 0 to 1).
The default *Color Ramp* converts those values to a grayscale.
Thus, medium gray corresponds to a 0.0 output by the sine, black to -1.0,
and white to 1.0. As you can see, :math:`sin(pi/ 2) = 1.0`. Like having your own visual color calculator!
Animating this node setup provides a smooth cyclic sequence through the range of grays.

Use this function to vary, for example,
the alpha channel of an image to produce a fading in/out effect.
Alter the Z channel to move a scene in/out of focus.
Alter a color channel value to make a color "pulse".

Brightening/Scaling a Channel
-----------------------------

.. figure:: /images/compositing-node-math_multiply.jpg

This example has a *Math: Multiply* node increasing the luminance channel (Y)
of the image to make it brighter. Note that you should use a *Map Value node*
with min() and max() enabled to clamp the output to valid values.
With this approach, you could use a logarithmic function to make a high-dynamic range image.
For this particular example,
there is also a *Brighten/Contrast node* that might give simpler control over brightness.

Quantize/Restrict Color Selection
---------------------------------

In this example, we want to restrict the color output to only 256 possible values.
Possible use of this is to see what the image will look like on an 8-bit cell phone display.
To do this, we want to restrict the R, G and B values
of any pixel to be one of a certain value, such that when they are combined,
will not result in more than 256 possible values. The number of possible values of an output
is the number of channel values multiplied by each other, or Q = R × G × B.

Since there are three channels and 256 values,
we have some flexibility how to quantize each channel,
since there are a lot of combinations of R × G × B that would equal 256. For example,
if {R, G, B} = {4, 4, 16}, then :math:`4 × 4 × 16 = 256`. Also, {6, 6, 7} would give 252 possible values.
The difference in appearance between {4, 4, 16} and {6, 6, 7} is that the first set
(4, 4, 16} would have fewer shades of red and green, but lots of shades of blue.
The set {6, 6, 7} would have a more even distribution of colors.
To get better image quality with fewer color values,
give possible values to the predominant colors in the image.

Theory
======

`Two Approaches to Quantizing to six values
&lt;https://wiki.blender.org/index.php/File:Manual-Compositing-Node-Math_ColorBand&gt;`__.

To accomplish this quantization of an image to 256 possible values, let us use the set {6, 6, 7}.
To split up a continuous range of values between 0 and 1 (the full Red spectrum)
into six values, we need to construct an algorithm or function that takes any input value but
only puts out six possible values, as illustrated by the image to the right.
We want to include zero as true black, with five other colors in between.
The approach shown produces {0, 0.2, 0.4, 0.6, 0.8, 1}. Dividing 1.0 by 5 equals 0.2,
which tells how far apart each quantified value is from the other.

So, to get good even shading,
we want to take values that are 0.16 or less and map them to 0.0;
values between 0.16 and 0.33 get fixed to 0.2;
color band values between 0.33 and 0.5 get quantized to 0.4,
and so on up to values between 0.83 and 1.0 get mapped to 1.0.

.. note:: Function f(x)

An algebraic function is made up of primitive mathematical operations
(add, subtract, multiply, sine, cosine, etc) that operate on an input value to provide the desired output value.

`Spreadsheet showing a function &lt;https://wiki.blender.org/index.php/File:Manual-Compositing-Node-Math_spreadsheet&gt;`__.

The theory behind this function is scaled truncation.
Suppose we want a math function that takes in a range of values between 0 and 1,
such as 0.552, but only outputs a value of 0.0, 0.2, 0.4, etc. We can imagine then that we need
to get that range 0 to 1 powered up to something 0 to 6 so that we can chop off and make it a
whole number. So, with six divisions,
how can we do that? The answer is we multiply the range by 6.
The output of that first math Multiply Node is a range of values between 0 and 6.
To get even divisions, because we are using the rounding function (see documentation above),
we want any number plus or minus around a whole number will get rounded to that number. So,
we subtract a half, which shifts everything over. The round()
function then makes that range 0 to 5. We then divide by 5 to get back a range of numbers
between 0 and 1 which can then be combined back with the other color channels. Thus,
you get the function :math:`f(x, n) = round(x × n - 0.5)/ (n - 1)`
where "n" is the number of possible output values, and "x" is the input pixel color and :math:`f(x, n)`
is the output value. There is only one slight problem, and that is for the value exactly equal to 1,
the formula result is 1.2, which is an invalid value.
This is because the round function is actually a roundup function,
and exactly 5.5 is rounded up to 6. So, by subtracting 0.501, we compensate and thus 5.
499 is rounded to 5. At the other end of the spectrum, pure black, or 0, when 0.501 subtracted,
rounds up to 0 since the Round() function does not return a negative number.

Sometimes using a spreadsheet can help you figure out how to put these nodes together to get
the result that you want. Stepping you through the formula for :math:`n = 6` and :math:`x = 0.70`,
locate the line on the spreadsheet that has the 8-bit value 179 and R value 0.7.
Multiplying by 6 gives 4.2. Subtracting 1/2 gives 3.7, which rounds up to
4.4 divided by 5 = 0.8. Thus, f(0.7, 6) = 0.8 or an 8-bit value of 204.
You can see that this same 8-bit value is output for a range of input values.

Reality
-------

To implement this function in Blender, consider the node setup above. First,
feed the image to the Separate RGB node. For the Red channel,
we string the math nodes into a function that takes each red color, multiplies (scales)
it up by the desired number of divisions (6), offsets it by 0.5,
rounds the value to the nearest whole number, and then divides the image pixel color by 5. So,
the transformation is {0 to 1} becomes {0 to 6}, subtracting centers the medians to {-0.5 to 5.5}
and the rounding to the nearest whole number produces {0, 1, 2, 3, 4, 5}
since the function rounds down,
and then dividing by five results in six values {0.0, 0.2, 0.4, 0.6, 0.8, 1.0}.

The result is that the output value can only be one of a certain set of values,
stair-stepped, because of the rounding function of the math node node setup.
Copying this one channel to operate on Green and Blue gives the node setup below.
To get the 6:6:7, we set the three Multiply Nodes to {6, 6, 7} and the divide nodes to {5, 5, 6}.

.. figure:: /images/compositing-node-math_quantize-red.jpg

If you make this into a node group, you can easily re-use this setup from project to project.
When you do, consider using a math node to drive the different values that you would have to
otherwise set manually, just to error-proof your work.

Summary
-------

Normally, an output render consists of 32- or 24-bit color depth,
and each pixel can be one of the millions of possible colors.
This node setup example takes each of the Red,
Green and Blue channels and normalizes them to one of a few values.
When all three channels are combined back together,
each color can only be one of 256 possible values.

While this example uses the Separate/Combine RGB to create distinct colors,
other Separate/Combine nodes can be used as well. If using the YUV values,
remember that U and V vary between (-0.5 to +0.5),
so you will have to first add on a half to bring the range between 0 and 1,
and then after dividing, subtract a half to bring in back into standard range.

The ``JPG`` or ``PNG`` image format will store each of the colors according to their image standard
for color depth (e.g. ``JPG`` is 24-bit), but the image will be very very small since reducing
color depth and quantizing colors are essentially what the ``JPEG`` compression algorithm
accomplishes.

You do not have to reduce the color depth of each channel evenly. For example,
if blue was the dominant color in an image, to preserve image quality,
you could reduce Red to 2 values, Green to 4, and let the blue take on :math:`256/(2 × 4)` or 32 values.
If using the HSV, you could reduce the Saturation and Value to 2 values (0 or 1.0)
by Multiply by 2 and Divide by 2, and restrict the Hue to 64 possible values.

You can use this node setup to quantize any channel; alpha, speed (vector), z-values, and so forth.
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/converter/rgb_to_bw&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/converter/rgb_to_bw&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/textures/nodes/types/converter/rgb_to_bw&gt;`

**************
RGB to BW Node
**************

.. figure:: /images/compositing_nodes_converter_rgb-to-bw.png
:align: right

RGB to BW Node.

This node maps a RGB color image to a grayscale by the luminance.

Inputs
======

Image
Color image input.

Properties
==========

This node has no properties.

Outputs
=======

Value
Grayscale value output.

.. TODO add examples of why this might be useful

**************
Set Alpha Node
**************

.. figure:: /images/compositing_nodes_converter_set-alpha.png
:align: right

Set Alpha Node.

This node adds an alpha channel to an image.

Inputs
======

Image
Standard image input.
Alpha
The amount of Alpha can be set for the whole image by using the input field or
per pixel by connecting to the socket.

Properties
==========

This node has no properties.

Outputs
=======

Image
Standard image output.

.. note::

This is not, and is not intended to be,
a general-purpose solution to the problem of compositing an image that does not contain Alpha information.
You might wish to use "Chroma Keying" or "Difference Keying" (as discussed elsewhere) if you can.
This node is most often used (with a suitable input being provided by means of the socket)
in those troublesome cases when you *cannot*, for some reason, use those techniques directly.

Example
=======

Fade To Black
-------------

To transition the audience from one scene or shot to another,
a common technique is to "fade to black". As its name implies,
the scene fades to a black screen. You can also "fade to white" or whatever color you wish,
but black is a good neutral color that is easy on the eyes and intellectually "resets" the
viewer's mind. The node map below shows how to do this using the Set Alpha node.

.. figure:: /images/compositing_nodes_converter_set-alpha_fade-to-black.png

Fade To Black.

In the example above, the alpha channel of the swirl image is ignored.
Instead, a :doc:`time node &lt;/compositing/types/input/time&gt;`
introduces a factor from 0.00 to 1.00 over 60 frames, or about 2 seconds,
to the Set Alpha node. Note that the time curve is exponentially-shaped,
so that the overall blackness will fade in slowly and then accelerate toward the end.
The Set Alpha node does not need an input image; instead, the flat (shadeless) black color is used.
The Set Alpha Node uses the input factor and color to create a black image that has an alpha
set which goes from 0.00 to 1.00 over 60 frames, or completely transparent to completely opaque.
Think of alpha as a multiplier for how vivid you can see that pixel.
These two images are combined by our trusty Alpha Over node completely (a *Factor* of 1.00)
to produce the composite image. The Set Alpha node will thus, depending on the frame being rendered,
produce a black image that has some degree of transparency.
Setup and Animate, and you have an image sequence that fades to black over a 2-second period.

.. note:: No Scene information used

This example node map does not use the Render Layer node.
To produce this 2-second animation, no Blender scene information was used.
This is an example of using Blender's powerful compositing abilities
separate from its modeling and animation capabilities.
(A Render Layer could be substituted for the Image layer,
and the "fade-network" effect will still produce the same effect).

Fade In a Title
---------------

To introduce your animation,
you will want to present the title of your animation over a background.
You can have the title fly in, or fade it in. To fade it in,
use the Set Alpha node with the Time node as shown below.

.. figure:: /images/compositing_nodes_converter_set-alpha_fade-in-title.png

Using Set Alpha to Fade in a Title.

In the above example, a Time curve provides the Alpha value to the input socket.
The current Render Layer node, which has the title in view, provides the image. As before,
the trusty Alpha Over node mixes (using the alpha values)
the background swirl and the alpha title to produce the composite image.
Notice the *Convert Premultiplied* - checkbox is **not** enabled; this produces a composite
where the title lets the background image show through where even the background image is
transparent, allowing you to layer images on top of one another.

Colorizing a BW Image
---------------------

.. figure:: /images/compositing_nodes_converter_set-alpha_colorizing-image.png

Using Set Alpha to Colorize an Image.

In the example above, notice how the blue tinge of the render input colors the swirl.
You can use the Set Alpha node's color button with this kind of node map to add a consistent color to a BW image.

In the example map to the right,
use the *Alpha* value of the Set Alpha node to give a desired degree of colorization.
Thread the input image and the Set Alpha node into an Alpha Over node to colorize any black and
white image in this manner. Note the *Convert Premultiplied* checkbox is enabled,
which tells the Alpha Over node not to multiply the alpha values of the two images together.

****************
Switch View Node
****************

.. figure:: /images/compositing_nodes_converter_switch-view.png
:align: right

Switch View Node.

The *Switch View* node combines the *views* (left and right) into a single Stereo 3D output.
This can be useful if for example, you need to treat the view as separate images by combining each of the views.

.. container:: lead

.. clear

.. seealso::

:doc:`The Multi-View Workflow &lt;/render/workflows/multiview/index&gt;`.

Inputs
======

Left
Left eye image input.
Right
Right eye image input.

Properties
==========

This node has no properties.

Outputs
=======

Image
Stereo 3D image output.

Example
=======

.. figure:: /images/multiview_compositor.png

Compositor, Backdrop and Split Viewer Node.

The views to render are defined in the current scene views,
in a similar way as you define the composite output resolution in the current scene render panel,
regardless of the Image nodes resolutions or Render Layers from different scenes.

***************
Corner Pin Node
***************

.. figure:: /images/compositing_nodes_distort_corner-pin.png
:align: right

Corner Pin Node.

The Corner Pin node uses explicit corner values for a plane warp transformation.
It works like the Plane Track Deform node,
but without using "plane track" data from the Movie Clip Editor.

Inputs
======

Image
Standard image input.
Corners
Four vector inputs to define the plane warping. (Z-component of vector inputs is ignored.)

Properties
==========

This node has no properties.

Outputs
=======

Image
Standard image output. (The image after distorting.)
Plane
A black and white alpha mask of the plane.

Example
=======

.. figure:: /images/compositing_nodes_connerpin_example.png

An example of the Conner Pin node.

In the example above, the image of the bird is distorted by the vectors specified by the Corner Pin node.

*********
Crop Node
*********

.. figure:: /images/compositing_nodes_distort_crop.png
:align: right

Crop Node.

The Crop Node takes an input image and crops it to a selected region.

Inputs
======

Image
Standard image input.

Properties
==========

Crop Image Size
When enabled, the image size is cropped to the specified region.
When disabled, the image remains the same size, and uncropped areas become transparent pixels.
Relative
When enabled, crop dimensions are a percentage of the image's width and height.
When disabled, the range of the *Crop Region Values* are the width and height of the image in pixels.
Crop Region Values
Define borders of the crop region.

lower, upper, left, right

Outputs
=======

Image
Standard image output.

*************
Displace Node
*************

.. figure:: /images/compositing_nodes_distort_displace.png
:align: right

Displace Node.

This node displaces the pixel position based on an input vector.

This node could be used to model phenomena, like hot air distortion,
refractions of uneven glass or for surreal video effects.

Inputs
======

Image
Standard image input.
Vector
Input of the displacement map.
If the a color output is implicitly converted in the vector input,
the first channel (red) value determines displacement along X axis.
The second channel (green) the displacement along Y axis.
If the input is a grayscale image, where both the channel values are equal,
the input image will be displaced equally in both X and Y directions.
Scale X, Y
Separate scaling of the vector input in X- and Y-direction.
Acting as multipliers by increasing or decreasing the strength of the
displacement along their respective axes.

Properties
==========

This node has no properties.

Outputs
=======

Image
Standard image output.

*********
Flip Node
*********

.. figure:: /images/compositing_nodes_distort_flip.png
:align: right

Flip Node.

This node flips an image at defined axis .

You can use this node to just flip or use it as a part of mirror setting.
Mix half of the image to be mirrored with its flipped version to produce mirrored image.

Inputs
======

Image
Standard image input.

Properties
==========

Axis
This can be either X or Y. Also, flipping can be done on both X and Y axis' simultaneously.

Flip X, Flip Y, Flip X &amp; Y

Outputs
=======

Image
Standard image output.

.. _composite-nodes-distort-index:

################
Distort Nodes
################

These nodes distort the image in some fashion, operating either uniformly on the image,
or by using a mask to vary the effect over the image.

.. toctree::
:maxdepth: 1

corner_pin.rst
crop.rst
displace.rst
flip.rst
lens.rst
map_uv.rst
movie_distortion.rst
plane_track_deform.rst
rotate.rst
scale.rst
stabilize_2d.rst
transform.rst
translate.rst

********************
Lens Distortion Node
********************

.. figure:: /images/compositing_nodes_distort_lens-distortion.png
:align: right

Lens Distortion Node.

Use this node to simulate distortions that real camera lenses produce.

Inputs
======

Image
Standard image input.
Distort
This creates a bulging or pinching effect from the center of the image.
Dispersion
This simulates chromatic aberration, where different wavelengths of light refract slightly differently,
creating a rainbow colored fringe.

Properties
==========

Projector
Enable or disable slider projection mode.
When on, distortion is only applied horizontally. Disables *Jitter* and *Fit*.
Jitter
Adds jitter to the distortion. Faster, but noisier.
Fit
Scales image so black areas are not visible. Only works for positive distortion.

Outputs
=======

Image
Standard image output.

***********
Map UV Node
***********

.. figure:: /images/compositing_nodes_distort_map-uv.png
:align: right

Map UV Node.

With this node objects can be "re-textured" after they have been rendered.

To apply a texture to individual enumerated objects the
:doc:`ID Mask Node &lt;/compositing/types/converter/id_mask&gt;` could be used.

Inputs
======

Image
The new 2D Texture.
UV
The input for UV render pass.
See :doc:`Cycles render passes &lt;/render/cycles/settings/passes&gt;` or
:doc:`Blender internal render passes &lt;/render/blender_render/settings/passes&gt;`.

.. hint::

To store the UV pass a multilayer OpenEXR format could be used.

Properties
==========

Alpha
Alpha threshold is used to fade out pixels on boundaries.

Outputs
=======

Image
The resulting image is the input image texture distorted to match the UV coordinates.
That image can then be overlay mixed with the original image to paint
the texture on top of the original. Adjust alpha and the mix factor to control
how much the new texture overlays the old.

.. hint::

When painting the new texture,
it helps to have the UV maps for the original objects in the scene,
it is recommended to keep those UV texture outlines around even, when shooting is done.

Examples
========

In the example below,
we have overlaid a grid pattern on top of the two heads after they have been rendered.
During rendering, we enabled the UV layer in the Properties editor
:menuselection:`Render Layer --&gt; Passes`. Using a mix node ("Overlay" in figure),
we mix that new UV Texture over the original face.
We can use this grid texture to help in any motion tracking that we need to do.

.. figure:: /images/compositing_nodes_distort_map-uv_example-1.png
:width: 700px

Adding a Grid UV Textures for Motion Tracking.

In the next example, we overlay a logo on top of a cubie-type thing,
and we ensure that we Enable the Alpha pre-multiply button on the Mix node.
The logo is used as additional UV Texture on top of the existing texture. Other examples include the
possibility that there was used an unauthorized product box during the initial animation,
and it is needed to substitute in a different product sponsor after rendering.

.. hint::

Due to limits of this node, it is not recommended rush pre-production rendering under
the guise of "fixing it later".

.. figure:: /images/compositing_nodes_distort_map-uv_example-2.png
:width: 700px

Adding UV Textures in Post-Production

*********************
Movie Distortion Node
*********************

.. figure:: /images/compositing_nodes_distort_movie-distortion.png
:align: right

Movie Distortion Node.

In real life, all camera lenses produce some or the other sort of lens distortion.
But, whatever we render has got no distortion. So, this node helps in removing distortion from movies
or adding distortion to render to make our render blend in with the movie clip.

Usually, it is used while motion tracking.

Calculating Distortion
======================

Before using this node, one has to calculate the lens distortion of the clip. This can be done by adjusting
K1, K2 and K3 values in :menuselection:`Movie Clip Editor --&gt; Properties --&gt; Lens`.
For more information on how to edit those values,
`check this out &lt;http://blender.stackexchange.com/questions/15620&gt;`__.

Inputs
======

Image
Standard image input.

Properties
==========

Movie Clip
Used to select the movie clip whose distortion is to be used.
This can be useful if more than one movie clips are present, each having a different distortion setting.
For controls see :ref:`ui-data-block`.
Distortion Method
Undistort
Used to undistort the image received, and is usually used for the raw distorted movie clip.
Distort
Used to distort the image received, and is usually used for rendered images.

Outputs
=======

Image
The image after distorting/undistorting.

Distortion vs Undistortion
==========================

Although, both, distortion of render and undistortion of movie clip are possible, and produce similar results,
there is a difference between these two methods.

There are two kinds of lens distortion possible and, in simple terms, they can be said as:

#. When the movie clip is bulging out.
#. When the movie clip is bulging in.

For the first case, it is recommended to distort the render and leave the movie clip as it is, because,
undistorting the movie clip will require extra pixel information, which is not available to Blender.
Similarly, in the second case, it is recommended to undistort the movie clip and leave the render as it is,
because, distorting the render will require those extra unavailable pixels.
Doing the wrong method in the wrong case can create weird results around the edges, such as in the image shown.

.. figure:: /images/compositing_node_distort_moviedistortion_problems.jpg

Problems (notice the edges?)

***********************
Plane Track Deform Node
***********************

.. figure:: /images/compositing_nodes_distort_plane-track-deform.png
:align: right

Plane Track Deform Node.

The Plane Track Deform Node is used to incorporate the special "plane track" in your composite by checking areas
which are planes, and replacing their footage with some other image.

Plane Track
===========

Before using this node, :ref:`plane track &lt;clip-tracking-plane&gt;` for the footage
should be made in the *Movie Clip Editor*.

Inputs
======

Image
Image to put in place of the plane track, and thus, override that area in the movie clip.

Properties
==========

Movie Clip
Used to select the movie clip whose plane track to use.
For controls see :ref:`ui-data-block`.
Object
Used to select the object to which the plane track is linked.
Track
Used to select the plane track to use.
Motion Blur
Specify whether to use blur caused by motion of the plane track or not.

Samples
Set the number of samples to take for each frame.
The higher the samples, the smoother the blur effect,
but the longer the render, as each virtual intermediate frame has to be rendered.

.. note::

Samples are taken only from the *next* frame, not the previous one.
Therefore the blurred object will appear to be slightly ahead of how it would look without motion blur.

Shutter
Time (in frames) the shutter is open.
If you are rendering at 24 fps, and the Shutter is set to 0.5,
the time in between frames is 41.67 ms, so the
shutter is open for half that, 20.83 ms.

Outputs
=======

Image
The output by perspective wrapping the image to that plane track.
Plane
Produces a black and white mask of the plane track.

Examples
========

Using Image output
------------------

This can simply be achieved by using the alpha over node.

.. figure:: /images/compositing_nodes_distort_planetrackdeform_example_image_output.png

Image output.

Using Plane output
------------------

This can be achieved by mixing the movie clip and the image using the plane output as the factor.

.. figure:: /images/compositing_nodes_distort_planetrackdeform_example_plane_output.png

Plane output.

Using Image output vs using original image
==========================================

Using Image output scales, translates and skews the input image according to the track
while using the original image and mixing it with the movie clip using Plane output as factor
will display the part of the image that lies inside that mask. This image shows the difference:

.. figure:: /images/compositing_nodes_distort_planetrackdeform_output_comparison.png

Comparison between image output and original image (see viewer nodes carefully).

***********
Rotate Node
***********

.. figure:: /images/compositing_nodes_distort_rotate.png
:align: right

Rotate Node.

This node rotates an image.

Inputs
======

Image
Standard image input.
Degr
Rotation angle in degree. Positive values rotate clockwise and negative ones counterclockwise.

Properties
==========

Filter
Interpolation Methods.

Nearest
No interpolation, uses nearest neighboring pixel.
Bilinear
Simple interpolation between adjacent pixels.
Bicubic
Highest quality interpolation.

Outputs
=======

Image
Standard image output.

**********
Scale Node
**********

.. figure:: /images/compositing_nodes_distort_scale.png
:align: right

Scale Node.

This node scales the size of an image.

Inputs
======

Image
Standard image input.
X, Y
Scale in the axis directions, only available if *Space* is set to *Relative* or *Absolute*.

Properties
==========

Space
Coordinate Space to scale relative to.

Relative
Percentage values relative to the dimensions of the image input.
Absolute
Size of an image by using absolute pixel values.
Scene Size
Sizes an image to the size of the final render resolution for the scene.
For example, rendering a scene at the standard 1080p resolution but setting the render percentage at 50%,
will produce a 1080p image with the scene scaled down 50% and leaving the rest of the image as alpha.
Render Size
Image dimensions set in the Render panel.

Stretch, Fit, Crop
Stretch distorts the image so that it fits into the render size.
Fit scales the image until the bigger axis "fits" into the render size.
Crop cuts the image so that it is the same aspect ratio as the render size.
X, Y
Offset factor for the final scaled image.

Outputs
=======

Image
Standard image output.

Examples
========

For instance X: 0.5 and Y: 0.5 would produce an image which width and height would be half of what they used to be.

Use this node to match image sizes. Most nodes produce an image that is the same size as the
image input into their top image socket. To uniformly combine two images of different size,
the second image has to be scaled up to match the resolution of the first.

*****************
Stabilize 2D Node
*****************

.. figure:: /images/compositing_nodes_distort_stabilize-2d.png
:align: right

Stabilize 2D Node.

Stabilizes the footage according to the settings set in
:menuselection:`Movie Clip Editor --&gt; Properties --&gt; 2D Stabilization`
For more information,
see :doc:`2D Stabilization &lt;/editors/movie_clip_editor/tracking/clip/properties/stabilization/index&gt;`.

Inputs
======

Image
Standard image input.

Properties
==========

Movie Clip
The movie clip whose stabilization to use.

Filter
Various methods for the stabilization.
Usually, the same as used in
:menuselection:`Movie Clip Editor --&gt; Properties --&gt; 2D Stabilization --&gt; Filter`.
For technical details on their difference,
`see this &lt;http://www.mathworks.com/help/vision/ug/interpolation-methods.html&gt;`_.
But for most purposes, default of Bilinear should suffice.

Invert
Invert the stabilization. If the stabilization calculated is to move the movie clip up by 5 units,
this will move the movie clip down by 5 units.

Outputs
=======

Image
Standard image input.

**************
Transform Node
**************

.. figure:: /images/compositing_nodes_distort_transform.png
:align: right

Transform Node.

This node combines the functionality of three other nodes: :doc:`Scale &lt;/compositing/types/distort/scale&gt;`,
:doc:`translate &lt;/compositing/types/distort/translate&gt;`,
and :doc:`rotate &lt;/compositing/types/distort/rotate&gt;` nodes.

Inputs
======

Image
Standard image input.
X, Y
Used to move the input image horizontally and vertically.
Angle
Used to rotate an image around its center.
Positive values rotate counter-clockwise and negative ones clockwise.
Scale
Used to resize the image. The scaling is relative, meaning a value of 0.5
gives half the size and a value of 2.0 gives twice the size of the original image.

Properties
==========

Filter
Interpolation Methods.

Nearest
No interpolation, uses nearest neighboring pixel.
Bilinear
Simple interpolation between adjacent pixels.
Bicubic
Highest quality interpolation.

Outputs
=======

Image
Standard image output.

**************
Translate Node
**************

.. figure:: /images/compositing_nodes_distort_translate.png
:align: right

Transform Node.

The translate node translates (moves) an image.

Could also be used to add a 2D Camera shake.

Inputs
======

Image
Standard image input.
X, Y
Used to move the input image horizontally and vertically.

Properties
==========

Relative
Percentage translation values relative to the input image size.
Wrapping
Repeat pixels on the other side when they extend over the image dimensions, making endless translating possible.

None, X Axis, Y Axis, Both Axis

Outputs
=======

Image
Standard image output.

..    TODO/Review: {{review|copy=X}}.

*******************
Bilateral Blur Node
*******************

.. figure:: /images/compositing_nodes_filter_bilateral-blur.png
:align: right

Bilateral Blur Node.

The Bilateral Blur node performs a high-quality adaptive blur on the source image.

It can be used for various purposes like:
smoothing results from Blender's raytraced ambient occlusion
smoothing results from various unbiased renderers,
to fake some performance-heavy processes, like blurry refractions/reflections, soft shadows,
to make non-photorealistic compositing effects.

Inputs
======

Image
Standard image input.
If only the image input is connected,
the node blurs the image depending on the edges present in the source image.
Determinator
Which is non-obligatory and if the Determinator is connected,
it serves as the source for defining edges/borders for the blur in the image.
This has great advantage in case the source image is too noisy,
but normals in combination with Z-buffer can still define exact borders/edges of objects.

Properties
==========

Iterations
Defines how many times the filter should perform the operation on the image.
It practically defines the radius of blur.
Color Sigma
Defines the threshold for which color differences in the image should be taken as edges.
Space Sigma
A fine-tuning variable for blur radius.

Outputs
=======

Image
Standard image output.

Examples
========

.. figure:: /images/compositing_nodes_filter_bilateral-blur_example-1.png
:width: 600px

Bilateral smoothed AO.

.. list-table::

* - .. figure:: /images/compositing_nodes_filter_bilateral-blur_example-1_render.jpg
:width: 320px

Render result.

- .. figure:: /images/compositing_nodes_filter_bilateral-blur_example-1_composite.jpg
:width: 320px

Composite.

.. figure:: /images/compositing_nodes_filter_bilateral-blur_example-2.png
:width: 600px

Bilateral faked blurry refraction and smoothed raytraced soft shadow.

.. list-table::

* - .. figure:: /images/compositing_nodes_filter_bilateral-blur_example-2_render.jpg
:width: 320px

Render result.

- .. figure:: /images/compositing_nodes_filter_bilateral-blur_example-2_composite.jpg
:width: 320px

Composite.

.. figure:: /images/compositing_nodes_filter_bilateral-blur_example-3.png
:width: 600px

Bilateral smoothed buffered shadow.

.. list-table::

* - .. figure:: /images/compositing_nodes_filter_bilateral-blur_example-3_render.jpg
:width: 320px

Render result.

- .. figure:: /images/compositing_nodes_filter_bilateral-blur_example-3_composite.jpg
:width: 320px

Composite.

*********
Blur Node
*********

.. figure:: /images/compositing_nodes_filter_blur.png
:align: right

Blur Node.

The Blur node blurs an image, providing several blur modes.

Inputs
======

Image
Standard image input.
Size
The optional Size input will be multiplied with the X and Y blur radius values.
It accepts also a value image, to control the blur radius with a mask.
The values should be mapped between (0 to 1) for an optimal effect.

Properties
==========

Type
The difference between the types is in the way they handle sharp edges, smooth gradients and
preserve the highs and the lows.

Flat
Simply blurs everything uniformly.
Tent
Preserves the high and the lows better by making a linear falloff.
Quadratic
TODO
Cubic
Preserve the highs, but give an almost out-of-focus blur while smoothing sharp edges.
Gaussian
TODO
Fast Gaussian
An approximation of the Gaussian.
Catmull-Rom
Catmull-Rom keeps sharp contrast edges crisp.
Mitch
Preserve the highs, but give an almost out-of-focus blur while smoothing sharp edges.

Variable Size
Allows a variable blur radius, if the size input is an image.

Bokeh
The Bokeh button will force the blur node to use a circular blur filter.
This gives higher quality results, but is slower than using a normal filter.
Gamma
The Gamma button applies a gamma correction on the image before blurring it.
Relative
Percentage Value of the blur radius relative to the image size.

Aspect Correction
None, Y, X
X, Y
Values set the ellipsoid radius in numbers of pixels over which to spread the blur effect.
Extend Bounds
Allows the image, that is being blurred, to extend past its original dimension.

Outputs
=======

Image
Standard image output.

Example
=======

.. figure:: /images/compositing_nodes_filter_blur_example.jpg

Blur node blur modes using 20% of image size as XY, no Bokeh/Gamma.

An example blend-file, in fact, the one used to create the image above,
`is available here. &lt;https://wiki.blender.org/index.php/Media:Manual-Node-Blur.blend&gt;`__.
The blend-file takes one image from the Render Layer node "Blurs" and blurs it while offsetting it *Translate*
and then combining it *Alpha Over* to build up the progressive sequence of blurs.
Play with the Value and Multiply nodes to change the amount of blurring that each algorithm does.

***************
Bokeh Blur Node
***************

.. figure:: /images/compositing_nodes_filter_bokeh-blur.png
:align: right

Bokeh Blur Node.

The Bokeh Blur node generates a bokeh type blur similar to Defocus.
Unlike defocus an in-focus region is defined in the compositor.
There is also more flexibility in the type of blur applied through the
:doc:`Bokeh Image &lt;/compositing/types/input/bokeh_image&gt;` node.

Several performance optimizations are also available such as OpenCL support,
calculation area restriction and masking.

Inputs
======

Image
Standard image input.
Bokeh
This is an input for the :doc:`Bokeh Image &lt;/compositing/types/input/bokeh_image&gt;` node.
Size
Size controls the amount of blur. Size can either be a single value across the entire image or a variable value
controlled by an input image. In order to use the latter, the Variable Size option must be selected.
See the examples section below for more on how to use this.
Bounding Box
This can be used with a :doc:`Box Mask &lt;/compositing/types/matte/box_mask&gt;`
matte node or with a :doc:`Mask &lt;/compositing/types/input/mask&gt;`
input node to restrict the area of the image the blur is applied to. This could be helpful, for example,
when developing a node system by allowing only a small area of the image to be filtered
thus saving composite time each time adjustments are made.

Properties
==========

Variable Size
Allows a variable blur radius, if the Size input is an image.
Max blur
Max blur is intended to act as an optimization tool by
limiting the number of pixels across which the blur is calculated.

Outputs
=======

Image
Standard image output.

Examples
========

Three examples of how the size input may be used follow.

An :doc:`ID masked &lt;/compositing/types/converter/id_mask&gt;`
alpha image can be used so that a background is blurred while foreground objects remain in focus.
To prevent strange edges the :doc:`Dilate Node &lt;/compositing/types/filter/dilate_erode&gt;` should be used.

The Z pass can be visualized using a :doc:`Map Value &lt;/compositing/types/vector/map_value&gt;` node
and :doc:`Color Ramp &lt;/compositing/types/converter/color_ramp&gt;` node
as described in :doc:`Render Layers &lt;/compositing/types/input/render_layers&gt;`.
A *multiply* :doc:`Math &lt;/compositing/types/converter/math&gt;` node can be used following the color-ramp
so that a blur value greater than one is used for objects outside the focal range.

.. figure:: /images/compositing_node_filter_bokehblur_example.jpg
:width: 100%

A manually created grayscale image can be used to define the sharp and blurry areas of a pre-existing image.
Again, a Multiply Node can be used so that a blur value greater than one is used.

.. figure:: /images/compositing_node_filter_bokehblur_example2.jpg
:width: 100%
..    TODO/Review: {{review|copy=X}}.

************
Defocus Node
************

.. figure:: /images/compositing_nodes_filter_defocus.png
:align: right

Defocus Node.

This node blurs areas of an image based on a map/mask input.

It is typically used to emulate depth of field (:term:`DOF`) using a post-processing method with a Z-buffer input.
But also allows to blur images that are not based on Z depth too.

Inputs
======

Image
Standard image input.
Z
Z-buffer input, but could also be a (grayscale) image used as a mask, or a single value input.

Properties
==========

Bokeh Type
The number of iris blades of the virtual camera's diaphragm.

Disk (to emulate a perfect circle) or Triangle (3 blades), Square (4 blades),
Pentagon (5 blades), Hexagon (6 blades), Heptagon (7 blades) or Octagon (8 blades).
Angle
This button is deactivated, if the Bokeh Type is set to Disk.
It can be used to add a rotation offset to the Bokeh shape.
The value is the angle in degrees.
Gamma Correction
Applies a gamma correction on the image before and after blurring it.
F-Stop
This option controls the amount of focal blur in the same way as a real camera.
It simulates the aperture *f* of a real lens' iris, without modifying the luminosity of the picture.
The default value 128 is assumed to be infinity:
everything is in perfect focus. Half the value will double the amount of blur.
This button is deactivated, if *No Z-buffer* is enabled.
Max Blur
This value limits the amount of blur by setting a maximum blur radius.
Could be used to optimize the performance.
The default value of 0 means no limit.
Threshold
Some artifacts, like edge bleed, may occur, if the blur difference between pixels is large.
This value controls how large that blur difference considered to be safe.

.. tip::

Only change this value,  if there is an occurring problem with an in-focus object.

Preview
If enabled a limited amount of (quasi-)random samples are used to render the preview.
This way of sampling introduces additional noise, which will not show up in the final render.
Scene
To select the linked scene.
No Z-buffer
Should be activate for a non Z-buffer in the Z input.
No Z-buffer will be enabled automatically
whenever a node that is not image based is connected to the Z input.
Z Scale
Only active when *No Z-buffer* is enabled. When *No Z-buffer* is used,
the input is used directly to control the blur radius (similar to *f-Stop* when using the Z-buffer).
This parameter can be used to scale the range of the Z input.

Outputs
=======

Image
Standard image output.

Examples
========

.. figure:: /images/compositing_nodes_defocus_example.jpg
:width: 200px
:figwidth: 200px

In this `blend-file example &lt;https://wiki.blender.org/uploads/7/79/Doftest.blend&gt;`__, the ball
array image is blurred as if it was taken by a camera with a f-stop of 2.8 resulting in a
fairly narrow depth of field centered on 7.5 Blender units from the camera.
As the balls recede into the distance, they get blurrier.
This node has no properties.

No Z-Buffer examples
--------------------

Sometimes might want to have more control to blur the image. For instance,
you may want to only blur one object while leaving everything else alone (or the other way around),
or you want to blur the whole image uniformly all at once.
The node, therefore, allows you to use something other than an actual Z-buffer as the Z input.
For instance, you could connect an image node and use a grayscale image where the color designates
how much to blur the image at that point, where white is the maximum blur and black is no blur.
Or, you could use a Time node to uniformly blur the image,
where the time value controls the maximum blur for that frame.
It may also be used to obtain a possibly slightly better DoF blur,
by using a fake depth shaded image instead of a Z-buffer.
(A typical method to create the fake depth shaded image is by using a linear blend texture
for all objects in the scene or by using the "fog/mist" fake depth shading method).
This also has the advantage that the fake depth image can have anti-aliasing,
which is not possible with a real Z-buffer.

The parameter *No Z-buffer*, becomes then the main blur control.
The input has to be scaled, because usually the value of a texture is only in the numeric range 0.0 to 1.0.

Camera Settings
---------------

.. figure:: /images/render_blender-render_camera_object-data_depth-of-field-panel.png

Distance setting in the Camera Depth of Field panel.

The *Defocus* node uses the actual camera data in your scene if supplied by a
*Render Layer* node.

To set the point of focus, the camera now has a *Distance* parameter,
which is shorthand for Depth of Field Distance.
Use this camera parameter to set the focal plane of the camera
(objects Depth of Field Distance away from the camera are in focus).
Set *Distance* in the main *Camera* edit panel;
the button is right below the *Depth of Field*.

To make the focal point visible, enable the camera *Limits* option,
the focal point is then visible as a yellow cross along the view direction of the camera.

Hints
-----

Preview
In general, use preview mode, change parameters to your liking,
only then disable preview mode for the final render.
This node is computer intensive, so watch your console window,
and it will give you status as it computes each render scan line.
Edge Artifacts
For minimum artifacts, try to setup your scene such that differences in distances between two objects that may
visibly overlap at some point are not too large.
"Focus Pull"
Keep in mind that this is not real DoF, only a post-processing simulation.
Some things cannot be done which would be no problem for real DoF at all.
A typical example is a scene with some object very close to the camera,
and the camera focusing on some point far behind it. In the real world, using shallow depth of field,
it is not impossible for nearby objects to become completely invisible,
in effect allowing the camera to see behind it.
Hollywood cinematographers use this visual characteristic to
to achieve the popular "focus pull" effect,
where the focus shifts from a nearby to a distant object, such that the "other" object all but disappears.
Well, this is simply not possible to do with the current post-processing method in a single pass.
If you really want to achieve this effect, quite satisfactorily, here is how:

- Split up your scene into "nearby" and "far" objects, and render them in two passes.
- Now, combine the two the two results, each with their own "defocus" nodes driven by the same Time node,
but with one of them inverted. (e.g. using a "Map Value" node with a Size of -1.)
As the defocus of one increases,
the defocus on the other decreases at the same rate, creating a smooth transition.

Aliasing at Low f-Stop Values
At very low values, less than 5,
the node will start to remove any oversampling and bring the objects at DoF Distance very sharply into focus.
If the object is against a contrasting background, this may lead to visible stair-stepping (aliasing)
which OSA is designed to avoid. If you run into this problem:

- Do your own OSA by rendering at twice the intended size and then scaling down,
so that adjacent pixels are blurred together.
- Use the blur node with a setting of 2 for X and Y.
- Set DoF Distance off by a little, so that the object in focus is blurred by the tiniest bit.
- Use a higher f-Stop, which will start the blur,
and then use the Z socket to a Map Value to a Blur node to enhance the blur effect.
- Rearrange the objects in your scene to use a lower-contrast background.

No Z-Buffer
A final word of warning, since there is no way to detect if an actual Z-buffer is connected to the node,
be **very** careful with the *No Z-Buffer* switch. If the *Z scale* value happens to be large,
and you forget to set it back to some low value,
the values may suddenly be interpreted as huge blur radius values that will cause processing times to explode.

**************
Despeckle Node
**************

.. figure:: /images/compositing_nodes_filter_despeckle.png
:align: right

Despeckle Node.

The *Despeckle node* is used to smooth areas of an image in which noise is noticeable,
while leaving complex areas untouched.

This works by the standard deviation of each pixel and its neighbors is calculated to determine
if the area is one of high complexity or low complexity.
If the complexity is lower than the threshold then the area is smoothed using a simple mean filter.

Inputs
======

Factor
Controls the amount the filter effects the image.
Image
Standard image input.

Properties
==========

Threshold
The threshold to control high/low complexity.
Neighbor
The threshold to control the number of pixels that must match.

Outputs
=======

Image
Standard image output.
..    TODO/Review: {{review|copy=X}}.

*****************
Dilate/Erode Node
*****************

.. figure:: /images/compositing_nodes_filter_dilate-erode.png
:align: right

Dilate/Erode Node.

This node provides a morphology (mathematical shape analysis) filter.

Inputs
======

Mask
Single color channel (or a black and white image) input.

Properties
==========

Mode
Step, Threshold, Distance, Feather
Distance
The Distance is the filter radius.
A *positive* value of Distance dilate (expands) the influence of a pixel on its surrounding pixels.
A *negative* value erodes (shrinks) its influence.

Outputs
=======

Mask
The filtered mask output.

Example
=======

In this example image,
we wanted to take the rather boring array of ball bearings and spruce it up; make it hot,
baby. So, we dilated the red and eroded the green, leaving the blue alone.
If we had dilated both red and green... (hint: red and green make yellow).
The amount of influence is increased by increasing the *Distance* values.
`Blend file available here. &lt;https://wiki.blender.org/uploads/5/51/Derotest.blend&gt;`__.

.. figure:: /images/compositing_nodes-dilate_ex.jpg
..    TODO/Review: {{review|copy=X}}.

*********************
Directional Blur Node
*********************

.. figure:: /images/compositing_nodes_filter_directional-blur.png
:align: right

Dilate/Erode Node.

Blurs an image in a specified direction and magnitude. Can be used to fake motion blur.

Inputs
======

Image
Standard image input.

Properties
==========

Iterations
Controls how may times the image is duplicated to create the blur effect.
Higher values give smoother results.
Wrap
Wraps the image on the X and Y axis to fill in areas,
that become transparent from the blur effect.
Center X, Y
Sets the position where the blur center is.
This makes a difference if the angle, spin, and/or zoom are used.

Distance
How large the blur effect is.
Angle
Image is blurred at this angle from the center.

Spin
Rotates the image each iteration to create a spin effect, from the center point.
Zoom
Scales the image each iteration, creating the effect of a zoom.

Outputs
=======

Image
Standard image output.
..    TODO/Review: {{review|copy=X}}.

***********
Filter Node
***********

.. figure:: /images/compositing_nodes_filter_filter.png
:align: right

Filter Node.

The Filter node implements various common image enhancement filters.

Inputs
======

Factor
Controls the amount of influence the node exerts on the output image.
Image
Standard image input.

Properties
==========

Type
The Soften, Laplace, Sobel, Prewitt and Kirsch all perform edge-detection
(in slightly different ways) based on vector calculus and set theory equations.

Soften
Slightly blurs the image.
Sharpen
Increases the contrast, especially at edges
Laplace
Softens around edges
Sobel
Creates a negative image that highlights edges
Prewitt
Tries to do Sobel one better.
Kirsch
Giving a better blending as Sobel or Prewitt, when approaching an edge.
Shadow
Performs a relief emboss/ bumpmap effect, darkening outside edges.

Outputs
=======

Image
Standard image output.

Example
=======

.. figure:: /images/compositing_nodes_filter_filter_example.jpg

The Filter node has seven modes, shown here.

**********
Glare Node
**********

.. figure:: /images/compositing_nodes_filter_glare.png
:align: right

Glare Node.

The *Glare node* is used add lens flares, fog,
glows around exposed parts of an image an much more.

Inputs
======

Image
Standard image input.

Properties
==========

Glare Type
----------

Ghosts
Creates a haze over the image.
Streaks
Creates bright streaks used to simulate lens flares.

Streaks
Total number of streaks.

Angle Offset
The rotation offset factor of the streaks.
Fade
Fade out factor for the streaks.
Fog Glow
Looks similar to *Ghost* however, it is much smaller in size
and gives more of a atmospheric haze or "glow" around the image.

Size
Scale of the glow relative to the size of the original bright pixels.
Simple Star
Works similar to *Streaks* but gives a simpler shape looking like a star.

Fade
Fade out factor for the streaks.
Rotate 45
Rotate the streaks by 45°.

Common Options
--------------

Quality
If not set to something other the *High*,
then the glare effect will only be applied to a low resolution copy of the image.
This can be helpful to save render times while only doing preview renders.
Iterations
The number of times to run through the filter algorithm.
Higher values will give more accurate results but will take longer to compute.
Note, that this is not available for *Fog Glow* as it does not use an iterative based algorithm.
Color Modulation
Used for *Streaks* and *Ghosts* to create a special dispersion effect.

Johannes Itten describes this effect, Color Modulation, as subtle variations in tones and chroma.
Mix
Value to control how much of the effect is added on to the image.
A value of -1 would give just the original image, 0 gives a 50/50 mix, and 1 gives just the effect.
Threshold
Pixels brighter than this value will be affected by the glare filter.

Outputs
=======

Image
Standard image output.

Example
=======

.. A nice lens flare render of an out door scene

TODO.
.. _composite-nodes-filter-index:

###############
Filter Nodes
###############

Filters process the pixels of an image to highlight additional details or perform some sort of
post-processing effect on the image.

.. toctree::
:maxdepth: 1

bilateral_blur.rst
blur_node.rst
bokeh_blur.rst
defocus.rst
despeckle.rst
dilate_erode.rst
directional_blur.rst
filter_node.rst
glare.rst
inpaint.rst
pixelate.rst
sun_beams.rst
vector_blur.rst

************
Inpaint Node
************

.. figure:: /images/compositing_nodes_filter_inpaint.png
:align: right

Inpaint Node.

The *Inpaint node* is used to extend borders of an image into transparent or masked regions.
This can be useful to solve problems like "wire removal" and holes created during chroma-keying.

Inputs
======

Image
Standard image input.

Properties
==========

Distance
The number of times to extend the image.

Outputs
=======

Image
Standard image output.

Examples
========

In the left image shows the "wire" in place and after chroma-key has been applied you will see you're left
with a blank space -- it's shown as a black line here but it will be alpha in your Blender output.

.. figure:: /images/compositing_nodes_filter_inpaint_example.png

Inpaint Node Example.

Inpainting fills in a couple of pixels using the surrounding image and voila... your wire is removed.

.. note::

The wider your "hole" is, the more noticeable this effect is!
If you use more than a few pixels of infill,
the effect is almost as irritating as the wire and your viewers won't be impressed.

Inpainting can also cover up a multitude of other minor sins
such as control points for motion capture: use it sparingly and it will amaze.

*************
Pixelate Node
*************

.. figure:: /images/compositing_nodes_filter_pixelate.png
:align: right

Pixelate Node.

Add this node in front of a :doc:`scale node &lt;/compositing/types/distort/scale&gt;`
to get a pixelated (non-smoothed) image from the resultant upscaled image.

Inputs
======

Color
Standard image input.

Properties
==========

This node has no properties.

Outputs
=======

Color
Standard image output.

Example
=======

In the Node editor, set the node tree to compositing in the header and check the *Use Nodes* checkbox.
Add an input Image node and an output Viewer node.
Connect the Input node to the viewer node and check the *Backdrop* checkbox in the header.
Open an image you would like to pixelate using the open button on the image node.
This image should now appear in the backdrop.
Now add two scale nodes between the input and output :menuselection:`Add --&gt; Distort --&gt; Scale`.
Change the values of X and Y to 0.2 in the first scale box and to 5 in the second.
The background image will be unchanged.

Now add a Pixelate node between the two scale nodes.

.. note::

You can use :kbd:`Alt-V` and :kbd:`V` to zoom the backdrop in and out respectively.

.. figure:: /images/compositing_nodes_filter_pixelate_example.png

**************
Sun Beams Node
**************

.. figure:: /images/compositing_nodes_filter_sun-beams.png
:align: right

Sun Beams Node.

The Sun Beams node provides a computationally cheap way of
creating the name giving effect based on the image brightness alone.

Sun Beams is a 2D effect for simulating the effect of bright light getting scattered in a medium
`(Crepuscular Rays) &lt;https://en.wikipedia.org/wiki/Crepuscular_rays&gt;`__.
This phenomenon can be created by renderers, but full volumetric lighting is
a rather arduous approach and takes a lot of render time.

Inputs
======

Image
Standard image input.

Properties
==========

Source width, height
Source point of the rays as a factor of the image dimensions.
Ray length
Length of the rays as a factor of the image size.

Outputs
=======

Image
Standard image output.

Example
=======

Usually, the first step is to define the area from which rays are cast.
Any diffuse reflected light from surfaces is not going to contribute to such scattering in the real world,
so should be excluded from the input data.
Possible ways to achieve this are:

- Entirely separate image as a light source.
- Brightness/contrast tweaking to leave only the brightest areas.
- Muting shadow and midtone colors, which is a bit more flexible.
- Masking for ultimate control.

After generating the sun beams from such a light source image they can then be overlayed on the original image.
Usually, a simple "Add" mix node is sufficient,
and physically correct because the scattered light adds to the final result.

.. figure:: /images/compositing_nodes_filter_sun-beams_example.jpg
:width: 400px
..    TODO/Review: {{review|copy=X}}.

*************************
Vector (Motion) Blur Node
*************************

.. figure:: /images/compositing_nodes_filter_vector-blur.png
:align: right

Vector Blur Node.

The Vector Blur node applies a **non** physically based method of simulating :term:`Motion blur`.
It uses the vector speed render pass to blur the image pixels in 2D.

Inputs
======

Image
Standard image input.
Z
Standard Z depth.
Speed
Input for the "Vector" render pass.
See :doc:`Cycles render passes &lt;/render/cycles/settings/passes&gt;` or
:doc:`Blender internal render passes &lt;/render/blender_render/settings/passes&gt;`.

Properties
==========

Samples
Quality factor.
Blur
Scaling factor for the motion vector (actually the "shutter speed" in frames).
Speed
The vector blur could produce artifacts like streaks, lines and other.
To combat these problems, the filter applies clamping,
which can be used to limit which pixels get blurred. The speed is set in pixel units.

Maximum Speed
The maximum threshold. The majority of artifacts are caused by pixels moving too fast.
Minimum Speed
The minimum threshold for moving pixels can separate
the hardly moving pixels from the moving ones.
Especially when the camera itself moves,
the vector mask can become the entire image.

Outputs
=======

Image
Standard image output.

.. hint::

You can make vector blur results in a little smoother by passing the Speed pass through a blur node
(but note that this can make strange results,
so it is only really appropriate for still images with lots of motion blur).

.. note::

Does not work when reading from a multilayer OpenEXR sequence set
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../editors/node_editor/nodes/groups.rst

****************
Bokeh Image Node
****************

.. figure:: /images/compositing_nodes_input_bokeh-image.png
:align: right

Bokeh Image Node.

The *Bokeh Image* node generates a special input image for use with the
:doc:`Bokeh Blur &lt;/compositing/types/filter/bokeh_blur&gt;` filter node.

The *Bokeh Image* node is designed to create a reference image which simulates optical parameters
such as aperture shape and lens distortions which have important impacts on bokeh in real cameras.

Inputs
======

This node has no input sockets.

Properties
==========

The first three settings simulate the aperture of the camera.

Flaps
Sets an integer number of blades for the cameras iris diaphragm.
Angle
Gives these blades an angular offset relative to the image plane
Rounding
Sets the curvature of the blades with (0 to 1) from straight to bringing them to a perfect circle.

Catadioptric
Provides a type of distortion found in mirror lenses and some telescopes.
This can be useful to produce a visual complex bokeh.
Lens Shift
Introduces chromatic aberration into the blur such as would be caused by a tilt-shift lens.

Outputs
=======

Image
The generated bokeh image.

Example
=======

In the example below the *Bokeh Image* is used to define the shape of the bokeh for the
:doc:`Bokeh Blur &lt;/compositing/types/filter/bokeh_blur&gt;` node.

.. figure:: /images/compositing_nodes_bokeh_image_example.jpg

Example of *Bokeh* Image node.

**********
Image Node
**********

.. figure:: /images/compositing_nodes_input_image.png
:align: right

Image Node.

The *Image* node injects any image :doc:`format that is supported by Blender &lt;/render/output/output&gt;`.

Inputs
======

This node has no input sockets.

Properties
==========

Image
Selection of different types of media. For controls see :ref:`ui-data-block`.
For the options see :doc:`/editors/uv_image/image/image_settings`.

.. note::

More options could be set in the properties region.

Outputs
=======

The first two sockets are the minimum.

Image
Standard image output.
Alpha
Separate Alpha value.
Z
Z-depth layer.

.. note:: MultiLayer format:

When a MultiLayer file format, like ``EXR``, is loaded, each
layer is made available as a socket.
.. _composite-nodes-input-index:

##############
Input Nodes
##############

Input nodes produce information from some source.
For instance, an input could be:

- Taken directly from the active camera in a selected scene,
- from a ``JPG``, ``PNG``, etc. file as a static picture,
- a movie clip (such as an image sequence or video), or
- just a color or value.

These nodes generate the information that feeds other nodes.
As such, they have no input-connectors; only outputs.

.. toctree::
:maxdepth: 1

bokeh_image.rst
image.rst
mask.rst
movie_clip.rst
render_layers.rst
rgb.rst
texture.rst
time.rst
track_position.rst
value.rst

*********
Mask Node
*********

.. figure:: /images/compositing_nodes_input_mask.png
:align: right

Mask Node.

The Mask node can be used to select a :doc:`Mask Data-block &lt;/editors/movie_clip_editor/masking/index&gt;`.
This node can be used with other nodes, for example to Invert, Multiply or Mix, or use as a factor input.

Inputs
======

This node has no input sockets.

Properties
==========

Masks
The selectable mask data-block. If the label is left blank the mask name will be set.
Anti-Alias
Create smooth mask edges rather than hard ones.
Feather
Use or ignore feather points defined for splines see :ref:`Mask Feathers &lt;mask-feather&gt;` for more details.
Size
Scene Size will give an image the size of the render resolution for the scene,
scaling along when rendering with different resolutions. Fixed gives a fixed size in pixels. Fixed/
Scene gives a size in pixels that still scales along when changing the render resolution percentage in the scene.
Motion Blur
For animated masks, creating a motion blurred mask from the surrounding frames,
with a given number of samples (higher gives better quality), and a camera shutter time in seconds.

Outputs
=======

Mask
The black and white output of the mask.

Example
=======

In the example below the *Mask node* is used to define a rough outline of the island,
where areas out side of the island are dark, drawing the eye to the island.

.. figure:: /images/compositing_input_mask_example.jpg

Example of the Mask Node.

***************
Movie Clip Node
***************

.. figure:: /images/compositing_nodes_input_movie-clip.png
:align: right

Movie clip node.

This node is a special node that uses some of the values taken from
footage cameras and trackings and links them to the output.
It is possible to load image sequences, but only Image and Alpha values
will be available, because the other outputs will not have any values
associated with them.
When a tracked clip is chosen, Blender will fulfill the outputs using
internal values taken from the tracking. So the controls for
start and end frames will be defined at the movie clip editor.

Inputs
======

This node has no input sockets.

Properties
==========

Movie Clip
Used to select the movie clip. For controls see :ref:`ui-data-block`.

Outputs
=======

The first two sockets are the minimum output.

Image
Outputs the entire image at the specified color space.
Alpha
The alpha value taken from the movie or image.
Offset X
The X offset value from the footage camera or tracking.
Offset Y
The Y offset value from the footage camera or tracking.
Scale
The scale of the image taken from the footage camera or tracking.
Angle
The lens angle taken from the footage camera or tracking.

******************
Render Layers Node
******************

.. figure:: /images/compositing_nodes_input_render-layers.png
:align: right

Render Layers Node.

This node is the starting place for getting a picture of your scene into the compositing node
map.

Inputs
======

This node has no input sockets.

Properties
==========

Scene
Select the within your blend-file. The scene information taken is the raw footage
(pre-compositing and pre-sequencing).

.. hint::
To use composited footage from another scene, it has to be rendered into a multilayer e.g. ``OpenEXR`` frameset
as an intermediate file store and then imported with Image input node again.

Render layer
A list of available :doc:`Render Layers &lt;/render/post_process/layers&gt;`.
The render button is a short hand to re-render the active scene.

Outputs
=======

Image
Rendered image.
Alpha
Alpha channel.

.. rubric:: Render passes sockets

Depending on the Render passes that are enabled, other sockets are available.
See :doc:`Cycles render passes &lt;/render/cycles/settings/passes&gt;` or
:doc:`Blender internal render passes &lt;/render/blender_render/settings/passes&gt;`.

Z
By default the Z depth pass is enabled.

.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/input/rgb&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/input/rgb&gt;`

********
RGB Node
********

.. figure:: /images/compositing_nodes_input_rgb.png
:align: right

RGB Node.

Inputs
======

This node has no input sockets.

Properties
==========

The RGB node uses the :ref:`color picker widget &lt;ui-color-picker&gt;`.

Outputs
=======

Color / RGBA
A single RGBA color value.

************
Texture Node
************

.. figure:: /images/compositing_nodes_input_texture.png
:align: right

Texture Node.

The Texture node makes 3D textures available to the compositor.

Inputs
======

Offset
A vector (XYZ) transforming the origin of the texture.
Scale
A vector (XYZ) to scale the texture.

Properties
==========

Texture
The texture could be selected from a list of textures available in the current blend-file or link in textures.
The textures themselves could not be edited in this note, but in the Texture panel.

Outputs
=======

Value
Gray scale color values.
Color
Color values.

.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/textures/nodes/types/input/time&gt;`

*********
Time Node
*********

.. figure:: /images/compositing_nodes_input_time.png
:align: right

Time Node.

The *Time node* generates a factor value (from 0.00 to 1.00)
that changes according to the curve was drawn as time progresses through the *Timeline*.

Inputs
======

This node has no input sockets.

Properties
==========

Curve
The Y-value defined by the curve is the factor output.
For the curve controls see: :ref:`Curve widget &lt;ui-curve-widget&gt;`.

.. tip::

Flipping the curve around reverses the time input, but
doing so is easily overlooked in the node setup.

Start, End
Start frame and End frame of the range of time specifying the values
the output should last. This range becomes the X-axis of the graph.
The time input could be reversed by specifying a start frame greater than the end frame.

Outputs
=======

Factor
A speed of time factor (from 0.00 to 1.00) relative to the frame rate
defined in the :ref:`Render Dimensions Panel &lt;render-tab-dimensions&gt;`.
The factor changes according to the defined curve.

.. hint:: Output values

The :doc:`Map Value &lt;/compositing/types/vector/map_value&gt;`
node can be used to map the output to a more appropriate value.
With sometimes curves, it is possible that the Time node may output a number larger than one or less than zero.
To be safe, use the Min/Max clamping function of the Map Value node to limit output.

Example
=======

.. figure:: /images/compositing_nodes_input_time_example.png

Time controls from left to right: no effect, slow down, freeze, accelerate, reverse

*******************
Track Position Node
*******************

.. figure:: /images/compositing_nodes_input_track-position.png
:align: right

Track Position Node.

The *Track Position node* is used to return information about a tracking marker to the compositor.

Inputs
======

This node as no inputs.

Properties
==========

Movie Clip
Used to select a Movie Clip data-block to use, for controls see :ref:`ui-data-block`.

Tracking Object
Camera object to get track information from.
Track Name
The name of the track to get track information from.

Position
Which marker position to use for output.

Absolute
Outputs a absolute position of a marker.
Relative Start
Outputs the positions of a marker relative to the first marker of a track.
Relative Frame
Outputs the positions of a marker relative to the markers of the given *Frame*.
Absolute Frame
Outputs the absolute positions of a marker at the given *Frame*.

Outputs
=======

X/Y
The markers X and Y location.
Speed
The velocity of the marker, measured in pixels per frame.
This could be used to fake effects like motion blur by connecting it to the Vector Blur Node.

Examples
========

TODO.
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/input/value&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/input/value&gt;`

**********
Value Node
**********

.. figure:: /images/compositing_nodes_input_value.png
:align: right

Value Node.

The *Value Node* is a simple node to input numerical values to other nodes in the tree.

Inputs
======

This node has no input sockets.

Properties
==========

Single numerical value (floating point).

Outputs
=======

Value
The value set in the options.

Example
=======

In the example below the *Value Node* is used to control multiple values at once,
this make the node a useful organizational tool.

.. figure:: /images/compositing_nodes_input_value_example.jpg

Example of the *Value Node*.

.. tip::

From this you can also make different values proportional to each other by adding a
:doc:`Math Node &lt;/compositing/types/converter/math&gt;` in between the different links.

**********
Frame Node
**********

The Frame node is a useful tool for organizing nodes by collecting related nodes together in a common area.
Frames are useful when a node setup becomes large and confusing yet the re-usability of a Node Group is not required.

.. figure:: /images/compositing_nodes_layout_frame_example.png

Properties
==========

.. figure:: /images/compositing_nodes_layout_frame_properties.png
:align: right

Label size
Font size of the label. For example, for subordinate frames to have smaller titles.
Shrink
Once a node is placed in the Frame, the Frame shrinks around it so as to remove wasted space.
At this point it is no longer possible to grab the edge of the Frame to resize it, instead resizing occurs
automatically when nodes within the Frame are rearranged.
This behavior can be changed by disabling this option.
Text
When you need to display more comprehensive text, frame nodes can display the contents of a text-block.
This is read-only, so you will need to use the *Text Editor* to modify the contents.

Editing
=======

Join in new Frame
-----------------

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Node --&gt; Join in new Frame`
| Hotkey:   :kbd:`Ctrl-J`

ToDo.

Adding
------

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Hotkey:   :kbd:`Ctrl-P`

Once a Frame node is placed in the editor, nodes can be added by simply dropping them onto the frame or by
selecting the node(s) then the frame and using :kbd:`Ctrl-P`.

Remove from Frame
-----------------

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Node --&gt; Remove from Frame`
| Hotkey:   :kbd:`Alt-P`

To remove them select the node(s) and use the :kbd:`Alt-P` shortcut.
This uses the same default keyboard bindings as Parenting and can be thought of as a similar concept.

.. _composite-nodes-layout-index:

###############
Layout Nodes
###############

These are nodes which help you control the layout and connectivity of nodes within the Compositor.

.. toctree::
:maxdepth: 1

frame.rst
reroute.rst
switch.rst

************
Reroute Node
************

A node used primarily for organization.
Reroute looks and behaves much like a socket on other nodes in that it supports one input
connection while allowing multiple output connections.

To quickly add a Reroute node into an existing connection, hold :kbd:`Shift` and :kbd:`LMB`
while sweeping across the link to add a *Reroute node*.

.. figure:: /images/compositing_nodes_layout_reroute.png

Properties
==========

Input
Input value used for unconnected sockets.

***********
Switch Node
***********

.. figure:: /images/compositing_nodes_layout_switch.png
:align: right

Switch Node.

Switch between two images using a checkbox.

Inputs
======

Image
First image input.
Image
Second image input.

Properties
==========

Switch
- When it is unchecked, the first input labeled "Off" is passed to the output.
- When checked, the second input labeled "On" is passed to the output.

Outputs
=======

Image
Standard image output.

.. tip::

Switch state may be animated by adding a :doc:`keyframe &lt;/animation/keyframes/introduction&gt;`
This makes the Switch node useful for bypassing nodes which are not wanted during part of a sequence.

*************
Box Mask Node
*************

.. figure:: /images/compositing_nodes_matte_box-mask.png
:align: right

Box Mask Node.

The *Box Mask* node creates an image suitable for use as a simple matte.

Inputs
======

Mask
An optional mask to use as the base for mask operations.
Value
Intensity of the generated mask.

Properties
==========

X, Y
Position of the center of the box as a fraction of the total width or height.
(0.5, 0.5 creates a centered box; 0.0, 0.0 creates a box in the lower left).
Width
Width of the box as a fraction of the total image width.
Height
Height of the box as a fraction of the total image *width*, not height.
Rotation
Rotation of the box around its center point.
Mask Type
Operation to use against the input mask.

Add
This yields the *union* of the input mask and the generated mask:
Areas covered by the generated mask are set to the specified *Value*.
Other parts of the input masked are passed through unchanged, or set to black if there is no input mask.
Subtract
Values of the input mask have the specified *Value* subtracted from them.
Multiply
This yields the *intersection* of this generated mask and the input mask:
Values of the input mask are multiplied by the specified *Value* for the area covered by the generated mask.
All other areas become black.
Not
Any area covered by both the input mask and the generated mask becomes black.
Areas covered by the generated mask that are black on the input mask become the specified *Value*.
Areas uncovered by the generated mask remain unchanged.

Outputs
=======

Mask
A generated rectangular mask merged with the input mask.
The created mask is the size of the current scene render dimensions.

.. tip::

For soft edges, pass the output mask through a slight :doc:`blur node &lt;/compositing/types/filter/blur_node&gt;`.

****************
Channel Key Node
****************

.. figure:: /images/compositing_nodes_matte_channel-key.png
:align: right

Channel Key Node.

The *Channel Key* node determines background objects from foreground objects by the
difference in the selected channel's levels.

For example in YUV color space,
this is useful when compositing stock footage of explosions (very bright)
which are normally shot against a solid, dark background.

Inputs
======

Image
Standard image input.

Properties
==========

Color Space
This button selects what color space the channels will represent.

RGB, HSV, YUV, YCbCr
Channel
This button selects the channel, defined by the Color Space, to use to determine the matte.
Algorithm
Max., Single
Limit
It is possible to have a separation between the two values to allow for a gradient of
transparency between foreground and background objects.

High
Determines the lowest values that are considered foreground.
(which is supposed to be -- relatively -- height values: from this value to 1.0).
Low
Determines the highest values that are considered to be background objects.
(which is supposed to be -- relatively -- low values: from 0.0 to this value).

Outputs
=======

Image
Image with an alpha channel adjusted for the keyed selection.
Matte
A black and white alpha mask of the key.

***************
Chroma Key Node
***************

.. figure:: /images/compositing_nodes_matte_chroma-key.png
:align: right

Chroma Key Node.

The *Chroma Key* node determines if a pixel is a foreground or background
(and thereby should be transparent) based on its chroma values.

Use this, for example, to composite images that have been shot in front of a green or blue screen.

Inputs
======

Image
Standard image input.
Key Color
The background color usually selected using the color picker and the original image.

Properties
==========

Acceptance
An angle on the color wheel that represents how tolerant the keying color is. Larger angles allow for larger
variation in the keying color to be considered background pixels.
Cutoff
Controls the level that is considered the pure background. Higher cutoff levels mean more pixels will be
100% transparent if they are within the angle tolerance.
Falloff
Increase to make nearby pixels partially transparent producing a smoother blend along the edges.

Outputs
=======

Image
Image with its alpha channel adjusted for the keyed selection.
Matte
A black and white alpha mask of the key.

**************
Color Key Node
**************

.. figure:: /images/compositing_nodes_matte_color-key.png
:align: right

Color Key Node.

The color key node creates a matte based on a specified color of the input image.

Inputs
======

Image
Standard image input.

Properties
==========

Color
The sliders represent threshold values.
Higher values in this node's context mean a wider range of colors from
the specified will be added to the matte.

Hue, Saturation, Value

Outputs
=======

Image
Image with its alpha channel adjusted for the keyed selection.
Matte
A black and white alpha mask of the key.

****************
Color Spill Node
****************

.. figure:: /images/compositing_nodes_matte_color-spill-key.png
:align: right

Color Spill Node.

The *Color Spill* node reduces one of the RGB channels so that it is not greater
then any of the others.

This is common when compositing images that were shot in front of a green or blue screen.
In some cases, if the foreground object is reflective, it will show the green or blue color;
that color has "spilled" onto the foreground object. If there is light from the side or back,
and the foreground actor is wearing white, it is possible to get "spill" green (or blue)
light from the background onto the foreground objects,
coloring them with a tinge of green or blue. To remove the green (or blue) light,
you use this fancy node.

Inputs
======

Image
Standard image input.
Factor
Standard Factor.

Properties
==========

Despill Channel
R, G, B
Algorithm
Simple, Average
Limiting Channel
R, G, B
Ratio
Scale limit by value
Unspill
Allows you to reduce the selected channel's input to the image
greater than the color spill algorithm normally allows.
This is useful for exceptionally high amounts of the color spill.

R, G, B

Outputs
=======

Image
The image with the corrected channels.

Example
=======

Results with the nodes applied to an image from the
`Mango Open Movie &lt;https://mango.blender.org/&gt;`_.

.. list-table::

* - .. figure:: /images/compositing-node-keying_screen_spill.jpg

Before: green border and green reflections.

- .. figure:: /images/compositing-node-keying_screen_good.jpg

After: no unwanted geen.

*******************
Difference Key Node
*******************

.. figure:: /images/compositing_nodes_matte_difference-key.png
:align: right

Difference Key Node.

This node produces a matte that isolates foreground content by comparing it with a reference background image.

Inputs
======

Image
Contains foreground content against the background that is to be removed.
Image
The reference background image.

Properties
==========

Tolerance
Where pixels match the reference background to within the specified threshold, the matte is made transparent.
Falloff
Increase to make nearby pixels partially transparent producing a smoother blend along the edges.

Outputs
=======

Image
Image with its alpha channel adjusted for the keyed selection.
Matte
A black and white alpha mask of the key.

*****************
Distance Key Node
*****************

.. figure:: /images/compositing_nodes_matte_distance-key.png
:align: right

Distance Key Node.

The Distance Key node determines a pixel's alpha value based on the three-dimensional
distance between the image pixel color and the key color in a 3D color space.

This key works well when trying to single out a specific color in a background
(not necessarily green).

Inputs
======

Image
Standard image input.
Key Color
The color that is to be keyed.

Properties
==========

Tolerance
A threshold what the node considers a match between the key color and the foreground pixel.
The tolerance affects how close a pixel needs to be to the background pixel
to be considered an absolute match.
Falloff
When the Falloff value is high, pixels that are close to the Key Color are more
transparent than pixels that are not as close to the Key Color
(but still considered close enough to be keyed).
When the Falloff value is low, it does not matter how close
the pixel color (Image) is to the Key Color, it is transparent.
Color Space
It is also possible to work with YCbCr color space,
but only the Cb and Cr channels are taken into consideration
for determining the distance between the foreground and background pixels.

RGB, YCC

Outputs
=======

Image
The image with an alpha channel adjusted for the keyed selection
Matte
A black and white alpha mask of the key.

*********************
Double Edge Mask Node
*********************

.. figure:: /images/compositing_nodes_matte_double-edge-mask.png
:align: right

Double Edge Mask Node.

The *Double Edge Mask* node creates a gradient between two masks.

Inputs
======

Inner Mask
A mask representing the inside shape, which will be fully white.
Outer Mask
A mask representing the outside shape, which will fade from black at its edges
to white at the *Inner Mask*.

Properties
==========

Inner Edge
All
All shapes in the *Inner Mask* contribute to the gradient, even ones that do
not touch the *Outer Mask* shape.
Adjacent Only
Only shapes in the *Inner Mask* that overlap with the *Outer Mask* contribute
to the gradient.

.. list-table::

* - .. figure:: /images/compositing_nodes_double_edge_all.png

All.

- .. figure:: /images/compositing_nodes_double_edge_adjacent.png

Adjacent Only.

Buffer Edge
Keep In
Parts of the *Outer Mask* that touch the edge of the image are treated as if
they stop at the edge.
Bleed Out
Parts of the *Outer Mask* that touch the edge of the image are extended
beyond the boundary of the image.

.. list-table::

* - .. figure:: /images/compositing_nodes_double_edge_in.png

Keep In.

- .. figure:: /images/compositing_nodes_double_edge_bleed.png

Bleed Out.

Outputs
=======

Mask
Standard mask output.

Example
=======

.. only:: builder_html and (not singlehtml)

.. youtube:: VcjEfoNIHZs

.. only:: not builder_html and (singlehtml)

A video can be found at https://www.youtube.com/watch?v=VcjEfoNIHZs

*****************
Ellipse Mask Node
*****************

.. figure:: /images/compositing_nodes_matte_ellipse-mask.png
:align: right

Ellipse Mask Node.

The *Ellipse Mask* node creates an image suitable for use as a simple matte or vignette mask.

Inputs
======

Mask
An optional mask to use as the base for mask operations.
Value
Intensity of the generated mask.

Properties
==========

X, Y
Position of the center of the ellipse as a fraction of the total width or height.
(0.5, 0.5 creates a centered ellipse; 0.0, 0.0 creates an ellipse with its center in the lower left).
Width
Width of the ellipse as a fraction of the total image width.
Height
Height of the ellipse as a fraction of the total image *width*, not height.
Equal *Width* and *Height* values with produce a circle.
Rotation
Rotation of the ellipse around its center point.
Mask Type
Operation to use against the input mask.

Add
This yields the *union* of the input mask and the generated mask:
Areas covered by the generated mask are set to the specified *Value*.
Other parts of the input masked are passed through unchanged, or set to black if there is no input mask.
Subtract
Values of the input mask have the specified *Value* subtracted from them.
Multiply
This yields the *intersection* of this generated mask and the input mask:
Values of the input mask are multiplied by the specified *Value* for the area covered by the generated mask.
All other areas become black.
Not
Any area covered by both the input mask and the generated mask becomes black.
Areas covered by the generated mask that are black on the input mask become the specified *Value*.
Areas uncovered by the generated mask remain unchanged.

Outputs
=======

Mask
A generated elliptical mask merged with the input mask.
The created mask is the size of the current scene render dimensions.

.. tip::

For soft edges, pass the output mask through a slight :doc:`blur node &lt;/compositing/types/filter/blur_node&gt;`.
For a vignette, pass the output of this through a heavy blur.
.. _composite-nodes-matte-index:

##############
Matte Nodes
##############

These nodes give you the essential tools for creating a :term:`Matte` for images
that do not already have their own :term:`Alpha Channel`. One usage scenario is
blue-screen or green-screen footage, where live action is shot in front of a
blue or green backdrop for replacement by a matte painting or virtual background.

In general, hook up these nodes to a viewer, set your UV/Image Editor to show the viewer node,
and play with the sliders in real-time using a sample image from the footage,
to get the settings right. In some cases,
small adjustments can eliminate artifacts or foreground image degradation.
Taking out too much green can result in foreground actors looking flat or blueish/purplish.

You can and should chain these nodes together,
improving your masking and color correction in successive refinements,
using each node's strengths to operate on the previous node's output.
:doc:`Keying Node &lt;/compositing/types/matte/keying&gt;` is the closest to a "does-it-all" node
for green screens, but the best results stem from a combination of techniques.

.. note::

Garbage Matte is not a node, but a technique selecting what to
exclude from an image. It is a :term:`Mask` used to identify content to be
removed from an image that cannot be removed by an automatic process like
chroma keying. It is used either to select specific content to be removed, or
it is the inverse of a rough selection of the subject; removing everything else.

Some nodes accept a garbage matte directly. For those that don't, you can
still apply one by subtracting the garbage matte from the matte generated
by the node.

Simple garbage mattes can be created with the
:doc:`Box Mask &lt;/compositing/types/matte/box_mask&gt;` or
:doc:`Ellipse Mask &lt;/compositing/types/matte/ellipse_mask&gt;`
More complicated matte shapes using
:doc:`Double Edge Mask &lt;/compositing/types/matte/double_edge_mask&gt;` or
using a :doc:`Mask &lt;/compositing/types/input/mask&gt;`.

.. toctree::
:maxdepth: 1

box_mask.rst
channel_key.rst
chroma_key.rst
color_key.rst
color_spill_key.rst
difference_key.rst
distance_key.rst
double_edge_mask.rst
ellipse_mask.rst
keying.rst
keying_screen.rst
luminance_key.rst

***********
Keying Node
***********

.. figure:: /images/compositing_nodes_matte_keying.png
:align: right

Keying Node.

The *Keying* node is an one-stop-shop for "green screen" / "blue screen" removal.
It performs both chroma keying to remove the backdrop and despill to correct color cast from the backdrop.
Additionally, you can perform common operations used to tweak the resulting matte.

Inputs
======

Image
Standard image input.
Key Color
The color of content to be removed. This may be a single color,
or a reference image such as generated by the
:doc:`Keying Screen Node &lt;/compositing/types/matte/keying_screen&gt;`.
Garbage Matte
An optional mask of area(s) to always *exclude* from the output.
This is removed from the chroma key generated matte.
Core Matte
An optional mask of area(s) to always *include* in the output.
This is merged with the chroma key generated matte.

Properties
==========

Pre Blur
Reduce the effects of color noise in the image by blurring only color by the given amount,
leaving luminosity intact. This will affect matte calculation only, not the result image.

Screen Balance
This is the balance between color channels compared with the key color.
0.5 will average the other channels (red and blue in the case of a green screen).

This may be tweaked in tandem with *Clip Black* and *Clip White* while
checking the *Matte* output to create a mask with optimal separation.
Despill Factor
Controls how much color bleed from the key color is removed from the input
image: 0 means no despilling, 1 means all possible spilling will be removed.
The underlying implementation is the same as adjusting the *Unspill* amount
of the :doc:`Color Spill Node &lt;/compositing/types/matte/color_spill_key&gt;`.
Despill Balance
This controls how the color chanels are compared when computing spill,
affecting the hue and shade of the corrected colors.
It is similar to setting the *Limiting Channel* in the
:doc:`Color Spill Node &lt;/compositing/types/matte/color_spill_key&gt;`.
Edge Kernel Radius
Defines the radius in pixel used to detect an edge.
Edge Kernel Tolerance
Defines threshold used to check if pixels in radius are the same as current pixel:
If the difference between pixel colors is higher than this threshold then the point
will be considered an edge.
Clip Black
This sets the threshold for what becomes fully transparent in the output (black
in the matte). It should be set as low as possible. Uneven backdrops will require
this value to be increased. Use of the
:doc:`Keying Screen Node &lt;/compositing/types/matte/keying_screen&gt;` can help keep
this value low. You may also use a *Garbage Matte* to exclude problematic areas.

This value does not impact areas detected as edges to ensure edge detail is preserved.
Clip White
This sets the threshold for what becomes fully opaque in the output (white in the matte).
It should be set as high as possible. Colors close to green in the foreground
may require lowing this and/or adjusting the *Screen Balance*. Particularly problematic
parts can fixed with a *Core Matte* instead of a low *Clip White*.

This value does not impact areas detected as edges to ensure edge detail is preserved.
Dilate/Erode
Enlarge (positive numbers) or shrink (negative numbers) the matte by the specified number of pixels.
This is similar to using the :doc:`Dilate/Erode Node &lt;/compositing/types/filter/dilate_erode&gt;` on the matte.

This a simple way to include more or less along the edges of the matte, particularly combined with *Post Blur*.
Feather Falloff
The rate of fall off at the edges of the matte when feathering, to manage edge detail.
Feather Distance
Controls how much the matte is feathered inwards (negative number) or outwards (positive number).
Post Blur
Make the matte less sharp, for smoother transitions to the background and noise reduction.

Outputs
=======

Image
Processed image with the *Matte* applied to the images's :term:`alpha channel`.
Matte
Output matte to use for checking the quality of the key, or to manually apply
using a :doc:`Set Alpha Node &lt;/compositing/types/converter/set_alpha&gt;` or
:doc:`Mix Node &lt;/compositing/types/color/mix&gt;`.
Edges
Shows what edges were detected on the matte. Useful for adjusting the
*Edge Kernel Radius* and *Edge Kernel Tolerance*.

.. tip::

If there are problems with the edges of the matte, it may help to start with
adjusting the *Edge Kernel* parameters before adjusting feathering. Detected
edges are not subject to *Clip Black* / *Clip White* thresholds to preserve
fine edge detail. You can check edge detection by connecting a
:doc:`Viewer Node &lt;/compositing/types/output/viewer&gt;` to the *Edges* output.

Sharper detected edges (smaller *Edge Kernel Radius*, like 2 / larger *Edge Kernel Tolerance*,
like 0.4) will create a sharper matte, but may loose some detail like stray hairs.
A sharp matte is good, but disappearing or flickering hairs are distracting.

Fat edges (larger *Edge Kernel Radius*, like 8 / smaller *Edge Kernel Tolerance*,
like 0.05) will capture more edge detail, but may also produce a halo around the subject.
The halo can be adjusted with *Feather* controls along with *Dilate/Erode*.

******************
Keying Screen Node
******************

.. figure:: /images/compositing_nodes_matte_keying-screen.png
:align: right

Keying Screen Node.

The *Keying Screen* node creates plates for use as a color reference for keying nodes.
It generates gradients from sampled colors on motion tracking points on movie clips.
It can be used to deal with uneven colors of green screens.

Inputs
======

This node has no input sockets.

Properties
==========

Movie Clip
The selectable clip data-block used as input for the gradient colors.
Tracking Object
Tracking Object to generate the gradient.
You will probably want to create new a tracking object in the
:ref:`Object &lt;movie-clip-tracking-properties-object&gt;` panel,
because tracks used for gradients can not actually be used for camera/object tracking.
After this tracks might be placed in places where gradient colors should be sampled.
These tracks could be tracked or moved manually,
so gradients would be updating automatically along the movie.
Tracks might have an offset for easier tracking of feature-less screens.

Outputs
=======

Screen
Gradient image output.

Example
=======

Consider a node setup for green screen removal, using a
:doc:`Color Key &lt;/compositing/types/matte/color_key&gt;`:

.. figure:: /images/compositing-node-color_key_usage.png
:width: 480px

Often, lighting is uneven across the backdrop.

.. figure:: /images/compositing-node-keying_screen_source.jpg

Example from the `Mango Open Movie &lt;https://mango.blender.org/&gt;`_, Tears of Steel.

That can result in a bad matte.

.. figure:: /images/compositing-node-keying_screen_bad.jpg

Example of a poor mask: Some of the backdrop is opaque,
and some parts of the gun in the foreground are transparent.

If you increase the tolerances on the keying node, it will accept
mores shades of green to mask out. But it may also incorrectly mask out more of
the foreground.

Instead of increasing the range of accepted shades to be masked out, the *Keying Screen*
node lets you change what shade of green (or other color) to use for different parts of
the image.

Start in the :doc:`Movie Clip Editor &lt;/editors/movie_clip_editor/introduction&gt;`.
Open the Properties Region and Tool Shelf to show tracking configuration.
Tracks used for gradients are not useful for camera solving, because they do not
track well.  So create a new object track in the *Objects* selector. Place tracking
markers on the clip to sample different parts of the backdrop.

.. figure:: /images/compositing-node-keying_screen_trackers.jpg

These tracks may be tracked or moved manually, so gradients can be updated
over time. If the marker is not enabled for a frame, it will not be used creating
the gradient. (Such as the red-colored marker on the arm in the screen shot above)

Once the tracks are created, add the node to your compositing setup, and select the
tracking object used for the backdrop.

.. figure:: /images/compositing-node-color_key_screen_usage.png
:width: 480px

Node configuration with *Keying Screen*'s generated gradient
plate connected to the Color input of the Keying node.

.. figure:: /images/compositing-node-keying_screen_generated.jpg

Gradient plate generated by *Keying Screen*.

The resulting image now has a better matte.

.. figure:: /images/compositing-node-keying_screen_good.jpg

******************
Luminance Key Node
******************

.. figure:: /images/compositing_nodes_matte_luminance-key.png
:align: right

Luminance Key Node.

The *Luminance Key* node determines background objects from foreground objects by
the difference in the luminance (brightness) levels.

Stock footage of explosions, smoke or debris  are normally shot against a solid,
dark background rather than a green screen. This node can separate the
foreground effect from the background. It can also be used for sky replacement for
over-exposed or gray skies that aren't suitable for chroma keying.

.. tip::

When compositing footage of something that emits light and has a dark background,
like fire, a :doc:`Mix Node &lt;/compositing/types/color/mix&gt;` using a *Screen* or
*Add* operator will produce better results.

Inputs
======

Image
Standard image input.

Properties
==========

Limit
High
Determines the lowest values that are considered foreground.
(which is supposed to be -- relatively -- light: from this value to 1.0).
Low
Determines the highest values that are considered to be background objects.
(which is supposed to be -- relatively -- dark: from 0.0 to this value).

.. note::

Brightness levels between the two values form a gradient of transparency
between foreground and background objects.

Outputs
=======

Image
Image with an alpha channel adjusted for the keyed selection.
Matte
A black and white alpha mask of the key.

Example
=======

For this example the model was shot against a *white* background.
Using the Luminance Key node, we get a matte out where the background is white,
and the model is black; the opposite of what we want.
If we wanted to use the matte, we have to switch the white and the black.
How to do this? Color Ramp node to the rescue -- we set the left color White Alpha 1.0,
and the right color to be Black Alpha 0.0. Thus, when the Color Ramp gets in black,
it spits out white, and vice versa. The reversed mask is shown;
her white outline is usable as an alpha mask now.

.. figure:: /images/compositing_nodes_matte_luminance-key_example.png

Using Luma Key with a twist.

Now to mix, we do not really need the *Alpha Over* node;
we can just use the mask as our Factor input. In this kinda weird case,
we can use the matte directly; we just switch the input nodes. As you can see,
since the matte is white (1.0) where we do not want to use the model picture,
we feed the background photo to the bottom socket
(recall the mix node uses the top socket where the factor is 0.0,
and the bottom socket where the factor is 1.0). Feeding our original photo into the top socket
means it will be used where the Luminance Key node has spit out Black. Voila,
our model is teleported from Atlanta to aboard a cruise ship docked in Miami.

**************
Composite Node
**************

.. figure:: /images/compositing_nodes_output_composite.png
:align: right

Composite Node.

The Composite node is where the actual output from the Compositor
is connected to the renderer.
This node is updated after each render, but also reflects changes in the node-tree
(provided at least one finished input node is connected).

Inputs
======

Connecting a node to the Composite node will output the result of the prior
tree of that node to the Compositor.

Image
RGB image. The default is black, so leaving this node unconnected will result in a blank image.
Alpha
Alpha channel.
Z
Z-depth.

Properties
==========

Use Alpha
Premultiplied or straight.

Outputs
=======

This node has no output sockets.

.. note::

If multiple Composite nodes are added, only the active one
(last selected, indicated with a slightly darker header) will be used.

****************
File Output Node
****************

.. figure:: /images/compositing_nodes_output_file.png
:align: right

File Output Node.

This node writes out an image, for each frame range specified,
to the filename entered, as part of a frameset sequence.

This node can be used as a way to automatically save the image after a render;
In addition, since this node can be hooked in anywhere in the node tree,
it can also save intermediate images automatically.

Inputs
======

Image
The image(s) will be saved on rendering, writing to the current frame.
An entire sequence of images will be saved, when an animation is rendered.

.. note::

To support subsequent arrangement and layering of images, the node can supply a Z-depth map.
However, please note that only the OpenEXR image formats save the Z information.

Properties
==========

Base Path
Unlike the render output filepath, this node uses a base directory and an image name,
by default the output path is composed of:
``{base path}/{file name}{frame number}.{extension}``.

Besides being split into two settings, in all other respects,
this setting is treated the same as the :ref:`render output path &lt;render-tab-output&gt;`.
File Format label
Shows the selected File Format.

.. note::

More options could be set in the properties region.

Outputs
=======

This node has no output sockets.
.. _composite-nodes-output-index:

###############
Output Nodes
###############

These nodes are used to output the composited result in some way.

.. toctree::
:maxdepth: 1

composite.rst
file.rst
levels.rst
split_viewer.rst
viewer.rst

***********
Levels Node
***********

.. figure:: /images/compositing_nodes_output_levels.png
:align: right

Levels Node.

The Levels Node read the inputs color channels
and outputs analytical values.

Inputs
======

Image
Standard image input.

Properties
==========

Channel
C (Combined RGB), R (Red), G (Green), B (Blue), L (Luminance)

Outputs
=======

1D values based on the levels of an image.

Mean
The mean is the average value of all image pixels in specified channel
(combined, red, green, blue, luminance). It tells you how dark or bright the image
is and can be used as such for setups that depend on how is input "bright" or "dark".
Standard deviation
How much those pixel values differ from the mean.
A low standard deviation indicates that the pixel values tend to be very close to the mean.
A high standard deviation indicates that the values are spread out over a large range of values.

The visualization of such data is just a gray rectangle.

*****************
Split Viewer Node
*****************

.. figure:: /images/compositing_nodes_output_split-viewer.png
:align: right

Split Viewer Node.

The *Split Viewer* node takes two images and displays these side-by-side
as backdrop or as a Viewer Node output.

Inputs
======

Image
Shown on the right or top half set by the axis.
Image
And respectively the left or bottom half.

Properties
==========

Axis
X or Y used as the split axis.
Factor
Percentage factor setting the space distribution between the two images.

Outputs
=======

This node has no output sockets.

.. hint::

This node could be used to plan scene transitions by comparison of the end frame of one scene
with the start frame of another to make sure that they align.

Examples
========

.. figure:: /images/compositing_nodes_color_gamma_example.jpg
:width: 700px

Example of Split Viewer node.

***********
Viewer Node
***********

.. figure:: /images/compositing_nodes_output_viewer.png
:align: right

Viewer Node.

The *Viewer* node is a temporary, in-process viewer.
It could be plug in anywhere to inspect an image or value-map in your node-tree.

Select a view node with :kbd:`LMB` to switch between multiple view nodes.
It is possible to automatically plug a Viewer node to any other node
by pressing :kbd:`Shift-Ctrl-LMB` on it.

Inputs
======

see :doc:`Composite Node &lt;/compositing/types/output/composite&gt;`.

Properties
==========

Tile order
The tile order can be defined for the backdrop image, using the *Tile order* field in the properties of the
viewer node (*Properties* panel in Properties region, with the viewer node selected):

Rule of thirds
Calculates tiles around each of the nine zones defined by the *rule of thirds* .
Bottom up
Tiles are calculated from the bottom up.
Random
Calculates tiles in a non-specific order.
Center
Calculates the tiles around a specific center, defined by X and Y fields.

X, Y

Outputs
=======

This node has no output sockets.

.. note::

It is possible to add multiple Viewer nodes, though only the active one
(last selected, indicated with a slightly darker header) will be shown on the backdrop or in the UV/Image editor.

Using the UV/Image Editor
=========================

The viewer node allows results to be displayed in the UV/Image Editor.
The image is facilitated in the header by selecting *Viewer Node* in the linked *Image* data-block menu.
The UV/Image Editor will display the image from the currently selected viewer node.

To save the image being viewed,
use :menuselection:`Image --&gt; Save As Image`, :kbd:`F3` to save the image in a file.

The UV/Image Editor also has three additional options in its header to view Images with or
without Alpha, or to view the Alpha or Z itself.
Holding :kbd:`LMB` in the Image display allows you to sample the values.
.. _composite-nodes-vector-index:

###############
Vector Nodes
###############

These nodes can be used to manipulate various types of vectors, such as surface normals and speed vectors.

.. toctree::
:maxdepth: 1

map_range.rst
map_value.rst
normal.rst
normalize.rst
vector_curves.rst

**************
Map Range Node
**************

.. figure:: /images/compositing_nodes_vector_map-range.png
:align: right

Map Range Node.

This node allows to convert (map) an input value range into a destination range.
By default, values outside the specified input range will be proportionally mapped as well.
This node is similar to *Map Value* node but provides a more intuitive way to specify the desired output range.

Inputs
======

Value
Standard value input.
From Min/Max
Start/End of the input value range.
To Min/Max
Start/End of the destination range.

Properties
==========

Clamp
Clamps values to Min/Max of the destination range.

Outputs
=======

Value
Standard value output.

Usage
=====

One important use case is to easily map the Z-depth channel from its original range
to a more usable range (i.e.: 0.0 - 1.0) for use as a matte for colorization or filtering operations.

**************
Map Value Node
**************

.. figure:: /images/compositing_nodes_vector_map-value.png
:align: right

Map Value Node.

Map Value node is used to scale, offset and clamp values.

Inputs
======

Value
Standard Value input. (value refers to each vector in the set).

Properties
==========

Offset
Factor added to the input value.
Size
Scales (multiply) the input value.
Use Minimum, Maximum
Enable this to activate their related operation.
Min, Max
Defines a range between minimum and maximum to :term:`clamp` the input value to.

Outputs
=======

Value
Standard value output.

Example
=======

Z Depth map
-----------

This is particularly useful in achieving a depth-of-field effect,
where the Map Value node is used to map a Z value
(which can be 20 or 30 or even 500 depending on the scene) to the range between (0 to 1),
suitable for connecting to a Blur node.

Multiplying values
------------------

This node can also be used the map value node to multiply values to achieve a desired output value.
In the mini-map to the right, the Time node outputs a value between 0.0 and 1.
00 evenly scaled over 30 frames. The *first* Map Value node multiplies the input by 2,
resulting in an output value that scales from 0.0 to 2.0 over 30 frames.
The *second* Map Value node subtracts 1 from the input,
giving working values between (-1.00 to 1.0), and multiplies that by 150,
resulting in an output value between (-150 to 150) over a 30-frame sequence.

.. figure:: /images/compositing_nodes_vector_map-value_example.png

Using Map Value to multiply
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/vector/normal&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/vector/normal&gt;`

***********
Normal Node
***********

.. figure:: /images/compositing_nodes_vector_normal.png
:align: right

Normal Node.

The Normal node generates a normal vector and a dot product.

Inputs
======

Normal
Normal vector input.

Properties
==========

Normal Direction
To manually set a fixed normal direction vector.
:kbd:`LMB` click and drag on the sphere to set the direction of the normal.
Holding :kbd:`Ctrl` while dragging snaps to 45 degree rotation increments.

Outputs
=======

Normal
Normal vector output.
Dot
Dot product output. The dot product is a scalar value.

- If two normals are pointing in the same direction the dot product is 1.
- If they are perpendicular the dot product is zero (0).
- If they are antiparallel (facing directly away from each other) the dot product is -1.

**************
Normalize Node
**************

.. figure:: /images/compositing_nodes_vector_normalize.png
:align: right

Normalize Node.

Normalizing a vector scales its magnitude, or length, to a value of 1,
but keeps its direction intact.

Inputs
======

Value
Standard value input.

Properties
==========

This node has no properties.

Outputs
=======

Value
Standard value output.

.. TODO add more info and examples
.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/types/vector/curves&gt;`
.. Editors Note: This page gets copied into :doc:`&lt;/render/blender_render/materials/nodes/types/vector/curves&gt;`

******************
Vector Curves Node
******************

.. figure:: /images/compositing_nodes_vector_vector-curves.png
:align: right

Vector Curves Node.

The Vector Curves node maps an input vector components to a curve.

Use this curve node to slow things down or speed them up from the original scene.

Inputs
======

In the shader context the node also has an additional Factor property.

Factor
Controls the amount of influence the node exerts on the output vector.
Vector
Standard vector input.

Properties
==========

Channel
X, Y, Z
Curve
For the curve controls see: :ref:`Curve widget &lt;ui-curve-widget&gt;`.

Outputs
=======

Vector
Standard vector output.

*****************
Custom Properties
*****************

.. figure:: /images/data-system_custom-properties_add.png
:align: right

Custom Properties Panel.

Custom properties are a way to store your own meta-data in Blender's data-blocks
which can be used for rigging (where bones and objects can have custom properties driving other properties),
and Python scripts, where it's common to define new settings not available in Blender.

Only certain data supports custom properties:

- All :ref:`data-blocks types &lt;data-system-datablock-types&gt;`.
- Bones and Pose-Bones.
- Sequence strips.

To add a custom property, find the *Custom Properties* panel,
found at the bottom of most :doc:`Properties Editor &lt;/editors/properties_editor&gt;`, and hit *Add*.

Editing Properties
==================

User Interface
--------------

Custom properties can be edited using the panel available for data types that support it.

.. figure:: /images/data-system_custom-properties_edit.png
:align: right

Custom Properties Edit Region.

Property Name
The name of the custom property
Property Value
Todo.
Min
The minimum value the custom property can take.
Max
The maximum value the custom property can take.
Use Soft Limits
Enables limits that the *Property Value* slider can be adjusted to
without having to input the value numerically.

Soft Min
The minimum value for the soft limit.
Soft Max
The maximum value for the soft limit.
Tooltip
Allows you to write a custom :doc:`Tooltip &lt;/getting_started/help&gt;` for your property.

Python Access
-------------

Custom properties can be accessed in a similar way to
`dictionaries &lt;https://docs.python.org/3/tutorial/datastructures.html#dictionaries&gt;`__,
with the constraints that keys can only be strings,
and values can only be strings, numbers, arrays and nested properties.

See the `API documentation
&lt;https://www.blender.org/api/blender_python_api_current/info_quickstart.html#custom-properties&gt;`__
for details.

***********
Data-Blocks
***********

The base unit for any Blender project is the data-block. Examples of data-blocks include:
meshes, objects, materials, textures, node-trees, scenes, texts, brushes, and even screens.

For clarity, bones, sequence strips and vertex groups are **not** data-blocks,
they belong to armature, scene and mesh types respectively.

Some common characteristics:

- They are the primary contents of the blend-file.
- They can link to each other, for reuse and instancing.
(child/parent, object/object-data, with modifiers and constraints too).
- Their names are unique.
- They can be added/removed/edited/duplicated.
- They can be linked between files (only enabled for a limited set of data-blocks).
- They can have their own animation data.
- They can have :doc:`Custom Properties &lt;/data_system/custom_properties&gt;`.

When doing more complex projects, managing data-blocks becomes more important,
especially when inter-linking blend-files.

.. figure:: /images/data_system_datablocks.jpg
:width: 400px

Data-blocks view.

Users (Garbage Collection)
==========================

It is good to be aware of how Blender,
handles data-blocks lifetime, when they are freed and why.

Blender follows the general rule where unused data is eventually removed.

Since it is common to add and remove a lot of data while working,
this has the advantage of not having to manually manage every single data-block.

This works by skipping zero user data-blocks when writing blend-files.

In some cases, you want to save a data-block even when it is unused
(typically for re-usable asset libraries). see `Fake User`_.

.. _data-system-datablock-fake-user:

Fake User
---------

Since zero user data-blocks are not saved,
there are times when you want to force the data to be kept irrespective of its users.

If you are building a blend-file to serve as a library of things that you intend to link to and from other files,
you will need to make sure that they do not accidentally get deleted from the library file.

Do this by giving the data-blocks a *Fake User*, by pressing the *F* button next to the name of the data-block.
This prevents the user count from ever becoming zero: therefore, the data-block will not be deleted.
(since Blender does not keep track of how many other files link to this one.)

Users (Sharing)
===============

Many data-blocks can be shared among other data-blocks,

Examples where sharing data is common:

- Sharing textures among materials.
- Sharing meshes between objects (instances).
- Sharing animated actions between objects,
for example to make all the lights dim together.

You can also share data-blocks between files, see:

- :doc:`linked libraries &lt;/data_system/linked_libraries&gt;`.

.. _data-system-datablock-make-single-user:

Make Single User
================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Make Single User`
| Hotkey:   :kbd:`U`

Makes the selected or all objects data-blocks a single user, that is,
not shared (linked) between other objects than the current one.

Type
These actions work on the selected objects, or on all the objects of the scene,

All, Selected Objects
Data-blocks
Lets you, in addition to the menu predefined selection, choose the type of data-blocks individually.

Object, Object Data, Materials, Textures, Object Animation

Removing Data-Blocks
====================

As covered in `Users (Garbage Collection)`_, data-blocks are typically removed when they are no longer used.

There are some exceptions to this, however.

The following data-blocks can be removed directly: Scene, Text, Group, and Screen.

Other data-blocks such as Groups and Actions can be *Unlinked* from the *Outliner* context menu.

.. tip::

Some data (images especially) is hard to keep track of,
especially since image views are counted as users.

For data-blocks that can be unlinked hold :kbd:`Shift`, while pressing on the *X* button.
This force clears the user-count, so the data-block will be removed on reloading.

.. _data-system-datablock-types:

Data-Block Types
================

.. EDITORS NOTE:
Mostly we want to avoid long lists of data - but in this case,
it is the only comprehensive list of data-blocks, and something which you cannot
find directly just through looking at the interface.
::
TODO, add links to related docs for each type.

.. image source: Scene tab --&gt; Active keying set panel --&gt; ID-block (sound replaced)

.. figure:: /images/data_system_id-types.png
:align: right
:width: 250px

Data-blocks types with their icon.

For reference, here is a table of data-blocks types stored in blend-files.

:Link: Library Linking, supports being linked into other blend-files.
:Pack: File Packing, supports file contents being packed into the blend-file.

.. EDITORS NOTE:
For each data-block, we have 2 lines.
1) a terse description.
2) how its used.
::
Keep these short.

.. container:: lead

.. clear

.. |tick|  unicode:: U+2713
.. |cross| unicode:: U+2717

.. list-table::
:header-rows: 1
:class: valign
:widths: 20 5 5 70

* - Type
- Link
- Pack
- Description
* - Action
- |tick|
- |cross|
- | Stores animation F-Curves.
| Used as data-block animation data,
| and the Non-Linear-Editor.
* - Armature
- |tick|
- |cross|
- | Skeleton used to deform meshes.
| Used as object data &amp; by the Armature Modifier.
* - Brush
- |tick|
- |cross|
- | Used by paint tools.
* - Camera
- |tick|
- |cross|
- | Used as object data.
* - Curve
- |tick|
- |cross|
- | Used by camera, font &amp; surface objects.
* - Font
- |tick|
- |tick|
- | References font files.
| Used by Font object-data.
* - GreasePencil
- |tick|
- |cross|
- | 2D/3D sketch data.
| Used as overlay *helper* info, by the
| 3D View, Image, Sequencer &amp; Movie Clip editors.
* - Group
- |tick|
- |cross|
- | Reference object's.
| Used by dupli-groups &amp; often library-linking.
* - Image
- |tick|
- |tick|
- | Image files.
| Used by textures &amp; shader nodes.
* - Lamp
- |tick|
- |cross|
- | Used as object-data.
* - Lattice
- |cross|
- |cross|
- | Grid based lattice deformation.
| Used as object data and by the Lattice Modifier.
* - Library
- |cross|
- |tick|
- | References to external blend-files.
| Access from the Outliner's blend-file view.
* - LineStyle
- |tick|
- |cross|
- | Used by the FreeStyle render-engine.
* - Mask
- |tick|
- |cross|
- | 2D animated mask curves.
| Used by compositing nodes &amp; sequencer strip.
* - Material
- |tick|
- |cross|
- | Set shading and texturing render properties.
| Used by objects, meshes &amp; curves.
* - Mesh
- |tick|
- |cross|
- | Geometry vertices/edges/faces.
| Used as object-data.
* - MetaBall
- |tick|
- |cross|
- | An isosurface in 3D space.
| Used as object-data.
* - MovieClip
- |tick|
- |cross|
- | Reference to an image sequence or video file.
| Used in the motion-tracking editor.
* - NodeGroup
- |tick|
- |cross|
- | Collections of re-usable nodes.
| Used in the Node Editor.
* - Object
- |tick|
- |cross|
- | An entity in the scene with location,
| scale, rotation.
| Used by scenes &amp; groups.
* - Particle
- |tick|
- |cross|
- | Particle settings.
| Used by particle systems.
* - Palette
- |tick|
- |cross|
- | Store color presets.
| Access from the paint tools.
* - Scene
- |tick|
- |cross|
- | Primary store of all data displayed and animated.
| Used as top-level storage for objects &amp; animation.
* - Screen
- |cross|
- |cross|
- | Screen layout.
| Used by each window, which has its own screen.
* - ShapeKeys
- |cross|
- |cross|
- | Geometry shape storage, which can be animated.
| Used by mesh, curve, and lattice objects.
* - Sounds
- |tick|
- |tick|
- | References to sound files.
| Used by speaker objects and the Game Engine.
* - Speaker
- |tick|
- |cross|
- | Sound sources for a 3D scene.
| Used as object-data.
* - Text
- |tick|
- |cross|
- | Text data.
| Used by Python scripts and OSL shaders.
* - Texture
- |tick|
- |cross|
- | 2D/3D textures.
| Used by materials, world and brushes.
* - World
- |tick|
- |cross|
- | Used by scenes for render environment settings.
* - WindowManager
- |cross|
- |cross|
- | The overarching manager for all of Blender's UI;
this includes screens, notification system, operators, and keymaps.

*****************************
Importing and Exporting Files
*****************************

Sometimes you may want to utilize files that either came from other 2D or 3D software,
or you may want to use the things you have made in Blender and edit them in other software.
Luckily, Blender offers a wide range of file formats (e.g. OBJ, FBX, 3DS, PLY, STL... etc)
that can be used to import and export.

These formats can be accessed from the menus:
:menuselection:`File --&gt; Import` and :menuselection:`File --&gt; Export`.

Popular formats are enabled by default, other formats are also supported and distributed with Blender,
these can be enabled in the User Preferences through the use of :doc:`Add-ons &lt;/preferences/addons&gt;`.

.. hint::

If you are not interested in technical details,
a good rule of thumb for selecting import/export formates for your project is:

Use :abbr:`STL (STereoLithography)`
if you intend to import/export the files for CAD software.
This format is also commonly used for loading into 3D printing software.
Use :abbr:`FBX (Filmbox)`
if you intend to export objects with rigs and/or animation
to be used in other 3D creation suites or game development.
Use :abbr:`DAE (Collada)`
if you intend to export objects with rigs and/or animation
to be used in other 3D creation suites or game development (provided they support Collada).
See also the `Blender Collada module &lt;https://wiki.blender.org/index.php?title=Doc:2.6/Manual/Data_System/Files/Import/COLLADA&gt;`__.
Use :abbr:`ABC (Alembic)`
if you want to import/export a large amount of scene data.

.. seealso::

A list of these add-ons can also be found on the
`Add-ons Catalog &lt;https://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts#Import-Export_Scripts&gt;`__.

#########
Files
#########

.. toctree::
:maxdepth: 1

open.rst
save.rst
import_export.rst
relative_paths.rst
startup_file.rst
media/index.rst

**************************
Supported Graphics Formats
**************************

Image Formats
=============

This is the list of image file formats supported internally by Blender:

.. |tick|  unicode:: U+2713
.. |cross| unicode:: U+2717

.. list-table::
:header-rows: 1
:class: valign
:widths: 25 25 10 10 10 20

* - Format
- `Channel Depth`_
- Alpha
- :doc:`Metadata &lt;/render/output/metadata&gt;`
- DPI
- Extensions
* - BMP
- 8bit
- |cross|
- |cross|
- |tick|
- ``.bmp``
* - Iris
- 8bit
- |tick|
- |cross|
- |cross|
- ``.sgi`` ``.rgb`` ``.bw``
* - PNG
- 8, 16bit
- |tick|
- |tick|
- |tick|
- ``.png``
* - JPEG
- 8bit
- |cross|
- |tick|
- |tick|
- ``.jpg`` ``.jpeg``
* - JPEG 2000
- 8, 12, 16bit
- |tick|
- |cross|
- |cross|
- ``.jp2`` ``.jp2`` ``.j2c``
* - Targa
- 8bit
- |tick|
- |cross|
- |cross|
- ``.tga``
* - `Cineon &amp; DPX`_
- 8, 10, 12, 16bit
- |tick|
- |cross|
- |cross|
- ``.cin`` ``.dpx``
* - `OpenEXR`_
- float 16, 32bit
- |tick|
- |tick|
- |tick|
- ``.exr``
* - `Radiance HDR`_
- float
- |tick|
- |cross|
- |cross|
- ``.hdr``
* - TIFF
- 8, 16bit
- |tick|
- |cross|
- |tick|
- ``.tif`` ``.tiff``

.. hint::

If you are not interested in technical details,
a good rule of thumb for selecting output formats for your project is:

Use OpenEXR
if you intend to do compositing or color-grading on these images.
Use PNG
if you intend on-screen output or encoding into multiple video formats.
Use JPEG
for on-screen output where file size is a concern and quality loss is acceptable.

*All these formats support compression which can be important when rendering out animations.*

.. note:: Quicktime

On macOS, Quicktime can be used to access file formats not natively supported (such as GIF).

Channel Depth
-------------

Image file formats support a varying number of bits per pixel.
This affects the color quality and file-size.

Commonly used depths:

8 bit (256 levels)
Most common for on-screen graphics and video
10, 12, 16 bit (1024, 4096, 65536 levels)
Used for some formats focusing on photography and digital films
(such as DPX and JPEG 2000).
16 bit half float
Since full 32bit float is often more than enough precision,
half float can save drive space while still providing a high dynamic range.
32 bit float
Highest quality color depth.

Internally Blender's image system supports either:

- 8 bit per channel (4 x 8 bits).
- 32 bit float per channel (4 x 32 bits) - *using 4x as much memory.*

Images higher than 8 bits per channel will be converted into a float on loading into Blender.

.. note::

Floating point is often used for :term:`HDRI`.

When an image has float colors, all imaging functions in Blender default to use that.
This includes the Video Sequence Editor, texture mapping, background images,
and the Compositor.

Export
------

Save As Render
ToDo.
Copy
The Copy checkbox will define if the data-block will reference the newly created file
or the reference will be unchanged, maintaining it with the original one.

Format Details
==============

Cineon &amp; DPX
------------

Cineon is Kodak's standard for film scanning, 10 bits/channel and logarithmic.
DPX has been derived from Cineon as the ANSI/SMPTE industry standard.
DPX supports 16 bits color/channel, linear as well as logarithmic.
DPX is currently a widely adopted standard used in the film hardware/software industry.

DPX as well as Cineon only stores and converts the "visible" color range of values between 0.0
and 1.0 (as a result of rendering or composite).

OpenEXR
-------

`ILM's OpenEXR &lt;http://www.openexr.com/&gt;`__ has become a software industry standard for HDR image files,
especially because of its flexible and expandable structure.

An OpenEXR file can store multiple layers and passes.
This means OpenEXR images can be loaded into a compositor keeping render layers, passes intact.

Output Options
^^^^^^^^^^^^^^

Available options for OpenEXR render output are:

Color Depth
Saves images in a custom 16 bits per channel floating point format.
This reduces the actual "bit depth" to 10 bits, with a 5 bits power value and 1 bit sign.

Float (Half), Float (Full)
Codec
``PIZ``
Lossless wavelet compression. Compresses images with grain well.
``ZIP``
Standard lossless compression using Zlib.
``RLE``
Run-length encoded, lossless, works well when scanlines have same values.
``PXR24``
Lossy algorithm from Pixar, converting 32 bits floats to 24 bits floats.
Z Buffer
Save the depth information.
In Blender, this now is written in floats too,
denoting the exact distance from the camera in "Blender unit" values.
Preview
On rendering animations (or single frames via command line),
Blender saves the same image also as a JPEG, for quick preview or download.

Radiance HDR
------------

Radiance is a suite of tools for lighting simulation.
Since Radiance had the first (and for a long time the only) HDR image format,
this format is supported by many other software packages.

Radiance (.hdr) files store colors still in 8 bits per component, but with an additional
(shared) 8 bits exponent value, making it 32 bits per pixel.

################
Media Formats
################

.. toctree::
:maxdepth: 2

introduction.rst
image_formats.rst
video_formats.rst

************
Introduction
************

TODO.

Color Spaces
============

TODO.

***********************
Supported Video Formats
***********************

Video Formats
=============

These formats are primarily used for compressing rendered sequences into a playable movie
(they can also be used to make plain audio files).

A codec is a little routine that compresses the video so that it will fit on a DVD,
or be able to be streamed out over the Internet, over a cable, or just be a reasonable file size.
Codecs compress the channels of a video down to save space and enable continuous playback.
*Lossy* codecs make smaller files at the expense of image quality. Some codecs, like H.264,
are great for larger images. Codecs are used to encode and decode the movie,
and so must be present on both the encoding machine (Blender) and the target machine.
The results of the encoding are stored in a container file.

There are dozens, if not hundreds, of codecs, including XviD, H.264, DivX, Microsoft,
and so on. Each has advantages and disadvantages and compatibility with different players on
different operating systems.

Most codecs can only compress the RGB or YUV :term:`color space`,
but some support the Alpha channel as well. Codecs that support RGBA include:

- Quicktime
- PNG TIFF Pixlet is not loss-less, and may be only available on macOS.
- `Lagarith Lossless Video Codec &lt;http://lags.leetcode.net/codec.html&gt;`__

AVI Codec
AVI codec compression. Available codecs are operating-system dependent.
When an AVI codec is initially chosen, the codec dialog is automatically launched.
The codec can be changed directly using the *Set Codec* button which appears (*AVI Codec settings.*).
AVI Jpeg
AVI but with Jpeg compression.
Lossy, smaller files but not as small as you can get with a Codec compression algorithm.
Jpeg compression is also the one used in the DV format used in digital camcorders.
AVI Raw
Audio-Video Interlaced (AVI) uncompressed frames.
Frameserver
Blender puts out `frames upon request
&lt;https://wiki.blender.org/index.php/Dev:Source/Render/Frameserver&gt;`__
as part of a render farm.
The port number is specified in the User Preferences.
H.264
Encodes movies with the H.264 codec.
MPEG
Encodes movies with the MPEG codec.
Ogg Theora
Encodes movies with the Theora codec as Ogg files.
QuickTime
Apple's Quicktime ``.mov`` file.
The Quicktime codec dialog is available when this codec is installed on macOS.
See *Quicktime* in `Video Containers`_.
Xvid
Encodes movies with the Xvid codec.

Video Containers
================

`MPEG-1 &lt;https://en.wikipedia.org/wiki/MPEG-1&gt;`__: ``.mpg``, ``.mpeg``
A standard for lossy compression of video and audio.
It is designed to compress VHS-quality raw digital video and CD audio down to 1.5 Mbit/s.
`MPEG-2 &lt;https://en.wikipedia.org/wiki/MPEG-2&gt;`__: ``.dvd``, ``.vob``, ``.mpg``, ``.mpeg``
A standard for "the generic coding of moving pictures and associated audio information".
It describes a combination of lossy video compression and lossy audio data compression
methods which permit storage and transmission of movies using currently
available storage media and transmission bandwidth.
`MPEG-4(DivX) &lt;https://en.wikipedia.org/wiki/MPEG-4&gt;`__: ``.mp4``, ``.mpg``, ``.mpeg``
Absorbs many of the features of MPEG-1 and MPEG-2 and other related standards, and adds new features.
`AVI &lt;https://en.wikipedia.org/wiki/Audio_Video_Interleave&gt;`__: ``.avi``
A derivative of the Resource Interchange File Format (RIFF), which divides a file's data into blocks, or "chunks".
`Quicktime &lt;https://en.wikipedia.org/wiki/.mov&gt;`__: ``.mov``
A multi-tracked format. QuickTime and MP4 container formats can use the same MPEG-4 formats;
they are mostly interchangeable in a QuickTime-only environment.
MP4, being an international standard, has more support.
`DV &lt;https://en.wikipedia.org/wiki/DV&gt;`__: ``.dv``
An intraframe video compression scheme,
which uses the discrete cosine transform (DCT) to compress video on a frame-by-frame basis.
Audio is stored uncompressed.
`H.264 &lt;https://en.wikipedia.org/wiki/H.264&gt;`__: ``.avi`` *for now*.
A standard for video compression, and is currently one of the most commonly used formats for the recording,
compression, and distribution of high definition video.
`Xvid &lt;https://en.wikipedia.org/wiki/Xvid&gt;`__: ``.avi`` *for now*
A video codec library following the MPEG-4 standard. It uses ASP features such as b-frames,
global and quarter pixel motion compensation, lumi masking, trellis quantization, and H.263,
MPEG and custom quantization matrices. Xvid is a primary competitor of the DivX Pro Codec.
`Ogg &lt;https://en.wikipedia.org/wiki/Theora&gt;`__: ``.ogg``, ``.ogv``
A free lossy video compression format.
It is developed by the Xiph.Org Foundation and distributed without licensing fees.
`Matroska &lt;https://en.wikipedia.org/wiki/Matroska&gt;`__: ``.mkv``
An open standard free container format, a file format that can hold an unlimited number of video,
audio, picture or subtitle tracks in one file.
`Flash &lt;https://en.wikipedia.org/wiki/Flash_Video&gt;`__: ``.flv``
A container file format used to deliver video over the Internet using Adobe Flash Player.
`Wav &lt;https://en.wikipedia.org/wiki/Wav&gt;`__: ``.wav``
An uncompressed (or lightly compressed) Microsoft and IBM audio file format.
`Mp3 &lt;https://en.wikipedia.org/wiki/MP3&gt;`__: ``.mp3``
A highly-compressed, patented digital audio encoding format using a form of lossy data compression.
It is a common audio format for consumer audio storage, as well as a de facto standard of digital
audio compression for the transfer and playback of music on digital audio players.

Video Codecs
------------

None
For audio-only encoding.
`MPEG-1 &lt;https://en.wikipedia.org/wiki/MPEG-1&gt;`__
See `Video Formats`_.
`MPEG-2 &lt;https://en.wikipedia.org/wiki/MPEG-2&gt;`__
See `Video Formats`_.
`MPEG-4(DivX) &lt;https://en.wikipedia.org/wiki/MPEG-4&gt;`__
See `Video Formats`_.
`HuffYUV &lt;https://en.wikipedia.org/wiki/Huffyuv&gt;`__
Lossless video codec created by Ben Rudiak-Gould which is
meant to replace uncompressed YCbCr as a video capture format.
`DV &lt;https://en.wikipedia.org/wiki/DV&gt;`__
See `Video Formats`_.
`H.264 &lt;https://en.wikipedia.org/wiki/H.264&gt;`__
See `Video Formats`_.
`Xvid &lt;https://en.wikipedia.org/wiki/Xvid&gt;`__
See `Video Formats`_.
`Theora &lt;https://en.wikipedia.org/wiki/Theora&gt;`__
See Ogg in `Video Formats`_.
`Flash Video &lt;https://en.wikipedia.org/wiki/Flash_Video&gt;`__
See `Video Formats`_.
`FFmpeg video codec #1 &lt;https://en.wikipedia.org/wiki/FFV1&gt;`__
A.K.A. FFV1, a loss-less intra-frame video codec.
It can use either variable length coding or arithmetic coding for entropy coding.
The encoder and decoder are part of the free, open-source library libavcodec in FFmpeg.

Audio Containers
================

`MP2 &lt;https://en.wikipedia.org/wiki/MPEG-1_Audio_Layer_II&gt;`__
A lossy audio compression format defined by ISO/IEC 11172-3.
`MP3 &lt;https://en.wikipedia.org/wiki/MP3&gt;`__
See MP3 in `Video Formats`_ (above).
`AC3 &lt;https://en.wikipedia.org/wiki/Dolby_Digital&gt;`__
Audio Codec 3, an audio compression technology developed by Dolby Laboratories.
`AAC &lt;https://en.wikipedia.org/wiki/Advanced_Audio_Coding&gt;`__
Advanced Audio Codec, a standardized, lossy compression and encoding scheme for digital audio.
-- AAC generally achieves better sound quality than MP3 at similar bit rates.
`Vorbis &lt;https://en.wikipedia.org/wiki/Vorbis&gt;`__
An open-standard, highly-compressed format comparable to MP3 or AAC.
-- Vorbis generally achieves better sound quality than MP3 at similar bit rates.
`FLAC &lt;https://en.wikipedia.org/wiki/FLAC&gt;`__
Free Lossless Audio Codec.
Digital audio compressed by FLAC's algorithm can typically be reduced to 50-60% of its original size,
and decompressed into an identical copy of the original audio data.
`PCM &lt;https://en.wikipedia.org/wiki/PCM&gt;`__
Pulse Code Modulation, a method used to digitally represent sampled analog signals.
It is the standard form for digital audio in computers and various Blu-ray,
Compact Disc and DVD formats, as well as other uses such as digital telephone systems.

Known Limitations
=================

Video Output Size
-----------------

Some codecs impose limitations on output size,
``H.264``, for example requires both the height and width to be divisible by 2.

*************
Opening Files
*************

.. figure:: /images/data_system_files_open_file-browser-open.jpg

Usage
=====

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`File --&gt; Open`
| Hotkey:   :kbd:`Ctrl-O` or :kbd:`F1`

The upper text field displays the current directory path,
and the lower text field contains the selected filename.

.. warning:: For Linux and macOS users:

When exiting you are **not** asked to save unsaved changes to the scene you were previously working on.
So take care to save your work.

On MS-Windows, there is a :ref:`prefs-save-load` option to warn on exit.

Options
=======

.. _file-load-ui:

Load UI
When *Load UI* is checked, it loads the screen layout saved inside each blend-file,
replacing the current layout. Otherwise the file screen layout is ignored.

.. tip::

If you want to work on the blend-file using your own defaults, start a fresh Blender,
then open the file browser and turn off the *Load UI* button, and then open the file.

Trusted Source
When enabled, Python scripts and drivers that may be included in the file will be run automatically.
Enable this only if you created the file yourself,
or you trust that the person who gave it to you did not include any malicious code with it.
See :doc:`Python Security &lt;/advanced/scripting/security&gt;` to configure default trust options.

.. _other-file-open-options:

Other File Open Options
=======================

From the *File* menu, you can also open files with the following tools:

Open Recent
Lists recently used files. Click on one to load it in.
Recover Last Session
This will load the ``quit.blend`` file Blender automatically saved just before exiting.
This option enables you to recover your last work session if, for example, you closed Blender by accident.
Recover Auto Save
This will allow you to open an automatically saved file to recover it.

.. seealso::

:ref:`Auto Saves &lt;troubleshooting-file-recovery&gt;`

**************
Relative Paths
**************

Many blend-files reference external images or other linked blend-files.
A path tells Blender where to look for these files.
If the external files are moved, the blend-file that references them will not look right.

When you specify one of these external files, the default option is to make the path relative.
Blender stores a partial path evaluated relative to the directory location of the referencing blend-file.
This choice helps when you need to reorganize folders or move your files.

With a relative path, you can move the blend-file to a new location provided
the externally linked files are moved along with it.
For example, you could send someone a folder that contains a blend-file
and a sub-folder of external images that it references.

When relative paths are supported, the File Browser provides a *Relative Path* check box,
when entering the path into a text field, use a double slash prefix (``//``) to make it so.

Relative paths are the default but this can be changed in the
:doc:`File &lt;/preferences/file&gt;` tab
of the User Preferences Editor.

.. note::

You cannot enter relative paths into a new *untitled* blend-file.
Save it before linking to external files.

.. hint::

If it is necessary to relocate a blend-file relative to its linked resources,
use Blender's File :doc:`Save As &lt;/data_system/files/save&gt;`
function which has an option to *Remap Relative* file links.

************
Saving Files
************

.. admonition:: Reference
:class: refbox

| Editor:   Info
| Menu:     File

There are a number of slightly different methods you can use to save your blend-file to your hard drive:

Save :kbd:`Ctrl-S`, :kbd:`Ctrl-W`
Save an existing blend-file over itself.
Save As :kbd:`Ctrl-Shift-S`, :kbd:`F2`
Choose a file to save the blend-file to.
Save Copy :kbd:`Ctrl-Alt-S`
Choose a file to save the blend-file to, but return to editing the original file upon completion.
This can be used to save backups of the current working state without modifying the original file.

If the file name does not end with ``.blend``, the extension is automatically appended.
If a file with the same given name already exists,
the text field will turn red as a warning that the file will be overwritten.

.. figure:: /images/data_system_files_save_file-browser_save.jpg

.. tip::

Use the *plus* or *minus* buttons to the right of the file name,
or :kbd:`NumpadPlus`, :kbd:`NumpadMinus` to increase/decrease a number at the end of the file name
(e.g. changing ``file_01.blend`` to ``file_02.blend``).

Options
=======

The save options appear in the operator panel.

Compress File
When enabled, the saved file will be smaller, but take longer to save and load.
Remap Relative
This option remaps :doc:`relative paths &lt;/data_system/files/relative_paths&gt;`
(such as linked libraries and images) when saving a file in a new location.
Save Copy
This option saves a copy of the actual working state but does not make the saved file active.
Legacy Mesh Format
Save the blend-file, but ignore faces with more than four vertices ("n-gons")
so that older versions of Blender (before 2.63) can open it.

.. seealso::

:ref:`Auto Save &lt;troubleshooting-file-recovery&gt;`

************
Startup File
************

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`File --&gt; Save Startup File`
| Hotkey:   :kbd:`Ctrl-U`

Saves the current file as the default Blender file ``startup.blend``.
This file is loaded every time Blender is opened or a new file is generated (:menuselection:`File --&gt; New`).

It contains the default :doc:`startup scene &lt;/editors/3dview/startup_scene&gt;` included with Blender.
This startup scene can be replaced by your own customized setup.

To change the startup scene, make all of the desired changes to the current scene or
current file and :menuselection:`File --&gt; Save Startup File`.

Saving the ``startup.blend`` still stores user preferences in the file.
Only if a ``userpref.blend`` exists, it uses the preferences from that file.

ToDo: Restore :ref:`factory-settings`.

###############
Data System
###############

.. toctree::
:maxdepth: 2

introduction.rst
data_blocks.rst
custom_properties.rst
scenes/index.rst
files/index.rst
linked_libraries.rst

************
Introduction
************

Each blend-file contains a database.
This database contains all scenes, objects, meshes, textures, etc. that are in the file.

A file can contain multiple scenes and each scene can contain multiple objects.
Objects can contain multiple materials which can contain many textures.
It is also possible to create links between different objects.

Outliner
========

You can easily inspect the contents of your file by using the *Outliner* editor,
which displays all of the data in your blend-file.

The *Outliner* allows you to do simple operations on objects,
such as selecting, renaming, deleting, linking and parenting.

:doc:`Read more about the Outliner &lt;/editors/outliner&gt;`

.. _pack-unpack-data:

Pack and Unpack Data
====================

Blender has the ability to encapsulate (incorporate)
various kinds of data within the blend-file that is normally saved outside of the blend-file.
For example, an image texture that is an external image file can be
put "inside" the blend-file via :menuselection:`File --&gt; External Data --&gt; Pack into blend-file`.
When the blend-file is saved, a copy of that image file is put inside the blend-file.
The blend-file can then be copied or emailed anywhere, and the image texture moves with it.

You know that an image texture is packed, because you will see
a little "Christmas present gift box" displayed in the header.

Unpack Data
-----------

When you have received a packed file,
you can :menuselection:`File --&gt; External Data --&gt; Unpack into Files...`.
If files are packed, there is also track of their original path,
which can be relative or absolute (this is needed in case of unpacking to original location).

Options
^^^^^^^

Use files in current directory (create when necessary)
Unpacks all files in the same directory ``//`` as the blend file,
grouping them in proper folders (like ''textures'' for instance).
However, if the final file exists already, it will use that file, instead of unpacking it.
Write files to current directory (overwrite existing files)
Unpacks all files in the same directory as the blend file,
grouping them in proper folders (like ''textures'' for instance).
If the final file exists already, it will overwrite it.
Use files in original location (create when necessary)
Unpacks all files in their original location.
However, if the final file exists already, it will use that file, instead of unpacking it.
Write files to original location (overwrite existing files)
Unpacks all files in their original location. If the final file exists already, it will overwrite it.
Disable AutoPack, keep all packed files
Cancels the operation and deactivates the *Automatically Pack Into .blend* option.

****************
Linked Libraries
****************

These functions help you reuse materials, objects and other :doc:`data-blocks &lt;/data_system/data_blocks&gt;`
loaded from an external source blend-file.
You can build libraries of common content and share them across multiple referencing files.

Append and Link
===============

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`File --&gt; Append or Link`
| Hotkey:   :kbd:`Shift-F1` or :kbd:`Ctrl-Alt-O`

*Link* creates a reference to the data in the source file such that
changes made there will be reflected in the referencing file the next time it is reloaded.

Whereas *Append* makes a full copy of the data into your blend.
You can make further edits to your local copy of the data,
but changes in the external source file will not be reflected in the referencing file.

In the :doc:`File Browser &lt;/editors/file_browser/introduction&gt;`
navigate to the external source blend-file and select the data-block you want to reuse.

Options
-------

Relative Path
Available only when linking, see :doc:`relative paths &lt;/data_system/files/relative_paths&gt;`.
Select
Makes the object *Active* after it is loaded.
Active Layer
The object will be assigned to the visible layers in your scene.
Otherwise, it is assigned to the same layers it resides on in the source file.
Instance Groups
This option links the Group to an object, adding it to the active scene.

Fake User
Sets a :ref:`Fake User &lt;data-system-datablock-fake-user&gt;` for the append items.
Localize All
ToDo.

When you select an Object type, it will be placed in your scene at the cursor.
Many other data types, cameras, curves, and materials for example,
must be linked to an object before they become visible.

Newly added Group types are available in :menuselection:`Add --&gt; Group Instances` in 3D View,
or for NodeTree groups, the same menu in the Node Editor.

Look in the Outliner, with display mode set to *blend-file*, to see all your linked and appended data-blocks.
:kbd:`Ctrl-LMB` on a file name allows you to redirect a link to another file.

.. _object-proxy:

Proxy Objects
=============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Make Proxy...`
| Hotkey:   :kbd:`Ctrl-Alt-P`

Lets you make changes locally over an object (or group) linked from an external library.
Some types of changes remain restricted, but others can be made locally, depending on the type of object.
Those changes are not sent to the external library.
:kbd:`Ctrl-Alt-P` makes the active linked object into a local proxy, appending "_proxy" to its name.

Used with rigged models, proxy objects, allow specified bone layers to be linked back to the source file
while the remainder of the object and its skeleton are edited locally.
Set the *Protected Layers* in the source file using the Skeleton panel of the Armatures tab.
See :ref:`Armature Layers &lt;armature-layers&gt;`.
The bones in protected layers will have their position restored from the source file
when the referencing file is reloaded.

.. _data-system-linked-libraries-make-link:

Make Link
=========

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Make Link...`
| Hotkey:   :kbd:`Ctrl-L`

Links objects between scenes or data-blocks of the active object to all selected objects.
In some case (i.e. Object Data, Modifier) the target objects must be of the same type
than the active one or capable of receiving the data.
The existing data-block of which will be unlinked from them.

Objects to Scene...
Lets you create links to the selected objects into a different scene than the current one.
A scene name must be chosen other than that of the current one.
The *Link Objects to Scene* Operator panel lets you choose between scenes.

This makes the same object exist in two different scenes at once,
including its position and animation data. The object's origin will change its color.
Type
Data-block type to link.

Object Data, Materials, Animation Data, Group, DupliGroup, Modifiers, Fonts

Transfer UV Maps
The active UV map of the selected objects will be replaced by a copy of the active UV map of the active object.
If the selected object doesn't have any UV maps, it is created.
Objects must be of type mesh and must have the same number of faces (matching geometry).

.. seealso::

:ref:`data-system-datablock-make-single-user` for unlinking data-blocks.

Make Local
==========

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Make Local...`
| Hotkey:   :kbd:`L`

Makes the selected or all external objects local in the current blend-file.
This makes e.g. the position editable, because its position is defined in its source file.

Type
Optionally unlinks the objects Object Data and Material Data.

Selected Objects, + Object Data, + Materials, All (i.e. including all scenes)

.. note::

Appending data you already have linked will add objects/groups to the scene,
but will keep them linked (and un-editable).

This is done so existing relationships with linked data remain intact.

.. hint::

Another way to transform a object locally is with the
use of :doc:`Dupli-Groups &lt;/editors/3dview/object/properties/duplication/dupligroup&gt;`.
Instead of linking to *Objects* directly, it is often more useful to link in *Groups*,
which can be assigned to empties and moved, while maintaining the link to the original file.

It is also useful to be able to add/remove objects from the group
without having to manage linking in multiple objects.

Known Limitations
=================

For the most part linking data will work as expected, however,
there are some corner-cases which are not supported.

Circular Dependencies
---------------------

In general, dependencies should not go in both directions.

Attempting to link or append data which links back to the current file will likely result in missing links.

Object Rigid-Body Constraints
-----------------------------

When linking objects *directly* into a blend-file, the *Rigid Body* settings
**will not** be linked in since they are associated with their scene's world.

As an alternative, you could link in the entire scene and set it as a :ref:`Background Set &lt;scene-background-set&gt;`.

#########
Scenes
#########

.. toctree::
:maxdepth: 2

introduction.rst
properties.rst

************
Introduction
************

Scenes are a way to organize your work.
Each blend-file can contain multiple scenes, which share other data such as objects and materials.

Scene management and library appending/linking are based on Blender's
:doc:`Library and Data System &lt;/data_system/index&gt;`,
so it is a good idea to read that manual page first, if you are not familiar with the basics of that system.

.. figure:: /images/data-system_scenes_introduction.png
:align: right

Scene data-block menu.

You can select and create scenes with the *Scene data-block* menu in the *Info Editor* header.

Controls
========

Scenes
A list of available scenes.
Add ``+``
New
Creates an empty scene with default values.
Copy Settings
Creates an empty scene, but also copies
the settings from the active scene into the new one.
Link Objects
This option creates a new scene with the same settings and contents as the active scene.
However, instead of copying the objects,
the new scene contains links to the objects in the old scene.
Therefore, changes to objects in the new scene will result in the same
changes to the original scene, because the objects used are literally the same.
The reverse is also true.
Link Object Data
Creates new, duplicate copies of all of the objects in the currently selected scene,
but each one of those duplicate objects will have links to the object-data (meshes, materials and so on)
of the corresponding objects in the original scene.

This means that you can change the position,
orientation and size of the objects in the new scene without affecting other scenes,
but any modifications to the object-data (meshes, materials, etc.) will also affect other scenes.
This is because a single instance of the "object-data" is now being shared by all of the objects
in all of the scenes, that link to it.
This has the effect of making a new independent copy of the object-data.
Full Copy
Using this option, nothing is shared.
This option creates a fully independent scene with copies of the active scene's contents.
Every object in the original scene is duplicated, and a duplicate,
private copy of its object-data is made as well.

.. note::

To choose between these options,
it is useful to understand the difference between *Object* and *Object Data*.
See :doc:`Duplication &lt;/editors/3dview/object/editing/duplication&gt;`.

The choices for adding a scene, therefore, determine just how much of this information will be
*copied from* the active scene to the new one, and how much will be *shared* (linked).

Delete ``X``
You can delete the current scene by clicking the *X* next to the name in the Info Editor.

.. seealso:: Linking to a Scene

You can :ref:`link &lt;data-system-linked-libraries-make-link&gt;` any object from one scene to another.

****************
Scene Properties
****************

Scene
=====

Camera
Used to select which camera is used as the active camera.

.. _scene-background-set:

Background
Allows you to use a scene as a background,
this is typically useful when you want to focus on animating the foreground for example,
without background elements getting in the way.

This scene can have its own animation, physics-simulations etc,
but you will have to select it from the *Scene* data-block menu, if you want to edit any of its contents.

.. tip::

This can also be used in combination with :ref:`Linking to a Scene &lt;data-system-linked-libraries-make-link&gt;`,
where one blend-file contains the environment, which can be re-used in many places.

Active Clip
Active movie clip for constraints and viewport drawing.

.. _data-scenes-props-units:

Units
=====

Length Presets
Common unit scales to use.
Length
None
Uses :term:`Blender Units`.
Metric, Imperial
Standard unit of measurement for lengths.
Angle
Standard unit for angular measurement.

Degrees, Radians

.. tip::

When you are using *Degrees*, the radian value is also displayed in the tooltip.

Unit Scale
Scale factor to use when converting between :term:`Blender Units` and *Metric*/*Imperial*.

.. tip::

Usually you will want to use the *Length* presets to change to scale factor,
as this does not require looking up values to use for conversion.

Separate Units
When *Metric* or *Imperial* display units as multiple values,
for example, "2.285m" will become "2m 28.5cm".

.. Normally we would avoid documenting long lists of values
however, this is not displayed anywhere else.

.. list-table:: Imperial Units
:header-rows: 1
:stub-columns: 1

* - Full Name
- Short Name(s)
- Scale of a Meter
* - thou
- ``mil``
- 0.0000254
* - inch
- ``"``, ``in``
- 0.0254
* - foot, feet
- ``'``, ``ft``
- 0.3048
* - yard
- ``yd``
- 0.9144
* - chain
- ``ch``
- 20.1168
* - furlong
- ``fur``
- 201.168
* - mile
- ``mi``, ``m``
- 1609.344

.. list-table:: Metric Units
:header-rows: 1
:stub-columns: 1

* - Full Name
- Short Name(s)
- Scale of a Meter
* - micrometer
- ``um``
- 0.000001
* - millimeter
- ``mm``
- 0.001
* - centimeter
- ``cm``
- 0.01
* - decimeter
- ``dm``
- 0.1
* - meter
- ``m``
- 1.0
* - dekameter
- ``dam``
- 10.0
* - hectometer
- ``hm``
- 100.0
* - kilometer
- ``km``
- 1000.0

Keying Sets
===========

See :doc:`/animation/keyframes/keying_sets`.

Color Management
================

Options to control how images appear on the screen.

For :ref:`Color Management settings &lt;render-post-color-management&gt;` for more information.

.. move to audio rendering?

.. _data-scenes-audio:

Audio
=====

Options to control global audio settings.

Volume
Volume for the scene.
Update Animation Cache
Updates the audio animation cache. This is useful if you start noticing artifact in the audio.

Distance Model
---------------------

Distance Model
TODO.

Speed
Speed of the sound for the Doppler effect calculations.
Doppler
Pitch factor for Doppler effect calculation.

Format
----------

Channels
TODO.
Mix Rate
TODO.

Gravity
=======

Options to control global gravity used for physic effects.

See the :doc:`Physics chapter &lt;/physics/gravity&gt;` for more information.

Rigid Body World
================

The *Rigid Body World* is a group of Rigid Body objects,
which holds settings that apply to all rigid bodies in this simulation.

See :doc:`Rigid Body World &lt;/physics/rigid_body/world&gt;` for more information.

.. todo move to render/settings - engine dependent

Simplify
========

Subdivision
Maximum number of *Viewport*/*Render* subdivisions to use for the
:doc:`Subdivision Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`

Child Particles
Percentage of :doc:`Child Particles &lt;/physics/particles/emitter/children&gt;`
to see in the *Viewport*/*Render*.

Use Camera Cull
Automatically culls objects based on the camera frustum.

Margin
Margin for the camera space culling.

*********
3D Cursor
*********

The 3D Cursor is simply a point in 3D space which can be used for a number of purposes.

Placement
=========

There are a few methods to position the 3D cursor.

Direct Placement with the Mouse
-------------------------------

.. figure:: /images/editors_3dview_3d-cursor_two-view-positioning.png
:align: center

Positioning the 3D cursor with two orthogonal views.

Using :kbd:`LMB` in the 3D View will place the 3D cursor directly under your mouse pointer.

For accuracy you should use two perpendicular orthogonal 3D Views, i.e.
any combination of top :kbd:`Numpad7`, front :kbd:`Numpad1` and side :kbd:`Numpad3`.
That way you can control the positioning along two axes in one view and determine depth in the second view.

To place the 3D Cursor on the surface of geometry,
enable *Cursor Depth* in the :doc:`User Preferences &lt;/preferences/interface&gt;`.

.. seealso::

The :doc:`Snap Menu &lt;/editors/3dview/object/editing/transform/control/snap&gt;`
which allows the cursor placement relative to scene objects.

3D Cursor panel
---------------

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Properties region --&gt; 3D Cursor`

.. figure:: /images/editors_3dview_3d-cursor_panel.png

The 3D Cursor panel of the Properties region.

The 3D cursor can also be positioned by editing the location coordinates values in
the *3D cursor* panel of the *Properties* region.

Usage
=====

The 3D Cursor is used as the origin for any added object, can be used and moved with the
:doc:`snap tool &lt;/editors/3dview/object/editing/transform/control/snap&gt;`, and is an option for
the :doc:`pivot point &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`.
.. _editors-3dview-index:

##########
3D View
##########

.. toctree::
:maxdepth: 2

introduction.rst
startup_scene.rst
modes.rst
navigate/index.rst
3d_cursor.rst
object/index.rst
properties/index.rst
.. _3dview-editor:

************
Introduction
************

The 3D View is used to interact with the 3D scene for a variety of purposes,
such as modeling, animation, texture painting, etc.

.. TODO expand, more general info

Header
======

The header contains various menus and controls based on the current
:doc:`mode &lt;/editors/3dview/modes&gt;`.

.. figure:: /images/editors_3dview_header.png

3D View header.

Menus
-----

View
This menu offers tools to :doc:`navigate &lt;/editors/3dview/navigate/index&gt;` in 3D space.
Select
Contains tools for :doc:`selecting &lt;/editors/3dview/object/selecting/index&gt;` objects.
Add
Gives a list of different :ref:`objects types &lt;objects-types&gt;` that can be added to a scene.
Object
This menu appears when in Object Mode.
it contains tools to edit :doc:`objects &lt;/editors/3dview/object/editing/transform/introduction&gt;`.
In edit mode, it will change to the appropriate menu with :doc:`editing tools &lt;/modeling/index&gt;`.

Controls
--------

Mode
The 3D view has :doc:`several modes &lt;/editors/3dview/modes&gt;`
used for editing different kinds of data:

- Object Mode
- Edit Mode
- Pose Mode
- Sculpt Mode
- Vertex Paint
- Weight Paint
- Texture Paint
- Particle Edit

Viewport Shading
Allows you to change the way objects are displayed in the viewport.
:doc:`Read more about the different shading modes &lt;/editors/3dview/properties/shading&gt;`
Pivot Point
Used to change the reference point (or :term:`pivot point`) used by many mesh manipulation tools.

:doc:`Read more about Pivot Points &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`
Transform Manipulator
These handy selectors allow you to rotate or move objects by grabbing
(clicking with your mouse) their controls and moving your mouse in the axis.

:doc:`Read more about Transform Manipulators &lt;/editors/3dview/object/editing/transform/control/manipulators&gt;`
Layer
The Layers Widget is documented in the :doc:`Layers page &lt;/editors/3dview/object/properties/relations/layers&gt;`.
Lock to Scene
By default, the "lock" button to the right of the layer buttons is enabled.
This means that in this view, the active layers and camera are those of the whole scene
(and those used at render time). Hence, all 3D Views locked this way will share the same
active layers and camera. When you change them in one view,
all locked others will immediately reflect these changes.

But if you disable this "lock" button, you then can specify different active layers and camera,
specific to this view. This might be useful if you do not want to have your working areas (views)
cluttered with the whole scene, and still have an ancillary complete view
(which is unlocked with e.g. all layers shown).
Or to have several views with different active cameras. Remember that you can use
:kbd:`Ctrl-Numpad0` to make the active object the active camera.

:doc:`Read more about Scenes &lt;/data_system/scenes/introduction&gt;`
Proportional Edit
:doc:`Proportional Edit &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`.
Snap
Controls the :doc:`snapping tools &lt;/editors/3dview/object/editing/transform/control/snap&gt;`
that help with transforming and modeling objects.
OpenGL Render
The Render Buttons render an OpenGL version of the 3D View.
See the :doc:`OpenGL Rendering &lt;/render/opengl&gt;` page for more information.

Tool Shelf
==========

The Tool shelf is a context-sensitive region containing tools depending on the current mode
(for example, modeling tools in *Edit Mode*, brush tools in *Sculpt Mode*...).

For more information on specific tools available, see:

- :doc:`Transformations &lt;/editors/3dview/object/editing/transform/index&gt;`
- :doc:`History &lt;/interface/undo_and_redo&gt;`
- :doc:`Creating Objects &lt;/modeling/meshes/editing/basics/adding&gt;`
- :doc:`Parents &lt;/editors/3dview/object/properties/relations/parents&gt;`
- :doc:`Groups &lt;/editors/3dview/object/properties/relations/groups&gt;`
- :ref:`animation-index`
- :ref:`rigid-body-index`
- :ref:`grease-pencil-index`
- :ref:`modeling-index`
- :ref:`painting-sculpting-index`
- :ref:`painting-vertex-index`
- :ref:`painting-weight-index`
- :ref:`painting-texture-index`

Properties Region
=================

The Properties Region contains properties of the active object and selected objects (such as their locations),
as well as properties of the editor itself:

- :doc:`Transform &lt;/editors/3dview/object/editing/transform/introduction&gt;`
- :doc:`Grease Pencil &lt;/interface/grease_pencil/introduction&gt;`
- :doc:`Display &amp; View Panels &lt;/editors/3dview/properties/panels&gt;`
- :doc:`Background Images &lt;/editors/3dview/properties/background_images&gt;`
- :doc:`Transform Orientations &lt;/editors/3dview/object/editing/transform/control/orientations&gt;`

************
Object Modes
************

.. _fig-view3d-mode-select:

.. figure:: /images/editors_3dview-mode.jpg
:align: right

The Mode select menu.

*Modes* are a Blender-level object-oriented feature,
which means that whole Blender application is always in a singular mode,
and that the available modes vary depending on the selected active object's type --
most of them only enable the default *Object Mode* (like cameras, lamps, etc.).
Each mode is designed to edit an aspect of the selected object.
See Tab. :ref:`tab-view3d-modes` below for details.

You set the current mode in the *Mode* selector of *3D View* header
(see Fig. :ref:`fig-view3d-mode-select`).

.. note::

You can only select objects in *Object Mode*.
In all others, the current object selection is "locked"
(except, to some extent, with an armature's *Pose Mode*).

Modes might affect many things in Blender:

- They can modify the panels and/or controls available in some Properties editor tabs.
- They can modify the behavior of the whole editor, like e.g.
the *UV/Image Editor* and *3D View*.
- They can modify the available header tools (menus and/or menu entries, as well as other controls...).
For example, in the *3D View* editor, the *Object* menu in *Object Mode* changes to a *Mesh* menu in
*Edit Mode* (with an active mesh object!), and a *Paint* menu in *Vertex Paint Mode*...

.. _tab-view3d-modes:

.. list-table:: Blender's Modes
:header-rows: 1
:class: valign
:widths: 10 25 15 50

* - Icon
- Name
- Shortcut
- Details
* - .. figure:: /images/icons_object-mode.png
:width: 35px
- *Object Mode*
- *None* [1]_
- The default mode, available for all object types,
as it is dedicated to *Object* data-block editing (e.g. position, rotation, size).
* - .. figure:: /images/icons_edit-mode.png
:width: 35px
- *Edit Mode*
- :kbd:`Tab` [1]_
- A mode available for all renderable object types,
as it is dedicated to their "shape" *Object Data* data-block editing
(e.g. vertices/edges/faces for meshes, control points for curves/surfaces, etc.)
* - .. figure:: /images/icons_sculpt-mode.png
:width: 35px
- *Sculpt Mode*
- *None* [1]_
- A mesh-only mode, that enables Blender's mesh 3D-sculpting tool.
* - .. figure:: /images/icons_vertex-paint.png
:width: 35px
- *Vertex Paint Mode*
- *None* [1]_
- A mesh-only mode, that allows you to set your mesh's vertices colors (i.e. to "paint" them).
* - .. figure:: /images/icons_texture-paint.png
:width: 35px
- *Texture Paint Mode*
- *None* [1]_
- A mesh-only mode, that allows you to paint your mesh's texture directly on the model, in the 3D Views.
* - .. figure:: /images/icons_weight-paint.png
:width: 35px
- *Weight Paint Mode*
- :kbd:`Ctrl-Tab` [2]_
- A mesh-only mode, dedicated to vertex group weighting.
* - .. figure:: /images/icons_particle-edit.png
:width: 35px
- *Particle Edit Mode*
- *None* [1]_
- A mesh-only mode, dedicated to particle systems, useful with editable systems (hair).
* - .. figure:: /images/icons_pose-mode.png
:width: 35px
- *Pose Mode*
- :kbd:`Ctrl-Tab` [2]_
- An armature only mode, dedicated to armature posing.
* - .. figure:: /images/icons_grease-pencil.png
:width: 35px
- Edit Strokes Mode
- :kbd:`D-Tab`.
- A Grease Pencil only mode, dedicated to editing Grease Pencil strokes.

.. [1] :kbd:`Tab` toggles *Edit Mode*.
.. [2] :kbd:`Ctrl-Tab` switches between the *Weight Paint Mode* (meshes)/*Pose Mode* (armatures) ,
and the other current one (by default, the *Object Mode*).
However, the same shortcut has other, internal meanings in some modes
(e.g. in *Sculpt Mode*, it is used to select the current brush)...

As you can see, using shortcuts to switch between modes can become quite tricky, especially with meshes.

.. note::

The cursor becomes a brush in:

- :ref:`painting-vertex-index` mode
- :ref:`painting-weight-index` mode
- :ref:`painting-texture-index` mode.

.. Todo add to chart

We will not go into any more detail on modes usages here, However,
most of them are tackled in the :doc:`modeling chapter &lt;/modeling/index&gt;`, as they are mainly related to this topic.
The *Particle Edit Mode* is discussed in the :doc:`particle section &lt;/physics/particles/mode&gt;`,
and the *Pose Mode* and *Edit Mode* for armatures, in the :doc:`rigging one &lt;/rigging/index&gt;`.

.. note::

If you are reading this manual and some button or menu option is referenced that does not appear on your screen,
it may be that you are not in the proper mode for that option to be valid.

********
Aligning
********

These options allow you to align and orient the view.

.. (todo) add negative/positive direction

Axes
====

Blender uses a right-angled "Cartesian" coordinate system with the Z axis pointing upwards.
*Left*/ *Right* corresponds to looking along the X axis,
*Front*/ *Back* along the Y axis, and
*Top*/ *Bottom* along the Z axis.

You can select the viewing direction for a 3D View with the *View* menu entries,
or by pressing the hotkeys. You can select the opposite directions if you hold
:kbd:`Ctrl` while using the same numpad shortcuts.

These operators change the view to be aligned with the specified global axes:

- Top :kbd:`Numpad7`
- Bottom :kbd:`Ctrl-Numpad7`
- Front :kbd:`Numpad1`
- Back :kbd:`Ctrl-Numpad1`
- Right :kbd:`Numpad3`
- Left :kbd:`Ctrl-Numpad3`

Align View Menu
===============

Align View to Active
The options in this menu align your view with specified local axes of the selected active object,
bone, or, in *Edit Mode* with the normal of the selected face.

Hold down :kbd:`Shift` while using the numpad to set the view axis.

Center Cursor and View All :kbd:`Shift-C`
Moves the cursor back to the origin and zooms in/out so that you can see everything in your scene.
Align Active Camera to View :kbd:`Ctrl-Alt-Numpad0`
Gives your active camera the current viewpoint.
Align Active Camera to Selected
Points the active camera toward the selected object; based on the direction of the current viewpoint.
View Selected :kbd:`NumpadPeriod`
Focuses view on currently selected object/s by centering them in the viewport,
and zooming in until they fill the screen.
Center View to Cursor :kbd:`Alt-Home`
Centers view to 3D-cursor.
View Lock to Active :kbd:`Shift-NumpadPeriod`
Centers view to the last selected active object, overriding other view alignment settings.
View Lock Clear :kbd:`Alt-NumpadPeriod`
Returns the view alignment to the view align settings before use of *View Lock to Active*.

View Menu
=========

View Selected
See above.

.. _3dview-view-all:

View All :kbd:`Home`
Frames all the objects in the scene, so they are visible in the viewport.

***********
Camera View
***********

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Camera`
| Menu:     :menuselection:`View --&gt; Camera --&gt; Active Camera`
| Hotkey:   :kbd:`Numpad0`

.. figure:: /images/editors_3dview_navigate_3d-view_camera-view.png

Demonstration of camera view.

The Camera view shows the current scene as seen from the currently active camera's view point.
It can be activated by pressing :kbd:`Numpad0`.
The Camera view can be used to virtually compose shots and preview how the scene will look when rendered.
The rendered image will contain everything within the dashed line.
In this view you can also set the *Render Border* which defines the portion of the 3D View to be rendered.

.. list-table:: Camera view provides a preview for the final rendered image.

* - .. figure:: /images/editors_3dview_navigate_camera-view_preview.png
:width: 335px

Camera view.

- .. figure:: /images/editors_3dview_navigate_camera-view_render.png
:width: 335px

Rendered image.

Camera Navigation
=================

There are several different ways to navigate and position the camera in your scene, some of them are explained below.

Zooming in and out is possible in this view, but to change the viewpoint,
you have to move or rotate the camera.

.. note::

Remember that the active "camera" might be any kind of object.
So these actions can be used, for example, to position and aim a lamp.

Move Active Camera to View
--------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Hotkey:   :kbd:`Ctrl-Alt-Numpad0`

This feature allows you to position and orient the active camera to match your current viewport.

Select a camera and then move around in the 3D View to a desired position and direction for
your camera (so that you are seeing what you want the camera to see). Now press
:kbd:`Ctrl-Alt-Numpad0` and your selected camera positions itself to match the view,
and switches to camera view.

Camera View Positioning
-----------------------

By enabling :ref:`Lock Camera to View &lt;3dview-lock-camera-to-view&gt;` in the View panel of the Properties region,
while in camera view, you can navigate the 3D View as usual,
while remaining in camera view. Controls are exactly the same as when normally moving in 3D.

Roll, Pan, Dolly, and Track
---------------------------

To perform these camera moves, the camera must first be *selected*,
so that it becomes the active object (while viewing through it,
you can :kbd:`RMB` -- click on the solid rectangular edges to select it).
The following actions also assume that you are in camera view :kbd:`Numpad0`!
Having done so, you can now manipulate the camera using the same tools
that are used to manipulate any object:

Roll
Press :kbd:`R` to enter object rotation mode. The default will be to rotate the camera in its local Z-axis
(the axis orthogonal to the camera view), which is the definition of a camera "roll".
Vertical Pan or Pitch
This is just a rotation along the local X-axis. Press :kbd:`R` to enter object rotation mode, then :kbd:`X` twice
(the first press selects the *global* axis, pressing the same letter a second time selects the *local* axis --
this works with any axis;
see the :doc:`axis locking page &lt;/editors/3dview/object/editing/transform/control/precision/axis_locking&gt;`).
Horizontal Pan or Yaw
This corresponds to a rotation around the camera's local Y axis.
Press :kbd:`R`, and then :kbd:`Y` twice.
Dolly
To dolly the camera, press :kbd:`G` then :kbd:`MMB` (or :kbd:`Z` twice).
Sideways Tracking
Press :kbd:`G` and move the mouse (you can use :kbd:`X` twice or :kbd:`Y`
to get pure-horizontal or pure-vertical sideways tracking).

.. seealso::

:ref:`Fly/Walk Mode &lt;3dview-walk-fly&gt;`
When you are in walk/fly mode, navigation actually moves your camera:
:ref:`Lock Camera to View &lt;3dview-lock-camera-to-view&gt;`
When enabled, performing typical view manipulation operations will move the camera object.

********
Clipping
********

.. _3dview-clip-border:

View Clipping Border
====================

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Set Clipping Border`
| Hotkey:   :kbd:`Alt-B`

Allows you to define a clipping border to limit the 3D View display to a portion of 3D space.
It can assist in the process of working with complex models and scenes.

Once activated with :kbd:`Alt-B`, you have to draw a rectangle with the mouse,
in the wanted 3D View. It becomes a clipping volume of four planes:

- A right-angled `parallelepiped &lt;https://en.wikipedia.org/wiki/Parallelepiped&gt;`__
(of infinite length) if your view is orthographic.
- A rectangular-based pyramid (of infinite height) if your view is in perspective.

Once clipping is used, you will only see whats inside a volume you have defined.
Tools such as paint, sculpt, selection, transform-snapping, etc.
will also ignore geometry outside the clipping bounds.

To delete this clipping, press :kbd:`Alt-B` again.

Example
-------

.. list-table:: Region/Volume clipping.

* - .. figure:: /images/editors_3dview_navigate_3d-view_clipping-border-1.png
:width: 320px

Selecting a region.

- .. figure:: /images/editors_3dview_navigate_3d-view_clipping-border-2.png
:width: 320px

Region selected.

- .. figure:: /images/editors_3dview_navigate_3d-view_clipping-border-3.png
:width: 320px

View rotated.

The *Region/Volume clipping* image shows an example of using the clipping tool with a cube.
Start by activating the tool with :kbd:`Alt-B` (upper left of the image).
This will generate a dashed cross-hair cursor.
Click with the :kbd:`LMB` and drag out a rectangular region shown in the upper right.
Now a region is defined and clipping is applied against that region in 3D space.
Notice that part of the cube is now invisible or clipped. Use the :kbd:`MMB` to rotate
the view and you will see that only what is inside the pyramidal volume is visible.
All the editing tools still function as normal but only within the pyramidal clipping volume.

The dark gray area is the clipping volume itself.
Once clipping is deactivated with another :kbd:`Alt-B`,
all of 3D space will become visible again.

Render Border
=============

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Render Border...`
| Hotkey:   :kbd:`Ctrl-B`, :kbd:`Ctrl-Alt-B`

Rectangular camera space clipping in and outside the Camera view.
ToDo.

.. seealso::

:ref:`3dview-nav-zoom-border`.

.. (todo?) Remove redundant info for the 'View Clipping Border' functionality.
Split the page and separate 'Render Border' and create text for this usage context.

#############
Navigating
#############

.. toctree::
:maxdepth: 2

introduction.rst
navigation.rst
walk_fly.rst
align.rst
projections.rst
clip.rst
views.rst
camera_view.rst
.. (todo) move orbit, pan, zoom?

************
Introduction
************

View Menu
=========

The view menu is located in the header of the 3D View.
The list below includes all menu entries discussed in *other* sections of the manual.

Show all Layers
Makes all :doc:`layers &lt;/editors/3dview/object/properties/relations/layers&gt;` visible.
Play Back Animation
Plays back the :doc:`animation &lt;/animation/index&gt;` from the current frame.
Duplicate Area in New Window
Clones the current :doc:`area &lt;/interface/window_system/areas&gt;` (3D View) in a new window.
Toggle Maximized Area
Maximizes the :doc:`area &lt;/interface/window_system/areas&gt;` (3D View).
Toggle Fullscreen Area
Maximizes the :doc:`area &lt;/interface/window_system/areas&gt;` (3D View)  to fill the full screen area.

**********
Navigation
**********

Navigating in the 3D space is done with the use of both mouse movement and keyboard shortcuts.

To be able to work in the three dimensional space that Blender uses,
you must be able to change your viewpoint as well as the viewing direction of the scene.
While we will describe the *3D View* editor, most of the other editors have similar functions.
For example, it is possible to translate and zoom in the UV/Image editor.

.. tip:: Mouse Buttons and Numpad

If you have a mouse with less than three buttons or a keyboard without numpad,
see the :doc:`Keyboard and Mouse &lt;/getting_started/installing/configuration/hardware&gt;`
page of the manual to learn how to use them with Blender.

Orbit
=====

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Navigation --&gt; Orbit`
| Hotkey:   :kbd:`MMB`, :kbd:`Numpad2`, :kbd:`Numpad4`, :kbd:`Numpad6`,
:kbd:`Numpad8`, :kbd:`Ctrl-Alt-Wheel`

Rotate the view around the point of interest.
Click and drag :kbd:`MMB` on the viewport's area.
If you start in the middle of the area and move up and down or left and right,
the view is rotated around the middle of the area.

To change the viewing angle in discrete steps, use :kbd:`Numpad8` and :kbd:`Numpad2`
(which correspond to vertical :kbd:`MMB` dragging, from any viewpoint),
or use :kbd:`Numpad4` and :kbd:`Numpad6` (or :kbd:`Ctrl-Alt-Wheel`)
to rotate the scene around the global Z axis from your current point of view.
Finally :kbd:`Numpad9` switches to the opposite side of the view.

Alternatively, if the *Emulate 3 button mouse* option is select in the *User Preferences*
you can press and hold :kbd:`Alt` while dragging :kbd:`LMB` in the viewport's area.

.. note:: Hotkeys

Remember that most hotkeys affect the **active** area (the one that has focus),
so check that the mouse cursor is in the area you want to work in before your use the hotkeys.

.. seealso::

- :ref:`Orbit Style Preference &lt;prefs-input-orbit-style&gt;`
- :ref:`Auto-Perspective Preference &lt;prefs-interface-auto-perspective&gt;`

Roll
====

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Navigation --&gt; Roll`
| Hotkey:   :kbd:`Shift-Numpad4`, :kbd:`Shift-Numpad6`, :kbd:`Ctrl-Shift-Wheel`

Rotate the viewport camera around its local Z axis in 15° discrete steps.

Panning
=======

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Navigation --&gt; Pan`
| Hotkey:   :kbd:`Shift-MMB` , :kbd:`Ctrl-Numpad2`, :kbd:`Ctrl-Numpad4`,
:kbd:`Ctrl-Numpad6`, :kbd:`Ctrl-Numpad8`

Moves the view up, down, left and right.
To pan the view, hold down :kbd:`Shift` and drag :kbd:`MMB` in the 3D View.
For discrete steps, use the hotkeys :kbd:`Ctrl-Numpad8`, :kbd:`Ctrl-Numpad2`,
:kbd:`Ctrl-Numpad4` and :kbd:`Ctrl-Numpad6` as with orbiting
(note: you can replace :kbd:`Ctrl` by :kbd:`Shift`).

For those without a middle mouse button,
you can hold :kbd:`Shift-Alt` while dragging with :kbd:`LMB`.

Zooming
=======

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Navigation --&gt; Zoom`
| Hotkey:   :kbd:`Ctrl-MMB`, :kbd:`Wheel`, :kbd:`NumpadPlus`, :kbd:`NumpadMinus`

Moves the camera forwards and backwards.
You can zoom in and out by holding down :kbd:`Ctrl` and dragging :kbd:`MMB`.
The hotkeys are :kbd:`NumpadPlus` and :kbd:`NumpadMinus`.
The :menuselection:`View --&gt; Navigation` sub-menu holds these functions too as well.
Refer to the 3D View's *View* menu image above for more information.
If you have a wheel mouse, you can zoom by rotating the :kbd:`Wheel`.

.. hint:: If You Get Lost

If you get lost in 3D space, which is not uncommon, two hotkeys will help you:
:kbd:`Home` changes the view so that you can see all objects :menuselection:`View --&gt; View All`,
while :kbd:`NumpadPeriod` zooms the view to the currently selected objects when in perspective mode
:menuselection:`View --&gt; View Selected`.

.. _3dview-nav-zoom-border:

Zoom Border
-----------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Zoom Border`
| Hotkey:   :kbd:`Shift-B`

The *Zoom Border* tool allows you to specify a rectangular region and zoom in so
that the region fills the 3D View.

You can access this through the *View* menu, or the shortcut :kbd:`Shift-B`,
then :kbd:`LMB` click and drag a rectangle to zoom into.

Alternatively you can zoom out using the :kbd:`MMB`.

.. _3dview-nav-zoom-dolly:

Dolly Zoom
----------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Hotkey:   :kbd:`Ctrl-Shift-MMB`

In most cases its sufficient to zoom the view to get a closer look at something,
however, you may notice that at a certain point you cannot zoom any closer.

This is because Blender stores a view-point thats used for orbiting and zooming.
It works well in many cases, but sometimes you want to move the view-point to a different place.
This is what Dolly supports, allowing you to transport the view from one place to another.

You can dolly back and fourth by holding down :kbd:`Ctrl-Shift` and dragging
:kbd:`MMB`.
.. _3dview-projections:

***********
Projections
***********

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; View Perspective/Orthographic`
| Hotkey:   :kbd:`Numpad5`

These operators change the projection of the viewport camera.
Each 3D View supports two different types of projection.
These are demonstrated in the Fig. below.

.. list-table::

* - .. figure:: /images/editors_3dview_navigate_3d-view_view-orthographic.png
:width: 320px

Orthographic projections.

- .. figure:: /images/editors_3dview_navigate_3d-view_view-perspective.png
:width: 320px

Perspective projections.

Our eye is used to perspective viewing because distant objects appear smaller.
Orthographic projection often seems a bit odd at first,
because objects stay the same size regardless of their distance.
It is like viewing the scene from an infinitely distant point.
Nevertheless, orthographic viewing is very useful
(it is the default in Blender and most other 3D applications),
because it provides a more "technical" insight into the scene,
making it easier to draw and judge proportions.

Options
=======

To change the projection for a 3D View, choose the :menuselection:`View --&gt; Orthographic`
or the :menuselection:`View --&gt; Perspective` menu entry.
The :kbd:`Numpad5` shortcut toggles between the two modes.
Changing the projection for a 3D View does not affect the way the scene will be rendered.
Rendering is in perspective by default. If you need to create an orthographic rendering,
select the camera, go to the Camera tab and press the
*Orthographic* button in the *Lens* panel.

.. seealso::

- :ref:`Render perspectives &lt;camera-lens-type&gt;`
- :term:`Camera Projections &lt;projection&gt;`
.. (todo) rename

*****
Views
*****

.. _3dview-local-view:

View Global/Local
=================

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; View Global/Local`
| Hotkey:   :kbd:`NumpadSlash`

Global view shows all of the 3D objects in the scene.
Local view isolates the selected object or objects,
so that they are the only ones visible in the viewport.
This is useful for working on objects that are obscured by other ones, or
to speed up viewport performance in heavy scenes.

You can toggle between *Global* and *Local View* by selecting the option
from the *View Menu* or using the shortcut :kbd:`NumpadSlash`.

.. list-table::

* - .. figure:: /images/editors_3dview_navigate_3d-view_local-view-1.png
:width: 320px

Global View.

- .. figure:: /images/editors_3dview_navigate_3d-view_local-view-2.png
:width: 320px

Local View.

.. note::

These notes cover changes in local-view which are not immediately obvious.

3D Cursor
In local-view the 3D cursor is not locked to the scene.
Instead, each view has an independent cursor location.
Layers
Local-view bypasses layers, using only the selected objects when entering local-view.
Although new objects may be added while in local-view.

Its also possible to send objects out of local view,
using :menuselection:`Object --&gt; Move Objects out of Local View`,
which can be useful to further isolate a selection.
Preview Renders
Preview renders will still use lamps outside the local-view,
this allows you to quickly render previews
without having to remember to select all lamps when entering local-view.

.. tip::

Accidentally pressing :kbd:`NumpadSlash` can happen rather often if you are new to Blender,
so if a bunch of the objects in your scene seem to have mysteriously vanished, try turning off local view.

Quad View
=========

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Toggle Quad View`
| Panel     :menuselection:`Properties region --&gt; Display --&gt; Toggle Quad View`
| Hotkey:   :kbd:`Ctrl-Alt-Q`

Toggling Quad View will split the 3D View into four views:
Three *Orthographic* "side views" and one *Camera*/*User View*.
This view will allow you to instantly see your model from a number of view points.
In this arrangement, you can zoom and pan each view independently but you cannot rotate the view.

.. rubric:: Shortcuts for all views at once:

- View All :kbd:`Ctrl-Home`
- View Selected :kbd:`Ctrl-NumpadPeriod`

.. note::

Quad View is different from :doc:`splitting the area &lt;/interface/window_system/areas&gt;`
and aligning the view manually. In Quad View, the four views are still part of a single 3D View.
So they share the same draw options and layers.

.. figure:: /images/editors_3dview_navigate_3d-view_quad-view.png

Quad View.

Options
-------

These options can be found in :menuselection:`Properties region --&gt; Display`.

Lock
If you want to be able to rotate each view, you can un-check the *Locked* option.
Box
Syncs view position between side views.
Clip
Clip objects based on what is visible in other side views.
.. _3dview-walk-fly:

*************
Walk/Fly Mode
*************

When you have to place the view, normally you do as described above.

However, there are cases in which you really prefer to just navigate your model,
especially if it is very large, like environments or some architectural model.
In these cases viewing the model in perspective mode has limitations,
for example after zooming a lot of panning is extremely uncomfortable and difficult,
or you apparently cannot move the camera any nearer. As an example,
try to navigate to a very distant object in the view with traditional methods
(explained above) and see what you can get.

With walk/fly modes you move, pan, tilt, and dolly the camera around without any of those limitations.

.. figure:: /images/editors_3dview_navigate_3d-view_walk-fly-mode.png

View Navigation.

In the :doc:`User Preferences editor &lt;/preferences/index&gt;`
select the navigation mode you want to use as default when invoking the View Navigation operator.
Alternatively you can call the individual modes from the View Navigation menu.

.. note::

This mode actually *moves* the camera used by the view.
This means that when you are in camera view,
it moves the active camera, which is another way to place and aim it.

Walk Mode
---------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; View Navigation --&gt; Walk Navigation`
| Hotkey:   :kbd:`Shift-F`

On activation the mouse pointer will move at the center of the view,
and a cross marker will appear...

This navigation mode behaves similar to the first person navigation system available in most 3D world games nowadays.
It works with a combination of keyboard keys :kbd:`W`, :kbd:`A`, :kbd:`S`, :kbd:`D` and mouse movement.
By default the navigation is in the "free" mode, with no gravity influence.
You can toggle between gravity and free mode during the navigation :kbd:`Tab`.

To move to places more quickly you can teleport :kbd:`Spacebar` around your scene.
If there is an object in front of the walk cross/aim you will move in that direction until you reach the point
(offset by the *camera height* value set in the :doc:`User Preferences &lt;/preferences/index&gt;`).

Shortcuts
^^^^^^^^^

- Move the mouse left/right to pan the view left/right or move it up/down to tilt the view up/down.
- Move the camera forward/backward :kbd:`W`, :kbd:`S`.
- Strafe left/right :kbd:`A`, :kbd:`D`.
- Jump :kbd:`V` - only in *gravity* mode.
- Move up and down :kbd:`Q`, :kbd:`E` - only in *free* mode.
- Alternate between *free* and *gravity* modes :kbd:`Tab`.
- Change the movement speed:
- :kbd:`WheelUp` or :kbd:`NumpadPlus` to increase the movement speed for this open session.
- :kbd:`WheelDown` or to :kbd:`NumpadMinus` to decrease the movement speed for this open session.
- :kbd:`Shift` (hold) - to speed up the movement temporarily.
- :kbd:`Alt` (hold) - to slow down the movement temporarily.

When you are happy with the new view, click :kbd:`LMB` to confirm.
In case you want to go back from where you started, press :kbd:`Esc` or :kbd:`RMB`, as usual.

If the defaults values (speed, mouse sensitivity, ...) need adjustments for your project,
in the :doc:`User Preferences &lt;/preferences/index&gt;` you can select a few options for the navigation system:

Fly Mode
--------

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; View Navigation --&gt; Fly Navigation`
| Hotkey:   :kbd:`Shift-F`

On activation the mouse pointer will move at the center of the view,
and a squared marker will appear – a sort of HUD...

Some of the options of Fly mode are influenced by the position of the
mouse pointer relative to the center of the view itself,
and the squared marker around this center provides a sort of
"safe region" where you can place the mouse for it to have no effect on the view.
The more you take the mouse pointer away from the marker, the more you pan, or track, etc.

Shortcuts
^^^^^^^^^

- Move the mouse left/right to pan the view left/right or move it up/down to tilt the view up/down.
- Move the view forward/backward:
- :kbd:`WheelUp` or :kbd:`NumpadPlus` to accelerate the movement forward.
- :kbd:`WheelDown` or to :kbd:`NumpadMinus` to accelerate the movement backward.

So if the view is already moving forward,
:kbd:`WheelDown`, :kbd:`NumpadMinus` will eventually stop it and then move it backward, etc.
- Drag the :kbd:`MMB` to dolly.
In this case the view can move laterally on its local axis at the moment you drag the mouse – quite obviously,
dragging left/right/up/down makes the view dolly on the left/right/up/down respectively.

When you are happy with the new view, click :kbd:`LMB` to confirm.
In case you want to go back from where you started, press :kbd:`Esc` or :kbd:`RMB`, as usual.

***********
Duplication
***********

There are two types of object duplication,
being `Duplicate`_ and `Linked Duplicates`_ which instance their Object Data.

Duplicate
=========

.. admonition:: Reference
:class: refbox

| Mode:     Edit and Object Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Edit --&gt; Duplicate`
| Menu:     :menuselection:`Object --&gt; Duplicate Objects`
| Hotkey:   :kbd:`Shift-D`

This will create a visually-identical copy of the selected object(s).
The copy is created at the same position as the original object and
you are automatically placed in *Grab* mode. See the examples below.

This copy is a new object, which shares some data-blocks with the original object
(by default, all the Materials, Textures, and F-Curves), but which has copied others,
like the mesh, for example. This is why this form of duplication is sometimes called "shallow link",
because not all data-blocks are shared; some of them are "hard copied"!

.. tip::

You can choose which types of data-block will be linked or copied when duplicating:
in the :ref:`User Preferences &lt;prefs-editing-duplicate-data&gt;`.

Examples
--------

.. figure:: /images/modeling-duplicate-example.png

The mesh ``Cone.006`` of object ``Cone.002`` is being edited.
The mesh's Unique data-block ID name is highlighted in the Outliner.

The cone in the middle has been (1) link duplicated to the left and (2) duplicated to the right.

- The duplicated right cone is being edited, the original cone in the middle remains unchanged.
The mesh data has been copied, not linked.
- Likewise, if the right cone is edited in object mode, the original cone remains unchanged.
The new object's transform properties or data-block is a copy, not linked.
- When the right cone was duplicated, it inherited the material of the middle cone.
The material properties were linked, not copied.

See above if you want separate copies of the data-blocks normally linked.

Linked Duplicates
=================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Edit --&gt; Duplicate Linked`
| Menu:     :menuselection:`Object --&gt; Duplicate Linked`
| Hotkey:   :kbd:`Alt-D`

You also have the choice of creating a *Linked Duplicate* rather than a *Duplicate*;
this is called a deep link.
This will create a new object with **all** of its data linked to the original object.
If you modify one of the linked objects in *Edit Mode*,
all linked copies are modified. Transform properties (object data-blocks) still remain copies,
not links, so you still can rotate, scale, and move freely without affecting the other copies.
Reference Expl. :ref:`Duplicate Example &lt;expl-object-link-duplicate&gt;` for the discussions below.

Linked
In the *Duplicate Objects* Operator panel the *Linked* checkbox is checked unlike with *Duplicate*.

.. hint::

If you want to make changes to an object in the new linked duplicate independently of the original object,
you will have to manually make the object a "single-user" copy by :kbd:`LMB`
the number in the *Object Data* panel of the Properties editor. (See :ref:`ui-data-block`.)

.. seealso::

:ref:`data-system-datablock-make-single-user` for unlinking data-blocks.

.. _expl-object-link-duplicate:

Examples
--------

.. figure:: /images/modeling-duplicate-linked-example.png

The object ``Cone.001`` was linked duplicated.
Though both these cones are separate objects with unique names,
the single mesh named Cone, highlighted in the Outliner, is shared by both.

The left cone is a *Linked Duplicate* of the middle cone (using :kbd:`Alt-D`).

- As a vertex is moved in *Edit Mode* in one object, the same vertex is moved in the original cone as well.
The mesh data are links, not copies.
- In contrast, if one of these two cones is rotated or rescaled in object mode, the other remains unchanged.
The transform properties are copied, not linked.
- As in the previous example, the newly created cone has inherited the material of the original cone.
The material properties are linked, not copied.

A common table has a top and four legs. Model one leg,
and then make linked duplicates three times for each of the remaining legs.
If you later make a change to the mesh, all the legs will still match.
Linked duplicates also apply to a set of drinking glasses,
wheels on a car... anywhere there is repetition or symmetry.

.. seealso:: Linked Library Duplication

:doc:`Linked Libraries &lt;/data_system/linked_libraries&gt;` are also a form of duplication.
Any object or data-block in other blend-files can be reused in the current file.

.. hint::

If you want transform properties (i.e. object data-blocks) to be "linked",
see the page on :doc:`parenting &lt;/editors/3dview/object/properties/relations/parents&gt;`.

##########
Editing
##########

.. toctree::
:maxdepth: 2

introduction.rst
transform/index.rst
duplication.rst

************
Introduction
************

In this section will be described tools for manipulating objects in Object Mode.
All editing tools can be found in Object menu and/or in Tools Shelf.

Delete
======

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Edit --&gt; Delete`
| Menu:     :menuselection:`Object --&gt; Delete`
| Hotkey:   :kbd:`X`

The selected objects are deleted from the scene.

Delete Globally :kbd:`Shift-X`
This checkbox in the Operator panel will cause the objects to be deleted from all the scenes where they are linked.

.. _object-show-hide:

Show/Hide
=========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Object --&gt; Show/Hide`

Show Hidden :kbd:`Alt-H`
Reveals all hidden objects.
Hide Selected :kbd:`H`
Hides all selected objects.
Hide Unselected :kbd:`Shift-H`
Hides all unselected objects of the scene.
The *Unselected* checkbox in the *Set Restrict View*/*Hide Selected* Operator panel will be checked.

.. _object-convert-to:

Convert To
==========

Curve to Mesh/Text
------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Convert to --&gt; Curve From Mesh/Text`
| Hotkey:   :kbd:`Alt-C`

Mesh objects and text objects can be converted into curve objects.
In mesh objects, only edges belonging to no faces will be taken into account.
The resulting curve will be a Poly curve type,
but can be converted to have smooth segments as described in :ref:`curve-convert-type`.

Mesh to Curve/Metaball/Surface/Text
-----------------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Convert to --&gt; Mesh From Curve/Metaball/Surface/Text`
| Hotkey:   :kbd:`Alt-C`

Converts the selected curve, metaball, surface and text objects to mesh objects.
The actual defined resolution of these objects will be taken into account for the conversion.
Note that it also keeps the faces and volumes created by closed and extruded curves.

Options
-------

Keep Original
Duplicates the original object before converting it.

.. _object-join:

Join
====

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Edit --&gt; Join`
| Menu:     :menuselection:`Object --&gt; Join`
| Hotkey:   :kbd:`Ctrl-J`

Join merges all selected objects into the last selected *Active* object.
All object data is linked to the active object (which must be selected).
All objects must be of the same type: mesh, curve, surface or armature.
If several curves are joined, each one will keep its subtype (NURBS or Bezier).

.. note::

Object data has many attributes which may be handled when joining.

Materials, vertex-groups, UV and Vertex layers will be merged.

Modifiers, constraints, groups and parent relationships
are ignored when joining and will not be applied to the active object.

*********************
Basic Transformations
*********************

Grab/Move
=========

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode, Edit Mode, and Pose Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Transform --&gt; Translate`
| Menu:     :menuselection:`Object type --&gt; Transform --&gt; Grab/Move`
| Hotkey:   :kbd:`G`

In Object Mode, the grab/move option lets you translate (move) objects.
Translation means changing location of objects.
It also lets you translate any elements that make up the object within the 3D space of the active 3D View.

Grab/Move works similarly here as it does
in the Node Editor, Graph Editor, UV/Image Editor, Sequencer, etc.

Pressing :kbd:`G` activates "Grab/Move" transformation mode.
The selected object or element then moves freely according to the mouse pointer's location and camera.

You can also move an object by clicking and holding :kbd:`RMB` on the object to move it.
To confirm the action, press :kbd:`LMB`.

While Grab/Move is active, the amount of change in the X, Y,
and Z coordinates is displayed at the bottom left corner of the 3D View editor.

.. figure:: /images/editors_3dview_transform_basics_grab_display-values.png

Translation Display.

.. tip::

Moving an object in Object Mode changes the object's origin.
Moving the object's vertices/edges/faces in Edit Mode does not change the object's origin.

Rotate
======

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Transform --&gt; Rotate`
| Menu:     :menuselection:`Object/Mesh/Curve/Surface --&gt; Transform --&gt; Rotate`
| Hotkey:   :kbd:`R`

Rotation is also known as a spin, twist, orbit, pivot, revolve,
or roll and involves changing the orientation of elements (vertices, edge, face, Object etc)
around one or more axes or
the :doc:`Pivot Point &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`.

The angle of rotation will be displayed in the footer of the 3D View editor.

.. figure:: /images/editors_3dview_transform_basics_rotate_display-values.png

Rotation values.

.. _view3d-transform-trackball:

Trackball Rotation
------------------

A free rotation mode. Press :kbd:`R`, :kbd:`R` to enable Trackball rotation.

Scale
=====

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Transform --&gt; Scale`
| Menu:     :menuselection:`Object/Mesh/Curve/Surface --&gt; Transform --&gt; Scale`
| Hotkey:   :kbd:`S`

Scaling means changing proportions of objects.
Pressing :kbd:`S` will enter the *Scale* transformation mode where the
selected element is scaled inward or outward according to the mouse pointer's location. The
element's scale will increase as the mouse pointer is moved away from the Pivot Point and
decrease as the pointer is moved towards it. If the mouse pointer crosses from the original side of the
:doc:`Pivot Point &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;` to the opposite side,
the scale will continue in the negative direction and flip the element.

.. figure:: /images/editors_3dview_object_transform_basics_scale_basic-usage.png

Basic scale usage. From left to right, the panels show: the original Object,
a scaled down Object, a scaled up Object and a scale-flipped Object.

The amount of scaling will be displayed in the footer of the 3D View editor.

.. figure:: /images/editors_3dview_transform_basics_scale_display-values.png

Scale values.

Common Options
===============

There are multiple ways to transform an element which include:

- The keyboard shortcut.
- The menu in the header or the Transform panel in the Tool Shelf.
- The :doc:`3D Transform Manipulator &lt;/editors/3dview/object/editing/transform/control/manipulators&gt;`
widget.
- The :doc:`Transform panel &lt;/editors/3dview/object/properties/transforms&gt;`
in the Properties region or the Object tab.

Confirm and Cancel
------------------

:kbd:`LMB` click to accept changes.
This behavior can be changed globally by activating  *Release Confirms*
in the :doc:`User Preferences &lt;/preferences/editing&gt;`,
so that a single :kbd:`RMB` drag can be used to move and confirm.

To cancel the transformation press :kbd:`RMB` or :kbd:`Esc` instead.
This will reset the object or element to its original state.

.. seealso::

Using combination of shortcuts gives you more control over your transformation.
See :doc:`Transform Control &lt;/editors/3dview/object/editing/transform/control/index&gt;`.

Operator Panel
--------------

In the case of the 3D View, there is the possibility to tweak the operation once accepted,
using the specific Operator panel corresponding to the tool.

Value
The amount of the transformation.

Vector, Angle
Constrain Axis
Used to constraint the transformation to one or more axes.

X, Y, Z
Orientation
Shows the :doc:`Orientations &lt;/editors/3dview/object/editing/transform/control/orientations&gt;`
of the constraint axes.
Proportional Editing, Falloff, Size
Activates/deactivates *Proportional Editing* and configures the type *Falloff* and
*Size* of the :doc:`/editors/3dview/object/editing/transform/control/proportional_edit` tool.
Edit Grease Pencil
ToDo.
Edit Texture Space
This checkbox lets you apply the transformation on the :ref:`Texture Space &lt;properties-texture-space&gt;`,
instead of the object or element itself. Only available in translation and scale.
Confirm on Release
Shows if either the operation was drag-and-release or move-and-confirm.

Workflow
--------

Using Keyboard Shortcuts
^^^^^^^^^^^^^^^^^^^^^^^^

#. Use :kbd:`RMB` to select the elements you want to transform.
#. Tap :kbd:`G`, or :kbd:`R`, or :kbd:`S` once to enter the transformation mode.
#. Transform the elements by moving the mouse.
#. :kbd:`LMB` click to accept changes.

Texture Space
=============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Menu:     :menuselection:`Object --&gt; Transform`
| Hotkey:   :kbd:`Shift-T`, :kbd:`Shift-Alt-T`

Transforms the object :ref:`Texture Space &lt;properties-texture-space&gt;`,
which will become visible in the 3D View.
Same as if the *Edit Texture Space* checkbox is enabled.

- Move Texture Space :kbd:`Shift-T`
- Scale Texture Space :kbd:`Shift-Alt-T`

*************
Clear &amp; Apply
*************

Clear
=====

Clearing transforms simply resets the transform values.
The objects location and rotation values return to 0, and the scale returns to 1.

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Clear --&gt; Clear Location/Clear Scale/Clear Rotation/Clear Origin`
| Hotkey:   :kbd:`Alt-G`, :kbd:`Alt-S`, :kbd:`Alt-R`, :kbd:`Alt-O`

Options
-------

.. figure:: /images/editors_3dview_transform-control_object-transformations-clear-transformations.png

Clear Transformation menu.

Clear Location :kbd:`Alt-G`
Clear (reset) the location of the selection.
This will move the selection back to the coordinates (0, 0, 0).
Clear Scale :kbd:`Alt-S`
Clear (reset) the scale of the selection.
This will resize the selection back to the size it was when created.
Clear Rotation :kbd:`Alt-R`
Clear (reset) the rotation of the selection.
This will set the rotation of the selection to 0 degrees in each plane.
Clear Origin :kbd:`Alt-O`
Clears (resets) the offset of the child objects origin.
This will cause child objects to move to the origin of the parent.

Apply
=====

These operations lets you apply several transformations to the selected objects.
The object transformation coordinates are transferred to the object data.
If the objects have hierarchical descendants, it also applies those transformations to their children.

Apply Object Transformations
----------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Apply --&gt;`
| Hotkey:   :kbd:`Ctrl-A`

Applying transform values essentially resets the values of object's position, rotation,
or scale, but does not actually do anything to the object.
The object origin point is moved to the global origin and the transform values are set to zero.
In terms of scale, the scale values return to 1.

To apply a transform select the *Apply* sub-menu from the *Object menu* or
use the shortcut :kbd:`Ctrl-A` and select the appropriate transform to apply.
The Operator panel lets you choose the combination of transformations to apply.

.. warning:: Armature Objects

While applying transformation to armatures is supported,
this does **not** apply to their pose position, animation curves or constraints.

This tool should be used before rigging and animation.

Options
^^^^^^^

.. figure:: /images/editors_3dview_transform-control_object-transformations-apply-transformations.png

Apply Transformation menu.

Location
Apply (set) the location of the selection.
This will make Blender consider the current location to be equivalent to 0 in each plane
i.e. the selection will not move, the current location will be considered to be the "default location".
The Object origin will be set to actual (0, 0, 0) (where the colored axis lines intersect in each view).
Rotation
Apply (set) the rotation of the selection.
This will make Blender consider the current rotation to be equivalent to 0 degrees in each plane
i.e. the selection will not rotated, the current rotation will be considered to be the "default rotation".
Scale
Apply (set) the scale of the selection.
This will make Blender consider the current scale to be equivalent to 0 in each plane
i.e. the selection will not scaled, the current scale will be considered to be the "default scale".
Rotation and Scale
Apply (set) the rotation and scale of the selection. Do the above two applications simultaneously.

Transforms to Deltas
--------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Apply --&gt;`
| Hotkey:   :kbd:`Alt-Shift-G`, :kbd:`Alt-Shift-R`, and :kbd:`Alt-Shift-S`

Clear both the normal and :ref:`Delta transforms &lt;transform-delta&gt;`.

- Location to Deltas :kbd:`Alt-Shift-G`
- Rotation to Deltas :kbd:`Alt-Shift-R`
- Scale to Deltas :kbd:`Alt-Shift-S`

All Transforms to Deltas
Converts all "normal" transformations to delta transforms.
Reset Values
ToDo.
Animated Transform to Deltas
Converts the "normal" transformation animations (animations done to the translation,
scale, and rotation values) to Delta transforms.
To use this tool simply select the object with the animations that you want to convert press :kbd:`Ctrl-A`
and select *Animated Transform to Deltas*.

Visual Transform
----------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Apply --&gt; Visual Transform`
| Hotkey:   :kbd:`Ctrl-A`

Apply (set) the result of a constraint and apply this back to the Object's location, rotation and scale.

Visual Geometry as Mesh
-----------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Apply --&gt; Visual Geometry as Mesh`
| Hotkey:   :kbd:`Ctrl-A`

Apply the visual state of all selected objects (modifiers, shape keys, hooks... etc) to object data.

This is a way to freeze all object data into static meshes, as well as converts non-mesh types to mesh.

Make Duplicate Real
-------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Apply --&gt; Make Duplicate Real`
| Hotkey:   :kbd:`Shift-Ctrl-A`

*Make Duplicates Real* unlinks linked duplicates so each duplicate now has its own data-block.

Parent
Parents all the generated objects to the former duplicator when the option is checked;
otherwise, they will be global objects.
Keep Hierarchy
If this option is checked, the internal hierarchies (i.e. parent relationships)
will be preserved in the newly generated objects,
even if *Parent* is also checked, in which case, only the duplicated objects on top of the hierarchy
will be parented to the former duplicator.

####################
Transform Control
####################

Transform controls can be used to modify and control the effects of the available transformations.

.. toctree::
:maxdepth: 2

precision/index.rst
manipulators.rst
proportional_edit.rst
orientations.rst
snap.rst
pivot_point/index.rst
.. |manip-menu| image:: /images/editors_3dview_transform_control_manipulators_header.png

***************************
Transformation Manipulators
***************************

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Menu:     |manip-menu|
| Hotkey:   :kbd:`Ctrl-Spacebar`

The Transformation manipulator widgets allow mouse controlled translation, rotation and scaling in the 3D View.
There is a separate manipulator for each operation.
Each manipulator can be used separately or in combination with the others.

.. figure:: /images/editors_3dview_transform_control-manipulators-manipulator_options.png

The different Manipulators.

Header Controls
===============

Manipulators can be accessed through the header of the *3D View*.

Axis
Enable/disable the manipulators :kbd:`Ctrl-Spacebar`.
Manipulators
Toggles each of the manipulators. Clicking with :kbd:`Shift-LMB` on multiple manipulator icons
will combine the manipulators.

Arrow
Translation.
Arc
Rotation.
Box
Scale.
Transform Orientation
A select menu of the
:doc:`Transform Orientations &lt;/editors/3dview/object/editing/transform/control/orientations&gt;`.

Manipulator Controls
====================

Basic
-----

You can use the widget by dragging :kbd:`LMB` one of the three colored axes.
The transformation will be locked to the clicked axis.

Dragging the small white circle allows free transformation.
In case of the rotation manipulator this starts a :ref:`trackball rotation &lt;view3d-transform-trackball&gt;`.
The rotation manipulator contains another big outer white circle to activate free transformation.

Releasing the mouse confirms the operation (*confirm on release*).

Extended
--------

The operations work in same way as described in
:doc:`precision control &lt;/editors/3dview/object/editing/transform/control/precision/index&gt;` except:

Holding down :kbd:`Shift` *after* you :kbd:`LMB`
the manipulator handle will constrain the action to smaller increments.
Holding down :kbd:`Shift` *before* you :kbd:`LMB` click on one of the handles will cause the manipulator action
to be performed relative to the other two axes. See :ref:`view3d-transform-plane-lock`.

.. seealso::

The :ref:`Manipulator Preferences &lt;prefs-interface-manipulator&gt;`.

.. TODO/Review: {{review|Need to change and explain the behavior of the transform orientation.
It is toggled between the chosen orientation and the
global orientation when transformations are made by shortcuts}}.

**********************
Transform Orientations
**********************

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Panel:    :menuselection:`Properties region --&gt; Transform Orientations`
| Hotkey:   :kbd:`Alt-Spacebar`

Orientations affect the behavior of Transformations: Location, Rotation, and Scale.
You will see an effect on the 3D Manipulator (the widget in the center of the selection),
as well as on transformation constraints
(like :doc:`axis locking &lt;/editors/3dview/object/editing/transform/control/precision/axis_locking&gt;`).
This means that, when you press :kbd:`G-X`, it will constrain to the *global* X-axis,
but if you press :kbd:`G-X-X` it will constrain to your *Transform Orientation* s X-axis.

.. figure:: /images/editors_3dview_object_transform-control_transform-orientations_menu.png

Transform Orientations selector.

The Orientations options can be set through the *Orientation* selector in a 3D View header,
with :kbd:`Alt-Spacebar`, or in the Transform Orientations panel in the Properties region.

Transform Orientations
In addition to the four preset options,
you can define your own custom orientation (see `Custom Orientations`_ below).

Orientations
============

Global
The manipulator matches the global axis.

When using the Global orientation, the orientation's XYZ matches world's XYZ axis.
When this mode is selected,
the local coordinates of the object are subjected to the Global coordinates.
This is good to place objects in the scene. To constrain an axis,
press :kbd:`G` and the desired axis. To constrain to a local axis,
press the desired axis two times. The difference between Global and Local, is more noticeable
when you have an object in which the origin is not located at the exact center of the object,
and does not match the Global coordinates.

Local
The manipulator matches the object axis.

Notice that, here, the Manipulator is at a slight tilt
(it is most visible on the object's Y-axis, the green arrow).
This is due to our 15° rotation of the object.
This demonstrates the difference between local coordinates and global coordinates.
If we had rotated the object 90° along its X-axis, we would see that the object's "Up" is the
world's "Forward" -- or the object's Z-axis would now be the world's Y-axis.
This orientation has an effect on many parts of the interface,
so it is important to understand the distinction.

Normal
The Z-axis of the manipulator will match the normal vector of the selection.

In Object Mode, this is equivalent to Local Orientation, in Edit Mode,
it becomes more interesting.

As you see, the light blue lines indicate the faces' normals,
and the darker blue lines indicate the vertex normals (these were turned on in the
:kbd:`N` Properties region under :menuselection:`Mesh Display --&gt; Normals --&gt; Face` and
*Vertex*).
Selecting any given face will cause our Manipulator's Z-axis to align with that normal.
The same goes for Vertex Select Mode.
Edge Select is different -- A selected Edge has the Z-axis aligned with it
(so you will have to look at the Manipulator widget to determine the direction of X and Y).
If you select several elements, it will orient towards the average of those normals.

A great example of how this is useful is in Vertex Select Mode: Pick a vertex and then do
:kbd:`G, Z, Z` to tug it away from the mesh and shove it into the mesh.
To make this even more useful, select a nearby vertex and press :kbd:`Shift-R` to repeat
the same movement -- except along that second vertex's normal instead.

Gimbal
Uses a :term:`Gimbal` behavior that can be changed
depending on the current :ref:`Rotation Mode &lt;rotation-modes&gt;`.

View
The manipulator will match the 3D View:

- Y: Up/Down
- X: Left/Right
- Z: Towards/Away from the screen.

This way you can constrain movement to one View axis with :kbd:`G-X-X`.

Custom Orientations
-------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Panel:    :menuselection:`Properties region --&gt; Transform Orientations`
| Hotkey:   :kbd:`Ctrl-Alt-Spacebar`

.. figure:: /images/editors_3dview_object_transform-control_transform-orientations_custom.png

Custom orientation.

You can define custom transform orientations, using object or mesh elements. Custom transform
orientations defined from objects use the local orientation of the object whereas those
defined from selected mesh elements (vertices, edges, faces)
use the normal orientation of the selection.

The *Transform Orientations* panel, found in the Properties region,
can be used to manage transform orientations: selecting the active orientation,
adding and deleting custom orientations.

.. figure:: /images/orientations-custom-name.png
:width: 300px

Renaming a Custom Orientation.

The default name for these orientations comes from whatever you have selected.
If an edge, it will be titled, "Edge," if an object,
it will take that object's name, etc.

Create Orientation
^^^^^^^^^^^^^^^^^^

Just after creating the orientation, the Create Orientation Operator panel gives a few options:

Name
Text field for naming the new orientation.
Use View
The new orientation will be aligned to the view space.
Use after creation
If checked it leaves the newly created orientation active.
Overwrite previous
If the new orientation is given an existing name, a suffix will be added to it to avoid overwriting the old one,
unless *Overwrite previous* is checked, in which case it will be overwritten.

Workflow
^^^^^^^^

.. _fig-view3d-transform-orientation-extrusion:

.. figure:: /images/orientations-custom-extrusion.png

Custom Extrusion.

The technique of creating custom orientations can become important in creating precise meshes.
In Fig. :ref:`fig-view3d-transform-orientation-extrusion`, to achieve this effect:

#. Select the object's sloping top edge
#. Create a Custom Orientation with :kbd:`Ctrl-Alt-Spacebar` and rename it "Top Edge".
#. Select the objects's bottom, right edge.
#. Extrude with :kbd:`E`.
#. Cancel the extrusion's default movement by pressing :kbd:`RMB` or :kbd:`Esc`.
#. Hit :kbd:`G` to reinitiate movement.
#. Hit :kbd:`Z-Z` to constrain to the "Top Edge" orientation.

Align to Transform Orientation
==============================

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Menu:     :menuselection:`Object --&gt; Transform --&gt; Align to Transform Orientation`

Aligns (rotates) the selected objects so that their local orientation matches the active transform orientation
in the Transform orientation panel or the *Orientation* selection in the Transform Operator panels.

Examples
========

Demo Cube
---------

.. figure:: /images/orientations-basicsetup.png

To demonstrate the various behaviors, we add some colors to the default cube,
rotate it -15° along its local Z- and X Axes, and we scale its "y" face down.

Please note two things:

- The "Mini-axis" in the lower-left corner, which represents the Global X, Y, Z orientation.
- The :doc:`"Object Manipulator" &lt;/editors/3dview/object/editing/transform/control/manipulators&gt;`
widget emanating from the selection, which represents the current Transform Orientation.

- If you click on one of the axes of the Manipulator with :kbd:`LMB`,
it will allow you to constrain movement to only this direction.
An example of a keyboard equivalent is :kbd:`G, Z, Z`.
- If you :kbd:`Shift-LMB` click,
it will lock the axis you clicked on and allow you to move in the plane of the two remaining axes.
The keyboard analogue is :kbd:`G, Shift-Z, Shift-Z`.

Effect on Manipulators
----------------------

The image below shows a cube with the rotation manipulator active in multiple transform orientations.
Notice how the manipulator changes depending on the orientation selected (compare A with F).

Similarly, notice how when normal orientation (F and G)
is selected the manipulator changes between *Object Mode* and *Edit Mode*.
The normal orientation manipulator will also change depending on what is selected in
*Edit Mode* i.e. the orientation is based on the normal of the selection which will
change depending on how many and which faces, edges or vertices are selected.

.. figure:: /images/editors_3dview_transform_control-manipulators-manipulator_orientation_options.png

Transform manipulator orientation options.

A) Standard cube in default top view with *global* orientation selected
B) Standard cube with view rotated and *global* orientation selected
C) Randomly rotated cube with view rotated and *global* orientation selected
D) Randomly rotated cube with *local* orientation selected
E) Randomly rotated cube with *gimbal* orientation selected
F) Randomly rotated cube with *normal* orientation selected
G) Randomly rotated cube, vertices selected with *normal* orientation selected
H) Randomly rotated cube with *view* orientation selected
.. |pivot-icon| image:: /images/editors_3dview_object_transform-control_pivot-point.png

*********
3D Cursor
*********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Header:   |pivot-icon| :menuselection:`Pivot Point --&gt; 3D Cursor`
| Hotkey:   :kbd:`Period`

The 3D cursor is the most intuitive of the pivot points.
With the 3D cursor selected as the active pivot point
(from either the *Editors Header* or via :kbd:`Period`),
simply position the 3D cursor and then do the required transformation. All rotation and
scaling transformations will now be done relative to the location of the 3D cursor.

Example
=======

The image below shows the difference when rotating an Object
around the median point (left) and around the 3D cursor (right).

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_3d-cursor_example.png

Rotation around the 3D cursor compared to the median point.
.. |pivot-icon| image:: /images/editors_3dview_object_transform-control_pivot-point.png

**************
Active Element
**************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Header:   |pivot-icon| :menuselection:`Pivot Point --&gt; Active Element`
| Hotkey:   :kbd:`Alt-Period`

The *active* element can be an Object, vertex, edge or a face. The active element is the
last one to be selected and will be shown in a lighter orange color when in *Object Mode*
and white when in *Edit Mode*. With *Active element as Pivot* set to active,
all transformations will occur relative to the active element.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_active-element_object-mode-display.png

Display of active elements in Object Mode where the active element (cube) is a lighter orange.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_active-element_edit-mode-display.png

Active elements for vertices, edges and faces in Edit Mode are displayed in white.

In Object Mode
==============

When in *Object Mode*,
rotation and scaling happen around the active Object's origin.
This is shown by the figure to the below where the active Object (the cube)
remains in the same location (note its position relative to the 3D cursor)
while the other Objects rotate and scale in relation to the active element.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_active-element_object-mode-rotation.png

Rotation and scaling with the cube as the active element.

In Edit Mode
============

Using the active element as a pivot point in *Edit Mode* may seem complex but all
the possible transformations follow a few rules:

- The pivot point is always at the median of the active element(s).
- The transformations occur by transformation of the *vertices* of the selected element(s).
If an unselected element shares one or more vertices with a selected element
then the unselected one will get some degree of transformation also.

Let us examine the following examples: in each case we will see that the two rules apply.

Single selection
----------------

When one single element is selected it becomes automatically active. In the image below,
you can see that when it is transformed its vertices move, with the consequence that any
adjacent element which shares one or more vertices with the active element is also
transformed.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_active-element_edit-mode-single.png

Edit Mode and only one element selected.

Let us review each case:

- *Faces* have their pivot point where their selection dot appears, which is where the median of their vertices is.
- *Edges* have their pivot point on their middle since this is always where the median of an edge is.
- A single *Vertex* has no dimensions at all so it cannot show any transformation
(except translation, which is not affected by the pivot point).

Multiple selection
------------------

When multiple elements are selected they all transform.
The pivot points stay in the same place as what we have seen above,
with only one exception for Fgons. In the image below,
the selected elements have been rotated.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_active-element_edit-mode-multiple.png

Edit Mode and multiple selections.

- For *Faces* the transformation occurs around the selection dot of the active face.
- *Edges* also keep the same behavior with their pivot point at their median.
- There is a case for *Vertices* this time: the active Vertex is where the pivot point resides.
All other vertices are transformed relative to it.
.. |pivot-icon| image:: /images/editors_3dview_object_transform-control_pivot-point.png

*******************
Bounding Box Center
*******************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Header:   |pivot-icon| :menuselection:`Pivot Point --&gt; Bounding Box Center`
| Hotkey:   :kbd:`Comma`

The bounding box is a rectangular box that is wrapped as tightly as possible around the selection.
It is oriented parallel to the world axes. In this mode the pivot point lies at the center of the bounding box.
You can set the pivot point to bounding box with :kbd:`Comma` or via the menu in the editors header.
The image below shows how the Object's Bounding Box size is determined by the size of the Object.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_bounding-box-center_demo.png

Relationship between an Object and its Bounding Box.

In Object Mode
==============

In *Object Mode*, the bounding box is wrapped around the Object and transformation
takes place relative to the location of the Object origin (indicated by the yellow circle).
The image below shows the results of using the Bounding Box as the pivot point in a number of
situations.

For example, images A (before rotation)
and B show rotation when the Object origin is in its default position, while images C
(before rotation) and D shows the result when the Object origin has been moved.
Image E shows that when multiple Objects are selected,
the pivot point is calculated based on the Bounding Box of all the selected Objects.

.. figure:: /images/editors_3dview_transform_control-pivot_point-bounding_box_center-object-rotation.jpg

The grid of four images on the left (ABCD) shows the results of Object rotation
when the pivot point is set to Bounding Box.
The image to the right (E) shows the location of the Bounding Box pivot point when multiple Objects are selected.
The pivot point is shown by a yellow circle.

In Edit Mode
============

This time it is the Object Data that is enclosed in the bounding box.
The bounding box in *Edit Mode* takes no account of the Object(s) origins,
only the center of the selected vertices.

.. figure:: /images/editors_3dview_transform_control-pivot_point-bounding_box_center-edit-mode-rotation.jpg

The effects of rotation in different mesh selection modes when the bounding box is set as the pivot point.
The pivot point is shown by a yellow circle.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_bounding-box-center_median-point.png

The bounding box center compared to the median point.
.. _pivot-point-index:

##############
Pivot Point
##############

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Header:   Pivot Point

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_modes.png
:align: right

Pivot Point modes.

When rotating or scaling an object or group of vertices/edges/faces,
you may want to shift the :term:`pivot point` to make it easier to manipulate an object.
Using this selector in the header of any 3D View, you can change the location of the pivot point.

.. toctree::
:maxdepth: 2

active_element.rst
median_point.rst
individual_origins.rst
3d_cursor.rst
bounding_box_center.rst
manipulate_center_points.rst
.. TODO. Wrong description in the section "In Edit Mode".
Whether the last example image is informative?

.. |pivot-icon| image:: /images/editors_3dview_object_transform-control_pivot-point.png

******************
Individual Origins
******************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Header:   |pivot-icon| :menuselection:`Pivot Point --&gt; Individual Origins`
| Hotkey:   :kbd:`Ctrl-Period`

In Object Mode
==============

.. figure:: /images/editors_3dview_transform-control_pivot-point_individual-origins-rotation-around-center.png

Rotation around individual origins.

The Origin of an object is shown in the 3D View by a small orange circle.
This is highlighted in the image to the right by the red arrow.
It tells Blender the relative position of that object in 3D space.
What you see in the 3D View (vertices, edges etc) is what makes up the object.

The origin does not have to be located in the center of the geometry (e.g. mesh).
This means that an object can have its origin located on one end of the mesh or
even completely outside the mesh. For example,
the orange rectangle in the image has its Origin located on the far left of the mesh.

Now let us examine: Rotation around the individual origins:

- The blue rectangle has its Origin located in the center of the mesh,
while the orange rectangle has its Origin located on the left hand side.
- When the Pivot Point is set to *Individual Origins*,
the origin of each object (indicated by the red arrow)
remains in place while the object rotates around it in the path shown by the black arrow.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_individual-origins_objects-rotate.png

Rotation around individual origins (middle) compared to the median point (right).

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_individual-origins_objects-scale.png

Scaling around individual origins (middle) compared to the median point (right).

In Edit Mode
============

In Edit Mode, setting the Pivot Point to Individual Origins produces different results when
the selection mode is set to Vertex, Edge or Face. For example, Vertex mode produces results
similar to setting the pivot point to median and Edge mode often produces distorted results.
Using Individual Origins in Face mode produces the most predictable results.

.. list-table::

* - .. figure:: /images/editors_3dview_transform-control_pivot-point_individual-origins-rotation-faces.png
:width: 320px

Rotation of individual faces with the pivot point indicated by the image text.

- .. figure:: /images/editors_3dview_transform-control_pivot-point_individual-origins-rotation-grouped-faces.jpg
:width: 320px

Rotation of grouped faces with the pivot point indicated by the image text.

As can be seen in the images above, faces that touch each other will deform when rotated when
the pivot point is set to Individual Origins.
Faces that do not touch will rotate around their Individual Origins (their center).

.. list-table::

* - .. figure:: /images/editors_3dview_transform-control_pivot-point_individual-origins-scale-individual-faces.png
:width: 320px

Scaling with non-touching faces.

- .. figure:: /images/editors_3dview_transform-control_pivot-point_individual-origins-scale-group-fgon-faces.png
:width: 320px

Scaling with touching faces.

Groups of faces and Fgons can be scaled without their outside perimeter being deformed.
However, the individual faces inside will not be scaled uniformly.

.. figure:: /images/editors_3dview_transform-control_pivot-point_individual-origins-anemone-example.jpg
:width: 300px

Modeling with faces and individual origins as the pivot point.

Once you are aware of its limitations and pitfalls,
this tool can save a lot of time and lead to unique shapes. This "anemone" was modeled from a
12 sided cylinder in about 10 minutes by repeatedly using this workflow:
extrusions of individual faces, scaling with *median as a pivot point*,
and scaling and rotations of those faces with *Individual Origins as pivot points*.
.. |pivot-icon| image:: /images/editors_3dview_object_transform-control_pivot-point.png

************************
Manipulate Center Points
************************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Pose Mode
| Header:   |pivot-icon| Manipulate Center Points
| Hotkey:   :kbd:`Alt-Comma`

When this option is enabled, the transformation
will change the positions of the object’s origins,
but will not affect the object itself.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_manipulate-center-points_button.png

Manipulate Center Points button.

In the examples below,
a comparison of the scaling and rotation of objects,
when *Manipulate Center Points* is enabled (middle) and disabled (right).

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_manipulate-center-points_rotate.png

Rotation example.

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_manipulate-center-points_scale.png

Scaling example.
.. |pivot-icon| image:: /images/editors_3dview_object_transform-control_pivot-point.png

************
Median Point
************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Header:   |pivot-icon| :menuselection:`Pivot Point --&gt; Median Point`
| Hotkey:   :kbd:`Ctrl-Comma`

The Median Point can be considered to be broadly similar to the concept of
Center of Gravity (COG). If we assume that every element (Object, face, vertex etc)
of the selection has the same mass,
the median point would sit at the point of equilibrium for the selection (the COG).

In Object Mode
==============

In Object Mode, Blender only considers the Object origins when determining the median point.
This can lead to some counterintuitive results. In the Fig. :ref:`fig-view3d-median-point-object-mode` below,
you can see that the median point is between the Object origins and can be nowhere near the
Objects' mesh (geometric center).

.. _fig-view3d-median-point-object-mode:

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_median-point_object-mode.png

Median points in Object Mode.

In Edit Mode
============

In Edit Mode,
the median point is determined via the part of the selection that has the most elements.
For example, in the Fig. :ref:`fig-view3d-median-point-edit-mode`,
when there are two cubes with an equal number of vertices,
the median point lies directly between the two cubes. However,
if we subdivide one cube multiple times so that it has many more vertices,
you can see that the median point has shifted to the region with the most vertices.

.. _fig-view3d-median-point-edit-mode:

.. figure:: /images/editors_3dview_object_transform-control_pivot-point_median-point_edit-mode.png

Median points in Edit Mode.

************
Axis Locking
************

.. figure:: /images/editors_3dview_transform_control-axis_locking-axis-locking.png
:width: 150px
:align: right

Axis locking.

This option limits the transformation to the specified axis.

:doc:`Transformations (translation/scale/rotation) &lt;/editors/3dview/object/editing/transform/introduction&gt;`
in *Object Mode* and *Edit Mode*, as well as extrusion in *Edit Mode*)
can be locked to particular axis relative to the current
:doc:`transform orientation &lt;/editors/3dview/object/editing/transform/control/orientations&gt;`.
By locking a transformation to a particular axis you are restricting transformations to a single dimension.

Usage
=====

A locked axis will display in a brighter color than an unlocked axis. For example in the image to the right,
the Z axis is drawn in light blue as movement is constrained to this axis. This example, can be achieved in two ways:

Hotkey
------

The axis of movement can be changed at any time during transformation by typing :kbd:`X`, :kbd:`Y`, :kbd:`Z`.

Pointing
--------

.. figure:: /images/editors_3dview_trans_basics_grab_mmb.jpg

Axis-Constraint in action.

Holding :kbd:`MMB` after starting a transformation lets you select an axis to constrain to.
A visual option to constrain the translation will be available,
showing the three axes in the 3D View space. A dotted white line is used as a pointer.
The axis of choice to confirm the operation
will depend on the highlighted axis about which the :kbd:`MMB` is released.

When you already moved the mouse in the desired direction,
pressing :kbd:`MMB` will lock to the axis in which was pointed at.

Axis locking types
==================

Axis locking
------------

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes (translate, rotate, scale, extrude)
| Hotkey:   :kbd:`X`, :kbd:`Y`, :kbd:`Z` or :kbd:`MMB` after moving the mouse in the desired direction.

Axis locking limits the transformation to a single axis (or forbids transformations along two axes).
An object, face, vertex or other selectable item will only be able to move,
scale or rotate in a single dimension.

.. _view3d-transform-plane-lock:

Plane locking
-------------

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes (translate, scale)
| Hotkey:   :kbd:`Shift-X`, :kbd:`Shift-Y`, :kbd:`Shift-Z` or :kbd:`Shift-MMB`
after moving the mouse in the desired direction.

.. figure:: /images/editors_3dview_transform_control-axis_locking-plane-locking.png
:width: 150px
:align: right

Plane locking.

Plane locking locks the transformation to *two* axes
(or forbids transformations along one axis),
thus creating a plane in which the element can be moved or scaled freely.
Plane locking only affects translation and scaling.

Note that for rotation, both axis and plane locking have the same effect because a rotation is
always constrained around one axis.
*Trackball* type rotations :kbd:`R-R` cannot be locked at all.

Axis locking modes
------------------

.. figure:: /images/editors_3dview_transform_control-axis_locking-locking-modes.png
:width: 340px

Axis locking modes.

A and B show Z axis locking in *Global* and *Normal* orientations respectively.
C and D show the same situation with face selection,
E and F with edge selection and G and H with vertex selection.

A single key press constrains movement to the corresponding *Global* axis. A second
key press of the *same* key constrains movement to the current transform orientation
selection (except if it is set to *Global*,
in which case the *Local* orientation is used). Finally,
a third key press of the same key removes constraints.

The orientation can be set
in the :doc:`Transform Orientation &lt;/editors/3dview/object/editing/transform/control/orientations&gt;`
selector of the 3D View header.

.. or independent in the Operator panel?

For example, if the current transform orientation is set to *Normal*,
pressing :kbd:`G` to start translation, followed by :kbd:`Z` will lock translation
in the Z direction relative to the *Global* orientation, pressing :kbd:`Z`
again will lock translation to the Z axis relative to the *Normal* orientation.
Pressing :kbd:`Z` again will remove all constraints.
The current mode will be displayed in the left hand side of the *3D View header*.

As can be seen in the *Axis locking modes* image,
the direction of the transform also takes into account the selection.

Note that using a locked axis does not prevent you from using the keyboard to enter
:doc:`numeric transformation &lt;/editors/3dview/object/editing/transform/control/precision/numeric_input&gt;` values.

############
Precision
############

.. toctree::
:maxdepth: 2

introduction.rst
numeric_input.rst
axis_locking.rst

************
Introduction
************

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Hotkey:   :kbd:`Ctrl` and/or :kbd:`Shift`

Holding :kbd:`Ctrl` during a transform operation (such as grab, rotate or scale)
will toggle :ref:`Transform Snapping &lt;transform-snap&gt;`.
When the :ref:`Snap Element &lt;transform-snap-element&gt;` is set to *Increment*,
this allows the transformation to be performed in discrete amounts.

Holding :kbd:`Shift` during a transform operation will transform the object at 1/10th the speed,
allowing much finer control.

The magnitude of the transformation can be viewed in the 3D View header in the bottom left hand corner.
Releasing :kbd:`Ctrl` or :kbd:`Shift` during the transformation will cause the movement
to revert back to its normal mode of operation.

Holding both :kbd:`Ctrl-Shift` enables precise snap.
This option will move the object with high precision along with the snapping constraint.

.. note::

The snapping behaviors described on this page **only** apply when :ref:`Increment Snap &lt;transform-snap-element&gt;`
is selected.

Usage
=====

With hotkeys
------------

Press :kbd:`G`, :kbd:`R` or :kbd:`S` and then hold either :kbd:`Ctrl`,
:kbd:`Shift` or :kbd:`Ctrl-Shift`.

With the Transform Manipulator
------------------------------

Hold :kbd:`Ctrl`, :kbd:`Shift` or :kbd:`Ctrl-Shift` and click on the appropriate manipulator handle.
Then move the mouse in the desired direction. The reverse action will also work i.e.
clicking the manipulator handle and then holding the shortcut key for precision control.

.. seealso::

:doc:`Read more about the Transform Manipulator &lt;/editors/3dview/object/editing/transform/control/manipulators&gt;`

.. tip:: Combining with other controls

All of the precision controls detailed on the page can be combined with the
:doc:`Axis Locking &lt;/editors/3dview/object/editing/transform/control/precision/axis_locking&gt;`
controls and used with the different
:doc:`Pivot Points &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`.

Snapping
========

Grab/move
---------

.. figure:: /images/editors_3dview_transform_control_precision_blender-units.png
:align: right

1 Blender Unit (default zoom level).

For grab/move operations at the default zoom level,
holding :kbd:`Ctrl` will cause your selection to move by increments of 1 Blender Unit
(1 BU) (i.e. between the two light gray lines). Zooming in enough to see the next set of gray
lines will now cause :kbd:`Ctrl` movements to occur by 1/10 of a BU. Zooming in further
until the next set of gray lines becomes visible will cause movement to happen by 1/100 of a
BU and so on until the zoom limit is reached.
Zooming out will have the opposite effect and cause movement to happen by increments of 10,
100 etc BU.

.. seealso::

:doc:`Read more about Zooming &lt;/editors/3dview/navigate/introduction&gt;`

Rotation
--------

Holding :kbd:`Ctrl` will cause rotations of 5 degrees.

Scale
-----

Holding :kbd:`Ctrl` will cause size changes in increments of 0.1 BU.

.. note:: Snapping modes

Note that if you have a
:ref:`Snap Element &lt;transform-snap-element&gt;` option enabled,
holding :kbd:`Ctrl` will cause the selection to snap to the nearest element.

:doc:`Read more about Snapping &lt;/editors/3dview/object/editing/transform/control/snap&gt;`

Precision
=========

Holding :kbd:`Shift` during transformations allows for very fine control that does not
rely on fixed increments. Rather, large movements of the mouse across the screen only result
in small transformations of the selection.

In rotation mode the selected element will be rotate in 0.01 degree increments.

Precision Snapping
==================

Grab/move
---------

For grab/move operations at the default zoom level, holding :kbd:`Ctrl-Shift` will cause
your selection to move by increments of 1/10 Blender Units. Holding :kbd:`Ctrl-Shift` at
any zoom level will cause the transformation increments to always be 1/10 of the increment if
you were only holding :kbd:`Ctrl`.

Rotation
--------

Holding :kbd:`Ctrl-Shift` will cause rotations of 1 degree.

Scale transformations
---------------------

Holding :kbd:`Ctrl-Shift` will cause size changes in 0.01 BU increments.

*************
Numeric Input
*************

.. figure:: /images/editors_3dview_transform_control-numeric_input_numeric-input-header.png

Numeric input displayed in the 3D View footer.

Using the mouse for transformations is convenient,
but if you require more precise control, you can also enter numeric values.
After pressing the shortcut type a number to indicate the magnitude of the transformation.
Then confirm or chancel. e.g. pressing :kbd:`S 2`, :kbd:`Enter` will double the scale of an object.

Translate :kbd:`G`
By default and with no other key presses, the translation will occur along the X-axis.
Rotation :kbd:`R`
The rotation is in clockwise direction for positive values.
Scale :kbd:`S`
Scaling works in almost identical fashion to translation.
The primary difference is that by default, scaling applies equally to all three axes.

You can see the numbers you enter in the 3D View's footer.

.. tip::

Numeric input can also be inputed in the
:doc:`Properties &lt;/editors/3dview/object/properties/transforms&gt;` region.

Simple Mode
===========

Blender has two "modes" a simple and an advanced one.
Simple mode only accepts simple numbers.
You can use basic :ref:`text editing &lt;ui-text-editing&gt;` except selection.

Decimals :kbd:`Period`
Decimals can be entered by pressing :kbd:`Period`.
Negate :kbd:`Minus`
Negate the whole value by pressing :kbd:`Minus`.
Inverse :kbd:`Slash`
Hitting :kbd:`Slash` during number entry switches the number being entered to its reciprocal,
e.g. :kbd:`2 /` results in 0.5 (1/2); :kbd:`2/0` results in 0.05 (1/20).
Reset :kbd:`Backspace`
Hitting :kbd:`Backspace` after having deleted all leading chars will first reset
the edited value to initial state, and on second press, the whole number editing will be canceled,
going back to usual transform with mouse.
Next/previous Component :kbd:`Tab`, :kbd:`Ctrl-Tab`
To enter numeric values for multiple axes, use :kbd:`Tab` or :kbd:`Ctrl-Tab`.
e.g. To move an object, one Blender unit on all three axes press:
:kbd:`G 1` and :kbd:`Tab 1` and :kbd:`Tab 1`.

Non-number Inputs
You can also combine numeric input with
:doc:`Axis Locking &lt;/editors/3dview/object/editing/transform/control/precision/axis_locking&gt;`
to limit movement to a particular axis or tool specific shortcuts.

Advanced Mode
=============

In advanced mode you can additionally enter expressions and units.

Use :kbd:`=` or :kbd:`NumpadAsterix` to enable advanced mode, and
:kbd:`Ctrl-=` or :kbd:`Ctrl-NumpadAsterix` to switch back to simple mode.

It features:

- Units (cm, ", deg, etc.).
- Basic operations from python/BKE_unit (``+``, ``*``, ``**``, etc.), and
math constants and functions (pi, sin, etc.).

You can still use the negate and inverse shortcuts (:kbd:`Minus`, :kbd:`/`) , as well as non-number inputs,
but you have to hold :kbd:`Ctrl` to activate them.

.. |prop-edit-icon| image::
/images/editors_3dview_object_transform-control_proportional-edit_header-object-mode.png

.. |prop-edit-edit-mode-icon| image::
/images/editors_3dview_object_transform-control_proportional-edit_header-edit-mode.png

*****************
Proportional Edit
*****************

Proportional Edit is a way of transforming selected elements (such as vertices)
while having that transformation affect other nearby elements. For example, having the
movement of a single vertex cause the movement of unselected vertices within a given range.
Unselected vertices that are closer to the selected vertex will move more than those farther
from it (i.e. they will move proportionally relative to the location of the selected element).
Since proportional editing affects the nearby geometry,
it is very useful when you need to smoothly deform the surface of a dense mesh.

.. note:: Sculpting

Blender also has :ref:`painting-sculpting-index`
that contains brushes and tools for proportionally editing a mesh without seeing the individual vertices.

Object Mode
===========

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     Via the |prop-edit-icon| icon in the header indicated by the yellow square in the below image.
| Hotkey:   :kbd:`O`

Proportional editing is typically used in *Edit Mode*, however,
it can also be used in *Object Mode*. In *Object Mode* the tool works on
entire objects rather than individual mesh components. In the image below,
the green cube is the active Object, while the red and blue cubes are located within the
proportional edit tool's radius of influence. When the green cube is moved to the right,
the other two cubes follow the movement.

.. figure:: /images/editors_3dview_transform-control_proportional-edit-object-mode.jpg

Proportional editing in Object Mode.

.. Todo move to modeling section

Edit Mode
=========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Proportional Editing` and via the |prop-edit-edit-mode-icon| highlighted icon
| Hotkey:   :kbd:`O`, :kbd:`Alt-O`, :kbd:`Shift-O`

When working with dense geometry, it can become difficult to make subtle adjustments to the
vertices without causing visible lumps and creases in the model's surface. When you face
situations like this the proportional editing tool can be used to smoothly deform the surface
of the model.
This is done by the tool's automatic modification of unselected vertices within a given range.

.. figure:: /images/editors_3dview_transform-control_proportional-edit-edit-mode.png

Proportional editing in Edit Mode.

Influence
---------

You can increase or decrease the radius of the proportional editing influence with the mouse
wheel :kbd:`WheelUp`, :kbd:`WheelDown` or :kbd:`PageUp`, :kbd:`PageDown`
respectively. As you change the radius,
the points surrounding your selection will adjust their positions accordingly.

.. figure:: /images/editors_3dview_transform-control_proportional-edit-influence.jpg

Influence circle.

Options
-------

.. list-table::

* - .. figure:: /images/editors_3dview_transform-control_proportional-edit-tool.jpg
:width: 200px

Proportional Editing tool.

- .. figure:: /images/editors_3dview_transform-control_proportional-edit-falloff-options.jpg
:width: 200px

Falloff menu.

The *Proportional Editing* mode menu is on the *3D View* header.

Disable :kbd:`O`, :kbd:`Alt-O`
Proportional Editing is Off, only selected vertices will be affected.
Enable :kbd:`O`, :kbd:`Alt-O`
Vertices other than the selected vertex are affected, within a defined radius.
Projected (2D)
Depth along the view is ignored when applying the radius.

.. figure:: /images/editors_3dview_transform-control_proportional-edit-2d_compare.png
:width: 400px

The difference between regular and Projected (2D) proportional option (right).

Connected :kbd:`Alt-O`
Rather than using a radius only, the proportional falloff spreads via connected geometry. This means that you can
proportionally edit the vertices in a finger of a hand without affecting the other fingers.
While the other vertices are physically close (in 3D space),
they are far away following the topological edge connections of the mesh.
The icon will have a gray center when *Connected* is active.
This mode is only available in *Edit Mode*.

Falloff
While editing, you can change the curve profile used by either using the
:menuselection:`Mesh --&gt; Proportional Falloff` submenu, using the header icon *Falloff menu*,
or by pressing :kbd:`Shift-O` to toggle between the various options.

.. list-table::

* - .. figure:: /images/editors_3dview_transform-control_proportional-edit-falloff-constant.png
:width: 320px

Constant, No Falloff.

- .. figure:: /images/editors_3dview_transform-control_proportional-edit-falloff-random.png
:width: 320px

Random Falloff.

* - .. figure:: /images/editors_3dview_transform-control_proportional-edit-falloff-linear.png
:width: 320px

Linear Falloff.

- .. figure:: /images/editors_3dview_transform-control_proportional-edit-falloff-sharp.png
:width: 320px

Sharp Falloff.

* - .. figure:: /images/editors_3dview_transform-control_proportional-edit-falloff-root.png
:width: 320px

Root Falloff.

- .. figure:: /images/editors_3dview_transform-control_proportional-edit-falloff-sphere.png
:width: 320px

Sphere Falloff.

* - .. figure:: /images/editors_3dview_transform-control_proportional-edit-falloff-smooth.png
:width: 320px

Smooth Falloff.

- ..

Examples
--------

Switch to a front view :kbd:`Numpad1` and activate the grab tool with :kbd:`G`.
As you drag the point upwards, notice how nearby vertices are dragged along with it.
When you are satisfied with the placement, click :kbd:`LMB` to fix the position.
If you are not satisfied,
cancel the operation and revert your mesh to the way it looked before with
:kbd:`RMB`, :kbd:`Esc`.

You can use the proportional editing tool to produce great effects with the scaling
:kbd:`S` and rotation :kbd:`R` tools,
as Fig. :ref:`fig-view3d-transform-landscape` shows.

.. _fig-view3d-transform-landscape:

.. figure:: /images/editors_3dview_transform-control_proportional-edit-landscape.jpg

A landscape obtained via proportional editing.

Combine these techniques with vertex painting to create fantastic landscapes.
The Fig. :ref:`fig-view3d-transform-landscape-rendered` below shows the results of proportional editing after the
application of textures and lighting.

.. _fig-view3d-transform-landscape-rendered:

.. figure:: /images/editors_3dview_objects_transform_proportional-edit_example.jpg
:width: 620px

Final rendered landscape.

********
Snapping
********

There are two types of snap operations that you can use in Blender. The first type snaps your
selection or cursor to a given point while the second type is used during transformations
(translate, rotate, scale) and snaps your selection to elements within the scene.

Snap Menu
=========

.. admonition:: Reference
:class: refbox

| Mode:     Object, Edit, and Pose Mode
| Menu:     :menuselection:`Object/Object type --&gt; Snap`
| Hotkey:   :kbd:`Shift-S`

The *Snap* menu (also available from the 3D header in both *Object Mode* and *Edit Mode*
:menuselection:`Object --&gt; Snap` and :menuselection:`Mesh --&gt; Snap`).
This menu provides a number of options to move the cursor or your selection to a defined point
(the cursor, selection or the grid).

Selection to Grid
Snaps the currently selected object(s) to the nearest grid point.
Selection to Cursor
Moves each one of the currently selected object(s) to the cursor location.
Selection to Cursor (Offset)
Places the selection at the position of the 3D cursor.
If there are multiple objects selected, they are not moved individually at the cursor position;
instead, they are centered around the 3D cursor, maintaining their relative distances.
Selection to Active
Moves the selection to the origin of the active object.

..

Cursor to Selected
Places the cursor to the center of the current selection, unless see below.
Cursor to Center
Places the cursor to the origin of the world (location 0, 0, 0).
Cursor to Grid
Places the cursor to the nearest grid point.
Cursor to Active
Places the cursor to the origin of the *active* (last selected) object.

The *Cursor to Selected* option is also affected by the current :ref:`pivot-point-index`. For example:

- With the *Bounding Box Center* pivot point active,
the *Cursor to Selected* option will snap the 3D cursor to the
center of the bounding box surrounding the objects' origins.
- When the *Median Point* pivot point is selected,
*Cursor to Selected* will snap the 3D cursor to the
`median &lt;https://en.wikipedia.org/wiki/Median&gt;`__ of the object origins.

.. _transform-snap:

Transform Snapping
==================

.. admonition:: Reference
:class: refbox

| Mode:     Object, Edit, and Pose Mode
| Header:    :menuselection:`Snap`
| Hotkey:   :kbd:`Shift-Tab`

The ability to snap Objects and Mesh element to various types of scene elements during a
transformation is available by toggling the magnet icon (which will turn red)
in the 3D View's header buttons.

.. figure:: /images/editors_3dview_transform_control_precision_snap_header-magnet-icon.png

Magnet icon in the 3D View header (red when enabled).

.. _transform-snap-element:

Snap Element
------------

.. admonition:: Reference
:class: refbox

| Mode:     Object, Edit, and Pose Mode
| Header:    :menuselection:`Snap Element`
| Hotkey:   :kbd:`Ctrl-Shift-Tab`

.. figure:: /images/editors_3dview_transform_control_precision_snap_element-menu.png
:align: right

Snap Element menu.

Volume
Snaps to regions within the volume of the first Object found below the mouse cursor.
Unlike the other options, this one controls the depth
(i.e. Z-coordinates in current view space) of the transformed element.
By toggling the button that appears to the right of the snap target menu (see below),
target objects will be considered as a whole when determining the volume center.
Face
Snap to the surfaces of faces in mesh objects. Useful for retopologizing.
Edge
Snap to edges of mesh objects.
Vertex
Snap to vertices of mesh objects.
Increment
Snap to grid points. When in Orthographic view, the snapping increment changes depending on zoom level.

.. note::

In this context the grid does not mean the visual grid cue displayed.
Snapping will use the resolution of the displayed grid,
but all transformations are relative to the initial position (before the snap operation).

Snap Target
-----------

Snap target options become active when either *Vertex*, *Edge*,
*Face*, or *Volume* is selected as the snap element.
These determine what part of the selection snaps to the target objects.

Active
Moves the active element (vertex in Edit Mode, object in Object Mode) to the target.
Median
Moves the median of the selection to the target.
Center
Moves the current transformation center to the target. Can be used with 3D cursor to snap with an offset.
Closest
Moves the closest point of the selection to the target.

.. list-table::

* - .. figure:: /images/editors_3dview_transform_control_precision_snap_target-closest.png

Closest.

- .. figure:: /images/editors_3dview_transform_control_precision_snap_target-active.png

Active.

- .. figure:: /images/editors_3dview_transform_control_precision_snap_target-median.png

Median.

Additional Snap Options
-----------------------

.. list-table::

* - .. figure:: /images/editors_3dview_transform_control_precision_snap_options-object-mode.png

Object Mode.

- .. figure:: /images/editors_3dview_transform_control_precision_snap_options-edit-mode.png

Edit Mode.

As seen by the yellow highlighted areas in the image above,
additional controls are available to alter snap behavior. These options vary between mode
(Object and Edit) as well as Snap Element. The four options available are:

.. list-table::
:header-rows: 1
:widths: 13 87

* - Icon
- Details
* - .. figure:: /images/editors_3dview_transform_control_precision_snap_option-icon-rotation.png
:width: 42px
- Align rotation with the snapping target.
* - .. figure:: /images/editors_3dview_transform_control_precision_snap_option-icon-project.png
:width: 42px
- Project individual elements on the surface of other objects.
* - .. figure:: /images/editors_3dview_transform_control_precision_snap_option-icon-self.png
:width: 42px
- Snaps elements to its own mesh.
* - .. figure:: /images/editors_3dview_transform_control_precision_snap_option-icon-whole.png
:width: 42px
- Consider Objects as whole when finding volume center.
* - .. figure:: /images/editors_3dview_transform_control_precision_snap_option-icon-absolute.png
:width: 42px
- Snap to grid, instead of snapping in increments relative to the current location.

Multiple Snap Targets
^^^^^^^^^^^^^^^^^^^^^

.. figure:: /images/editors_3dview_transform_control_precision_snap_target-multiple.png

Multiple snapping targets.

Once transforming a selection with Snapping on (not just when holding :kbd:`Ctrl`),
you can press :kbd:`A` to mark the current snapping point, then proceed to mark as many other
snapping points as you wish and the selection will be snapped to the average location of all
the marked points.

Marking a point more than once will give it more weight in the averaged location.

############
Transform
############

.. toctree::
:maxdepth: 2

introduction.rst
basics.rst
control/index.rst
tools.rst
mirror.rst
clear_apply.rst

************
Introduction
************

Transformations refer to a number of operations that can be performed on a
selected Object or Mesh that alters its position or characteristics.

Each object can be moved, rotated and scaled in *Object Mode*.
However, not all of these transformations have an effect on all objects.
For example, scaling a camera has no effect on the render dimensions.

:doc:`Basic transformations &lt;/editors/3dview/object/editing/transform/basics&gt;` include:

- Grabbing (moving)
- Rotating
- Scaling

These three transforms are the three big ones however, more, advanced transformations can be found in the
:doc:`Advanced Transformations &lt;/editors/3dview/object/editing/transform/index&gt;` section.

For making other changes to the geometry of editable objects,
you should use *Edit Mode*.

Once you have added a basic object, you remain in *Object Mode*.

You can switch between *Object Mode* and *Edit Mode* by pressing :kbd:`Tab`.

The object's wireframe should now appear orange. This means that the object is now selected and active.

The Fig. Selected object image shows both the solid view and wireframe view of the default cube.
To switch between wireframe and solid view, press :kbd:`Z`.

******
Mirror
******

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Menu:     :menuselection:`Object/Mesh --&gt; Mirror`
| Hotkey:   :kbd:`Ctrl-M`

Mirroring an Object or Mesh selection will create a reversed version of the selection. The
position of the mirrored version of the selection is determined by the
:doc:`Pivot Point &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`.
A common use of mirroring is to model half an object, duplicate it and then use the
mirror transform to create a reversed version to complete the model.

.. note::

Mirrored duplicates can also be created with a :doc:`Mirror Modifier &lt;/modeling/modifiers/generate/mirror&gt;`.

.. _fig-mesh-duplicating-mirror-selection:

.. figure:: /images/editors_3dview_transformations_advanced_mirror_mirror-example.jpg

Mirroring a Selection.

Usage
=====

To mirror a selection along a particular global axis press:
:kbd:`Ctrl-M`, followed by :kbd:`X`, :kbd:`Y` or :kbd:`Z`.
The image :ref:`Mirroring a Selection &lt;fig-mesh-duplicating-mirror-selection&gt;`
shows the results of this action after a mesh element has been duplicated.

In Mesh mode, you can mirror the selection on the currently selected
:doc:`Transform Orientations &lt;/editors/3dview/object/editing/transform/control/orientations&gt;`
by pressing the appropriate axis key a second time. For example,
if the Transform Orientation is set to *Normal*, pressing:
:kbd:`Ctrl-M`, followed by :kbd:`X` and then :kbd:`X` again
will mirror the selection along the X-axis of the *Normal Orientation*.

.. figure:: /images/editors_3dview_transformations_advanced_mirror_interactive-mirror.jpg

Interactive Mirror.

You can alternatively hold the :kbd:`MMB` to interactively mirror the object by moving
the mouse in the direction of the mirror axis.

***************
Transform Tools
***************

Randomize Transform
===================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Deform: Randomize`
| Menu:     :menuselection:`Object --&gt; Transform --&gt; Randomize Transform`,
:menuselection:`Mesh --&gt; Transform --&gt; Randomize`

.. figure:: /images/editors_3dview_object_transform_tools_randomize.png
:figwidth: 158px
:align: right

Randomize transform options.

This tool allows you to apply a randomized transformation.

Object Mode
-----------

In Object Mode it randomizes the translate, rotate,
and scale values to an object or multiple objects. When applied on multiple objects,
each object gets its own seed value, and will get different transform results from the rest.

Options
^^^^^^^

Random Seed
The random seed is an offset to the randomized transformation.
A different seed will produce a new result.
Transform Delta
Randomize :ref:`Delta Transform &lt;transform-delta&gt;`
values instead of regular transform.

Randomize Location
Randomize Location values.
Location
The maximum distances the objects can move along each axis.

Randomize Rotation
Randomize rotation values.
Rotation
The maximum angle the objects can rotate on each axis.

Randomize Scale
Randomize scale values.
Scale Even
Use the same scale for each axis.
Scale
The maximum scale randomization over each axis.

Edit Mode
----------

The *Randomize* tool in Edit Mode allows you to displace the vertices of a mesh
along their normal.

Options
^^^^^^^

Amount
Distance of the displacement.
Uniform
Adds a random offset of the amount.
Normal
Adds a random offset to the displacement normal.
Random Seed
The random seed is an offset to the random transformation.
A different seed will produce a new result.

Align Objects
=============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Transform --&gt; Align Objects`

The align tool is used to align multiple selected objects so they line up on a specified axis.

Options
-------

High Quality
Uses more precise math to better determine the locations for the objects.
In case of positive or negative bounding box alignment,
if one or more of the selected objects have any rotation transformations
(or delta rotation transformations), it is recommended to check *High Quality*
so that their bounding box is calculated with precision for all three global axes.

Align Mode
The *Align Mode* control will define what part of the objects will be aligned:

Centers
The objects centers.
Positive Sides/Negative Sides
The positive or negative sides (on the global axes) of their respective bounding boxes.
Relative To
The *Relative To* control will let us choose to align the objects to:

Active
The active object.
Selection
The median point of the selection.
3D Cursor
..
Scene Origin
The global origin.
Align X, Y, Z
Chooses which axis to align the selected objects on.
.. _objects-index:

##########
Objects
##########

.. toctree::
:maxdepth: 2

introduction.rst
origin.rst
types.rst
selecting/index.rst
editing/index.rst
properties/index.rst

************
Introduction
************

The geometry of a scene is constructed from one or more Objects. These objects
can range from lamps to light your scene, basic 2D and 3D shapes to fill it with models, armatures
to animate those models, to cameras to take pictures or video of it all.

Instancing
==========

Each Blender object type (mesh, lamp, curve, camera, etc.) is composed from two parts:
an *Object* and *Object Data* (sometimes abbreviated to *ObData*):

Object
Holds information about the position, rotation and size of a particular element.
Object Data
Holds everything else. For example:

:Meshes: Store geometry, material list, vertex groups... etc.
:Cameras: Store focal length, depth of field, sensor size... etc.

Each object has a link to its associated :ref:`object-data &lt;properties-data-tabs&gt;`,
and a single object-data may be shared by many objects.

*************
Object Origin
*************

Each object has an origin point. The location of this point determines where the object is located in 3D space.
When an object is selected, a small circle appears, denoting the origin point.
The location of the origin point is important when translating, rotating or scaling an object.
See :doc:`Pivot Points &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;` for more.

The color of the origin is set by the :ref:`animation-state-colors` and
in light blue to denote library linkage on both the source and the linked object.
The size can be changed in the :doc:`Interface tab &lt;/preferences/interface&gt;` of the User Preferences.

Set Origin
==========

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Edit --&gt; Set Origin`
| Menu:     :menuselection:`Object --&gt; Transform`
| Hotkey:   :kbd:`Shift-Ctrl-Alt-C`

The Object Origin and Geometry can be moved relative to each other and to the 3D Cursor.

Type
Geometry to Origin
Moves the model to the origin and
this way the origin of the object will also be at the center of the object.
Origin to Geometry
Moves the origin to the center of the object and
this way origin of the object will also be at the center of the object.
Origin to 3D Cursor
Moves the origin of the model to the position of the 3D cursor.
Origin to Center of Mass
Moves the origin to the calculated center of mass of model (assuming the mesh has a uniform density).
Center
Median Point Center, Bounding Box Center

*******
Display
*******

.. figure:: /images/editors_3dview_object_properties_display.png

Display panel.

The *Display* panel is used to enable extra drawing or viewing options for the 3D View.

Name
Displays the name of the object in the 3D View.
Axis
Displays a object similar to an *Empty* that shows the object's axis.
Wire
Draws an object's wire frame on top of the solid drawing.
Draw All Edges
Displays all edges for mesh objects.
Bounds
Displays a bounding box around an object.

Draw Bounds Type
TODO.

Texture Space
Displays the objects :term:`Texture Space`.
X-Ray
Makes the object draw in front of others. (Unsupported for duplicator drawing).
Transparency
Displays material transparency in the object. (Unsupported for duplicator drawing).

Maximum Draw Type
The Maximum shading mode to display in the 3D View.
This can be useful if you have a high poly object that is slowing down performance.

.. _objects-display-object-color:

Object Color
Allows to specify the color used when the *Object Color* in
:doc:`Material Options &lt;/render/blender_render/materials/properties/options&gt;`
is enabled.

**********
DupliFaces
**********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Object --&gt; Duplication`
| Menu:     :menuselection:`Object --&gt; Make Dupli-Face`

*Duplication Faces* or *DupliFaces* is the capability to replicate an object on each face of a parent object.
One of the best ways to explain this is through an example illustration.

.. seealso:: Example blend-file

Download the blend-file used for the examples on this page
`here &lt;https://wiki.blender.org/index.php/:File:Manual-2.5-Duplifaces-Example01.blend&gt;`__.

Basic Usage
===========

.. figure:: /images/dupliface-example01-1start.png

A cube and a sphere.

In this example we will use a UV sphere with an extruded "north pole" as our base object and
cube as our parent mesh. To parent the sphere to the cube, in *Object Mode*,
first :kbd:`RMB` select the sphere, then :kbd:`Shift-RMB` select the cube
(order is very important here), and finally :kbd:`Ctrl-P` to parent.

.. figure:: /images/dupliface-example01-2duplifaceenabled.jpg

Duplication Faces applied to the cube.

Next, in the :menuselection:`Object tab --&gt; Duplication panel`,
enable *Faces*. The sphere is duplicated one for each face of the cube.

.. note:: Inherited properties

The location, orientation, and scale of the duplicated child(ren) matches that of the faces of the parent.
So, if several objects are parented to the cube, they will all be duplicated once for each face on the cube.
If the cube is subdivided, every child will be duplicated for each face on the cube.

Both the parent object and original are displayed as editable "templates" in 3D View,
but neither is rendered.

Scale
=====

.. figure:: /images/dupliface-example01-3scaleenabled.jpg

Scale enabled.

.. figure:: /images/dupliface-example01-4scalechanged.jpg

Top face of cube scaled down.

By enabling *Scale* for the parent object,
the scale of the child objects will be adapted to the size of each face in the parent object.

Thus, by rescaling the face of the parent object,
the size of the duplicated object will change accordingly.

Limitations/Considerations
============================

The positioning of the duplicated geometry relative to the face is dependent upon the position
of the child objects relative to the duplicator's origin. This can lead to some visual
artifacts in the editor as the geometry of the original objects overlaps or intersects with
the duplicates.
One workaround is to move the origin of the duplicator mesh off of the plane of the faces.

If the geometry of the children is not symmetrical then the orientation of the face
(as determined by the order of its vertices) could matter. As of 2.70 Blender does not have
tools which allow you to adjust the ordering of the vertices on a face.

However, there is a workflow that lets you control for this. Make a single square and enable
the Duplication/Faces so you can see the duplicated geometry in your editor.
If the orientation is not what you want, rotate the face until it is how you want.
Typically you want to do the rotation in Edit Mode, not Object Mode,
but this is not a hard rule.

Once you have the orientation correct,
Duplicate the face and move the duplicate where you want it.
Repeat this process until you have enough faces.
Since it is common for these faces to butt up against one another,
your geometry will have lots of duplicate vertices.
Use the Remove Doubles button in the Tools panel.

.. rubric:: Demo Video

.. only:: builder_html and (not singlehtml)

A short video illustrating this workflow:

.. youtube:: diI8xJ9oo_8

.. only:: not builder_html and (singlehtml)

A short video illustrating this workflow can be found at https://www.youtube.com/watch?v=diI8xJ9oo_8

***********
DupliFrames
***********

DupliFrames is a tool to duplicate objects at frames distributed along a path.
This is a useful tool to quickly arrange objects.

Examples
========

.. figure:: /images/modeling-dupliframes-example01.png
:width: 300px

Settings for the curve.

:kbd:`Shift-A` to add a *Bézier Circle* and scale it up.
In the *Curve* menu under *Path Animation* enable *Follow*
and set *Frames* to something more reasonable than 100 (say 16).

.. figure:: /images/modeling-dupliframes-example02.png
:width: 300px

Settings for the object.

Add a *Monkey*. In the *Object* menu under *Duplication* enable *Frames* and disable *Speed*.

.. note:: Speed

The *Speed* option is used when the parent-child relationship is set to *Follow Path* (see below).
In this example, the monkey will then travel along the circle over 16 frames.

.. figure:: /images/modeling-dupliframes-example03.png
:width: 300px

Parenting.

To parent the monkey to the Bézier circle, first select the monkey then the curve
(so that the curve is the active object) and :kbd:`Ctrl-P`.
Select the monkey and :kbd:`Alt-O` to reset its origin.

.. figure:: /images/modeling-dupliframes-example04.png
:width: 300px

Orientation tweaks.

You can now change the orientation of the monkey by either rotating it
(either in *Edit Mode* or *Object Mode*) or by changing the *Tracking Axes*
under *Relations Extras* (with the monkey selected).
The arrangement of monkeys can, of course, be further enhanced by editing the curve.

To transform all monkeys into real objects, first :kbd:`Ctrl-Shift-A`
to *Make Duplicates Real*. All monkeys are now real objects, but still linked copies.
To change this, :menuselection:`Object --&gt; Make Single User --&gt; Object &amp; Data --&gt; All`.

.. note::

There are many alternatives to Dupliframes. Which tool to use depends on context:

- To use a small curve as a profile and a larger curve as a path,
simply use the former as a *Bevel Object* to the latter.
- To arrange objects along a curve, combining an *Array Modifier* and a *Curve Modifier* is often useful.
- Dupliverts can be used to arrange objects, for example, along a circle or across a subdivided plane.

.. seealso::

`Blender Artists: Dupliframes in 2.5 &lt;http://blenderartists.org/forum/showthread.php?181911-Dupliframes-in-2-5&gt;`__

**********
DupliGroup
**********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Object --&gt; Duplication --&gt; Group`

*Duplication Group* or *DupliGroup* allows you to create an instance of a group for each instance of another object.

*DupliGroups* may contain animations, objects with physics simulations and even other nested *DupliGroups*.

Basic Usage
===========

Create a Group:
- Selecting the objects to be grouped.
- Create a new group :menuselection:`Object --&gt; Group --&gt; Create New Group`
- Rename your group in the properties editor: :menuselection:`Object --&gt; Groups`
Create a new Group Instance:
- :menuselection:`Add --&gt; Group Instance`
Change the Group Instance of existing objects:
- In the properties editor: :menuselection:`Object --&gt; Duplication`, enable *Group*.
- Select the name of your newly created group.

At this point, an instance of the group will appear. You can duplicate the empty,
and the DupliGroup settings will be preserved for each empty.
This way, you can get multiple copies of linked data very easily.

DupliGroup and Dynamic Linking
==============================

See :doc:`Appending and Linking &lt;/data_system/linked_libraries&gt;`
to understand how to dynamically link data from another blend-file into the current file.
You can dynamically link groups from one blend-file to another.
When you do so, the linked group does not appear anywhere in your scene
until you create an object controlling where the group instance appears.

.. important::

Material Transparency will not display when instancing dupli-groups;
this is a known limitation of Blender's viewport.

Making a DupliGroup Object Real
===============================

Say you want to make further edits on an DupliGroup instance:

Simply select your DupliGroup and press :kbd:`Ctrl-Shift-A` to convert the DupliGroup
into regular objects that can be transformed and animated normally.

.. note::

Note that if the DupliGroup was linked from an external file the Object Data
(mesh, materials, textures, transforms) will also still be linked from the original group.
However, the various object's parent-child relationships do not carry over.

**********
DupliVerts
**********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Object --&gt; Duplication`

*Duplication Vertices* or *DupliVerts* is the duplication of a base object at the location of the vertices of a mesh.
In other words, when using *DupliVerts* on a mesh,
an instance of the base object is placed on every vertex of the mesh.

There are actually two approaches to modeling using *DupliVerts*.
They can be used as an arranging tool,
allowing to model geometrical arrangements of objects (e.g. the columns of a Greek temple,
the trees in a garden, an army of robot soldiers, the desks in a classroom).
The object can be of any object type which Blender supports.
The second approach is to use them to model an object starting from a single part of it (e.g.
the spikes in a club, the thorns of a sea-urchin, the tiles in a wall,
the petals in a flower).

.. note:: Download example blend-file

You can download a file with the examples described on this page.
In `this blend &lt;https://wiki.blender.org/index.php/:File:Manual-2.5-DupliVerts-Examples.blend&gt;`__,
the first example, a monkey parented to a circle is on layer 1;
while a tentacle parented to an icosphere is on layer 2.

DupliVerts as an Arranging Tool
===============================

Setup
-----

.. figure:: /images/dupliverts-example01-1start.png

A monkey head and a circle.

All you need is a base object (e.g. the *tree* or the *column*)
and a pattern mesh with its vertices following the pattern you have in mind. In this section,
we will use a simple scene for the following part. We will be using a monkey head located at
the origin of the coordinate system as our base object and a circle at the same location as
our parent mesh.

.. figure:: /images/dupliverts-example01-2dupliverted.png

Dupliverted monkeys.

First, in *Object Mode*,
select the base object and :kbd:`Shift-RMB` to add the circle to the selection
(order is very important here),
and :kbd:`Ctrl-P` to parent the base object to the circle.
Now, the circle is the parent of the monkey; if you move the circle, the monkey will follow it.

With only the circle selected, enable *Duplication vertices* in the
:menuselection:`Object panel --&gt; Duplication --&gt; Vertices`.
A monkey head should be placed at every vertex of the circle.

The original monkey head at the center and the parent mesh are still shown in the 3D View but
neither will be rendered. If the placement and rotation of your monkey head is odd,
you might need to clear its rotation :kbd:`Alt-R`, scale :kbd:`Alt-S`,
location :kbd:`Alt-G`, and origin :kbd:`Alt-O`.

Rearranging
-----------

If you now select the base object and modify it in either object or edit mode,
all changes will also affect the shape of all duplicate objects.
You can also select the parent mesh to modify the arrangement of the duplicates;
adding vertices will also add more base objects.

Note that the base objects will inherit changes made to the parent mesh in Object Mode, but
not in Edit Mode. So scaling the circle up in object mode will enlarge the monkey head,
while scaling the circle up in edit mode will only increase the distance between the base
objects.

Orientation
-----------

.. figure:: /images/dupliverts-example01-3orientation.png

Orientation enabled, orientation +Y.

The orientation of the base objects can be controlled by enabling *Rotation* in the
*Duplication* panel.
This will rotate all base objects according to the vertex normals of the parent mesh.

To change the orientation of the duplicated objects, select the base object and in the
:menuselection:`Object --&gt; Relations extras` panel change the :menuselection:`Tracking Axes`.

Output of various orientations:

.. figure:: /images/dupliverts-example01-4negy.png

Negative Y.

.. figure:: /images/dupliverts-example01-5posx.png

Positive X.

.. figure:: /images/dupliverts-example01-6posz.png

Positive Z, up X.

.. note::

The axes of an object can be made visible in the :menuselection:`Object --&gt; Display` panel.
To display the vertex normals of the parent mesh,
enter *Edit Mode* and enable this function in :menuselection:`Properties --&gt; Display`
panel where you can also resize the displayed normals as necessary.

DupliVerts as a Modeling Tool
=============================

Very interesting models can be made using DupliVerts and a standard primitive.
In this example, a simple tentacle was made by extruding a cube a couple of times.
The tentacle object was then parented to an icosphere.
With dupli *Rotation* enabled for the parent mesh (the icosphere),
the orientation of the base object (the tentacle)
was adapted to the vertex normals of the parent mesh

(in this case the tentacle was rotated -90° about the X axis in edit mode).

.. list-table::

* - .. figure:: /images/dupliverts-example02-1tentacle.jpg

A simple tentacle set to smooth.

- .. figure:: /images/dupliverts-example02-2norot.jpg

Tentacle dupliverted onto the parent mesh.

- .. figure:: /images/dupliverts-example02-3rot.jpg

Rotation enabled to align duplicates.

As in the previous example, the shape and proportions of the arrangement can now be tweaked.

To turn all duplicates into real objects, simply select the icosphere and
:menuselection:`Object --&gt; Apply --&gt; Make Duplicates Real`, :kbd:`Ctrl-Shift-A`.
To make the icosphere and the tentacle a single object,
make sure they are all selected and go to :menuselection:`Object --&gt; Join`, :kbd:`Ctrl-J`.

.. seealso::

Other duplication methods are listed :doc:`here &lt;/editors/3dview/object/editing/duplication&gt;`.

##############
Duplication
##############

There are currently four ways in Blender to procedurally duplicate objects.
These options are located in the *Object* menu.

Vertices
This creates an instance of all children of this object on each vertex (for mesh objects only).
Faces
This creates an instance of all children of this object on each face (for mesh objects only).
Group
This creates an instance of the group with the transformation of the object.
Group duplicators can be animated using actions,
or can get a :ref:`Proxy &lt;object-proxy&gt;`.
Frames
For animated objects, this creates an instance on every frame.
As you will see on this topic's subpage,
this is also a *very* powerful technique for arranging objects and for modeling them.

.. toctree::
:maxdepth: 2

dupliframes.rst
dupliverts.rst
duplifaces.rst
dupligroup.rst

##############
Properties
##############

.. toctree::
:maxdepth: 2

introduction.rst
transforms.rst
relations/index.rst
display.rst
duplication/index.rst

************
Introduction
************

TODO.

Item panel
==========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Properties region --&gt; Item`

This panel lets you edit the name of the active object.

****************
Relations Extras
****************

Tracking Axes
TODO.

Axis
Axis that points in the "forward" direction.
(Applies to *DupliFrame* when parent *Follow* is enabled).
Up Axis
Axis that points in the upward direction.
(Applies to *DupliFrame* when parent *Follow* is enabled).

Show Parent
Create a delay in the parent relation.

.. warning::

This may be unsafe for renderfarms as it may be invalid after jumping around the time line.

Offset
Delay in the parent offset.

Extra Object Update
Refresh the object agian on frame changes.
Extra Data Update
Refresh the object's data again on frame changes.

******
Groups
******

There can be many objects in a scene: A typical stage scene consists of furniture, props,
lights, and backdrops.
Blender helps you keep everything organized by allowing you to group like objects together.

.. _fig-view3d-grouped-objects:

.. figure:: /images/editors_3dview_object_properties_relations_grouped-cubes.png

Grouped objects.

Group objects together without any kind of transformation relationship.
Use groups to just logically organize your scene,
or to facilitate one-step appending or linking between files or across scenes.
Objects that are part of a group always shows as light green when selected.
See Fig. :ref:`fig-view3d-grouped-objects`.

Groups Menu
===========

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Groups`
| Hotkey:   :kbd:`Ctrl-G`, etc.

Creating New Group :kbd:`Ctrl-G`
Creates a new group and adds the selected object(s) to it.
The name of the new group can be specified in the *Create New Group* Operator panel.
Removing from Group :kbd:`Ctrl-Alt-G`
Remove the selected objects from a group.
If the object belongs to more one group a pop-up lets you select the group and
an option to remove it from all groups.
Removing from All Groups :kbd:`Ctrl-Alt-G`
Remove the selected objects from all group.
Add Selected to Active Group :kbd:`Shift-Ctrl-G`
Adds the selected objects to the groups to which the active object belongs.
Remove Selected from Active Group :kbd:`Shift-Alt-G`
Causes the selected objects to be removed from the groups to which the active object belongs.

Groups Panel
============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Object tab --&gt; Groups`

.. figure:: /images/modeling-objects-grouping-objprop.png

Group panel and Outliner.

All groups that an object has been assigned to are listed in the Properties editor
:menuselection:`Object tab --&gt; Group panel`.

Add to Group
Adds the selected objects from a group.
A pop-up lets you specify the group to add to.
New ``+``
Creates a new group and adds the selected object(s) to it.
Name
To rename a group, simply click in the groups name field.
Remove ``X``
To remove an object from a group,
find the name of the group from which you wish to remove the object,
and click the ``X`` to the right of the group name.
Specials
Unlink Group, Select Group, Set Offset From Cursor
Dupligroup Visibility
Restricting Group Contents via Layers The cluster of layer buttons attached to each group determines from
which layers the group objects will be included when duplicated.
If your group contains objects on layers 10, 11 and 12,
but you disable the layer 12 button in the group controls, duplicates of that group (using the
:doc:`Dupligroup &lt;/editors/3dview/object/properties/duplication/dupligroup&gt;`
feature) will only show the portions of the group that reside in layers 10 and 11.
Offset
ToDo.

.. seealso:: Appending or Linking Groups

To append a group from another blend-file,
consult :doc:`this page &lt;/data_system/linked_libraries&gt;`.
In summary, :menuselection:`File --&gt; Link/Append Link` Select a blend-file and, and then the group.

.. tip:: Selecting Groups

Groups can be selected, see :ref:`Select Grouped &lt;select-grouped&gt;` for more information.

###################
Object Relations
###################

.. toctree::
:maxdepth: 2

layers.rst
parents.rst
groups.rst
extras.rst

******
Layers
******

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Object --&gt; Relations`
| Menu:     :menuselection:`Object --&gt; Move to Layer...`
| Hotkey:   :kbd:`M`

3D scenes often become exponentially more confusing as they grow more complex.
Sometimes the artist also needs precise control over how individual objects are lit,
and does not want lights for one object to affect nearby objects.
For this and other reasons below, objects can be placed into one or more "layers".
Using object layers, you can:

- Selectively display objects from certain layers in your 3D View,
by selecting those layers in the *3D View* header. This allows you to speed up interface redrawing,
reduce virtual-world clutter, and help improve your workflow.
- Control :ref:`which lights illuminate an object &lt;bi-lamp-influence&gt;`,
by making a light illuminate only the objects on its own layer(s).
- Control which forces affect which :doc:`particle systems &lt;/physics/particles/index&gt;`,
since particles are only affected by forces and effects on the same layer.
- Control which layers are rendered (and hence, which objects),
and which properties/channels are made available for compositing by using
:doc:`render layers &lt;/render/post_process/layers&gt;`.

Armatures can also become very complex, with different types of bones, controllers, solvers,
custom shapes, and so on. Since armatures are usually located close together,
this can quickly become cluttered. Therefore, Blender also provides layers just for armatures.
Armature layers are very similar to object layers, in that you can divide up an armature (rig)
across layers and only display those layers you wish to work on.

.. seealso::

:ref:`armature-layers`

Working with Layers
===================

3D layers differ from the layers you may know from 2D graphics applications as they have no
influence on the drawing order and are there (except for the special functions listed above)
mainly to allow you to organize your scene.

When rendering, Blender only renders the selected layers.
If all your lights are on a layer that is *not selected*,
you will not see anything in your render except for objects lit by ambient lighting.

:doc:`Groups &lt;/editors/3dview/object/properties/relations/groups&gt;` and
:doc:`Parents &lt;/editors/3dview/object/properties/relations/parents&gt;`
are other ways to logically group related sets of objects.

Viewing layers
--------------

Blender provides twenty layers whose visibility can be toggled with the small unlabeled
buttons in the header (see *3D View layer buttons*). To select a single layer,
click the appropriate button with :kbd:`LMB`; to select more than one,
use :kbd:`Shift-LMB` - doing this on an already active layer will deselect it.

.. figure:: /images/editors_3dview_layers_header-layer-buttons.png

3D View layer buttons.

To select layers via the keyboard, press :kbd:`1` to :kbd:`0`
(on the main area of the keyboard) for layers 1 through 10 (the top row of buttons),
and :kbd:`Alt-1` to :kbd:`Alt-0` for layers 11 through 20 (the bottom row).
Use :kbd:`Shift` for multiple (de)selection works for these shortcuts too.

You can select or deselect all Scene Layer buttons at once by pressing :kbd:`\\`.

Locking to the scene
--------------------

By default, the lock button directly to the right of the layer buttons is enabled.
This means that changes to the viewed layers affect all other 3D Views locked to the scene.
See the :doc:`navigating the 3D View options page &lt;/editors/3dview/navigate/index&gt;` for more information.

Multiple Layers
---------------

An object can exist on multiple layers. For example,
a lamp that only lights objects on a shared layer could "be" on layers 1, 2, and 3.
An object on layers 3 and 4 would be lit, whereas an object on layers 4 and 5 would not.
There are many places where layer-specific effects come into play,
especially lights and particles.

Moving objects between layers
-----------------------------

.. figure:: /images/editors_3dview_layers_move-layer-menu.png

Layer selection.

To move selected objects to a different layer,
press :kbd:`M` and then select the layer you want from the pop-up menu.
Objects can also be on more than one layer at a time. To have an object on multiple layers,
hold :kbd:`Shift` while clicking.

.. figure:: /images/editors_3dview_layers_object-tab.png

Selection in the Object tab.

Another way to view or change a selected object layer is via the *Relations* panel,
in the *Object* tab.

.. figure:: /images/editors_3dview_layers_relations-panel.png

Layers in Object tab, Relations panel.

You will then see the layer buttons in the *Relations* panel -- as before -- the object
can be displayed on more than one layer by clicking :kbd:`Shift-LMB`.
..    TODO/Review:

*****************
Parenting Objects
*****************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Parent`
| Hotkey:   :kbd:`Ctrl-P`

When modeling a complex object, such as a watch,
you may choose to model the different parts as separate objects. However,
all of the parts may be attached to each other. In these cases,
you want to designate one object as the parent of all the children. Movement,
rotation or scaling of the parent also affects the children.

To parent objects, select at least two objects (select the *Child Objects* first,
and select the *Parent Object* last), and press :kbd:`Ctrl-P`. The *Set Parent To*
menu will pop up allowing you to select from one of several possible different
parenting types. Selecting one of the entries in *Set Parent To* confirms,
and the child/children to parent relationship is created.

The last object selected will be the *Active Object* (outlined in light orange),
and will also be the *Parent Object*.
If you selected multiple objects before selecting the parent,
they will all be children of the parent and will be at the same level of the hierarchy
(they are "siblings").

The *Set Parent To* pop-up menu is context sensitive, which means the number of entries it
displays can change depending on what objects are selected when the :kbd:`Ctrl-P`
shortcut is used.

For non-inverse-mode, press :kbd:`Shift-Ctrl-P` instead. This creates an alternative
parent-child-relationship where child-objects exist entirely in the parent's coordinate
system. This is the better choice for CAD purposes, for example.

Moving, rotating or scaling the parent will also usually move/rotate/scale the child/children.
However, moving/rotating/scaling the child/children of the parent will not result in the parent
moving/rotating/scaling. In other words,
the direction of influence is from parent to child and not child to parent.

In general when using :kbd:`Ctrl-P` or :menuselection:`3D View Header --&gt; Object --&gt; Parent`
to parent objects, the *Child Objects* can only have one *Parent Object*.
If a *Child Object* already has a *Parent Object* and you give it another parent then
Blender will remove the previous parent relationship.

Blender supports many different types of parenting, listed below:

- Object
- Bone
- Vertex
- Vertex (Triangle)

.. rubric:: Setups

Besides parenting the selected objects,
it adds a Modifier or Constraint to the child objects, with the parent as target object
or activates a parent property i.e. *Follow Path*.

- :doc:`Armature Deform &lt;/rigging/armatures/skinning/parenting&gt;`
- :doc:`Curve Deform &lt;/modeling/modifiers/deform/curve&gt;`
- :ref:`Follow Path &lt;curve-path-animation&gt;`
- :doc:`Path Constraint &lt;/rigging/constraints/relationship/follow_path&gt;`
- :doc:`Lattice Deform &lt;/modeling/modifiers/deform/lattice&gt;`

.. _object-parenting:

Object Parent
=============

*Object Parent* is the most general form of parenting that Blender supports.
If will take selected objects and make the last selected object the *Parent Object*,
while all other selected objects will be *Child Objects*.
The child objects will inherit the transformations of the parent. The parent object can be of any type.

Object (Keep Transform) Parent
------------------------------

*Object (Keep Transform) Parent* works in a very similar way to *Object Parent* the major difference is in whether
the *Child Objects* will remember any previous transformations applied to them from the previous *Parent Object*.

Since explaining this in an easy to understand technical way is hard,
lets instead use an example to demonstrate.

Assume that we have a scene consisting of three objects,
those being two Empty Objects named "EmptyA" and "EmptyB", and a Monkey object.
Fig. :ref:`fig-view3d-parent-scene-no` shows the three objects with no parenting relationships active on them.

.. _fig-view3d-parent-scene-no:

.. figure:: /images/editors_3dview_object_properties_relations_parents_keep-transform-a.png

Scene with no parenting.

If you select the Monkey object by :kbd:`RMB` click and then :kbd:`Shift-RMB`
click "EmptyA" object and press :kbd:`Ctrl-P` and then select *Object* from the
*Set Parent To* pop-up menu.
This will result in "EmptyA" object being the *Parent Object* of the Monkey object. With
only "EmptyA" selected rotating/scaling/moving it will result in the Monkey object being
altered respectively.

Scale the "EmptyA" object, so that the Monkey becomes smaller and moves to the left a little.

.. figure:: /images/editors_3dview_object_properties_relations_parents_keep-transform-b.png

The monkey is the child object of "EmptyA".

If you select only the Monkey object by :kbd:`RMB` click and then :kbd:`Shift-RMB`
click "EmptyB" object and press :kbd:`Ctrl-P` and select *Object* from
the *Set Parent To* pop-up menu.
This will result in "EmptyB" object being the *Parent Object* of the Monkey object.
Notice that when you change the parent of the Monkey the scale of the Monkey changed.

.. figure:: /images/editors_3dview_object_properties_relations_parents_keep-transform-c.png

The monkey is the child object of "EmptyB".

This happens because the Monkey object never had its scale altered directly,
the change came about because it was the child of "EmptyA" which had its scale altered.
Changing the Monkey's parent to "EmptyB" resulted in those indirect changes in scale being
removed, because "EmptyB" has not had its scale altered.

This is often the required behavior, but it is also sometimes useful that if you change your
*Parent Object* that the *Child Object* keep any previous transformations it got from the
old *Parent Object*; If instead when changing the *Parent Object* of the Monkey from
"EmptyA" to "EmptyB" we had chosen parenting type *Object (Keep Transform)*, the Monkey
would keep its scale information it obtained from the old parent "EmptyA" when it is assigned
to the new parent "EmptyB";

.. figure:: /images/editors_3dview_object_properties_relations_parents_keep-transform-d.png

The Object (Keep Transform) parent method.

If you want to follow along with the above description here is the blend-file used to describe
*Object (Keep Transform)* parenting method:

`File:Parent_-_Object_(Keep_Transform)_(Demo_File).blend
&lt;https://wiki.blender.org/index.php/File:Parent_-_Object_(Keep_Transform)_(Demo_File).blend&gt;`__.

Bone Parent
===========

Bone parenting allows you to make a certain bone in an armature the Parent Object of another object.
This means that when transforming an armature the Child Object will only move
if the specific bone it is the Child Object of moves.

.. _fig-view3d-parent-bone-parent:

.. figure:: /images/editors_3dview_object_relationships_parents-bone-1.png

Three pictures of Armatures with four Bones.

In Fig. :ref:`fig-view3d-parent-bone-parent` with the 2nd bone being the Bone Parent of the Child Object Cube.
The Cube is only transformed if the 1st or 2nd bones are.
Notice altering the 3rd and 4th bones has no effect on the Cone.

To use Bone Parenting, you must first select all the Child Objects you wish to parent to a specific Armature Bone,
then :kbd:`Shift-RMB` select the Armature Object and switch it into Pose Mode and then select the
specific bone you wish to be the Parent Bone by :kbd:`RMB` selecting it.
Once done press :kbd:`Ctrl-P` and select Bone from the Set Parent To pop-up menu.

Now transforming that bone in Pose Mode will result in the Child Objects also transforming.

Relative Parenting
------------------

Bone Relative parenting is an option you can toggle for each bone.
This works in the same way as Bone parenting with one difference.

With Bone parenting if you have parented a bone to some Child Objects and
you select that bone and switch it into Edit Mode and then translate that bone;
When you switch back into Pose Mode on that bone,
the Child Object which is parented to that bone will snap back to the location of the bone in Pose Mode.

.. _fig-view3d-parent-bone-parent-child:

.. figure:: /images/editors_3dview_object_relationships_parents-bone-2.png

Single Armature Bone which has a Child Object cube parented to it using Bone parenting.

In Fig. :ref:`fig-view3d-parent-bone-parent-child` the 1st picture shows the position of the cube and
armature before the bone is moved in Edit Mode.
2nd picture shows the position of the cube and armature after the bone was selected in Edit Mode,
moved and switched back into Pose Mode. Notice that the Child Object moves to the new location of the Pose Bone.

Bone Relative parenting works differently;
If you move a Parent Bone in Edit Mode, when you switch back to Pose Mode,
the Child Objects will not move to the new location of the Pose Bone.

.. _fig-view3d-parent-bone-parent-relative:

.. figure:: /images/editors_3dview_object_relationships_parents-bone-3.png

Single Bone with Bone Relative parent to a cube.

In Fig. :ref:`fig-view3d-parent-bone-parent-relative` the 1st picture
shows the position of the cube and armature before the bone is moved in Edit Mode.
2nd picture shows the position of the cube and armature after the bone was selected in Edit Mode,
moved and switched back into Pose Mode.
Notice that the Child Object does not move to the new location of the Pose Bone.

Vertex Parent
=============

For objects of type curve, surface, mesh and lattice,
there is the possibility to use one of its vertices or points as the parent of other objects.
You can parent an object to a single vertex or a group of three vertices as well;
that way the child/children will move when the parent mesh is deformed,
like a mosquito on a pulsing artery.

Vertex Parent from Edit Mode
----------------------------

In *Object Mode*, select the child/children and then the parent object.
:kbd:`Tab` into *Edit Mode* and on the parent object select either one vertex
that defines a single point, or select three vertices that define an area
(the three vertices do not have to form a complete face;
they can be any three vertices of the parent object),
and then press :kbd:`Ctrl-P` and confirm.

At this point, if a single vertex was selected,
a relationship/parenting line will be drawn from the vertex to the child/children. If three
vertices were selected then a relationship/parenting line is drawn from the averaged center of
the three points (of the parent object) to the child/children. Now,
as the parent mesh deforms and the chosen parent vertex/vertices move,
the child/children will move as well.

Vertex Parent from Object Mode
------------------------------

Vertex parenting can be performed from object mode,
This is done like regular object parenting,
Press :kbd:`Ctrl-P` in object mode and select *Vertex* or *Vertex (Triangle)*.

The nearest vertices will be used from each object which is typically what you would want.

.. figure:: /images/parent_vertex_object_mode_example.jpg

Vertex Parent example.

A) The small cubes can each be automatically parented to a triad of nearby vertices on the icosphere using the
"Vertex (Triangle)" in the set parent context menu.
B) Reshaping the object in edit mode then means each of the cubes follows their vertex parent separately.
C) Re-scaling the parent icosphere in object mode means the child cubes are also rescaled as expected.

The parent context menu item means users can rapidly set up a large number of vertex parent
relationships,
and avoid the tedious effort of establishing each parent-child vertex relationship separately.

.. note::

It is in fact a sort of "reversed" :doc:`hook &lt;/modeling/modifiers/deform/hooks&gt;`

Options
=======

Move child
----------

You can *move* a child object to its parent by clearing its origin.
The relationship between the parent and child is not affected.
Select the child object and press :kbd:`Alt-O`.
By confirming the child object will snap to the parent's location.
Use the *Outliner* view to verify that the child object is still parented.

Clear Parent
------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Parent`
| Hotkey:   :kbd:`Alt-P`

You can *remove* a parent-child relationship via :kbd:`Alt-P`

The menu contains:

Clear Parent
If the parent in the group is selected nothing is done.
If a child or children are selected they are disassociated from the parent,
or freed, and they return to their *original* location, rotation, and size.
Clear and Keep Transformation
Frees the children from the parent, and *keeps* the location, rotation, and size given to them by the parent.
Clear Parent Inverse
Places the children with respect to the parent as if they were placed in the Global reference.
This effectively clears the parent's transformation from the children.
The hierarchical relationships are not removed, but the correcting matrix
(''parent inverse'') is cleared from the selected objects.

For example, if the parent is moved 10 units along the X axis and *Clear Parent Inverse* is invoked,
any selected children are freed and moved -10 units back along the X axis.
The "Inverse" only uses the last transformation; if the parent moved twice,
10 units each time for a total of 20 units, then the "Inverse" will only move the child back 10 units, not 20.

Hints
=====

.. _fig-view3d-parent-outliner:

.. figure:: /images/editors_3dview_object_properties_relations_parents_outliner-view.png

Outliner view.

There is another way to see the parent-child relationship in groups and that is to use the *Outliner* view
of the :doc:`Outliner editor &lt;/editors/outliner&gt;`. Fig. :ref:`fig-view3d-parent-outliner`
is an example of what the *Outliner* view looks like for the figurers in the :ref:`object-parenting` example.
Cube A's object name is "Cube_Parent" and cube B is "Cube_Child".
.. _bpy.types.Object.location:

********************
Transform Properties
********************

Each object stores its position, orientation, and scale values.
These may need to be manipulated numerically, reset, or applied.

Transform Panel
===============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Object --&gt; Transform`
| Panel:    :menuselection:`Properties region --&gt; Transform`

The *Transform* panel in the Properties region allows you to view and
manually/numerically control the position, rotation, and other properties of an object, in *Object Mode*.
In *Edit Mode*. It mainly allows you to enter precise coordinates for a vertex,
or median position for a group of vertices (including an edge/face). As each type of object has a different set of
options in its *Transform* panel in *Edit Mode*,
see their respective descriptions in the :doc:`Modeling chapter &lt;/modeling/index&gt;`.

Options in Object Mode
----------------------

Use this panel to either edit or display the object's transform properties such as position,
rotation and/or scaling. These fields change the object's origin and then affect the aspect
of all of its *vertices* and faces.

.. figure:: /images/editors_3dview_transform-control_properties.png
:align: right

Transform Properties.

Location
The object's origin location in global coordinates.
Rotation
The object's orientation, relative to the global axes and its own origin.

.. _rotation-modes:

Rotation Mode
Method for calculating rotations, additional information can be found
`here &lt;https://wiki.blender.org/index.php/User:Pepribal/Ref/Appendices/Rotation&gt;`__.

Euler
The manipulator handles are aligned to the :term:`Euler` axis,
allowing you to see the discreet XYZ axis underlying the euler rotation,
as well as possible :term:`gimbal lock`.
Axis Angle
The X, Y, and Z coordinates define a point relative to the object origin.
This point and the origin define a axis around the W value defines the rotation.
Quaternion
X, Y, Z and W correspond to the :term:`Quaternion` components.

Scale
The object's relative scale along the local axis
(e.g. the *Scale X* value represents the scale along the local X-axis).
Each object (cube, sphere, etc.), when created, has a scale of one Blender unit in each local direction.
To make the object bigger or smaller, you scale it in the desired axis.
Dimensions
The size of the objects bounding box.
(aligned with the local axes -- think of a cardboard box just big enough to hold the object).

Transform Properties Locking
----------------------------

When the toggle is locked, the corresponding transformation value can not be changed in any interactive operation.
However, the value can still be changed using non-interactive operations,
like editing the corresponding number button or using Python.

For example, if you locked the *Location X* property then you cannot use the 3D manipulator to
translate the object along the global X axis.
However, you can still translate it using the *Location X* number button.
Consider the locking feature as a rigid constraint only changeable from the panel.

To lock a property, click the padlock icon next to the button.
The button is unlocked if the icon shows a open padlock,
and it is locked if the icon appears as a closed padlock.

.. _transform-delta:

Delta Transforms
================

Delta Transforms are simply transformations that are applied on top of the transforms described above.
They can be found in the :menuselection:`Properties Editor --&gt; Object --&gt; Delta Transforms`.

Usage
-----

Delta Transforms are particularly useful in animations. For example,
you can animate an object with the "normal" transforms then move them around with Delta Transforms.

############
Selecting
############

.. toctree::
:maxdepth: 2

introduction.rst
tools.rst
menu.rst

************
Introduction
************

Selection determines which elements will be the target of our actions.
Selections work on the current scene visible objects.
Blender has advanced selection methods. Both in *Object Mode* and in *Edit Mode*.

.. _object-active:

Selections and the Active Object
================================

Blender distinguishes between two different states of selection:

.. figure:: /images/editors_3dview_selecting_color.png

Unselected object in black, selected object in orange, and active object in yellow.

In *Object Mode* the last (de)selected item is called the "Active Object"
and is outlined in yellow (the others are orange).
There is exactly one active object at any time (even when nothing is selected).

Many actions in Blender use the active object as a reference (for example linking operations).
If you already have a selection and need to make a different object the active one,
simply re-select it with :kbd:`Shift-RMB`.

All other selected objects are just selected. You can select any number of objects.
In order to change a property or to perform an operation on all selected objects (bones, and sequencer-strips)
hold :kbd:`Alt`, while confirming.

****
Menu
****

There are also many more options accessible through the *Select* menu of the 3D View.
Each is more adapted to certain operations.

.. _select-grouped:

Select Grouped
==============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Select --&gt; Grouped`
| Hotkey:   :kbd:`Shift-G`

There are two ways to organize the objects in relation to one another.
The first one is *parenting*, and the second is simple *grouping*.
These relationships to an artist's advantage by selecting members of respective families or groups.
*Select Grouped* uses the active object as a basis to select all others.

Options
-------

Children
Selects all hierarchical descendants of the active object.
Immediate Children
Selects all direct children of the active object.
Parent
Selects the parent of this object if it has one.
Siblings
Select objects that have the same parent as the active object.
This can also be used to select all root level objects (objects with no parents).
Type
Select objects that are the same type as the active one.
Layer
Objects that have at least one shared layer.
Group
Objects that are part of a group (rendered green with the default theme)
will be selected if they are in one of the groups that the active object is in.
If the active object belongs to more than one group,
a list will pop up so that we can select which group to select.
Object Hooks
Every hook that belongs to the active object.
Pass
Select objects assigned to the same :ref:`render pass &lt;render-cycles-passes&gt;`.
Color
Select objects with same :ref:`Object Color &lt;objects-display-object-color&gt;`.
Properties
Select objects with same :doc:`Game Engine Properties &lt;/game_engine/logic/properties&gt;`.
Keying Set
Select objects included in the active :doc:`Keying Set &lt;/animation/keyframes/keying_sets&gt;`.
Lamp Type
Select matching lamp types.
Pass Index
Select matching object pass index.

Select Linked
=============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Select --&gt; Linked`
| Hotkey:   :kbd:`Shift-L`

Selects all objects which share a common data-block with the active object.
*Select Linked* uses the active object as a basis to select all others.

Options
-------

Object Data
Selects every object that is linked to the same Object Data, i.e.
the data-block that specifies the type (mesh, curve, etc.) and the build
(constitutive elements like vertices, control vertices, and where they are in space) of the object.
Material
Selects every object that is linked to the same material data-block.
Texture
Selects every object that is linked to the same texture data-block.
Dupligroup
Selects all objects that use the same *Group* for duplication.
Particle System
Selects all objects that use the same *Particle System*.
Library
Selects all objects that are in the same :doc:`Library &lt;/data_system/linked_libraries&gt;`
Library (Object Data)
Selects all objects that are in the same :doc:`Library &lt;/data_system/linked_libraries&gt;`
and limited to *object data*.

Select All by Type
==================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Select --&gt; Select All by Type`
| Hotkey:   None

With this tool, it becomes possible to select objects of a certain type in one go.

Options
-------

The types are Mesh, Curve, Surface, Meta, Font,
Armature, Lattice, Empty, Camera, Lamp, Speaker.

Select All by Layer
===================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Select --&gt; Select All by Layer`
| Hotkey:   None

.. figure:: /images/editors_3dview_select_allbylayer.png
:align: right

All by Layer selection menu.

This option allows the selection of every single object that belongs to a given layer.
Selected objects become visible.

.. Comment: Not implemented yet?:
This selection is added to anything that was already selected at that moment.

Options
-------

Match
The match type for selection.
Extend
Enable to add objects to current selection rather than replacing the current selection.
Layer
The layer on which the objects are.

.. tip:: Selection of Objects

Rather than using the :menuselection:`Select All by Layer` option,
it might be more efficient to make the needed layers visible and use :kbd:`A` on them.
This method also allows objects to be deselected.

More/Less
=========

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:     :menuselection:`Select --&gt; More/Less`
| Hotkey:   :kbd:`Ctrl-NumpadPlus`, :kbd:`Ctrl-NumpadMinus`

Their purpose, based on the hierarchical.

More
Select connected parent/child objects.
Less
Deselect objects at the boundaries of parent/child relationships.
Parent
ToDo.
Child
ToDo.
Extend Parent
Extends the selection to the parent of the selection.
ToDo: active object.
Extend Child
ToDo.

Other Menu Options
==================

Available options on the first level of the menu are:

(De)select All :kbd:`A`
If anything was selected it is first deselected.
Otherwise it toggles between selecting and deselecting every visible object.

Action
Select, Deselect, Invert, Toggle
Inverse :kbd:`Ctrl-I`
Selects all objects that were not selected, while deselecting all those which were.
Random
Randomly selects unselected objects based on percentage probability on currently active layers.
On selecting the operator a numerical selection box becomes available in the *Tool Shelf*.
It is important to note that the percentage represents the likelihood of an unselected object being
selected and not the percentage amount of objects that will be selected.
Mirror :kbd:`Shift-Ctrl-M`
Select the Mirror objects of the selected object, based on their names.
e.g. "sword.L" and "sword.R".
Select Camera
Select the active camera.
Select Pattern
Selects all objects whose name matches a given pattern.
Supported wildcards: \* matches everything, ? matches any single character,
[abc] matches characters in "abc", and [!abc] match any character not in "abc".
As an example \*house\* matches any name that contains "house",
while floor\* matches any name starting with "floor".

Case Sensitive
The matching can be chosen to be case sensitive or not.
Extend
When *Extend* checkbox is checked the selection is extended instead of generating a new one.

*****
Tools
*****

Point Selection
===============

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Hotkey:   :kbd:`RMB` and :kbd:`Shift-RMB`

The simplest form of object *selection* consists of using :kbd:`RMB` on it.

To *add to the selection*, use :kbd:`Shift-RMB` on more objects.

If the *objects are overlapping* in the view,
you can use :kbd:`Alt-RMB` to cycle through possible choices (*Object Mode* only).

If you want *to add to a selection* this way then the shortcut becomes :kbd:`Shift-Alt-RMB`.

To *activate an object* that is already selected, click :kbd:`Shift-RMB` on it.

To *deselect* an active object,
click :kbd:`Shift-RMB` one time and hence, two clicks if the object is not active.
Note that this only works if there are no other objects under the mouse.
Otherwise it just adds those to the selection. There appears to be no workaround for this bug.

.. _select-border:

Border Select
=============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Menu:     :menuselection:`Select --&gt; Border Select`
| Hotkey:   :kbd:`B`

To activate the tool use the :kbd:`B`.
With *Border Select* you draw a rectangle while holding down :kbd:`LMB`.
Any object that lies even partially within this rectangle becomes selected.
If any object that was last active appears in the selection it will become active.

For deselecting objects,
use :kbd:`MMB` or *Border Select* again with holding :kbd:`Shift` or :kbd:`Alt`.

To cancel the selection use :kbd:`RMB`.

Example
-------

.. figure:: /images/object-selection-border.jpg

Border selecting in three steps.

*Border Select* has been activated in the first image and is indicated by showing a dotted cross-hair cursor.
In the second image, the *selection region* is being chosen by drawing a rectangle with the :kbd:`LMB`.
The rectangle is only covering two cubes.
Finally, in the third image, the selection is completed by releasing :kbd:`LMB`.

Notice in the third image, the bright color of left-most selected cube.
This means it is the "active object",
the last selected object prior to using the *Border Select* tool.

.. hint::

*Border Select* adds to the previous selection, so in order to select only the contents of the rectangle,
deselect all with :kbd:`A` first.

.. _select-circle:

Circle Select
=============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Menu:     :menuselection:`Select --&gt; Circle Select`
| Hotkey:   :kbd:`C`

*Circle Select* :kbd:`C` is used by moving with dotted circle through objects with :kbd:`LMB`.
You can select any object by touching of circle area.
It is possible to dynamically change the diameter of circle by scrolling :kbd:`Wheel`
or with :kbd:`NumpadPlus` and :kbd:`NumpadMinus` as seen in pictures below.
Deselection is under the same principle -- :kbd:`MMB`.
To cancel the selection use :kbd:`RMB` or key :kbd:`Esc` or :kbd:`Enter`.

.. list-table::

* - .. figure:: /images/object-selection-circle1.png
:width: 320px

Circle selection.

- .. figure:: /images/object-selection-circle2.png
:width: 320px

...with huge circle.

Lasso Select
============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Menu:     no entry in the menu
| Hotkey:   :kbd:`Ctrl-LMB`

Lasso select is used by drawing a dotted line around vertices or
the origin of the objects, in *Object Mode*.

While holding :kbd:`Ctrl` down, you simply have to draw around the points
you want to select with :kbd:`LMB`.

Lasso select adds to the previous selection. For deselection, use :kbd:`Ctrl-Shift-LMB`.

.. figure:: /images/object-selection-lasso.png

Lasso selection example.
.. _objects-types:

************
Object Types
************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Create --&gt; Add Primitive`
| Menu:     :menuselection:`Add`
| Hotkey:   :kbd:`Shift-A`

New objects can be created with the *Add* menu in the 3D Views header.

Mesh
:doc:`Meshes &lt;/modeling/meshes/introduction&gt;` are objects composed of Polygonal Faces, Edges and/or Vertices,
and can be edited extensively with Blender's mesh editing tools.
See :doc:`Mesh Primitives &lt;/modeling/meshes/primitives&gt;`.
Curve
:doc:`Curves &lt;/modeling/curves/introduction&gt;` are mathematically defined objects
which can be manipulated with control handles or control points (instead of vertices),
to manage their length and curvature. See :doc:`Curves Primitives &lt;/modeling/curves/primitives&gt;`.
Surface
:doc:`Surfaces &lt;/modeling/surfaces/introduction&gt;` are patches that are also manipulated with control points.
These are useful for simple rounded forms and organic landscapes.
See :doc:`Surfaces Primitives &lt;/modeling/surfaces/primitives&gt;`.
Metaball
:doc:`Meta Objects &lt;/modeling/metas/introduction&gt;` (or Metaballs) are objects formed by a mathematical function
(with no control points or vertices)  defining the 3D volume in which the object exists.
Meta Objects have a liquid-like quality, where when two or more Metaballs are brought together,
they merge by smoothly rounding out the connection, appearing as one unified object.
See :doc:`Meta Primitives &lt;/modeling/metas/primitives&gt;`.
Text
:doc:`Text objects &lt;/modeling/texts/introduction&gt;`
create a two dimensional representation of a string of characters.
Armature
:doc:`Armatures &lt;/rigging/armatures/index&gt;` are used for :doc:`rigging &lt;/rigging/introduction&gt;`
3D models in order to make them poseable and animateable.
Lattice
:doc:`Lattices &lt;/rigging/lattice&gt;` are non-renderable wireframes, commonly used for taking additional control
over other objects with help of the :doc:`Lattice Modifier &lt;/modeling/modifiers/deform/lattice&gt;`.
Empty
:doc:`Empties &lt;/modeling/empties&gt;` are null objects that are simple visual transform nodes that do not render.
They are useful for controlling the position or movement of other objects.
Speaker
:doc:`Speaker &lt;/render/audio/speaker&gt;` brings to scene source of sound.
Camera
This is the virtual camera that is used to determine what appears in the render.
See Cameras in :doc:`Blender Internal &lt;/render/blender_render/camera/index&gt;`
and :doc:`Cycles &lt;/render/cycles/camera&gt;`.
Lamp
These are used to place light sources in the scene.
See Lamps in :doc:`Blender Internal &lt;/render/blender_render/lighting/lamps/index&gt;`,
:doc:`Cycles &lt;/render/cycles/lamps&gt;`.
Force Field
:doc:`Force Fields &lt;/physics/force_fields/index&gt;` are used in physical simulations.
They give simulations external forces, creating movement,
and are represented in the 3D View editor as small control objects.
Group Instance
Lets you select from a list of existing object groups.
Once selected, an Empty object will be created, with an instance of the selected group (group duplication active).
See :doc:`/editors/3dview/object/properties/duplication/dupligroup`.

.. _object-common-options:

Common Options
==============

You can change the options of the object in the Operator panel just after creating it:

Type
Some objects let you change its type after creation with a selector.
Radius/Size
Sets the starting size.

.. from the center to what? compare plane to circle (3 vertices)

Align to View
By default objects are aligned to the global space axes.
This option rotates the new object so that it is aligned to the view space.
Location
Objects are placed, by default, at the position of the 3D Cursor.
These values let you place the object in an other position.
Rotation
Values let you rotate the object so that default rotation is overridden.

*****************
Background Images
*****************

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties region --&gt; Background Image`

A background picture in your 3D View is very helpful in many situations:
modeling is obviously one, but it is also useful when painting (e.g.
you can have reference pictures of faces when painting textures directly on your model...),
or animation (when using a video as background), etc.

.. note::

Background images are only available for orthographic views.

Settings
========

.. figure:: /images/editors_3dview_background_images.png

Axis
Choose which views the image is visible from.
This is helpful when you have several reference images from different views (e.g. top, front and side).
Data Source
The source of the background image.

Image
Use an external image, image sequence, video file or generated texture.
Movie Clip
Use one of the Movie Clip data-blocks.
Opacity
Controls the transparency of the background image.
Front/Back
Choose whether the image is shown behind all objects, or in front of everything.
Stretch/Fit/Crop
Controls how the image is placed in the camera view.

Stretch
Forces the image dimensions to match the camera bounds (may alter the aspect ratio).
Fit
Scales the image down to fit inside the camera view without altering the aspect ratio.
Crop
Scales the image up so that it fills the entire camera view,
but without altering the aspect ratio (some of the image will be cropped)
X/Y
Positions the background image using these offsets.

In orthographic views, this is measured in the normal scene units.
In the camera view, this is measured relative to the camera bounds
(0.1 will offset it by 10% of the view width/height)
Flip Horizontally
Swaps the image around, such that the left side is now on the right, and the right now on the left.
Flip Vertically
Swaps the image around, such that the top side is now on the bottom, and the bottom now on the top.
Rotation
Rotates the image around its center.
Size
Scales the image up or down from its center.

##############
Properties
##############

.. toctree::
:maxdepth: 2

panels.rst
shading.rst
background_images.rst

***********************
Display and View Panels
***********************

Display Panel
=============

This panel lets you configure some visualization parameters of the viewport.

Only Render
Displays only items that will be rendered.
This option hides visualizations, overlays, the 3D cursor, and the grid floor.
The :doc:`3D manipulator widget &lt;/editors/3dview/object/editing/transform/control/manipulators&gt;`
has to be toggled separately.

This can be useful for a preview and for :doc:`OpenGL &lt;/render/opengl&gt;` viewport rendering.

.. note::

While the option displays the regular view-port without distracting elements,
the objects displayed are **not** matching the final render output.

Options such as restrict-render, modifiers render option,
dupli-parents and render layers are not taken into account.

Outline Selected
If disabled, the orange outline around your selected objects in
*Solid*, *Shaded*, *Textured* draw types will no longer be displayed.
World Background
Creates an estimation of what the world background will look like and uses it to draw the background.
All Object Origins
Forces the origin dot of objects to always be visible, even for non-selected objects
(by default, unselected objects' origins might be hidden by geometry in solid/shaded/textured shadings).
Relationship Lines
Controls whether the dashed parenting, constraining, hooking, etc., lines are drawn.
Grid Floor
Grid Floor is a finite grid which is shown in other views than the aligned orthographic (top, front, side).
It lays on the global XY plane. The checkbox lets you show or hide that grid.
In aligned orthographic views an infinite grid is shown.

Axis
Controls which global axes are shown as colored lines (Grid floor only).
Their length depend on the defined size of that grid.

X, Y, Z
Lines
Controls the total number of lines that make the grid, in both directions
(odd values will be rounded down).
Scale
Controls the distance between the grid lines.
Subdivisions
Controls the number of sub-lines that appear in each cell of the grid.
In aligned orthographic views the level of subdivision depend on the zoom.
Toggle Quad View
Toggles the four view 3D View.
:doc:`Read more about arranging areas &lt;/interface/window_system/areas&gt;`.

View Panel
==========

The *View Properties* panel lets you set other settings regarding the 3D View.
You can show it with the :menuselection:`View --&gt; View Properties...` menu entry.

Lens
Control the focal length of the 3D View camera in millimeters,
unlike a :doc:`rendering camera &lt;/render/blender_render/camera/index&gt;`.
Lock to Object
Lock to Object lets you define an object in the *Object* Data ID as the center of the view.
In that case, the view can be rotated around or zoomed towards that central object,
but not on translation, unless you translate that itself object 
(this option is not available in a camera view).
Lock to Cursor
Lock the center of the view to the position of the 3D cursor.
It is only available when *Lock to Object* is not active.

.. _3dview-lock-camera-to-view:

Lock Camera to View
When in camera view, all changes in the view (pans, rotations, zooms) will affect the active camera,
which will follow all those changes. The camera frame will be outlined with an red dashed line.

.. _3dview-view-clip:

Clip Start and Clip End
Adjust the minimum and maximum distances range to be visible for the viewport camera.
Objects outside the range will not be shown.

.. note::

A large clipping range will allow you to see both near and far objects,
but reduces the depth precision resulting in artifacts.

See :ref:`Troubleshooting Depth Buffer Glitches &lt;troubleshooting-depth&gt;` for more information.

Local Camera
Active camera used in this view to override the (global) scene camera.
The option is available only when *lock local camera and layers* toggle in the header is not enabled.
Render Border
Use a Render Border when not looking through a camera.
Using :kbd:`Ctrl-B` to draw a border region will automatically enable this option.

*******
Shading
*******

.. _view3d-viewport-shading:

Viewport Shading
================

.. admonition:: Reference
:class: refbox

| Header:   :menuselection:`Viewport Shading`

.. figure:: /images/interface_popup-menu.jpg
:align: right

The Viewport Shading menu.

Shading refers to the way objects are drawn and lit in the 3D View.

Bounding Box
Only shows rectangular boxes that outline an object's size and shape.
Wireframe
Objects appear as a mesh of lines representing the edges of faces and surfaces.
Solid
The default drawing mode using solid colored surfaces and simple lighting.
Textured
Shows meshes with an image applied using the mesh's active UV Map.
For Cycles materials, the image is the last one selected in the
:doc:`Node Editor &lt;/editors/node_editor/index&gt;`. For other render engines,
the UV Map's applied face texture will be shown.
Material
A fast approximation of the applied material.
Rendered
An accurate representation using the selected *Render Engine* and lit with the visible scene lights.

Except for *Rendered*, these shading modes are not dependent on light sources in the scene.
Instead they use a simple default lighting adjusted by the *Solid OpenGL Lights*
controls on the *System* tab of the :doc:`User Preferences &lt;/preferences/system&gt;` editor.

The viewport shading controls the appearance of all objects in a scene,
but this can be overridden for individual objects using the *Display panel* in their *Object Properties*.

.. rubric:: Keyboard Shortcuts

.. list-table::
:stub-columns: 1
:class: valign
:widths: 80 20

* - Switches between *Wireframe* and *Solid* draw modes.
- :kbd:`Z`
* - Switches between the current and *Rendered* draw modes.
- :kbd:`Shift-Z`
* - Switches between *Solid* and *Textured* draw modes.
- :kbd:`Alt-Z`

Shading Panel
=============

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties region --&gt; Shading`

.. figure:: /images/editors_3dview_display_shading.png
:align: right

3D View Shading Panel.

The shading panel in the Properties Region provides additional control over the way objects in the 3D View appear.

Textured Solid
Display assigned :ref:`face textures &lt;face-textures&gt;` in the *Solid* shading mode.
(*not* available in the Cycles Render Engine).
Shadeless
Textured mode only -- Draws textures without shading. Its most common use case is texture painting.
Matcap
"Matcaps" are images mapped on a normal.
It provides a quick way to define visible material properties for modeling and sculpting.
Because Matcap rendering fully bypasses the material shader code, it's a very fast rendering option.
The selected Matcap is a setting per 3D View. This way you can have multiple views drawing different Matcaps.
(Solid Viewport shading only).
Backface Culling
Only show the front side of faces. Use this to find faces flipped the wrong way,
especially when exporting to programs that use single sided drawing.
Hidden Wire
Show only front-facing wireframes. This is useful for a retopology workflow.
Tip: Optimally this could be combined with the *X-Ray* display setting.
(Mesh, Edit Mode only).
Depth of Field
Simulates a camera's focal blur effect in the 3D View. This is only visible in a camera view.
Control the effect using these options in the :ref:`Properties Tab &lt;camera-settings&gt;`
of the active camera: Focal Length, Sensor Size, Focus Object or Focus Distance, and Viewport F-stop.
Ambient Occlusion
Improves the realism of the viewport image by simulating the darkening effect that
occurs in crevices and corners. This is done by raycasting in screen space.
Typically such effects are rendered at higher quality,
but this is a quick real-time preview which can help when modeling or sculpting.

Strength
This factor directly multiplies the computed color of the effect,
so increasing this value gives a stronger effect.
Distance
The maximum world space distance the effect is computed in.
I.e. how far out of the corners does the effect extend.
Attenuation
How strongly the effect attenuates with distance.
Increasing this makes far away surfaces contribute less to the effect.
Use this to get rid of some banding artifacts.
Samples
The number of samples used for the effect.
Low numbers produce a grainy effect, but the actual number used is squared so use high numbers with caution.
Color
Color of the effect, can be modified to give a different feel, from ambient lighting to dirt/rust.

*************
Startup Scene
*************

After closing the splash the startup scene is displayed in the 3D View,
if no other blend-file was loaded. A customized startup scene
can be saved as a part of the :doc:`startup file &lt;/data_system/files/startup_file&gt;`.

.. figure:: /images/editors_3dview_startup_scene.png

The Startup scene.

Elements
========

Cube
The gray cube in the center of the scene is a :doc:`mesh &lt;/modeling/meshes/index&gt;` object.
Because the cube is selected it is drawn with an orange outline.

Object Origin
The :doc:`Origin of the object &lt;/editors/3dview/object/origin&gt;` is displayed as
an orange dot and it marks the cube's (relative) position.
Transformation Widget
This :doc:`widget &lt;/editors/3dview/object/editing/transform/control/manipulators&gt;`
is composed out of a white circle and three colored (red, green, and blue) arrows.
It is used to move entities (e.g. the cube) in the scene.
Lamp
The circle with a thin line to the bottom is a light source illuminating the cube.
Lights in: :doc:`Blender Internal &lt;/render/blender_render/lighting/lights/index&gt;`,
:doc:`Cycles &lt;/render/cycles/lamps&gt;`.

Camera
The pyramid with a big triangle pointing upward is the camera used as point of view for rendering.
Cameras in :doc:`Blender Internal &lt;/render/blender_render/camera/index&gt;`, :doc:`Cycles &lt;/render/cycles/camera&gt;`.
3D Cursor
The :doc:`3D cursor &lt;/editors/3dview/3d_cursor&gt;`, a cross with a red and white circle,
is used for placing objects in the scene.
Grid Floor
The gray squares forming a floor mark the zero height of the world.
The red and green lines are the axis of the world coordinate system.
They meet at the origin, which is also the position of the *Cube*.
The Grid Floor settings are in the :doc:`Display panel &lt;/editors/3dview/properties/panels&gt;`.

.. figure:: /images/editors_3dview_startup_scene_single.png

The elements of the startup scene.

Overlays
========

The visibility and settings of the overlays can be set in the :doc:`User Preferences &lt;/preferences/interface&gt;`.

View Name
If the viewport camera is not aligned, the view is named "User" plus
the perspective of the viewport camera.
Playback FPS
Displays the Frames Per Second screen rate, while playing an animation back.
Mini Axis
Shows the axes of world coordinate system as plain lines with name.
Object Info
Shown in brackets is the current frame. Followed by the name of the :ref:`active object &lt;object-active&gt;`.
And optionally the selected :doc:`shape key &lt;/animation/shape_keys/index&gt;` and
in brackets (&lt;&gt;) the :doc:`/animation/markers` name on the current frame.
The color of the Object Info is set by the :ref:`animation-state-colors` (keyframe only).

.. (todo) rendering the startup scene
..    TODO/Review: {{review|partial=X}}.

*************
Action Editor
*************

The *Action Editor* enables you to see and edit the F-Curve data-blocks you defined
as :doc:`Actions &lt;/animation/actions&gt;` in the *F-Curve Editor*.
So it takes place somewhere in-between the low-level
:doc:`F-Curves &lt;/editors/graph_editor/introduction&gt;`, and the high-level :doc:`NLA editor &lt;/editors/nla/index&gt;`.

It gives you a slightly simplified view of the F-Curve data-blocks
(somewhat similar to F-Curve drawn without handles).
The editor can lists all Action data-blocks of an object at once.

Each Action data-block forms a top-level channel (see below).
Note that an object can have several *Constraint* (one per animated constraint)
and *Pose* (for armatures, one per animated bone) F-Curve data-blocks,
and hence an action can have several of these channels.

..
:doc:`Action constraint &lt;/rigging/constraints/relationship/action&gt;` or
the :doc:`pose libraries &lt;/rigging/armatures/properties/pose_library&gt;`

.. figure:: /images/editors_dopesheet_action-editor.png

The Action Editor.

Header
======

Layer Previous/Next (down/up arrow peak icon)
Switch between different actions stacked/stashed on top of each other in the NLA Stack,
without having to go to the NLA Editor and leaving tweak mode and reentering it on the other strip.

Clicking on the up/down arrow buttons to go to the action in the NLA Track above/below the NLA Strip being
whose action is being tweaked in the Action Editor.

If there are multiple actions/strips on the same layer/track,
then only the one closest to the current frame will be used.

The operators will take into account the settings to view/edit the action in isolation (i.e. Solo and NLA Muting).
This was done to make it easier to preview different stashed actions.

- If moving from a solo'd NLA Track to the active action,
the NLA stack will be muted so that the action can be edited in isolation.
- Likewise, if the NLA stack is muted when editing the action action,
the NLA Track below it will be edited with solo enabled.
- If switching between NLA Tracks, the solo status for the previous track will be transferred to the new track.

.. note::

These still work when you're not editing the action used by a NLA Strip.
If you're just animating a new action normally,
it is possible to use the "down arrow" to temporarily jump down to the previous action
without losing the new action you're working on, and then use the "up arrow" to get back to
it once you're done checking the other action(s).

.. _dopesheet-action-action:

Action
A :ref:`Data-block menu &lt;ui-data-block&gt;`.

Add ``+``
When an action is created it is stored in a NLA Action Stash.
Unlink ``X``
When :kbd:`Shift-LMB` clicking it clears the Fake User and
removes the stashed action from the NLA stack too.
Push Down (double down arrow peak icon)
Adds the active action on to the NLA stack as a contributing strip.
This is basically the same as pressing the Push Down button in the NLA Editor.
Stash (Snowflake icon)
Stashes the active action on to the NLA stack. i.e. it is added as a non-contributing stack
in the same way that it would if you were creating a new action instead.

.. note::

In both of these cases (Push Down and Stash), once the action has been added to the NLA stack,
it is cleared/unassigned from the active action slot
(i.e. it cannot be edited anymore from the Action/Graph Editors,
unless you enter "Tweak Mode" on the corresponding strips later).

*************
Grease Pencil
*************

It is possible to set a :doc:`grease pencil &lt;/interface/grease_pencil/introduction&gt;` block
to be loaded up in the *Dope Sheet* for editing of the timings of the drawings.

This is especially useful for animators blocking out shots,
where the ability to re-time blocking is one of the main purposes of the whole exercise.

This mode can be accessed by change the Dope Sheet editor's *Mode* selector (found beside the menus)
to *Grease Pencil*.

.. figure:: /images/editors_dopesheet_greasepencil.png
:width: 598px

Channels Region
===============

Grease Pencil (light blue)
The channels region shows the Grease Pencil data-blocks containing the layers.
Multiple blocks are used for each area (e.g. one for the 3D View and the UV/Image editor).
Layers (gray)
This channels contain the keyframes to which the layers are bind.

Header
======

Active Only
Only show the Grease Pencil blocks attached to the current scene and the objects within it.

Copying Sketches
----------------

It is possible to copy sketches from a layer/layers to other layers
using the "Copy"/"Paste" buttons in the header.
This works in a similar way as the copy/paste tools for keyframes in the *Action Editor*.

Sketches can also be copied from data-block to another using these tools.
It is important to keep in mind that keyframes will only be pasted into selected layers,
so layers will need to be created for the destination areas too.

Main View
=========

The keyframes can be manipulated like any other data in the *Dope Sheet* can be.

Insert Keyframe
---------------

Insert Keyframe :kbd:`I` can be used for creating blank Grease Pencil frames at a particular frame.
It will create blank frames if *Additive Drawing* is disabled, otherwise
it will make a copy of the active frame on that layer, and use that.

.. _editors-dope-sheet-index:

##############
Dope Sheet
##############

.. toctree::
:maxdepth: 2

introduction.rst
action.rst
grease_pencil.rst
shapekey.rst

************
Introduction
************

.. figure:: /images/editors_dopesheet_overview.jpg
:width: 400px

The Dope Sheet.

Classical hand-drawn animators often made a chart, showing exactly when each drawing,
sound and camera move would occur, and for how long. They nicknamed this the "dope sheet".
While CG foundations dramatically differ from classical hand-drawn animation,
Blender's *Dope Sheet* inherits a similar directive.
It gives the animator a "birds-eye-view" of every thing occurring within a scene.

Dope Sheet Modes
================

.. figure:: /images/editors_dopesheet_modes.jpg

Dope Sheet Modes.

There are four basic views for the Dope Sheet. These all view different contexts of animation:

Dope Sheet
The Dope Sheet Mode allow you to edit multiple actions at once.
Action Editor
:doc:`Action Editor &lt;/editors/dope_sheet/action&gt;` is where you can define and control actions.
Shape Key Editor
:ref:`ShapeKey Editor &lt;dope-sheet-shape-key&gt;` is dedicated to the shape key data-blocks.
Grease Pencil
:doc:`Grease Pencil &lt;/editors/dope_sheet/grease_pencil&gt;` Mode is dedicated to
the :doc:`grease pencil tool's &lt;/interface/grease_pencil/index&gt;`
keyframes for each :doc:`grease pencil layer &lt;/interface/grease_pencil/drawing/layers&gt;`,
you have a strip along which you can grab its keys,
and hence easily re-time your animated sketches.
Mask
:ref:`Mask &lt;dope-sheet-mask&gt;` Mode is dedicated to the mask data-blocks.
Cache File
Todo.

Interface
=========

The *Dope Sheet Editor* interface is somewhat similar to the *Graph Editor*
one, it is divided in three regions:

.. figure:: /images/editors_dopesheet_action-editor.png
:width: 600px

The Action Editor with object channels.

Header
------

Here you find the menus, a first block of controls related to the editor "mode",
a second one concerning the action data-blocks, and a few other tools
(like the copy/paste buttons, and snapping type).

Summary
ToDo.

View Menu
^^^^^^^^^

Sync Markers
Sync Markers with keyframe edits.

See Graph editor's :ref:`graph-view-menu`.

Marker Menu
^^^^^^^^^^^

See the :doc:`Markers page &lt;/animation/markers&gt;`.

Key Menu
^^^^^^^^

Keyframe Type :kbd:`R`
Sets the :ref:`keyframe-type` of the selected keyframes.

See :doc:`F-Curve &lt;/editors/graph_editor/fcurves/index&gt;`.

Main Region
-----------

It contains the keyframes for all visible action channels.
As with the other "time" editor, the X-axis represents time.
The Y-axis has no mean in itself, unlike with the *Graph Editor*, it is a "stack" of action channels.

Each one being shown as an horizontal colored strip (of a darker shade "during" the animated/keyed period).
On these channel strips lay the keyframes, visualized as light-gray (unselected) or yellow (selected) diamonds.

One of the key feature of this editor is that it allow you to visualize immediately which channel (i.e. F-Curve)
is *really* affected. When the value of a given channel does not change at all between two neighboring keyframes
("long keyframes"), a gray (unselected) or yellow (selected) bar is drawn between them.
Similar bars are drawn between keyframes tagged as moving hold.

Channels Region
---------------

.. _fig-dope-sheet-action:

.. figure:: /images/editors_dopesheet_action-editor-sliders.png

The Action editor's channels region.

See :doc:`/editors/graph_editor/channels`.
.. (todo) rename

*********
Shape Key
*********

.. _dope-sheet-shape-key:

Shape Key Editor
================

Shape Key Editor is used to adjust the animation timing of :doc:`shape keys &lt;/animation/shape_keys/index&gt;`.
These are stored inside a Action data-block. It lets you edit the :ref:`value &lt;animation-shapekey-relative-value&gt;`
of relative shape keys.

This mode of the Dope Sheet using a similar interface as the :doc:`/editors/dope_sheet/action` Mode
with the distinction of the absence header filter controls and tools for channels.

.. _dope-sheet-mask:

Mask
====

In the Dope Sheet's Mask Mode mask shape keyframes can be selected and edited.
All Mask data-blocks in the blend-file are shown.

################
File Browser
################

.. toctree::
:maxdepth: 2

introduction.rst
previews.rst

************
Introduction
************

.. figure:: /images/editors_file_editor.png

The File Browser.

Usage
=====

The File Browser is used in all the file-related operations.
It has multiple use cases, while its often used for save/load.

These include:

- Opening and Saving Blend files.
- Import/Export other file formats.
- Picking new locations for existing file-paths (images, video, fonts...).
- Browsing inside other blend-files, when using :doc:`Linked Libraries &lt;/data_system/linked_libraries&gt;`.

You can also keep the File Browser open, as with any other editor type,
to browse through the file system. In this case, confirm/cancel buttons will be absent.

The main purpose of this is to be able to drag media files:

- Images into the :ref:`editors-sequencer-index` (to set background or apply as material textures).
- Media files into the :ref:`editors-sequencer-index`.

On the other hand, if the File Browser is opened for a file action (opening, saving, importing, etc.),
it will appear maximized and waiting for an operation to complete before returning to the former screen layout.

.. _file-browser-open-sequence:

Opening an Image Sequence
-------------------------

The filename of the images must contain a digit, indicating the frame.
The sequence could be opened by the selection of the images and
by the confirmation with the *Open Image* button or :kbd:`Enter`.

.. To load image sequence in any of the supported image
file formats, first click on the first frame and then Accept.
Then change the Source to Image Sequence, and enter the ending frame number of this sequence.

Header
======

Navigation icon buttons
Tools for navigation of files.

Left Arrow :kbd:`Backspace`
Move to previous folder.
Right Arrow :kbd:`Shift-Backspace`
Move to next folder.
Up Arrow :kbd:`P`
Move up to parent directory.
Cycle Arrows :kbd:`R`, :kbd:`NumpadPeriod`
Refresh current folder.

Create Directory
Prompts you to enter the name of a newly created directory inside the current one :kbd:`I`.
Recursion
The number of directory levels to show at once in a flat way.

- None (only the current directory)
- Blend File (inside blend-files)
- One level
- Two Levels
- Three levels

Display type
Controls how files are displayed.

- Short list
- Detailed list
- Thumbnails (show :doc:`previews &lt;/editors/file_browser/previews&gt;`)
Display size
The size of thumbnails or the width of columns.

Tiny, small, normal, large
Sorting
Sorts files by on of the following methods:

- Alphabetically
- By file type
- By date of last edit
- By file size
Show hidden
Shows hidden files (starting with ``.``) :kbd:`H`.
File filtering
File Type
Filters files by type.

- Folders
- blend-files
- Backup blend-files
- Image files
- Movie files
- Script files
- Font files
- Sound files
- Text files

Data-Block Type
Data-block type filtering inside blend-files.
Search box
Filter files by name.

File Region
===========

File Path
The text field for the current path.
:kbd:`Tab` will auto-complete an existing path.
If you type a non existing directory path, you will be prompted to create that new directory.
File Name
Text field to edit the file name and extension.
If the background is red, a file with same name already exist in the folder.
:kbd:`Tab` will auto-complete to existing names in the current directory.
Increment Filename ``+``, ``-``
Adds/increase or removes/decreases a trailing number to your file name
(use to make *versions* of a file).
Confirm
The main button to Open Directory/File or Save (As) :kbd:`Enter` or
double click with :kbd:`LMB` on the entry confirms with that file or data-block.

- :kbd:`Shift-LMB` -- Open the file externally (selected in :doc:`/preferences/file`).
- :kbd:`Alt-LMB` -- Open the directory externally (using the system's file manager).
Cancel
Cancels the Open or Save file selection and closes the File browser :kbd:`Esc` or
by using the *Back to Previous* in the Info editor header.

Tool Shelf
==========

The left region displays different ways to find files and several options.
Clicking with :kbd:`LMB` on one of the entries, the File Browser will navigate to that folder.

System
------

The system panel contains a list of drives that are available
to navigate through to find files.

System Bookmarks
----------------

Bookmarks that are common for a particular operating system.

Bookmarks
---------

A :ref:`List View &lt;ui-list-view&gt;` of shortcuts to folders,
that you want to be able to access often without having to navigate to them in the file browser.

Add ``+``
This button adds the current directory to the list.

Recent
------

This is a list of recently accessed folders. You can control how many folders appear in this
list by going to the *File* tab of the :doc:`User Preferences &lt;/preferences/file&gt;`,
in the *Recent Files* number button.

Operator Panel
--------------

Link/Append from Library
See :doc:`Linked libraries &lt;/data_system/linked_libraries&gt;`.
Open, Save, Save As Blender File
See :doc:`/data_system/files/open` or :doc:`/data_system/files/save`.
Open, Replace, Save As Image
See :doc:`/data_system/files/media/image_formats`.

For the common option:

Relative Path
See :doc:`Relative paths &lt;/data_system/files/relative_paths&gt;`.

Main Region
===========

Navigation
----------

Entering a Directory
A single :kbd:`LMB` click on a directory enters that directory.
Parent Directory :kbd:`Backspace`, :kbd:`P`
Takes you up one level of directory.

Arrow Keys
^^^^^^^^^^

Directory navigation is also possible through the arrow keys with :kbd:`Alt` pressed:

- Go to Parent :kbd:`Alt-Up`
- Previous :kbd:`Alt-Left`
- Next Directory :kbd:`Alt-Right`

File Drop
^^^^^^^^^

You now can simply drag &amp; drop files from your local file explorer into the blender file browser.
This will relocate the File browser to the directory of the dropped file and the file will be selected.

Selection
---------

Select
Both :kbd:`LMB` and :kbd:`RMB` works.
(De)select All :kbd:`A`
Toggles selecting all files.
Dragging
Dragging with :kbd:`LMB` starts a :ref:`border selection &lt;select-border&gt;`.

Arrow Keys
^^^^^^^^^^

It is also possible to select/deselect files by "walking" through them using the arrow keys:

- Just using an arrow key, the next file in the chosen direction will be selected and all others deselected.
- Holding down :kbd:`Shift` while doing this does not deselect anything so it extends to the selection,
plus it allows to deselect files by navigating into a block
of already selected ones (minimum two files in sequence).
- Holding down :kbd:`Ctrl-Shift` further selects/deselects all files in-between.

If no file is selected, the arrow key navigation selects the first or last file in the directory,
depending on the arrow direction.

If you select a directory and hit :kbd:`Enter`, you will go into that directory
(and highlighting 'parent' entry will bring you up one level).

File Management
---------------

Delete Files :kbd:`Delete`, :kbd:`X`
Delete the currently selected files.
Rename :kbd:`Ctrl-LMB`
Can be used on a file or directory to rename it.

*************
Data Previews
*************

.. figure:: /images/editors_file_previews.png

File Browser Previews.

The File Browser supports many types of previews. These include:

- Image and video formats
- Blend-files
- Internal :doc:`Data-blocks &lt;/data_system/data_blocks&gt;`
- Fonts

Data-Blocks
===========

Creating and Deleting Previews
------------------------------

Previews can be created and deleted in many ways from :menuselection:`Info Editor --&gt; File --&gt; Data Previews`

Refresh Data-Block Previews
Ensures that data-block previews are available and up to date.
Batch-Generate Previews
Generates previews for selected blend-files.

Scenes
Generates previews for scenes.
Groups
Generates previews for groups.
Objects
Generates previews for objects.
Mat/Tex/..
Generates Previews for materials, textures, images, etc.
Trusted Blend Files
Enables Python evaluation for blend-files.
Save Backups
Enables backups in case blend-files become corrupt while generating previews.
This can be useful when you are worried about large files or can be disabled to save drive space.

Clear Data-block Previews
Clears data-block previews.
Batch-Clear Previews
Clears previews for selected blend-files.

Scenes
Clears previews for scenes.
Groups
Clears previews for groups.
Objects
Clears previews for objects.
Mat/Tex..
Clears previews for materials, textures, images, etc.
Trusted Blend Files
Enables Python evaluation for blend-files.
Save Backups
Enables backups in case blend-files become corrupt while generating previews.

********
Channels
********

Channels Region
===============

.. figure:: /images/editors_graph-editor_introduction_channels-region.png

The Channels Region.

The channels region is used to select and manage the curves for the Graph editor.
This part shows the objects and their animation data hierarchy each as headers.
Each level can be expended/collapsed by the small arrow to the left of its header.

- Scenes, Objects (dark blue)
- :doc:`Actions &lt;/animation/actions&gt;`, :doc:`Shape keys &lt;/animation/shape_keys/index&gt;`, etc. (light blue)
- Groups (green)
- Channels (gray)

Controls
--------

On the headers, there are toggles to control channel's setting:

Pin (pin icon)
ToDo (Graph editor only).
Hide (eye icon)
Hides the channel(s)/curve (Graph editor only).
Modifiers (wrench icon)
Deactivates the F-Modifiers of the curve or all curves in the channel.
Mute (speaker icon)
Deactivates the channel/curve.
Lock (padlock icon)
Toggle channel/curve from being editable.

.. note::

In the Dope Sheet this is also working inside the NLA,
but that it does not prevent edition of the underlying F-Curve).

Selecting
---------

- Select channel (text in white/black): :kbd:`LMB`
- Multi Select/Deselect: :kbd:`Shift-LMB`
- Toggle Select All: :kbd:`A`
- Border Select: (:kbd:`LMB` drag) or :kbd:`B` (:kbd:`LMB` drag)
- Border Deselect: (:kbd:`Shift-LMB` drag) or :kbd:`B` (:kbd:`Shift-LMB` drag)
- Select all keyframes in the channel: double :kbd:`LMB` on a channel header.

Editing
-------

- Rename: :kbd:`Ctrl-LMB`
- Delete selected: :kbd:`X` or :kbd:`Delete`
- Lock selected: :kbd:`Tab`
- Make only selected visible: :kbd:`V`
- Enable Mute Lock selected: :kbd:`Shift-Ctrl-W`
- Disable Mute Lock selected: :kbd:`Alt-W`
- Toggle Mute Lock selected: :kbd:`Shift-W`

Sliders
^^^^^^^

.. figure:: /images/editors_dopesheet_action-editor-sliders.png

The Action editor showing sliders.

On channels headers you can have another column with number buttons or sliders,
allowing you to change the value on the current keyframes, or to add new keyframes.
See :ref:`graph-view-menu` for how to show these sliders.

Menu
=====

Delete Channels :kbd:`X`
Deletes the whole channel from the current action
(i.e. unlink the underlying F-Curve data-block from this action data-block).

.. warning::

The :kbd:`X` shortcut is area-dependent: if you use it in the left list part,
it will delete the selected channels, whereas if you use it in the main area,
it will delete the selected keyframes.

Un/Group Channels :kbd:`Ctrl-G`, :kbd:`Alt-G`
ToDo.
Settings Toogle/Enable/Disable, :kbd:`Shift-W`, :kbd:`Ctrl-Shift-W`, :kbd:`Alt-W`
Enable/disable a channel's setting (selected in the menu that pops-up).

Lock, Mute
Toggle Channel Editability :kbd:`Tab`
Locks or unlocks a channel for editing
Extrapolation Mode
Change the :ref:`extrapolation &lt;editors-graph-fcurves-settings-extrapolation&gt;` between selected keyframes.
Expand Channels, Collapse Channels :kbd:`NumpadPlus`, :kbd:`NumpadMinus`
Expands or collapses selected channels.
Move...
This allows you to move top-level channels up/down :kbd:`Shift-PageUp`, :kbd:`Shift-PageDown`,
or directly to the top/bottom :kbd:`Ctrl-Shift-PageUp`, :kbd:`Ctrl-Shift-PageDown`.
Revive Disabled F-Curves
Clears "disabled" tag from all F-Curves to get broken F-Curves working again.

*******
Editing
*******

By default, when new channels are added, the *Graph Editor* sets them to *Edit Mode*.
Selected channels can be locked by pressing :kbd:`Tab`.

Many of the hotkeys are the same as the viewport ones, for example:

- :kbd:`G` to grab
- :kbd:`R` to rotate
- :kbd:`S` to scale
- :kbd:`B` for border select/deselect

And of course you can lock the transformation along the X (time frame) or Y
(value) axises by pressing :kbd:`X` or :kbd:`Y` during transformation.

For precise control of the keyframe position and value,
you can set values in the *Active Keyframe* of the Properties Region.

Insert Keyframe
===============

.. admonition:: Reference
:class: refbox

| Hotkey:   :kbd:`Ctrl-LMB`, :kbd:`Ctrl-Shift-LMB`

:kbd:`Ctrl-LMB` inserts a keyframe to the active F-Curve at the mouse position.
The newly added keyframes will be selected, making it easier to quickly tweak the newly added keyframes.
All previously selected keyframes are kept selected by using :kbd:`Ctrl-Shift-LMB`.

Transform Snapping
==================

When transforming keyframes with :kbd:`G`, :kbd:`R`, :kbd:`S`,
the transformation can be snapped to increments.

Snap Transformation to 1.0 :kbd:`Ctrl`.

Divide Transformation by 10.0 :kbd:`Shift`.

Snap
----

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Key --&gt; Snap`
| Hotkey:   :kbd:`Shift-S`

Keyframes can be snapped to different properties by using the *Snap Keys* tool.

Current Frame
Snap the selected keyframes to the *Time Cursor*.
Cursor Value
Snap the selected keyframes to the *Cursor*.
Nearest Frame
Snap the selected keyframes to their nearest frame individually.
Nearest Second
Snap the selected keyframes to their nearest second individually, based on the *FPS* of the scene.
Nearest Marker
Snap the selected keyframes to their nearest marker individually.
Flatten Handles
Flatten the *Bézier* handles for the selected keyframes.

.. list-table:: Flatten Handles snapping example.

* - .. figure:: /images/editors_graph-editor_fcurves_editing_flatten-handles-1.png
:width: 200px

Before Flatten Handles.

- .. figure:: /images/editors_graph-editor_fcurves_editing_flatten-handles-2.png
:width: 200px

After Flatten Handles.

Mirror
======

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Key --&gt; Mirror`
| Hotkey:   :kbd:`Shift-M`

Selected keyframes can be mirrored over different properties using the *Mirror Keys*
tool.

By Times Over Current Frame
Mirror horizontally over the *Time Cursor*.
By Values over Cursor Value
Mirror vertically over the *Cursor*.
By Times over Time 0
Mirror horizontally over frame 0.
By Values over Value 0
Mirror vertically over value 0.
By Times over First Selected Marker
Mirror horizontally the over the first selected *Marker*.

Clean Keyframes
===============

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Key --&gt; Clean Keyframes`
| Hotkey:   :kbd:`X`

*Clean Keyframes* resets the keyframe tangents on selected keyframes to their auto-clamped shape,
if they have been modified.

.. list-table::

* - .. figure:: /images/editors_graph-editor_fcurves_introduction_clean1.png
:width: 320px

F-Curve before cleaning.

- .. figure:: /images/editors_graph-editor_fcurves_introduction_clean2.png
:width: 320px

F-Curve after cleaning.

Clean Channels
===============

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Key --&gt; Channels`
| Hotkey:   :kbd:`X`

Acts like the *Clean Keyframes* tool but will also delete the channel itself if it is only left with
a single keyframe containing the default property value and
it's not being used by any generative f-curve modifiers or drivers.

.. note::

The modified curve left after the clean tool is run is not the same as the original,
so this tool is better used before doing custom editing of f-curves and after initial keyframe insertion,
to get rid of any unwanted keyframes inserted while doing mass keyframe insertion
(by selecting all bones and pressing :kbd:`I` for instance).

Smoothing
=========

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Key --&gt; Smooth Keys`
| Hotkey:   :kbd:`Alt-O`

There is also an option to smooth the selected curves , but beware: its algorithm seems to be
to divide by two the distance between each keyframe and the average linear value of the curve,
without any setting, which gives quite a strong smoothing! Note that the first and last keys
seem to be never modified by this tool.

.. list-table::

* - .. figure:: /images/editors_graph-editor_fcurves_introduction_clean1.png
:width: 320px

F-Curve before smoothing.

- .. figure:: /images/editors_graph-editor_fcurves_editing_smooth.png
:width: 320px

F-Curve after smoothing.

Sampling and Baking Keyframes
=============================

Sample Keyframes :kbd:`Shift-O`
Sampling a set a keyframes replaces interpolated values with a new keyframe for each frame.

.. list-table::

* - .. figure:: /images/editors_graph-editor_fcurves_editing_sample.png
:width: 320px

F-Curve before sampling.

- .. figure:: /images/editors_graph-editor_fcurves_editing_sample2.png
:width: 320px

F-Curve after sampling.

Bake Curves :kbd:`Alt-C`
Baking a curve replaces it with a set of sampled points, and removes the ability to edit the curve.

Bake Sound to F-Curves
======================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Key --&gt; Bake Sound to F-Curves`

The *Bake Sound to F-Curves* tool takes and sound file and uses its sound wave to create the animation data.

Lowest frequency
Cutoff frequency of a high-pass filter that is applied to the audio data.
Highest frequency
Cutoff frequency of a low-pass filter that is applied to the audio data.
Attack time
Value for the hull curve calculation that tells how fast the hull curve can rise.
The lower the value the steeper it can rise.
Release time
Value for the hull curve calculation that tells how fast the hull curve can fall.
The lower the value the steeper it can fall.
Threshold
Minimum amplitude value needed to influence the hull curve.

Accumulate
Only the positive differences of the hull curve amplitudes are summarized to produce the output.
Additive
The amplitudes of the hull curve are summarized. If *Accumulate* is enabled,
both positive and negative differences are accumulated.
Square
Gives the output as a square curve.
Negative values always result in -1, and positive ones in 1.

Square Threshold
All values lower than this threshold result in 0.

Show/Hide
=========

Hide :kbd:`H`
Hide selected curves.
Hide Unselected :kbd:`Shift-H`
Show only the selected curve (and hide everything else).
Show Hidden :kbd:`Alt-H`
Show all previous hidden curves.
..    TODO/Review: {{review|im=examples}}.

*****************
F-Curve Modifiers
*****************

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties region --&gt; Modifiers --&gt; Modifiers`

F-Curve modifiers are similar to object modifiers, in that they add non-destructive effects,
that can be adjusted at any time, and layered to create more complex effects.

Adding a Modifier
=================

.. figure:: /images/editors_graph-editor_fcurves_fmodifiers_panel.png

Modifiers Panel.

The F-Curve modifier panel is located in the Properties region.
Select a curve by selecting one of its curve points, or by selecting the channel list.
Click on the *Add Modifier* menu to select a modifier.

Types of Modifiers
==================

Generator
---------

Generator creates a Factorized or Expanded Polynomial function.
These are basic mathematical formulas that represent lines, parabolas,
and other more complex curves, depending on the values used.

Additive
This option causes the modifier to be added to the curve, instead of replacing it by default.
Polynomial Order
Specify the order of the polynomial, or the highest power of ``X`` for this polynomial.
(number of coefficients: 1).

Change the Coefficient values to change the shape of the curve.

.. seealso::

`The Wikipedia Page &lt;https://en.wikipedia.org/wiki/Polynomial&gt;`__
for more information on polynomials.

Built-in Function
-----------------

These are additional formulas, each with the same options to control their shape.
Consult mathematics reference for more detailed information on each function:

- Sine
- Cosine
- Tangent
- Square Root
- Natural Logarithm
- Normalized Sine (``sin(x)/x``)

Amplitude
Adjusts the Y scaling.
Phase Multiplier
Adjusts the X scaling.
Phase Offset
Adjusts the X offset.
Value Offset
Adjusts the Y offset.

Envelope
--------

Allows you to adjust the overall shape of a curve with control points.

Reference Value
Set the Y value the envelope is centered around.
Min
Lower distance from Reference Value for ``1:1`` default influence.
Max
Upper distance from Reference Value for ``1:1`` default influence.

Add Point
Add a set of control points. They will be created at the current frame.

Point
Frame
Set the frame number for the control point.
Min
Specifies the lower control point's position.
Max
Specifies the upper control point's position.

Cycles
------

Cycles allows you add cyclic motion to a curve that has two or more control points.
The options can be set for before and after the curve.

Cycle Mode
Repeat Motion
Repeats the curve data, while maintaining their values each cycle.
Repeat with Offset
Repeats the curve data, but offsets the value of the first point to the value of the last point each cycle.
Repeat Mirrored
Each cycle the curve data is flipped across the X-axis.

Before, After Cycles
Set the number of times to cycle the data. A value of 0 cycles the data infinitely.

Noise
-----

Modifies the curve with a noise formula.
This is useful for creating subtle or extreme randomness to animated movements,
like camera shake.

Blend Type
Replace
Adds a -0.5 to 0.5 range noise function to the curve.
Add
Adds a 0 to 1 range noise function to the curve.
Subtract
Subtracts a 0 to 1 range noise function to the curve.
Multiply
Multiplies a 0 to 1 range noise function to the curve.

Scale
Adjust the overall size of the noise. Values further from 0 give less frequent noise.
Strength
Adjusts the Y scaling of the noise function.
Offset
Offsets the noise in time.
Phase
Adjusts the random seed of the noise.
Depth
Adjusts how detailed the noise function is.

Limits
------

Limit curve values to specified X and Y ranges.

Minimum, Maximum X
Cuts a curve off at these frames ranges, and sets their minimum value at those points.
Minimum, Maximum Y
Truncates the curve values to a range.

Stepped Interpolation
---------------------

Gives the curve a stepped appearance by rounding values down within a certain range of frames.

Step Size
Specify the number of frames to hold each frame.
Offset
Reference number of frames before frames get held.
Use to get hold for (1-3) vs (5-7) holding patterns.
Use Start Frame
Restrict modifier to only act before its "end" frame.
Use End Frame
Restrict modifier to only act after its "start" frame.

############
F-Curves
############

.. toctree::
:maxdepth: 2

introduction.rst
editing.rst
properties.rst
fmodifiers.rst
..    TODO/Review: {{review|text= move direction of time?}}.

************
Introduction
************

After animating some property in Blender using keyframes you can edit their corresponding curves.
When something is "animated," it changes over time. This curve is shown as something called an F-Curve.
Basically what an F-Curve does is an interpolation between two animated properties. In Blender,
animating an object means changing one of its properties, such as the object's location, or its scale.

As mentioned, Blender's fundamental unit of time is the "frame",
which usually lasts just a fraction of a second, depending on the *frame rate* of the scene.
As animation is composed of incremental changes spanning multiple frames,
usually these properties are **not** manually modified *frame by frame*, because:

- It would take ages!
- It would be very difficult to get smooth variations of the property
(unless you compute mathematical functions and type a precise value for each frame, which would be crazy).

This is why nearly all direct animation is done using *interpolation*.

The idea is simple: you define a few Keyframes, which are multiple frames apart.
Between these keyframes, the properties' values are computed (interpolated)
by Blender and filled in. Thus, the animators' workload is significantly reduced.

.. figure:: /images/editors_graph-editor_fcurves_introduction_f-curves-concept.png
:align: right
:width: 200px

Example of interpolation.

For example, if you have:

- A control point of value 0 at frame 0,
- another one of value 10 at frame 25,
- and you use linear interpolation,

then, at frame 5 we get a value of 2.

The same goes for all intermediate frames: with just two points,
you get a smooth growth from (0 to 10) along the 25 frames.
Obviously, if you would like the frame 15 to have a value of 9,
you would have to add another control point (or keyframe)...

Settings
========

F-Curves have three additional properties, which control the interpolation between points,
extension behavior, and the type of handles.

.. _editors-graph-fcurves-settings-interpolation:

Interpolation Mode
------------------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Key --&gt; Interpolation Mode`
| Hotkey:   :kbd:`T`

Mode for the :term:`Interpolation` between the current and next keyframe.

Interpolation
^^^^^^^^^^^^^

Constant
There is no interpolation at all. The curve holds the value of its last keyframe,
giving a discrete (stairway) "curve".
Usually only used during the initial "blocking" stage in pose-to-pose animation workflows.

.. figure:: /images/editors_graph-editor_fcurves_introduction_constant.png
:width: 300px

Constant.

Linear
This simple interpolation creates a straight segment, giving a noncontinuous line.
It can be useful when using only two keyframes and the *Extrapolation* extend mode,
to easily get an infinite straight line (i.e. a linear curve).

.. figure:: /images/editors_graph-editor_fcurves_introduction_linear.png
:width: 300px

Linear.

Bézier
The more powerful and useful interpolation, and the default one.
It gives nicely smoothed curves, i.e. smooth animations!

.. figure:: /images/editors_graph-editor_fcurves_introduction_clean1.png
:width: 300px

Bézier.

.. note::

Remember that some F-Curves can only take discrete values,
in which case they are always shown as if constant interpolated, whatever option you chose.

Easing (by strength)
^^^^^^^^^^^^^^^^^^^^

Different methods of easing interpolations for F-Curve segment.
The "Robert Penner easing equations" (basically, equations which define some preset ways that
one keyframe transitions to another) which reduce the amount of manual work (inserting and tweaking keyframes)
to achieve certain common effects. For example, snappy movements.

- Linear
- Sinusoidal
- Quadratic
- Cubic
- Quartic
- Quintic
- Exponential
- Circular

.. seealso::

For more info and a few live demos, see http://easings.net and
http://www.robertpenner.com/easing/

Dynamic Effects
^^^^^^^^^^^^^^^

These additional easing types imitate (fake) physics-based effects like bouncing/springing effects.
The corresponding settings can be found in the :menuselection:`Properties region --&gt; Active Keyframe panel`.

Elastic
Exponentially decaying sine wave, like an elastic band.
This is like bending a stiff pole stuck to some surface,
and watching it rebound and settle back to its original state.

Amplitude
The amplitude property controls how strongly the oscillation diverges from the basic curve.
At 0.0, there is no oscillation (i.e. it just snaps to the B-value like an extreme exponential transition),
and at 1.0 a profile similar to the one shown in the icon occurs.
Period
The period property controls the frequency with which oscillations occur.
Higher values result in denser oscillations.
Bounce
Exponentially decaying parabolic bounce, like when objects collide.
e.g. for Bouncing balls, etc.
Back
Cubic easing with overshoot and settle.
Use this one when you want a bit of an overshoot coming into the next keyframe,
or perhaps for some wind-up anticipation.

Back
The back property controls the size and direction (i.e. above/below the curve) of the overshoot.

.. _editors-graph-fcurves-settings-easing:

Easing Type
-----------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Key --&gt; Easing Type`
| Hotkey:   :kbd:`Ctrl-E`

The Easing Type controls which end of the segment between the two keyframes that the easing effects apply to.

Automatic Easing
The most commonly expected of the below behaviors is used.
For the transitional effects, this is basically *ease in*, while for the physics effects it is *ease out*.
Ease In
Effect builds up to the second keyframe.
Ease Out
Effect fades out from the first keyframe.
Ease In Out
Effect occurs on both ends of the segment.

.. _editors-graph-fcurves-settings-extrapolation:

Extrapolation
-------------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Channel --&gt; Extrapolation Mode`
| Hotkey:   :kbd:`Shift-E`

Extrapolation defines the behavior of a curve before the first and after the last keyframes.

There are two basic extrapolation modes:

Constant
The default one, curves before their first keyframe and after their last one have a constant value
(the one of these first and last keyframes).

.. figure:: /images/editors_graph-editor_fcurves_introduction_extrapolate1.png
:width: 300px

Constant extrapolation.

Linear
Curves ends are straight lines (linear), as defined by their first two keyframes
(respectively their last two keyframes).

.. figure:: /images/editors_graph-editor_fcurves_introduction_extrapolate2.png
:width: 300px

Linear extrapolation.

Additional extrapolation tools (e.g. the "Cycles" F-Modifier)
are located in the :doc:`F-Curve Modifiers &lt;/editors/graph_editor/fcurves/fmodifiers&gt;`

.. _editors-graph-fcurves-settings-handles:

Handle Types
------------

There is another curve option quite useful for Bézier-interpolated curves.
You can set the type of handle to use for the curve points :kbd:`V`

Automatic
Keyframes are automatically interpolated.

.. figure:: /images/editors_graph-editor_fcurves_introduction_auto.png
:width: 400px

Auto handles.

Vector
Creates linear interpolation between keyframes.
The linear segments remain if keyframe centers are moved. If handles are moved, the handle becomes Free.

.. figure:: /images/editors_graph-editor_fcurves_introduction_vector.png
:width: 400px

Vector handles.

Aligned
Handle maintain rotation when moved, and curve tangent is maintained.

.. figure:: /images/editors_graph-editor_fcurves_introduction_aligned.png
:width: 400px

Aligned handles.

Free
Breaks handles tangents.

.. figure:: /images/editors_graph-editor_fcurves_introduction_free.png
:width: 400px

Free handles.

Auto Clamped
Auto handles clamped to not overshoot.

.. figure:: /images/editors_graph-editor_fcurves_introduction_autoclamped.png
:width: 400px

Auto clamped handles.

Direction of Time
=================

Although F-Curves are very similar to :ref:`curve-bezier`,
there are some important differences.

For obvious reasons, a property represented by a Curve
cannot have more than **one** value at a given time, hence:

- When you move a control point ahead of a control point that was previously ahead of the point that you are moving,
the two control points switch their order in the edited curve, to avoid that the curve goes back in time.
- For the above reason, it is impossible to have a closed F-Curve.

.. list-table:: Two control points switching: the curve cannot go back in time!

* - .. figure:: /images/editors_graph-editor_fcurves_introduction_moving1.png

Before moving the second keyframe.

- .. figure:: /images/editors_graph-editor_fcurves_introduction_moving2.png

After moving the second keyframe.

**********
Properties
**********

Active F-Curve Panel
====================

.. figure:: /images/editors_graph-editor_fcurves_properties_active-fcurve-panel.png

Active F-Curve Panel.

This panel displays properties for the active *F-Curve*.

Channel Name
*ID Type* + Channel name (X Location).
RNA Path
*RNA Path* to property + Array index.
Color Mode
*Color Mode* for the active *F-Curve*.

Auto Rainbow
Increment the *hue* of the *F-Curve* color based on the channel index.
Auto XYZ to RGB
For property sets like location XYZ, automatically set the set of colors to red, green, blue.
User Defined
Define a custom color for the active *F-Curve*.

Active Keyframe Panel
=====================

.. figure:: /images/editors_graph-editor_fcurves_properties_active-keyframe-panel.png

Active Keyframe Panel.

Interpolation
Set the forward :ref:`editors-graph-fcurves-settings-interpolation` for the active keyframe.
Easing
See :ref:`editors-graph-fcurves-settings-easing`.
Key
Frame
Set the frame for the active keyframe.
Value
Set the value for the active keyframe.
Left/Right Handle
Set the position of the left/right interpolation handle for the active keyframe.

Handle Type
See :ref:`editors-graph-fcurves-settings-handles`.

.. _editors-graph-index:

################
Graph Editor
################

.. toctree::
:maxdepth: 2

introduction.rst
channels.rst
fcurves/index.rst

************
Introduction
************

The Graph editor is the main animation editor.
It allows you to modify the animation for any properties using
:doc:`F-Curves &lt;/editors/graph_editor/fcurves/introduction&gt;`.

The graph editor has two modes, *F-Curve* for :doc:`Actions &lt;/animation/actions&gt;`,
and *Drivers* for :doc:`Drivers &lt;/animation/drivers/index&gt;`. Both are very similar in function.

.. figure:: /images/editors_graph_example.jpg
:width: 600px

The Graph Editor.

Curve View
==========

Here you can see and edit the curves and keyframes.

.. figure:: /images/editors_graph-editor_introduction_graph_curve.png

A curve with different types of interpolation.

See :doc:`F-Curves &lt;/editors/graph_editor/fcurves/introduction&gt;` for more info.

Navigation
----------

As with most editors, you can:

Pan
Pan the view vertically (values) or horizontally (time) with click and drag (:kbd:`MMB`).
Zoom
Zoom in and out with the mouse wheel (:kbd:`Wheel`).
Scale View
Scale the view vertically or horizontally (:kbd:`Ctrl-MMB`).

2D Cursor
---------

.. figure:: /images/editors_graph-editor_introduction_2dcursor.png

Graph Editor 2D Cursor.

The current frame is represented by a green vertical line called the *Time Cursor*.

As in the :doc:`Timeline &lt;/editors/timeline&gt;`,
you can change the current frame by pressing or holding :kbd:`LMB`.

The green horizontal line is called the *Cursor*.
This can be disabled via the *View Menu* or the *View Properties* panel.

The *Time Cursor* and the *Cursor* make the *2D Cursor*.
The *2D Cursor* is mostly used for editing tools.

View Axes
---------

For *Actions* the X-axis represents time,
the Y-axis represents the value to set the property.

For *Drivers* the X-axis represents the *Driver Value*,
the Y-axis represents the value to set the property.

Depending on the selected curves, the values have different meaning:
For example rotation properties are shown in degrees,
location properties are shown in Blender Units.
Note that *Drivers* use radians for rotation properties.

Markers
-------

Like with most animation editors, markers are shown at the bottom of the editor.

.. figure:: /images/editors_graph-editor_introduction_markers.png

Graph Editor Markers.

*Markers* can be modified in the *Graph Editor* though it's usually best to use the *Timeline*.

See :doc:`Markers &lt;/animation/markers&gt;` for more info.

Header
======

.. _graph-view-menu:

View Menu
---------

Realtime Updates
When transforming keyframes, changes to the animation data are flushed to other views.
Show Cursor
ToDo.
Show Sliders
A toggle option that shows the value sliders for the channels.
See the Fig. :ref:`fig-dope-sheet-action`.
Show Group Colors
Draw groups and channels with colors matching their corresponding groups.
AutoMerge Keyframes
Automatically merge nearby keyframes.
Use High Quality Drawing
ToDo.
Show Handles :kbd:`Ctrl-H`
ToDo.
Only Selected Curve Keyframes
ToDo.
Only Selected Keyframes Handles
ToDo.
View All :kbd:`Home`
Reset viewable area to show all keyframes.
View Selected :kbd:`NumpadPeriod`
Reset viewable area to show selected keyframes.
View Frame :kbd:`Numpad0`
Centers the area to the Time cursor.

See Timeline's :ref:`timeline-view-menu`.

.. _graph-preview-range:

Preview Range
^^^^^^^^^^^^^

Set Preview Range :kbd:`P`
Interactively define frame range used for playback.
Allow you to define a temporary preview range to use for the :kbd:`Alt-A` realtime playback
(this is the same thing as the *Playback Range* option of the
:ref:`Tmeline editor header &lt;animation-editors-timeline-headercontrols&gt;`).
Clear Preview Range :kbd:`Alt-P`
Clears the preview range.
Auto-Set Preview Range :kbd:`Ctrl-Alt-P`
Automatically sets the preview range to playback the whole action or
the selected NLA strips.

Mode
----

F-Curve for :doc:`Actions &lt;/animation/actions&gt;`,
and Drivers for :doc:`Drivers &lt;/animation/drivers/index&gt;`.

.. figure:: /images/editors_graph-editor_introduction_header_mode.jpg

Graph Mode.

View Controls
-------------

.. figure:: /images/editors_graph-editor_introduction_header_view.png

View Controls.

Show Only Selected (mouse cursor icon)
Only include curves related to the selected objects and data.
Show Hidden (ghost icon)
Include curves from objects/bones that are not visible.
Show Only Errors (livesaver icon)
Only include curves and drivers that are disabled or have errors.
Useful for debugging.
Search Filter (magnifying glass icon) :kbd:`F`
Only include curves with keywords contained in the search field.

Multi-Word (az icon)
Fuzzy/Multi-Word name filtering matches word snippets/partial words,
instead of having to match everything. It breaks down the search string based on whitespace placement.
e.g. "lo ro" will filter all location and rotation, while "lc rt" will *not* work.
Type Filter
Filter curves by property type.

Data-block Sort (az icon)
Objects data-blocks appear in alphabetical order, so that it is easier to find where they occur
(as well as helping to keep the animation of related objects together in the NLA for instance).

If you find that your playback speed suffers from this being enabled
(it should only really be an issue when working with lots of objects in the scene),
you can turn this off.

Normalize
Normalize curves so the maximum or minimum point equals 1.0 or -1.0.

Auto
Automatically recalculate curve normalization on every curve edit.
This is useful to prevent curves from jumping after tweaking it.

Curve Controls
--------------

.. figure:: /images/editors_graph-editor_introduction_header_edit.png

Curve Controls.

Proportional Editing :kbd:`O`
See :doc:`Proportional editing &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`.
Auto Snap
Auto snap the keyframes for transformations.

- No Auto-Snap
- Frame Step
- Second Step
- Nearest Frame
- Nearest Second
- Nearest Marker

Pivot Point
Pivot point for rotation.

Bounding Box Center
Center of the selected keyframes.
2D Cursor
Center of the *2D Cursor*. *Time Cursor* + *Cursor*.
Individual Centers
Rotate the selected keyframe *Bézier* handles.

Copy Keyframes :kbd:`Ctrl-C`
Copy the selected keyframes to memory.
Paste Keyframes :kbd:`Ctrl-V`
Paste keyframes from memory to the current frame for selected curves.
Create Snapshot (ghost icon)
Creates a picture with the current shape of the curves.

Properties Region
=================

The panels in the *Properties Region*.

View Tab
--------

View Properties Panel
---------------------

.. figure:: /images/editors_graph-editor_introduction_view-properties-panel.png

View Properties Panel.

Show Cursor
Show the vertical *Cursor*.
Cursor from Selection
Set the *2D cursor* to the center of the selected keyframes.
Cursor X
*Time Cursor* X position.

To Keys
Snap selected keyframes to the *Time Cursor*.
Cursor Y
Vertical *Cursor* Y position.

To Keys
Snap selected keyframes to the *Cursor*.

Further Tabs
------------

F-Curve Tab
See :doc:`F-Curve &lt;/editors/graph_editor/fcurves/properties&gt;`.
Drivers Tab
See :doc:`/animation/drivers/drivers_panel`.
Modifiers Tab
See :doc:`F-Modifiers &lt;/editors/graph_editor/fcurves/fmodifiers&gt;`.
.. _editors-index:

###########
Editors
###########

.. figure:: /images/editors_menu.png
:align: right

The Editor Type selector.

Blender provides a number of different editors for displaying and modifying different aspects of data.

The *Editor Type* selector, the first button at the left side of a header,
allows you to change the editor in that area. Every area in Blender may contain any type of editor
and it is also possible to open the same type multiple times.

There is also documentation on the :doc:`general interface &lt;/interface/index&gt;` of editors.

3D
==

.. toctree::
:maxdepth: 1

3dview/index.rst

Animation
=========

.. toctree::
:maxdepth: 1

timeline.rst
graph_editor/index.rst
dope_sheet/index.rst
nla/index.rst

Image/Video
===========

.. toctree::
:maxdepth: 1

uv_image/index.rst
movie_clip_editor/index.rst
vse/index.rst

Nodes/Logic
===========

.. toctree::
:maxdepth: 1

text_editor.rst
node_editor/index.rst
logic_editor.rst

Settings
========

.. toctree::
:maxdepth: 1

properties_editor.rst
outliner.rst
../preferences/index.rst
info/index.rst

Other
=====

.. toctree::
:maxdepth: 1

file_browser/index.rst
python_console.rst

****
File
****

The options to manage files are:

New :kbd:`Ctrl-N`
Clears the current scene and loads startup.blend.
Open :kbd:`Ctrl-O`
:doc:`Open &lt;/data_system/files/open&gt;` a blend-file.
Open Recent :kbd:`Shift-Ctrl-O`
Displays a list of :ref:`recently &lt;other-file-open-options&gt;` saved blend-files to open.
Recover Last Session
This will load the ``quit.blend`` file Blender automatically saves just before exiting.
So this :ref:`option &lt;other-file-open-options&gt;` enables you to :doc:`recover &lt;/troubleshooting/recover&gt;`
your last work session, e.g. if you closed Blender by accident.
Recover Auto Save
:ref:`This &lt;other-file-open-options&gt;` will open an automatically saved file
to :doc:`recover &lt;/troubleshooting/recover&gt;` it.
Save :kbd:`Ctrl-S`
:doc:`Save &lt;/data_system/files/save&gt;` the current blend-file.
Save As :kbd:`Shift-Ctrl-S`
Opens file browser to specify file name and location of :doc:`save &lt;/data_system/files/save&gt;`.
Save Copy :kbd:`Shift-Alt-S`
:doc:`Saves &lt;/data_system/files/save&gt;` a copy of the current file.
User Preferences :kbd:`Ctrl-Alt-U`
Opens the :doc:`User Preferences Editor &lt;/preferences/introduction&gt;` in a new window.
Save User Settings :kbd:`Ctrl-U`
Saves the current scene and preferences to :doc:`startup.blend &lt;/data_system/files/startup_file&gt;`.
Load Factory Settings
Restores the default startup-file as :ref:`factory settings &lt;factory-settings&gt;`.
Link :kbd:`Ctrl-Alt-O`
Links data from an external blend-file (library) to the current scene.
The edition of that data is only possible in the external library.
*Link* and *Append* is used to load in only selected parts from another file.
See :doc:`Linked Libraries &lt;/data_system/linked_libraries&gt;`.
Append :kbd:`Shift-F1`
Appends data from an external blend file to the current scene.
The new data is copied from the external file, and completely unlinked from it.
Import
Blender can use information stored in a variety of other format files which are created by
other graphics programs. See :doc:`Import/Export &lt;/data_system/files/import_export&gt;`.
Export
Normally you save your work in a blend-file,
but you can export some or all of your work to a format that can be processed by other graphics programs.
See :doc:`Import/Export &lt;/data_system/files/import_export&gt;`.
External Data
External data, like texture images and other resources,
can be stored inside the .blend file (packed) or as separate files (unpacked).
Blender keeps track of all unpacked resources via a relative or absolute path.
See :ref:`pack or unpack external Data &lt;pack-unpack-data&gt;`

Automatically Pack Into .blend
This option activates the file packing.
If enabled, every time the blend-file is saved, all external files will be saved (packed) in it.
Pack All Into .blend
Pack all used external files into the blend-file.
Unpack Into Files
Unpack all files packed into this blend-file to external ones.
Make All Paths Relative
Make all paths to external files :doc:`relative &lt;/data_system/files/relative_paths&gt;` to current blend-file.
Make All Paths Absolute
Make all paths to external files absolute. Absolute ones have full path from the system's root.
Report Missing Files
This option is useful to check if there are links to unpacked files that no longer exist.
After selecting this option a warning message will appear in the Info editors header.
If no warning is shown, there are no missing external files.
Find Missing Files
In case we have broken links in our blend file, this option will help us fix the problem.
A File Browser will show up. Select the desired directory (or a file within that directory),
and a search will be performed in it, recursively in all contained directories.
Every missing file found in the search will be recovered.
Those recoveries will be done as absolute paths,
so if you want to have relative paths you will need to select *Make All Paths Relative*.

.. note::

Recovered files might need to be reloaded. You can do that one by one, or
you can save the blend file and reload it again, so that all external files are reloaded at once.

Quit :kbd:`Ctrl-Q`
Closes Blender and the file is saved into ``quit.blend``.

###############
Info Editor
###############

.. toctree::
:maxdepth: 2

introduction.rst
file.rst
screenshot.rst

************
Introduction
************

The Info Editor is found at the top of the Default Screen and has the following components.

Header
======

.. figure:: /images/editors_info_introduction_info-editor.png

Info Editor header.

Editor Type Selector (red), Menus (blue), Screen Data-block (green),
Scene Data-block (orange), Engine Selector (purple), Resource Information (aqua).

Menus
---------

Provides access to the Blender's main menu options.

File
^^^^

See :doc:`/editors/info/file` menu.

Render
^^^^^^

Render
See :doc:`/render/output/render_panel`.
OpenGL Render
See :doc:`/render/opengl`
Show/Hide Render View :kbd:`F11`
Shows (or hides) the editor where the last render was performed.
Play Rendered Animation :kbd:`Ctrl-F11`
Plays the last rendered animation using the internal :doc:`/render/output/animation_player` or
an external video player, which has to be defined in the File tab of the User Preferences.

Window
^^^^^^

Duplicate Window :kbd:`Ctrl-Alt-W`
Duplicates the current window so that a new one is created with the same screen layout and size.
Useful for multiple monitors.
Toggle Window Fullscreen :kbd:`Alt-F11`
Toggles full screen on or off.
Screenshot, Screencast
See :doc:`/editors/info/screenshot`.
Toggle System Console
Shows or hides the :doc:`System Console &lt;/advanced/command_line/introduction&gt;` (on MS Windows).

Help
^^^^

See :ref:`help-menu`.

Controls
-----------

Back to Previous
A button shown when an area is maximized to return to tiled areas.
Screen
:ref:`Data-block menu &lt;ui-data-block&gt;` used to select and edit
:doc:`Screens &lt;/interface/window_system/screens&gt;` (window layouts).
Scene
:ref:`Data-block menu &lt;ui-data-block&gt;` to select different :doc:`Scenes &lt;/data_system/scenes/introduction&gt;`.
Having multiple Scenes allows you to work with separate virtual environments,
with completely separate data, or with object and/or mesh data linked between them.
Engine
Gives a list of selectable render and game engines.
Render/Baking progress
A progressbar and a cancel button are shown while rendering or baking.
Hovering over them shows a time estimate.
Capture Stop
A button shown while :ref:`screen casting &lt;info-screencast&gt;` to stop the recording.
Report Message
Label for an operator to display results or warnings. It disappears after a short time.
By clicking with :kbd:`LMB` on the icon on the left side, the full report is copied into a new text data-block,
which you can be open in the Text Editor.
Blender Icon
Clicking on the Blender logo opens the :ref:`splash`.
Blender version
This label displays the Blender version.
Resource Information
Scene
Displays information about the current loaded scene dependent on the mode and object type.
When two numbers are shown, the first one means the selected, and the second one means the total count.
This can be the number of vertices, faces, triangles or bones, as well as the selected objects and lamps.
Memory
The "Mem" label shows the calculated memory consumption by Blender.
This can help to identify, when you are reaching the limits of your hardware.
Active Object
The object type of the current selected object.

.. _info-report-console:

Report Console
==============

When the Info Editor's area is scaled up, it reveals the Report console,
where a scripting trail is displayed.
Whenever an operator has been executed, it leaves a report, creating a log.

.. figure:: /images/editors_info_introduction_report-console.png

The Report Console after adding a Cube.

**************
Screen Capture
**************

Screenshots
===========

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Window --&gt; Save Screenshot`
| Hotkey:   :kbd:`Ctrl-F3`

.. figure:: /images/editors_info_screenshot_save-options.png

Save Screenshot Option.

:kbd:`Ctrl-F3` will take a screenshot of Blender and then open the :doc:`File Browser &lt;/editors/file_browser/index&gt;`,
allowing you to specify the name and location of the screenshot.
In the example image at the right, the ``PNG`` format will be the output of the screenshot taken
(settings are the same as the ones available to save render results).
When the :doc:`File Browser &lt;/editors/file_browser/index&gt;` opens, on the left, there is a tab
called *Save Screenshot* where you can find format settings and a checkbox with the option
*Full Screen*.

- Check the Option to save the entire Blender window
(full width and height of the Blender window you are using when you call the command).
- Uncheck the box to save only your active area (where your mouse is located when you call the command).

.. _info-screencast:

Screencasts
===========

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`Window --&gt; Make Screencast`
| Hotkey:   :kbd:`Alt-F3`

This is a quick way to make screen-casts from within Blender.

.. note::

This is limited to a single window and does *not* support audio.

For recording tutorials you may want to use more comprehensive, 3rd party solutions.

Screencasts will record your actions over time either as a video or sequence of image files.
The type and location of the output are determined by the settings in the
:doc:`Output panel &lt;/render/output/output&gt;` of the Properties :ref:`Render tab &lt;properties-render-tab&gt;`.
The default settings will generate a screencast consisting of a series of ``PNG`` images captured
every 50 ms and stored in the ``/tmp`` folder. If you want to record a video, set the
*Output* to one of the *Movie File Formats* supported by your system
listed in the *Output panel* format menu.
If you are unsure what video codecs your system supports, select ``AVI JPEG``.

.. note::

You can change the frame-rate for a screencast in the :ref:`User Preferences &lt;prefs-system-screencast&gt;`.

When you start Blender Screencasts, the header of the *Info Editor* will change,
and it will show you a button for stopping your capture.

.. figure:: /images/editors_info_screenshot_stop-button.png

Info Header with the Capture Stop Button.

.. note:: The only way to stop the Screencast

Pressing the Stop button in the header of the Info Editor is the only way to stop the Screencast capture.
If you press :kbd:`Esc`, the shortcut will only work for operations
performed in the Blender *User Interface*, (it will stop animations, playbacks and so on...),
but will not work to stop *Screencasts*.

.. _fig-screencast-frame-range:

.. figure:: /images/editors_info_screenshot_frame-range.png

:menuselection:`Render --&gt; Dimensions Panel --&gt; Frame Range`

The frames are stored using a suffix added to their file name,
where the suffix is composed of the numbers present in the fields for *start* and *end frames*,
defined in the Frame Range of the Dimensions panel,
:ref:`Render tab &lt;properties-render-tab&gt;`.
(See Fig. :ref:`fig-screencast-frame-range` highlighted in yellow)

.. note::

The configuration of the End frame, present in the Frame Range of the Dimensions Panel,
**will not** stop your capture automatically.
You will always have to stop the Screencast manually, using the Stop button.

The Videos are generated internally in the same manner as the *Screenshots*,
using the width and height of the Window you are working in.
If you choose to capture to a Video file,
Blender will have to pass those frames to a Video codec.

.. warning::

Some codecs limit the output width/height or the video quality:

- When you save your *Screencast* in an Image format,
the Images will be saved using the entire Blender Window, with full width and height,
and the quality of the Image will be defined by its type (e.g. JPG, PNG, and so on)
and configuration (e.g. Slider *quality* of the .JPG format).
- When you save your *Screencast* in a Video format, it will be sent to a codec.
Depending on the codec limitations, the resulting output Video could be scaled down.
Furthermore, some combinations of Window width and height cannot be processed by certain codecs.
In these cases, the *Screencast* will try to start, but will immediately stop.
In order to solve this, choose another Window format and/or another codec.

Blender Window Dimension
------------------------

There is a way to match the Blender Window dimensions with the Output Video File,
achieving standard dimensions for the output of the Blender Screencast.
(e.g. NTSC, HD, Full HD, etc).
You can control the width and height of your Blender Window, starting Blender from a Command Line.
To learn more about starting Blender from a command line,
see the page about :doc:`Blender Console Window &lt;/advanced/command_line/introduction&gt;`.

************
Logic Editor
************

The Logic Editor provides the main method of setting up and editing the game logic for the
various actors (i.e. objects) that make up the game. The logic for the objects which are
currently selected in the associated 3D View are displayed as logic bricks,
which are shown as a table with three columns, showing sensors, controllers, and actuators,
respectively. The links joining the logic bricks conduct the pulses between sensor-controller
and controller-actuator.

To give you a better understanding of the Logic Editor, the image below shows a typical
editor content in which the major components have been labeled.
We will look at each one individually.

.. figure:: /images/editors_logic_expanded_menus.png

The different parts of the Logic Editor.

1) Property Region, 2) Object Name, 3a) Links, 3b) Link socket,
4) Sensor column, 5) Controller Column, 6) Actuator Column.

Main view
=========

Object Name
This box shows the name of the object which owns the logic bricks below.
Links
Links (3A) indicate the direction of logical flow between objects.
Link lines are drawn by :kbd:`LMB` dragging from one Link socket (3B) to another.
Links can only be drawn from Sensors to Controllers, or from Controllers to Actuators.
You cannot directly link Sensors to Actuators; likewise,
Actuators cannot be linked back to Sensors
(however, special actuator and sensor types are available to provide these connections).

Sending nodes (the black circles found on the right-hand side of Sensors and Controllers)
can send to multiple Reception nodes
(the white circles found on the left-hand side of Controllers and Actuators).
Reception nodes can likewise receive multiple links.

Links can be created between logic bricks belonging to different objects.
To delete a link between two nodes, :kbd:`LMB` drag between the two nodes.

Sensor Column
-------------

This column contains a list of all sensors owned by the active object (and any other selected objects).
New sensors for the active object are created using the "Add Sensor" button.
For a more in-depth look at the content, layout and available operations in this area,
see :doc:`Sensors &lt;/game_engine/logic/sensors/introduction&gt;`.

Controller Column
-----------------

This column contains a list of all controllers owned by the active object (and any other selected objects).
New controllers for the active object are created using the "Add Controller" button,
together with the creation of states for the active object.
For a more in-depth look at the content, layout, and available operations in this area,
see :doc:`Controllers &lt;/game_engine/logic/controllers/introduction&gt;`.

Actuator Column
---------------

This column contains a list of all actuators owned by the active object (and any other selected objects).
New actuators for the active object are created using the "Add Actuator" button.
For a more in-depth look at the content, layout, and available operations in this area,
see :doc:`Actuators &lt;/game_engine/logic/actuators/introduction&gt;`.

Property Region
===============

Game properties are like variables in other programming languages.
They are used to save and access data associated with an object.
Several types of properties are available.
Properties are declared by clicking the *Add Game Property* button in this region.
For a more in-depth look at the content,
layout and available operations in this region, see :doc:`Properties &lt;/game_engine/logic/properties&gt;`.
.. _editors-movieclip-index:

#####################
Movie Clip Editor
#####################

.. toctree::
:maxdepth: 2

introduction.rst
tracking/index.rst
masking/index.rst
properties/index.rst

************
Introduction
************

The Movie Clip Editor has two main purposes, it can be used for for tracking or masking movies.
The empty editor looks like the image below.

.. figure:: /images/editors_movie-clip.png

Movie Clip Editor interface.

Header
======

Clip Menu
---------

- Open Clip :kbd:`Alt-O`

Controls
--------

Movie Clip
:ref:`Data-block menu &lt;ui-data-block&gt;` used for add a movie file.
Both movie files and image sequences can be used in the Clip editor.
When a movie clip is loaded into the clip editor, extra panels are displayed in the interface.

.. figure:: /images/editors_movie-clip_example.jpg

Movie Clip Editor with an Opened Clip.

Modes
- :doc:`Motion Tracking &lt;/editors/movie_clip_editor/tracking/index&gt;`
- :doc:`Masking &lt;/editors/movie_clip_editor/masking/index&gt;`

Pivot Point
See :doc:`Pivot Points &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`.
Proportional Edit
See :doc:`Proportional Edit &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`.

Properties Region
=================

Footage Settings
See :doc:`/editors/uv_image/image/image_settings`.

Main View
=========

Mini Timeline
-------------

When a clip is loaded a Timeline is shown at bottom of the Preview.
It expands over the full area limited by the animation range.
You can move the Time Cursor by dragging with :kbd:`LMB`.

The Timeline is composed of the following visual elements:

- Green line: Time Cursor
- Yellow: Motion track
- Yellow line: Keyframe
- Orange line: Shape keyframe
- Purple: Prefetched frames
- Light green line: Solve start/end keyframe

*******************
Selection &amp; Editing
*******************

Selection
=========

The usual selection tools are available:

- Toggle Select All :kbd:`A`.
- Border and Circle Select :kbd:`B` , :kbd:`C`.
- Lasso Select :kbd:`Ctrl-Alt-LMB`.
- Select Linked from selection :kbd:`Ctrl-L`
- Select Linked with mouse :kbd:`L`.

- Select tracking marker :kbd:`Ctrl-RMB`.

Editing
=======

The tools and panels available to edit masks are the same in both editors.
Editing of mask splines happens in a way similar to editing Bézier curves or paths in GIMP or other curve editors.

.. tip::

To get interactive feedback on the resulting mask,
a Mask node can be connected directly to a Viewer node in the compositor,
which will then keep updating the compositing result while editing.

Control Points
--------------

Add Vertex and Slide :kbd:`Ctrl-LMB`
:kbd:`Ctrl-LMB` is used to place new control points and define handle orientations by a continued mouse drag.
A :kbd:`Ctrl-LMB` double click will also close the curve if the last point was selected.
Transform
Existing control points can be slided with :kbd:`LMB` and
translated, scaled and rotated with the usual :kbd:`G`, :kbd:`S`, :kbd:`R` shortcuts.
The whole spline can be move by dragging the center dot with :kbd:`LMB`.
Toggle Cyclic :kbd:`Alt-C`
Toggle to create a close curve or open it again.
Close the mask by joining the last control point to the first.
Delete :kbd:`X`
Removes control points.

Curve Handles
-------------

Slide Spline Curvature
:kbd:`LMB` click on curve and drag to move the handle.
Set Handle Type :kbd:`V`
Set handle type for selected spline points.
Recalculate Normals :kbd:`Ctrl-N`
Make normals (handle directions) consistent.
Switch Direction
Switch Direction handle directions in/out.

.. _mask-feather:

Feather
-------

Add Feather Vertex and Slide :kbd:`Shift-LMB`
:kbd:`Shift-LMB` is used to define a feathering outline curve. To create an initial feather,
sliding from a spline control point outside or inside will create and position feather points.
After this :kbd:`Shift-LMB`
will insert new feather point and mouse sliding can be used to move them around.
Scale Feather :kbd:`Alt-S`
Will scale the feather size.

Animation
---------

Masks can be animated with the shape keying system.
This can be useful when there are not enough good feature points to track in the footage,
or the mask is not based on footage.
Mask animation timing can be edited from the Dope Sheet :ref:`Mask &lt;dope-sheet-mask&gt;` mode.

Insert Shape Key :kbd:`I`
Will insert a shape key for the active mask layer at the current frame.
This works on the level of mask layers,
so inserting a shape key will keyframe all the splines and points contained in it.
Clear Shape Key :kbd:`Alt-I`
Will clear the shape key for the active mask layer at the current frame.
Feather Reset Animation
Resets the feather offset across all animated frames.
Re-Key Points of Selected Shapes
Re-interpolate selected points on across the range of keys selected in the dope sheet.

Show/Hide
---------

- Hide selected :kbd:`H`
- Hide unselected :kbd:`Shift-H`
- Reveal :kbd:`Alt-H`

###########
Masking
###########

.. toctree::
:maxdepth: 2

introduction.rst
scurve.rst
editing.rst
properties.rst

************
Introduction
************

Masks can be created in the UV/Image and Movie Clip editors, by changing the mode to Mask in the header.
This will add various tools and properties to the editor panels,
while hiding others that are not needed for interacting with masks.

Masks have many purposes. They can be used in a motion tracking workflow to mask out,
or influence a particular object in the footage.
They can be used for manual rotoscoping to pull a particular object out of the footage,
or as a rough matte for green screen keying. Masks are independent from a particular image of movie clip,
and so they can just as well be used for creating motion graphics or other effects in the compositor.

While the Clip Editor and UV/Image editor are used to edit masks,
the Compositor and Sequencer are just using already created mask.

Masks can be driven over the time so that they follow some object from the footage,
e.g. a running actor. This can be achieved with shape keys or parenting the mask to tracking markers.

Mask Data-block
===============

Mask data-block containing multiple mask layers and splines.
They are the most high-level entity used for masking purposes.
Masks can be reused in different places, and hold global parameters for all the entities they consist of.

Header
======

Mask
Once set to Mask mode, a Mask data-block can be added.
Any image, movie clip, render or compositing result can be used as a backdrop to draw masks over.

New ``+`` :kbd:`Alt-N`

**********
Properties
**********

Mask Layer
==========

Mask Layer
Mask layers consists of one or several splines and used to "grouped" operation on splines.
Layers can be used to create complex shapes and to define how the splines interact with each other.
Splines belonging to the same layer can be animated together, for example by an item
from motion tracker footage.
Example of such tools might be parenting the whole set of splines to single motion tracking data or
simple to transform all of them together.

Opacity
ToDo.

Invert
ToDo.
Blend
ToDo.
Falloff
Feather. ToDo.
Overlap
Detect self intersections. ToDo.
Holes
Option not to treat overlapping curves as holes.
Concentric splines will generating holes in the mask.

By creating overlapping splines holes can be created, and
it's the layer membership that defines which splines interact to create holes.
As addition, splines from the same layer are behaving in a way, that concentric splines are defining holes in mask,
but if two splines from different layers are concentric they wouldn't define hole --
they'll just be union in final mask.

Example
-------

The purpose of mask layers can be explained with an example.
Suppose there are two unwanted people in the footage, and one of them goes from left to right, and
the other in the opposite direction. Two mask layers can then be used to mask them separately
using a single mask data-block. At the point of intersection of these shapes they will be added together rather than
creating a hole, as would happen if they were on the same layer. If the motion is simple enough,
a single motion tracked point can be used to drive the location of the entire mask layer.

Mask Display
============

Smooth
Display the edge anti-aliased.
Edge Draw Type
Style of the edge.
Overlay
Added mask overlay to both image and clip editors.

Mode
Alpha Channel
Which displays rasterized mask as a grayscale image.
Combined
Which multiples image/clip with the mask.

Active Spline
=============

.. (wip)
It is possible to control feather of mask, including a way to define non-linear feather.
Linear feather is controlled by a slider,
non-linear feather is controlled in the same curve-based way to define feather falloff.

Feather Offset
ToDo.
Weight Interpolation
ToDo.
Cyclic
If the spline is closed or not.
Fill
Disable calculation of holes.
Self Intersection Check
Fill self intersections.

Active Point
============

This panel is shown when both a tracking marker and mask is selected.

Parent
------

In the Movie Clip Editor it is possible to link the whole mask or its points to motion tracks.
This way the mask or points will follow the tracks.

Make Parent :kbd:`Ctrl-P`
Parents one or more selected spline points to the active motion tracker.
Clear Parent :kbd:`Alt-P`
Clears any parenting relationship for the selected spline points.

Parent
:ref:`Data ID &lt;ui-data-id&gt;` to which the mask or spline is parented to
in case of parenting to movie tracking data set to Movie Clip data-block.
Type
Point Track, Plane Track
Object
:ref:`Object &lt;movie-clip-tracking-properties-object&gt;` to parent to.
Track
Name of individual tracks.

Mask Settings
=============

ToDo.

********
S-Curves
********

The curve type used for creating mask splines is almost a Bézier curve, but with some differences.
Smooth edges of the mask are defined by feathering.
The curve needed to support feathering in a way that stuck to the curve as you edited it,
for ease of editing an animation. These are called S-Curves.

Besides the handles, every control point also has points that define the feather between
the current point and the next point on the spline.
Each feather point is stored in UV space,
where U means position across spline segment, and V means distance between main spline and feather points.

.. figure:: /images/editors_movie-clip_masking_scurve.png

S- Curve Explained.

This allows for deforming the main spline in almost any way,
and the feather will be updated automatically to reflect that change.

For example if there is just rotation of the spline,
feather would stay completely unchanged. If one point's feather is moved,
the other feathers will be automatically stretched uniformly along that segment
and the overall shape will be almost the same as artists would want it to be.

Primitives
==========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Tool Shelf --&gt; Mask --&gt; Add`
| Hotkey:   :kbd:`Shift-A`

There are two primitives available: a Bezier Circle and a Square with vector handles.

*************
Display Panel
*************

This panel contains display settings related on editor itself.

Channels
The R, G, B toggles control the color channels used for frame preview.
It is needed because the tracking algorithm works with gray-scale images and it is not
always obvious to see which channels disabled will increase contrast of feature points and reduce noise.
Grayscale Preview (B/W)
Shows the whole frame grayscale.
Mute (eye icon) :kbd:`M`
Changes displaying on movie frame itself with black square,
It helps to find tracks which are tracked inaccurately or which were not tracked at all.
Render Undistorted
ToDo.
Lock to Selection :kbd:`L`
Makes the editor display selected tracks at the same screen position
along the whole footage during playback or tracking.
This option helps to control the tracking process and
stop it when the track is starting to slide off or when it jumped.
Display Stabilization
This option makes the displayed frame be affected by the 2D stabilization settings
(available in reconstruction mode only).
It is only a preview option, which does not actually change the footage itself.
Grid
Displays a grid which is originally orthographic, but is affected by the
distortion model (available in distortion mode only). This grid can be used for manual calibration --
distorted lines of grids are equal to straight lines in the footage.
Calibration
Applies the distortion model for grease pencil strokes (available in distortion mode only).
This option also helps to perform manual calibration.
A more detailed description of this process will be added later.
Display Aspect Ratio
Changes the aspect ratio for displaying only. It does not affect the tracking or solving process.

##############
Properties
##############

.. toctree::
:maxdepth: 2

proxy.rst
display.rst

********************
Proxy/Timecode Panel
********************

Once you have chosen the Proxy/Timecode parameters,
you need to use :menuselection:`Clip --&gt; Proxy --&gt; Rebuild Proxy and Timecode indices`
to generate the proxy clip and it will be available after Blender makes it.

Proxy
=====

.. figure:: /images/editors_movieclip_proxy.png
:align: right

A proxy is a smaller image (faster to load) that stands in for the main image.
When you rebuild proxies Blender computes small images (like thumbnails)
for the big images and may take some time. After computing them, though,
editing functions like scrubbing and scrolling is much faster but gives a low-res result.
Make sure to disable proxies before final rendering.

Build Original
Used to define which resolutions of proxy images should be built.
Build Undistorted
Builds images from undistorted original images for the sizes set above.
This helps provide faster playback of undistorted footage.
Quality
Defines the quality of the JPEG images used for proxies.
Proxy Custom Directory
By default, all generated proxy images are storing to
the ``&lt;path of original footage&gt;/BL_proxy/&lt;clip name&gt;`` folder,
but this location can be set by hand using this option.
Rebuild Proxy
Regenerates proxy images for all sizes set above and regenerate all timecodes which can be used later.
Timecode
See `Timecode`_.
Proxy Render Size
defines which proxy image resolution is used for display.
If *Render Undistorted* is set, then images created from undistorted frames are used.
If there is no generated proxies, render size is set to "No proxy, full render",
and render undistorted is enabled, undistortion will happen automatically on frame draw.

Timecode
========

When you are working with footage directly copied from a camera without pre-processing it,
there might be bunch of artifacts, mostly due to seeking a given frame in sequence.
This happens because such footage usually does not have correct frame rate values in their headers. So,
for Blender to calculate the position of a needed frame in the stream works inaccurately and can give errant result.
There are two possible ways to avoid this:

- Preprocess your video with, say, mencoder to repair file header and insert correct keyframes.
- Use Proxy/Timecode option in Blender.

Options
-------

:term:`Timecode`
Timecode to use on the selected movie strip.

The following timecodes are supported:

- No TC in use- do not use any timecode
- Record Run
- Free Run
- Free Run (rec date)
- Record Run No Gaps

.. note::

Record Run is the timecode which usually is best to use, but if the clip's file is totally damaged,
*Record Run No Gaps* will be the only chance of getting acceptable result.

##########
Editing
##########

.. toctree::
:maxdepth: 2

track.rst
solve.rst

*****
Solve
*****

.. _clip-tracking-plane:

Plane Track Panel
=================

The *Create Plane Track* operator creates a new plane track.
Planar tracking takes advantage of the fact that there are often planar surfaces in footage,
by attaching markers to points on these flat planes.
It can be used to replace things like billboards and screens on the footage with another image or video.
It also might be used for masking.

This button will create a plane object
which is deforming in the same way as plane defined by all selected point tracks.
At least four feature points tracked across the footage which belongs to
the plane one wants to replace are needed. More tracks will give better estimation of plane motion.

Feature points used to estimate plane motion could be used from any place on the plane,
meaning it's not necessarily need to be corners. Corners are not always easy to be tracked,
they might be occluded. In this case you can position tracked features that lay on the same plane
far away from the actual plane which should be replaced.

This provides more information about the possible deformation of the marker in following frames,
and such markers can be tracked even if partially occluded (appear and disappear during the time).
It is only required that two neighbor frames have at least 4 common tracks.

An image can be projected onto the plane with the
:doc:`/compositing/types/distort/plane_track_deform` compositing node.

Solve Panel
===========

Tripod
------

Tripod Motion can be used for footage where the camera does not move and only rotates.
Such footage can't be tracked with a generic solver approach, and
it is impossible to determine the actual feature points in space due to a lack of information.
So this solver will solve only the relative camera rotation and then reproject the feature points into a sphere,
with the same distance between feature and camera for all feature points.

.. note::

Please note, that this is special type of camera solver and it behaves different from regular solver.
It means using more tracks doesn't imply more accurate solution.
Having 5-10 tracks on frame is likely what shall be commonly used for this kind of solver.

Keyframe
--------

Keyframe
Automatically select keyframes for initial reconstruction.
This option enables complex algorithms which tries to find a keyframe pair
with minimal reconstruction error and best scene scale guess.
Keyframe A, B :kbd:`Q`, :kbd:`E`
Start (A) and End (B) frame of the range used for reconstruction.

Refine
------

The *Refine* option specifies which parameters should be refined during solve.
Such refining is useful when you are not sure about some camera intrinsics,
and solver should try to find the best parameter for those intrinsics.
But you still have to know approximate initial values --
it will fail to find correct values if they were set completely incorrectly initially.

.. _editors-movie-clip-tracking-clip-solve-motion:

Solve Camera/Object Motion
--------------------------

The *Camera Motion* operator solves the motion of camera using all tracks placed
on the footage and two keyframes specified on this panel. There are some requirements:

- There should be at least eight common tracks on the both of the selected keyframes.
- There should be noticeable parallax effects between these two keyframes.

If everything goes smoothly during the solve, the average reprojection error is reported to
the information space and to the clip editor header. Reprojeciton error means the average
distance between reconstructed 3D position of tracks projected back to footage and original
position of tracks. Basically, reprojection error below 0.3 means accurate reprojection,
(0.3 - 3.0) means quite nice solving which still can be used.
Values above 3 means some tracks should be tracked more accurately,
or that values for focal length or distortion coefficients were set incorrectly.

.. (todo) object solver

Cleanup Panel
=============

This panel contains a single operator and its settings. This operator cleans up bad tracks:
tracks which are not tracked long enough or which failed to reconstruct accurately.

Frames
ToDo.
Error
Error threshold value.
Action
Several actions can be performed for bad tracks:

Selected
They can simply be selected.
Delete Track
The whole track can be deleted.
Delete Segments
Bad segments of tracked sequence can be removed.

Geometry Panel
==============

3D Markers to Mesh
Converts the reconstructed points into a point cloud (single mesh). ToDo.
Link Empty to Track
ToDo.

Orientation Panel
=================

Scene orientation tools can be used for orienting object to bundles.

Floor
Select three markers that should lay on the floor plane. ToDo.
Wall
Define world orientation based on points on the wall.
Set Origin
ToDo.
Set X, Y Axis
ToDo.
Set Scale
Object has got scale to define "depth" in camera space.
Apply
Apply scale on scene solution.
Distance
ToDo.

Scene Setup
===========

Set as Background
Sets the clip currently being edited as the camera background for all visible 3D Views.
If there is no visible 3D Views or the Clip Editor is open in full screen,
nothing will happen.
Setup Tracking Scene
ToDo.

*****
Track
*****

Clip Panel
==========

Prefetch :kbd:`P`
Fills cache with frames. As many frames as fits into cache are load form the drive.
This allows to fill in the cache as fast as possible when you really need to track something,
but this keeps CPU and drive bandwidth idle if you've got clip editor opened but not actually interacting with it.
Reload
ToDo.
Set Scene Frames
ToDo.

Marker panel
============

Add Marker and Move
Places a new marker at the position of the mouse
(which is under the button in this case, not ideal but it is just how things work)
and then it can be moved to the needed location. When it is moved to the desired position,
:kbd:`LMB` can be used to finish placing the new marker.
Also, :kbd:`Enter` and :kbd:`Spacebar` can be used to finish placing the marker.
But it is faster to use :kbd:`Ctrl-LMB` to place markers directly on the footage.
This shortcut will place the marker in the place you have clicked.
One more feature here: until you have released the mouse button,
you can adjust the marker position by moving the mouse and using
the track preview widget to control how accurately the marker is placed.

Detect Features
Detects all possible features on the current frame and places markers at these features.
This operator does not take into account other frames,
so it can place markers on features which belong to moving objects,
and if camera is turning away from this shot,
no markers would be placed on frames after the camera moved away.

There are several properties for this operator:

Placement
Used to control where to place markers. By default, they will be added through the whole frame, but you can
also outline some areas with interesting features with grease pencil and place markers only inside the
outlined area. That is how the "Inside Grease Pencil" placement variant works. You can also outline areas of
no interest (like trees, humans and so) and place markers outside of these areas. That is how the "Outside
Grease Pencil" placement variant works.
Margin
controls the distance from the image boundary for created markers. If markers are placed too close to the
image boundary, they will fail to track really quickly and they should be deleted manually. To reduce the
amount of manual clean-up, this parameter can be used.
Threshold
Limits minimal threshold for placing markers. This value comes from the feature detection algorithm and
basically it means: low values means most probably this feature would fail to track very soon, high value
means it is not much such track. Amount of markers to be added can be controlled with this value.
Distance
Defines the minimal distance between placed markers. It is needed to prevent markers from being placed too
close to each other (such placement can confuse the camera solver).

Delete Track
is a quite self-explaining operator which deletes all selected tracks.

.. _clip-tracking-settings:

Tracking Settings Panel
=======================

This panel contains all settings for the 2D tracking algorithms.

Tracking Presets
ToDo.
Channels
ToDo.
Pattern Size, Search
ToDo.
Motion Model
Defines which possible motions tracking feature has. This option should be set depending on which motion
a particular feature has and it'll make tracking most accurate for such a motion.

Location only, Location+Rotation, Location+Scale, Location+Rotation+Scale, Affine

Perspective
Is usually used to track a planar feature,
but often *Affine* is a good enough approximation and may have more stable tracks.
Pattern Match
Pattern Match controls which patterns get tracked; to be more precise,
the pattern from which frame is getting tracked. Here is an example which should make things clearer.

The tracker algorithm receives two images inside the search area and the position of a point
to be tracked in the first image.
The tracker tries to find the position of that point from the first image in the second image.

Now, this is how tracking of the sequence happens.
The second image is always from a frame at which the position of marker is not known
(next tracking frame). But a different first image
(instead of the one that immediately precedes the second image in the footage)
can be sent to the tracker.

Keyframe
An image created from a frame on which the track was keyframed.
This configuration prevents sliding from the original position
(because the position which best corresponds to the original pattern is returned by the tracker),
but it can lead to small jumps and can lead to failures when the feature point is deformed due to camera motion
(perspective transformation, for example).
Previous Frame
Keyframes for tracks are creating every frames,
and tracking between keyframed image and next image is used.
In this configuration the pattern is tracking between two neighboring frames.
It allows dealing with cases of large transformations of the feature point
but can lead to sliding from the original position, so it should be controlled.
Prepass
Enables a two pass tracking, where the first pass is a brute force tracking of location only, and
the second pass will use tracking of the full motion model refining the first pass.
Normalize
Means patterns will be normalized by their average intensity while tracking,
to make them invariant to illumination changes. An example where this is useful is a scene where
a marker moves in the shadow of an object.
Copy From Active Track
Tracker settings only -- ToDo.

.. (alt) Previous frame: An image created from the current frame is sent as first image to the tracker.

Extra Settings
--------------

Use Mask
ToDo.
Correlation
Is now a single value for all tracking settings and defines the minimal correlation between
a matched pattern and a reference to be considered a successful tracking.
If the tracker is giving up too easily, decrease this value, or if the tracker is slipping too much
when it should give up sooner, increase this value.
Frames Limit
Controls how many frames can be tracked when the Track Sequence operator is called.
So, each Track Sequence operation would track maximum *Frames Limit* frames.
This also helps to notice slide-off of tracks and correct them.
Margin
Can be used disable tracks when they become too close to the image boundary.
This slider sets "too close" in pixels.
Speed
Marker settings only -- Can be used to control the speed of sequence tracking.
This option does not affect the quality of tracking; it just helps to control if tracking happens accurately.
In most cases tracking happens much faster than real time, and it is difficult to notice when a track began
to slide out of position. In such cases *Speed* can be set to Double or Half to add some delay between
tracking two frames, so slide-off would be noticed earlier and the tracking process can be canceled to
adjust positions of tracks.
Weight
See Track :ref:`Weight &lt;clip-tracking-weight&gt;`.

.. hybrid tracker:
The algorithm tracks an image larger than the defined pattern first to find the general direction of motion.
Then it tracks a slightly smaller image to refine the position from the first step and make the final
position more accurate. This iterates several times.

Track panel
===========

Tracks
------

The first row of buttons is used to perform tracking of selected tracks
(i.e. following the selected feature from frame to frame).
Tracking can happen (in order of buttons):

- Backward one frame :kbd:`Alt-Left`
- Backward along the sequence :kbd:`Shift-Ctrl-T`
- Forward along the whole sequence :kbd:`Ctrl-T`
- Forward one frame :kbd:`Alt-Right`

This operator depends on settings from the Tracking Settings panel, which will be described later.
If during sequence tracking the algorithm fails to track some markers,
they will be disabled and tracking will continue for the rest of the markers.
If the algorithm fails when tracking frame-by-frame, the marker is not disabled,
and the most likely position of the feature on the next frame is used.

Clear
-----

Action
Clear (After/Remained) (left arrow icon) :kbd:`Alt-T`
Deletes all tracked and keyframed markers before the current frame for all selected tracks.
Clear (Before/Up-to) (right arrow icon) :kbd:`Shift-T`
Deletes all tracked and keyframed markers after the current frame for all selected tracks.
Clear (Track Path/All) :kbd:`Shift-Alt-T`
Clears all markers except the current one from all selected tracks.
Clear Active
ToDo.

Refine
------

This operator will run a tracker from previous keyframe to current frame for all selected markers.
Current markers positions are considering initial position guess which could be updated by a tracker for better match.

Useful in cases when feature disappears from the frame and then appears again. Usage in this case is the following:

* When feature point re-appeared on frame, manually place marker on it.
* Use Refine Markers operation (which is in Track panel) to allow tracker to find a better match.

Depending on direction of tracking use either Forwards or Backwards refining.
It's easy: if tracking happens forwards, use Refine Forwards, otherwise use Refine Backwards.

Merge
-----

Join Tracks :kbd:`Ctrl-J`
This operator joins all selected tracks into one.
Selected tracks should not have common tracked or keyframed markers at the same frame.

.. (wip)
Joining two tracks now works better for tracks which have got intersection by frames:
coordinates of joined track would be interpolated linearly on segments with intersection.
This is still not perfect from accurate solving point of view,
but this allows to prevent camera jump which is much more annoying than sight camera slide.

#############
Clip View
#############

.. toctree::
:maxdepth: 2

introduction.rst
marker.rst
editing/index.rst
properties/index.rst

************
Introduction
************

The Clip View is used is the main part of the of the Movie Clip editor.
Almost all motion tracking tools are concentrated in the Movie Clip Editor.

It should be mentioned that the camera solver consists of three quite separate steps:

#. 2D tracking of footage.
#. Camera intrinsics (focal length, distortion coefficients) specification/estimation/calibration.
#. Solving camera, scene orientation, and scene reconstruction.

***************
Tracking Marker
***************

Point
=====

.. figure:: /images/editors_movie-clip_tracking_clip_marker_schematic.svg
:align: center

Marker schematic.

The whole marker can be moved with :kbd:`RMB` or by dragging the anchor point (black dot) with :kbd:`LMB`.
Pressing :kbd:`G` also translates the whole marker. When pressing  :kbd:`G` twice the marker will be translated
while keeping the anchor in place. Note that the anchor point outside the pattern area is shown as a cross connected
with marker position with a dashed line.

:kbd:`S` scales the whole marker.
The whole pattern area only will be scaled by pressing :kbd:`S` twice;
The Pattern can also be rotated using the :kbd:`R` button which, depending on the used pivot point,
will either rotate patterns around their own centers or rotate the whole markers around e.g. the median point.

To match the perspective transformation of a marker on a plane, the individual corners must be edited manually.
Each marker corner can deform individually to define the shapes.
Corner positions can be edited by dragging them with a mouse.
Dragging with :kbd:`LMB` will change the position of an individual corner.

.. note::

Note that deforming a pattern is not only useful for planar / affine tracking.
Since only pixels within the pattern will be considered this can help to
specify a better pattern to track even for simple position tracking.

The Search area can not be rotated; this is intentional. It doesn't make sense to deform the search area.

Plain
=====

The left bottom corner of the plane does have X/Y axis (X is red, Y is green) to
help distinguishing orientation of the plane in space.

It is likely that corner of the plane object need to be manually adjusted.
To do this sliding individual corners with mouse :kbd:`LMB` or general transform tools
:kbd:`G`, :kbd:`R`, :kbd:`S` could be used.

Adjusting plane corners will keep it following the plane defined by tracks it was originally created from.

***********
Camera Data
***********

This panel contains all settings of the camera used for filming the movie which is currently
being edited in the clip editor.

Camera
======

Camera Presets
Predefined settings can be used here.
But such settings as distortion coefficients and principal point are not included in the presets and
should be filled in even if camera presets are used.
Sensor
Width
Is the width of the CCD sensor in the camera. This value can be found in camera specifications.
Pixel Aspect Ratio
Is the pixel aspect of the CCD sensor. This value can be found in camera specifications,
but can also be guessed. For example, you know that the footage should be 1920×1080,
but the images themselves are 1280×1080. In this case, the pixel aspect is: 1920 / 1280 = 1.5.
Optical Center
Is the optical center of the lens used in the camera. In most cases it is equal to the image center,
but it can be different in some special cases. Check camera/lens specifications in such cases.
To set the optical center to the center of image, there is a :kbd:`Enter` button below the sliders.

Lens
====

Focal Length
Is self-explanatory; it is the focal length with which the movie was shot.
It can be set in millimeters or pixels.

Lens Distortion
---------------

Distortion Model
Polynomial
Polynomial radial distortion.
Division
It defines high distortions, which makes this model suitable much better for cameras with fish-eye lenses.

Coefficients
Coefficients are used to compensate for lens distortion when the movie was shot. Currently these values can be
tweaked by hand only (there are no calibration tools yet)
using tools available in Distortion mode. Basically, just
tweak K1 until solving is most accurate for the known focal length (but also take grid and grease pencil into
account to prevent "impossible" distortion).

The coefficients of the division model work independent from each other and
positive values will give a barrel distortion.

K1, K2 and K3

##############
Properties
##############

.. toctree::
:maxdepth: 2

introduction.rst
camera_data.rst
marker.rst
stabilization/index.rst

************
Introduction
************

.. _movie-clip-tracking-properties-object:

Objects Panel
=============

.. figure:: /images/editors_movie-clip_objects_panel.jpg
:align: right
:width: 130px

Objects Panel.

This panel contains a :ref:`list view &lt;ui-list-view&gt;` with all objects which can be used for tracking,
camera or object solving.
By default there is only one object in this list which is used for camera solving.
It cannot be deleted and other objects cannot be used for camera solving;
all added objects are used for object tracking and solving only.
These objects can be referenced from Follow Track and Object Solver constraints.
Follow Track uses the camera object by default.

If some tracks were added and tracked to the wrong object, they can be copied to another
object using :menuselection:`Track --&gt; Copy Tracks` and :menuselection:`Track --&gt; Paste Tracks`.

The usage for all kind of objects (used for camera and object tracking) is the same:
track features, set camera data, solve motion. Camera data is sharing between all objects and
refining of camera intrinsics happens when solving camera motion only.

Track Panel
===========

.. figure:: /images/editors_movie-clip_track_panel.png
:align: right
:width: 130px

Track Panel.

Name
The track name can be changed with this field.
Track names are used for linking tracking data to other areas, like a Follow Track constraint.
Enable (eye icon)
This toggle controlled the marker's enabled flag.
If a marker is disabled, its position is not used either by solver nor by constraints.
Lock (padlock icon)
The toggle controls whether the track is locked. Locked tracks cannot be edited at all.
This helps to prevent accidental changes to tracks which are "finished"
(tracked accurate along the whole footage).

Track Preview Widget
--------------------

The widget in this panel is called "Track Preview" and it displays the content of the
pattern area. This helps to check how accurately the feature is being tracked
(controlling that there is no sliding off original position)
and also helps to move the track back to the correct position.
The track can be moved directly using this widget by mouse dragging.

If an anchor is used (the position in the image which is tracking is different from the
position which is used for parenting),
a preview widget will display the area around the anchor position. This configuration helps in
masking some things when there is no good feature at position where the mask corner should be
placed. Details of this technique will be written later.

There is small area below the preview widget which can be used to enlarge the vertical size of
preview widget (the area is highlighted with two horizontal lines).

Further Options
---------------

Channels
Tracking happens in gray-scale space, so a high contrast between the feature and
its background yields more accurate tracking.
In such cases disabling some color channels can help.
Grayscale Preview (B/W)
Display the preview image as grayscale even if all channels are enabled.
Alpha Preview (B/W icon)
ToDo.

.. _clip-tracking-weight:

Weight
When several tracks are used for 3D camera reconstruction, it is possible
to assign a reduced weight to some tracks to control their influence on the solution result.
This parameter can (and often need to be) animated.

Altering the weights of problem tracking markers can correct or greatly reduce undesirable jumps
as feature disappear or become difficult to track.

Another use of Track Weights is when you want to reconstruct a scene from your camera solution.
In that case you can first carefully track and solve your scene, and once you're done,
lock all your markers with :kbd:`Ctrl-L`, set the tracker weight in the Extra Settings of
the tracker settings to zero and use the feature detection to quickly add lots of markers.
Now track them and solve the scene again. Since their weight is zero
they will not influence your solution at all, but you will have lots of good reference points in your scene.
Stabilization Weight
While *Weight* parameter is used for 3D reconstruction,
the *Stabilization Weight* is used to control 2D stabilization.
Color Presets
The preset for the *Custom Color*.
Custom Color
This setting overrides the default marker color used in the clip editor and 3D View,
and it helps to distinguish different type of features (for example,
features in the background vs. foreground and so on). Color also can be used for "grouping"
tracks so a whole group of tracks can be selected by color using the Select Grouped operator.

.. tip::

To select good points for tracking, use points in the middle of the footage timeline
and track backwards and forwards from there.
This will provide a greater chance of the marker and point staying in the camera shot.

Plane Track Panel
=================

.. figure:: /images/editors_movie-clip_plane_track_panel.png
:align: right
:width: 130px

Plane Track Panel.

Its properties are shown only when a plane track is selected.
Firstly, the name of the selected plane track is shown. It can also be changed from here.

Auto Keyframe
Toggles the auto-keyframing for corners of the plane track.
With this enabled, keyframes will automatically get inserted when any corner is moved.
Image
Field to select an image which will be displayed inside the plane track.
This image is for preview purposes in movie clip editor only.
To include it in your final render,
see :doc:`Plane Track Deform node &lt;/compositing/types/distort/plane_track_deform&gt;`.
Opacity
Used to set the opacity of this image. Again,
this is for display purposes only, and will not affect your final render.

Tracking Settings Panel
=======================

This panel contains :ref:`tracker settings &lt;clip-tracking-settings&gt;` for each marker.

Grease Pencil Panel
===================

Grease pencil strokes can be enabled/disabled with the checkbox in the panel header.
It is a standard grease pencil panel where new grease pencil layers and frames can be controlled.
There is one difference in the behavior of the grease pencil from other areas --
when a new layer is created "on-demand" (when making a stroke without adding a layer before this)
the default color for the layer is set to pink. This makes the stroke easy to notice on all kinds of movies.

******
Marker
******

Marker Display
==============

Pattern
Can be used to disable displaying of rectangles which correspond to pattern areas of tracks.
In some cases it helps
to make the clip view cleaner to check how good tracking is.
Search :kbd:`Alt-S`
Can be used to disable displaying of rectangles which correspond to search areas of tracks.
In some cases it helps to make the clip view cleaner to check how good tracking is.
Only search areas for selected tracks will be displayed.
Path
And *Length* control displaying of the paths of tracks. The ways tracks are moving can be visible looking
at only one frame. It helps to determine if a track jumps from its position or not.
Disabled :kbd:`Alt-D`
Makes it possible to hide all tracks which are disabled on the current frame.
This helps to make view more clear, to see if tracking is happening accurately enough.
Info
Displays information such as track name and status of the track
(if it is keyframed, disabled, tracked or estimated).
Names and status for selected tracks are displayed.
3D Markers
Makes sense after solving the movie clip,
and it works in the following way: the solved position of each track gets
projected back to the movie clip and displayed as a small point. The color of the point depends on the distance
between the projected coordinate and the original coordinate: if they are close enough, the point is green,
otherwise it will be red. This helps to find tracks which were not solved nicely and need to be tweaked.
Thin
The way in which markers are displayed compact (black outline and yellow foreground color)
makes tracks visible on all kind of footage (both dark and light).
But sometimes it can be annoying and this option will make the marker display
more compactly -- the outline is replaced by dashed black lines drawn on top of the foreground,
so that marker areas are only 1px thick.

Marker Panel
============

.. figure:: /images/editors_movie-clip_tracking_clip_properties_introduction_marker.svg
:width: 350px
:align: center

Marker schematic.

This panel contains numerical settings for marker position,
pattern and search area dimensions, and offset of anchor point from pattern center.
All sliders are self-explanatory.

####################
2D Stabilization
####################

.. toctree::
:maxdepth: 2

introduction.rst
panel.rst
workflow.rst

************
Introduction
************

The 2D video stabilization is a feature built on top of Blender's image feature tracking abilities:
we use some *tracking points* to remove shakiness, bumps and jerks from video footage.
Typically, image stabilization is part of a **2D workflow** to prepare and improve footage
prior to further processing or modeling steps. This page helps to understand how it works,
introduces related terms and concepts, describes the available interface controls in detail
and finally gives some hints about usage in practice.

Typical **usage scenarios** of the stabilizer:

- fix minor deficiencies (shaky tripod, jerk in camera movement)
- "poor man’s steadycam" (when a real steadycam was not available, affordable or applicable)
- as preparation for masking, matching and rotoscoping

It is not uncommon for 2D stabilization to have to deal with somewhat imperfect and flawed footage.

How it works
============

To detect spurious movement in a given shot, we'll assume a simplified model about this movement.
We then try to fit the movement of tracked features with this simplified model to derive a compensation.
Of course, this works only to the degree our model is adequate -- yet in practice, this simplified approach works
surprisingly well even with rather complicated shots, where our basic assumption was just an approximation of
much more elaborate movements.

This simplified model underlying the 2D stabilization as implemented here assumes movement
by an **affine-linear transform**:

- the camera is pushed up/down/sideways by some **translation component**
- the image is then **tilted** and **scaled** around a **pivot point** (rotation center)

To compensate movement according to this simplified model, the 2D stabilizer proceeds in two steps.
First we try to detect the translation offset from the weighted average of all *translation tracking points*.
After compensating this translation component, we then use additional *rotation/scale tracking points* to detect
rotation around a given pivot point. Again, we detect rotation and scale changes through a weighted average
of all the rotation/scale tracking points given.

In the current version, the **pivot point** is anchored to the *weight center of the translation tracking points*.
So effectively the detected translation is already factored out. In some cases this is not optimal,
especially when tracks have gaps or do not cover the whole duration of the footage -- we plan further options
to better control the pivot point in future releases.

Stabilization Tracks
--------------------

Thus, as foundation for any image stabilization, we need tracked image features to derive the movements.
These *tracking points* or "tracks" can be established with Blender's
:doc:`image feature tracking component &lt;/editors/movie_clip_editor/tracking/clip/introduction&gt;`
The right choice of points to track is somewhat tricky, yet crucial for successful image stabilization.
Often, we're here because we'll have to deal with imperfect footage. In such cases, the *averaging of tracks*
helps to work around image or tracking errors at some point.
Moreover, when the footage contains *perspective induced movements,* symmetrically placed tracking points above
and below the horizon can be used to cancel out spurious movement and get stabilization to the focal area in between.

.. figure:: /images/editors_movie-clip_stabilization_perspective.jpg
:align: center
:width: 600px

Diverging movements caused by perspective.

Tracks can be added in two groups

- first of all is the list of tracks to be used to compensate for jumps in the camera location.
From all the tracking points added to this group, we calculate a *weighted average.*
We then try to keep this average location constant during the whole shot.
Thus it is a good idea to use tracking markers close to and centered around the most important subject.
- a second selection of tracks is used to keep the rotation and scale of the image constant.
You may use the same tracks for both selections. But usually it is best to use tracking points with large distance
from the image center, and symmetrically, on both sides, to capture the angular movements more precisely.
Similar to the "location" case, we calculate an *average angular contribution* and then try
to keep this value constant during the whole shot.

Footage, Image and Canvas
-------------------------

When talking about the movement stabilization of video, we have to distinguish several frames of reference.
The image elements featured by the footage move around irregularly within the footage's **original image boundaries**
-- this is the very reason why we are using the stabilizer. When our attempt at stabilization was successful,
the image elements can be considered *stable* now, while in exchange the footage's image boundaries have taken on
irregular movement and jump around in the opposite way.
This is the immediate consequence of the stabilizer's activity.

Since the actual image elements, i.e the subject of our footage can be considered stable now, we may use these
as a new frame of reference: we consider them attached to a fixed backdrop, which we call the **canvas**.
Introducing this concept of a "canvas" helps to deal with deliberate movements of the camera. And beyond that,
it yields an additional benefit: It is very frequent for the pixels of video footage to be *non square.*
So we have to stretch and expand those pixels, before we're able to preform any sensible rotation stabilization.
Thus the canvas becomes, by definition, the reference for an undistorted display of the image contents.

But when the camera was *moved intentionally,* we have to consider yet another frame of reference beyond the canvas:
namely the frame (or *"cadre"*) of the **final image** we want to create. To understand this distinction,
let's consider a hand-held, panning shot to the right: Since our camera was turned towards the right side,
the actual image contents move towards the left side *within* the original image frame.
But let's assume the stabilizer was successful with "fixing" any image contents relative to the *canvas* --
which in turn means, that the original image boundaries start to move irregularly towards the right side,
and the *contents* of the image will begin to disappear gradually behind the left boundary of the original image.
After some amount of panning, we'll have lost all of our original contents and just see an empty black image backdrop.
The only solution to deal with that problem is to *move the final image frame along to the right,*
thus following the originally intended panning movement. Of course, this time, we do want to perform this
newly added panning movement in a smooth and clean way.

.. figure:: /images/editors_movie-clip_stabilization_panning.jpg
:align: center
:width: 600px

Stabilizing a panning shot.

.. figure:: /images/editors_movie-clip_stabilization_canvas.jpg
:align: right
:width: 400px

Restoring the expected camera movement.

To allow for such a compensation and to reintroduce deliberate panning, or tilting and zoom of the resulting image,
the stabilizer offers a dedicated set of controls: *Expected position*, *Expected rotation* and *Expected scale*.
These act like the controls of a virtual camera filming the contents we have fixed onto the canvas.
By *animating* those parameters, we're able to perform all kinds of deliberate camera movements in a smooth fashion.

.. container:: lead

.. clear

The "dancing" black Borders
---------------------------

As explained above, when we succeed with stabilizing the image contents, the boundaries of the original footage
start to jump around in the opposite direction of the movements compensated. This is inevitable -- yet very annoying,
since due to the irregular nature of these movements, these "dancing black borders" tend to draw away attention
from the actual subject and introduce an annoying restlessness. Thus our goal must be to hide those dancing borders
as good as possible. A simple solution is to add a small amount of zoom. Sometimes we'll also need to animate
the parameter *Expected position* in order to keep the image centered as good as we can -- this helps to reduce
the amount of zoom necessary to remove those annoying borders.

The **Autoscale function** can be used to find the minimal amount of zoom just sufficient to remove
those black borders completely. However, if the camera jumps a lot, the autoscale function often zooms in too much,
especially since this calculation aims at finding a single, static zoom factor for the whole duration of the footage.
When this happens, you'll typically get overall better results
with animating both the zoom factor and the expected position manually.
.. (todo) introductory text parts to introduction.rst

**********************
2D Stabilization Panel
**********************

There is one extra panel which is available in reconstruction mode -- 2D Stabilization Panel.
The purpose of this feature is to smooth out jerky camera handling on existing real world footage.
To activate the 2D stabilizer, you need to set the toggle in the panel, and additionally you need to enable
*Display Stabilization* in the Display panel.
Then you'll need to set up some tracking points to detect the image movements.

The 2D Stabilization panel is used to define the data used for 2D stabilization of the shot.
Several options are available in this panel: you may add a list of tracks to determine lateral image shifts
and another list of tracks to determine tilting and zooming movements.
Based on the average contribution of these tracks, a compensating movement is calculated and applied to each frame.

When the footage includes panning and traveling movements, the stabilizer tends to push the image out of the
visible area. This can be compensated by animating the parameters for the intentional, "expected" camera movement.

.. note::

To *activate* the 2D stabilizer, you need to set the toggle in the panel,
and additionally you need to enable *Display Stabilization* in the *Display* panel.

Options
=======

.. figure:: /images/editors_movie-clip_2d_stabilization_panel.png
:align: right
:width: 130px

2D Stabilization Panel.

Anchor Frame
Reference point to anchor stabilization:
other frames will be adjusted relative to this frame's position, orientation and scale.
You might want to select a frame number where your main subject is featured in an optimal way.

Stabilization Type
Rotation
In addition to location, stabilizes detected rotation around the *rotation pivot point,*
which is the weighted average of all location tracking points.

Scale
Compensates any scale changes relative to center of rotation.

Tracks For Stabilization
Location
List of tracks to be used to compensate for camera jumps, or location movement.

Rotation/Scale
List of tracks to be used to compensate for camera tilts and scale changes.

Autoscale
Finds smallest scale factor which, when applied to the footage,
would eliminate all empty black borders near the image boundaries.

Max
Limits the amount of automatic scaling.

Expected Position X/Y
Known relative offset of original shot, will be subtracted, e.g. for panning shots
Expected Rotation
Rotation present on original shot, will be compensated, e.g. for deliberate tilting.
Expected Zoom
Explicitly scale resulting frame to compensate zoom of original shot.

Influence
The amount of transformation applied to the footage can be controlled.
In some cases it is not necessary to fully compensate camera jumps.
The amount of stabilization applied to the footage can be controlled.
In some cases you may not want to fully compensate some of the camera's jumps.
Please note that these "\* *Influence*" parameters do control only the *compensation movements*
calculated by the stabilizer, not the deliberate movements added through the "*Expected* \*"-parameters.

Interpolate
The stabilizer calculates compensation movements with sub pixel accuracy.
Consequently, a resulting image pixel needs to be derived from several adjacent source footage pixels.
Unfortunately, any interpolation causes some minor degree of softening and loss of image quality.

Nearest
No interpolation, uses nearest neighboring pixel.
No interpolation, use nearest neighboring pixel.
This setting basically retains the original image's sharpness.
The downside is we also retain residual movement below the size of one pixel,
and compensation movements are done in 1 pixel steps, which might be noticeable as irregular jumps.
Bilinear
Simple linear interpolation between adjacent pixels.
Bicubic
Highest quality interpolation, most expensive to calculate

********
Workflow
********

Depending on the original footage's properties, achieving good stabilization results might be simple and easy,
or it might require some work, dedication and careful planning. This section covers some practical considerations
to help improving the results.

The Simple Case
===============

Whenever the camera is basically fixed, or at least "almost" stationary, and the footage is crisp and without
motion blur, perfect stabilization is easy to achieve. This might be the case when a tripod was used,
but wind or vibrations on the floor (e.g. on a stage) caused some minor shakes. Shoulder camera shots done
by an experienced operator also frequently fall into this category.

- Use as few points as possible. Start with a single point right on the main subject.
- Track this single point as accurate as possible. Beware of movements and shape changes of the tracked feature.
Proceed in small increments (e.g. 50 frames), zoom in and readjust the target point manually when it drifts away.
Another option is to use a larger target area for tracking; since we're tracking only a single point,
the slower tracking speed might be acceptable.
- After enabling the basic (location) stabilization, consider if you really need rotation stabilization.
Often, some minor, slow swinging movements are not really noticeable and do not warrant the additional working time
and quality loss caused by rotation and scale stabilization.
- For rotation, start with one extra point, well spaced but preferably still attached to the main subject.
- Consider to fix some slow residual motion by manually animating the "*Expected* \*" parameters,
before you even think of adding more tracking markers. Because doing so is often not worth the effort.
- If you need to add more points, the most important goal is to achieve *symmetry.*
Place location tracking points symmetrically above and below the horizon.
Place rotation tracking points into diagonally opposed direction, always centered around the main focal area.

Avoid Problematic Footage
=========================

The 2D stabilizer can not work miracles; some flaws simply can not be fixed satisfactory.
Notorious issues are motion blur, rolling shutter, pumping autofocus and moving compression artifacts.
Especially if you do succeed with basic stabilization, such image flaws become yet the more noticeable and annoying.
When on set or on location, it might be tempting to "fix matters in postpro".
Resist that deception, it rarely works out well.

- Prefer a short exposure time to avoid motion blur.
While motion blur is good to render filmed movements more smooth and natural,
it seriously impedes the ability to track features precisely.
As a guideline, try to get at least to 1/250 s
- Prefer higher frame rates. The more *temporal resolution* the stabilizer has to work on, the better the results.
If you have the option to choose between progressive and interlaced modes, by all means use interlaced
and deinterlace the footage to the *doubled frame rate*. This can be done with the
`yadif &lt;https://ffmpeg.org/ffmpeg-filters.html#yadif-1&gt;`__ filter of FFmpeg: use the mode 1 (``send_field``).
- Beware of `Rolling Shutter &lt;https://en.wikipedia.org/wiki/Rolling_shutter&gt;`__.
Avoid fast lateral movements. If you can, prefer a camera which produces less rolling shutter.
Also, using a higher frame rate reduces the amount of rolling shutter; another reason to prefer
interlaced over progressive for the purpose at hand.
- Switch off autofocus.
Better plan your movement beforehand, set a fixed focus and rely on depth-of-field through using a small aperture.
Pumping movements might not be so noticeable to the human observer, but the feature tracking tends to slide away
on defocused image elements; fixing this manually after the fact can cause a huge waste of time.
- Increase the lighting level, at least use a higher sensitivity.
This helps to set a fast shutter speed plus a small aperture.
Better lighting and good exposure also help to reduce the impact of compression artifacts.
If you can, also select a codec with less data reduction, better color space etc.
Inevitably, we're loosing some quality through the interpolation necessary for stabilization.
Plus we're loosing some quality due to color space conversion.

Elaborate Movements
===================

When the footage builds on elaborate intended movement of the camera, the process of stabilization
becomes more involved -- especially when there is a shift in the main area of interest within the shot.
When working with many tracks and fine grained animation, it is easy to get into a situation where additional
manipulations actually decrease the quality, while it might be hard to spot and locate the root cause of problems.
Recommendation is to proceed systematically, starting from the general outline down to tweaking of specific aspects.

#. Understand the nature of the movements in the shot, both the intended and the accidental.
#. Track some relevant features for location.
#. Establish the basic location stabilization.
This includes the decision, which feature to use for what segment of the shot.
Work with the track weights to get an overall consistent movement of the weight center,
in accordance with the inherent focus of the shot.
#. Define the panning movements of the virtual camera (through animation of the *Expected Position* parameter)
#. Add tracking for rotation and zoom stabilization
#. Fine tuning pass:

Break down the whole duration of the shot into logical segments to define the intended camera movement.
Then refine those segments incrementally step by step, until the overall result looks satisfactory...

Animating Stabilization Parameters
==================================

Animating some parameters over duration of the shot is often necessary, at least to get the final touch,
including control of the scale factor to hide the dancing black borders. Unfortunately there is a **known limitation**
in the current version: it is not possible to open the generic animation editors (F-curve and dope sheet)
for animation data beyond the 3D scene. So, while it *is possible* to set key frames *right within the UI controls*
of the stabilizer (either through pressing the :kbd:`I` key or with the help of the context menu), it is not possible
to manipulate the resulting curves graphically. The only way to readjust or remove a misguided keyframe is to locate
the timeline to the very frame and then use the context menu of the animated UI control.
(Hint: the color of the UI control changes when you have located at precisely the frame number of the keyframe)

Irregular Track Setup
=====================

It might not be possible to track a given feature over the whole duration of the shot.
The feature might be blurred or obscured; it might even move out of sight entirely, due to deliberate camera movement.
In such a situation, we need *another tracked feature* to take on it's role, and we need some *overlap time*
to get a smooth transition without visible jump.

.. figure:: /images/editors_movie-clip_stabilization_irregular-tracks.png
:align: right
:width: 250px

Irregular Tracks.

The stabilizer is able to deal with gaps and partial coverage within the given tracks.
However, the basic assumption is that each track covers a single, fixed reference point whenever there is any
usable/enabled data. Thus, you must not "re-use" a given track to follow several different points,
rather you should disable and thus end one track, when tracking this feature is no longer feasible.
You may include "gaps", when a tracking point is temporarily disabled or unavailable,
but you should start a new track for each distinct new feature to be tracked.

Each track contributes to the overall result by the degree controlled through its *Stab Weight* parameter.
It is evaluated on a per frame base, which enables us to control the influence of a track by *animating* this
*Stab Weight*. You may imagine the overall working of the stabilizer as if each tracking point "drags" the image
through a flexible spring: When you turn down the *Stab Weight* of a tracking point, you decrease the amount of "drag"
it creates. Sometimes the contribution of different tracks has to work partially counter each other.
This effect might be used to cancel out spurious movement, e.g. as caused by perspective.
But when, in such a situation, one of the involved tracks suddenly goes away,
a jump in image position or rotation might be the result. Thus, whenever we notice
a jump at the very frame where some partially covered track starts or ends, we need to soften the transition.
We do so by animating the *Stab Weight* gradually down, so that it reaches zero at the boundary point.
In a similar vein, when we plan a "handover" between several partially covered tracks, we define a *cross-fade* over
the duration where the tracks overlap, again by animating the *Stab Weight* parameters accordingly.
But even with such cross-fade smoothing, some residual movement might remain,
which then needs to be corrected with the *Expected Position*
or *Expected rotation* parameters. It is crucial to avoid "overshooting" movements in such a situation --
always strive at setting the animation keyframes onto precisely
the same frame number for all the tracks and parameters involved.

***************
Dope Sheet View
***************

.. figure:: /images/editors_movie-clip_dopesheet.png

Dope Sheet View.

The dope sheet view is used to visualize motion tracking data,
it implemented as separate view of the movie clip editor just like the Graph View.

It displays channels for selected tracks and each channel visualizes tracked
segments of tracks as dark bars and keyframed positions of tracks as small diamonds.

The background is highlighted depending on the number of tracks in a frame.
This means that if for a frame (or sequence of frames) there are less than eight tracks,
the background will turn red;if there are from eight to sixteen tracks, the background will be yellow.

This is only a visual feedback, which doesn't mean that the camera motion will not
reconstruct with less than eight tracks. It only means that you should pay attention to those frames and
check if all possible good feature points are tracked there. Remember, if there are no good feature points in
the frame and there are less than 16 tracks in the frame, it doesn't mean the solution won't be accurate.
Rather, adding more tracks on bad feature points will reduce the accuracy of solution.

Header
=======

.. figure:: /images/editors_movie-clip_dopesheet_sort.png
:align: right

Sort Channels Order.

Show
Only selected (mouse cursor icon)
ToDo.
Hidden (ghost icon)
ToDo.
Sort Method
Sort order of the tracks.

Name
Sort selected tracks in alphabetical order based on their names.
Longest
Sort tracks by longest tracked segment length.
Total
Sort tracks by overall amount of frames.
Average Error
Sort tracks by their average reprojection error after solving camera or object motion.
Invert
To change the sort order from ascending to descending.

Usage
=====

Currently the dope sheet view is for visualization and does not have any tools to actually edit data.

**********
Graph View
**********

.. figure:: /images/editors_movie-clip_graph.png

Graph View.

Introduction
============

The graph or curves view has numerous purposes based on the color of the lines.
The red and green lines on the graph show you the speed of the trackers at a given frame.
Green is vertical movement, Red is horizontal. Therefore the first frames will always be at zero.

The blue line is the line that comes out when you click on the film strip is the average per frame error.
This curve is available only after pressing camera solve and is not editable.
This is the one line that you want to be as flat as possible and as closer to zero as you can.
The high points will show you where in your shot you are having inaccurate tracking.

Frames outside of scene frame range are darkened.

Header
=======

Show
Only selected (mouse cursor icon)
Hidden (ghost icon)
Filter
Display options.

Frames
ToDo.
Motion
ToDo.
Error
Per-frame reprojection error of tracks.

Usage
=====

The curves are useful to see if particular trackers are moving differently than the average.
A line that spikes from the rest of the curve usually means a tracking error.

You can manually edit the curve by selecting a point in the curve and dragging it or deleting,
that will affect the corresponding tracker on that particular frame.

Lock to Time Cursor :kbd:`L`
Locked the time cursor the view center.

###################
Motion Tracking
###################

.. toctree::
:maxdepth: 2

introduction.rst
clip/index.rst
graph.rst
dopesheet.rst

************
Introduction
************

Motion Tracking is used to track the motion of objects and applying that data to 3D object through the compositor.
Blender's motion tracker supports a couple of very powerful tools for 2D tracking and 3D motion tracking,
including camera tracking and object tracking, as well as some special features like the plane track for compositing.
Tracks can also be used to move and deform masks for rotoscoping in the Mask Editor,
which is available as a special mode in the Movie Clip Editor.

Views
======

In Tracking Mode there are three different views available. You can toggle between view modes using
the View menu, which is located in the header.
When you selected a view in the whole area of the Movie Clip editor will change.
Hence, to display a curve or dope sheet view, the editor must be split into two,
with one switched to the curve or dope sheet view.

Manual Lens Calibration
=======================

All cameras record distorted video.
Nothing can be done about this because of the manner in which optical lenses work.
For accurate camera motion,
the exact value of the focal length and the "strength" of distortion are needed.

Currently, focal length can be automatically obtained only from the camera's settings or from
the EXIF information. There are some tools which can help to find approximate values to compensate for distortion.
There are also fully manual tools where you can use a grid which is getting affected by distortion model and deformed
cells defines straight lines in the footage.

You can also use the grease pencil for this -- just draw a line which should be straight on the footage using poly
line brush and adjust the distortion values to make the grease pencil match lines on the footage.

To calibrate your camera more accurately, use the grid calibration tool from OpenCV.
OpenCV is using the same distortion model, so it should not be a problem.

Camera and Object Motion Solving
================================

Blender not only supports the solving of camera motion, including tripod shots,
but also the solving of object motion in relation to the motion of the camera.
In addition to that there is the Plane Track, which solves the motion of all markers on one plane.

There are also plans to add more tools in the future, for example more automatic tracking and solving,
multi-camera solving and constrained solutions.

Tools for Scene Orientation and Stabilization
=============================================

After solve, you need to orient the real scene in the 3D scene for more convenient compositing.
There are tools to define the floor, the scene origin, and the X/Y axes to perform scene orientation.

Sometimes, the video footage includes spurious jumps and tilting movements, like e.g. when using a hand held camera.
Based on some tracked image elements, the
:doc:`/editors/movie_clip_editor/tracking/clip/properties/stabilization/index`
is able to detect and compensate such movements to improve the quality of the final result.

##############
NLA Editor
##############

.. toctree::
:maxdepth: 2

introduction.rst
tracks.rst
strips.rst
properties_modifiers.rst

************
Introduction
************

The NLA editor, short for Non-Linear Animation, can manipulate and repurpose :doc:`/animation/actions`,
without the tedium of handling keyframes. It is often used to make broad,
significant changes to a scene's animation, with relative ease.
It can also re-purpose, chain together a sequence of motions, and "layer" actions, which make it easier to organize,
and version-control your animation.

Header
=======

View Menu
---------

Show Control F-Curves
ToDo.
Show Local Markers
ToDo.

**********************
Properties &amp; Modifiers
**********************

Properties
==========

Strip properties can be accessed via the NLA Properties region.

Animation Data
--------------

.. figure:: /images/editors_nla_animation-data-panel.png

Animation Data panel

Context
ToDo.
Action
:ref:`Data-Block &lt;ui-data-block&gt;` allows you to edit actions shown in the action track.
See also the Action Editor's :ref:`Action &lt;dopesheet-action-action&gt;`.
Action Extrapolation
Action to take for gaps past the strip extents.

Hold
Affects both sides of the strip.
Hold Forward
Affects the region after the clip, only.
Nothing
Neither.

Action Blending
Affects the behavior when two tracks simultaneously have a curve affecting the same property.

Replace
Causes the top strip to take precedence according to the parameters
of the Blend In/Out (see next option, below).

Multiply, Subtract, Add
Action Influence
ToDo.

Active Track
------------

Name
Name of the track which the strip currently belongs to.

Active Strip
------------

.. figure:: /images/editors_nla_active-strip-panel.png

Active Strip panel

Options of the strip itself.

Name
Renames the strips.
Type
Will either say "Action Clip", "Transition", or "Meta", according to the three types of strips.
Strip Extents
The boundaries of the strip itself. Note that this will stretch the duration of the Action,
it will not cause greater or fewer keyframes from the Actions to play (see below for that option).
Extrapolation
See *Action Extrapolation* above.
Blending
See *Action Blending* above.
Auto Blend In/Out
Creates a ramp starting at the overlap of the strips. The first strip has full control,
and it ramps linearly giving the second strip full control by the end of the overlapping time period.
Blend In
Set the frame that represents when this strip will have full influence.
Blend Out
Set the last frame of this strip's full influence.
Muted
Mute a single strip (like muting the track, above). Causes the track outline to be dashed.
Reversed
Cause this strip to be played completely backwards.

Action Clip
-----------

.. figure:: /images/editors_nla_action-clip-panel.png

Action Clip panel

This represents the 'object data' of the strip. Much like the transform values of an object.

Action
A reference to the Action contained within the strip.
Can be changed to replace the current strip's value with another Action.
Action Extents
How much of the Action to use.

Note: If you select values that are above or below the actual keyframe count of the Action,
then the F-Curve Extrapolation will be consulted.
Which can be changed in the Graph Editor, under :menuselection:`Channel --&gt; Extrapolation Mode`.
Sync Length
Causes the "Start" and "End" Frames, above, to be reset to the first and last keyframed frames of the Action.
Sync Action Length "Now"
Causes the "Start" and "End" Frames, above, to be reset to the first and last keyframed frames of the Action.
Playback Settings
Scale
Stretches strip, another way of increasing the *Strip Extents: End Frame*, above.
Repeat
Also expands the strip, but by looping from the first keyframe and going forward.

Evaluation
----------

.. figure:: /images/editors_nla_evaluation-panel.png

Evaluation panel

This determines the degree of influence the strip has, and over what time.

Animated Influence
Enabling alteration of the degree of influence this strip has as a keyframable value.
If influence isn't animated, the strips will fade linearly, during the overlap.

These can be found in the Dope Sheet or Graph Editors under the *NLA Control Curves* and
look like group channels. They appear before all the groups/FCurves for that channel.
Animated Strip
Same as *Animated Influence*, but with *Strip Time*.
Cyclic Strip Time
Cycle the animated time within the action start and end.

Modifiers
=========

Like its close cousins in mesh and graph editing,
Modifiers can stack different combinations of effects for strips.

See :doc:`F-Curve Modifiers &lt;/editors/graph_editor/fcurves/fmodifiers&gt;`.

******
Strips
******

Types
=====

There are four kinds of strips: Action, Transition, Sound clip and Meta.

Action Strips
-------------

An Action Strip is a container of keyframe data of an action.
Any action used by the NLA first must be turned into an Action strip.
This is done so by clicking the Push Down action button see above.
Alternatively, you can go to :menuselection:`Add --&gt; Action Strip`.

Transition Strips
-----------------

Transitions interpolate between Actions. They must be placed in between other strips.
Select two or more strips on the same track,
and go to: :menuselection:`Add --&gt; Transition`.

.. figure:: /images/editors_nla-basics_transition.png

Transition Strip.

Sound Clip Strips
-----------------

Controls when a speaker plays a sound clip.
:menuselection:`Add --&gt; Sound Clip`.

Meta Strips
-----------

Meta strips group strips together as a whole, so you can move them as one.
If you find yourself moving a lot of strips together, you can group them into a Meta strip.
A meta strip can be moved and duplicated like a normal strip.

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Add --&gt; Add Meta-Strips`
| Hotkey:   :kbd:`Shift-G`

.. list-table::

* - .. figure:: /images/editors_nla_meta_strips_01.png
:width: 200px

Shift-select two or more strips.

- .. figure:: /images/editors_nla_meta_strips_02.png
:width: 200px

Combine them into a meta strip.

A meta strip still contains the underlying strips. You can ungroup a Meta strip.

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Add --&gt; Remove Meta-Strips`
| Hotkey:   :kbd:`Alt-G`

Editing
=======

Start Tweaking Strips Action
----------------------------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Edit --&gt; Start Tweaking Strips Action`
| Hotkey:   :kbd:`Tab`

The contents of Action strips can be edited, but you must be in *Tweak Mode* to do so.
The keyframes of the action can then be edited in the Dope Sheet.

.. list-table::

* - .. figure:: /images/editors_nla_strip_nla_mode.png
:width: 200px

Strip in NLA mode.

- .. figure:: /images/editors_nla_strip_editmode.png
:width: 200px

Strip in Tweak mode.

When your finished editing the strip, simply go to :menuselection:`Edit --&gt; Tweaking Strips Action`
or press :kbd:`Tab`.

Start Editing Stashed Action
----------------------------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Edit --&gt; Start Editing Stashed Action`
| Hotkey:   :kbd:`Shift-Tab`

It will enter and exit Tweak Mode as usual, but will also make sure that the action can be edited in isolation
(by flagging the NLA track that the action strip comes from as being "solo").
This is useful for editing stashed actions, without the rest of the NLA Stack interfering.

Duplicate
---------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Edit --&gt; Duplicate`
| Hotkey:   :kbd:`Shift-D`

Creates a new instance of the selected strips with a copy of the action.

Linked Duplicate
----------------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Edit --&gt; Linked Duplicate`
| Hotkey:   :kbd:`Alt-D`

The contents of one Action strip can be instanced multiple times. To instance another strip,
select a strip, go to :menuselection:`Edit --&gt; Linked Duplicate`.
It will uses the same action as the selected strips.

Now, when any strip is tweaked, the others will change too.
If a strip other than the original is tweaked,
the original will turn to red.

.. figure:: /images/editors_nla_linked-strip-edit.png

Linked duplicated strip being edited.

Make Single User
----------------

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Edit --&gt; Make Single User`
| Hotkey:   :kbd:`U`

This tools ensures that none of the selected strips use an action which is also used by any other strips.

.. (dev) NOTE: This does not recursively go inside meta's, so care is still advised in that case.

******
Tracks
******

Tracks are the layering system of the NLA. At its most basic level,
it can help organize strips. But it also layers motion much like an image editor layers pixels --
the bottom layer first, to the top, last.

.. figure:: /images/editors_nla_tracks.png

NLA Tracks and Strips.

Solo (star icon)
Toggling *Solo Track* causes only the selected tracks effects to be visible when animating.
Mute (speaker icon)
Keeps the track from having an effect on the animation. (Mute only applies when *Solo* is not used).
All strips in that track are drawn as being muted (dashed outline).
Lock (padlock icon)
Prevents changes from being made to this layer.

Action Track
============

By default, the Action Editor automatically stores the keyframes you create through the 3D View
by storing them into an action based on the name as the object you are working on.

.. (alt) icon: downwards chevron

Push Down (double down arrow peak icon)
Turns the active action into a new NLA strip at the top of the NLA stack.

.. figure:: /images/editors_nla_push-down-button.png

Push Down action button.

Pin (pin icon)
If you try moving the strip, while in *Tweak Mode*,
you will notice that the keys will go along with it. On occasion,
you will prefer the keys to remain on their original frames, regardless of where the strip is.
To do so, hit the *unpin* icon, next to the strip.

.. figure:: /images/editors_nla_pinned_01.png

NLA strip with pinned keys.

.. figure:: /images/editors_nla_pin_02.png

Strip moved, notice the keys move with it.

.. figure:: /images/editors_nla_pin_03.png

The unpinned keys return to their original frames.

.. (todo) add track

.. (todo) Action Stashing http://aligorith.blogspot.com/2015/03/action-management-roadmap-2015-version.html

Action Stashing
===============

When creating a new action, if the existing action only has a single user (i.e. the current reference only),
it will get "stashed" in the NLA stack. Action Stashing should prevent most cases actions getting lost.

The action "stashing" method works by storing otherwise unused/dormant actions in the NLA stack
as strips in special muted NLA Tracks. This way, Blender can "know" that the action is related
to a particular data-block (i.e. to a specific object, or to a specific material/lamp/etc.) and
that you still want to keep it for later use.

Deleting &amp; Converting
---------------------

If you decide that you no longer want a stashed action anymore, simply delete the corresponding NLA strip,
then save and reload the file.

Also, note that since these are NLA strips, you can reuse these as normal NLA strips simply by un-muting
(and renaming) the NLA track they live in. You may also want to move it above all the other stashed-action tracks.

Remove Empty Animation Data
===========================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Edit --&gt; Remove Empty Animation Data`

This operator removes AnimData blocks (restricted to only those
which are visible in the animation editor where it is run from) which are "empty"
(i.e. that is, have no active action, drivers, and NLA tracks or strips).

It is sometimes possible to end up with a lot of data-blocks which have old and unused
Animation Data containers still attached. This most commonly happens when doing motion
graphics work (i.e. when some linked-in objects may have previously been used to develop
a set of reusable assets), and is particularly distracting in the NLA Editor.
.. _editors-node-index:

###############
Node Editor
###############

.. toctree::
:maxdepth: 2

introduction.rst
navigate.rst
nodes/index.rst

************
Introduction
************

.. figure:: /images/editors_node_example.jpg

The Node Editor.

The *Node Editor* is used to work with node-based work flows.
The node tree type can be changed using the buttons in the Node editor header.
However, here we will only give an overview of what the *Node Editor* is.
In the list below it shows a list of different types of node trees and where each is documented.

.. _node-tree-types:

.. list-table::
:header-rows: 1
:class: valign
:widths: 10 30 60

* - Icon
- Name
- Documentation
* - .. figure:: /images/icons_material.png
:width: 35px
- Material Nodes
- Because there are two different render engines documentation is split between :doc:`Blender Internal
&lt;/render/blender_render/materials/nodes/index&gt;` and :doc:`Cycles &lt;/render/cycles/nodes/index&gt;`.
* - .. figure:: /images/icons_render-layers.png
:width: 35px
- Composite Nodes
- Documentation can be found in the :doc:`Compositing &lt;/compositing/index&gt;` section.
* - .. figure:: /images/icons_texture.png
:width: 35px
- Texture Nodes
- Texture Nodes are covered in the
:doc:`Blender Internal &lt;/render/blender_render/textures/nodes/introduction&gt;` docs.

After choosing what node context you want to use, you have to enable nodes with the *Use Nodes* button.

Interface
=========

Header
------

The *Header* contains various menus, buttons and options, partially based on the current node tree type.

.. figure:: /images/editors_node-editor_introduction_header.png

Common Node Header Options.

View
This menu changes your view of the editor.
Select
This menu allows you to select a node or groups of nodes.
Add
This menu allows you to add nodes.
Node
To do things with selected nodes, akin to vertices.
Material, Compositing or Texture buttons
Nodes are grouped into three categories, to see the list see :ref:`Node Tree Types &lt;node-tree-types&gt;`.
Use Nodes
Tells the render engine to use the node map in computing the material color or rendering the final image,
or not. If not, the map is ignored and the basic render of the material tabs or scene is accomplished.
Use Pinned
When enabled, the editor will retain the material or texture, even when the user selects a different object.
A node tree can then be edited independent of the object selection in the 3D view.
Go to Parent button
This button allows you go to parent node tree e.g. leaving a group.

.. _editors-nodes-usage-auto-offset:

Auto-offset
^^^^^^^^^^^

When you drop a node with at least one input and one output socket onto an existing connection between two nodes,
auto-offset will, depending on the direction setting, automatically move the left or right node away to make room
for the new node.
Auto-offset is a feature that helps organizing node layouts interactively without interrupting the user workflow.

.. figure:: /images/editors_node-editor_nodes_auto-offset.png

Auto-offset is enabled by default, but it can be disabled from the Node editor header.

You can toggle the offset direction while you are moving the node by pressing :kbd:`T`.

The offset margin can be changed using the *Auto-offset Margin*
setting in the editing section of the User Preferences.

.. seealso:: Example Video:

`Auto-Offset. A workflow enhancement for Blender’s node editor. &lt;https://vimeo.com/135125839&gt;`__

Further Menus
^^^^^^^^^^^^^

Snap
Toggle snap mode for node in the Node Editor.
Snap Node Element Selector
This selector provide the follow node elements for snap:

:Grid: (default) Snap to grid of the Node Editor.
:Node X: Snap to left/right node border.
:Node Y: Snap to top/bottom node border.
:Node X/Y: Snap to any node border.

Snap Target
Which part to snap onto the target.

:Closest: Snap closest point onto target.
:Center: Snap center onto target.
:Median: Snap median onto target.
:Active: Snap active onto target.

Copy Nodes
This button allows you copy selected nodes to the clipboard.
Paste Nodes
This button allows you paste nodes from the clipboard to the active node tree.

Tool Shelf
----------

The *Tool Shelf* is a context-sensitive region, natively containing tools for the Grease Pencil
and buttons for adding nodes. The Tool Shelf is organized using tabs.

Properties Region
-----------------

The *Properties Region* contains properties for the current selected node as well as Node editor specific settings.

**********
Navigating
**********

Navigating the Node editor is done with the use of both mouse movement and keyboard shortcuts.

Pan :kbd:`MMB`
Move the view up, down, left and right
Zoom :kbd:`Ctrl-MMB`, :kbd:`Wheel`
Move the camera forwards and backwards.
View Selected
:kbd:`Period`
View All
:kbd:`Home`

Node Editor Actions
===================

When the cursor is in the area, several standard Blender hotkeys and mouse actions are available, including:

Search... (add menu)
Brings up a pop-up menu, allowing you to search the available nodes.
Undo
:kbd:`Ctrl-Z`
Redo
:kbd:`Ctrl-Y` or :kbd:`Ctrl-Shift-Z` -- You can use this if you used "undo" a bit too often.

****************
Adding &amp; Editing
****************

Adding
======

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:     :menuselection:`Tool Shelf`
| Menu:     :menuselection:`Add`
| Hotkey:   :kbd:`Shift-A`

Nodes are added in two ways to the Node editor:

- By using the Tool Shelf which has buttons for adding nodes, organized with tabs.
- By using the :menuselection:`Add` menu :kbd:`Shift-A`.

Transform
=========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Node --&gt; Translate, Rotate, Resize`
| Hotkey:   :kbd:`G`, :kbd:`R`, :kbd:`S`

Move a single node by click and drag it around. A node can be clicked almost anywhere to start dragging.
Multiple nodes can be translated after pressing :kbd:`G`.

In general it is recommended to arrange your nodes within the view such that the data flows from
left to right, top to bottom.

A node can be resized by dragging the edges on the left or right side.

Connecting Sockets
==================

Interactively
-------------

:kbd:`LMB`-click on a socket and drag. You will see a line coming out of it: This is called a *link*.

Keep dragging and connect the link to an input socket of another node, then release the :kbd:`LMB`.

While multiple links can route out of an output socket, only a single link can be attached to an input socket.

To reposition the outgoing links of a node, rather than adding a new one, hold :kbd:`Ctrl` while dragging from an
output socket. This works for single as well as for multiple outgoing links.

Nodes that have no connections can be inserted on a link.
Just move the node over the link and release when the link turns orange.

Make Links :kbd:`F`
Select multiple nodes with open sockets, then use the Make Links to create links between them.
Use Make Links again if there are other nodes which can be connected.

Make and Replace Links :kbd:`Shift-F`
Make and Replace Links replaces similarly to Make Links, but it will replace existing links if any exist.

Disconnecting Sockets
=====================

Interactively
-------------

Drag the link from an input socket and let it go keeping it unconnected.

Cut Links
---------

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Node --&gt; Cut Links`
| Hotkey:   :kbd:`Ctrl-LMB`

To break a link between sockets :kbd:`Ctrl-LMB`-click in an empty area, near the link you want to disconnect, and
drag: You will see a little cutter icon appearing at your mouse pointer. Move it over the link itself, and
release the :kbd:`LMB`.

Detach Links
Use Detach Links in order to cut all links attached to selected nodes at once.

Duplicate
=========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Node --&gt; Duplicate`
| Hotkey:   :kbd:`Shift-D`

Click :kbd:`LMB` or :kbd:`RMB` on the desired node, press :kbd:`Shift-D` and move the mouse away to see the
duplicate of the selected node appearing under the mouse pointer.

.. note::

When you duplicate a node, the new node will be positioned *exactly* on top of the node that was duplicated.
If you leave it there (and it is quite easy to do so),
you can **not** easily tell that there are *two* nodes there!
When in doubt, grab a node and move it slightly to see if something's lurking underneath.

Delete
======

Delete :kbd:`X`, :kbd:`Delete`
Deletes the selected node(s).
Delete with Reconnect :kbd:`Ctrl-X`
Delete the node(s) without loosing the connections.

Mute
====

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Node --&gt; Toggle Node Mute`
| Hotkey:   :kbd:`M`

Muting a node removes the contribution of the node to the node tree,
and makes all links pass through that node without change.
Links will appear red as an indicator of passing through the muted node.

Show/Hide
=========

Hide
:kbd:`H`
Toggle Node Preview
:kbd:`Shift-H`
Toggle Hidden Node Sockets
:kbd:`Ctrl-H`
Toggle Node Options
..
Collaps and Hide Unused Sockets
..

Layers
======

Read Render-Layers
:kbd:`Ctrl-R`
Read Full Sample Layers
:kbd:`Shift-R`

***********
Node Groups
***********

Grouping nodes can simplify a node tree by allowing instancing and hiding parts of the tree.
Both material and composite nodes can be grouped.

Conceptually, grouping nodes allows you to specify a *set* of nodes that you can treat as
though it were "just one node". Node groups are similar to functions in programming.
You can then re-use it inside, which are then called "NodeGroups",
or in other blend-file(s), when appending called "NodeTrees".

As an example:  If you have created a material that you would like to use with different inputs
e.g. diffuse color: red plastic, green plastic. You could create different materials with *Make Single User*
for each different color with a copy of the tree part describing the plastic material.
If you like to edit the material you would need to redo the edit on all materials.
A better method of re-use is to create node groups, exposing only the variable inputs (e.g. diffuse color).

Also nested node groups are supported. I.e. a node group can be inserted or created inside another node group.

.. note:: Recursion

Recursive node groups are prohibited for all the current node systems to prevent infinite recursion.
A node group can never contain itself (or another group that contains it).

Make Group
==========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Group --&gt; Make Group`
| Hotkey:   :kbd:`Ctrl-G`

To create a node group, in the Node editor, select the nodes you want to include, then
press :kbd:`Ctrl-G`, :menuselection:`Group --&gt; Make Group`.
A node group will have a green title bar. All of the selected nodes will now be contained within the group node.
Default naming for the node group is "NodeGroup", "NodeGroup.001" etc.
There is a name field in the node group you can click into to change the name of the group.
Change the name of the node group to something meaningful.
When appending node groups from one blend file to another,
Blender does not make a distinction between material node groups or composite node groups,
so it is recommended some naming convention, that will allow you to easily distinguish between the two types.

.. tip::

What **not** to include in your groups (all modes of Node editors)

Remember that the essential idea is that a group should be an easily-reusable,
self-contained software component. Material node groups should **not** include:

Input nodes
If you include a source node in your group,
you will end up having the source node appearing *twice*: once inside the group,
and once outside the group in the new material node-network.
Output node
If you include an output node in the group, there will not be an output socket available *from* the group!

Edit Group
==========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Group --&gt; Edit Group`
| Header:   :menuselection:`Go to Parent Node Tree`
| Hotkey:   :kbd:`Tab`, :kbd:`Ctrl-Tab`

With a group node selected, :kbd:`Tab` expands the node to a frame, and the individual nodes within
it are shown. You can move them around, play with their individual controls, re-thread them internally, etc.
just like you can if they were a normal part of the editor view. You will not be able, though, to thread them to a
node outside the group; you have to use the external sockets on the side of the group node. To add or
remove nodes from the group, you need to ungroup them.
While :kbd:`Tab` can be used to both enter and exit a group, :kbd:`Ctrl-Tab` only exits.

Interface
---------

Interactively
^^^^^^^^^^^^^

The Input/Output sockets are part of the regular nodes Group Input/Group Output.

ToDo.

Panel
^^^^^

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Properties region --&gt; Interface`

Sockets can be added or removed, descriptive names can be added and the details of the input data value defined here.

ToDo.

Ungroup
=======

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Group --&gt; Ungroup`
| Hotkey:   :kbd:`Alt-G`

The :kbd:`Alt-G` tool removes the group and places the individual nodes into your editor workspace.
No internal connections are lost, and now you can thread internal nodes to other nodes in your workspace.

Group Insert
============

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Group --&gt; Group Insert`

ToDo.

.. move node into selected group

Adding a Group Instance
=======================

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Add --&gt; Group`

ToDo.

Appending Node Groups
=====================

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Info Editor --&gt; File --&gt; Link/Append`

Once you have appended a NodeTree to your blend-file, you can make use of it in the Node editor by
pressing :kbd:`Shift-A`, :menuselection:`Add --&gt; Group`, then select the appended group.
The "control panel" of the Group is the individual controls for the grouped nodes.
You can change them by working with the Group node like any other node.

#########
Nodes
#########

.. toctree::
:maxdepth: 2

introduction.rst
parts.rst
selecting.rst
editing.rst
properties.rst
groups.rst

************
Introduction
************

Todo.

.. (todo) links

**********
Node Parts
**********

All nodes in Blender are based off of a similar construction.
This applies to :ref:`any type of node &lt;node-tree-types&gt;`.
These parts include the Title, Sockets, Preview and more.

.. figure:: /images/editors_node_parts.png

Title
=====

The *Title* shows the name/type of the node.
It can be overridden by changing the value of Label in the *Node* section of the *Properties Region* :kbd:`N`.
On the left side of the title is the *collapse toggle*
which can be used to collapse the node this can also be done with :kbd:`H`.

.. figure:: /images/editors_node_collapsed.png

How a node appears when collapsed.

Sockets
=======

The *Sockets* input and output values from the node.
They appear as little colored circles on either side of the node.
Unused sockets can be hidden with :kbd:`Ctrl-H`.
There are two functions of sockets; `inputs`_ and `outputs`_.

Each socket is color-coded depending on what type of data it handles.

Color (Yellow)
Indicates that color information needs to be input or will be output from the node.
This may or may not include an alpha channel.
Numeric (Grey)
Indicates numeric values information.
It can either be a single numerical value or a so-called "value map".
(You can think of a value map as a grayscale-map where the different amount of
bright/dark reflects the value for each point).
If a single value is used as an input for a "value map" socket, all points of the map are set to this same value.
Common use: Alpha maps and value options for a node.
Vector (Blue)
Indicates vector, coordinate and normal information.
Shader (Green)
Used for shaders in :doc:`Cycles &lt;/render/cycles/index&gt;`

Inputs
------

The *Inputs* are located on bottom left side of the node,
and provide the data the node needs to perform its function.
Each input socket, except for the green shader input, when disconnected,
has a default value which can be edited via a color, numeric, or vector interface input.
In the screen shot of the node above, the second color option is set by a color interface input.

Outputs
-------

The *Outputs* are located on the top right side of the node,
and can be connected to the input of nodes further down the node tree.

Properties
==========

Many nodes have settings which can affect the way they interact with inputs and outputs.
Node settings are located below the outputs and above any inputs.

.. figure:: /images/editors_node_controls.png

An example of the controls on the chroma key node.

Preview
-------

On some nodes this shows a preview image of how the output data for a certain channel will appear.
Usually it shows color data.

The preview can be toggled using the icon on the very top right hand corner of the node, next to the title.

.. figure:: /images/editors_node_previewless.png

How a node appears without the preview.

**********
Properties
**********

In the properties region.

Node Panel
==========

Name
A unique node identifier.
Label
Nodes can be given a title by modifying the text field.

Color Panel
===========

Color Presets
Colors saved as a preset for re-use in other nodes.
Color
Color of the node background. Node colors can be used to provide a visual cue.

*********
Selecting
*********

Border Select
:kbd:`B` starts the bounding box selection process.
Position your cursor and :kbd:`LMB` click &amp; drag to select a set of nodes.
Cut connections (lasso)
:kbd:`Ctrl-Alt-LMB` click &amp; drag starts a lasso selection, **but** when you let up the mouse button,
all threads (connections) within the lasso are broken.

(De)select All
:kbd:`A`
Inverse
:kbd:`Ctrl-I`
Select Linked From
:kbd:`L`
Select Linked To
:kbd:`Shift-L`
Select Grouped :kbd:`Shift-G`
Selects similar nodes to the active node
by their :doc:`properties &lt;/editors/node_editor/nodes/properties&gt;`.

Type
The node type. e.g. all Math nodes.
Color
The color property.
Prefix, Suffix
Matches the name property from start/end of the text.
Activate Same Type Previous/Next :kbd:`Shift-]`/:kbd:`Shift-[`
Finds the previous/next node of same type, activates the node, and ensures the node is visible.
Find Node :kbd:`Ctrl-F`
To search for a node. On selecting a node, it activates the node and makes sure the node is visible.

Select multiple
:kbd:`Shift-LMB` or :kbd:`Shift-RMB` used for multiple node selection.

********
Outliner
********

.. figure:: /images/editors_outliner.png

The Outliner editor.

The *Outliner* is a list that organizes data in the blend-file.
i.e. the scene data and also the User Preferences.

.. rubric:: Usage

- View the data in the scene.
- Select and deselect objects in the scene.
- Hide or show an object in the scene.
- Enable or disable selection (to make an object "unselectable" in the 3D View).
- Enable or disable the rendering of an object.
- Delete objects from the scene.
- Unlink data (equivalent to pressing the *X* button next to the name of a data-block).
- Easily select which render layer to render.
- Easily select which render pass to render (for example, you can choose to render just the *Specular* pass).

Tree View
=========

Each row in the *Outliner* shows a data-block. You can click the plus-sign to the
left of a name to expand the current data-block and see what other data-blocks it contains.

You can select data-blocks in the *Outliner*,
but this will not necessarily select the data-block in the scene.
To select the data-block in the scene, you have to activate it.

Selecting and Activating
------------------------

Single selection does not require any pre-selection: just work directly with :kbd:`LMB`
(and/or :kbd:`RMB` -- contextual menu, see below) *inside* the name/icon area.

When you select an object in the list this way,
it is selected and becomes the active object in all other 3D Views.

Activating a data-block
^^^^^^^^^^^^^^^^^^^^^^^

To "activate" the data-block with :kbd:`LMB` on the *icon* of the data-block.
Activating the data-block will automatically switch to the relevant mode.
For example, activating the mesh data of the cube will select the cube
and enter *Edit Mode* while activating the object data of the
cube will select the cube and enter *Object Mode* (see right).

Selecting a group of data-blocks
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Useful when you want to select/deselect a whole bunch of data-blocks.
For this you must prepare the selection using, to your liking:

- :kbd:`RMB` or :kbd:`LMB`,
- :kbd:`Shift-RMB` or :kbd:`Shift-LMB`,
- :kbd:`RMB` and drag or :kbd:`LMB` and drag,

all *outside* the name/icon area. Those pre-selected have their line in a lighter color.
You then can (de)select them with a :kbd:`RMB` *on* the name/icon area,
which brings on a context menu (see bellow).
:kbd:`A` to select/deselect all open items.

.. figure:: /images/editors_outliner_column-icons.png

Selection of a data-block.

Context menu
^^^^^^^^^^^^

Show the context menu for a data-block with :kbd:`RMB` on the icon or name.
Depending on the type of the pre-selected data-block(s), you will have all or part of the following options:

Select, Deselect
..
Unlink
To unlink a data-block from its "owner" (e.g., a material from its mesh).
Make Local
To create a "local" duplicate of this data-block.
Make Single User
ToDo.
Delete
ToDo.
Delete Hierarchy
Deletes the object and all of its child objects.
Remap Users
ToDo.
Add Fake User, Clear Fake User
ToDo.
Rename
ToDo.
Select Linked
ToDo.

.. note::

Some data-block types will not have a context menu at all!

Object-level Restrictions
-------------------------

The three following toggles, in the right side of the *Outliner* editor,
are available for objects, modifiers and constraints.
When holding :kbd:`Ctrl` all its child objects are affected as well.

Visibility (eye icon)
Toggles the visibility of the object in the 3D View.
:kbd:`V` will toggle this property for any objects that are selected in the *Outliner*.
Selectability (mouse cursor icon)
This is useful for if you have placed something in the scene
and do not want to accidentally select it when working on something else.
:kbd:`S` will toggle this property for any objects that are selected in the *Outliner*.
Rendering (camera icon)
This will still keep the object visible in the scene, but it will be ignored by the renderer.
:kbd:`R` will toggle this property for any objects that are selected in the *Outliner*.

Header
======

View Menu
---------

Sort Alphabetically
Sort the entries alphabetically.
Show Restriction Columns
Toggles the three columns of `Object-level Restrictions`_.

Show Active
Centers the Tree View to selected object :kbd:`Period`.
Show/Hide One Level
Expand one level down in the tree :kbd:`NumpadPlus` and :kbd:`NumpadMinus` to collapse.
Show Hierarchy
To collapse all levels of the tree :kbd:`Home`.

Display Mode
------------

The editors header has a select menu that let you filter what the Outliner should show. It helps to narrow the
list of objects so that you can find things quickly and easily.

All Scenes
Shows *everything* the *Outliner* can display (in all scenes, all layers, etc.)
Current Scene
Shows everything in the current scene.
Visible Layers
Shows everything on the visible (currently selected) layers in the current scene.
Use the :doc:`layer &lt;/editors/3dview/object/properties/relations/layers&gt;` buttons
to make objects on a layer visible in the 3D View.
Selected
Lists the object(s) that are currently selected in the 3D View.
See :doc:`selecting in the 3D View &lt;/editors/3dview/object/selecting/index&gt;` for more information.
Active
Lists only the active (often last selected) object.
Same Types
Lists only those objects in the current scene that are of the same types as those selected in the 3D View.
Groups
Lists only :doc:`Groups &lt;/editors/3dview/object/properties/relations/groups&gt;` and their members.
Sequence
Lists :doc:`data-block &lt;/data_system/data_blocks&gt;`
that are used by the :doc:`Sequencer &lt;/editors/vse/index&gt;`.
Blender File
Lists all data in the current blend-file.
Data-Blocks
Lists every :doc:`data-block &lt;/data_system/data_blocks&gt;` along with any properties that they might have.
User Preferences
Lists options that can be found in the :doc:`User Preferences &lt;/preferences/index&gt;`
along with some other settings.
Orphan Data
Lists :doc:`data-blocks &lt;/data_system/data_blocks&gt;`
which are unused and/or will be lost when the file is reloaded.

Searching
---------

You can search the view for data-blocks,
by using Search field in the header of the *Outliner*,
The *Search* menu lets you toggle the following options:

- Case Sensitive Matches Only
- Complete Matches Only

.. Edit menu for data-blocks

Example
=======

.. figure:: /images/editors_outliner_example.png

The Outliner with different kind of data.

*****************
Properties Editor
*****************

.. figure:: /images/editors_properties_top.png
:align: right

Properties editor top part.

The *Properties Editor* is used to edit data and properties for the *Active Scene* and the *Active Object*.

Tabs
====

The Properties editor shows several tabs,
which can be chosen via the icon row in the header.
The tabs are documented in their own manual sections,
the links are listed below.

Scene/Render
------------

These tabs are used to add features, and to change properties for the Active Scene.

.. figure:: /images/editors_properties_render.png
:align: right

Scene/Render tabs.

.. _properties-render-tab:

- :doc:`Render &lt;/render/output/index&gt;` and Settings:
:doc:`Blender Internal &lt;/render/blender_render/settings/index&gt;`, :doc:`Cycles &lt;/render/cycles/settings/index&gt;`
- :doc:`/render/post_process/layers`
- :doc:`Scene &lt;/data_system/scenes/properties&gt;`
- World: :doc:`Blender Internal &lt;/render/blender_render/world/index&gt;`, :doc:`Cycles &lt;/render/cycles/world&gt;`

.. _properties-data-tabs:

Object &amp; Object Data
--------------------

These tabs are used to add features, and to change properties for the Active Object
(and other active elements, material, curve, etc.).

.. figure:: /images/editors_properties_object.png
:align: right

Object Data tabs.

The Object Data tabs shown depend on what type of object was selected last (The Active Object).

- :doc:`Object &lt;/editors/3dview/object/properties/index&gt;`
- :doc:`/rigging/constraints/index`
- :doc:`/modeling/modifiers/index`

..

- :doc:`Mesh &lt;/modeling/meshes/properties/object_data&gt;`
- :doc:`Curve &lt;/modeling/curves/properties/index&gt;`
- :doc:`Surface &lt;/modeling/surfaces/properties&gt;`
- :doc:`Metaball &lt;/modeling/metas/properties&gt;`
- :doc:`Text &lt;/modeling/texts/properties&gt;`
- :doc:`Empty &lt;/modeling/empties&gt;`

..

- :doc:`Armature &lt;/rigging/armatures/properties/index&gt;`
- :doc:`Bones &lt;/rigging/armatures/bones/properties/index&gt;`
- :doc:`Bone Constraints &lt;/rigging/armatures/posing/bone_constraints/introduction&gt;`
- :doc:`Lattice &lt;/rigging/lattice&gt;`

..

- :doc:`Speaker &lt;/render/audio/speaker&gt;`
- Camera: :doc:`Blender Internal &lt;/render/blender_render/camera/object_data&gt;`,
:doc:`Cycles &lt;/render/cycles/camera&gt;`
- Lamp: :doc:`Blender Internal &lt;/render/blender_render/lighting/lights/lamp_panel&gt;`,
:doc:`Cycles &lt;/render/cycles/lamps&gt;`

..

- Material: :doc:`Blender Internal &lt;/render/blender_render/materials/index&gt;`,
:doc:`Cycles &lt;/render/cycles/materials/index&gt;`
- Texture: :doc:`Blender Internal &lt;/render/blender_render/textures/index&gt;`,
:doc:`Cycles &lt;/render/cycles/materials/texture_editing&gt;`
- :doc:`Particles &lt;/physics/particles/index&gt;`
- :doc:`Physics &lt;/physics/index&gt;`

.. (todo) Generic Object Data page?

Main View
=========

.. figure:: /images/editors_properties.png

The Properties Editor with the Mesh tab selected.

At the top of the each tab a list of icons explains the context in which the properties are being edited.
In the example above, the mesh *Cube* is linked to the object *Cube* which is linked to the scene *Scene*.

.. This is a branch of the scene graph?

By toggling the pin symbol on the left side on and off,
Blender can be told to display only the selected property or to follow context.

**************
Python Console
**************

The Python console is a quick way to execute commands,
with access to the entire Python API, command history and auto-complete.

Its a good way to explore possibilities, which can then be pasted into larger scripts.

Introduction
============

Accessing Built-in Python Console
---------------------------------

By pressing :kbd:`Shift-F4` in any Blender Editor type (3D View, Timeline etc.,)
you can change it to a Console Editor.

.. figure:: /images/editors_python-console_1-default.png

The command prompt is typical for Python 3.x,
the interpreter is loaded and is ready to accept commands at the prompt ``&gt;&gt;&gt;``

First look at the Console Environment
-------------------------------------

To check what is loaded into the interpreter environment, type ``dir()``
at the prompt and execute it.

.. figure:: /images/editors_python-console_2-dir.png

Auto Completion
---------------

Now, type ``bpy.`` and then press :kbd:`Ctrl-Spacebar` and you will see the Console
auto-complete feature in action.

.. figure:: /images/editors_python-console_3-completion.png

You will notice that a list of sub-modules inside of ``bpy`` appear. These modules encapsulate all
that we can do with Blender Python API and are very powerful tools.

Lets list all the contents of ``bpy.app`` module.

Notice the green output above the prompt where you enabled auto-completion.
What you see is the result of auto completion listing.
In the above listing all are module attribute names,
but if you see any name end with ``(``, then that is a function.

We will make use of this a lot to help our learning the API faster.
Now that you got a hang of this, lets proceed to investigate some of modules in ``bpy``.

Before tinkering with the modules..
-----------------------------------

If you look at the 3D View in the default Blender scene, you will notice three objects: Cube,
Lamp and Camera.

- All objects exist in a context and there can be various modes under which they are operated upon.
- At any instance, only one object is active and there can be more than one selected object.
- All objects are data in the blend-file.
- There are operators/functions that create and modify these objects.

For all the scenarios listed above (not all were listed, mind you..)
the ``bpy`` module provides functionality to access and modify data.

Examples
========

bpy.context
-----------

.. note::

For the commands below to show the proper output, make sure you have selected object(s) in the 3D View.

.. figure:: /images/editors_python-console_4-bpy-context.png

Try it out!
^^^^^^^^^^^

bpy.context.mode
Will print the current 3D View mode (Object, Edit, Sculpt etc.,).

bpy.context.object or bpy.context.active_object
Will give access to the active object in the 3D View.

Change X location to a value of 1::

bpy.context.object.location.x = 1

Move object from previous X location by 0.5 unit::

bpy.context.object.location.x += 0.5

Changes X, Y, Z location::

bpy.context.object.location = (1, 2, 3)

Same as above::

bpy.context.object.location.xyz = (1, 2, 3)

Data type of objects location::

type(bpy.context.object.location)

Now that is a lot of data that you have access to::

dir(bpy.context.object.location)

``bpy.context.selected_objects``
Will give access to a list of all selected objects.

Type this and then press :kbd:`Ctrl-Spacebar`::

bpy.context.selected_objects

To print out the name of first object in the list::

bpy.context.selected_objects[0]

The complex one... But this prints a list of objects not including the active object::

[obj for obj in bpy.context.selected_objects if obj != bpy.context.object]

bpy.data
--------

``bpy.data`` has functions and attributes that give you access to all the data in the
blend-file.

You can access following data in the current blend-file:
objects, meshes, materials, textures, scenes, screens, sounds, scripts, etc.

That is a lot of data.

Try it out!
^^^^^^^^^^^

.. figure:: /images/editors_python-console_5-bpy-data.png

Exercise
^^^^^^^^

After :kbd:`Enter` twice it prints the names of all objects
belonging to the Blender scene with name "Scene"::

for obj in bpy.data.scenes['Scene'].objects: print(obj.name)

Unlink the active object from the Blender scene named 'Scene'::

bpy.data.scenes['Scene'].objects.unlink(bpy.context.active_object)

.. code-block:: python

bpy.data.materials['Material'].shadows

bpy.data.materials['Material'].shadows = False

bpy.ops
-------

The tool system is built around the concept of operators.
Operators are typically executed from buttons or menus but can be called directly from Python too.

See the `bpy.ops &lt;https://www.blender.org/api/blender_python_api_current/bpy.ops.html&gt;`__ API documentation
for a list of all operators.

Lets create a set of five Cubes in the 3D View. First,
delete the existing Cube object by selecting it and pressing :kbd:`X`

Try it out!
^^^^^^^^^^^

The following commands are used to specify that the objects are created in layer 1.
So first we define an array variable for later reference::

mylayers = [False] * 20
mylayers[0] = True

We create a reference to the operator that is used for creating a cube mesh primitive::

add_cube = bpy.ops.mesh.primitive_cube_add

Now in a *for loop*, we create the five objects like this (in the screenshot above,
another method is used) :
Press :kbd:`Enter` twice after entering the command at the shell prompt::

for index in range(5):
add_cube(location=(index * 3, 0, 0), layers=mylayers)

.. figure:: /images/editors_python-console_6-bpy-ops.png

Usage
=====

Aliases
-------

Some variables and modules are available for convenience:

- ``C``: Quick access to ``bpy.context``.
- ``D``: Quick access to ``bpy.data``.
- ``bpy``: Top level Blender Python API module.

Key Bindings
------------

- :kbd:`Up` / :kbd:`Down` -- Cycle command history.
- :kbd:`Left` / :kbd:`Right` -- Cursor motion.
- :kbd:`Ctrl-Left` / :kbd:`Ctrl-Right` -- Cursor motion, by word.
- :kbd:`Backspace` / :kbd:`Delete` -- Erase characters.
- :kbd:`Tab` -- Indent.
- :kbd:`Shift-Tab` -- Unindent.
- :kbd:`Ctrl-Backspace` / :kbd:`Ctrl-Delete` -- Erase words.
- :kbd:`Ctrl-Spacebar` -- Auto complete.
- :kbd:`Enter` -- Execute command.
- :kbd:`Shift-Return` -- Add to command history without executing.
- :kbd:`Ctrl-C` -- Copy the selection.
- :kbd:`Ctrl-V` -- Paste into the command line.

***********
Text Editor
***********

Blender has a *Text Editor* among its editor types,
accessible via the *Editor type* menu, or the shortcut :kbd:`Shift-F11`.

Header
======

The newly opened Text editor is gray and empty, with a very simple header
Fig. :ref:`fig-text-header-plain`

.. _fig-text-header-plain:

.. figure:: /images/editors_text-editor_header.png

Text header.

.. _fig-text-header-full:

.. figure:: /images/editors_text-editor_header-loaded.png

Text header with a text loaded.

Editor type
The standard editor selection button.
Menus
Editors `Menus`_.
Text
Data-block menu.
Once a text is selected or newly created, the header changes.
Fig. :ref:`fig-text-header-full`
Show
The following three buttons toggle display options.

Line numbers, word-wrap text, syntax highlighting

.. _editors-text-run-script:

Run Script/ Script Node Update
Executes the text as a Python script :kbd:`Alt-P`. See `Script and Templates`_.
Register
Todo.
Label
This Label shows, if the text is saved internal or external and
if there are unsaved changes to an external file.

Menus
------

View
Bottom of File
Moves the view and cursor to the end of the text.
Top of File
Moves the view and cursor to the start of the text.
Text
Create Text Block
Creates a new internal text.
Open Text Block
Loads a text, a :doc:`File Browser &lt;/editors/file_browser/index&gt;` appears :kbd:`Alt-O`.
Reload
Reopens (reloads) the current buffer (all non-saved modifications are lost) :kbd:`Alt-R`.
Save
Saves an already open file :kbd:`Alt-S`.
Save As
Saves unsaved text as a text file,
a :doc:`File Browser &lt;/editors/file_browser/index&gt;` appears :kbd:`Shift-Ctrl-Alt-S`.
Make Internal
Stores the text inside the blend-file.
Run Script
Executes the text as a Python script :kbd:`Alt-P`.
See `Script and Templates`_.
Edit
Cut :kbd:`Ctrl-X`
Cuts out the marked text into the text clipboard.
Copy :kbd:`Ctrl-C`
Copies the marked text into the text clipboard.
Paste :kbd:`Ctrl-V`
Pastes the text from the clipboard at the cursor location in the Text editor.
Duplicate Line :kbd:`Ctrl-D`
Duplicates the current line.
Move line(s) up
Swaps the current line with the above.
Move line(s) down
Swaps the current line with the below.
Select
Select Line, Select All.
Jump
Shows the Jump pop-up, which lets you select a line number where to jump to.
Find...
Shows the Find panel in the Properties Region.
Text Auto Complete :kbd:`Ctrl-Spacebar`
Shows a selectable list of Python commands and matching against words already used in the text.
Text To 3D Object
One Object, One Object per line.
Format
Indent
Indents the selection :kbd:`Tab`.
Unindent
Un-indents the selection :kbd:`Shift-Tab`.
Comment
Turns the selected lines into a Python comment.
Uncomment
Uncomments the selected lines.
Convert Whitespace
Converts sigular space characters, to tab characters.
Template
See `Script and Templates`_.

Python, OpenShading Language

Script and Templates
--------------------

The most notable keystroke is :kbd:`Alt-P` which makes the content of the buffer being parsed by the internal Python
interpreter built into Blender.
Before going on it is worth noticing that Blender comes with a fully functional Python interpreter built in,
and with a lots of Blender-specific modules,
as described in the :doc:`/advanced/scripting/index` section.

The *Text Editor* has now also some dedicated Python scripts,
which add some useful writing tools, like a class/function/variable browser, completion...
You can access them through the Template menu in the header.

Main View
=========

Typing on the keyboard produces text in the text buffer.
As usual, pressing, dragging and releasing :kbd:`LMB` selects text.

.. tip:: Usages for the Text editor

The Text editor is handy also when you want to share your blend-files with others.
The Text editor can be used to write in a ``README`` text explaining the contents of your blend-file.
Be sure to keep it visible when saving!

.. |first| unicode:: U+023EE
.. |last|  unicode:: U+023ED
.. |rewind| unicode:: U+025C0
.. |play|   unicode:: U+025B6
.. |previous| unicode:: U+023EA
.. |next|     unicode:: U+023E9
.. |pause| unicode:: U+023F8

***************
Timeline Editor
***************

The *Timeline* editor, identified by a clock icon,
is shown by default at the bottom of the screen.

.. figure:: /images/editors_timeline.png

The Timeline.

The *Timeline* is not much of an editor, but more of an information and control.

Here you can have an overview of the animation part of your scene.
What is the current time frame, either in frames or in seconds, where are the keyframes of the active object,
the start and end frames of your animation, markers, etc...

The *Timeline* has *Player Controls*, to play, pause the animation,
and to skip though parts of the scene.

It also has some tools for *Keyframes*, *Keying Sets*, and *Markers*.

Main View
=========

The main *Timeline* region displays the animation frames over time.

.. figure:: /images/editors_timeline_main.png

Timeline Main Area.

Adjusting the View
------------------

The *Timeline* can be panned by holding :kbd:`MMB`,
then dragging the area left or right.

You can zoom the *Timeline* by using :kbd:`Ctrl-MMB`, the mouse :kbd:`Wheel`,
or pressing :kbd:`NumpadMinus` and :kbd:`NumpadPlus`.

Time Cursor
-----------

The *Time Cursor* is the green line, it is used to set and display the current time frame.

.. figure:: /images/editors_timeline_cursor.png
:align: center

Time Cursor.

The *Time Cursor* can be set or moved to a new position by pressing or holding
:kbd:`LMB` in the Timeline editor.

The current frame or second can be displayed on the *Time Cursor*,
check the View menu for settings.

The *Time Cursor* can be moved in steps by pressing :kbd:`Left` or :kbd:`Right`,
or in steps of 10 frames by pressing :kbd:`Shift-Up` or :kbd:`Shift-Down`.

Playback/Rendering Range
------------------------

By default, the *Playback/Rendering Range* (Frame Start 1 to Frame End 200)
is a lighter shade of gray. The start and end frame can be set to the *Time Cursor*
by pressing :kbd:`S` or :kbd:`E`.
The *Playback Range* can also be set by pressing :kbd:`P` then drawing a box.

Keyframes
---------

For the active and selected objects, keyframes are displayed as a yellow line.
For *Armatures*, the object keyframes and the pose bones keyframes are drawn.

*Only Selected Channels* can be enabled. :menuselection:`Timeline --&gt; View --&gt; Only Selected Channels`.
For *Armatures*, this will draw the object keyframes,
and the keyframes for the active and selected pose bones.

Markers
-------

Markers are the small triangles, with their name near them.
Markers are usually used to identify key parts of the animation.

.. figure:: /images/animation_markers_standard.png

Markers.

See the :doc:`Markers page &lt;/animation/markers&gt;` for more information.

Header
======

Menus
-----

.. _timeline-view-menu:

View Menu
^^^^^^^^^

The *View Menu* controls what you see, and what it looks like.

Show Seconds :kbd:`Ctrl-T`
Whether to show the time in the X-axis and the *Time Cursor* as
frames (based on the FPS) or as seconds.
Lock Time to Other Windows
ToDo.
Show Frame Number Indicator
This will draw the current frame or seconds on the *Time Cursor*.
Only Keyframes from Selected Channels
For *Armatures*, this will draw the object keyframes,
and the keyframes for the active and selected pose bones.
Cache
Show Cache
Show all enabled types.

Softbody, Particles, Cloth, Smoke, Dynamic Paint, Rigid Body.

.. figure:: /images/editors_timeline_cache.png

Timeline Cache.

View All :kbd:`Home`
Maximize the area based on the Animation Range.
View Frame :kbd:`Numpad0`
Centers the Timeline to the Time cursor.
Bind Camera to Markers :kbd:`Ctrl-B`
This is used switch cameras during animation.
It binds the active camera to the selected markers.
First select a camera. Then select the marker(s). Then use the function.

Marker Menu
^^^^^^^^^^^

See the :doc:`Markers page &lt;/animation/markers&gt;` for more information.

Frame Menu
^^^^^^^^^^

Auto-Keyframing Mode
This controls how the Auto Keyframe mode works.
Only one mode can be used at a time.

Add &amp; Replace
Add or Replace existing keyframes.
Replace
Only Replace existing keyframes.

.. _timeline-playback:

Playback Menu
^^^^^^^^^^^^^

Top-Left 3D Editor
While playing, updates the Timeline, if Animation Editors and All 3D View Editors disabled.
All 3D View Editors
While playing, updates the 3D View and the Timeline.
Animation Editors
While playing, updates the Timeline, Dope Sheet, Graph Editor, Video Sequence Editor.
Property Editors
When the animation is playing, this will update the property values in the UI.
Image Editors
The UV/Image editor in Mask mode.
Sequencer Editors
While playing, updates the Video Sequence Editor.
Node Editors
While playing, updates the Node properties for the Node Editor.
Clip Editors
While playing, updates the Movie Clip Editor.
Follow
Animation editors can be setup to always follow the time indicator as animation is being played back.
Following will be done when animating and changing frame.
Frame Dropping
Play back dropping frames if frame display is too slow.
AV-sync
Play back and sync with audio clock, dropping frames if frame display is too slow.
See `Synchronize Playback`_ for more info.
Audio Muted
Mute the sound from Sequence Editors.
Audio Scrubbing
If your animation has sound, this option plays bits of the sound wave
while you move the time cursor with :kbd:`LMB` or keyboard arrows (like a moving playhead) .

.. _animation-editors-timeline-headercontrols:

Header Controls
---------------

The Timeline header controls.

.. figure:: /images/editors_timeline_header.png

Timeline header controls.

\1. Range Control, 2. Frame Control, 3. Player Control,
\4. Synchronize Playback, 5. Keyframe Control.

Range Control
^^^^^^^^^^^^^

Use Preview Range (clock icon)
This is an alternative range used to preview animations.
This works for the UI playback, this will not work for rendering an animation.
See :ref:`graph-preview-range`.
Lock Time Cursor to Playback Range (padlock icon)
This limits the *Time Cursor* to the *Playback Range*.

Frame Control
^^^^^^^^^^^^^

Start Frame
The start frame of the animation/playback range.
End Frame
The end frame of the animation/playback range.
Current Frame :kbd:`Alt-Wheel`
The current frame of the animation/playback range.
Also the position of the *Time Cursor*.

Player Control
^^^^^^^^^^^^^^

These buttons are used to set, play, rewind, the *Time Cursor*.

.. figure:: /images/editors_timeline_player_controls.png
:align: right

Player Controls.

Jump to start (|first|) :kbd:`Shift-Ctrl-Down`, :kbd:`Shift-Left`
This sets the cursor to the start of frame range.
Jump to previous keyframe (|previous|) :kbd:`Down`
This sets the cursor to the previous keyframe.
Rewind (|rewind|) :kbd:`Shift-Alt-A`
This plays the animation sequence in reverse.
When playing the play buttons switch to a pause button.
Play (|play|) :kbd:`Alt-A`
This plays the animation sequence.
When playing the play buttons switch to a pause button.
Jump to next keyframe (|next|) :kbd:`Up`
This sets the cursor to the next keyframe.
Jump to end (|last|) :kbd:`Shift-Ctrl-Up`, :kbd:`Shift-Right`
This sets the cursor to the end of frame range.
Pause (|pause|) :kbd:`Alt-A`
This stops the animation.

Synchronize Playback
^^^^^^^^^^^^^^^^^^^^

.. figure:: /images/animation_red_fps.png
:figwidth: 109px
:align: right

3D View Red FPS.

60:54.75

When you play an animation, the FPS is displayed at the top left of the 3D View.
If the scene is detailed and playback is slower than the set
*Frame Rate* (see :ref:`render-tab-dimensions`,
these options are used to synchronize the playback.

No Sync
Do not sync, play every frame.
Frame Dropping
Drop frames if playback is too slow.
This enables *Frame Dropping* from the *Playback Menu*.
AV-sync
(Audio Video Synchronization). Sync to audio clock, dropping frames if playback is slow.
This enables *AV-sync* and *Frame Dropping* from the *Playback Menu*.

.. _animation-editors-timeline-autokeyframe:

Keyframe Control
^^^^^^^^^^^^^^^^

Auto Keyframe
.. figure:: /images/editors_info_keyframes-auto.png
:align: right

Timeline Auto Keyframe.

The "Record" red-dot button enables something called *Auto Keyframe* :
It will add and/or replace existing keyframes for the active object when you transform it in the 3D View.

For example, when enabled, first set the *Time Cursor* to the desired frame,
then move an object in the 3D View, or set a new value for a property in the UI.

When you set a new value for the properties,
Blender will add keyframes on the current frame for the transform properties.
Other use cases are :ref:`Fly/Walk Mode &lt;3dview-walk-fly&gt;` to record the walk/flight path
and :ref:`Lock Camera to View &lt;3dview-lock-camera-to-view&gt;` to record the navigation in camera view.

Auto Keying Set (red record icon)
When enabled *Auto Keyframe* will insert new keyframes for the properties in the active *Keying Set*.
Layered (two keys icon)
Adds a new NLA Track and strip for every loop/pass made over the animation to allow non-distructive tweaking.

.. note::

Note that *Auto Keyframe* only works for transform properties (objects and bones),
in the 3D Views (i.e. you can't use it e.g. to animate the colors of a material in the Properties editor...).

Keyframe Type
:ref:`keyframe-type` on insertion.

Active Keying Set
.. figure:: /images/editors_timeline_keying-sets.png
:align: right

Timeline Keying Sets.

*Keying Sets* are a set of keyframe channels in one.

They are made so the user can record multiple properties at the same time.

With a keying set selected, when you insert a keyframe,
Blender will add keyframes for the properties in the active *Keying Set*.

There are some built in keying sets, *LocRotScale*, and also custom keying sets.

Custom keying sets can be defined in the panels
:menuselection:`Properties --&gt; Scene --&gt; Keying Sets + Active Keying Set`.

Insert Keyframes (key icon)
Insert keyframes on the current frame for the properties in the active *Keying Set*.
Delete Keyframes (striked through key icon)
Delete keyframes on the current frame for the properties in the active *Keying Set*.

*************
Display Panel
*************

You can set the editors display options in the this panel.

.. figure:: /images/editors_uv-image_display.png
:align: right

Display Panel.

With both an image and UVs selected.

Image
=====

Aspect Ratio
Display Aspect for this image. Does not affect rendering.
Coordinates
Repeat
Draw the image repeated outside of the main view.

UV
==

Coordinates
Normalized
Display UV coordinates from 0.0 to 1.0 rather than in pixels.
Cursor Location
2D cursor location for this view.
UVs
Edge Draw Type
Sets how UV edges are displayed.

Outline, Dash, Black, White
Draw Faces
Draw faces over the image.
Smooth
Makes edges appeared anti-aliased.
Modified
Show results of modifiers in the UV display.
Stretch
Shows how much of a difference there is between UV coordinates and 3D coordinates.
Blue means low distortion, while Red means high distortion.
Choose to display the distortion of *Angles* or the *Area*.
.. (Todo) move to data_system: shared with movie editor?

**************
Image Settings
**************

.. figure:: /images/editors_uv-image_image-settings_movie-image-panel.png
:align: right

Image panel.

Image
Data-block menu.

New ``+``
The *New Image* button opens a pop-up to configure a `Generated`_ image.

Source
======

See about supported :doc:`/data_system/files/media/image_formats`.

Single Image
------------

Still image or a single frame.

Image Sequence
--------------

Each frame is stored in a separate file.
How to load a :ref:`file-browser-open-sequence`.

Frame
A label showing the current frame.
Further options
See `Movie`_ below.

Movie
-----

Frames packed into a container.

Deinterlace
TODO
Fields
Sets the number of fields per rendered frame (2 fields is 1 frame).
Used with Fields and interlaced video,
it says whether each image has both odd and even, or just one.
Frame
Frames
Sets the range of frames to use.
Start
Global starting frame of the sequence, when the playback should start.
This is a global setting which means it affects all clip users such as the Movie clip editor itself,
motion tracking constraints and compositor nodes.
Offset
Offsets the first frame of the clip. It adds an extra offset to the frame number when
converting a scene frame to the frame number in the file name.
This option does not affect tracking data or any other associated data.
Match Movie Length
This button set image's user's length to the one of selected movie.
Auto Refresh
Automatically refresh images on frame changes.
Cyclic
Start over and repeats after the last frame to create a continuous loop.

.. _image-generated:

Generated
---------

Image generated in Blender or preloaded.

.. list-table::

* - .. figure:: /images/editors_uv-image_image-settings_generated-image-panel.png

Image panel for Generated source.

- .. figure:: /images/editors_uv-image_image-settings_generated-new-image.png

The New Image pop-up menu.

Width, Height
The size of image in pixels.
Color
Sets the fill color if creating a blank image.
32 bit Float/ Float Buffer
Creates a 32 bit image. This is a larger file size,
but holds much more color information than the standard 8 bit image.
For close ups and large gradients, it may be better to use a 32 bit image.
Type
Blank
Creates a Blank image of a single specified color.
UV Grid
Creates a checkerboard pattern with a colored cross (+) in each square.
Color Grid
Creates a more complex colored grid with letters and numbers denoting locations in the grid.
It could be used for testing how the UVs have been mapped and to reduce stretching or distortion.

Common Options
==============

File
Use for replacing or packing files.

Pack
Embed the resource into the current blend-file.
Path
Path to the linked file.
Open
Opens the :doc:`/editors/file_browser/index` to select a file from a drive.
Reload
Reloads the file. Useful when an file has been rework in an external application.
Color Space
:term:`Color Space`.

XYZ
XYZ space.
VD16
The simple video conversion from a gamma 2.2 sRGB space.
sRGB
Standard RGB display space.
Raw
Raw space.
Non-Color
Color space used for images which contains non-color data (e.g. normal maps).
Linear ACES
ACES linear space.
Linear
Linear 709 (full range). Blender native linear space.
View as Render
Apply render part of display transformation when displaying this image on the screen.
Use Multi-View
See :doc:`Multi-View &lt;/render/workflows/multiview/index&gt;`.
Use Alpha
Determines whether the alpha channel of the image is used.

Alpha Mode
:term:`Alpha Channel`.

Straight, Premultiplied

Fields
Work with :doc:`/render/blender_render/post_processing/fields` images.
Video frames consist of two different images (fields) that are merged.
This option ensures that when fields are rendered,
the correct field of the image is used in the correct field of the rendering.
*MIP Mapping* cannot be combined with *Fields*. Order of video fields:

Upper First, Lower First.

########
Image
########

.. toctree::
:maxdepth: 2

introduction.rst
image_settings.rst
scopes.rst

************
Introduction
************

.. The UV/Image Editor offers few options to edit images &gt; Compositor texture mode.

Header
======

Image Menu
----------

New Image
Creates a new :ref:`image-generated` Image.
Open Image
Load image from a file.
Read Render Layers
ToDo.
Save All Images
ToDo.
Replace Image
Replaces the current image, while preserving the link to UV maps,
with an selected file.
Reload Image
Reloading the image from an external file.
Save Image
Save the image, if the image is already a file :kbd:`Alt-S`.
Save As Image
Save the (rendered) image in a separate file :kbd:`F3` or
you want to save it under a different name.
Save a Copy
Using *Save as Copy* will save the file to a specified name,
but will keep the old one open in the UV/Image editor.
Edit Externally
Using the *Edit Externally* tool Blender will open an external image editor,
as specified in the *User Preferences* and load in the image to be edited.
Invert
Invert Image Colors
Invert the colors of an image.
Invert Channel
Red, Green, Blue, Alpha
Pack
Pack Image
..
Pack As PNG
Packs the image inside the blend-file.
See :ref:`pack-unpack-data`.

.. important::

Rendered images had to be saved externally or packed.

Controls
--------

Image
:ref:`Data-block menu &lt;ui-data-block&gt;` used for selecting images.
When an image has been loaded or created in the UV/Image editor,
the Image panel appears in the *Properties region*.
See :doc:`/editors/uv_image/image/image_settings`.

- Render Result
- Viewer Node
Pin Image
Displays current image regardless of selected object.

Multi-Layer
^^^^^^^^^^^

When a rendered image is displayed in the UV/Image Editor,
several new menu items become available.

Slot
You can save successive renders into the render buffer by selecting a new slot before rendering.
If an image has been rendered to a slot, it can be viewed by selecting that slot.
Empty slots appear as blank grids in the UV/Image editor.
Use the :kbd:`J` and :kbd:`Alt-J` to cycle forwards and backwards through saved renders.
Render Layer
If you are using :doc:`Render Layers &lt;/render/post_process/layers&gt;`,
use this menu to select which layer is displayed.
Render Pass
If you are using :doc:`Render Passes &lt;/render/blender_render/settings/passes&gt;`,
use this menu to select which pass is displayed.

Channels
^^^^^^^^

Draw Channels
The radio buttons set which channels of the image are displayed.

RGBA
Replaces transparent pixels with background checkerboard, denoting the alpha channel.
RGB
Draw the colored image, without alpha channel.
Alpha
Displays the Alpha channel a gray-scale image. White areas are opaque, black areas have an alpha of 0.
Z-Buffer
Display the depth from the camera, from Clip Start to Clip End,
as specified in the :doc:`Camera settings &lt;/render/blender_render/camera/introduction&gt;`.
Red, Green, Blue
Single Color Channel visualized as a gray-scale image.

Main View
=========

When :kbd:`LMB` dragging mouse the color under the cursor is shown in the footer as well the cursor position and
the color values in the RGBA, HSV and Luminance :term:`color space`.
.. Add images (TODO)

******
Scopes
******

Histogram
=========

.. copied from the sequencer.

This mode displays a graph showing the distribution of color information in the pixels of the
currently displayed image. The X-axis represents values of pixel, from 0 to 1 (or 0 to 255),
while the Y-axis represents the number of pixels in that tonal range. A predominantly dark
image would have most of its information toward the left side of the graph.

Use this mode to balance out the tonal range in an image.
A well balanced image should a nice smooth distribution of color values.

Luma
Shows the luminosity of an image.
RGB
Shows the :abbr:`RGB (Red, Green, Blue)` channels stacked on top of each other.
R/G/B/A
Depending on the channel you choose the scope will show the appropriate channel.
Show line
Displays lines rather then filled shapes.

Waveform
========

.. Add description of a Waveform maybe this should go in the glossary? (TODO).

Waveform Opacity
Opacity of the points.

Waveform Mode
Luma
ToDo.
Parade
The RGB channels are shown side-by-side.
Red Green Blue
Shows the RGB channels overlaid as a "Full color" waveform.
It is useful for color grading.

Vectorscope
===========

.. Add description of a Vectorscope maybe this should go in the glossary? (TODO).

Vectorscope Opacity
Opacity of the points.

Sample Line
===========

The *Sample Line* scope is the same as the `Histogram`_
but allows you to get the sample data from a line.

Sample Line
Used to draw a line to use to read the sample data from.

Scope Samples
=============

Full Sample
Sample every pixel.

Accuracy
Proportion of original image source pixel lines to sample.
.. _editors-uv-image-index:

###################
UV/Image Editor
###################

.. toctree::
:maxdepth: 2

introduction.rst
navigating.rst
image/index.rst
uv_editing/index.rst
display_panel.rst
painting.rst

************
Introduction
************

TODO see https://developer.blender.org/T46878

The UV/Image Editor is where you can edit 2D assets like images/textures and UVs.

.. Using the UV editor is explained more in depth in the next sections.
This is an overview of the tools found there.

.. figure:: /images/editors_uv-image-main.jpg

UV/Image Editor with a UV map and a test grid texture.

Header
======

View
Tools for controlling how the content is displayed in the editor.
See :doc:`/editors/uv_image/navigating`.
Select
Tools for :doc:`Selecting UVs &lt;/editors/uv_image/uv_editing/layout_editing&gt;`
Image
This contains options for :doc:`/editors/uv_image/image/index`.
UVs
Contains tools for :doc:`Unwrapping Meshes &lt;/editors/uv_image/uv_editing/overview&gt;`
and :doc:`Editing UVs &lt;/editors/uv_image/uv_editing/layout_editing&gt;`.

Modes
View
Images and UV maps.
Paint
:doc:`/sculpt_paint/painting/texture_paint/index`.
Mask
:doc:`/editors/movie_clip_editor/masking/index`.

Properties Region
=================

Grease Pencil
See the :doc:`Grease Pencil &lt;/interface/grease_pencil/index&gt;` docs.
Display
Controls display options.

**********
Navigating
**********

2D View
=======

Panning can be done by clicking the :kbd:`MMB` and dragging.

Zooming can be done by scrolling :kbd:`Wheel` up or down.
Also, as in the 3D View, you can use :kbd:`NumpadPlus` or :kbd:`NumpadMinus` to zoom.

View Menu
=========

Update Automatically
Update the view in multiple areas.
UV Local View
..
Draw Other Objects
Draws the UVs of selected objects (Object Mode) in the background.
Show Metadata
Draws the Metadata if they were set in the render tabs :doc:`/render/output/metadata` panel.
Draw Texture Paint UVs
Hides the UVs in Paint Mode.
View Zoom In/Out
Adjusts the Zoom level :kbd:`Wheel`.
Zoom Ratio
- Zoom 1:8 :kbd:`Numpad8`
- Zoom 1:4 :kbd:`Numpad4`
- Zoom 1:2 :kbd:`Numpad2`
- Zoom 1:1 :kbd:`Numpad1`
- Zoom 2:1 :kbd:`Shift-Numpad2`
- Zoom 4:1 :kbd:`Shift-Numpad4`
- Zoom 8:1 :kbd:`Shift-Numpad8`
View Center
Center the view to the entire UVs :kbd:`NumpadPeriod`.
View All
Center the view to the entire image :kbd:`Home`.
View Fit
Fit the view to the image dimensions :kbd:`Shift-Home`.

********
Painting
********

TODO see https://developer.blender.org/T46878
..    TODO/Review: {{review|}}.

*****************
Applying Textures
*****************

Sooner or later, you may want to use an image texture on your model.
If you are using an external application, you need to know where on the mesh you are painting.
You may also need to test your UV mapping with a test image.
This section covers how to export an outline of your UV map,
and how to load images into the UV/Image editor.

Applying Textures to UVs
========================

The UV/Image Editor allows you to map textures directly to the mesh faces.
The 3D View editor shows you the object being textured.
If you set this editor into Textured viewport shading,
you will immediately see any changes made in the UV/Image and this editor,
and vice versa.

You can edit and load images,
and even play a game in the Blender Game Engine with UV textures for characters and object,
without a material, and still see them in the 3D View.
This is because no real rendering is taking place; it is all just viewport shading.
If you were to apply an image to UVs then render, the texture would not show up by default.

To render an image however, you must:

- Create a Material for the object, and
- tell Blender to use the UV Textures on faces when rendering.

To create a Material, you have to click *Add New* Material in the Shading context.

There are two ways to tell Blender to use the UV Texture when rendering:
the Proper way and the Quick Way:

Use UV Coordinates
------------------

.. figure:: /images/editors_uv-image_uv-editing_applying-image_coords.png

A texture setup to map using its UV coordinates.

In the Texture channel panel,
Add a New Texture and define the texture as an image and load the image you want to use.
In the Mapping section, choose UV from the Coordinates menu, and select the UV map to use.

Make sure it is mapped to Color in the Influence section as well
(it will be mapped to Color by default, and the UV Texture is named "UVTex" by default).
If the image has an alpha channel and you want to use it,
click "Use Alpha" in the Map Image panel.

Full details of using Image textures are on the
:doc:`Image Textures &lt;/render/blender_render/textures/types/image/index&gt;` page.

.. note:: Material is Required for Rendering

You can perform UV Texturing on a mesh within Blender without assigning a material,
and you will even see it in your 3D View in textured viewport mode. However, when you render,
you will just get a default gray if the object does not have a Material assigned.
You will get a black if you do not load an image. If you do not create a texture that uses the image,
or enable *Face Texture*, your object will render according to the procedural material settings.

.. _face-textures:

Face Textures
-------------

.. figure:: /images/editors_uv-image_uv-editing_applying-image_facetex.png

The Material panel with activated Face Textures button.

An alternate way is to set up a Face Textures Material as shown. To do so,
with the Properties editor displayed, press :kbd:`F5` to display the Shader Buttons.
In the Properties editor, Material settings, click *Add New* material.

On the Options panel, enable *Face Textures*. This way is quick,
but bypasses the normal rendering system for fast results,
but results which do not respect transparency and proper shading.

Using the Test Grid
-------------------

If your image is a base uniform pattern and
you want the application of that image to your model to look like cloth,
you do **not** want any stretching (unless you want the cloth to look like spandex).

.. list-table::

* - .. figure:: /images/editors_uv-image_uv-editing_applying-image_test-grid-uvs.png
:width: 320px

The test grid applied to the UVs.

- .. figure:: /images/editors_uv-image_uv-editing_applying-image_test-grid-geometry.png
:width: 320px

A preview of the texture on the geometry.

When you render, the mesh will have the test grid as its colors,
and the UV Texture will be the size image you specified.

Modifying your Image Texture
============================

.. seealso::

- :doc:`Render Bake &lt;/render/blender_render/bake&gt;`
- :doc:`Texture Paint &lt;/sculpt_paint/painting/texture_paint/introduction&gt;`.

The advantage to saving as a separate file is that you can easily switch textures just by
copying other image files over it, and you can use external editing programs to work on it.
The advantage of packing is that your whole project is kept in the blend-file,
and that you only have to manage one file.

##############
UV Editing
##############

.. toctree::
:maxdepth: 2

introduction.rst
overview.rst
unwrapping/index.rst
layout_management.rst
selecting.rst
layout_editing.rst
uv_sculpt.rst
layout_workflow.rst
applying_image.rst

************
Introduction
************

Header
======

.. figure:: /images/editors_uv-image_texturing-header.png

UV/Image Editor Header.

The header contains several menus and options for working with UVs.

Select
Tools for :doc:`Selecting UVs &lt;/editors/uv_image/uv_editing/layout_editing&gt;`.
UVs
Contains tools for :doc:`Unwrapping Meshes &lt;/editors/uv_image/uv_editing/overview&gt;`
and :doc:`Editing UVs &lt;/editors/uv_image/uv_editing/layout_editing&gt;`.

Pivot Point Selector
Similar to working with Pivot Points in the 3D View.
Sync Selection
Keeps UV and Mesh component selections in sync.
Selection Modes
- Vertex
- Edge
- Face
- Island
Sticky Selection Mode
When Sync Selection is disabled, these options control how UVs are selected.
Proportional Editing
See :doc:`Proportional Editing &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`.
UV Snapping
Similar to Snapping in the 3D View.
Active UV Texture Map Selector
Select which UV texture to use.
Auto Update Other Affected Windows
Update other affected windows automatically to reflect changes during interactive operations e.g. transforms.

Properties Region
=================

UV Vertex Panel
---------------

.. figure:: /images/editors_uv-image_uv-vertex.png
:align: right

UV Vertex Panel.

UV Vertex
Transform Properties :doc:`Selecting UVs &lt;/editors/uv_image/uv_editing/layout_editing&gt;`.

..    TODO/Review: {{review|im=old screenshot: Need to update}}.

***********
Editing UVs
***********

After unwrap, you will likely need to arrange the UV maps into something that can be logically
textured or painted. Your goals for editing are:

- Stitch some pieces (UV maps) back together.
- Minimize wasted space in the image.
- Enlarge the faces where you want more detail.
- Re-size/enlarge the faces that are stretched.
- Shrink the faces that are too grainy and have too much detail.

With a minimum of dead space,
the most pixels can be dedicated to giving the maximum detail and fineness to the UV Texture.
A UV face can be as small as a pixel (the little dots that make up an image)
or as large as an entire image. You probably want to make some major adjustments first,
and then tweak the layout.

Menu
====

Snap to pixel
Will force the UVs to snap to the nearest pixels of an image if loaded.
Constraining to Image Bounds
Turning on *Constrain to Image Bounds* will prevent UVs from being moved outside the
0 to 1 UV range.
Live Unwrap
..
Unwrap
..

Pin and Unpin
-------------

You can pin UVs so they do not move between multiple unwrap operations.

.. &gt;

When Unwrapping a model it is sometimes useful to "Lock" certain UVs,
so that parts of a UV layout stay the same shape, and/or in the same place.

Pinning is done selecting a UV, then by selecting *Pin* from the *UVs* menu,
or the shortcut :kbd:`P`. You can *Unpin a UV* with the shorctut :kbd:`Alt-P`

Pinning is most effective when using the Unwrap method of UV mapping, for organic objects.
An example is when you are modeling a symmetrical object using the
:doc:`Mirror Modifier &lt;/modeling/modifiers/generate/mirror&gt;`.
Some of the UVs on the mirror axis may be shared across the mirrored counterparts.
You could pin the UVs that correspond to the midline, then align them on the X axis,
and they will stay in that location.

Pinning also work great with the Live Unwrap tool. If you pin two or more UVs,
with Live Unwrap on, dragging pinned UVs will interactively unwrap the model.
This helps with fitting a UV island to a certain shape or region.

Pack Islands
------------

.. admonition:: Reference
:class: refbox

| Mode:     View mode
| Menu:     :menuselection:`UVs --&gt; Pack Islands`
| Hotkey:   :kbd:`Ctrl-P`

The *Pack Islands* tool generates a optimized UV layout with non overlapping islands
that tries to efficiently fill the texture space.

First it will uniformly scale the selected island,
then individually transform each island so that they fill up the UV space as much as possible.

Average Island Scale
--------------------

.. admonition:: Reference
:class: refbox

| Mode:     View mode
| Menu:     :menuselection:`UVs --&gt; Average Island Scale`
| Hotkey:   :kbd:`Ctrl-A`

Using the *Average Island Scale* tool, shortcut :kbd:`Ctrl-A`,
will scale each UV island so that they are all approximately the same scale.

Minimize Stretch
-----------------

.. admonition:: Reference
:class: refbox

| Mode:     View mode
| Menu:     :menuselection:`UVs --&gt; Minimize Stretch`
| Hotkey:   :kbd:`Ctrl-V`

The *Minimize Stretch* tool, :kbd:`Ctrl-V`,
reduces UV stretch by minimizing angles. This essentially relaxes the UVs.

Stitch
------

.. admonition:: Reference
:class: refbox

| Mode:     View mode
| Menu:     :menuselection:`UVs --&gt; Stitch`
| Hotkey:   :kbd:`V`

*Stitch*, :kbd:`V`, will join selected UVs that share vertices.
You set the tool to limit stitching by distance in the Operator panel,
by activating *Use Limit* and adjusting the *Limit Distance*

Seams
-----

Mark Seam
..
Clear Seam
..
Seams From Island
..

Copy Mirrored UV coords
------------------------

..

Transform
---------

- Translate :kbd:`G`
- Rotate :kbd:`R`
- Scale :kbd:`S`
- Shear :kbd:`Shift-Ctrl-Alt-S`

Axis Locking
^^^^^^^^^^^^

Transformations can be locked to an axis by pressing :kbd:`X` or :kbd:`Y` after
one of the transform tools. Also,
holding the :kbd:`MMB` will constrain movement to the X or Y axis.

Mirror
------

UVs can be mirrored on the Y axis or the X axis:

- Mirror X
- Mirror Y

You can also use the hotkey :kbd:`Ctrl-M`, then enter :kbd:`X` or :kbd:`Y`,
or hold the :kbd:`MMB` and drag in the mirror direction.

Snap
----

Snapping in UV/image editor is similar to
:doc:`Snapping in 3D &lt;/editors/3dview/object/editing/transform/control/snap&gt;`.
For the snap to pixel options to work an image has to be loaded.

Selected to Pixels
Moves selection to nearest pixel. See also *Snap to pixel* above.
Selected to Cursor
Moves selection to 2D cursor location.
Selected to Cursor (Offset)
Moves selection center to 2D cursor location, while preserving the offset of the vertices from the center.
Selected to Adjacent Unselected
Moves selection to adjacent unselected element.

Cursor to Pixels
Snaps the cursor to the nearest pixels.
Cursor to Selected
Moves the Cursor to the center of the selection.

Weld/Align
----------

.. admonition:: Reference
:class: refbox

| Mode:     View mode
| Menu:     :menuselection:`UVs --&gt; Weld/Align`
| Hotkey:   :kbd:`W`

The *Weld or Align* tool, :kbd:`W`.

Weld
The *Weld* tool will move selected UVs to their average position.
Remove Doubles UV
..
Straighten
Auto, X, Y
Align
Will line up the selected UVs on the X axis, Y axis, or automatically chosen axis.

Auto, X, Y

Proportional Editing
--------------------

Proportional Editing is available in UV editing. The controls are the same as in the 3D View.
See :doc:`Proportional Editing in 3D &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`
for full reference.

Show/Hide Faces
---------------

- Reveal Hidden :kbd:`Alt-H`
- Hide Select :kbd:`H`
- Hide Unselect :kbd:`Shift-H`

.. _uv-image-export-layout:

Export UV Layout
----------------

.. &lt;

Using your favorite image painting program, you could use an exported UV layout to create a texture.
Then save your changes, and back in Blender,
use the :menuselection:`Image --&gt; Open` menu entry to load it as your UV image
for the mesh in Edit Mode for the desired (and active) UV map.

.. &gt;

As a way of communicating to an artist who is painting your UV Texture for you,
Blender has a tool called *Save UV Face Layout*
(located in the UV/Image Editor, :menuselection:`UVs --&gt; Save UV Face Layout`)
that saves an image as a ``Targa`` (``.tga``), ``EPS``, or an ``SVG`` format for the object you have selected.

The image is an outline of the UV face mapping.
Activating the tool brings up the File Browser with options for saving the layout:

.. figure:: /images/editors_uv-image_uv-editing_layout-editing_export-panel.png

Export Options.

All UVs
if disabled, then only the UV faces selected will be outlined
Modified
Export UVs from the modified mesh.
Format
Select the type of image file to save (``.png``, ``.eps``, ``.svg``)
Size
select the size of the image in pixels. The image be square.
Fill Opacity
Set the opacity of the fill.

The image will be lines defining the UV edges that are within the image area of the UV mapping
area. Edges outside the boundary, even if selected, will not be shown in the saved graphic.

The artist will use this as a transparent layer in their paint program as a guide when
painting your texture. The example below shows Blender in the background,
and the Gimp working on the texture, using the saved layout as a guide.
Note that ``targa`` format supports the Alpha channel,
so you can paint transparent areas of the mesh.

For using images as textures, see the page on
:doc:`Image Textures &lt;/render/blender_render/textures/types/image/index&gt;`.

.. list-table::

* - .. figure:: /images/editors_uv-image_uv-editing_layout-editing_uv-layout.png
:width: 320px

A UV Layout in the UV/Image Editor.

- .. figure:: /images/editors_uv-image_uv-editing_layout-editing_uv-layout-export.png
:width: 320px

A UV Layout in an paint program.

Header
======

Pivot Point
-----------

The UV/Image editor has a 2D cursor.
Its position can be changed by :kbd:`LMB` clicking in the UV/Image editor.
You can also manually adjust its position in the Properties region.
The range by default is from 0 to 256 starting from the lower left corner.
By enabling *Normalized* under *Coordinates*,
the range changes from 0 to 1.

The Pivot Point can be changed to:

- Bounding Box Center
- Median Point
- 2D Cursor Location

Proportional Editing
--------------------

Proportional Editing is available in UV editing. The controls are the same as in the 3D View.
See :doc:`Proportional Editing in 3D &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`
for full reference.

Snap
----

..

UV Data
-------

..

3D View
=======

Face Mirror and Rotate UVs
--------------------------

The orientation of the UV Texture is defined by each face.
If the image is, for example, upside down or laying on its side,
use the :menuselection:`Face --&gt; Rotate UVs` (in the 3D View in Face Select mode)
menu to rotate the UVs per face in 90-degree turns.

The :menuselection:`Face --&gt; Mirror UVs` tool mirrors the UVs per face,
which flips the image over, showing you the image reversed.

..    TODO/Review: {{review|copy=X|partial=X}}.

****************
Managing UV Maps
****************

After you finish editing a UV map, you may need to create additional maps on the same object,
or transfer a UV map to another mesh.

Transferring UV Maps
====================

You can copy a UV Map from one mesh to another Mesh provided both meshes have the same
geometry/vertex order. This is useful for example when you want to recreate a UV map from an
earlier version of your model with intact UVs.

Workflow
--------

- :kbd:`RMB` Select the target mesh (to which you want to copy the UV Map)
- :kbd:`Shift` select the source mesh (that contains the intact UV map)
- :menuselection:`Object menu --&gt; Make Links... --&gt; Transfer UV Layouts` (Shortcut: :kbd:`Ctrl-L` ...)

The target Mesh will now have a UV map that matches the original mesh.

Multiple UV Maps
================

You are not limited to one UV Map per mesh.
You can have multiple UV maps for parts of the mesh by creating new UV maps.
This can be done by clicking the *Add* button next to UV maps list
(in *Object Data* tab in the Properties Editor)
and unwrapping a different part of the mesh. UV maps always include the whole mesh.

.. (todo) continue image clipping

.. _uv-maps-panel:

UV Maps Panel
=============

.. figure:: /images/editors_3dview_object_properties_uvmaps.png

The UV Maps panel in the Mesh tab.

In the Mesh tab the UV maps panel contains a :ref:`ui-list-view` that lists the UV maps created for this mesh.
The selected map is displayed in the UV/Image Editor.

Active Render
Click the camera icon to enable that UV texture for rendering.
If no other map is explicitly specified.

Add ``+``
Clicking the *Add* button duplicates the selected UV map.

.. seealso::

Note that each texture can be mapped to a specific UV texture.
See the :doc:`Mapping &lt;/render/blender_render/textures/properties/mapping&gt;` panel of the texture tab.

**************
Layout Worflow
**************

Optimizing the UV Layout
========================

When you have unwrapped, possibly using seams,
your UV layout may be quite disorganized and chaotic.
You may need to proceed with the following tasks: Orientation of the UV mapping,
arranging the UV maps, stitching several maps together.

The next step is to work with the UV layouts that you have created through the unwrap process.
If you do add faces or subdivide existing faces when a model is already unwrapped,
Blender will add those new faces for you. In this fashion,
you can use the UV Texture image to guide additional geometry changes.

When arranging, keep in mind that the entire view is your workspace,
but only the UV coordinates within the grid are mapped to the image. So,
you can put pieces off to the side while you arrange them. Also,
each UV unwrap is its own linked set of coordinates.

You can lay them on top of one another, and they will onionskin
(the bottom one will show through the top one). To grab only one though,
:kbd:`RMB` select one of the UV coordinates,
and use :menuselection:`Select --&gt; Linked UVs`, :kbd:`Ctrl-L`
to select connected UVs, not border select because UVs from both will be selected.

Combining UV Maps
-----------------

.. figure:: /images/editors_uv-image_uv-editing_combining-uv-maps-1.png

Bad unwrap, note ear and neck.

Very often you will unwrap an object, such as the face example we have been using,
and get it "mostly right" but with parts of the mesh that did not unwrap properly,
or are horribly confusing. The picture to the right shows an initial unwrap of the face using
the Unwrap from sphere option. The issues are with the ear; it is just a mush of UVs,
and the neck, it is stretched and folded under. Too much work to clean up.

.. figure:: /images/editors_uv-image_uv-editing_combining-uv-maps-2.png

Unwrap face only, without ear or neck.

We can tell that the ear would unwrap nicely with just a straightforward projection from the
side view, and the neck with a tubular unwrap. So,
our general approach will be to unwrap different parts of the object (face, ears, and so on)
using different unwrap calculations,
selecting each calculation according to whatever works best for that piece. So let us begin:
We select only the "face" faces, unwrap them using the *Sphere* calculation, and scale and
rotate them somewhat to fit logically within the image area of the UV/Image Editor.

.. figure:: /images/editors_uv-image_uv-editing_combining-uv-maps-3.png

Unwrap ear only, using the *Project From View*.

Once we are satisfied with the face, it is time to turn our attention to the ear. First,
unselect the faces you were working with. Their
UVs will disappear from the UV/Image Editor, but they are still there, just not shown.
(To verify this,
you can select a few faces in 3D View and it will show up in the UV/Image Editor.)

To work on the ear, in the 3D View, we now select only the "ear" faces.
You can use Vertex Groups to select the ear faces. Selecting sub-meshes is easy too,
since they are not connected to the rest of the mesh.
Simply selecting Linked vertices will select that entire submesh. Basically,
since you are in Edit Mode, all of the selecting/deselecting features are available to you.

Now re-unwrap the ear using the *Project* calculation from side view,
and scale and rotate them somewhat (discussed in the next section),
and place them off to the side. You can do this repetitively, using different UV calculations;
each re-calculation just puts those UVs for the selected faces somewhere else. Choose the
calculation for each piece that gives you the best fit and most logical layout for subsequent
painting of that piece.

When all of the pieces of the mesh have been unwrapped using the various calculations,
you should end up with something that looks like to the Example to the right.
All of the sections of the mesh have been mapped,
and all those maps are laid out in the same UV Texture map. Congratulations! From here,
it is a simple matter of "stitching" (discussed in the next section)
to construct the entire UV Map as a single map.

.. figure:: /images/editors_uv-image_uv-editing_combining-uv-maps-4.png

UV Maps arranged together and stitched.

When you have completed arranging and stitching, you will end up with a consolidated UV Map,
like that shown to the right, arranged such that a single image will cover, or paint,
all of the mesh that needs detailed painting.
All of the detailed instructions on how to do this are contained in the next section.
The point of this paragraph is to show you the ultimate goal.
Note that the mesh shown is Mirrored along the Z axis,
so the right side of the face is virtual; it is an exact copy of the right,
so only one set of UVs actually exist. (If more realism is desired,
the Mirror Modifier would be applied, resulting in a physical mirror and a complete head.
You could then make both side physically different by editing one side and not the other.
Unwrapping would produce a full set of UVs (for each side)
and painting could thus be different for each side of the face, which is more realistic.)

Iteration and Refinement
------------------------

At least for common people, we just do not "get it right the first time." It takes building on
an idea and iterating our creative process until we reach that magical milestone called
"Done." In software development, this is called the Spiral Methodology.

Applied to Computer Graphics, we cycle between modeling, texturing, animating,
and then back to making some modifications to mesh, re-UV mapping, tweaking the animation,
adding a bone or two, finding out we need a few more faces, so back to modeling, etc.
We continue going round and round like this until we either run out of time, money,
or patience, or, in some rare cases, are actually happy with our results.

Refining the Layout
===================

Refinement comes into play when we finally look at our character,
and realize that we need more detail in a particular spot. For example,
areas around the eyes might need crow's feet, or we need to add a logo to the vest.
As you start to edit the image,
you realize that there just are not enough pixels available to paint the detail that you want.

Your only choice is to expand the size (scale out) that UV face.
Using the minimize stretch or scale tools,
you expand the UV faces around the eyes or chest, allocating more pixels to those areas,
but at the same time taking away pixels (detail) from something else,
like the back of the head. After refining the UV map,
you then edit the image so that it looks right and contains the details you want.

Reusing Textures
----------------

Another consideration is the need to conserve resources. Each image file is loaded in memory.
If you can re-use the same image on different meshes, it saves memory. So, for example,
you might want to have a generic face painting, and use that on different characters,
but alter the UV map and shape and props (sunglasses) to differentiate.

You might want to have a "faded blue jeans" texture,
and unwrap just the legs of characters to use that image.
It would be good to have a generic skin image, and use that for character's hands, feet, arms,
legs, and neck. When modeling a fantasy sword,
a small image for a piece of the sword blade would suffice,
and you would Reset Unwrap the sword faces to re-use that image down the length of the blade.

********
Overview
********

The most flexible way of mapping a 2D texture over a 3D object is a process called "UV
mapping". In this process, you take your three-dimensional (X, Y &amp; Z)
mesh and unwrap it to a flat two-dimensional (X &amp; Y ... or rather, as we shall soon see,
"U &amp; V") image. Colors in the image are thus mapped to your mesh,
and show up as the color of the faces of the mesh. Use UV texturing to provide realism to your
objects that procedural materials and textures cannot do,
and better details than Vertex Painting can provide.

UVs Explained
=============

.. list-table::

* - .. figure:: /images/editors_uv_image_uv_editing_overview_boxprecut.jpg

Box being inspected.

- .. figure:: /images/editors_uv_image_uv_editing_overview_boxcutup.jpg

Box mapped flat.

The best analogy to understanding UV mapping is cutting up a cardboard box.
The box is a three-dimensional (3D) object, just like the mesh cube you add to your scene.

If you were to take a pair of scissors and cut a seam or fold of the box,
you would be able to lay it flat on a tabletop.
As you are looking down at the box on the table,
we could say that U is the left-right direction, is V is the up-down direction.
This image is thus in two dimensions (2D). We use U and V to refer to these
"texture-space coordinates" instead of the normal X and Y, which are always used
(along with Z) to refer to the three dimensional space (3D).

When the box is reassembled, a certain UV location on the paper is transferred to an (X, Y, Z)
location on the box.
This is what the computer does with a 2D image in wrapping it around a 3D object.

During the UV unwrapping process, you tell Blender exactly how to map the faces of your object
(in this case, a box) to a flat image in the UV/Image Editor.
You have complete freedom in how to do this. (Continuing our previous example, imagine that,
having initially laid the box flat on the tabletop, you now cut it into smaller pieces,
somehow stretch and/or shrink those pieces,
and then arrange them in some way upon a photograph that is also lying on that tabletop).

Cartography Example
-------------------

Cartographers (map makers) have been dealing with this problem for millennia. A cartography
(map-making) example is creating a projection map of the whole world. In cartography,
we take the surface of the earth (a sphere)
and make a flat map that can be folded up into the glove compartment aboard the space shuttle.
We "fill in" spaces toward the poles, or change the outline of the map in any of several ways:

.. list-table::

* - .. figure:: /images/editors_uv_image_uv_editing_overview_projection-mercator.jpg
:width: 190px

Mercator Projection.

- .. figure:: /images/editors_uv_image_uv_editing_overview_projection-mollweide.jpg
:width: 190px

Mollweide Projection.

- .. figure:: /images/editors_uv_image_uv_editing_overview_projection-albers.jpg
:width: 190px

Albers-equal Projection.

Each of these is an example of a way to UV map a sphere.
Each of the hundred or so commonly accepted projections has its advantages and disadvantages.
Blender allows the same thing anyway we want to, on the computer.

On more complex models (like seen in the earth map above)
there pops up an issue where the faces cannot be cut,
but instead they are stretched in order to make them flat. This helps making easier UV maps,
but sometimes adds distortion to the final mapped texture. (Countries and states that are
closer to the North or the South Pole look smaller on a flat map than do ones which are close
to the Equator.)

Half-Sphere Example
-------------------

.. figure:: /images/editors_uv_image_uv_editing_overview_3d-uv-space.jpg
:width: 600px

3D Space (XYZ) versus UV Space (click to enlarge).

In this image you can easily see that the shape and size of the marked face in 3D space is
different in UV space.

This difference is caused by the "stretching" (technically called mapping) of the 3D part
(XYZ) onto a 2D plane (i.e the UV map).

If a 3D object has a UV map, then, in addition to the 3D-coordinates X, Y, and Z,
each point on the object will have corresponding U and V coordinates. (*P* in the
image above is an example of how a point on a 3D object might be mapped onto a 2D image.)

The UV/Image Editor
===================

To learn about the functionalities for UV mapping see the
:ref:`UV/Image Editor &lt;editors-uv-image-index&gt;` section for details.

Advantages of UVs
=================

While procedural textures (described in the previous chapters) are useful-they never repeat
themselves and always "fit" 3D objects-they are not sufficient for more complex or natural
objects. For instance, the skin on a human head will never look quite right when procedurally generated.
Wrinkles on a human head, or scratches on a car do not occur in random places,
but depend on the shape of the model and its usage. Manually-painted images,
or images captured from the real world gives more control and realism.
For details such as book covers, tapestry, rugs, stains, and detailed props,
artists are able to control every pixel on the surface using a UV Texture.

A UV map describes what part of the texture should be attached to each polygon
in the model. Each polygon's vertex gets assigned to 2D coordinates that define which part of
the image gets mapped. These 2D coordinates are called UVs
(compare this to the XYZ coordinates in 3D).
The operation of generating these UV maps is also called "unwrap",
since it is as if the mesh were unfolded onto a 2D plane.

For most simple 3D models,
Blender has an automatic set of unwrapping algorithms that you can easily apply.
For more complex 3D models, regular Cubic, Cylindrical or Spherical mapping,
is usually not sufficient. For even and accurate projection,
use seams to guide the UV mapping.
This can be used to apply textures to arbitrary and complex shapes,
like human heads or animals. Often these textures are painted images,
created in applications like the Gimp, Photoshop, or your favorite painting application.

.. note:: Games

UV mapping is also essential in the :doc:`Game Engine &lt;/game_engine/index&gt;`,
or any other game. It is the de facto standard for applying textures to models;
almost any model you find in a game is UV mapped.

*********
Selecting
*********

Selection tools are available in the *Select Menu* in the header,
and the shortcuts listed below:

Menu
====

Border Select
Use the box lasso to select UV coordinates :kbd:`B`.
See :ref:`select-border`.
Border Select Pinned
Use the box lasso to select only pinned UV coordinates :kbd:`Shift-B`.
Circle Select
See :ref:`select-circle`.
Select/Deselect All
Selects or de-selects all UV coordinates :kbd:`A`.
Inverse
Inverts the current selection :kbd:`Ctrl-I`.
Select Pinned
Selects all pinned UVs :kbd:`Shift-P`.
See Pinning.
Select Linked
This operator selects all UVs that are connected to currently selected UVs :kbd:`Ctrl-L`.
This works similarly to the tools in 3D View.
More
..
Less
..

.. Ed. Unlink not working? Ctrl-shift-L is key-mapped.

Unlink Selection :kbd:`Alt-L`
Cuts apart the selected UVs from the map.
Only those UVs which belong to fully selected faces remain selected.
As the name implies, this is particularly useful to unlink faces and move them elsewhere.
The hotkey is analogous to the mesh Separate tool.

Header
======

Sync Selection
Turning on the *Sync Selection* button causes selection of components
in the 3D View to sync with their corresponding elements in the UV/Image editor.
If off only the selected faces are displayed in the UV/Image editor.
These two modes have very different results when transforming components in the UV/Image editor.

Selection Modes
---------------

Select Modes dependent on the Sync Selection.

Sync Selection Off
^^^^^^^^^^^^^^^^^^

Vertex
Select individual vertices.
Edge
Select edges.
Face
Select faces.
Island
Select contiguous groups of faces.

Sticky Selection Mode
This selector lets you enable automatic additional selection.

Shared Vertex
Selects UVs that share a mesh vertex, even if they are in different UV locations.
Shared Location
Selects UVs that are in the same UV location and share a mesh vertex.
Disabled
Disables Sticky Selection.
When you move a UV in this mode, each face owns its own UVs, allowing them to be separated.

Sync Selection On
^^^^^^^^^^^^^^^^^

When selecting UVs or Edges, it behave like *Shared Vertex* mode above.
When selecting Faces, it behaves as in *Disabled Stick Selection* above.

- Vertex
- Edge
- Face

##############
Unwrapping
##############

.. toctree::
:maxdepth: 2

introduction.rst
mapping_types.rst
seams.rst

************
Introduction
************

The first step is to unwrap your mesh. You want to unwrap when you feel your mesh is complete
with respect to the number of faces it needs to have.
If you do add faces or subdivide existing faces when a model is already unwrapped,
Blender will add those new faces for you,
but you may need to do additional mapping or editing. In this fashion,
you can use the UV Texture image to guide additional geometry changes.

This section covers techniques for Mapping Uvs.
The next sections cover :doc:`Editing UVs &lt;/editors/uv_image/uv_editing/layout_editing&gt;`,
followed by methods of :doc:`Managing UV Layouts &lt;/editors/uv_image/uv_editing/layout_management&gt;`,
and :doc:`Applying Images to UVs &lt;/editors/uv_image/uv_editing/applying_image&gt;`.

About UVs
=========

Every point in the UV map corresponds to a vertex in the mesh.
The lines joining the UVs correspond to edges in the mesh.
Each face in the UV map corresponds to a mesh face.

Each face of a mesh can have many UV Textures.
Each UV Texture can have an individual image assigned to it.
When you unwrap a face to a UV Texture in the UV/Image Editor, each face of the mesh is
automatically assigned *four UV coordinates:* These coordinates define the way an image or a
texture is mapped onto the face. These are 2D coordinates, which is why they are called UV,
to distinguish them from XYZ coordinates.
These coordinates can be used for rendering or for real-time OpenGL display as well.

Every face in Blender can have a link to a different image.
The UV coordinates define how this image is mapped onto the face.
This image then can be rendered or displayed in real time. A 3D View has to be in "Face
Select" mode to be able to assign Images or change UV coordinates of the active Mesh Object.
This allows a face to participate in many UV Textures.
A face at the hairline of a character might participate in the facial UV Texture,
*and* in the scalp/hair UV Texture.

These are described more fully in the next sections.

Getting Started
===============

.. figure:: /images/editors_uv_image_uv_editing_unwrapping_introduction_screenlayout.jpg
:width: 320px

UV Editing screen layout.

By default, meshes are not created with UVs. First you must map the faces, then
you can :doc:`edit them &lt;/editors/uv_image/uv_editing/layout_editing&gt;`.
The process of unwrapping your model is done within Edit Mode in the 3D View editor.
This process creates one or more UV Islands in the :ref:`UV/Image Editor &lt;editors-uv-image-index&gt;`.

To begin, choose the *UV Editing* :doc:`screen layout &lt;/interface/window_system/screens&gt;`
from the selection list at the top of your screen in the User Preferences header.
This sets one of the area to show you the UV/Image Editor
:kbd:`Shift-F10`, and the other area to the 3D View :kbd:`Shift-F5`.

Enter *Edit Mode*, as all unwrapping is done in Edit Mode. You can be in vertex,
face, or edge selection mode.

Workflow
--------

The process for unwrapping is straightforward, but there are tons of options available,
each of which dramatically affect the outcome of the unwrap.
By understanding the meaning behind the options, you will become more efficient at unwrapping.
The process is:

- Mark Seams if necessary
- Select all of the mesh components
- Select a UV mapping method from the UV Unwrap menu
- Adjust the unwrap settings
- Add a test image to see if there will be any distortion.
See :doc:`Applying Images to UVs &lt;/editors/uv_image/uv_editing/applying_image&gt;`
- Adjust UVs in the UV/Image editor.
See :doc:`Editing UVs &lt;/editors/uv_image/uv_editing/layout_editing&gt;`
..    TODO/Review: {{review|im=additional examples}}.

*************
Mapping Types
*************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Shading/UVs --&gt; UVs --&gt; UV Mapping: Unwrap`
| Menu:     :menuselection:`Mesh --&gt; UV Unwrap`
| Hotkey:   :kbd:`Ctrl-U`

Blender offers several ways of mapping UVs.
The simpler projection methods use formulas that map 3D space onto 2D space,
by interpolating the position of points toward a point/axis/plane through a surface.
The more advanced methods can be used with more complex models, and have more specific uses.

Basic:

`Cube Projection`_
Maps the mesh onto the faces of a cube, which is then unfolded.
Sphere
Projects the UVs onto a spherical shape. Useful only for spheres or spherical shapes, like eyes, planets, etc.
Cylinder
Projects UVs onto a cylindrical surface.
`Project from View`_
Takes the current view in the 3D View and flattens it as it appears.

Advanced:

`Unwrap`_
Useful for organic shapes. Smooths the mesh into a flat surface by cutting along seams.
`Smart UV Project`_
Breaks the mesh into islands based on an angle threshold.
Lightmap Pack
Separates each face and packs them onto the UV grid.
`Follow Active Quads`_
Follow UV from active quads along continuous face loops.

You can also `Reset`_ UVs, which maps each face to fill the UV grid,
giving each face the same mapping.

If we were to use an image that was tileable,
the surface would be covered in a smooth repetition of that image,
with the image skewed to fit the shape of each individual face.
Use this unwrapping option to reset the map and undo any unwrapping (go back to the start).

Unwrap
======

.. figure:: /images/editors_uv_image_uv_editing_unwrapping_unwrap-example.png
:width: 300px

Result of unwrapping Suzanne.

Begin by selecting all faces to be unwrapped in the 3D View. With our faces selected,
it is now time to unwrap them.
In the 3D View, select :menuselection:`Mesh --&gt; UV Unwrap --&gt; Unwrap` or
:kbd:`U` and select Unwrap.

You can also do this from the UV/Image Editor with :menuselection:`UVs --&gt; Unwrap` or :kbd:`E`.
This method will unwrap all of the faces and reset previous work. The
UVs menu will appear in the UV/Image Editor after unwrapping has been performed once.

This tool unwraps the faces of the object to provide the
"best fit" scenario based on how the faces are connected and will fit within the image,
and takes into account any seams within the selected faces.
If possible, each selected face gets its own different area of the image and is not overlapping any other faces UV's.
If all faces of an object are selected, then each face is mapped to some portion of the image.

Operator panel
--------------

Blender has two ways of calculating the unwrapping.
They can be selected in the tool setting in the tool panel in the 3D View.

Angle Based
This method gives a good 2D representation of a mesh.
Conformal
Uses LSCM (Least Squared Conformal Mapping). This usually gives a less accurate UV mapping than Angle Based,
but works better for simpler objects.

Fill Holes
Activating Fill Holes will prevent overlapping from occurring and better represent any holes in the UV regions.
Correct Aspect
Map UVs taking image aspect into account.

Use Subdivision Surface Modifier
Map UVs taking vertex position after Subdivision Surface Modifier into account.

Margin
Space between UV islands.

.. tip::

A face's UV image texture only has to use *part* of the image, not the *whole* image.
Also, portions of the same image can be shared by multiple faces.
A face can be mapped to less and less of the total image.

Smart UV Project
================

.. figure:: /images/editors_uv_image_uv_editing_unwrapping_smart-project.png
:width: 250px

Smart UV project on a cube.

Smart UV Project, (previously called the Archimapper)
gives you fine control over how automatic seams should be created,
based on angular changes in your mesh.
This method is good for simple and complex geometric forms,
such as mechanical objects or architecture.

This function examines the shape of your object,
the faces selected and their relation to one another,
and creates a UV map based on this information and settings that you supply.

In the example to the right,
the Smart Mapper mapped all of the faces of a cube to a neat arrangement of three sides on top,
3 sides on the bottom, for all six sides of the cube to fit squarely,
just like the faces of the cube.

For more complex mechanical objects, this tool can very quickly and easily create a very
logical and straightforward UV layout for you.

Operator panel
--------------

The Operator panel in the Tool Shelf allows the fine control over how the mesh is
unwrapped:

Angle Limit
This controls how faces are grouped: a higher limit will lead to many small groups but less distortion,
while a lower limit will create fewer groups at the expense of more distortion.

Island Margin
This controls how closely the UV islands are packed together.
A higher number will add more space in between islands.

Area Weight
Weight projection's vector by faces with larger areas.

.. _lightmap-pack:

Lightmap Pack
=============

Lightmap Pack takes each of a mesh's faces, or selected faces,
and packs them into the UV bounds. Lightmaps are used primarily in gaming contexts,
where lighting information is baked onto texture maps,
when it is essential to utilize as much UV space as possible.
It can also work on several meshes at once.
It has several options that appear in the Tool Shelf:

You can set the tool to map just *Selected Faces* or *All Faces* if
working with a single mesh.

The *Selected Mesh Object* option works on multiple meshes. To use this,
in *Object Mode* select several mesh objects,
then go into *Edit Mode* and activate the tool.

Operator panel
--------------

Share Tex Space
This is useful if mapping more than one mesh.
It attempts to fit all of the objects' faces in the UV bounds without overlapping.
New UV Map
If mapping multiple meshes, this option creates a new UV map for each mesh.
See :doc:`Managing the Layout &lt;/editors/uv_image/uv_editing/layout_management&gt;`.
New Image
Assigns new images for every mesh, but only one if *Shared Tex Space* is enabled.

Image Size
Set the size of the new image.

Pack Quality
Pre-packing before the more complex Box packing.
Margin
This controls how closely the UV islands are packed together.
A higher number will add more space in between islands.

Follow Active Quads
===================

The :menuselection:`Face --&gt; Unwrap --&gt; Follow Active Quads` takes the selected faces and lays them out
by following continuous face loops, even if the mesh face is irregularly shaped.
Note that it does not respect the image size,
so you may have to scale them all down a bit to fit the image area.

Operator panel
--------------

Edge Length Mode:

Even
Space all UVs evenly.
Length
Average space UVs edge length of each loop.

.. note::

Please note that it is the shape of the active quad in UV space that is being followed,
not its shape in 3D space. To get a clean 90-degree unwrap make sure the active quad is a
rectangle in UV space before using "Follow active quad".

Cube Projection
===============

Cube mapping projects s mesh onto six separate planes, creating six UV islands.
In the UV/Image editor, these will appear overlapped, but can be moved.
See :doc:`Editing UVs &lt;/editors/uv_image/uv_editing/layout_editing&gt;`.

Basic Mapping

Based on the fundamental geometry of the object, and how it is being viewed,
the :menuselection:`Mesh --&gt; UV Unwrap --&gt; Cube, Cylinder and Sphere`
UV Calculations attempt to unfold the faces for you as an initial best fit.
Here, the view from the 3D View is especially important.
Also, the settings for cube size or cylinder radius (Editing buttons, UV Calculation panel)
should be set (in Blender units) to encompass the object.

Operator panel
--------------

Cube Size
Set the size of the cube to be projected onto.

Common
^^^^^^

The following settings are common for the Cube, Cylinder, and Sphere mappings:

Correct Aspect
Map UVs taking image aspect ratios into consideration.
If an image has already been mapped to the texture space that is non-square,
the projection will take this into account and distort the mapping to appear correct.
Clip to Bounds
Any UVs that lie outside the (0 to 1) range will be clipped to that range
by being moved to the UV space border it is closest to.
Scale to Bounds
If the UV map is larger than the (0 to 1) range, the entire map will be scaled to fit inside.

Cylinder and Sphere Projection
==============================

.. figure:: /images/editors_uv_image_uv_editing_unwrapping_sphere-projection.png
:width: 350px

Using a Mercator image with a Sphere Projection.

Cylindrical and Spherical mappings have the same settings. The difference is that a
cylindrical mapping projects the UVs on a plan toward the cylinder shape,
while a spherical map takes into account the sphere's curvature,
and each latitude line becomes evenly spaced.

Normally, to unwrap a cylinder (tube) as if you slit it lengthwise and folded it flat,
Blender wants the view to be vertical, with the tube standing "up".
Different views will project the tube onto the UV map differently, skewing the image if used.
However, you can set the axis on which the calculation is done manually.
This same idea works for the sphere mapping:

Recall the opening cartographer's approaching to mapping the world? Well,
you can achieve the same here when unwrapping a sphere from different perspectives. Normally,
to unwrap a sphere, view the sphere with the poles at the top and bottom. After unwrapping,
Blender will give you a Mercator projection;
the point at the equator facing you will be in the middle of the image.
A polar view will give a very different but common projection map. Using a Mercator projection
map of the earth as the UV image will give a very nice planet mapping onto the sphere.

Operator panel
--------------

Direction
View on Poles
Use when viewing from the top (at a pole) by using an axis that is straight down from the view.
View on Equator
Use if view is looking at the equator, by using a vertical axis.
Align to Object
Uses the object's transform to calculate the axis.

Align
Select which axis is up.

Polar ZX
Polar 0 is on the X axis.
Polar ZY
Polar 0 is on the Y axis.

Radius
The radius of the cylinder to use.

Project From View
=================

In the 3D View, the :menuselection:`Face --&gt; Unwrap UVs --&gt; Project from View` option maps the face as
seen through the view of the 3D View it was selected from.
It is almost like you had x-ray vision or squashed the mesh flat as a pancake onto the UV map.
Use this option if you are using a picture of a real object as a UV Texture for an object that
you have modeled. You will get some stretching in areas where the model recedes away from you.

Project From View (Bounds)
==========================

Using *Project from View (Bounds)* will do the same as above,
but scales the UVs to the bounds of the UV space.

Reset
=====

In the 3D View, :menuselection:`Face --&gt; Unwrap --&gt; Reset`
maps each selected face to the same area of the image,
as previously discussed. To map all the faces of an object (a cube, for example)
to the same image, select all the faces of the cube,
and unwrap them using the Reset menu option.

*****
Seams
*****

Introduction
============

.. figure:: /images/editors_uv_image_uv_editing_unwrapping_seam_simple.png
:width: 300px

Simple Seam on a Cylinder.

For many cases, using the Unwrap calculations of Cube, Cylinder, Sphere,
or best fit will produce a good UV layout. However, for more complex meshes,
especially those with lots of indentations, you may want to define a *seam* to limit and
guide any of the unwrapping processes discussed above.

Just like in sewing, a seam is where the ends of the image/cloth are sewn together.
In unwrapping, the mesh is unwrapped at the seams.
Think of this method as peeling an orange or skinning an animal.
You make a series of cuts in the skin, then peel it off. You could then flatten it out,
applying some amount of stretching. These cuts are the same as seams.

When using this method, you need to be aware of how much stretching there is.
The more seams there are, the less stretching there is,
but this is often an issue for the texturing process.
It is a good idea to have as few seams as possible while having the least amount of stretching.
Try to hide seams where they will not be seen. In productions where 3D paint is used,
this becomes less of an issue, as projection painting can easily deal with seams,
as opposed to 2D texturing, where it is difficult to match the edges of different UV islands.

The workflow is the following:

- Create seams.
A seam is marked in Edit Mode by selecting edges to make the seam and then issuing the Mark Seam operator.
- Unwrap.
- Adjust seams and repeat.
- Manually adjust UVs. See the next section on Editing UVs.

Marking Seams
=============

.. figure:: /images/editors_uv_image_uv_editing_unwrapping_seams.png
:width: 250px

Seamed Suzanne.

To add an edge to a seam,
simply select the edge and :kbd:`Ctrl-E` *Mark Seam*.
To take an edge out of a seam, select it, :kbd:`Ctrl-E` and *Clear Seam*.

In the example to the right, the back-most edge of the cylinder was selected as the seam
(to hide the seam), and the default unwrap calculation was used.
In the UV/Image Editor, you can see that all the faces are nicely unwrapped,
just as if you cut the seam with a scissors and spread out the fabric.

When marking seams, you can use the :menuselection:`Select --&gt; Linked Faces` or :kbd:`Ctrl-L` in
Face Select Mode to check your work.
This menu option selects all faces connected to the selected one, up to a seam.
If faces outside your intended seam are selected, you know that your seam is not continuous.
You do not need continuous seams, however, as long as they resolve regions that may stretch.

Just as there are many ways to skin a cat,
there are many ways to go about deciding where seams should go. In general though,
you should think as if you were holding the object in one hand,
and a pair of sharp scissors in the other,
and you want to cut it apart and spread it on the table with as little tearing as possible.
Note that we seamed the outside edges of her ears, to separate the front from the back.
Her eyes are disconnected sub-meshes, so they are automatically unwrapped by themselves.
A seam runs along the back of her head vertically,
so that each side of her head is flattened out.

Another use for seams is to limit the faces unwrapped. For example, when texturing a head, you
do not really need to texture the scalp on the top and back of the head since it will be
covered in hair. So define a seam at the hairline. Then, when you select a frontal face,
and then select linked faces before unwrapping,
the select will only go up to the hairline seam, and the scalp will not be unwrapped.

When unwrapping anything that is bilateral, like a head or a body,
seam it along the mirror axis. For example,
cleave a head or a whole body right down the middle in front view. When you unwrap,
you will be able to overlay both halves onto the same texture space,
so that the image pixels for the right hand will be shared with the left;
the right side of the face will match the left, etc.

.. note::

You **do not** have to come up with "one unwrapping that works perfectly
for everything everywhere." As we will discuss later,
you can easily have multiple UV unwrappings,
using different approaches in different areas of your mesh.

************
UV Sculpting
************

.. admonition:: Reference
:class: refbox

| Mode:     Paint Mode and Mask Mode
| Panel:    :menuselection:`Tools Shelf --&gt; Tools`
| Menu:     :menuselection:`UVs --&gt; UV Sculpt`
| Hotkey:   :kbd:`Q`

The UV Sculpting "mode" allow you to grab, pinch and smooth UVs, just like Sculpt Mode.
It can be activated with :kbd:`Q` or by checking UV Sculpt in the *UVs* menu.

UV Sculpt
=========

When UV sculpting is activated, the Tool Shelf shows the brush tool selection and options.

Lock Borders
Locks the boundary of UV islands from being affected by the brush.
This is very useful to preserve the shape of UV islands.
Sculpt All Islands
To edit all islands and not only the island nearest to the brush center
when the sculpt stroke was started.
UV Sculpt Tools
Brushes that operate on UVs.
All brushes use the Airbrush Stroke Method: they continue to act as long as you keep :kbd:`LMB` pressed.

Grab :kbd:`G`
The Grab brush moves UVs around.
Relax :kbd:`S`, :kbd:`Shift-LMB`
The Relax brush makes UVs more evenly distributed.
The algorithm relies on space, not stretch minimization,
so most probably a minimize stretch will have to be run for optimal results.
However it is great to use after stitching islands,
or when unwrap produces cluttered results  to smooth the distribution of UVs.

Relaxation Method
There are two relax algorithms:

Laplacian, HC
Pinch :kbd:`P`
The Pinch brush moves UVs toward brush center.
The pinch brush can be inverted by pressing :kbd:`Ctrl-LMB`.
Show Brush
Hides the sculpt cursor.
.. _editors-sequencer-index:

#########################
Video Sequence Editor
#########################

.. toctree::
:maxdepth: 2

introduction.rst
sequencer/index.rst
preview/index.rst

************
Introduction
************

In addition to modeling and animation, Blender can be used to edit video.
There are two possible methods for this one being the :doc:`Compositor &lt;/compositing/introduction&gt;`.
However, this chapter is on the other, the Video Sequence Editor (VSE) and some time shorten to just Sequencer.
The Sequencer within Blender is a complete video editing system that allows you to combine multiple
video channels and add effects to them. You can use these effects to create powerful video edits
(especially when you combine it with the animation power of Blender!).

To use the VSE, you load multiple video clips and lay them end-to-end (or in some cases, overlay them),
inserting fades and transitions to link the end of one clip to the beginning of another.
Finally, you can audio and synchronize the timing of the video sequence to match it.

.. figure:: /images/editors_sequencer_modes_screen_layout.jpg

Default Video Editing screen layout.

View Types
==========

The Video Sequence Editor has a three view types for the main view.

The View Types toggles in the header allow you to change the view of the VSE.
When the first button is toggled only the sequencer is displayed (the default).
The second button displays only the Preview region, and
the third button displays both the Sequencer and the Preview.

************
Display Mode
************

The are an array of different display modes available, each having a specific purpose.

Image Preview
=============

The Image Preview mode shows you what the resulting video will look like when saved.
This is the main working mode for adding strips and moving them around,
cutting, grouping (making meta) and splicing them through special effects.

Luma Waveform
=============

For the selected channel, brightness, or luminosity, is mapped with this display.

A luma waveform allows you to judge the quality of the luminance distribution across the video signal,
you can view a luma-waveform instead of the usual output display on every control monitor.

The display plots for every scanline the luminance value. The lines are all drawn on top of each other.
The points get brighter if the lines cross (which is very likely with several hundred scanlines).
You will understand the picture most easily if you plug an oscilloscope to the
Luma-video-output of your television set. It will basically look the same.

In this mode, the vertical axis represents the luminosity: 0 at the bottom, 1 at the top;
the horizontal axis is a mapping from the horizontal axis of the frame.
There are as many curves as scanlines in the frame:
each one of this curves represents the luminosity of the pixels of one line.
Moreover, the color of a pixel in this mode represents the number of pixels from the matching column of the
frame sharing the same luminosity, i.e. the number of curves that cross at this point
(black/transparent, for no pixel, white/opaque for at least three pixels).

Separate Colors
Separates RGB channels into separate graphs.

This mode is good for:

- If the waveform does not fill the whole picture you might want to play with the Bright/Contrast modifier
until it fills the whole picture (contrast autostretch).
- With the more advanced Curves or Color Balance modifiers, you can be more precise.
- You can judge if you want to dump the whole thing since it is
completely distorted and clips at the top or the bottom.

.. list-table::

* - .. figure:: /images/editors_sequencer_display-modes_luma-waveform-example-1.png

The various horizontal lines in the Luma waveform
match the uniform-color lines of the picture. Note that the 'gray 20%'
one-pixel width line (inside the yellow strip) is represented in the Luma waveform by a gray line.
The two lines drawing an "X" are from the two linear tone shades (white --&gt; black and black --&gt; white).
Finally, the broken line matches the complex tone shade at the bottom of the picture.

- .. figure:: /images/editors_sequencer_display-modes_luma-waveform-example-2.png

The curves are quite visible. We found a luma of 80-100% for the sky,
a luma around 40% for the sea, and a luma of 10-20% for the mountains,
growing around 40% for the sunny part.

.. Note::

Note that the pictures (first green frame, at the top) are only 50px high,
to limit the number of curves displayed in the *Luma waveform*

Use this display to check for appropriate contrast and luminosity across all frames in the channel.
When spots in the film that should have even illumination do not,
it looks like a flashbulb went off or an extra light was suddenly turned on. This can happen
if two strips were rendered or shot under different lighting conditions but are supposed to be contiguous.

Chroma Vectorscope
==================

.. figure:: /images/editors_sequencer_display-modes_example.jpg

Example image.

.. figure:: /images/editors_sequencer_display-modes_vectorscope.png

Example of Chroma Vectorscope Preview.

Use this mode judge the quality of the color-distribution and saturation, you can also view a U/V scatter-plot.

The picture is converted to YUV-format. The U- and V-values represent the angle of the color.
For pixel of the picture, one point is plotted in the display at the U and V-value-position.
If several pixels happen to have the same U/V-value the pixel in the plot gets brighter.

To help you understand what color is meant, a hexagram marking the extreme positions (red,
magenta, blue, cyan, green, yellow) is drawn and a red cross to mark the origin.

In other words, for the selected channel, this display shows the color space of the image inside a hexagon.
Each point of the hexagon is a primary color: red, magenta, blue, cyan, green, and yellow.
Black is at the center, and overall saturation is scaled as dots closer to the outside.
The example to the right shows that the image has a lot of red (50% saturation)
and small amount of blue, with no green.

Always: remember to activate an additional control monitor of the end result.
Color calibration is a matter of taste and depends on what you want.

Use this display to check for too much color saturation.
While over-saturated images look great for op-art and computer displays,
they stink when shown on the big screen TV. Use :kbd:`Alt-A` to scrub the video;
this display will update with a new/revised map for each frame.
Just like watching the Image preview to see what it looks like,
watch the Chroma Vectorscope to watch for color use.

This mode is good for:

- If you picture looks very moody or desaturated you might want to take a look at the U/V-plot.
You will most likely see all pixels building a crowd at the origin.
If you add saturation using the *Saturation* slider in the Filter panel or any modifiers that change color,
you can see in the U/V-plot if you distort the color.
- If you do color-matching on a by hand basis you can match the angle you see of different channels monitors.

Histogram
=========

.. figure:: /images/editors_sequencer_display-modes_example.jpg

Example image.

.. figure:: /images/editors_sequencer_display-modes_histogram.png

Example of Histogram Preview.

This mode displays a graph showing the distribution of color information in the pixels of the
currently displayed image. The X-axis represents values of pixel, from 0 to 1 (or 0 to 255),
while the Y-axis represents the number of pixels in that tonal range. A predominantly dark
image would have most of its information toward the left side of the graph.

Use this mode to balance out the tonal range in an image.
A well balanced image should a nice smooth distribution of color values.

###########
Preview
###########

.. toctree::
:maxdepth: 2

introduction.rst
display_mode.rst
properties.rst
.. |texture-button| image:: /images/icons_texture.png
:width: 1.1em

************
Introduction
************

By default, the VSE only displays the strips, however, there are a few ways to preview the result of your sequence.
The first is the preview mode, this can be enable by hitting the texture button (|texture-button|).

Header
======

View Menu
---------

Fit preview in window :kbd:`Home`
Resizes preview so that it fits in the window.
Zoom 1:1 :kbd:`Numpad1`
Resizes preview to a 1:1 scale (actual size).
Safe Areas
Displays an overlay on the preview, marking where title safe region is.

Controls
--------

Several options in the header allow you change the editor
to display the sequence in real time, and in various ways.

.. figure:: /images/editors_sequencer_display-modes_header.png

Sequencer Display Header.

The second button will change the editor to display only the preview,
and the third button displays both the sequencer and the preview.

Display Mode
Mode to show different aspects of the composite result,
for the current frame:

- Image/Sequence: Colors (what you see).
- Luma: Brightness/contrast.
- Chroma: Color hue and saturation.
- Histogram: Levels of red, green, and blue.

Channel
Selects the channels to show in the preview.

Channel 0 is the compositing result of all strips.
Channel 1 is the current frame's image from the strip in channel 1 only
(channel 1 is at the bottom of the heap). The display of these modes is either the composite
(channel 0) or the frame from the strip (channels 1 through n).
Overlay (ghost icon)
Option to enable the overlay. It can be used for comparing the current frame to a reference frame.

Frame
The slider control the offset of the reference frame relative to current frame.
Lock (padlock icon)
It's still possible to lock the reference frame to its current position.
Type
It describes the way the reference frame should be displayed.

Rectangle
Which means the rectangle area of reference frame will be displayed on top of current frame.
This area can be defined by pressing :kbd:`O` key over the preview.
Reference
Only the reference frame is displayed in the preview region.
Current
Only the current frame is be displayed in the preview region.

.. tip::

It is possible to have several Sequencer Editors opened and they can use different overlay types.
So it is possible to have current and reference frames displayed in different editor spaces.

..
You can adjust the view by zooming in with :kbd:`Plus` and zoom out with :kbd:`Minus`.
You can also reset the view with :kbd:`Home`.

**********
Properties
**********

Scene Preview/Render
====================

It allows you to control how the images of :doc:`Scene Strips &lt;/editors/vse/sequencer/strips/scene&gt;`
are displayed in the preview.

OpenGL Preview
Use a quick OpenGL preview (see :doc:`OpenGL render &lt;/render/opengl&gt;` for more on this subject),
otherwise a full render is used, which can be very slow.

Sequencer Preview Shading
Method for rendering OpenGL renders.
See the 3D view's :ref:`view3d-viewport-shading` options.
Textured Solid
Display textures even when in solid mode.

Settings used by OpenGL Previews:

- The anti-alias setting from the active scene is used for all scenes.
- The alpha setting is taken from each scene strip *Alpha Mode* option.

View Settings
=============

Show Overexposed
Shows overexposed (bright white) areas using a zebra pattern.
The threshold can be adjust with the slider.
Proxy Render Size
Size to display proxies at in the preview region.
Using a smaller preview size will increase speed.

Safe Areas
==========

Shows guides used to position elements to ensure that the
most important parts of the video can be seen across all screens.

.. seealso::

See :ref:`Safe Areas &lt;camera-safe-areas&gt;` in the camera docs.

Grease Pencil
=============

Allows you to use :doc:`Grease Pencil &lt;/interface/grease_pencil/index&gt;` in the sequencer.

*******
Editing
*******

Grab/Move
=========

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Strip --&gt; Grab/Move`
| Hotkey:   :kbd:`G`

Holding down :kbd:`RMB` and then moving the mouse drags the active strip in time or in channels.
Pressing :kbd:`G` moves the all selected strip(s).
Move your mouse horizontally (left/right) to change the strip's position in time.
Move vertically (up/down) to change channels.

Holding down :kbd:`Ctrl` while dragging snaps to the start and endpoints of other strips.
The position of the mouse relative to the selection influences where the strips are snapped.
If it is closer to the start of the selection, then the start frame of the selection gets snapped,
else the end frame will get snapped.

To "ripple edit" (Make room for strips you drag) hold :kbd:`Alt` when placing a strip.

You can also lock the direction to time with :kbd:`X` or to change the strip's channel with :kbd:`Y`.

Start Frame Offset
------------------

The *start frame offset* for that strip could be selected by clicking :kbd:`RMB` on the left arrow of the strip;
holding it down (or pressing :kbd:`G` rab and then moving the mouse left/right
changes the start frame within the strip by the number of frames you move it.
The frame number label under the strip displays the start frame of the strip.

- If you have a 20-image sequence strip, and drag the left arrow to the right by 10 frames,
the strip will start at image 11 (images 1 to 10 will be skipped).
Use this to clip off a rollup or useless lead-in.
- Dragging the left arrow left will create a lead-in (copies) of the first frame for as many frames as you drag it.
Use this when you want some frames for transitions to the this clip.

End Frame
---------

The *end frame* of the strip could be selected by clicking :kbd:`RMB` on the right arrow of the strip;
holding it down (or pressing :kbd:`G` rab) and then moving the mouse changes the ending frame within the strip.
The frame number label over the strip displays the end frame of the strip.

- Dragging the right arrow to the left shortens the clip;
any original images at the tail are ignored. Use this to quickly clip off a rolldown.
- Dragging the right arrow right extends the clip.
For movies and images sequences, more of the animation is used until exhausted.
Extending a clip beyond its end results in Blender making a copy of the last image.
Use this for transitions out of this clip.

.. note:: Multiple selection

You can select several (handles of) strips by :kbd:`Shift-RMB` clicking: when you press :kbd:`G`,
everything that is selected will move with your mouse- this means that,
for example, you can at the same time move a strip, shorten two others, and extend a forth one.

Grab/Extend from Frame
======================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Strip --&gt; Grab/Extend from Frame`
| Hotkey:   :kbd:`E`

With a number of strips selected, pressing :kbd:`E` lets you interactively extend the strips.
This is is similar to grabbing but is useful for extending (or shortening) time around the current frame.

All selected strip handles to the "mouse side" of the current frame indicator will transform together,
so you can change the duration of the current frame.

Slip Strip Content
==================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Strip --&gt; Slip Strip Content`
| Hotkey:   :kbd:`S`

The slip tool allows you to change the position of the contents of a strip without moving the strip itself.

Tools
=====

Erase Strips :kbd:`X`, :kbd:`Delete`
Delete the selected strip(s).
Duplicate Strips :kbd:`Shift-D`
Duplicate a strip to make an unlinked copy;
drag it to a time and channel, and drop it by :kbd:`LMB` click.
Clear Strips Offsets :kbd:`Alt-O`
To reset the (soft) start/end frame handles.

The Strip Menu contains additional tools for working with strips:

- Insert/Remove Gap
- Deinterlace Movies
- Set Render Size
- Reload Strips
- Swap Inputs
- Lock Strips
- UnLock Strips
- Swap Strips

Snap Strips
===========

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Strip --&gt; Snap Strips`
| Hotkey:   :kbd:`Shift-S`

Position your cursor (vertical green line) to the time you want.
Snap to current frame to start a strip exactly at the beginning of the frame.
If your Time display is in seconds,
you can get to fractional parts of a second by zooming the display;
you can get all the way down to an individual frame.

Separate Images
===============

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Strip --&gt; Separate Images`
| Hotkey:   :kbd:`Y`

For images sequence only -- Converts the strip into multiple strips, one strip for each frame.
Useful for slide shows and other cases where you want to bring in a set on non-continuous images.

Length
You have to specify the duration you want the resulting strips will be.

Reassign Inputs
===============

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Strip --&gt; Reassign Inputs`
| Hotkey:   :kbd:`R`

This tool can be used to assign (reconnect) effect strips in a different way
Just select three arbitrary strips and press :kbd:`R`.
If you don't create a cycle, those will be connected to a new effect chain.

Cut (soft) at Frame
===================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Strip --&gt; Cut (soft) at Frame`
| Hotkey:   :kbd:`K`

.. While splicing two strips happens just by placing them finish-to-start,

Cut the selected strip in two by pressing :kbd:`K` at the current frame.
This will result in two strips of the same source, but resized to fit the original strip's length.
You will still be able to resize them after.
Use Cut to trim off roll-ups or lead-ins, or roll-downs or extra film shot.

.. note:: Note on the *Cut*

When you cut a strip, you do not really make a cut like it cutting a real of film.
In fact, you make a copy of the strip: the end of the original one is "winded" to the cut point,
as with the beginning of the new copy.

For example, imagine that you have a strip of 50 frames,
and that you want to delete the first ten ones.
You have to go to frame 11, and press :kbd:`K`;
the cut divides your strip in two parts. You now can select the first small part
(frame 1 to frame 10), and delete it press :kbd:`X`.

You might think that you have really erased the frames (1 to 10),
but there are still there, winded, as in a film reel, under your frame 11:
you just have deleted one of the two copies of your strip created by the cut.
And you can at any time get your lost frames back
(just :kbd:`RMB` click on the left arrow of the strip,
then :kbd:`G` grab it to the left to display the desired number of frames again (or to
the right to hid more frames -- this is another way to remove frames at the beginning/end of a strip!).

This is at the heart of nearly every editor solution, and that is quite handy!

.. note:: Action Stops

When extending the start beyond the beginning or end after the ending,
keep in mind that only the last image copies, so when viewed, action will stop on that frame.
Start your transition (fade, cross) a little early while action is
still happening so that the stop action is not that noticeable.

Change the length of an effect strip by changing the start/end frame of the origin strips.

Cut (hard) at Frame
===================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Strip --&gt; Cut (hard) at Frame`
| Hotkey:   :kbd:`Shift-K`

Like *Cut (soft) at Frame*, it cuts a strip in two distinct strips,
but this time you will not be able enlarge the resulting strips.
You can still adjust the :ref:`duration (hard) &lt;sequencer-duration-hard&gt;` number buttons
in the Strip Input panel.

Mute
====

Mute Strips :kbd:`H`
Mute the selected strip(s).
Un-Mute Strips :kbd:`Alt-H`
Un-Mutes all strips.
Mute Deselected Strips :kbd:`Shift-H`
You can mute all strips but the selected.

.. (todo) to header

Copy and Paste
==============

You can copy a clip and paste it using the two header buttons.

.. _sequencer-edit-change:

Change
======

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties Region --&gt; Strip Input`
| Menu:     :menuselection:`Strip --&gt; Change`
| Hotkey:   :kbd:`C`

The Change sequence operator modifies the file path or effect inputs/type on selected strips.

Effect
Switch the effects on a selected Effect strips.
Path/Files
Changes the source file contained in a selected strip.

#############
Sequencer
#############

.. toctree::
:maxdepth: 2

introduction.rst
navigating.rst
strips/index.rst
selecting.rst
editing.rst
meta.rst
properties/index.rst

************
Introduction
************

Header
======

.. figure:: /images/editors_sequencer_introduction_header.png

Video Sequencer Header.

Marker Menu
-----------

The Marker menu allows you to add markers in the VSE.
Markers are shared across animation editors. See :doc:`Markers &lt;/animation/markers&gt;`

Main View
=========

Channels
--------

The sequencer workspace is horizontally striped into channels and each video strip will go in
a horizontal channel. Each channel is numbered consecutively on the Y axis, starting from zero.
The X axis represents time.

.. note::

The first channel 0 is unusable as a place to put strips.
This is because it is used by the :doc:`Sequencer Display &lt;/editors/vse/preview/introduction&gt;`
to show a composite of all strips above channel 0.

The channels are stacked bottom to top (the lowest channel forms the background and the highest the foreground).

.. note::

By default the Sequencer is enabled however, it can be disabled
in the :doc:`Post Processing Panel &lt;/render/post_process/panel&gt;`.

***********
Meta Strips
***********

A Meta Strip is a strip which contain multiple strips treated as if it was one strip.
It allows you to reduce the vertical space used in the sequencer.
You can edited the same way as strips.

It is a kind of organization tool. For example,
if you are using a lot of strips and they are complicated in
the interface you can group them together using Meta strips.

Make Meta Strip :kbd:`Ctrl-G`
To create a Meta strips select all the strips you want to group, and :kbd:`Ctrl-G` to group them.
The Meta strips will span from the beginning of the first strip to the end of the last one,
and condenses all channels into a single strip.
UnMeta Strip :kbd:`Alt-G`
Separating (ungrouping) the Meta strip restores the strips to their relative positions and channels.
This can be used if you choose to delete a Meta strips and want to keep the strips inside.

.. figure:: /images/editors_sequencer_strips_meta.png

Example of Meta strips.

You can edit the content inside a Meta strip by pressing :kbd:`Tab`.
It will expand the strip to the whole view and hide any other strips.
To exit the Meta strips press :kbd:`Tab` again.
Meta strips can also be nested, which make editing them a little confusing.
To exit out one level of Meta Strip make sure you do not have a Meta strips selected when you press :kbd:`Tab`.

.. note::

The default blend mode for a Meta strip is Replace. There are many cases where this alters
the results of the animation so be sure to check the results and adjust the blend mode if necessary.

One convenient use for Meta strips is when you want to apply the same effect to multiple strips.
For example: if you have a video that was recorded in different files and want to add an effect strip.
It is much more convenient to apply a single set of effects
to one Meta strips then applying it to each individual strip.

.. seealso::

It is also possible to do the similar task described above with a
:doc:`Adjustment Layer &lt;/editors/vse/sequencer/strips/effects/adjustment&gt;` effect strip.

**********
Navigating
**********

Header
======

View Menu
---------

As usual, the View Menu controls the editors view settings.

View all Sequences :kbd:`Home`
Zooms the display to show all strips.
View Selected :kbd:`NumpadPeriod`
Zooms in the display to fit only the selected strips.
View Frame :kbd:`Numpad0`
ToDo.
Show Seconds :kbd:`Ctrl-T`
Displays the time instead of the frame number, in the Frame Number Indicator.
Show Frame Number Indicator
Toggles the units of measure across the bottom of the time cursor between seconds or frames.
Show Offsets
ToDo.

.. (wip) Show overflow bars when sliding the content.
Waveform Drawing
Global option to either draw the waveform, or the strip info,
or use the individual :ref:`strip option &lt;sequencer-sound-waveform&gt;`.
Sync Markers
Transform Markers as well as Strips.

Frame Menu
----------

Preview Range :kbd:`P`, :kbd:`Alt-P`
See :ref:`graph-preview-range`.
Jump to end of strip :kbd:`PageUp`
Current frame will jump to end of strip.
Jump to beginning of strip :kbd:`PageDown`
Current frame will jump to beginning of strip.

Refresh Sequencer
-----------------

To force Blender to re-read in files, and to force a re-render of the 3D View,
click the *Refresh Sequencer* button.
Blender will update and synchronize all cached images and compute the current frame.

Certain operations, like moving an object in 3D View, may not force the *Sequencer*
to call for a refresh of the rendered image (since the movement may not affect the rendered image).
If an image or video, used as a strip, is changed by some application outside of Blender,
Blender has no real way of being notified from your operating system.

Backdrop
--------

Displays the current frame in the background of the main view like in the node editor.

Main View
=========

Adjusting the View
------------------

Use these shortcuts to adjust the sequence area of the VSE:

- Pan :kbd:`MMB`
- Zoom :kbd:`Wheel`
- Vertical Scroll use :kbd:`Shift-Wheel`, or drag on the left scroll bar.
- Horizontal Scroll use :kbd:`Ctrl-Wheel`, or drag on the lower scroll bar.
- Scale View, :kbd:`Ctrl-MMB` and drag up/down (vertical scale) or left/right (horizontal scale).
- Scale View Vertically, drag on the circles on the vertical scroll bar.
- Scale View Horizontally, drag on the circles on the horizontal scroll bar.

Time Cursor
-----------

To move back and forth through your movie, :kbd:`LMB` click and drag left/right
in the Sequencer's main view by moving the Time cursor (the vertical bar which indicates the current frame).
As you do, the image for that frame is displayed in the Preview region.

When you drag the frame indicator with :kbd:`LMB` directly on a sequence strip,
this will show the strip *solo*, (temporarily disregarding effects and other strips,
showing only this strips output) and the strip will be highlighted.

When holding :kbd:`Ctrl` while dragging it will snap to the start and endpoints of strips.

Real-time preview is possible on reasonable computers when viewing an
image sequence or movie (``avi``/``mov``) file.
Scene strips can use OpenGL previews or proxies for realtime playback,
otherwise displaying rendered frame is supported, but typically too slow for real-time playback.

.. hint::

Every other synced editor can be used for scrubbing e.g. the Timeline.

****************
Edit Strip Panel
****************

The *Edit Strip* panel is used to control placement and properties of strips.

Name
You can name or rename your strips here.
Type
Displays the type of strip selected.
Blend Mode
Controls how the strip affects other strips.
Autoblending modes remove the need for separate effect strips.

Replace
A strip replaces the output image of any lower-level strips.
Opacity
Set the opacity (alpha) of the strip.
Mute (eye icon)
Hides the strip so that it does not participate in the final image computation.
Lock (padlock icon)
Prevents the strip from being moved.
Channel
Changes the channel number, or row, of the strip.
Start Frame
Changes the starting frame number of the strip, which is the same as grabbing and moving the strip.
Length
Specify the number of frames to use for the strip.

At the bottom you can see several informations about the input media.

************
Filter Panel
************

.. figure:: /images/editors_sequencer_properties_filter.png
:align: right

Enables you to quickly set common image pre-processing options.

Video
=====

Strobe
To only display each nth frame. For example, if you set this to 10,
the strip will only display frames 1, 11, 21, 31, 41... of the source.
*Strobe* is a float value -- this way you can get a strobe effect synced exactly to a beat,
for example, by using non-integer values.
Flip
Flips (mirrors) the image.

- X: left-to-right
- Y: top-to-bottom

Backwards
Plays the strip in reverse (time).
Deinterlace
Removes fields in a video file.
In example if it is a broadcast video and it has even or odd interlacing fields.

Colors
======

Saturation
Increase or decrease the saturation of an image.
Multiply
Multiplies the colors by this value. This will increases the brightness.

Convert Float
Converts input to float data.

##############
Properties
##############

.. toctree::
:maxdepth: 2

edit_strip.rst
input.rst
filter.rst
proxy_timecode.rst
modifiers.rst

*****************
Strip Input Panel
*****************

.. figure:: /images/editors_sequencer_properties_input.png
:align: right

Strip Input Settings.

The Strip Input panel is used to controls the source,
the duration of the strip along with some basic transforms.

Path
A text field that lets you edit/update the path of the file used by a strip.
When you moved the files, it avoids having to delete and re-create the strip.
File
Same than before, but in case you renamed the source file, you can retreive it (or change it).
Input Color Space
To specify the color space of the source file.
Alpha mode
If the source file has an Alpha (transparency) channel, you can choose:

:term:`Straight Alpha`, :term:`Premultiplied Alpha`
Change Data/File :kbd:`C`
Same as the *Path* and *File* fields, but
this time combined to open the file browser in order to find the file(s) you search.
MPEG Preseek
Movie strip only -- Use the Preseek field to tell Blender to look backward and
compose the image based on the n previous frames (e.g. 15 for Mpeg2 DVD).
Stream index
Movie strip only -- For files with several movie streams, use the stream with the given index.

Image Offset
Used to translate the frames along the X and Y axis.
Additionally it disables the auto-scaling of the image.
Image Crop
Used to crop the source image, use *Top*, *Left*,
*Bottom*, and *Right* to control which part of the image is cropped.

.. _sequencer-duration-hard:

Trim Duration (hard)
Controls at what frame the source of the strip starts and ends at.
Trim Duration (soft)
Can be used to either extend the strip beyond the end frame by repeating the last frame.
Or it can be used to shorten the strip, as if you were cropping the end frame.
This is the same has adjusting the strip handles.

***************
Modifiers Panel
***************

.. figure:: /images/editors_sequencer_properties_modifiers.png
:align: right

Modifiers are used to make adjustments on the image, like contrast,
brightness, saturation, color balance and applying masks.

You can add these modifiers directly to the selected strip,
or you can use it within an "Adjustment Layer" effect strip,
which allows you to apply these modifiers onto several strips the same time.

Use Linear Modifiers
Calculate modifiers in linear space instead of sequencer space.
Copy to Selected Strips
Allows you to copy the modifiers to selected strips.
This works two ways, you can either replace the old modifiers or append/add to the previous modifiers.

Common Options
==============

Each modifiers have several buttons at their top:

Mute (eye icon)
Disables the modifier. Very useful to compare the image, with / without modifications.
Move (up and down arrows icon)
The next two buttons are used to change the modifier's position in the stack.
Remove ``X``
The cross is to delete the modifier from the stack.

Input Mask Type
---------------

Strip
Use this to apply the modification on the whole image, or to use another strip's image (with alpha channel)
for masking the modifier (and only this modifier), by choosing it in the "Mask" select menu.
Mask
This allows you to choose a Mask created in the Mask editor
which will limit the modification to the masked image's zones.

Types
=====

Currently, the following modifiers are supported:

Color Balance
Color balance adjustments, through Lift, Gamma, and Gain.

This modifier works the same as the :doc:`Color Balance Node &lt;/compositing/types/color/color_balance&gt;`.
Curves
Color and RGB curves.

This modifier works the same as the :doc:`Curves Node &lt;/compositing/types/color/rgb_curves&gt;`.
Hue Correct
HSV multi points curves.

This modifier works the same as the :doc:`Curves Node &lt;/compositing/types/color/hue_correct&gt;`.
Bright/Contrast
Adjusts the brightness and contrast of the modifier input.
Mask
Use it for masking the other modifiers in the stack which are below.

For example, to correct the brightness only on a certain zone of the image,
you can filter the Bright/Contrast modifier by placing a Mask modifier,
just before it in the stack. You can choose to use a Mask created in the Mask editor,
or to use another strip as a mask (the image of this strip must have an alpha channel).
This mask will be applied on all the others modifiers below it in the stack.
White Balance
Use it to adjust the white balance by choosing the color that should be white.
Tone Map
Used to map one set of colors to another in order to approximate the appearance
of high dynamic range images in a medium that has a more limited dynamic range.

This modifier works the same as the :doc:`Tone Map Node &lt;/compositing/types/color/tone_map&gt;`.

********************
Proxy/Timecode Panel
********************

Once you have chosen the Proxy/Timecode parameters,
you need to use :menuselection:`Strip --&gt; Rebuild Proxy and Timecode indices`
to generate the proxy clip and it will be available after Blender makes it.

Proxy
=====

.. figure:: /images/editors_sequencer_timecode.png
:align: right

A proxy is a lower resolution version (faster to load) that stands in for the main image or video.
When you Rebuild proxy Blender computes small images (like thumbnails)
for the big images and may take some time. After computing them, though, editing functions
like scrubbing and scrolling and compositing functions like cross using these proxies is much
faster but gives a low-res result. Disable proxies before final rendering.

In order to actually use the proxies, the proper Proxy Render Size selector value must
be selected in the Properties region of the Sequencer View (where the edit plays back).

Proxy Storage
Defines whether the proxies are for individual strips or the entire sequence.

Per Strip
Proxies are stored in the directory of the input.

Proxy Custom Directory
By default, all generated proxy images are storing to the &lt;path of original footage&gt;
/BL_proxy/&lt;clip name&gt; folder, but this location can be set by hand using this option.
Proxy Custom File
Allows you to use pre-existing proxies.

Project
All proxies are stored in one directory.

Proxy Directory
The location to store the proxies for the project.

Proxy Size
Buttons to control how big the proxies are.
The available options are 25%, 50%, 75%, 100 percent of original strip size.
Overwrite
Saves over any existing proxies in the proxy storage directory.
Quality
Defines the quality of the JPEG images used for proxies.
Timecode
See `Timecode`_.
Set Selected Strip Proxies
Same as choosing the *Proxy Size* and *Overwrite*.
Rebuild Proxy and Timecode Indices
Generates Proxies and Timecodes, same as doing :menuselection:`Strip --&gt; Rebuild Proxy and Timecode indices`.

Timecode
========

When you are working with footage directly copied from a camera without pre-processing it,
there might be bunch of artifacts, mostly due to seeking a given frame in sequence.
This happens because such footage usually does not have correct frame rate values in their headers. So,
for Blender to calculate the position of a needed frame in the stream works inaccurately and can give errant result.
There are two possible ways to avoid this:

- Preprocess your video with, say, mencoder to repair file header and insert correct keyframes.
- Use Proxy/Timecode option in Blender.

Options
-------

:term:`Timecode`
Timecode to use on the selected movie strip.

The following timecodes are supported:

- No TC in use- do not use any timecode
- Record Run
- Free Run
- Free Run (rec date)
- Record Run No Gaps

.. note::

Record Run is the timecode which usually is best to use, but if the clip's file is totally damaged,
*Record Run No Gaps* will be the only chance of getting acceptable result.

*********
Selecting
*********

The active sequence strip is displayed with a light outline.
The *entire* strip could be selected by clicking :kbd:`RMB` in the middle of the strip.

The Select Menu helps you select strips in different ways.

Strips to the Left
Select all strips to the left of the currently selected strip.
Strips to the Right
Select all strips to the right of the currently selected strip.
Select Linked Time :kbd:`Ctrl-RMB`
Selects the strip under the cursor as well as all strips with the same start/end.
Select Surrounding Handles :kbd:`Alt-RMB`
Selects the strip under the cursor as well as the handles of neighboring strips.

.. note::

Select with this method
to move a strip that is between to others without affecting the selected strip's length.
Select Both Handles :kbd:`Alt-RMB`
Select the handle under the cursor as well as the handles of the adjacent strip.

.. note::

Select with this method
when you want to change the timing of a cut.
Select Linked :kbd:`L`
Select all strips linked to the currently selected strip.
Select Grouped :kbd:`Shift-G`
Selects strips according to their relation with other strips.

Type
Selects any strips of the same type within a category for example,
if you have a cross strip selected this will select all other effect strips.
Global Type
Selects any strips of the same type, e.g. Effect, Image, Movie, ect.
Effect Type
Selects all effect strips.
Data
Selects strips that share the same data, for example, two image strips sharing the same image file.
Effect
Selects the strip that is shares an effect strip.
Effect/Linked
Selects the effect strips, if any, linked to the currently selected strip.
Overlap
Selects any strips that occur on the same frame as the current.

Select All :kbd:`A`
Selects all the strips loaded.
Select Inverse :kbd:`Ctrl-I`
Inverts the current selection.
Border Select :kbd:`B`
Begins the *Box* mode select process.
Click and drag a rectangular lasso around a region of strips in your Sequence workspace.
When you release the mouse button, the additional strips will be selected.

************
Sound Strips
************

As well as images and movies the VSE can also edit audio tracks.
You can add Waveform Audio format ``WAV``, ``mp3`` and other audio formats files from your drive,
or from sound encoded within a movie, and mix them using an F-Curve as a volume control.

.. figure:: /images/editors_sequencer_audio_editing.png

Example of Sound Editing.

Options
=======

Pack
This allows you to save the audio file into the blend-file.
Caching
Caching loads a file into RAM and plays it from there, apposed to reading it for the hard drive.

.. _sequencer-sound-waveform:

Draw Waveform
Draws either the waveform or the strip name, file name, duration.
This can be useful for syncing two or more audio strips.
Volume
Changes the loudness of the audio.
Pitch
Transposes the frequency of the audio.
Pan
Used to pan the audio from left and right channels -2 being hard left, 2 being hard right.
Trim Duration
Offset the start and end of a sound strip.

Working with Audio Tracks
=========================

An audio track (strip) is just like any other strip in the VSE. You can grab and move it,
adjust its starting offset using :kbd:`RMB` over the arrow end handles,
and :kbd:`K` cut it into pieces.
A useful example is cutting out the "um's" and dead voice time.

You can have as many Audio strips as you wish and the result will be the mixing of all of
them. You can give each strip its own name and volume via the properties region.

Overlapping strips are automatically mixed down during the rendering process. For example,
you can have the announcer on channel 5, background music on channel 6,
and Foley sound effects on channel 7.

.. seealso::

In the :ref:`timeline-playback` menu of the Timeline you will find some options
concerning audio playback behavior.

Animating Audio Track Properties
================================

To animate audio strips simply hit :kbd:`I` over any of its values.
Examples of animating an audio strip are to fade in/out background music or to adjust volume levels.
Layered/crossed audio strips are added together;
the lower channel does not override and cut out higher channels (unlike image and video strips).
This makes Blender an audio mixer.
By adding audio tracks and using the curves to adjust each tracks' sound level,
you have an automated dynamic multi-track audio mixer!

Output
======

There are two ways to render out your audio. You can either have it encoded with a video file
or in its own audio file. To render your audio in an video file make sure to use a video format
as the output with an audio codec and hit the render *Animation* button in the properties editor.
Read more on how to do this :doc:`here &lt;/render/output/video&gt;`. To render as an audio file simple
use the *Audio* button. Read more on how to do this :doc:`here &lt;/render/output/video&gt;`.

Known Limitations
=================

Hiss, Crackle and Pop
---------------------

.. EDITORS NOTE:
This is a common problem and unavoidable see T37432#351492

In some cases when *Caching* is disabled, playback noise/hiss is introduced.

If you hear pops and crackles, usually that is a sign that your hardware cannot keep up in real-time playback.
They will not be present in your final rendered animation output.

Also, static hiss can occur whenever two or more audio strips are overlapping in the timeline.

*****************
Clip &amp; Mask Strip
*****************

Clip
====

Clip can be modified within the :doc:`Movie Clip Editor &lt;/editors/movie_clip_editor/masking/index&gt;`.

Options
-------

This strip has no options.

Mask
====

The Mask strip generates a mask image from the selected mask data-block generated
in the :doc:`Movie Clip Editor &lt;/editors/movie_clip_editor/masking/index&gt;`.
This works similar to the :doc:`Mask Node &lt;/compositing/types/input/mask&gt;`
but without the options available for finer control.
The mask image is always generated at the render resolution,
scaling along with different proxy levels.

Options
-------

Mask
:ref:`Data-block menu &lt;ui-data-block&gt;` to select a mask.

**********
Add Effect
**********

The Add Effect adds the colors of two strips together,
Use this effect with a base image strip, and a modifier strip.
The modifier strip is either a solid color or a black-and-white mask,
or another image entirely.

You can use this effect to increase the brightness of an image, or if you use a BW mask,
selectively increase the brightness of certain areas of the image. The Mix node, in Add mode,
does exactly the same thing as the Add SFX strip here,
and is controlled the same way by feeding the Factor input.

.. Red and Cyan (Green and Blue) make White. Red and Blue make Magenta. Red and Green make Yellow.

Options
=======

This strip has no options.

Example
=======

.. only:: builder_html

.. figure:: /images/editors_sequencer_strips_add-example.gif
:align: right

Can you hear the thunder?

The example to the right shows what happens when you add gray to an image,
and animate the effect over time. The image gets bright because we are adding gray
(R:.5, G:.5, B:.5) to say, a blue color (R.1, G:.1, B:.5) resulting in (R:.6, G:.6, B:1.0)
which retains the original hue (relationship between the colors) but is much brighter
(has a higher value). When applied to the whole image like this,
the whole image seems to flash.

.. only:: latex or epub

The image described above can be found at:
https://docs.blender.org/manual/en/dev/_images/editors_sequencer_strips_add-example.gif

****************
Adjustment Layer
****************

The Adjustment Layer strip works like a regular input file strip except for the fact,
that it considers all strips below it as its input.

Real world use cases, you want to add some last finishing color correction on top of parts of
your final sequence, timeline without messing with meta strips around.
Just add an adjustment layer on top and activate the color balance.

Or you can stack a primary color correction and several secondary color correction on top of
each other (probably using the new mask input for area selection).

Options
=======

This strip has no options.

*****************************
Alpha Over, Under &amp; Over Drop
*****************************

.. figure:: /images/editors_sequencer_strips_alpha.png
:width: 300px

Alpha Over Effect.

Using the alpha (transparency channel), this effect composites a
result based on transparent areas of the dominant image.
If you use a Scene strip, the areas of the image where there is not anything solid are transparent;
they have an alpha value of 0. If you use a movie strip, that movie has an alpha value of 1 (completely opaque).

So, you can use the *Alpha Over* / *Alpha Under* effect to composite the CGI Scene on top of your movie.
The result is your model doing whatever as if it was part of the movie.
The :menuselection:`Edit Strip --&gt; Opacity` controls how much the foreground is mixed over the background,
fading in the foreground on top of the background. The colors of transparent foreground image
areas is ignored and does not change the color of the background.

Select two strips :kbd:`Shift-RMB`:

Alpha Over
==========

With *Alpha Over*, the strips are layered up in the order selected; the first strip selected is the background,
and the second one goes *over* the first one selected.
The *Opacity* controls the transparency of the *foreground*, i.e. *Opacity* of 0.0;
will only show the background, and a *Opacity* of 1.0 will completely override the background with the foreground
(except in the transparent areas of this one, of course!)

Alpha Under
===========

With *Alpha Under*, this is the contrary: the first strip selected is the
foreground, and the second one, the background.
Moreover, the *Opacity* controls the transparency of the *background*, i.e. a *Opacity* of 0.0;
will only show the foreground (the background is completely transparent),
and a *Opacity* of 1.0 will give the same results as with *Alpha Over*.

Alpha Over Drop
===============

*Alpha Over Drop* is between the two others:
as with *Alpha Under*, the first strip selected will be the foreground, but as with *Alpha Over*,
the *Opacity* controls the transparency of this foreground.

.. Todo, update text for new image.

Example
=======

The example shows layering of Alpha Over effects. The very bottom channel is red,
and an arrow is on top of that. Those two are Alpha Over to Channel 3.
My favorite toucan is Channel 4, and Channel 5 alpha over composes the toucan on top of the composited red arrow.
The last effect added is tied to Channel 0 which will be rendered.

..    Comment: Not (more) true, I think!
Alpha Channel Needed for Alpha Over|The foreground strip must have an alpha channel,
such as Scene or a .PNG image sequence, for Alpha Over to work properly; .avi and .mov
files do not have an alpha channel so they can only be used as a background.

By clicking the Premultiply Alpha button in the properties panel of the foreground strip,
the Alpha values of the two strips are not multiplied or added together.
Use this effect when adding a foreground strip that has a variable alpha channel
(some opaque areas, some transparent, some in between) over a strip that has a flat opaque
(Alpha=1.0 or greater) channel. If you notice a glow around your foreground objects,
or strange transparent areas of your foreground object when using Alpha Over,
enable *Premultiply*.

The Alpha Over Drop effect is much like the Cross,
but puts preference to the top or second image,
giving more of a gradual overlay effect than a blend like the Cross does. Of course,
all of the Alpha effects respect the alpha (transparency) channel, whereas Cross does not.

The degree of Alpha applied, and thus color mixing, can be controlled by an F-Curve.
Creating a Sine wave could have the effect of the foreground fading in and out.

*************
Gaussian Blur
*************

The Gaussian Blur strip is used to blur the input strip in a defined direction.
This can be used to blur a background or to blur a transition strip.

Options
=======

Size X
Distance of the blur effect on the X axis.
Size Y
Distance of the blur effect on the Y axis.

Example
=======

For example, in the image below it shows an example of this strip being used to blur a transition.
In this set up the *Gaussian Blur Strip* is modifying a
:doc:`Adjustment Layer Strip &lt;/editors/vse/sequencer/strips/effects/adjustment&gt;`
where the curve defines the amount of blur over the length of the *Adjustment Layer Strip*.

.. figure:: /images/editors_sequencer_strips_blur_example.png

Example of Blurring a Transition.

*****
Color
*****

This effect generates solid color frames.
By default, when it is created, the color strip is 50 frames long, but
you can extend it by grabbing and moving one of the ends.
Use this strip crossed with your main movie to provide a fade-in or fade-out.

Options
=======

Color
Click on the color button in the Effect panel in the Properties region, to pick a different color.

*******************
Cross &amp; Gamma Cross
*******************

.. figure:: /images/editors_sequencer_strips_cross.png

Cross Effect.

This effect fades from one strip to another, based on how many frames the two strips overlap.
This is a very useful strip that blends the whole image from one to the other.

Gamma Cross uses color correction in doing the fade,
resulting in a smooth transition that is easier on the eye.

Options
=======

Default Fade
Todo.

Effect Fader
Todo.

****
Glow
****

This effect makes parts of an image glow brighter by working on
the luminance channel of an image.
The *Glow* is the superposition of the base image and a modified version,
where bright areas are blurred.

To "animate" the glow effect,
mix it with the base image using the Gamma Cross effect,
crossing from the base image to the glowing one.

Options
=======

Threshold
Areas brighter than the *Threshold* are blurred.
Clamp
The maximum luminosity that is added.
Boost Factor
Multiplier of the brightness.
Blur Distance
The size of the blur.
Quality
ToDo.
Only boost
This checkbox allows you to only show/use
the "modified" version of the image, without the base one.

Example
=======

.. figure:: /images/editors_sequencer_strips_glow.png

Example of a Glow effect applied to a picture.

.. _sequencer-effects-index:

#################
Effect Strips
#################

.. toctree::
:maxdepth: 2

introduction.rst
add.rst
adjustment.rst
alpha_over_under_overdrop.rst
blur.rst
color.rst
cross.rst
glow.rst
multicam.rst
multiply.rst
speed_control.rst
subtract.rst
text.rst
transform.rst
wipe.rst

************
Introduction
************

Blender offers a set of effects that can be added to your sequence.
Each effect is explained in the next pages individually, but they all are added and controlled in the same way.

To add an effect strip, select one base strip (image, movie, or scene) by :kbd:`RMB` clicking on it.
For some effects, like the Cross transition effect, you will need to :kbd:`Shift-RMB` a second overlapping strip
(it depends on the effect you want). Then select :menuselection:`Add --&gt; Effect`
and pick the effect you want from the pop-up menu. When you do,
the Effect strip will be shown above the source strips. If it is an independent effect,
like the :doc:`Color Generator &lt;/editors/vse/sequencer/strips/effects/color&gt;`,
it will be placed at the position of the frame indicator.

.. note::

Since most Effects strips depend on one or two source strips,
their frame location and duration depends on their source strips. Thus,
you may not be able to move it; you have to move the source strips in order to affect the effect strip.

To use an effect that combines or makes a transitions select two strips,
When you add the effect strip, it will be placed in a channel above the two.
Its duration will be the overlap between the two strips as a maximum.

With some effects, like the :doc:`Alpha Over &lt;/editors/vse/sequencer/strips/effects/alpha_over_under_overdrop&gt;`,
the order in which you select the strips is important.
You can also use one effect strip as the input or source strip with another strip,
thus layering effects on top of one another.

.. note::

The only exception is the :doc:`Color Generator &lt;/editors/vse/sequencer/strips/effects/color&gt;` effect.
It does not depend on a base strip; you can add and position it independent of any other strip.
Change the length as you would any strip.

If you picked the wrong effect from the menu,
you can always exchange it with :ref:`Change &lt;sequencer-edit-change&gt;` operator.

.. (todo) Common Option: Fade

*****************
Multicam Selector
*****************

The Multicam Selector strip is used for multi camera editing.
Multi camera editing is when a scene is recorded using multiple cameras from different angles
and then edited together after words. This process can be rather easy in the :abbr:`VSE (Video Sequence Editor)`
if you properly setup every to improve your workflow.

Options
=======

Source Channel
The channel which the Multicam Selector gets its input from.
Cut To
Cuts the Multicam strip at the current frame an changes
the *Source Channel* automatically to the selected channels.

Workflow
========

#. First your going to want to add in each of your video strips.
#. Next, you will want to sync all your cameras by either using
:doc:`Audio Waveforms &lt;/editors/vse/sequencer/strips/audio&gt;` or by the movement of objects.

.. tip::

To make syncing strips easier you can group cameras, there audio,
and there effects together using :doc:`Meta Strips &lt;/editors/vse/sequencer/meta&gt;`.

#. Add a viewer region for every input channel and to improve performance use 25% proxies.
#. Add a Multicam Selector strip *above* all the channel tracks.

After completing these steps you should get something similar to the image below:

.. figure:: /images/editors_sequencer_stips_mulitcam.png

Multi camera editing setup.

#. Now select the multicam strip, if you take a look at the strip options (Properties region),
you will notice, that multicam is a rather simple effect strip:
It just takes a selected channel as its input. That is all.
The magic comes with the convenient keyboard layout.
#. When you select the multicam strip, the keys 1-9 are mapped to the cut buttons.
So, select the multicam strip and start playback and press the keys
for the correct input while watching the individual cameras.
#. You will end up with a small multicam selector strip for every cut.

In reality, it boils down to: watch a few seconds to see, what is coming,
watch it again and do a rough cut using the number keys,
do some fine tuning by selecting the outer handles of two neighboring multicam for A/B rolling.

********
Multiply
********

.. figure:: /images/editors_sequencer_strips_multiply.png
:width: 300px

Multiply Effect.

The *Multiply* effect multiplies two colors.
Blender uses values between (0.0 to 1.0) for the colors,
this operation does not have to be normalized, the multiplication of two terms
between (0.0 to 1.0) always gives a result between (0.0 to 1.0).

(with the "traditional" representation of three bytes, like RGB(124, 255, 56) ,
the multiplications give far too high results, like RGB(7316, 46410, 1848),
that have to be, normalized (brought back) by dividing them by 256
to fit in the range of (0 to 255) ...).

This effect has two main usages:

.. rubric:: With a Mask

A mask is a black and white picture which, after multiplication with a "normal" image,
only show this one in the white areas of the mask (everything else is black).

The opening title sequence to James Bond movies,
where the camera is looking down the barrel of a gun at James, is a good example of this effect.

.. rubric:: With Uniform Colors

Multiplying a color with a "normal" image allows you to soften some hues of this one
(and so -- symmetrically -- to enhance the others).

For example, if you have a brown pixel RGB(0.50, 0.29, 0.05), and
you multiply it with a cyan filter (uniform color RGB(0.0, 1.0, 1.0), you will get a color RGB(0.0, 0.29, 0.5).
Visually, the result is to kill the reds and bring up (by "symmetry" -- the real values remain unchanged!)
the blues an greens. Physically, it is the same effect as shining a cyan light onto a chocolate bar. Emotionally,
vegetation becomes more lush, water becomes more Caribbean and inviting, skies become friendlier.

.. note::

This effect reduces the global luminosity of the picture
(the result will always be smaller than the smallest operand).
If one of the image is all white, the result is the other picture;
if one of the image is all black, the result is all black!

Options
=======

This strip has no options.

*************
Speed Control
*************

Speed Control time-warps the strip, making it play faster or slower than it normally would.
A *Global Speed* less than 1.0 makes the strip play slower; greater than 1.
0 makes it play faster. Playing faster means that some frames are skipped,
and the strip will run out of frames before the end frame.
When the strip runs out of frames to display, it will just keep repeating the last one;
action will appear to freeze. To avoid this,
position the next strip under the original at a point where you want motion to continue.

Options
=======

Todo.

.. (wip)
Stretch to Input Strip Length
Will match the length of the Speed Control strip with the length of the Input strip.
Use as Speed
Speed Factor
Todo.
Scale to Length
Todo.
Multiply Speed
Todo.

Examples
========

Creating a Slow-Motion Effect
-----------------------------

.. figure:: /images/editors_sequencer_strips_speed-control.jpg
:width: 300px

50% Slow motion using Speed Control.

Suppose you want to slow your strip down.
You need to affect the speed of the video clip without affecting the overall frame rate.
Select the clip and :menuselection:`Add --&gt; Effect --&gt; Speed Control` effect strip.
Click to drop it and press :kbd:`N` to get the Properties.
Uncheck the *Stretch to input strip length* option in the Effect Strip section.
Set the Speed factor to be the factor by which you want to adjust the speed.
To cut the displayed speed by 50%, enter 0.5.
Now, a 275-frame clip will play at half speed, and thus display only the first 137 frames.

If you want the remaining frames to show in slow-motion after the first set is displayed,
double the Length of the source strip
(since effects strip bounds are controlled by their source strips).
If you are using a speed factor other than 0.5 then use the formula:

``new_length = real_length / speed_factor``

That is it, set your render to animate (in this example) all 550 frames.

Keyframing the Speed Control
----------------------------

.. figure:: /images/editors_sequencer_strips_types_effects_speed-control_keyframing.png
:align: right

Keyframing the Frame number.

To get even finer control over your clip timing, you can use curves!
While it is possible to keyframe the Speed factor,
usually you want to keyframe the Frame number directly.

Uncheck *Stretch to input strip length* and uncheck *Use as speed*.
You now have a Frame number button which you can keyframe.
If you want the strip to animate **at all** you will have to insert some keyframes,
otherwise it will look like a still. In most cases you will want to use the Graph editor view
to set the curve interpolation to Linear since the default Bézier will rarely be what you
want.

If you do choose to keyframe the Speed factor instead, remember to click the Refresh Sequencer
button in the header of the Video Sequence Editor's strip view or your changes will not take
effect.

Changing Video Frame Rates
--------------------------

You can use the speed control to change the frames per second (fps), or framerate, of a video.
If you are rendering your video to a sequence set,
you can effectively increase or decrease the number of individual image files created,
by using a Global Speed value less than or greater than one, respectively. For example,
if you captured a five-minute video at 30 fps and wanted to transfer that to film,
which runs at 24 fps, you would enter a Global Speed of 30/24, or 1.25
(and Enable Frame Blending to give that film blur feel).
Instead of producing ``5 × 60 × 30 = 9000`` frames,
Blender would produce ``9000/ 1.25 = 7200 = 5 × 60 × 24`` frames.
In this case, you set a *start* = 1 and *end* = 7200, set your Format output to ``jpeg`` 30fps,
and image files ``0001.jpg`` through ``7200.jpg`` would be rendered out,
but those images cover the entire 9000 frames. The image file ``7200.jpg`` is the same a frame 9000.
When you read those images back into your film blend-file at 24 fps, the strip will last exactly 5 minutes.

***************
Subtract Effect
***************

.. figure:: /images/editors_sequencer_strips_subtract.png

Subtract Effect.

This effect takes away one strip's color from the second.

Make a negative of an image using this effect,
or switch the order of the strips and just darken the strip.
Subtracting a hue of blue from a white image will make it yellow,
since red and green make yellow.

Options
=======

This strip has no options.

***********
Text Effect
***********

The text effect strip allows you to directly displaying text in the sequence editor.
The strip will display the text inserted in its text field on the final sequence.

.. figure:: /images/editors_sequencer_strips_text.png

Text Effect.

Options
=======

Text
The actual text displayed.
Size
Size of the text.
Color
The text color.
Shadow
Creates a shadow under the text.
Align X, Y
Horizontal (X) or vertical (Y) alignment of the text relative to the location.
Location X, Y
Positions the text on the X, Y axis.
Wrap Width
Todo,
Export Subtitles
Exporting subtitles in .srt format is also supported.
The exported subtitles contain all text strips in the sequence editing.

*********
Transform
*********

.. figure:: /images/editors_sequencer_strips_transform.png
:align: right

Transform is a swiss-army knife of image manipulation.
It translate (shifts), rotate, and scales the images within a strip.

Options
=======

Interpolation
None
No interpolation, uses nearest neighboring pixel.
Bilinear
Simple interpolation between adjacent pixels.
Bicubic
Highest quality interpolation.
Translation Unit
Control whether the input values are in *Percent* or *Pixels*.
Position
Moves the input along the X and Y axis.
Uniform Scale
Scale the input evenly along the X and Y axis.
Scale
Scale the image on the X and Y axis.
Rotation
Rotates the input two-dimensionally along the Z axis.

****
Wipe
****

.. figure:: /images/editors_sequencer_strips_wipe.png
:align: right

Wipe Effect Settings.

The wipe effect is a type of transition strip. It can be used to transition from one strip to the next.
The wipe will have no effect if created from a single strip instead of two strips.
The duration of the wipe is the intersection of the two source strips and cannot be adjusted.
To adjust the start and end of the wipe you must adjust the temporal bounds of the source strips
in a way that alters their intersection.

Options
=======

Transition
The type of transition used.

Single
Reveals the next strip by uncovering it in a straight line moving across the image.
Double
Similar to *Single*, but uses two lines either starting from the middle of the image or the outside.
Like the blink of an eye.
Iris
Reveals the next strip through an expanding (or contracting) circle.
Like the aperture of a camera or pupil of an eye.
You can blur the transition, so it looks like ink bleeding through a paper.
Clock
Like the hands of an analog clock, it sweeps clockwise or (if Wipe In is enabled)
counterclockwise from the 9:00 position. As it sweeps, it reveals the next strip.

Direction
Control whether to fade *In* or *Out*.
Blur Width
The width of the blur used to blur the transition.
Angle
Control the angle of the line for *Single* and *Double* transition types.

********************
Movie &amp; Image Strips
********************

Movie
=====

To add a movie (with or without audio) select a movie file(s) in the File Browser
e.g. in the Audio-Video Interleaved format (``*.avi`` file).

.. note:: Clips can be Huge

A three minute quicktime ``.mov`` file can be 140Megs.
Loading it, even over a high-speed LAN can take some time.
Do not assume your computer or Blender has locked up if nothing happens for awhile.

Image
=====

Single Image
------------

When you add a single still image (``*.jpg``, ``*.png``, etc.),
Blender creates a 25 frames long strip which will show this image along the strips range.

Image Sequence
--------------

In the case of (numbered) image sequences
(e.g. ``*-0001.jpg``, ``*-0002.jpg``, ``*-0003.jpg``, etc, of any image format), you have a choice:

Range
Navigate into the directory and :kbd:`RMB` click and drag over a range of names to highlight multiple files.
You can page down and continue :kbd:`RMB` click-dragging to add more to the selection.
Batch
:kbd:`Shift-RMB` click selected non-related stills for batch processing; each image will be one frame,
in sort order, and can be a mix of file types (``jpg``, ``png``, ``exr,`` etc.).
All
Press :kbd:`A` to select/deselect all files in the directory.

.. tip:: Dealing with Different Sizes

Dealing with different sized images and different sized outputs is tricky.
If you have a mis-match between the size of the input image and the render output size,
the VSE will try to auto-scale the image to fit it entirely in the output.
This may result in clipping. If you do not want that, use *Crop* and/or *Offset* in the Input
panel to move and select a region of the image within the output. When you use *Crop* or *Offset*,
the auto-scaling will be disabled and you can manually re-scale by adding the Transform effect.

Add Image Strip
---------------

Placeholder Images
^^^^^^^^^^^^^^^^^^

Image sequences can use placeholder files. This works by enabling *Use placeholders* checkbox
when adding an image strip. The option detects the frame range of opened images using
blender's frame naming scheme (filename + frame number + .extension) and makes an image sequence with
all files in between even if they are missing.
This allows you to render an image sequence with a few frames missing and
still the image strip will have the correct range to account for the missing frames displayed as black.
When the missing frames are rendered or placed in the same folder, you can refresh the sequencer and
get the missing frames in the strip. The option is also available when using the *Change Data/File* operator and
allows you to add more images to the range.

Example
=======

.. figure:: /images/editors_sequencer_example.png

If you scroll up the workspace, you will see an information channel
(at vertical location channel 0) that gives you some helpful hints about the active strip.
The example above shows a color strip from frames 1 to 25, then a ``mov`` file,
and then an image strip. The info channel shows handy information about the image strip,
whose name has been scrunched in the strip display,
but is clearly spelled out in the information strip.

##########
Strips
##########

.. toctree::
:maxdepth: 1

introduction.rst

Types
=====

.. toctree::
:maxdepth: 2

scene.rst
clip_mask.rst
image_movie.rst
audio.rst
effects/index.rst

************
Introduction
************

.. figure:: /images/editors_sequencer_strips_introduction_strip-graphic.svg

Strip schematic.

A strip is a container which carries frames provided by one or more sources (input).
It is defined by a *Start Frame* and a *Length*, and is displayed as a colored horizontal rectangle.

Add
===

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Add`
| Hotkey:   :kbd:`Shift-A`

.. figure:: /images/editors_sequencer_strips_introduction_add-menu.png
:align: right

The Add Menu.

The Add menu is the main menu you will be using to add content to the VSE.
In general, you load up your strips, create strips of special transition effects,
and then animate out your sequence by selecting "Do Sequence" and clicking the *Animation* button.
You can use the Add menu in the header,
or hover your mouse cursor over the Sequence workspace and press :kbd:`Shift-A`.

Blender does not care which of these you use; you can freely mix and match any of them.
When you choose to add one of these, it lets you either choose a data-block or
the VSE editor will switch to a File Browser for you to select what you want to add.
Supported files are filtered by default.

The start frame of the newly created strips will be placed at the position of the frame indicator.
When loading multiple files (movie and sound) at the same time each will be add one after the other.

Visualization
=============

They all become a color-coded strip in the VSE:

- Scene strip: Light green.
- Clip strip: Dark blue.
- Mask strip: Red.
- Movie strip: Aquamarine.
- Image strip: Purple.
- Sound strip: Turquoise.

Each of the effect strips has its own color.

***********
Scene Strip
***********

Scene strips are a way to insert the render output of a scene into your sequence.
Instead of rendering out a video, then inserting the video file, you can insert the scene directly.

The strip length will be determined based on the animation settings in that scene.

Options
=======

Use Sequence
Expand the scenes sequence strips, allowing one scene to re-use another scenes edit,
(instead of taking the render output from the scene).

This is similar to how :doc:`Meta Strips &lt;/editors/vse/sequencer/meta&gt;` work,
with the added advantage of supporting multiple instances of the same data.
Camera Override
This can be used to override the scenes camera with any other object.

It is useful to support switching views within a single scene.
Show Grease Pencil
Shows :doc:`Grease Pencil &lt;/interface/grease_pencil/index&gt;` in OpenGL preview.
Audio Volume
Volume of the audio taken from the chosen scene.
Alpha Mode
Sky
Fills in a solid background.
Transparent
Creates a transparent background.
This is useful for doing overlays like rendering out Grease Pencil films via the Sequencer.

.. hint::

Its best not add a scene strip for the scene you are currently editing.
While this is supported, it can be confusing when changing the start and end frame.

*****************
Standalone Player
*****************

The standalone player allows a Blender game to be run without having to load the Blender
system. This allows games to be distributed to other users,
without requiring them a detailed knowledge of Blender
(and also without the possibility of unauthorized modification). Note that the Game Engine
Save as Runtime is an add-on facility which must be pre-loaded before use.

The following procedure will give a standalone version of a working game.

#. :menuselection:`File --&gt; User Preferences --&gt; Add-ons --&gt; Game Engine --&gt; Save As Game Engine Runtime`
enable the checkbox. (You can also *Save User Settings*,
in which case the add-on will always be present whenever Blender is re-loaded).
#. :menuselection:`File --&gt; Export --&gt; Save As Game Engine Runtime`
(give appropriate directory/filename) confirm with *Save as Game Engine Runtime*.

The game can then be executed by running the appropriate ``.exe`` file.
Note that all appropriate libraries are automatically loaded by the add-on.

If you are interested in licensing your game,
read `Licensing &lt;https://www.blender.org/about/license/&gt;`__
for a discussion of the issues involved.

.. tip:: Exporting...

If the game is to be exported to other computers,
make a new empty directory for the game runtime and all its ancillary libraries etc.
Then make sure the **whole** directory is transferred to the target computer

***********
Dome Camera
***********

This feature allows artists to visualize their interactive projects within an immersive dome
environment. In order to make it an extensible tool, we are supporting Fulldome,
Truncated domes (front and rear), Planetariums and domes with spherical mirrors.

.. tip::

The Dome camera uses a multipass texture algorithm as developed by Paul Bourke and was
implemented by Dalai Felinto with sponsorship from SAT -- Society for Arts and
Technology within the SAT Metalab
`immersion research program &lt;http://paulbourke.net/miscellaneous/domemirror/BlenderiDome/&gt;`__,
that involves rendering the scene four times and placing the subsequent images
onto a mesh designed especially such that the result, when viewed with an
orthographic camera, is a fisheye projection.

.. note::

Remember to use Blender in 'fullscreen mode' to get the maximum out of your projector.

To accomplish that launch Blender with the command-line argument ``-W``.
Also to get away of the top menu on Blender try to join all areas
(buttons, 3D View, text,...) in a single one. Otherwise if you only maximize it :kbd:`Ctrl-Up`)
you cannot get the whole screen free to run your game
(the top bar menu takes about 20 pixels).

Dome Camera Settings
====================

.. figure:: /images/game-engine_camera_dome.png

Dome Type
This menu allows you to select which type of dome camera to use.
They are outlined below, along with their respective settings.

- `Fisheye Mode`_
- `Front-Truncated Dome Mode`_
- `Rear-Truncated Dome Mode`_
- `Cube Map Mode`_
- `Spherical Panoramic Mode`_

Available camera settings change depending on the selected Dome Type:

Resolution
Sets the resolution of the Buffer. Decreasing this value increases speed, but decreases quality.
Tessellation
4 is the default. This is the tessellation level of the mesh. (Not available in Cube Map mode).
Angle
Sets the field of view of the dome in degrees, from 90 to 250. (Available in Fisheye and Truncated modes).
Tilt
Set the camera rotation in the horizontal axis. Available in Fisheye and Truncated modes).

`Warp Data Mesh`_
Use a custom warp mesh data file.

Fisheye Mode
------------

An Orthogonal Fisheye view from 90º to 250º degrees.

- From 90º to 180º we are using four renders.
- From 181º to 250º we are using five renders.

.. figure:: /images/bge_dome-fisheye.jpg

Fisheye Mode.

Front-Truncated Dome Mode
-------------------------

Designed for truncated domes,
this mode aligns the fisheye image with the top of the window, while touching the sides.

- The Field of view goes from 90º to 250º degrees.
- From 90º to 180º we are using four renders.
- From 181º to 250º we are using five renders.

.. figure:: /images/bge_dome-front-truncated.jpg

Front Truncated Dome Mode.

Rear-Truncated Dome Mode
------------------------

Designed for truncated domes,
this mode aligns the fisheye image with the bottom of the window, while touching the sides.

- The Field of view goes from 90º to 250º degrees.
- From 90º to 180º we are using four renders.
- From 181º to 250º we are using five renders.

.. figure:: /images/bge_dome-rear-truncated.jpg

Rear Truncated Dome Mode.

Cube Map Mode
-------------

Cube Map mode can be used for pre-generate animated images for CubeMaps.

- We are using six renders for that. The order of the images follows Blender internal EnvMap file format:
- first line: right, back, left
- second line: bottom, top, front

.. figure:: /images/bge_dome-envmap.jpg

Environment Map Mode.

Spherical Panoramic Mode
------------------------

A full spherical panoramic mode.

- We are using six cameras here.
- The bottom and top start to get precision with *Definition* set to 5 or more.

.. figure:: /images/bge_dome-panoramic.jpg

Full Spherical Panoramic Mode.

Warp Data Mesh
--------------

Many projection environments require images that are not simple perspective projections that
are the norm for flat screen displays. Examples include geometry correction for cylindrical
displays and some new methods of projecting into planetarium domes or upright domes intended
for VR.

For more information on the mesh format see `Paul Bourke's article &lt;http://paulbourke.net/dataformats/meshwarp/&gt;`__.

.. figure:: /images/bge_dome-warped.jpg

In order to produce that images, we are using a specific file format.

File template:

.. code-block:: none

mode
width height
n0_x n0_y n0_u n0_v n0_i
n1_x n1_y n1_u n1_v n1_i
n2_x n1_y n2_u n2_v n2_i
n3_x n3_y n3_u n3_v n3_i
(...)

First line is the image type the mesh is support to be applied to:
``2 = rectangular``, ``1 = radial`` Next line has the mesh dimensions in
pixelsRest of the lines are the nodes of the mesh.

Each line is compound of *x*, *y*, *u*, *v*, *i* (x, y)
are the normalized screen coordinates (u, v)
texture coordinates *i* a multiplicative intensity factor.

*x* varies from -screen aspect to screen aspect varies from -1 to 1 *u* and *v* vary from 0 to 1.
*i* ranges from 0 to 1, if negative do not draw that mesh node.

#. You need to create the file and add it to the Text Editor in order to select it as your Warp Mesh data file.
#. Open the Text Editor :menuselection:`Editor Types --&gt; Text Editor`.
#. Open your mesh data file (e.g. myDome.data) in the text editor (:menuselection:`Text --&gt; Open` or :kbd:`Alt-O`).
#. Go to Game Framing Settings :menuselection:`Editor Types --&gt; Properties editor --&gt; Scene`.
#. Enable Dome Mode.
#. Type filename in Warp Data field (e.g. myDome.data).

To create your own Warp Meshes an interactive tool called meshmapper is available as part of
`Paul Bourke's Warpplayer &lt;http://paulbourke.net/miscellaneous/domemirror/warpplayer/&gt;`__
software package (requires full version).

Examples
========

- `Spherical Mirror Dome 4×3 &lt;https://wiki.blender.org/uploads/8/81/Dev-GameEngine-Dome-Standard_4x3.data&gt;`__
- `Truncated Dome 4×3 &lt;https://wiki.blender.org/uploads/9/9b/Dev-GameEngine-Dome-Truncated_4x3.data&gt;`__
- `Sample Fullscreen File 4×3 &lt;https://wiki.blender.org/uploads/d/d4/Dev-GameEngine-Dome-Sample-FullScreen_4x3.data&gt;`__
- `Sample Fullbuffer File 4×3 &lt;https://wiki.blender.org/uploads/3/3d/Dev-GameEngine-Dome-Sample-FullBuffer_4x3.data&gt;`__

.. important::

The viewport is calculated using the ratio of canvas width by canvas height.
Therefore different screen sizes will require different warp mesh files. Also in order to get
the correct ratio of your projector you need to use Blender in Fullscreen mode.
.. _game-engine-camera-index:

##########
Camera
##########

.. toctree::
:maxdepth: 2

introduction.rst
stereo.rst
dome.rst

************
Introduction
************

The Game Engine camera is in many ways similar to the Camera in the normal Blender Render system,
and is created, parameterized and manipulated in similar ways.
However, because of its use as a real-time device, the Game Engine camera has a number of
additional features -- it may be used as not only as a static camera,
but also as a moving device with its default characteristics (i.e. with its own programmed moves),
or it may track another object in the game. Furthermore, any game object may be used as a camera;
the view is taken from the object's origin point.
Lastly, it may be given special capabilities such as Stereo vision,
Dome visualization, etc... which have special relevance to game technology.

When you start the Game Engine, the initial camera view is taken from the latest 3D View.
This may be either a selected camera object or the default camera (see below).
Thus to start the game with a particular camera,
you must select the camera and press :kbd:`Numpad0` before starting the Game Engine.

.. tip:: To avoid camera distortion

Always zoom the view in until the camera object fills the entire viewport.

Default Camera
==============

The default camera view is taken from the latest 3D View view,
at a distance equivalent to the viewer. This means that if the normal 3D View is active the
scene does not change when the Game Engine is started.

Camera Object
=============

The Camera object in the Game Engine follows much the same structure as the conventional Blender camera -- see
:doc:`Camera &lt;/render/blender_render/camera/index&gt;` for details of how to set up, manipulate and select a camera.
The following sections show some of the special facilities available in BGE cameras.

Parent Camera to Object
=======================

The camera will follow the object. First select the camera and then select the object.
Next :kbd:`Ctrl-P` :menuselection:`--&gt; Make Parent`.

Note that if your object has any rotations then the camera will also have those rotations.
To avoid this use `Parent to Vertex`_.

Parent to Vertex
================

The easiest way to accomplish this is to select your object and :kbd:`Tab` to *Edit Mode*.
Now select the vertex and :kbd:`Tab` back to *Object Mode*.

Next, without any objects selected, select the camera and, holding :kbd:`Shift`,
select the object. :kbd:`Tab` into *Edit Mode*, and :kbd:`Ctrl-P` and choose *Make vertex parent*.

Now the camera will follow the object and it will maintain its rotation, while the object rotates.

*************
Stereo Camera
*************

Stereo Cameras allow you to generate images that appear three dimensional when wearing special glasses.
This is achieved by rendering two separate images from cameras that are a small distance apart from each other,
simulating how our own eyes see. When viewing a stereo image, one eye is limited to seeing one of the images,
and the other eye sees the second image. Our brain is able to merge these together,
making it appear that we are looking at a 3D object rather than a flat image.
See `Stereoscopy &lt;https://en.wikipedia.org/wiki/Stereoscopy&gt;`__
for more information on different stereoscopic viewing methods.

Stereo Settings
===============

.. figure:: /images/game-engine_camera_stereo.png

Sterea Settings.

Stereo Mode
Specifies the way in which the left-eye image and the right-eye image pixels are put together
during rendering. This must be selected according to the type of apparatus available to
display the appropriate images to the viewer's eyes.

Anaglyph
One frame is displayed with both images color encoded with red-blue filters. This mode only requires
`glasses with color filters &lt;https://en.wikipedia.org/wiki/Stereoscopy#Color_anaglyph_systems&gt;`__,
there are no special requirements for the display screen and GPU.
Quad Buffer
Uses double buffering with a buffer for each eye, totaling four buffers
(Left Front, Left Back, Right Front and Right Back), allowing to swap the buffers for both eyes in sync.
See `Quad Buffering &lt;https://en.wikipedia.org/wiki/Quad_buffering&gt;`__ for more information.
Side by Side
Lines are displayed one after the other, so providing the two images in two frames side by side.
Above-Below
Frames are displayed one after the other, so providing the two images in two frames, one above the other.
Interlaced
One frame is displayed with the two images on alternate lines of the display.
Vinterlaced
One frame is displayed with both images displayed on alternate columns of the display.
This works with some 'autostereo displays'.
3D Tv Top-Bottom
One frame displays the left image above and the right image below.
The images are squashed vertically to fit. This mode is designed for passive 3D TV.

Eye Separation
This value is extremely important. It determines how far apart the two image-capturing cameras are,
and thus how "deep" the scene appears. Too small a value and the image appears flat; too high a value
can result in headaches and eye strain. The ideal value mimics the separation of the viewer's two eyes.
.. _game-engine-index:

##############
Game Engine
##############

.. toctree::
:maxdepth: 2

introduction.rst
screen_layout.rst
settings/index.rst
materials.rst
world.rst
logic/index.rst
camera/index.rst
physics/index.rst
performance.rst
python_api/index.rst
blender_player.rst
licensing.rst

************
Introduction
************

The Blender Game Engine (BGE) is Blender's tool for real time projects,
from architectural visualizations and simulations to games.

A word of warning,
before you start any big or serious project with the Blender Game Engine,
you should note that it is currently not very supported and that there are plans
for its retargeting and refactoring that, in the very least, will break compatibility.
For further information, you should get in touch with the developers via mailing list or IRC and read the
`development roadmap &lt;https://code.blender.org/2013/06/blender-roadmap-2-7-2-8-and-beyond/&gt;`__.

Use Cases and Sample Games
==========================

Blender has its own built in Game Engine that allows you to create interactive 3D applications
or simulations. The major difference between Game Engine and the conventional Blender system
is in the rendering process. In the normal Blender engine,
images and animations are built off-line -- once rendered they cannot be modified.
Conversely, the Blender Game Engine renders scenes continuously in real-time,
and incorporates facilities for user interaction during the rendering process.

.. figure:: /images/bge_introduction_screenshot.jpg

Screenshot from "Yo Frankie", produced with Blender Game Engine.

The Blender Game Engine oversees a game loop, which processes logic, sound,
physics and rendering simulations in sequential order. The engine is written in C++.

By default, the user has access to a powerful, high level, Event Driven
:doc:`Logic Editor &lt;/editors/logic_editor&gt;`
which is comprised of a series of specialized components called "Logic Bricks".
The :doc:`Logic Editor &lt;/editors/logic_editor&gt;` provides deep interaction with the simulation,
and its functionality can be extended through Python scripting.
It is designed to abstract the complex engine features into a simple user interface,
which does not require experience with Programming.
An overview of the :doc:`Logic Editor &lt;/editors/logic_editor&gt;`
can be found in the :doc:`Game Logic Screen Layout &lt;/game_engine/screen_layout&gt;`

The Game Engine is closely integrated with the existing code base of Blender, which permits
quick transitions between the traditional modeling feature set and game-specific functionality
provided by the program. In this sense,
the Game Engine can be efficiently used in all areas of game design,
from prototyping to final release.

The Game Engine can simulate content within Blender,
however, it also includes the ability to export a binary run-time to Linux, macOS, and MS-Windows.

There are a number of powerful libraries the Game Engine takes advantage of:

- Audaspace: A sound library for control of audio. Uses OpenAL or SDL.
- Bullet: A physics engine featuring 3D collision detection, soft body dynamics, and rigid body dynamics.
- Detour: A path-finding and spatial reasoning toolkit.
- Recast: A state of the art navigation mesh construction tool set for games.

When creating a game or simulation in the BGE, there are four essential steps:

- Create visual elements that can be rendered. This could be 3D models or images.
- Enable interaction within the scene using logic bricks to script custom behavior and determine how it is invoked
(using the appropriate "sensors" such as keyboards or joysticks).
- Create one (or more) camera to give a frustum from which to render the scene,
and modify the parameters to support the environment in which the game will be displayed, such as Stereo rendering.
- Launch the game, using the internal player or exporting a runtime to the appropriate platform.

**************************
Licensing of Blender Games
**************************

Blender and the Blender Game Engine (BGE) are licensed as GNU GPL, which means that your games
(if they include Blender software)
have to comply with that license as well.
This only applies to the software, or the bundle if it has software
in it, not to the artwork you make with Blender. All your Blender creations are your sole property.

GNU GPL -- also called "Free Software" -- is a license that aims at keeping the licensed software free, forever.
GNU GPL does not allow you to add new restrictions or limitations on the software you received under that license.
That works fine if you want your clients or your audience to have the same rights as you have (with Blender).

In summary, the software and source-code are bound to the GNU GPL, but the blend-files
(models, textures, sounds) are not.

Standalone Games
================

In case you save out your game as a single "Standalone" the blend-file gets included in the binary (the BGE player).
That requires the blend-file to be compatible with the GNU GPL license.

In this case, you could decide to load and run another blend-file game (using the Game Actuator logic brick).
That file then is not part of the binary, so you can apply any license you wish on it.

More Information
================

More information you can find in the `blender.org FAQ &lt;https://www.blender.org/support/faq/&gt;`__.

***********************
Actuator Common Options
***********************

.. figure:: /images/bge_actuator_column3.png
:width: 292px

Common Actuator Options.

All actuators have a set of common buttons, fields and menus. They are organized as follows:

Triangle button
Collapses the sensor information to a single line (toggle).
Actuator type menu
Specifies the type of the sensor.
Actuator name
The name of the actuator. This can be selected by the user.
It is used to access actuators with Python; it needs to be unique among the selected objects.
``X`` *Button*
Deletes the actuator.

****************
Actuator Editing
****************

.. figure:: /images/bge_actuator_column.png
:width: 292px

Actuator Column with Typical Actuator.

Blender actuators can be set up and edited in the right-hand column of the Logic Panel.
This page describes the general column controls,
and also those parameters which are common to all individual actuator types.

The image shows a typical actuator column with a single example actuator.
At the top of this column, the column heading includes menus and buttons to control which of
all the actuators in the current Game Logic are displayed.

Column Heading
==============

.. figure:: /images/bge_actuator_column1.png
:width: 292px

Actuator Column Heading.

The column headings contain controls to set which actuators, and the level of detail given,
in the actuator column. This is very useful for hiding unecessary actuators so that the
necessary ones are visible and easier to reach. Both these can be controlled individually.

.. rubric:: Actuators

Show Objects
Expands all objects.
Hide Objects
Collapses all objects to just a bar with their name.
Show Actuators
Expands all actuators.
Hide Actuators
Collapses all actuators to bars with their names.

It is also possible to filter which actuators are viewed using the four heading buttons:

Sel
Shows all actuators for selected objects.
Act
Shows only actuators belonging to the active object.
Link
Shows actuators which have a link to a controller.
State
Only actuators connected to a controller with active states are shown.

Object Heading
==============

.. figure:: /images/bge_actuator_column2.png
:width: 292px

Actuator Object Heading.

In the column list, actuators are grouped by object. By default,
actuators for every selected object appear in the list,
but this may be modified by the column heading filters.

At the head of each displayed object sensor list, two entries appear:

Name
The name of the object.
Add
When clicked, a menu appears with the available actuator types.
Selecting an entry adds a new actuator to the object.
See :doc:`Actuators &lt;/game_engine/logic/actuators/index&gt;` for list of available actuator types.
.. _actuators-index:

############
Actuators
############

.. toctree::
:maxdepth: 2

introduction.rst
editing.rst
common_options.rst

Actuators Types
===============

.. toctree::
:maxdepth: 1

types/action.rst
types/camera.rst
types/constraint.rst
types/edit_object.rst
types/2d_filters.rst
types/game.rst
types/message.rst
types/mouse.rst
types/motion.rst
types/parent.rst
types/property.rst
types/random.rst
types/scene.rst
types/steering.rst
types/sound.rst
types/state.rst
types/visibility.rst

************
Introduction
************

Actuators perform actions, such as move, create objects, play a sound.
The actuators initiate their functions when they get a positive pulse from one (or more)
of their controllers.

The logic blocks for all types of actuator may be constructed and changed using the
:doc:`Logic Editor &lt;/editors/logic_editor&gt;`; details of this process are given in the
:doc:`Actuator Editing &lt;/game_engine/logic/actuators/editing&gt;` page.

The following types of actuator are currently available:

:doc:`Action &lt;/game_engine/logic/actuators/types/action&gt;`
Handles armature actions. This is only visible if an armature is selected.
:doc:`Camera &lt;/game_engine/logic/actuators/types/camera&gt;`
Has options to follow objects smoothly, primarily for camera objects, but any object can use this.
:doc:`Constraint &lt;/game_engine/logic/actuators/types/constraint&gt;`
Constraints are used to limit object's locations, distance, or rotation.
These are useful for controlling the physics of the object in game.
:doc:`Edit Object &lt;/game_engine/logic/actuators/types/edit_object&gt;`
Edits the object's mesh, adds objects, or destroys them.
It can also change the mesh of an object (and soon also recreate the collision mesh).
:doc:`Filter 2D &lt;/game_engine/logic/actuators/types/2d_filters&gt;`
Filters for special effects like sepia colors or blur.
:doc:`Game &lt;/game_engine/logic/actuators/types/game&gt;`
Handles the entire game and can do things as restart, quit, load, and save.
:doc:`Message &lt;/game_engine/logic/actuators/types/message&gt;`
Sends messages, which can be received by other objects to activate them.
:doc:`Motion &lt;/game_engine/logic/actuators/types/motion&gt;`
Sets object into motion and/or rotation.
There are different options, from "teleporting" to physically push rotate objects.
:doc:`Parent &lt;/game_engine/logic/actuators/types/parent&gt;`
Can set a parent to the object, or unparent it.
:doc:`Property &lt;/game_engine/logic/actuators/types/property&gt;`
Manipulates the object's properties, like assigning, adding, or copying.
:doc:`Random &lt;/game_engine/logic/actuators/types/random&gt;`
Creates random values which can be stored in properties.
:doc:`Scene &lt;/game_engine/logic/actuators/types/scene&gt;`
Manage the scenes in your blend-file. These can be used as levels or for UI and background.
:doc:`Sound &lt;/game_engine/logic/actuators/types/sound&gt;`
Used to play sounds in the game.
:doc:`State &lt;/game_engine/logic/actuators/types/state&gt;`
Changes states of the object.
:doc:`Steering &lt;/game_engine/logic/actuators/types/steering&gt;`
Provides pathfinding options for the object.
:doc:`Visibility &lt;/game_engine/logic/actuators/types/visibility&gt;`
Changes visibility of the object.

******************
Filter 2D Actuator
******************

*2D Filter* s are image filtering actuators, that apply on final render of objects.

.. figure:: /images/bge_actuator_filter_2d.png
:width: 271px

Edit Object actuator.

.. rubric:: Filter 2D Type

Select the type of 2D Filter required.

- Custom Filter
- Invert
- Sepia
- Gray Scale
- Prewitt
- Sobel
- Laplacian
- Erosion
- Dilation
- Sharpen
- Blur
- Motion Blur
- Remove Filter
- Disable Filter
- Enable Filter

Only one parameter is required for all filters:

Pass Number
The pass number for which this filter is to be used.

Details of the filters are given in the descriptive text below.

Motion Blur
===========

*Motion Blur* is a *2D Filter* that needs previous rendering information to produce motion effect on objects.
Below you can see *Motion Blur* filter in Blender window, along with its logic bricks:

.. figure:: /images/bge_motionblur_render-full.jpg

2D Filters: Motion Blur.

You can enable Motion Blur filter using a *Python* controller::

from bge import render
render.enableMotionBlur(0.85)

And disable it::

from bge import render
render.disableMotionBlur()

.. note::

Your graphic hardware and OpenGL driver must support accumulation buffer (``glAccum`` function).

Built-In 2D Filters
===================

All 2D filters you can see in *2D Filter* actuator have the same architecture,
all built-in filters use fragment shader to produce final render view,
so your hardware must support shaders.

.. figure:: /images/bge_motionblur_render-full.jpg
:width: 200px

2D Filters: Motion Blur.

.. figure:: /images/sepia_render-full.jpg
:width: 200px

2D Filters: Sepia.

.. figure:: /images/bge_sobel_render-full.jpg
:width: 200px

2D Filters: Sobel.

Blur, Sharpen, Dilation, Erosion, Laplacian, Sobel, Prewitt, Gray Scale, Sepia and Invert
Are built-in filters.
These filters can be set to be available in some passes.

To use a filter you should:

- Create appropriate sensor(s) and controller(s).
- Create a *2D Filter* actuator.
- Select your filter, for example *Blur*.
- Set the pass number that the filter will be applied.

To remove a filter on a specific pass:

- Create appropriate sensor(s) and controller(s).
- Create a *2D Filter* actuator.
- Select *Remove Filter*.
- Set the pass number you want to remove the filter from it.

To disable a filter on a specific pass:

- Create appropriate sensor(s) and controller(s).
- Create a *2D Filter* actuator.
- Select *Disable Filter*.
- Set the pass number you want to disable the filter on it.

To enable a filter on a specific pass:

- Create appropriate sensor(s) and controller(s)
- Create a *2D Filter* actuator.
- Select *Enable Filter*.
- Set the pass number you want to enable the filter on it.

Custom Filters
==============

.. figure:: /images/custom_2d_filter.jpg

2D Filters: Custom Filter.

Custom filters give you the ability to define your own 2D filter using GLSL.
Its usage is the same as built-in filters,
but you must select *Custom Filter* in *2D Filter* actuator,
then write shader program into the Text Editor, and then place shader script name on actuator.

Blue Sepia Example:

.. code-block:: glsl

uniform sampler2D bgl_RenderedTexture;
void main(void)
{
vec4 texcolor = texture2D(bgl_RenderedTexture, gl_TexCoord[0].st);
float gray = dot(texcolor.rgb, vec3(0.299, 0.587, 0.114));
gl_FragColor = vec4(gray * vec3(0.8, 1.0, 1.2), texcolor.a);
}

***************
Action Actuator
***************

.. figure:: /images/bge_actuator_action.png
:width: 292px

Action Actuator.

Actuates armature actions, and sets the playback method.
The Action actuator is only visible when an armature is selected,
because actions are stored in the armature.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

Action Playback Type
Play
Play F-Curve once from start to end when a TRUE pulse is received.
Ping Pong
Play F-Curve once from start to end when a TRUE pulse is received.
When the end is reached play F-Curve once from end to start when a TRUE pulse is received.
Flipper
Play F-Curve once from start to end when a TRUE pulse is received.
(Plays backwards when a FALSE pulse is received).
Loop End
Play F-Curve continuously from end to start when a TRUE pulse is received.
Loop Start
Play F-Curve continuously from start to end when a TRUE pulse is received.
Property
Uses a property to define what frame is displayed.

Action
Select the action to use
Continue
Restore last frame when switching on/off, otherwise play from the start each time.
Start Frame
Set the start frame of the action.
End Frame
Set the end frame of the action.
Child Button
Update action on all children objects as well.
Blendin
Number of frames of motion blending.
Priority
Execution priority -- lower numbers will override actions with higher numbers.
With 2 or more actions at once, the overriding channels must be lower in the stack.
Frame Property
Assign the action's current frame number to this property.
Property
Use this property to define the Action position. Only for Property playback type.
Layer
The animation layer to play the action on.
Layer Weight
How much of the previous layer to blend into this one.

***************
Camera Actuator
***************

Makes the camera follow or track an object.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

.. figure:: /images/bge_actuator_camera.png
:width: 271px

Camera Actuator.

Camera Object
Name of the Game Object that the camera follows/tracks.
Height
Height the camera tries to stay above the Game Object's object center
Axis
Axis in which the Camera follows (X or Y)
Min
Minimum distance for the camera to follow the Game Object
Max
Maximum distance for the camera to follow the Game Object
Damping
Strength of the constraint that drives the camera behind the target.
Range: 0 to 10. The higher the parameter,
the quicker the camera will adjust to be inside the constrained range (of min, max and height).

********************
Constraints Actuator
********************

Adds a constraint to the location, orientation.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

Constraint Mode
===============

Menu specifying type of constraint required.

- Force Field Constraint
- Orientation Constraint
- Distance Constraint
- Location Constraint

.. figure:: /images/bge_actuator_constraint_forcefield.png
:width: 271px

:menuselection:`Constraint actuator --&gt; Force Field`.

Force Field Constraint
Create a force field buffer zone along one axis of the object.

Damping
Damping factor of the Fh spring force.
Distance
Height of Fh area.
Rot Fh
Make game object axis parallel to the normal of trigger object.
Direction
Axis in which to create force field (can be + or -, or None).
Force
Force value to be used.
N
When on, use a horizontal spring force on slopes.
M/P
Trigger on another Object will be either Material (M) or Property (P).
Property
Property/Material that triggers the Force Field constraint (blank for **all** Properties/Materials).
Per
Persistence button
When on, force field constraint always looks at Property/Material;
when off, turns itself off if it cannot find the Property/Material.
Time
Number of frames for which constraint remains active.
RotDamp
Damping factor for rotation.

.. figure:: /images/bge_actuator_constraint_orientation.png
:width: 271px

:menuselection:`Constraint Actuator --&gt; Orientation`.

.. rubric:: Orientation Constraint

Constrain the specified axis in the Game to a specified direction in the World axis.

Direction
Game axis to be modified (X, Y, Z or none).
Damping
Delay (frames) of the constraint response.
Time
Time (frames) for the constraint to remain active.
Reference Direction
Reference direction (global coordinates) for the specified game axis.
Min Angle
Minimum angle for the axis modification.
Max Angle
Maximum angle for the axis modification.

.. figure:: /images/bge_actuator_constraint_distance.jpg
:width: 271px

:menuselection:`Constraint actuator --&gt; Distance`.

Distance Constraint
===================

Maintain the distance the Game Object has to be from a surface.

Direction
Axis Direction (X, Y, Z, -X, -Y, -Z, or None).
L
If on, use local axis (otherwise use World axis).
N
If on, orient the Game Object axis with the mesh normal.
Range
Maximum length of ray used to check for Material/Property on another game object.
Force Distance
Distance to be maintained between object and the Material/Property that triggers the
Distance Constraint (-2000 to +2000 Blender Units).
Damping
Delay (frames) of the constraint response.
M/P
Trigger on another Object will be either Material (M) or Property (P).
Property
Property/Material that triggers the Force Field constraint (blank for **all** Properties/Materials).
Per
Persistence button: When on, force field constraint always looks at Property/Material;
when off, turns itself off if it cannot find the Property/Material.
Time
Number of frames for which constraint remains active.
Rotation Damping
Damping factor for rotation.

.. figure:: /images/bge_actuator_constraint_location.png
:width: 271px

:menuselection:`Constraint actuator --&gt; Location`.

Location Constraint
===================

Limit the position of the Game Object within one World Axis direction.
To limit movement within an area or volume, use two or three constraints.

Limit
Axis in which to apply limits (LocX, LocY, LocZ or none).
Min
Minimum limit in specified axis (Blender Units).
Max
Maximum limit in specified axis (Blender Units).
Damping
Delay (frames) of the constraint.

********************
Edit Object Actuator
********************

The Edit Object actuator allows the user to edit settings of objects in game.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

.. figure:: /images/bge_actuator_edit_object.png
:width: 271px

Edit Object actuator.

Edit Object
Menu of options for Edit Object actuator.

- Dynamics
- Track To
- Replace Mesh
- End Object
- Add Object

.. figure:: /images/bge_actuator_edit_object_dynamics.png
:width: 271px

:menuselection:`Edit Object actuator --&gt; Dynamics`.

Dynamics
Provides a menu of *Dynamic Operations* to set up dynamics options for object.

Set Mass
Enables the user to set the mass of the current object for Physics (Range 0 - 10,000).
Disable Rigid Body
Disables the Rigid Body state of the object -- disables collision.
Enable Rigid Body
Disables the Rigid Body state of the object -- enables collision.
Suspend Dynamics
Suspends the object dynamics (object velocity).
Restore Dynamics
Resumes the object dynamics (object velocity).

.. figure:: /images/bge_actuator_edit_object_track_to.jpg
:width: 271px

:menuselection:`Edit Object actuator --&gt; Track to`.

Track To
Makes the object "look at" another object, in 2D or 3D.
The Y-axis is considered the front of the object.

Object
Object to follow.
Time
No. of frames it will take to turn towards the target object (Range 0-2000).
3D Button (toggle).
Enable 2D (X, Y) or 3D (X, Y, Z) tracking.

.. figure:: /images/bge_actuator_edit_object_replace_mesh.jpg
:width: 271px

:menuselection:`Edit Object actuator --&gt; Replace Mesh`.

Replace Mesh
Replace mesh with another. Both the mesh and/or its physics can be replaced,
together or independently.

Mesh
name of mesh to replace the current mesh.
Gfx Button
replace visible mesh.
Phys Button
replace physics mesh (not compound shapes)

.. figure:: /images/bge_actuator_edit_object_end_object.png
:width: 271px

:menuselection:`Edit Object actuator --&gt; End Object`.

End Object
==========

Destroy the current object (Note, debug properties will display error Zombie Object in console)

.. figure:: /images/bge_actuator_edit_object_add_object.png
:width: 271px

:menuselection:`Edit Object actuator --&gt; Add Object`.

Add Object
==========

Adds an object at the center of the current object.

The object that is added needs to be on another, hidden, layer.
Object
The name of the object that is going to be added.:
Time
The time (in frames) the object stays alive before it disappears.
Zero makes it stay forever.
Linear Velocity
Linear Velocity, works like in the motion actuator but on the created object instead of the object itself.
Useful for shooting objects, create them with an initial speed.
Angular Velocity
Angular velocity, works like in the motion actuator but on the created object instead of the object itself.

*************
Game Actuator
*************

The Game actuator allows the user to perform Game-specific functions, such as Restart Game,
Quit Game and Load Game.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

.. figure:: /images/bge_actuator_game.jpg
:width: 271px

Game actuator.

.. figure:: /images/bge_actuator_game_options.jpg
:width: 271px

Game.

Game
====

Load ``bge.logic.globalDict``
Load ``bge.logic.globalDict`` from ``.bgeconf``.
Save ``bge.logic.globalDict``
Save ``bge.logic.globalDict`` to ``.bgeconf``.
Quit Game
Once the actuator is activated, the blenderplayer exits the runtime.
Restart Game
Once the actuator is activated, the blenderplayer restarts the game (reloads from file).
Start Game From File
Once the actuator is activated, the blenderplayer starts the blend-file from the path specified.

File
Path to the blend-file to load.

.. note::

If you use the keyboard sensor as a hook for :kbd:`Esc`,
in the event that the quit game actuator fails, such as an error in a Python file,
the game will be unable to close. Data may be recovered from ``quit.blend``
:menuselection:`File --&gt; Recover Last Session`

****************
Message Actuator
****************

The Message actuator allows the user to send data across a scene,
and between scenes themselves.

.. figure:: /images/bge_actuator_message.png
:width: 271px

Message actuator.

.. figure:: /images/bge_actuator_message_options.jpg
:width: 271px

Message actuator Options.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

To
Object to broadcast to. Leave blank if broadcast to all (or sending to another scene).
Subject
Subject of message. Useful if sending certain types of message, such as "end-game",
to a message sensor listening for "end game" ``and`` Quit Game actuator.
Body
Body of message sent (only read by Python).
Text
User specified text in body.
Property
User specified property.

.. note::

You can use the Message Actuator to send data, such as scores to other objects,
or even across scenes! (alternatively use ``bge.logic.globalDict``).

***************
Motion Actuator
***************

The Motion actuator sets an object into motion. There are two modes of
operation, Simple or Servo, in which the object can either teleport &amp;
rotate, or dynamically move.

.. seealso::

:doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;`
for common options.

Special Options:

Motion Type
===========

Which determines the type of motion:

Simple Motion
Applies a change in location and/or rotation directly.
Servo Control
Sets a target speed, and also how quickly it reaches that speed.

The `Simple Motion`_ actuator gives control over position and
velocity, but does this as an instant displacement; the object never
passes any of the coordinates between the start and end positions.
This can interfere with the physical simulation of other objects, and
can cause an object to go through another object. The `Servo Control`_
actuator does not suffer from this, since it produces physically
correct velocities, and leaves updating the position to the physics
simulation.

Simple Motion
=============

.. figure:: /images/gameengine_actuator_motion_simple.png
:width: 271px

Motion actuator for Simple Motion.

Loc
The object jumps the number of Blender units entered,
each time a pulse is received.

Rot
The object rotates by the specified amount,
each time a pulse is received.

L
Coordinates specified are Global (gray) or Local (White).

Servo Control
=============

.. figure:: /images/gameengine_actuator_motion_servo.png
:width: 271px

Motion actuator set to *Servo Control*.

The Servo Control actuator influences the velocity of a game object by
applying forces, resulting in correct behavior when colliding with
other objects controlled by the physics simulation. The amount of
force necessary is determined by a `PID controller`_, a type of
controller that is often used in control systems. Only the positional
velocity is influenced by this actuator; it does not control rotation
at all, and it controls position only indirectly.

Controlling the position is not necessary in that respect; that is
left to a player moving the object via direction-type controls (such
as the WSAD keys in a first person shooter). In such a scenario, each
direction-key sensor should be attached to a different Servo Control
actuator setting a different target velocity.

.. tip::

To use the Servo Control actuator, it is necessary to set the
object's Physics Type to "Dynamic" or "Rigid Body", and to mark the
object as "Actor" in the same panel. This actuator does not work
with the Character physics type.

Reference Object
Specifies the object which the actuator uses as a reference for the
velocity. When set, it will use a velocity relative to that object
instead of absolute (i.e. world-relative) velocity. Use this for a
player object standing on a moving platform.

Linear Velocity
The target linear velocity for the object.

L
Determines whether the Linear Velocity specified are in Local
(button depressed) or Global (button released) coordinates.

X, Y, Z force limits
Sets minimum and maximum limits for the force applied to the
object. If disabled (i.e. X, Y or Z buttons are depressed) the
force applied is unlimited.

The following three coefficients determine the response to the
*velocity error*, which is the difference between the target velocity
and the object's actual velocity.

Proportional Coefficient
This controls the reaction proportional to the velocity error.
Small values cause smooth (but possibly too slow) changes in
velocity. Higher values cause rapid changes, but may cause
overshooting.

Integral Coefficient
This controls the reaction to the sum of errors so far. Using only
the Proportional component results in a systematic velocity error
if there is friction: some velocity delta is necessary to produce
the force that compensates the friction. Using the Integral
component suppresses this effect (the target velocity is achieved
on average) but can create oscillations; the control will speed to
compensate the initial velocity error. To avoid the oscillation,
the Proportional component must be used with the Integral component
(the Proportional component damps the control) This is why the GUI
sets the Proportional Coefficient systematically when you change
the Integral Coefficient.

Derivative Coefficient
Set the Derivative Coefficient. This dampens the acceleration when
the target velocity is almost reached.

.. _PID controller: https://en.wikipedia.org/wiki/PID_controller

**************
Mouse Actuator
**************

Todo.

***************
Parent Actuator
***************

Enables you to change the parent relationships of the current object.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

Scene
=====

Menu for parenting operation required.

.. figure:: /images/bge_actuator_parent.jpg
:width: 271px

Parent Actuator.

Set Parent
Make this object to be current object's parent.

Parent Object
Name of parent object.
Compound'
Add this object shape to the parent shape (only if the parent shape is already compound).
Ghost'
Make this object ghost while parented.

Remove Parent
Remove all parents of current object.

Parent Object
Name of parent object.

*****************
Property Actuator
*****************

Using the Property actuator you can change the value of a given property once the actuator
itself is activated.

.. seealso::

:doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;`
for common options.

Special Options:

.. figure:: /images/bge_actuator_property.jpg
:width: 271px

Property actuator.

Mode
====

Assign
the *Property* target property will become equal to the set *Value* once the actuator is activated
Add
adds *Value* to the value of the property *Property* once the actuator is activated
(enter a negative value to decrease).
For *Bool*, a value other than 0 (also negative) is counted as True.
Copy
copies a property from another object to a property of the actuator owner once the actuator is activated.
Toggle
switches 0 to 1 and any other number than 0 to 0 once the actuator is activated. Useful for on/off switches.

Property
The target property that this actuator will change.

Value
The value to be used to change the property.

Example
=======

You have a character, it has a property called "hp" (hit points)
to determine when he has taken enough damage to die. hp is an int with the start value of 100.

You set up two *Collision* sensors, one for enemy bullets,
and one for picking up more health. The first one is connected
(through an *AND* controller)
to an *Add Property* actuator with the property hp and the value -10.
Every time the player is hit by an enemy bullet he loses 10 hp. The other sensor is connected
(through an *AND* controller) to an other *Add Property* actuator,
this one with the value 50.
So every time the player collides with a health item the hp increases by 50.
Next you set up a *Property* sensor for an interval, greater than 100.
This is connected (through an *AND* controller)
to an *Assign Property* actuator which is set to 100.
So if the players hp increases over 100 it is set to 100.

***************
Random Actuator
***************

Sets a random value into a property of the object.

.. seealso::

:doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;`
for common options.

Special Options:

.. figure:: /images/bge_actuator_random_bool_constant.jpg
:width: 271px

Camera Actuator.

Seed
====

Starting seed for random generator (range 1 - 1000).

Distribution
============

Menu of distributions from which to select the random value.
The default entry of Boolean Constant gives either True or False,
which is useful for test purposes.

.. figure:: /images/bge_actuator_random_float_neg_exp.jpg
:width: 271px

Float Neg. Exp.

Float Neg. Exp.
Values drop off exponentially with the specified half-life time.

Property
Float property to receive value.
Half-Life Time
Half-life time (Range 0.00 - 10000.00).

.. figure:: /images/bge_actuator_random_float_normal.jpg
:width: 271px

Float Normal.

Float normal
Random numbers from a normal distribution.

Property
Float property to receive value.
Mean
Mean of normal distribution (Range -10000.00 to +10000.00).
SD
Standard deviation of normal distribution (Range 0.00 to +10000.00).

.. figure:: /images/bge_actuator_random_float_uniform.png
:width: 271px

Float Uniform.

Float uniform
Random values selected uniformly between maximum and minimum.

Property
Float property to receive value.
Min
Minimum value (Range -10000.00 to +10000.00).
Max
Maximum value (Range -10000.00 to +10000.00).

.. figure:: /images/bge_actuator_random_float_constant.jpg
:width: 271px

Float Constant.

Float constant
Returns a constant value.

Property
Float property to receive value.
Value
Value (Range 0.00 to +1.00).

.. figure:: /images/bge_actuator_random_int_poisson.jpg
:width: 271px

Random Integer Poisson.

Int Poisson
Random numbers from a Poisson distribution.

Property
Integer property to receive value.
Mean
Mean of Poisson distribution (Range 0.01 to +100.00).

.. figure:: /images/bge_actuator_random_int_uniform.png
:width: 271px

Random Integer Uniform.

Int uniform
Random values selected uniformly between maximum and minimum.

Property
Integer property to receive value.
Min
Minimum value (Range -1000 to +1000).
Max
Maximum value (Range -1000 to +1000).

.. figure:: /images/bge_actuator_random_int_constant.jpg
:width: 271px

Random Integer Constant.

Int constant
Returns a constant value.

Property
Integer property to receive value.
Value
Value (Range 0.00 to +1.00).

.. figure:: /images/bge_actuator_random_bool_bernoulli.jpg
:width: 271px

Random Bool Bernoulli.

Bool Bernoulli
Returns a random distribution with specified ratio of TRUE pulses.

Property
Boolean property to receive value.
Chance
Proportion of TRUE responses required.

.. figure:: /images/bge_actuator_random_bool_uniform.jpg
:width: 271px

Random Bool Uniform.

Bool uniform
A 50/50 chance of obtaining True/False.

Property
Boolean property to receive value.

.. figure:: /images/bge_actuator_random_bool_constant.jpg
:width: 271px

Random Bool Constant.

Bool constant
Returns a constant value.

Property
Boolean property to receive value.
Value
Value (True or False).

**************
Scene Actuator
**************

.. figure:: /images/bge_actuator_sound.png
:width: 257px

Scene actuator.

The *Scene* actuator manages the scenes in your blend-file,
these can be used as levels or for UI and background.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:
The actuator has eight modes:

.. figure:: /images/bge_actuator_scene_options.jpg
:width: 257px

Scene actuator options.

Restart
Restarts the current scene, everything in the scene is reset.
Set Scene
Changes scene to selected one.
Set Camera
Changes which camera is used.
Add Overlay Scene
This adds an other scene, and draws it on top of the current scene.
It is good for interfacing: keeping the health bar, ammo meter,
speed meter in an overlay scene makes them always visible.
Add Background Scene
This is the opposite of an overlay scene, it is drawn behind the current scene.
Remove Scene
Removes a scene.
Suspend Scene
Pauses a scene.
Resume Scene
Resumes a paused scene.

.. note::
A scene that it is paused cannot resume itself.
You need an active scene to resume other scene that it is paused.
..    TODO/Review: {{WikiTask/Inprogress}}.

**************
Sound Actuator
**************

Select a sound file from the list or make a new one.

.. figure:: /images/bge_actuator_sound.png
:width: 271px

Sound Actuator.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

Music File title
Select music file from the list presented.

**************
State Actuator
**************

The State actuator allows the user to create complex logic,
while retaining a clear user interface. It does this by having different states,
and performing operations upon them.

.. seealso::

:doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;`
for common options.

Special Options:

.. figure:: /images/bge_actuator_state.png
:width: 271px

State actuator.

.. figure:: /images/bge_actuator_state_options.jpg
:width: 271px

State actuator options.

Operation
=========

Menu to select the state operation required.

Change State
Change from the current state to the state specified.
Remove State
Removes the specified states from the active states (deactivates them).
Add State
Adds the specified states to the active states (activates them).
Set State
Moves from the current state to the state specified, deactivating other added states.

Usage Notes
===========

With the state actuator, you can create tiers of logic,
without the need for hundreds of properties. Use it well, and you benefit greatly,
but often problems may be circumvented by Python.

*****************
Steering Actuator
*****************

The steering actuator moves an object towards a target object, with options to seek, flee, or follow a path.
This actuator will not actually try to avoid obstacles by deviating the objects course.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Options
=======

.. figure:: /images/bge_actuator_steering-steering_panel.jpg

Steering Actuator Panel.

Behavior
Seek, Flee or Path following
Target Object
The game object to seek.

Navigation Mesh Object:
The name of the navigation mesh object used by the Steering Actuator when in Path following behavior.
The game object will use the Navigation Mesh to create a path to follow the Target Object.

.. tip::

You can create your own mesh to use for navigation and make it a Navigation Mesh in:

:menuselection:`Properties editor --&gt; Physics --&gt; Physics panel --&gt; choosing Physics Type: Navigation Mesh`

Or you can let Blender create a Navigation Mesh, then select a mesh.  (Floor or ground or etc.)

:menuselection:`Properties editor --&gt; Scene --&gt; Navigation mesh object panel --&gt; Build navigation mesh`

Distance
The maximum distance for the game object approach the Target Object.
Velocity
The velocity used to seek the Target Object.
Acceleration
The maximum acceleration to use when seeking the Target Object.
Turn Speed
The maximum turning speed to use when seeking the Target Object.
Facing
Set a game object axis that always faces the Target Object.
Axis
The game object axis that always faces the Target Object.
Options are: Positive (X, Y, Z) and Negative (-X, -Y, -Z).
Axis N
Use the Normal of the Navigation Mesh to align the up vector of the game object.

.. rubric:: Self Terminated

Disabled
Stops moving toward the Target Object once it reaches the maximum distance to approach the Target Object.
Will follow the Target Object if it moves further away than the maximum distance.
Enabled
Stops moving toward the Target Object once it reaches the maximum distance to approach the Target Object.
Will not follow even if the Target Object moves further away than the maximum distance.
Visualize
This checkbox let the user specify whether to show or not the debug informations of the actuator.
It is also necessary to enable Debug Properties in the Display menu of the *Render* tab.

*******************
Visibility Actuator
*******************

The Visibility actuator allows the user to change the visibility of objects during runtime.

.. figure:: /images/bge_actuator_visibility.jpg
:width: 271px

Visibility actuator.

See :doc:`Actuator Common Options &lt;/game_engine/logic/actuators/common_options&gt;` for common options.

Special Options:

Visible
Toggle checkbox to toggle visibility
Occlusion
Toggle checkbox to toggle occlusion. Must be initialized from the *Physics* tab.
Children
Toggle checkbox to toggle recursive setting --
will set visibility / occlusion state to all child objects, children of children (recursively)

Usage Notes
===========

Using the visibility actuator will save on Rasterizer usage, however, not Physics,
and so is limited in terms of Level of Detail (LOD). For LOD look at replace mesh,
but be aware that the logic required can negate the effect of the LOD.

******************
Controller Editing
******************

.. figure:: /images/bge_controller_column.jpg
:width: 292px

Controller Column with Typical Sensor.

Blender controllers can be set up and edited in the central column of the Logic Panel.
This page describes the general column controls,
those parameters which are common to all individual controller types,
and how different states for the objects in the logic system can be set up and edited.

The image shows a typical controller column with a single controller.
At the top of this column, and for sensors and actuators, the column heading includes menus
and buttons to control which of all the controllers in the current Game Logic are displayed.

Column Heading
==============

.. figure:: /images/bge_controller_column1.png
:width: 292px

Controller Column Headings.

The column headings contain controls to set which controllers appear,
and the level of detail given, in the controller column. This is very useful for hiding
unnecessary controllers so that the necessary ones are visible and easier to reach.
Both these can be controlled individually.

Controllers
===========

Show Objects
Expands all objects.
Hide Objects
Collapses all objects to just a bar with their name.
Show Controllers
Expands all Controllers.
Hide Controllers
Collapses all Controllers to bars with their names.

It is also possible to filter which controllers are viewed using the three heading buttons:

Sel
Shows all controllers for selected objects.
Act
Shows only controllers belonging to the active object.
Link
Shows controllers which have a link to actuators/sensors.

Object Heading
==============

.. figure:: /images/bge_controller_column2.png
:width: 292px

.. figure:: /images/bge_controller_column4.png
:width: 292px

In the column list, controllers are grouped by object. By default,
controllers for every selected object appear in the list,
but this may be modified by the column heading filters.

At the head of each displayed object controller list, three entries appear:
*Used States Button* Shows which states are in use for the object.
Detailed description of the marked panel is given in :doc:`States &lt;/game_engine/logic/states&gt;`.
Name
The name of the object.
Add Controller
When clicked, a menu appears with the available controller types.
Selecting an entry adds a new controller to the object.
See :doc:`Controllers &lt;/game_engine/logic/controllers/index&gt;` for a list of available controller types.

Standard Controller Parts
=========================

.. _standard-controller-parts:

The controller heading is standard to every controller.

.. figure:: /images/game_engine_controller_parts.png

Controller Type menu
Specifies the type of the controller.
Controller Name
The name of the controller. This can be selected by the user.
It is used to access controllers with Python; it needs to be unique among the selected objects.
State Index
Sets the designated state for which this controller will operate.
Preference Button
If on, this controller will operate before all other non-preference controllers (useful for start-up scripts).
Active Checkbox
When unchecked the controller is deactivated, no pluses will be sent to the connect actuators.
``X`` Button
Deletes the sensor.
.. _controllers-index:

##############
Controllers
##############

.. toctree::
:maxdepth: 2

introduction.rst
editing.rst

Controller Types
================

.. toctree::
:maxdepth: 1

types/and.rst
types/or.rst
types/nand.rst
types/nor.rst
types/xor.rst
types/xnor.rst
types/expression.rst
types/python.rst

************
Introduction
************

The controllers are the bricks that collect data sent by the sensors,
and also specify the state for which they operate. After performing the specified logic operations,
they send out pulse signals to drive the actuators to which they are connected.

When a sensor is activated, it sends out a positive pulse, and when it is deactivated,
it sends out a negative pulse.
The controllers' job is to check and combine these pulses to trigger the proper response.

The logic blocks for all types of controller may be constructed and changed using the
:doc:`Logic Editor &lt;/editors/logic_editor&gt;`; details of this process are given in the
:doc:`Controller Editing &lt;/game_engine/logic/controllers/editing&gt;` page.

Controller Types
================

There are eight types of controller logic brick to carry out the logic process on the input
signal(s): these are described in the separate pages shown below:

- :doc:`AND &lt;/game_engine/logic/controllers/types/and&gt;`
- :doc:`OR &lt;/game_engine/logic/controllers/types/or&gt;`
- :doc:`XOR &lt;/game_engine/logic/controllers/types/xor&gt;`
- :doc:`NAND &lt;/game_engine/logic/controllers/types/nand&gt;`
- :doc:`NOR &lt;/game_engine/logic/controllers/types/nor&gt;`
- :doc:`XNOR &lt;/game_engine/logic/controllers/types/xnor&gt;`
- :doc:`Expression &lt;/game_engine/logic/controllers/types/expression&gt;`
- :doc:`Python &lt;/game_engine/logic/controllers/types/python&gt;`

This table gives a quick overview of the logic operations performed by the logical controller
types. The first column, input,
represents the number of positive pulses sent from the connected sensors.
The following columns represent each controller's response to those pulses.
True means the conditions of the controller are fulfilled,
and the actuators it is connected to will be activated;
false means the controller's conditions are not met and nothing will happen. Please consult
the individual controller pages for a more detailed description of each controller.

.. note::

It is assumed that more than one sensor is connected to the controller.
For only one sensor, consult the "All" line.

.. list-table::
:header-rows: 1

* - Positive sensors
- Controllers
- ..
- ..
- ..
- ..
- ..
* - ..
- :doc:`AND &lt;/game_engine/logic/controllers/types/and&gt;`
- :doc:`OR &lt;/game_engine/logic/controllers/types/or&gt;`
- :doc:`XOR &lt;/game_engine/logic/controllers/types/xor&gt;`
- :doc:`NAND &lt;/game_engine/logic/controllers/types/nand&gt;`
- :doc:`NOR &lt;/game_engine/logic/controllers/types/nor&gt;`
- :doc:`XNOR &lt;/game_engine/logic/controllers/types/xnor&gt;`
* - None
- False
- False
- False
- True
- True
- True
* - One
- False
- True
- True
- True
- False
- False
* - Multiple, not all
- False
- True
- False
- True
- False
- True
* - All
- True
- True
- False
- False
- False
- True

**************
AND Controller
**************

This controller gives a positive (TRUE) output when
All its inputs are TRUE, and
The object is in the designated State.
For all other conditions the controller gives a negative (FALSE) output.

Options:

.. figure:: /images/bge_controller_and.png
:width: 292px

AND Controller.

See :ref:`standard controller parts &lt;standard-controller-parts&gt;` for descriptions of the remaining options.

*********************
Expression Controller
*********************

This controller evaluates a user written expression, and gives a positive (TRUE) output when
The result of the expression is TRUE, and
The object is in the designated State.
For all other conditions the controller gives a negative (FALSE) output.

.. figure:: /images/bge_controller_expression.png
:width: 292px

Expression Controller.

Expression
==========

The expression, which is written in the box, can consist of variables,
constants and operators. These must follow the rules laid out below.

Variables
=========

You can use:

- *sensors names*,
- *properties* : assign a game property to an object and use it in a controller expression.

These cannot contain blank spaces.

Operations
==========

Mathematical operations
-----------------------

Operators: ``*``, ``/``, ``+``, ``-``

Returns: a number

Examples: ``3 + 2``, ``35 / 5``

Logical operations
------------------

- Comparison operators: ``&lt;``, ``&gt;``, ``&gt;=``, ``&lt;=``, ``==``, ``!=``
- Booleans operators: ``AND``, ``OR``, ``NOT``

Returns: ``True`` or ``False``.

Examples: ``3 &gt; 2 (True)``, ``1 AND 0 (False)``

Conditional statement (if)
==========================

Use::

if( expression, pulse_if_expression_is_true, pulse_if_expression_is_false )

If the controller evaluates ``expression`` to True:

- if ``pulse_if_expression_is_true`` is ``True``, the controller sends a positive pulse to the connected actuators.
- if ``pulse_if_expression_is_true`` is ``False``, the controller sends a negative pulse to the connected actuators.

If the controller evaluates ``expression`` to False:

- if ``pulse_if_expression_is_false`` is ``True``, the controller sends a positive pulse to the connected actuators.
- if ``pulse_if_expression_is_false`` is ``False``, the controller sends a negative pulse to the connected actuators.

Examples
========

Given the object has a property ``coins`` equal to 30::

coins &gt; 20

returns True (the controller sends a positive pulse to the connected actuators).

Given the object has:

- a sensor called ``Key_Inserted`` equal to True,
- a property named ``Fuel`` equal to False,

.. code-block:: python

Key_Inserted AND Fuel

returns False (the controller sends a negative pulse to the connected actuators).

This is the same as doing::

if (Key_Inserted AND Fuel, True, False)

Instead, you could do::

if (Key_Inserted AND Fuel, False, True)

to return a positive pulse when ``Key_Inserted AND Fuel`` returns False.

You can also do::

if ((Key_Inserted AND Fuel) OR (coins &gt; 20), True, False)

This expression returns True,
hence in this case the controller sends a positive pulse to the connected actuators.

Parts of the Expression Controller
==================================

.. figure:: /images/game_engine_controllers_expression.png

The Expression to calculate.

.. 1. Expression.

See :ref:`standard controller parts &lt;standard-controller-parts&gt;` for descriptions of the remaining options.

***************
NAND Controller
***************

This controller *activates* all connected actuators if...

- the game object is in the designated state.
- at least one connected sensor triggers the controller.
- at least one connected sensor evaluated False.

This controller *deactivates* all connected actuators if...

- the game object is in the designated state.
- at least one connected sensor triggers the controller.
- ALL connected sensor evaluated True.

Options:

.. figure:: /images/bge_controller_nan.png
:width: 292px

NAND Controller.

See :ref:`standard controller parts &lt;standard-controller-parts&gt;` for descriptions of the remaining options.

**************
NOR Controller
**************

This controller gives a positive (TRUE) output when
None of its inputs are TRUE, and
The object is in the designated State.
For all other conditions the controller gives a negative (FALSE) output.

Options:

.. figure:: /images/bge_controller_nor.png
:width: 292px

NOR Controller.

See :ref:`standard controller parts &lt;standard-controller-parts&gt;` for descriptions of the remaining options.

*************
OR Controller
*************

This controller gives a positive (TRUE) output when
Any one or more of its inputs are TRUE, and
The object is in the designated State.
For all other conditions the controller gives a negative (FALSE) output.

Options:

.. figure:: /images/bge_controller_or.png
:width: 292px

OR Controller.

See :ref:`standard controller parts &lt;standard-controller-parts&gt;` for descriptions of the remaining options.

*****************
Python Controller
*****************

The Python controller runs a Python script when a sensor triggers the controller.
This Python script can interact with the scene or logic bricks through
:doc:`Blender's API &lt;/game_engine/python_api/index&gt;`.

A Python script can either run as an entire file or a single module.
A file must be added in the text editor, and is identified simply by its name, not its path.
Names are case sensitive. Modules are identified by the file name *without* the extension followed by a ``.``
and then the name of the module. For example:

A file ``myscript.py`` contains::

def myModule ():
print("Go Open Source!");

The function can be accessed as ``myscript.myModule``, which will run ``print("Go Open Source!");``
every time the controller is triggered.

The entire file can be run by setting the type to *Script* and setting the name to myscript.py.

Parts of the Python Controller
===============================

.. figure:: /images/game_engine_python_controller.jpg

Python Controller.

Type
Specifies whether it is a module or entire file.
Name
The name of the file to be loaded.
D (Use Debug)
Continuously reloads the file.

See :ref:`standard controller parts &lt;standard-controller-parts&gt;` for descriptions of the remaining options.

.. seealso:: For more information on the Python API see:

- `The API docs &lt;https://www.blender.org/api/blender_python_api_current/&gt;`__
- :doc:`This chapter for more Game Engine related API &lt;/game_engine/python_api/index&gt;`.

***************
XNOR Controller
***************

This controller gives a positive (TRUE) output when
One (and only one) of its inputs are FALSE, and
The object is in the designated State.
For all other conditions the controller gives a negative (FALSE) output.

Options:

.. figure:: /images/bge_controller_xnor.png
:width: 292px

XNOR Controller.

See :ref:`standard controller parts &lt;standard-controller-parts&gt;` for descriptions of the remaining options.

**************
XOR Controller
**************

This controller gives a positive (TRUE) output when
One (and only one) of its inputs are TRUE, and
The object is in the designated State.
For all other conditions the controller gives a negative (FALSE) output.

Options:

.. figure:: /images/bge_controller_xor.png
:width: 292px

XOR Controller.

See :ref:`standard controller parts &lt;standard-controller-parts&gt;` for descriptions of the remaining options.
.. _logic-index:

########
Logic
########

.. toctree::
:maxdepth: 2

introduction.rst
sensors/index.rst
controllers/index.rst
actuators/index.rst
properties.rst
states.rst

************
Introduction
************

*Game Logic* is the default scripting layer in the Game Engine.
Each *Game Object* in the game may store a collection of logical components (Logic Bricks)
which control its behavior within the scene. Logic bricks can be combined to perform
user-defined actions that determine the progression of the simulation.

Logic Bricks
============

The main part of game logic can be set up through a graphical interface the
:doc:`Logic Editor &lt;/editors/logic_editor&gt;`, and therefore does not require detailed programming knowledge.
Logic is set up as blocks (or "bricks") which represent preprogrammed functions;
these can be tweaked and combined to create the game/application. There are three types of logic brick:
:doc:`Sensors &lt;/game_engine/logic/sensors/introduction&gt;`,
:doc:`Controllers &lt;/game_engine/logic/controllers/introduction&gt;` and
:doc:`Actuators &lt;/game_engine/logic/actuators/introduction&gt;`.
Sensors are primitive event listeners, which are triggered by specific events, such as a collision,
a key press or mouse movement. Controllers carry out logic operations on sensor output,
and trigger connected actuators when their operating conditions are met.
Actuators interact with the simulation directly, and are the only components in the game which
are able to do so (other than the Python controller, and other simulation components such as Physics).

Properties
==========

:doc:`Properties &lt;/game_engine/logic/properties&gt;` are like variables in other programming languages.
They are used to save and access data values either for the whole game (eg. scores),
or for particular objects/players (e.g. names).
However, in the Blender Game Engine, a property is associated with an object.
Properties can be of different types,
and are set up in a special area of the :doc:`Logic Editor &lt;/editors/logic_editor&gt;`.

States
======

Another useful feature is object :doc:`States &lt;/game_engine/logic/states&gt;`.
At any time while the simulation is running,
the object will process any logic which belongs to the current state of the object.
States can be used to define groups of behavior -- e.g. an actor object may be "sleeping", "awake" or "dead",
and its logic behavior may be different in each of these three states. The states of an object are set up,
displayed and edited in the Controller logic bricks for the object.

**********
Properties
**********

Properties are the game logic equivalent to variables. They are stored with the object,
and can be used to represent things about them such as ammo, health, name, and so on.

.. _game-engine-property-types:

Property Types
--------------

There are five types of properties:

Timer
Starts at the property value and counts upwards as long as the object exists.
It can for example be used if you want to know how long time it takes the player to complete a level.
Float
Uses decimal numbers as values, can range from -10000.000 to 10000.000. It is useful for precision values.
Integer
Uses integers (whole numbers) as values, between -10000 and 10000.
Useful for counting things such as ammunition, where decimals are unnecessary.
String
Takes text as value. Can store 128 characters.
Boolean
Boolean variable, has two values: true or false.
This is useful for things that have only two modes, like a light switch.

Using Properties
================

When a game is running, values of properties are set, manipulated, and evaluated using the
:doc:`Property Sensor &lt;/game_engine/logic/sensors/types/property&gt;` and the
:doc:`Property Actuator &lt;/game_engine/logic/actuators/types/property&gt;`.

Logic Properties are created and edited using the panel on the left of the Logic Editor
Panel. The top menu provides a list of the available property types.

.. figure:: /images/bge_game_logic_properties.png

Properties Panel of the Logic Editor.

Add Game Property button
This button adds a new property to the list, default is a *Float* property named ``prop``,
followed by a number if there already is one with this name.

Name field
Where you give your property its name, this is how you are going to access it through Python or expressions.
The way to do so in Python is by dictionary style lookup (``GameObject["propname"]``).
The name is case sensitive.

Type menu
This menu determines which type of property it is. The available options are in `Property Types`_.
Value field
Sets the initial value of the property.

Information (*i* button)
Display property value in debug information. If debugging is turned on,
the value of the property is given in the top left-hand corner of the screen while the game is running.
To turn debugging on, tick the *Show Debug Properties* checkbox in the *Game* menu.
All properties with debugging activated will then be presented with their object name,
property name and value during gameplay.
This is useful if you suspect something with your properties is causing problems.
.. |true-button| image:: /images/icons_sensor-true.png
:width: 1.1em
.. |false-button| image:: /images/icons_sensor-false.png
:width: 1.1em

*********************
Sensor Common Options
*********************

.. figure:: /images/bge_sensor_column3.jpg
:width: 292px

Common Sensor Options.

All sensors have a set of common buttons, fields and menus. They are organized as follows:

Triangle button
Collapses the sensor information to a single line (toggle).
Sensor type menu
Specifies the type of the sensor.
Sensor name
The name of the sensor. This can be selected by the user. It is used to access sensors with Python;
it needs to be unique among the selected objects.
Pin button
Display the sensor even when it is not linked to a visible states controller.
Checkbox button
Sets active state of the sensor
X button
Deletes the sensor.

.. note:: Note about triggers

If a controller does not get trigger by any connected sensor
(regardless of the sensors' state) it will not be activated at all.

A sensor triggers the connected controllers on state change.
When the sensor changes its state from negative to positive or positive to negative,
the sensor triggers the connected controllers.
A sensor triggers a connected controller as well when the sensor changes from deactivation to
activation.

The following parameters specifies how the sensor triggers connected controllers:

True level triggering
If this is set, the connected controllers will be triggered as long as the sensor's state is positive.
The sensor will trigger with the delay (see parameter: frequency) of the sensor. |true-button|
False level triggering
If this is set, the connected controllers will be triggered as long as the sensor's state is negative.
The sensor will trigger with the delay (see parameter: frequency) of the sensor. |false-button|
Freq
Despite it is name "Frequency", this parameter sets the delay between repeated triggers,
measured in frames (also known as logic ticks). The default value is 0 and it means no delay.
It is only used at least one of the level triggering parameters are enabled.

Raising the value of *freq* is a good way for saving performance costs by avoiding
to execute controllers or activate actuators more often than necessary.

Examples: (Assuming the default frame rate with a frequency of 60 Hz (60 frames per second)).

.. list-table::
:header-rows: 1
:class: valign
:widths: 10 30 15 15 15 15

* - freq
- meaning
- frames with trigger
- frames without trigger
- period in frames
- frequency in frames/sec
* - 0
- The sensor triggers the next frame.
- 1
- 0
- 1
- 60
* - 1
- The sensor triggers at one frame and waits another one until it triggers again. It results in half speed.
- 1
- 1
- 2
- 30
* - 29
- The sensor triggers one frame and waits 29 frames until it triggers again.
- 1
- 29
- 30
- 2
* - 59
- The sensor triggers one frame and waits 59 frames until it triggers again.
- 1
- 59
- 30
- 1

*Level* Button
Triggers connected controllers when state (of the build-in state machine) changes.
(For more information see :doc:`States &lt;/game_engine/logic/states&gt;`).

The following parameters specifies how the sensor's status gets evaluated:

*Tap* Button
Changes the sensor's state to negative one frame after changing
to positive even if the sensor evaluation remains positive.
As this is a state change it triggers the connected controllers as well.
Only one of *Tap* or *Level* can be activated.
If the *TRUE level triggering* is set,
the sensor state will consecutive change from True to False until the sensor evaluates False.
The *FALSE level triggering* will be ignored when the *Tap* parameter is set.

*Invert* Button
This inverts the sensor output.
If this is set, the sensor's state will be inverted.
This means the sensor's state changes to positive when evaluating False and changes to
False when evaluating True.
If the *Tap* parameter is set, the sensor triggers the controller based on the inverted sensor state.

**************
Sensor Editing
**************

.. figure:: /images/bge_sensor_column.jpg
:width: 292px

Sensor Column with Typical Sensor.

Blender sensors can be set up and edited in the left-hand column of the Logic Panel.
This page describes the general column controls,
and also those parameters which are common to all individual sensor types.

The image shows a typical sensor column with a single example sensor.
At the top of this column, the column heading includes menus and buttons to control which of
all the sensors in the current Game Logic are displayed.

Column Heading
==============

.. figure:: /images/bge_sensor_column1.png
:width: 292px

Sensor Column Heading.

The column headings contain controls to set which sensors, and the level of detail given,
in the sensor column. This is very useful for hiding unnecessary sensors so that the necessary
ones are visible and easier to reach. Both these can be controlled individually.

Sensors
=======

Show Objects
Expands all objects.
Hide Objects
Collapses all objects to just a bar with their name.
Show Sensors
Expands all sensors.
Hide Sensors
Collapses all sensors to bars with their names.

It is also possible to filter which sensors are viewed using the four heading buttons:

Sel
Shows all sensors for selected objects.
Act
Shows only sensors belonging to the active object.
Link
Shows sensors which have a link to a controller.
State
Only sensors connected to a controller with active states are shown.

Object Heading
==============

.. figure:: /images/bge_sensor_column2.png
:width: 292px

Sensor Object Heading.

In the column list, sensors are grouped by object. By default,
sensors for every selected object appear in the list,
but this may be modified by the column heading filters.

At the head of each displayed object sensor list, two entries appear:

Name
The name of the object.
Add Sensor
When clicked, a menu appears with the available sensor types.
Selecting an entry adds a new sensor to the object.
See :doc:`Sensors &lt;/game_engine/logic/sensors/index&gt;` for a list of available sensor types.
.. _sensors-index:

##########
Sensors
##########

.. toctree::

introduction.rst
editing.rst
common_options.rst

Sensor Types
============

.. toctree::
:maxdepth: 1

types/actuator.rst
types/always.rst
types/collision.rst
types/delay.rst
types/joystick.rst
types/keyboard.rst
types/message.rst
types/mouse.rst
types/near.rst
types/property.rst
types/radar.rst
types/random.rst
types/ray.rst

************
Introduction
************

Sensors are the logic bricks that cause the logic to do anything.
Sensors give an output when something happens, e.g.
a trigger event such as a collision between two objects, a key pressed on the keyboard,
or a timer for a timed event going off. When a sensor is triggered,
a positive pulse is sent to all controllers that are linked to it.

The logic blocks for all types of sensor may be constructed and changed using the
:doc:`Logic Editor &lt;/editors/logic_editor&gt;`
details of this process are given in the :doc:`Sensor Editing &lt;/game_engine/logic/sensors/editing&gt;` page.

The following types of sensor are currently available:

:doc:`Actuator &lt;/game_engine/logic/sensors/types/actuator&gt;`
Detects when a particular actuator receives an activation pulse.
:doc:`Always &lt;/game_engine/logic/sensors/types/always&gt;`
Gives a continuous output signal at regular intervals.
:doc:`Collision &lt;/game_engine/logic/sensors/types/collision&gt;`
Detects collisions between objects or materials.
:doc:`Delay &lt;/game_engine/logic/sensors/types/delay&gt;`
Delays output by a specified number of logic ticks.
:doc:`Joystick &lt;/game_engine/logic/sensors/types/joystick&gt;`
Detects movement of specified joystick controls.
:doc:`Keyboard &lt;/game_engine/logic/sensors/types/keyboard&gt;`
Detects keyboard input.
:doc:`Message &lt;/game_engine/logic/sensors/types/message&gt;`
Detects either text messages or property values
:doc:`Mouse &lt;/game_engine/logic/sensors/types/mouse&gt;`
Detects mouse events.
:doc:`Near &lt;/game_engine/logic/sensors/types/near&gt;`
Detects objects that move to within a specific distance of themselves.
:doc:`Property &lt;/game_engine/logic/sensors/types/property&gt;`
Detects changes in the properties of its owner object.
:doc:`Radar &lt;/game_engine/logic/sensors/types/radar&gt;`
Detects objects that move to within a specific distance of themselves, within an angle from an axis.
:doc:`Random &lt;/game_engine/logic/sensors/types/random&gt;`
Generates random pulses.
:doc:`Ray &lt;/game_engine/logic/sensors/types/ray&gt;`
Shoots a ray in the direction of an axis and detects hits.

***************
Actuator Sensor
***************

.. figure:: /images/bge_sensor_actuator.png
:width: 300px

Actuator sensor.

The Actuator sensor detects when a particular actuator receives an activation pulse.

The *Actuator* sensor sends a TRUE pulse when the specified actuator is activated.

The sensor also sends a FALSE pulse when the specified actuator is deactivated.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:

Actuator
Name of actuator (NB This must be owned by the same object).

*************
Always Sensor
*************

.. figure:: /images/bge_sensor_always.jpg
:width: 300px

Always sensor.

The *Always* sensor is used for things that need to be done every logic tick,
or at every *x* logic tick (with non-null *f*), or at start-up
(with *Tap*).

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

This sensor does not have any special options.

****************
Collision Sensor
****************

.. figure:: /images/bge_sensor_collision.jpg
:width: 300px

Collision sensor.

A *Collision* sensor works like a *Touch* sensor but can also filter by
property or material. Only objects with the property/material with that name will generate a
positive pulse upon collision. Leave blank for collision with any object.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:

Pulse button
Makes it sensible to other collisions even if it is still in touch
with the object that triggered the last positive pulse.
M/P button
Toggles between material and property filtering.

.. note:: Note about soft bodies

The *Collision* sensor cannot detect collisions with soft bodies.
This is a limitation in Bullet, the physics library used by the Game Engine.

************
Delay Sensor
************

.. figure:: /images/bge_sensor_delay.jpg
:width: 300px

Delay sensor.

The *Delay* sensor is designed for delaying reactions a number of logic ticks.
This is useful if an other action has to be done first or to time events.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.
Special Options:

Delay
The number of logic ticks the sensor waits before sending a positive pulse.
Duration
The number of logic ticks the sensor waits before sending the negative pulse.
Repeat Button
Makes the sensor restart after the delay and duration time is up.

***************
Joystick Sensor
***************

.. figure:: /images/bge_sensor_joystick1.jpg
:width: 200px

Joystick sensor.

The *Joystick* sensor triggers whenever the joystick moves.
It also detects events on a range of ancillary controls on the joystick device (hat, buttons,
etc.). More than one joystick may be used (see "Index").
The exact layout of the joystick controls will depend on the make and model of joystick used.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:

Index
Specifies which joystick to use.
All Events
Sensor triggers for all events on this joystick's current type.

.. figure:: /images/bge_sensor_joystick_event.jpg
:width: 200px

Joystick Events.

Event Type
A menu to select which joystick event to use.

.. rubric:: Single Axis

.. figure:: /images/bge_sensor_joystick_singaxis.png
:width: 200px

Joystick Single Axis.

Single Axis
Detect movement in a single joystick Axis.

Axis Number
- 1 = Horizontal axis (left/right)
- 2 = Vertical axis (forward/back)
- 3 = Paddle axis up/down
- 4 = Joystick axis twist left/right
Axis Threshold
Threshold at which joystick fires (Range 0 - 32768)

.. rubric:: Hat

.. figure:: /images/bge_sensor_joystick_hat.png
:width: 200px

Joystick Hat.

Hat
Detect movement of a specific hat control on the joystick.

Hat number
Specifies which hat to use (max. 2).
Hat Direction
Specifies the direction to use: up, down, left, right, up/right, up/left, down/right, down/left.

.. rubric:: Axis

.. figure:: /images/bge_sensor_joystick_axis.jpg
:width: 200px

Joystick Axis.

Axis
Axis Number
Specifies the axis (1 or 2).
Axis Threshold
Threshold at which joystick fires (Range 0 - 32768).
Axis Direction
Specifies the direction to use:

- (Axis Number = 1) Joystick Left, Right, Up, Down
- (Axis Number = 2) Paddle upper (Left); paddle Lower (Right);
- Joystick twist left (Up) Joystick twist right (Down)

.. rubric:: Button

.. figure:: /images/bge_sensor_joystick1.jpg
:width: 200px

Joystick Button.

Button
Specify the *button number* to use.

***************
Keyboard Sensor
***************

.. figure:: /images/bge_sensor_keyboard.png
:width: 300px

Keyboard sensor.

The *Keyboard* sensor is for detecting keyboard input.
It can also save keyboard input to a :ref:`String property &lt;game-engine-property-types&gt;`.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:

Key
This field detects presses on a named key.
Press the button with no label and a key to assign that key to the sensor.
This is the active key, which will trigger the TRUE pulse.
Click the button and then click outside of the button to deassign the key.

A FALSE pulse is given when the key is released.

All keys button
Sends a TRUE pulse when any key is pressed.
This is useful for custom key maps with a
:doc:`Python controller &lt;/game_engine/logic/controllers/types/python&gt;`.
First Modifier, Second Modifier
Specifies additional key(s), all of which must be held down while
the active key is pressed in order for the sensor to give a TRUE pulse.
These are selected in the same way as Key.
This is useful if you wish to use key combinations,
for example :kbd:`Ctrl-R` or :kbd:`Shift-Alt-Esc` to do a specific action.
Log Toggle
Assigns a *Bool* property which determines if the keystroke will or will not be logged in the target *String*.
This property needs to be TRUE if you wish to log your keystrokes.
Target
The name of property to which the keystrokes are saved. This property must be of type *String*.
Together with a *Property* sensor this can be used for example to enter passwords.

**************
Message Sensor
**************

.. figure:: /images/bge_sensor_message.jpg
:width: 300px

Message Sensor.

The *Message* sensor can be used to detect either text messages or property values.
The sensor sends a positive pulse once an appropriate message is sent from anywhere in the
engine. It can be set up to only send a pulse upon a message with a specific subject.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:

Subject
Specifies the message that must be received to trigger the sensor (this can be left blank).

.. note::

See :doc:`Message Actuator &lt;/game_engine/logic/actuators/types/message&gt;` for how to send messages.

************
Mouse Sensor
************

.. figure:: /images/bge_sensor_mouse1.jpg
:width: 300px

Mouse sensor.

The *Mouse* sensor is for detecting mouse events.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:
The controller consist only of a list of types of mouse events. These are:

Mouse over any
Gives a TRUE pulse if the mouse moves over any game object.
Mouse over
Gives a TRUE pulse if the mouse moves over the owner object.
Movement
Any movement with the mouse causes a stream of TRUE pulses.
Wheel Down
Causes a stream of TRUE pulses as the scroll wheel of the mouse moves down.
Wheel Up
Causes a stream of TRUE pulses as the scroll wheel of the mouse moves up.
Right button
Gives a TRUE pulse.
Middle button
Gives a TRUE pulse.
Left button
Gives a TRUE pulse.

A FALSE pulse is given when any of the above conditions ends.

There is no logic brick for specific mouse movement and reactions
(such as first person camera), these have to be coded in Python.

***********
Near Sensor
***********

.. figure:: /images/bge_sensor_near.png
:width: 300px

Near sensor.

A *Near* sensor detects objects that move to within a specific distance of
themselves. It can filter objects with properties, like the *Collision* sensor.

Options
=======

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Property
This field can be used to limit the sensor to look for only those objects with this property.
Distance
The number of Blender units it will detect objects within.
Reset
The distance the object needs to be to reset the sensor (send a FALSE pulse).

.. note::

#. The Near sensor can detect objects "through" other objects (walls etc).
#. Objects must have "Actor" enabled to be detected.

.. note:: Note about soft bodies

The *Near* sensor cannot detect soft bodies.
This is a limitation in Bullet, the physics library used by the Game Engine.

***************
Property Sensor
***************

.. figure:: /images/bge_sensor_property1.png
:width: 300px

Property sensor.

The *Property* sensor detects changes in the properties of its owner object.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:

.. figure:: /images/property_evaluation_types.jpg
:width: 300px

Property Evaluation.

Evaluation Type
Specifies how the property will be evaluated against the value(s).
Greater Than
Sends a TRUE pulse when the property value is greater than the *Value* in the sensor.
Less Than
Sends a TRUE pulse when the property value is less than the *Value* in the sensor.
Changed
Sends a TRUE pulse as soon as the property value changes.
Interval
Sends a TRUE pulse when the *Value* of the property is between the *Min* and *Max* values of the sensor.
Not Equal
Sends a TRUE pulse when the property value differs from the *Value* in the sensor.
Equal
Sends a TRUE pulse when the property value matches the *Value* in the sensor.

.. note::

The names of other properties can also be entered to compare properties.

************
Radar Sensor
************

.. figure:: /images/bge_sensor_radar.png
:width: 300px

Radar sensor.

The *Radar* sensor works much like a *Near* sensor,
but only within an angle from an axis, forming an invisible cone with the top in the objects'
center and base at a distance on an axis.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:

Property
This field can be used to limit the sensor to look for only those objects with this property.

.. note::

#. The Radar sensor can detect objects "through" other objects (walls etc).
#. Objects must have "Actor" enabled to be detected.

Axis
This menu determines the direction of the radar cone.
The ± signs is whether it is on the axis direction (+), or the opposite (-).
Angle
Determines the angle of the cone. (Range: 0.00 to 179.9 degrees).
Distance
Determines the length of the cone. (Blender units).

This sensor is useful for giving bots sight only in front of them, for example.

.. note:: Note about soft bodies

The *Radar* sensor cannot detect soft bodies.
This is a limitation in Bullet, the physics library used by the Game Engine.

*************
Random Sensor
*************

.. figure:: /images/bge_sensor_random.jpg
:width: 300px

Random sensor.

The *Random* sensor generates random pulses.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:

Seed
This field to enter the initial seed for the random number algorithm. (Range 0-1000).

.. note::

0 is not random, but is useful for testing and debugging purposes.

.. note::

If you run several times with the same Seed, the sequence of intervals you get will be the same in each run,
although the intervals will be randomly distributed.

**********
Ray Sensor
**********

.. figure:: /images/bge_sensor_ray.png
:width: 300px

Ray sensor.

The *Ray* sensor shoots a ray in the direction of an axis and sends a positive pulse
once it hits something.
It can be filtered to only detect objects with a given material or property.

See :doc:`Sensor Common Options &lt;/game_engine/logic/sensors/common_options&gt;` for common options.

Special Options:
It shares a lot of buttons and fields with *Radar* sensor.

Property
This field can be used to limit the sensor to look for only those objects with this property.

.. note::

#. Unless the Property field is set, the Ray sensor can detect objects "through" other objects (walls etc).
#. Objects must have "Actor" enabled to be detected.

Axis
This menu determines the direction of the ray.
The ± signs is whether it is on the axis direction (+), or the opposite (-).
Range
Determines the length of the ray. (Blender units).
X-Ray Mode button
Makes it x-ray, so that it sees through objects that do not
have the property or material specified in the filter field.
.. |info-button| image:: /images/icons_info.png
:width: 1.1em

******
States
******

In the BGE, an object can have different "states". At any time while the game is playing,
the current state of the object defines its behavior. For instance,
a character in your game may have states representing awake, sleeping or dead. At any moment
their behavior in response to a loud bang will be dependent on their current state;
they may crouch down (awake); wake up (asleep) or do nothing (dead).

How States Operate
==================

States are set up and used through controllers: note that only controllers,
not actuators and sensors, are directly controlled by the state system.
Each object has a number of states (up to 30; default = 1),
and can only be in one state at any particular time. A controller must always specify the
state for which it will operate -- it will only give an output pulse if a)
its logic conditions are met, and b) the object is currently in the specified State.
States are set up and edited in the object's Controller settings (for details see below).

.. tip::

State settings are automatic in simple games. By default,
the number of states for each object is 1, and all controllers are set to use State 1. So,
if a game does not need multiple states, everything will work without explicitly setting
states -- you do not need to bother about states at all.

One of the actuators, the State actuator, can set or unset the object's State bits,
and so allow the object's reaction to a sensor signal to depend on its current state. So,
in the above example, the actor will have a number of controllers connected to the "loud bang"
sensor, for each of the "awake", "asleep" or "dead" states.
These will operate different actuators depending on the current state of the actor,
and some of these actuators may switch the actor's state under appropriate conditions.

Editing States
==============

.. figure:: /images/bge_controller_state_panel.png
:width: 292px

State Panel Button.

States are set up and edited using the Controller (center) column of the Game Logic Panel.
To see the State panel, click on the State Panel Button shown.
The panel shows two areas for each of the 30 available states; these show Visible states,
and Initial states (see below). Setting up the State system for a game is performed by
choosing the appropriate state for each controller in the object's logic.

The display of an object's state logic, and other housekeeping,
is carried out using the State Panel for the object,
which is switched on and off using the button shown. The panel is divided into two halves,
Visible and Initial.

.. figure:: /images/bge_controller_state_panel1.png
:width: 292px

State Panel Visible.

Visible States
==============

In the Visible area, each of the 30 available states is represented by a light-gray square.
This panel shows what logic is visible for the logic brick displayed for the object.
At the right is the All button; if clicked, then all the object's logic bricks are displayed
(this is a toggle), and all State Panel squares are light-gray. Otherwise,
individual states can be clicked to make their logic visible.
(Note that you can click more than one square). Clicking the square again unselects the state.

States for the object that are in use (i.e.
the object has controllers which operate in that state) have dots in them,
and squares are dark-gray if these controllers are shown in the Game Logic display. The
display of their connected sensors and actuators can also be controlled if the State buttons
at the head of their columns are ticked.

.. figure:: /images/bge_controller_state_panel2.png
:width: 292px

State Panel Initial.

Initial State
=============

In the Initial area, each of the 30 available states is again represented by a light-gray square.
One of these states may be clicked as the state in which the object starts when the game is run.

At the right is the |info-button| button; if clicked,
and the :menuselection:`Game --&gt; Show Debug Properties`
is clicked, the current state of the object is shown in the
top left-hand corner of the display while the game is running.
..    TODO/Review: {{review|void=X}}.

**************
Game Materials
**************

Game Settings
=============

.. figure:: /images/materials_properties_game_settings.jpg

Game Settings Panel.

This panel contains properties that control how the object surfaces that use the
material are rendered in real time by the Blender Game Engine.

Backface Cull
Hide the back faces of objects rendered with this material.
If "Off", both sides of the surface are visible (at the expense of lower rendering speed).
Note that this setting is applied per-material and not per-face; e.g.
if the material is applied to a cube, only the back and front faces of the cube are visible,
and not both sides of each face.

Invisible
Hide all faces of objects rendered with this material.

Text
Use material as :doc:`Text object &lt;/modeling/texts/introduction&gt;` in the Game Engine.

Alpha Blend
Controls how the alpha channel is used to create a transparent texture in the rendered image.

Alpha Sort
Orders the sequence in which transparent objects are drawn on top of each other,
so that ones in front receive more light than ones behind.
Alpha Blend
Uses the alpha values present in the bitmap image sourced in the Image slot.
Alpha Clip
Uses the alpha channel as a simple mask.
Add
Render face transparent and add color of face.
Opaque (default)
All alpha values are ignored; the scene is completely non-transparent.

Face Orientation
================

Provides options regarding the orientation (i.e. rotation transformation)
of faces to which the material is applied.

Shadow
Faces are used for shadow.
Billboard
Billboard with Z-axis constraint.
Halo
Screen aligned billboard.
Normal (default)
No transformation.

Material Physics
================

.. figure:: /images/materials-properties-game-physics-settings.png

Panel Physics in Material context.

This panel contains physical properties that control how the object surfaces that use the
material are rendered in real time by the Blender Game Engine.

Physics settings are visible when using the Game Engine for rendering,
and handled by the :doc:`Game Engine's physics engine &lt;/game_engine/physics/index&gt;`

Friction
Coulomb friction coefficient when inside the physics distance area.

Elasticity
The elasticity of collisions determines how much of the kinetic
energy is retained after the collision. A value of 1 will result in
a collision where objects bounce off each other, and the kinetic
energy after the collision is the same as before. A value of 0 will
result in a collision where the objects stick together after the
collision, as all energy will have been converted to heat (or other
energy forms that Blender also does not model).

In macroscopic nature (so bigger than atomic particles) an
elasticity of 1 is never seen, as at least some energy is converted
to heat, sound, etc. An elastic (elasticity=high) collision occurs
when two metal balls collide. An inelastic (elasticity=low)
collision is seen when two half-inflated beach balls collide.

Force Field
Controls force field settings.

Force
Upward spring force when inside the physics distance area.
Distance
Distance of physics area.
Damping
Damping of the spring force when inside the physics distance area.
Align to Normal
Align dynamic game objects along the surface normal when inside the physics distance area.

**************************
Performance Considerations
**************************

When developing games, game engineers, software and hardware developers uses some tools to
fine tune their games to specific platforms and operating systems, defining a basic usage
scenario whereas the users would have the best possible experience with the game.

Most of these tools, are software tools available for the specific Game Engines whereas the
games were being developed and will run.

Blender Game Engine also comes with some visual tools to fine tune the games being developed,
so the game developers could test the best usage scenario and minimum software and hardware
requirements to run the game.

In Blender, those tools are available at the *System* and *Display* panel
of *Render* tab in the *Properties editor*.
There are options for specific performance adjusts and measurements,
ways to control the frame rate or the way the contents are rendered in Blender window
(game viewport) while the game runs,
as well as controls for maintaining geometry allocated in graphic cards memory.

Blender Game Engine rendering system controls:
:ref:`System &lt;game-engine-settings-render-system&gt;` --
Controls for Scene rendering while the game is running.
Blender Game Engine Performance measurements:
:ref:`Display &lt;game-engine-settings-render-display&gt;` --
Controls for showing specific data about performance while the game is running.
.. _game-engine-physics-index:

###########
Physics
###########

.. toctree::
:maxdepth: 2

introduction.rst
world.rst
usage.rst

Physics Types
=============

.. toctree::
:maxdepth: 1

types/static.rst
types/no_collision.rst
types/dynamic.rst
types/rigid_body.rst
types/soft_body.rst
types/vehicle.rst
types/occluder.rst
types/sensor.rst
types/character.rst
types/navigation_mesh.rst

************
Introduction
************

Blender includes advanced physics simulation in the form of the Bullet Physics Engine
(`Bullet Physics &lt;http://bulletphysics.org&gt;`__).
Most of your work will involve setting the right properties on the objects in your scene,
then you can sit back and let
the engine take over. The physics simulation can be used for Games, but also for Animation.

The Blender Game Engine (BGE) is based on Rigid-Body Physics,
which differs significantly from the complementary set of
tools available in the form of Soft Body Physics Simulations. Though the BGE does have a Soft Body type, it is not
nearly as nuanced as the non-BGE Soft Body.
The inverse is even more true: it is difficult to get the non-BGE physics to
resemble anything like a stiff shape.
Rigid Body Physics does not have, as an effect or a cause, any mesh deformations.
For a discussion on how to partially overcome this, see:
`Mesh Deformations`_.

Global Options
==============

The global Physics Engine settings can be found in the :doc:`World Properties &lt;/game_engine/physics/world&gt;`,
which include the Gravity constant and some important engine performance tweaks.

Object Physics
==============

.. figure:: /images/game-engine_physics_introduction_tab-header.png

.. _game-engine-physics-types:

Physics Type
============

:doc:`No Collision &lt;/game_engine/physics/types/no_collision&gt;`
Is not affected by the simulation nor affects other objects.
:doc:`Static &lt;/game_engine/physics/types/static&gt;`
Participates in the simulation, affecting other objects, but is not affected by it.
:doc:`Dynamic &lt;/game_engine/physics/types/dynamic&gt;`
Object that can move besides colliding and being collided with.
:doc:`Rigid Body &lt;/game_engine/physics/types/rigid_body&gt;`
Has rigid body dynamics.
:doc:`Soft Body &lt;/game_engine/physics/types/soft_body&gt;`
Soft body dynamics.
:doc:`Character Controller &lt;/game_engine/physics/types/character&gt;`
Character controller.
:doc:`Vehicle Controller &lt;/game_engine/physics/types/vehicle&gt;`
Vehicle controller.
:doc:`Occluder &lt;/game_engine/physics/types/occluder&gt;`
Prevents calculation of rendered objects (not their physics, though!).
:doc:`Sensor &lt;/game_engine/physics/types/sensor&gt;`
Detects presence without restituting collisions.
:doc:`Navigation Mesh &lt;/game_engine/physics/types/navigation_mesh&gt;`
To make pathfinding paths. Useful for Artificial Intelligence.

Material Physics
================

Physics can be associated with a material on the material properties tab.
These are settings that one would normally associate with a material,
such has its friction and they are meant to be used in conjunction with the object physics
settings, not replace it.

Constraints
===========

It is imperative to understand that the Blender Constraints generally do not work inside the BGE.
This means interesting effects such as *Copy Rotation* are unavailable directly.

Your options include:

- :doc:`Parenting &lt;/editors/3dview/object/properties/relations/parents&gt;` - But not Vertex Parenting.
- :doc:`Rigid Body Joint &lt;/rigging/constraints/relationship/rigid_body_joint&gt;` --
This is the one Constraint that you can set up through the UI that works in the BGE.
It has several options, and can be very powerful -- see ITS page for a detailed description and demo blend-file.
Do not forget that you can loop through objects using ``bpy`` instead of clicking thousands of
times to set up chains of these Constraints.
- Rigid Body Joints on the Fly --
You can add/remove them after the BGE starts by using ``bge.constraints.createConstraint()``.
This can be good either to simply automate their setup, or to truly make them dynamic.
A simple demo can be viewed in: `BGE-Physics-DynamicallyCreateConstraint.blend
&lt;https://wiki.blender.org/index.php/Media:BGE-Physics-DynamicallyCreateConstraint.blend&gt;`__
- :doc:`Python Controllers &lt;/game_engine/logic/controllers/types/python&gt;` -- As always, in the BGE,
you can get the most power when you drop into Python and start toying with the settings directly.
For instance, the *Copy Rotation* mentioned above is not hard --
All you have to do is something to the effect of
``own.worldOrientation = bge.logic.getCurrentScene().objects['TheTargetObject'].worldOrientation``

Visualizing Physics
===================

.. figure:: /images/bge-physics-visualization.png

Go to :menuselection:`Game --&gt; Show Physics Visualization` to show lines representing various attributes
of the Bullet representation of your objects.
Note that these might be easier to see when you turn on Wireframe Mode :kbd:`Z`
before you press :kbd:`P`.
Also note that you can see how the Bullet triangulation is working
(it busts all your Quads to Tris at run-time, but the BGE meshes are still quads at run-time).

- *RGB/XYZ Widget* - Representing the object's Local Orientation and Origin.
- *Green* - "sleeping meshes" that are not moving, saving calculations until an external event "wakes" it.
- *White* - White lines represent active bounding meshes at are undergoing physics calculations,
until such calculations are so small that the object is put to rest.
This is how you can see the effects of the *Collision Bounds*.
- *Thick*, or *Many White Lines* - A compound collision mesh/meshes.
- *Violet* - Bounding meshes for Soft bodies.
- *Red* - The Bounding Box, the outer boundary of object.
It is always aligned with global X Y and Z, and is used to optimize calculations.
Also represents meshes that have been forced into "no sleep" status.
- *Yellow* - Normals.
- *Black* - When in wireframe, this is your mesh's visual appearance.

If you want finer-grained control over the display options,
you can add this as a Python Controller and uncomment whichever pieces you want to see::

import bge
debugs = (
bge.constraints.DBG_DRAWAABB,
)
for d in debugs:
bge.constraints.setDebugMode(d)

For all debug modes, API docs for ``bge.constraints``.

Show Framerate and Profile
--------------------------

.. figure:: /images/bge-physics_profilestats.jpg

A shot of `Manual-BGE-Physics-DancingSticks.blend
&lt;https://wiki.blender.org/index.php/Media:Manual-BGE-Physics-DancingSticks.blend&gt;`__ with
:menuselection:`Game --&gt; Show Framerate and Profile` enabled.

If you enable :menuselection:`Game --&gt; Show Framerate and Profile`,
it will put some statistics in the upper-left area of the game window.

.. seealso::

These can be very informative, but also a bit cryptic. Moguri has elaborated on their meanings, for us:
`Moguris blog &lt;https://mogurijin.wordpress.com/2012/01/03/bge-profile-stats-and-what-they-mean/&gt;`__.

Mesh Deformations
=================

As mentioned above, Rigid Body physics do not affect mesh deformations,
nor do they account for them in the physics model. This leaves you with a few options:

Soft Bodies
-----------

You can try using a :doc:`Soft Body &lt;/game_engine/physics/types/soft_body&gt;`,
but these are fairly hard to configure well.

Actions
-------

To use an :doc:`Action Actuator &lt;/game_engine/logic/actuators/types/action&gt;`
to do the deformation, you have to make a choice. If you use Shapekeys in the Action,
you will be fine as far as the overall collisions (but see below for the note on ``reinstancePhysicsMesh()``).
The mesh itself is both a display and a physics mesh, so there is not much to configure.

To use an Armature as the deformer will require a bit of extra thought and effort.
Basically the Armature will only deform a mesh if the Armature is the parent of that mesh.
But at that point, your mesh will lose its physics responsivenes, and only hang in the air
(it is copying the location/rotation of the Armature).
To somewhat fix this you can then parent the Armature to a collision mesh
(perhaps a simple box or otherwise very-low-poly mesh).
This "Deformation Mesh" will be the physics representative, being type: Dynamic or Rigid Body,
but it will be set to Invisible. Then "Display Mesh" will be the opposite set to *No Collision*,
but visible. This still leaves the problem mentioned in the previous paragraph.

When you deform a display mesh, it does not update the corresponding physics mesh.
You can view this evidently when you
enable physics visualization (`Visualizing Physics`_) -- the collision bounds will remain exactly as when they began.
To fix this, you must call ``own.reinstancePhysicsMesh()`` in some form.
Currently this only works on *Triangle Mesh* bounds, not *Convex Hull*.
We have prepared a demonstration file in
`Manual-BGE-Physics-DancingSticks.blend
&lt;https://wiki.blender.org/index.php/Media:Manual-BGE-Physics-DancingSticks.blend&gt;`__.
Note that we had to increase the
:menuselection:`World --&gt; Physics --&gt; Physics Steps --&gt; Substeps` to make the collisions work well.
The more basic case is the case the Shapekeyed Action, which you can see in the back area of the scene.
Since it is the only object involved, you can call ``reinstancePhysicsMesh()`` unadorned,
and it will do the right thing.

The more complicated case is the :menuselection:`Collision Mesh --&gt; Armature --&gt; Display Mesh` cluster,
which you can see in the front of the scene.
What it does in the blend-file is call ``reinstancePhysicsMesh(viz)``,
that is, passing in a reference to the visual mesh.
If we tried to establish this relationship without the use of Python,
we would find that Blender's dependency check system would reject it as a cyclic setup.
This is an example of where Blender's checking is too coarsely-grained,
as this circle is perfectly valid: the grandparent object (the Collision Mesh)
controls the location/rotation, while the middle object (the Armature)
receives the animated Action, where the child (the Display Mesh) receives the deformation,
and passes that on up to the top, harmlessly. Something to note is that the Collision Mesh is
merely a plane -- that is all it requires for this,
since it will be getting the mesh data from ``viz``.

Ragdolls
--------

A third option is to create your items out of many sub-objects, connected together with Rigid Body Joints or similar.
This can be quite a bit more work, but the results can be much more like a realistic response to collisions.
For an Add-on that can help you out in the process, check out the
`Blender Ragdoll Implementation Kit
&lt;https://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts/Game_Engine/BRIK_ragdolls&gt;`__.

.. _game-engine-physics-bake-keyframes:

Digging Deeper
==============

Sometimes you will want to look at:

- The `main Bullet Physics page &lt;http://bulletphysics.org/wordpress/&gt;`__
- The `Bullet Wiki &lt;http://www.bulletphysics.org/mediawiki-1.5.8/index.php?title=Documentation&gt;`__
- The `Bullet API Docs &lt;http://www.continuousphysics.com/Bullet/BulletFull/index.html&gt;`__
- The `Bullet Forums &lt;http://www.bulletphysics.org/Bullet/phpBB3/&gt;`__

Recording to Keyframes
======================

Beyond gaming, sometimes you wish to render a complex scene that involves collisions,
multiple forces, friction between multiple bodies,
and air drag or even a simple setup that is just easier to achieve using the realtime physics.

Blender provides a way to ''bake'' or ''record'' a physics simulation into keyframes
allowing it then to be played as an action either for animation or games.
Keep in mind that the result of this method is a recording, no longer a simulation.
This means that the result is completely deterministic
(the same everytime it is run) and unable to interact with
new objects that are added to the physics simulation after it was recorded.
This may, or not, be desired according to the situation.

.. figure:: /images/bge-physics-recordanimation.png

Menu to record Keyframes to the Dopesheet.

All you have to do to achieve this effect is go to the Info Editor
(the bar at the top of the window) :menuselection:`Game --&gt; Record Animation`,
and it will lock away your keyframes for use in *Blender Render* mode.
You can go back to the 3D View and press :kbd:`Alt-A` to play it back,
or :kbd:`Ctrl-F12` to render it out as an animation.

Note that you can also use Game Logic Bricks and scripting. Everything will be recorded.

Keyframe Clean-up
-----------------

.. figure:: /images/bge-physics-dopesheetfull.png

Resulting recorded animation.

*Record Animation* keys redundant data (data that was did not change relative to the last frame).
Pressing :kbd:`O` while in the *DopeSheet* will remove all superfluous keyframes.
Unwanted channels can also be removed.

.. figure:: /images/bge-physics-dopesheetcleaned.png

Cleaned up recording.

Exporting
=========

.bullet / Bullet compatible engines
-----------------------------------

You can snapshot the physics world at any time with the following code::

import bge
bge.constraints.exportBulletFile("test.bullet")

This will allow importing into other Bullet-based projects. See the
`Bullet Wiki on
Serialization &lt;http://bulletphysics.org/mediawiki-1.5.8/index.php/Bullet_binary_serialization&gt;`__ for more.

*****************
Character Physics
*****************

The character physics type is used for player-controlled characters,
for which the other physics types often result unexpected results
(bouncing off walls, sliding etc.) and for which simple kinematics offer much more precision.

Properties
==========

Step Height
The maximum height of steps the character can run over.
Jump Force
Upward velocity applied to character when jumping.
Fall Speed Max
Maximum speed at which the character will fall.
Max Jumps
Maximum number of jumps the character can make before it hits the ground.

.. note::

Obstacle traversal (e.g. step climbing) is governed by (in order of importance):

- The velocity of the character object
- The shape and margin of the collision bounds (character and obstacle)
- The *Step Height* parameter
- The leading slope of the obstacle

Character fall speed is governed by (in order of importance):

- The *Fall Speed Max* parameter
- The *Step Height* parameter (more *Step Height* -&gt; more fall speed)

Example
=======

Todo

***************
Dynamic Physics
***************

Dynamic objects in the :doc:`Game Engine &lt;/game_engine/index&gt;` give/receive collisions,
but when they do so they themselves do not rotate in response.
So, a Dynamic ball will hit a ramp and slide down, while a Rigid Body ball would begin rotating.

If you do not need the rotational response the Dynamic type can save the extra computation.

Note that these objects can still be rotated with :doc:`Logic Bricks &lt;/game_engine/logic/index&gt;` or Python code.
Their physics meshes will update when you do these rotations -- so collisions will be based on the new orientations.

For more documentation, see the :doc:`Top BGE Physics page &lt;/game_engine/physics/index&gt;`.

Options
=======

.. note::  bpy Access

Note that most of these properties are accessible through the non-
BGE scripting API via ``bpy.data.objects["ObjectName"].game``,
which is of type ``bpy.types.GameObjectSetting``. This is useful so you can,
for example, set a range of objects to have gradated values via a for-loop.

Actor
Enables detection by Near and Radar Sensors. Python property: ``obj.game.use_actor``
Ghost
Disables collisions completely, similar to :doc:`No collision &lt;/game_engine/physics/types/no_collision&gt;`.
Invisible
Does not display, the same as setting the object to unrendered (such as unchecking the "Camera"
icon in the :doc:`Outliner &lt;/editors/outliner&gt;`. Python property: ``obj.use_render``
Use Material Force Field
Materials can have physics settings on them as well: Friction, Elasticity,
Force Field (positive or negative force), and also Dampening to other materials.
When you turn on this checkbox, you are enabling the Material to exhibit this spring force.
Python property: ``obj.game.use_material_physics_fh``
Rotate From Normal
Todo Python property: ``obj.game.use_rotate_from_normal``
No Sleeping
Prevents simulation meshes from sleeping. When an object has a linear velocity or angular velocity,
it is in motion. It will detect collisions, receive gravity, etc. Once these thresholds are close to zero,
it will cease these calculations -- until another object interacts with it wake it up.
Python property: ``obj.game.use_sleep``
Mass
Affects the reaction due to collision between objects -- more massive objects have more inertia.
Will also affect material force fields.
Will also change behaviors if you are using the suspension and steering portions of Bullet physics.
Python property: ``obj.game.mass``
Radius
If you have the "Collision Bounds: Sphere"
set explicitly (or implicitly through having the Collision Bounds subpanel unchecked),
this will multiply with the Object's (unapplied) Scale. Note that none of the other bounds types are affected.
Also note that in the 3D View the display will show this for all types,
even though it is only actually used with Sphere. Python property: ``obj.game.radius``

.. list-table::
:header-rows: 1

* - Basic
- Radius= 1.5
- Unapplied Scale
- Applied Scale
- Collision Bounds

* - Rolls, radius of 1 BU
- Rolls, radius of 1.5 BU (after "popping" upward)
- Rolls, radius of 1.5 BU
- Rolls, radius of 1 BU (!)
- Default (which is Sphere)

* - Slides, extent of 1 BU
- Slides, extent of 1 BU
- Slides, extent of 1 BU
- Slides, extent of 1 BU
- Box

* - ""
- ""
- ""
- ""
- Convex Hull

* - Slides, extent of 1 BU (but with more friction than above)
- Slides, extent of 1 BU (but with more friction than above)
- Acts insane
- Slides extent of 1.5 BU
- Triangle Mesh

Form Factor
For affecting the Inertia Tensor. The higher the value, the greater the rotational inertia,
and thus the more resistant to torque. You might think this is strange,
considering Dynamic types do not have torque in response to collisions --
but you can still see this value's effects when you manually apply Torque.
Python property: ``obj.game.form_factor``
Anisotropic Friction
Isotropic friction is identical at all angles. Anisotropic is directionally-dependant.
Here you can vary the coefficients for the three axes individually, or disable friction entirely.
Python properties: ``obj.game.use_anisotropic_friction``
(boolean) and ``obj.game.friction_coefficients`` (a 3-element array).
Velocity
Limit the speed of an object 0 - 1000.

Minimum
The object is allowed to be at complete rest,
but as soon as it accelerates it will immediately jump to the minimum speed.
Python property: ``obj.game.velocity_min``
Maximum
Top speed of the object.  Python property: ``obj.game.velocity_max``
Damping- Increase the "sluggishness" of the object.
Translation
Resist movement 0 - 1. At "1" the object is completely immobile. Python property: ``obj.game.damping``
Rotation
Resist rotation, but not the kind of rotation that comes from a collision. For example,
if a Motion Controller applies Torque to an object, this damping will be a factor.
Python property: ``obj.game.rotation_damping``
Lock Translation
Seize the object in the world along one or more axes.
Note that this is global coordinates, not local or otherwise.

- X Python property: ``obj.game.lock_location_x``
- Y Python property: ``obj.game.lock_location_y``
- Z Python property: ``obj.game.lock_location_z``
Lock Rotation
Same, but for rotation (also with respect to the global coordinates).

- X Python property: ``obj.game.lock_rotation_x``
- Y Python property: ``obj.game.lock_rotation_y``
- Z Python property: ``obj.game.lock_rotation_z``

.. _game-engine-physics-object-collision-bounds:

Collision Bounds
================

The first thing you must understand is the idea of the 3D Bounding Box.
If you run through all the vertices of a mesh and record the lowest and highest x values,
you have found the *x min/max* the complete boundary for all x values within the mesh.
Do this again for y and z, then make a rectangular prism out of these values, and you have a *Bounding Box*.
This box could be oriented relative globally to the world or locally to the object's rotation.

.. figure:: /images/bge-physics-boundingbox.png

Demonstration of a Local Bounding Box (left) and a Global Bounding Box (right).

The *x extent*, then, is half of the distance between the x min/max.

Throughout all of this you must be cognizant of the Object Origin. For the Game engine,
the default :kbd:`Ctrl-Alt-Shift-C`, :kbd:`3` or :menuselection:`Set Origin --&gt; Origin to Geometry`
is unlikely to get the desired placement of the Collision Bounds that you want.
Instead, you should generally set the origin by looking at the Tool Shelf after you do the *Set Origin*,
and changing the *Center* from *Median Center* to *Bounds Center*.
Blender will remember this change for future :kbd:`Ctrl-Alt-Shift-C` executions.

All Collision Bounds are centered on this origin. All boxes are oriented locally, so object rotation matters.

.. figure:: /images/bge-physics-origintoboxbounds.png

Setting the origin to Bounds Center instead of Median Center.

A final introductory comment: When you set the Collision Bounds on an object,
Blender will attempt to display a visualization of the bounds in the form of a dotted outline.
Currently, there is a bug: *The 3D View*
does not display this bounds preview where it actually will be during the game.
To see it, go to :menuselection:`Game --&gt; Show Physics Visualization`
and look for the white (or green, if sleeping) geometry.

Now we can explain the various options for the *Collision Bounds* settings:

Default
For Dynamic and Static objects, it is a Triangle Mesh (see below).
For everything else, it is a Sphere (see below).
Capsule
Which is a cylinder with hemispherical caps, like a pill.
Radius of the hemispheres is the greater of the X or Y extent.
Height is the Z bounds.
Box
The X, Y, Z bounding box, as defined above.
Sphere
Radius is defined by the object's scale (visible in the N properties panel) times the physics radius
(can be found in :menuselection:`Physics --&gt; Attributes --&gt; Radius`.
Note: This is the only bounds that respects the Radius option.
Cylinder
Radius is the greater of the x or y extent.
Height is the z bounds.
Cone
Base radius is the greater of the x or y extent.
Height is the z bounds.
Convex Hull
Forms a shrink-wrapped, simplified geometry around the object.

.. figure:: /images/bge-physics-convexhull.png

A convex hull sketch.

Triangle mesh
Most expensive, but most precise. Collision will happen with all of triangulated polygons,
instead of using a virtual mesh to approximate that collision.
By Hand
This is not an option in the Physics tab's Collision Bounds settings, but a different approach, entirely.
You create a second mesh, which is invisible, to be the physics representation.
This becomes the parent for your display object. Then,
your display object is set to ghost so it does not fight with the parent object.
This method allows you to strike a balance between the accuracy of *Triangle Mesh*
with the efficiency of some of the others. See the demo of this in the dune buggy to the right.

.. figure:: /images/bge-physics-manualhull.png

Another way to create Collision Bounds -- By hand.

Options
-------

There are only two options in the Collision Bounds subpanel.

Margin
"Add extra margin around object for collision detection, small amount required for stability."
If you find your objects are getting stuck in places they should not, try increasing this to, say, 0.06.

Sometimes 0.06 is the default (such as on the Default Cube), but sometimes it is not.
You have to keep an eye on the setting, or else learn the symptoms so you can respond when it gives you trouble.
If you are lazy/paranoid/unsure/diligent/bored,
you can always run this on the Python Console to bump all 0.0 margins to 0.06: for
``obj`` in ``bpy.data.objects``: ``obj.game.collision_margin = obj.game.collision_margin`` or 0.06
Compound
"Add children to form compound collision object." Basically,
if you have a child object and do not have this enabled,
the child's collisions will not have an effect on that object "family"
(though it will still push other objects around). If you do have it checked,
the parent's physics will respond to the child's collision (thus updating the whole family).
Python property: ``obj.game.use_collision_compound``

Create Obstacle
===============

Todo

***********************
Navigation Mesh Physics
***********************

Path-finding in Blender is based on the concept of `navigation meshes &lt;http://en.wikipedia.org/wiki/Navigation_mesh&gt;`.
Now you can create navigation mesh for your level geometry directly in Blender and use it in Blender Game Engine (BGE)
to get your actors to find path to the target and move along it. Besides path following,
there are also a few other steering behaviors which can be assigned to the actor: *seek* and *flee*.
Path-finding with navigation mesh is effective for big static obstacles.
To enable actors to avoid small dynamic objects during their movement local obstacle avoidance can be used.
If the obstacle simulation is enabled the actor will try to choose direction which is free of collision
with obstacles on each frame during execution one of the steering behaviors.

Options
=======

NavMesh Copy Face Index
Copies the navigation polygon index from the active face to selected faces.
NavMesh New Face Index
Adds a new navigation polygon index to selected faces.

NavMesh Reset Index Values
Assigns a new index to every faces.
NavMesh Clear Data
Removes the navigation data from the mesh.

********************
No Collision Physics
********************

"No Collision" objects in the :doc:`Game Engine &lt;/game_engine/index&gt;` are completely unaffected by
:doc:`Physics &lt;/game_engine/physics/index&gt;`, and do not cause physics reactions.
They are useful as pure display objects, such as the child of a *Custom Collision Hull*
(:ref:`game-engine-physics-object-collision-bounds`).

For more documentation, see the :doc:`Top BGE Physics page &lt;/game_engine/physics/index&gt;`.

Options
=======

The only option available on No Collision types is:

Invisible
Does not display, the same as setting the object to unrendered
(such as unchecking the "Camera" icon in the Outliner). Python property: ``obj.use_render``

**********************
Occlude Object Physics
**********************

If an Occlude type object is between the camera and another object,
that other object will not be rasterized (calculated for rendering).
It is culled because it is occluded.

There is a demo blend-file to exemplify some concepts:
`BGE-Physics-Objects-Occluder.blend &lt;https://wiki.blender.org/index.php/Media:BGE-Physics-Objects-Occluder.blend&gt;`__

- A messed-up, subdivided Cube named "Cube".
- Another one behind a "Physics Type: Occlude" plane, named "Cube.BG".
- Another one outside the view Frustum, named "Cube.OffCamera".

Now observe what happens to the profiling stats for each of the following (in order):

#. Hit :kbd:`P` as the scene is. It hums along at a fairly slow rate. On my system the Rasterizer step takes 130ms.
The framerate will finally jump up once the "Cube" object has completely moved out of the view frustum.
It is as if the Occluder does not do anything while the Cube is behind it.
#. Delete the "Cube.OffCamera" object above,
and notice that there is no improvement in speed.
This is the view frustum culling working for you -- it does not matter if that object exists or not.
#. Hit :kbd:`Z` to view wireframe. Notice that in the 3D View you can see "Cube.BG",
but once you press :kbd:`P`, it is not there.
#. Make the "Occluder" object take up the whole camera's view with :kbd:`S-X-5`.
You will see a huge leap in framerate,
since almost nothing is being Rasterized. On my system the Rasterizer step drops to 5ms.
#. Try a run with :menuselection:`World properties --&gt; Physics --&gt; Occlusion Culling` disabled. It will be slow again.
#. Reenable :menuselection:`World properties --&gt; Physics --&gt; Occlusion Culling`
and run it one more time to prove to yourself that your speed is back.
#. Change the Occluder to "Physics Type: Static". Notice that it is back to the original slowness.
#. Change it back to "Physics Type: Occlude".
#. Now make the "Occluder" invisible. The framerate is back down to its original, slow rate.

.. ??? - I thought this was supposed to work when invisible.

.. Incorporate some of the details from:
Dev:Ref/Release_Notes/2.49/Game_Engine#BGE_Scenegraph_improvement|2.49 Release Notes

Details
=======

As far as Physics is concerned, this type is equivalent to Rigid Object "No collision". The
reason why the Occluder mode is mutually exclusive with other physics mode is to emphasize
the fact that occluders should be specifically designed for that purpose and not every mesh
should be an occluder. However,
you can enable the Occlusion capability on physics objects using Python and Logic bricks.
See (Link- TODO).

When an occluder object enters the view frustum,
the BGE builds a Z-Depth buffer from the faces of that object.
Whether the faces are one-side or two-side is important:
only the front faces and two-side faces are used to build the Z-Depth buffer.
If multiple occluders are in the view frustum,
the BGE combines them and keeps the most foreground faces.

The resolution of the Z-Depth buffer is controllable in the World settings with
the "Occlusion Culling Resolution" button:

By default the resolution is 128 pixels for the largest dimension of the viewport while the
resolution of the other dimension is set proportionally.
Although 128 is a very low resolution, it is sufficient for the purpose of culling.
The resolution can be increased to maximum 1024 but at great CPU expense.

The BGE traverses the DBVT (Dynamic Bounding Volume Tree)
and for each node checks if it is entirely hidden by the occluders and if so, culls the node
(and all the objects it contains).

To further optimize the feature, the BGE builds and uses the Z-Depth buffer only when at least
one occluder is in the view frustum. Until then,
there is no performance decrease compared to regular view frustum culling.

Recommendations
===============

Occlusion culling is most useful when the occluders are large objects (buildings, mountains...)
that hide many complex objects in an unpredictable way. However,
do not be too concerned about performance: even if you use it inappropriately,
the performance decrease will be limited due to the structure of the algorithm.

There are situations where occlusion culling will not bring any benefit:

- If the occluders are small and do not hide many objects.

- In that case, occlusion culling is just dragging your CPU down).

- If the occluders are large but hides simple objects.

- In that case you are better off sending the objects to the GPU).

- If the occluders are large and hides many complex objects but in a very predictable way.

- Example: a house full of complex objects. Although occlusion culling will perform well in this case,
you will get better performance by implementing a specific logic that hides/unhides the objects;
for instance making the objects visible only when the camera enters the house).

- Occluders can be visible graphic objects but beware that too many faces will make the Z Depth buffer creation slow.

- For example, a terrain is not a good candidate for occlusion: too many faces and too many overlap.
Occluder can be invisible objects placed inside more complex objects
(ex: "in the walls" of a building with complex architecture).
Occluders can have "holes" through which you will see objects.
.. xxx this is the same as game_engine/physics/object/dynamic.rst

******************
Rigid Body Physics
******************

Probably the most common type of object in the :doc:`Game Engine &lt;/game_engine/index&gt;`.
It will give/receive collisions and react with a change in its velocity and its rotation.
A Rigid Body ball would begin rotating and roll down
(where a :doc:`Dynamic &lt;/game_engine/physics/types/dynamic&gt;` ball would only hit and slide down the ramp).

The idea behind Rigid Body dynamics is that the mesh does not deform.
If you need deformation you will need to either go to
:doc:`Soft Body &lt;/game_engine/physics/types/soft_body&gt;` or else fake it with animated Actions.

For more documentation, see the :doc:`Top BGE Physics page &lt;/game_engine/physics/index&gt;`.

Options
=======

.. note::  bpy Access

Note that most of these properties are accessible through the non-
BGE scripting API via ``bpy.data.objects["ObjectName"].game``,
which is of type ``bpy.types.GameObjectSetting``. This is useful so you can,
for example, set a range of objects to have gradated values via a for-loop.

Actor
Enables detection by Near and Radar Sensors. Python property: ``obj.game.use_actor``
Ghost
Disables collisions completely, similar to :doc:`No collision &lt;/game_engine/physics/types/no_collision&gt;`.
Invisible
Does not display, the same as setting the object to unrendered (such as unchecking the "Camera"
icon in the :doc:`Outliner &lt;/editors/outliner&gt;`. Python property: ``obj.use_render``
Use Material Force Field
Materials can have physics settings on them as well: Friction, Elasticity,
Force Field (positive or negative force), and also Dampening to other materials.
When you turn on this checkbox, you are enabling the Material to exhibit this spring force.
Python property: ``obj.game.use_material_physics_fh``
Rotate From Normal
Todo Python property: ``obj.game.use_rotate_from_normal``
No Sleeping
Prevents simulation meshes from sleeping. When an object has a linear velocity or angular velocity,
it is in motion. It will detect collisions, receive gravity, etc. Once these thresholds are close to zero,
it will cease these calculations -- until another object interacts with it wake it up.
Python property: ``obj.game.use_sleep``
Mass
Affects the reaction due to collision between objects -- more massive objects have more inertia.
Will also affect material force fields.
Will also change behaviors if you are using the suspension and steering portions of Bullet physics.
Python property: ``obj.game.mass``
Radius
If you have the "Collision Bounds: Sphere"
set explicitly (or implicitly through having the Collision Bounds subpanel unchecked),
this will multiply with the Object's (unapplied) Scale. Note that none of the other bounds types are affected.
Also note that in the 3D View the display will show this for all types,
even though it is only actually used with Sphere. Python property: ``obj.game.radius``

.. list-table::
:header-rows: 1

* - Basic

- Radius= 1.5
- Unapplied Scale
- Applied Scale
- Collision Bounds

* - Rolls, radius of 1 BU
- Rolls, radius of 1.5 BU (after "popping" upward)
- Rolls, radius of 1.5 BU
- Rolls, radius of 1 BU (!)
- Default (which is Sphere)

* - Slides, extent of 1 BU
- Slides, extent of 1 BU
- Slides, extent of 1 BU
- Slides, extent of 1 BU
- Box

* - ""
- ""
- ""
- ""
- Convex Hull

* - Slides, extent of 1 BU (but with more friction than above)
- Slides, extent of 1 BU (but with more friction than above)
- Acts insane
- Slides extent of 1.5 BU
- Triangle Mesh

Form Factor
For affecting the Inertia Tensor. The higher the value, the greater the rotational inertia,
and thus the more resistant to torque. You might think this is strange,
considering Dynamic types do not have torque in response to collisions --
but you can still see this value's effects when you manually apply Torque.
Python property: ``obj.game.form_factor``
Anisotropic Friction
Isotropic friction is identical at all angles. Anisotropic is directionally-dependant.
Here you can vary the coefficients for the three axes individually, or disable friction entirely.
Python properties: ``obj.game.use_anisotropic_friction``
(boolean) and ``obj.game.friction_coefficients`` (a 3-element array).
Velocity- Limit the speed of an object 0 - 1000.
Minimum
The object is allowed to be at complete rest,
but as soon as it accelerates it will immediately jump to the minimum speed.
Python property: ``obj.game.velocity_min``
Maximum
Top speed of the object.  Python property: ``obj.game.velocity_max``
Damping- Increase the "sluggishness" of the object.
Translation
Resist movement (0 - 1). At "1" the object is completely immobile. Python property: ``obj.game.damping``
Rotation
Resist rotation, but not the kind of rotation that comes from a collision. For example,
if a Motion Controller applies Torque to an object, this damping will be a factor.
Python property: ``obj.game.rotation_damping``
Lock Translation
Seize the object in the world along one or more axes.
Note that this is global coordinates, not local or otherwise.

- X Python property: ``obj.game.lock_location_x``
- Y Python property: ``obj.game.lock_location_y``
- Z Python property: ``obj.game.lock_location_z``

Lock Rotation
Same, but for rotation (also with respect to the global coordinates).

- X Python property: ``obj.game.lock_rotation_x``
- Y Python property: ``obj.game.lock_rotation_y``
- Z Python property: ``obj.game.lock_rotation_z``

Collision Bounds
================

The first thing you must understand is the idea of the 3D Bounding Box.
If you run through all the vertices of a mesh and record the lowest and highest x values,
you have found the *x min/max* the complete boundary for all x values within the mesh.
Do this again for y and z, then make a rectangular prism out of these values, and you have a *Bounding Box*.
This box could be oriented relative globally to the world or locally to the object's rotation.

.. figure:: /images/bge-physics-boundingbox.png

Demonstration of a Local Bounding Box (left) and a Global Bounding Box (right).

The *x extent*, then, is half of the distance between the x min/max.

Throughout all of this you must be cognizant of the Object Origin. For the Game engine,
the default :kbd:`Ctrl-Alt-Shift-C`, :kbd:`3` or :menuselection:`Set Origin --&gt; Origin to Geometry`
is unlikely to get the desired placement of the Collision Bounds that you want.
Instead, you should generally set the origin by looking at the Tool Shelf after you do the *Set Origin*,
and changing the *Center* from *Median Center* to *Bounds Center*.
Blender will remember this change for future :kbd:`Ctrl-Alt-Shift-C` executions.

All Collision Bounds are centered on this origin. All boxes are oriented locally, so object rotation matters.

.. figure:: /images/bge-physics-origintoboxbounds.png

Setting the origin to Bounds Center instead of Median Center.

A final introductory comment: When you set the Collision Bounds on an object,
Blender will attempt to display a visualization of the bounds in the form of a dotted outline.
Currently, there is a bug: *The 3D View*
does not display this bounds preview where it actually will be during the game.
To see it, go to :menuselection:`Game --&gt; Show Physics Visualization`
and look for the white (or green, if sleeping) geometry.

Now we can explain the various options for the *Collision Bounds* settings:

Default
For Dynamic and Static objects, it is a Triangle Mesh (see below).
For everything else, it is a Sphere (see below).
Capsule -- A cylinder with hemispherical caps, like a pill.
Radius of the hemispheres is the greater of the X or Y extent.
Height is the Z bounds
Box
The X, Y, Z bounding box, as defined above.
Sphere
Radius is defined by the object's scale (visible in the N properties panel) times the physics radius
(can be found in :menuselection:`Physics --&gt; Attributes --&gt; Radius`.
Note: This is the only bounds that respects the Radius option.
Cylinder
Radius is the greater of the x or y extent.
Height is the z bounds.
Cone
Base radius is the greater of the x or y extent.
Height is the z bounds.
Convex Hull
Forms a shrink-wrapped, simplified geometry around the object.

.. figure:: /images/bge-physics-convexhull.png
:width: 200px

A convex hull sketch.

Triangle mesh
Most expensive, but most precise. Collision will happen with all of triangulated polygons,
instead of using a virtual mesh to approximate that collision.
By Hand
This is not an option in the Physics tab's Collision Bounds settings, but a different approach, entirely.
You create a second mesh, which is invisible, to be the physics representation.
This becomes the parent for your display object. Then,
your display object is set to ghost so it does not fight with the parent object.
This method allows you to strike a balance between the accuracy of *Triangle Mesh*
with the efficiency of some of the others. See the demo of this in the dune buggy to the right.

.. figure:: /images/bge-physics-manualhull.png
:width: 300px

Another way to create Collision Bounds -- By hand.

Options
-------

There are only two options in the Collision Bounds subpanel.

Margin
"Add extra margin around object for collision detection, small amount required for stability."
If you find your objects are getting stuck in places they should not, try increasing this to, say, 0.06.

Sometimes 0.06 is the default (such as on the Default Cube), but sometimes it is not.
You have to keep an eye on the setting, or else learn the symptoms so you can respond when it gives you trouble.
If you are lazy/paranoid/unsure/diligent/bored,
you can always run this on the Python Console to bump all 0.0 margins to 0.06: for
``obj`` in ``bpy.data.objects``: ``obj.game.collision_margin = obj.game.collision_margin`` or 0.06
Compound
"Add children to form compound collision object." Basically,
if you have a child object and do not have this enabled,
the child's collisions will not have an effect on that object "family"
(though it will still push other objects around). If you do have it checked,
the parent's physics will respond to the child's collision (thus updating the whole family).
Python property: ``obj.game.use_collision_compound``

Create Obstacle
===============

Todo
..    TODO/Review: {{review|partial=X|text=sections}}.

**************
Sensor Physics
**************

The object detects static and dynamic objects but not other collisions sensors objects.
The Sensor is similar to the physics objects that underlie the Near and Radar sensors.
Like the Near and Radar object it is:

- Static and ghost.
- Invisible by default.
- Always active to ensure correct collision detection.
- Capable of detecting both static and dynamic objects.
- Ignoring collision with their parent.
- Capable of broadphase filtering based on:

- Actor option: the collisioning object must have the Actor flag set to be detected
- property/material: as specified in the collision sensors attached to it.

Broadphase filtering is important for performance reason:
the collision points will be computed only for the objects that pass the broadphase filter.

- Automatically removed from the simulation when no collision sensor is active on it.

Unlike the Near and Radar object it can:

- Take any shape, including triangle mesh.
- Be made visible for debugging (just use the Visible actuator).
- Have multiple collision sensors using it.

Other than that, the sensor objects are ordinary objects.
You can move them freely or parent them. When parented to a dynamic object,
they can provide advanced collision control to this object.

The type of collision capability depends on the shape:

- Box, sphere, cylinder, cone, convex hull provide volume detection.
- Triangle mesh provides surface detection but you can give some volume to
the surface by increasing the margin in the Advanced Settings panel.
The margin applies on both sides of the surface.

.. rubric:: Performance tip

- Sensor objects perform better than Near and Radar:
they do less synchronizations because of the Scenegraph optimizations and they can
have multiple collision sensors on them (with different property filtering for example).
- Always prefer simple shape (box, sphere) to complex shape whenever possible.
- Always use broadphase filtering (avoid collision sensor with empty property/material).
- Use collision sensor only when you need them. When no collision sensor is active on the sensor object,
it is removed from the simulation and consume no CPU.

.. rubric:: Known limitations

- When running Blender in debug mode, you will see one warning line of the console:

.. code-block:: sh

warning btCollisionDispatcher::needsCollision: static-static collision!
In release mode this message is not printed.

- Collision margin has no effect on sphere, cone and cylinder shape.

Settings
========

Invisible
See :doc:`Here &lt;/game_engine/physics/types/static&gt;`

Collision Bounds
================

See :ref:`Here &lt;game-engine-physics-types&gt;`.

*****************
Soft Body Physics
*****************

The most advanced type of object in the :doc:`Game Engine &lt;/game_engine/index&gt;`.
Also, it is the most finicky. If you are used to the fun experimentation
that comes from playing around with the non-BGE Soft Body sims (such as Cloth),
you will probably find a frustrating lack of options and exciting results.
Do not despair, we are here to help you get some reasonable settings.

Your setup will involve making sure you have sufficient geometry in the Soft Body's mesh to
support the deformation, as well as tweaking the options.

Options
=======

Actor
Enables detection by Near and Radar Sensors.

- Default: On.
- Python property: ``obj.game.use_actor``
Ghost
Disables collisions completely, similar to No Collision.

- Default: Off.
- Python property: ``obj.game.use_ghost``
Invisible
Does not display, the same as setting the object to unrendered
(such as unchecking the "Camera" icon in the Outliner).

- Default: Off.
- Python property: ``obj.use_render``

Mass
Affects the reaction due to collision between objects --
more massive objects have more inertia. Will also affect material force fields.
Will also change behaviors if you are using the suspension and steering portions of Bullet physics.

- Range: 0.01 - 10,000.
- Default: 1.
- Python property: ``obj.game.mass``

Shape Match
Upon starting the Game Engine this will record the starting shape of the mesh as the "lowest energy" state.
This means that the edges will have tension whenever they are flexed to some other form.
This is set to on by default,
and in this configuration turns the object into more of a thin sheet of metal rather than a cloth.

- Default: On.
- Python property: ``obj.game.soft_body.use_shape_match``
Threshold
`Linearly scales the pose match
&lt;http://www.continuousphysics.com/Bullet/BulletFull/btSoftBody_8cpp_source.html#l01566&gt;`__.

- A threshold of 1.0 makes it behave like *Shape Match* on with a *Linear Stiffness* of 1.0.
- A threshold of 0.0 makes it behave like *Shape Match* off with a *Linear Stiffness* of 0.0.
- Range: 0-1.
- Default: 0.5.
- Python property: ``obj.game.soft_body.shape_threshold``
Welding
TODO.
Position Iteration
Increase the accuracy at a linearly-increasing expense of time.
The effect is visible especially with Soft Bodies that fall on sharp corners,
though this can slow down even very simple scenes.

- Range: 0-10.
- Default: 2.
- Python property: ``obj.game.soft_body.location_iterations``
Linear Stiffness
Linear stiffness of the soft body links.
This is most evident when you have *Shape Match* off, but it is also evident with it on.

- Range: 0-1.
- Default: 0.5.
- Python property: ``obj.game.soft_body.linear_stiffness``

Friction
Dynamic friction coefficient.

.. TODO: Learn/demo/explain.

- Range: 0-1.
- Default: 0.2.
- Python property: ``obj.game.soft_body.dynamic_friction``

Margin
Small value makes the algorithm unstable.

.. TODO: Learn/demo/explain.

- Range: 0.01-1.
- Default: 0.01.
- Python property: ``obj.game.soft_body.collision_margin``

Bending Constraint
Enable Bending Constraints.

.. TODO: Learn/demo/explain.

- Default: On.
- Python property: ``obj.game.soft_body.use_bending_constraints``

Cluster Collision
Affects Collision sensors as well as physics.

Rigid to Soft Body
Enable cluster collisions between Rigid and Soft Bodies.

- Default: Off.
- Python property: ``obj.game.soft_body.use_cluster_rigid_to_softbody``

Soft to Soft Body
Enable cluster collisions among Soft Bodies.

- Default: Off.
- Python property: ``obj.game.soft_body.use_cluster_soft_to_softbody``

Iterations
Number of cluster iterations.

- Range: 1-128.
- Default: 64.
- Python property: ``obj.game.soft_body.cluster_iterations``

Hints
=====

- A very important configurable in the case of Soft Body interactions is
:doc:`World Properties &lt;/game_engine/physics/world&gt;`
:menuselection:`--&gt; Physics --&gt; Physics Steps --&gt; Substeps`.
- Surprisingly, the more vertices you have in your hit object, the less likely the Soft Body is to react with it.
If you try letting it hit a Plane, it might stop, but a subdivided Grid might fail.

.. note::

Soft bodies do not work with the Collision, Touch, Near, and Radar logic brick sensors.

.. warning::

A common practice within the non-BGE Cloth simulator is to employ
:doc:`Force Fields &lt;/physics/force_fields/index&gt;` to animate the cloth.
These do not work in the BGE, so you will have to figure out a way to use Python
(or perhaps plain Logic Bricks) to apply forces to the Soft Body objects.

Goal Weights
============

TODO. See `Python API
&lt;https://www.blender.org/api/blender_python_api_current/bpy.ops.curve.html#bpy.ops.curve.spline_weight_set&gt;`__.

**************
Static Physics
**************

Static objects in the :doc:`Blender Game Engine &lt;/game_engine/index&gt;` do not automatically react to physics,
including gravity and collisions.
Even if hit by the force of a speeding 18-wheeler truck,
it will remain unresponsive in terms of location, rotation, or deformation.

It will, however, give collision reactions. Objects will bounce off of Static Objects,
and rotational inertia will transfer to objects capable of rotating (that is,
Rigid Body Objects will spin in response, though Dynamic Objects will not).

Note that none of this prevents you from transforming the Static Objects with
:doc:`Logic Bricks &lt;/game_engine/logic/index&gt;` or Python code.
The visual objects will correctly move and their physics representation will update in the engine as well.

Another important note is that the default
`Collision Bounds`_
is a Triangle Mesh, meaning it is higher in computational requirements but also in detail.
This in turn means the "Radius" option has no effect by default.

For more documentation, see the :doc:`Top BGE Physics page &lt;/game_engine/physics/index&gt;`.

Options
=======

.. note::  bpy Access

Note that most of these properties are accessible through the non-
BGE scripting API via ``bpy.data.objects["ObjectName"].game``,
which is of type ``bpy.types.GameObjectSetting``. This is useful so you can,
for example, set a range of objects to have gradated values via a for-loop.

Actor
Enables detection by Near and Radar Sensors.

- Default: On.
- Python property: ``obj.game.use_actor``
Ghost
Disables collisions completely, similar to No Collision.

- Default: Off.
- Python property: ``obj.game.use_ghost``
Invisible
Does not display, the same as setting the object to unrendered
(such as unchecking the "Camera" icon in the Outliner).

- Default: Off.
- Python property: ``obj.use_render``

Radius
If you have the "Collision Bounds: Sphere"
set explicitly (or implicitly through having the Collision Bounds subpanel unchecked),
this will multiply with the Object's (unapplied) Scale. Note that none of the other bounds types are affected.
Also note that in the 3D View the display will show this for all types,
even though it is only actually used with Sphere. Python property: ``obj.game.radius``

.. list-table::
:header-rows: 1

* - Basic
- Radius= 1.5
- Unapplied Scale
- Applied Scale
- Collision Bounds

* - Rolls, radius of 1 BU
- Rolls, radius of 1.5 BU (after "popping" upward)
- Rolls, radius of 1.5 BU
- Rolls, radius of 1 BU (!)
- Default (which is Sphere)

* - Slides, extent of 1 BU
- Slides, extent of 1 BU
- Slides, extent of 1 BU
- Slides, extent of 1 BU
- Box

* - ""
- ""
- ""
- ""
- Convex Hull

* - Slides, extent of 1 BU (but with more friction than above)
- Slides, extent of 1 BU (but with more friction than above)
- Acts insane
- Slides extent of 1.5 BU
- Triangle Mesh

Anisotropic Friction
Isotropic friction is identical at all angles. Anisotropic is directionally-dependant.
Here you can vary the coefficients for the three axes individually, or disable friction entirely.
Python properties: ``obj.game.use_anisotropic_friction``
(boolean) and ``obj.game.friction_coefficients`` (a 3-element array).

Collision Bounds
================

.. note::

The Static type differs from the others in that it defaults to a Triangle Mesh bounds,
instead of a simple sphere.

The first thing you must understand is the idea of the 3D Bounding Box.
If you run through all the vertices of a mesh and record the lowest and highest x values,
you have found the *x min/max* the complete boundary for all x values within the mesh.
Do this again for y and z, then make a rectangular prism out of these values, and you have a *Bounding Box*.
This box could be oriented relative globally to the world or locally to the object's rotation.

.. figure:: /images/bge-physics-boundingbox.png

Demonstration of a Local Bounding Box (left) and a Global Bounding Box (right).

The *x extent*, then, is half of the distance between the x min/max.

Throughout all of this you must be cognizant of the Object Origin. For the Game engine,
the default :kbd:`Ctrl-Alt-Shift-C`, :kbd:`3` or :menuselection:`Set Origin --&gt; Origin to Geometry`
is unlikely to get the desired placement of the Collision Bounds that you want.
Instead, you should generally set the origin by looking at the Tool Shelf after you do the *Set Origin*,
and changing the *Center* from *Median Center* to *Bounds Center*.
Blender will remember this change for future :kbd:`Ctrl-Alt-Shift-C` executions.

All Collision Bounds are centered on this origin. All boxes are oriented locally, so object rotation matters.

.. figure:: /images/bge-physics-origintoboxbounds.png

Setting the origin to Bounds Center instead of Median Center.

A final introductory comment: When you set the Collision Bounds on an object,
Blender will attempt to display a visualization of the bounds in the form of a dotted outline.
Currently, there is a bug: *The 3D View*
does not display this bounds preview where it actually will be during the game.
To see it, go to :menuselection:`Game --&gt; Show Physics Visualization`
and look for the white (or green, if sleeping) geometry.

Now we can explain the various options for the *Collision Bounds* settings:

Default
For Dynamic and Static objects, it is a Triangle Mesh (see below).
For everything else, it is a Sphere (see below).
Capsule
Which is a cylinder with hemispherical caps, like a pill.
Radius of the hemispheres is the greater of the X or Y extent.
Height is the Z bounds
Box
The X, Y, Z bounding box, as defined above.
Sphere
Radius is defined by the object's scale (visible in the N properties panel) times the physics radius
(can be found in :menuselection:`Physics --&gt; Attributes --&gt; Radius`.
Note: This is the only bounds that respects the Radius option.
Cylinder
Radius is the greater of the x or y extent.
Height is the z bounds.
Cone
Base radius is the greater of the x or y extent.
Height is the z bounds.
Convex Hull
Forms a shrink-wrapped, simplified geometry around the object.

.. figure:: /images/bge-physics-convexhull.png
:width: 200px

A convex hull sketch.

Triangle mesh
Most expensive, but most precise. Collision will happen with all of triangulated polygons,
instead of using a virtual mesh to approximate that collision.
By Hand
This is not an option in the Physics tab's Collision Bounds settings, but a different approach, entirely.
You create a second mesh, which is invisible, to be the physics representation.
This becomes the parent for your display object. Then,
your display object is set to ghost so it does not fight with the parent object.
This method allows you to strike a balance between the accuracy of *Triangle Mesh*
with the efficiency of some of the others. See the demo of this in the dune buggy to the right.

.. figure:: /images/bge-physics-manualhull.png
:width: 300px

Another way to create Collision Bounds -- By hand.

Options
-------

There are only two options in the Collision Bounds subpanel.

Margin
"Add extra margin around object for collision detection, small amount required for stability."
If you find your objects are getting stuck in places they should not, try increasing this to, say, 0.06.

Sometimes 0.06 is the default (such as on the Default Cube), but sometimes it is not.
You have to keep an eye on the setting, or else learn the symptoms so you can respond when it gives you trouble.
If you are lazy/paranoid/unsure/diligent/bored,
you can always run this on the Python Console to bump all 0.0 margins to 0.06: for
``obj`` in ``bpy.data.objects``: ``obj.game.collision_margin = obj.game.collision_margin`` or 0.06
Compound
"Add children to form compound collision object." Basically,
if you have a child object and do not have this enabled,
the child's collisions will not have an effect on that object "family"
(though it will still push other objects around). If you do have it checked,
the parent's physics will respond to the child's collision (thus updating the whole family).
Python property: ``obj.game.use_collision_compound``

Create Obstacle
===============

Todo

**************************
Vehicle Controller Physics
**************************

Introduction
============

The Vehicle Controller is a special :ref:`type of physics object &lt;game-engine-physics-types&gt;`
that the Physics Engine (bullet) recognizes.

It is composed of a *rigid body*
representing the chassis and a set of wheels that are set to *no collision*.
Emphasizing the distinction between a Game Engine,
Logical or Render object and its representation for the Physics Engine is important.

To simulate a vehicle as a true rigid body, on top of also rigid body wheels, with a real suspension system made with
joints, would be far too complicated and unstable.
Cars and other vehicles are complicated mechanical devices and most
often we do not want to simulate that, only that it 'acts as expected'. The Vehicle Controller exists to provide a
dedicated way of simulating a vehicle behavior without having to simulate all the physics that would actually happen
in the real world. It abstracts the complexity away by providing a simple interface with tweakable parameters such as
suspension force, damping and compression.

How it works
============

Bullet's approach to a vehicle controller is called a "Raycast Vehicle".
Collision detection for the wheels is approximated
by ray casts and the tire friction is an anisotropic friction model.

A raycast vehicle works by casting a ray for each wheel.
Using the ray's intersection point,
we can calculate the suspension length and hence the suspension force that is then applied to the chassis,
keeping it from hitting the ground. In effect, the vehicle chassis 'floats' along on the rays.

The friction force is calculated for each wheel where the ray contacts the ground.
This is applied as a sideways and forwards force.

You can check Kester Maddock's approach to vehicle simulation
`here &lt;https://docs.google.com/document/d/18edpOwtGgCwNyvakS78jxMajCuezotCU_0iezcwiFQc/edit&gt;`__.
It includes some common problems, workarounds and tips and tricks.

How to use
==========

Currently the Vehicle Controller can only be used as a constraint via Python.
There are plans to add it to the interface.

Setup
-----

You should have a body acting as the chassis, set it as a 'Rigid Body'.

The wheels should be separate objects set to 'No Collision'.
The vehicle controller will calculate the collisions for you as rays so, if you set it to something else,
it will calculate it twice in different ways and produce weird results.

Collisions
----------

A cylinder is typically a good collision shape for the wheels.
For the chassis, the shape should be rough, like a box.
If the vehicle is very complicated,
you should split it into simpler objects and parent those (with their collision shapes)
to the vehicle controller so that they will follow it.
If your vehicle even has moving bits (weapons, wrecking balls, trolleys etc)
they should also be simulated separately and connected to the vehicle as a joint.

Python
------

Assembling the Vehicle
^^^^^^^^^^^^^^^^^^^^^^

The overall steps are:

- Create a constraint for the vehicle and save its ID for future reference
- Attach the wheels
- Set wheel parameters: influence, stiffness, damping, compression and friction
- Init variables

You can see an example in the file below.

Controlling the Vehicle
^^^^^^^^^^^^^^^^^^^^^^^

This is done in two parts and it should be modeled according to the desired behavior.
You should think of your gameplay and research appropriate functions for the input.
For instance, can the vehicle reverse? jump? drift?
does it turn slowly? How much time does it take to brake or get to full speed?
The first part is *response to keys*.
Whenever the player presses a key, you should set a value accordingly, such as increase acceleration.
Example::

if key[0] == events.UPARROWKEY:
logic.car["force"] = -15.0
elif key[0] == events.RIGHTARROWKEY:
logic.car["steer"] -= 0.05

The second part is to *compute the movement* according to your functions::

## apply engine force ##
for i in range(0, totalWheels):
vehicle.applyEngineForce(logic.car["force"],i)
...
## slowly ease off gas and center steering ##
logic.car["steer"] *= 0.6
logic.car["force"] *= 0.9

Both should be run each frame.

Example
-------

`demo_file.zip &lt;https://dl.dropboxusercontent.com/u/3226675/blender/vehicle_controller_demo.zip&gt;`__
(last update 9 September 2014)

**********
Converting
**********

Sometimes, you may want to animate a wall being broken down by an object,
or a bunch of objects collapsing, falling, or bouncing with accurate physics. You could
manually insert keyframes and do trial and error adjusting with F-Curves to simulate physics
and acceleration, or, you can do it much easier and automatically by taking advantage of
Blender Game Engine Physics. Blender now has a feature which allows you to record animation in
a Blender game and turn it into Blender Animation Keyframes.

Animation can be recorded by going :menuselection:`Game --&gt; Record Animation`.
The animation can them to recorded with :kbd:`Alt-A`

.. figure:: /images/game_engine_physics_blocks.png

Some Blocks about to fall.

.. figure:: /images/game_engine_physics_blocks2.png

A Pile.

If you just want a static pile of stuff, you can move to the last frame,
and delete all the keyframes quickly by turning them into NLAs and deleting.
..    TODO/Review: {{Review|partial=x|im=needs images?}}.

*************
World Physics
*************

.. figure:: /images/bge_world_physics.png
:align: right
:width: 290px

BGE World Physics Panel.

Physics Panel
=============

The *Game Physics* located in the *World* panel determine the type
of physical rules that govern the Game Engine scene, and the gravity value to be used.
Based on the physics engine selected, in physics simulations in the Game Engine,
Blender will automatically move *Actors* in the downward (-Z) direction.
After you arrange the actors and they move as you wish,
you can then bake this computed motion into keyframes
(see :ref:`game-engine-physics-bake-keyframes` for more info).

Physics Engine
Set the type of physics engine to use.

Bullet
The default physics engine, in active development.
It handles movement and collision detection.
The things that collide transfer momentum to the collided object.
None
No physics in use. Things are not affected by gravity and can fly about in a virtual space.
Objects in motion stay in that motion.
Gravity
The gravitational acceleration, m.s\ :sup:`-2` (in units of meters per squared second),
of this world. Each object that is an actor has a mass and size slider.
In conjunction with the frame rate (see :doc:`Render &lt;/render/index&gt;` section),
Blender uses this info to calculate how fast the object should accelerate downward.
Culling Resolution
The size of the occlusion culling buffer in pixel, use higher value for better precision (slower).
The optimized Bullet DBVT for view frustum and occlusion culling is activated internally by default.
Physics Steps
Max
Sets the maximum number of physics steps per game frame if graphics slow down the game.
higher value allows physics to keep up with realtime.
Substeps
Sets the number of simulation substeps per physics timestep. Higher value give better physics precision.
FPS
Set the nominal number of game frames per second.
Physics fixed timestep = 1/fps, independently of actual frame rate.
Logic Steps
Sets the maximum number of logic frame per game frame if graphics slows down the game,
higher value allows better synchronization with physics.
Physics Deactivation
These settings control the threshold at which physics is deactivated.
These settings help reducing the processing spent on Physics simulation during the game.

Linear Threshold
The speed limit under which a rigid bodies will go to sleep (stop moving)
if it stays below the limits for a time equal or longer than the deactivation time
(sleeping is disabled when deactivation time is set to 0).
Angular Threshold
Same as linear threshold, but for rotation limit (in rad/s)
Time
The amount of time in which the object must have motion below the thresholds
for physics to be disabled (0.0 disables physics deactivation).

Navigation Mesh
===============

Rasterization
Cell size
rasterized cell size.
Cell height
rasterized cell height.
Agent
Height
Minimum height where the agent can still walk.
Radius
Radius of the agent.
Max climb
Maximum height between grid cells the agent can climb.
Max slope
Maximum walkable slope angle in degrees.
Region
Min Region Size
Minimum regions size. Smaller regions will be deleted.
Merged Region Size
Minimum regions size. Smaller regions will be merged.
Partitioning
Watershed
Classic Recast partioning method generating the nicest tessellation.
Monotone
The fastest navmesh generation method, but may cause long thin polygons.
Layers
A reasonably fast method that produces better triangles than monotone partitioning.
Polygonization
Max Edge Length
Maximum contour edge length.
Max Edge Error
Maximum distance error from contour to cells.
Verts Per Poly
Max number of vertices per polygon.
Detail Mesh
Sample Distance
Detail mesh sample spacing.
Max Sample Error
Detail mesh simplification max sample error.

Obstacle Simulation
===================

Simulation used for obstacle avoidance in the Game Engine,
based on the RVO (Reciprocal Velocity Obstacles) principle.
The aim is to prevent one or more actors colliding with obstacles.

See `Path finding and steering behaviors &lt;https://wiki.blender.org/index.php/User:Nicks/Gsoc2010/Docs&gt;`__
for more details.

Type
None
Obstacle simulation is disabled, actors are not able to avoid obstacles
RVO (cells)
Obstacle simulation is based on the `RVO method &lt;http://gamma.cs.unc.edu/RVO/&gt;`__ with cell sampling.
RVO (rays)
Obstacle simulation is based on the `RVO method &lt;http://gamma.cs.unc.edu/RVO&gt;`__ with ray sampling.

Level height
Max difference in heights of obstacles to enable their interaction.
Used to define minimum margin between obstacles by height,
when they are treated as those which are situated one above the other i.e. they does not influence to each other.
Visualization
Enable debug visualization for obstacle simulation.

*************************
Bullet physics Python API
*************************

Bullet Physics provides collision detection and rigid body dynamics for the Blender Game
Engine. It takes some settings from Blender that previously were designed for the former
collision detection system (called Sumo).

However, new features do not have a user interface yet,
so Python can be used to fill the gap for now.

Features:

- Vehicle simulation.
- Rigid body constraints: hinge and point to point (ball socket).
- Access to internal physics settings, like deactivation time, debugging features.

Easiest is to look at the Bullet physics demos, how to use them. More information can be found
`here &lt;http://www.continuousphysics.com/Bullet/phpBB2/viewforum.php?f=17&gt;`__.

Python script example::

import PhysicsConstraints
print dir(PhysicsConstraints)

.. note:: Note about parameter settings

Since this API is not well documented, it can be unclear what kind of values to use for setting parameters.
In general, damping settings should be in the range of 0 to 1 and
stiffness settings should not be much higher than about 10.
.. _game-engine-python-api-index:

###############
Python API
###############

.. toctree::
:maxdepth: 2

introduction.rst
bullet_physics.rst
videotexture.rst

************
Introduction
************

This site is currently under development.

To see the full Python API please click on the following link:
`Python API &lt;https://www.blender.org/api/blender_python_api_current/&gt;`__.

More informations:

- :doc:`Bullet physics &lt;/game_engine/python_api/bullet_physics&gt;`
- :doc:`Video Texture &lt;/game_engine/python_api/videotexture&gt;`

************************************
The VideoTexture module: bge.texture
************************************

The ``bge.texture`` module allows you to manipulate textures during the game.
Several sources for texture are possible: video files, image files, video capture,
memory buffer, camera render or a mix of that.
The video and image files can be loaded from the Internet using a URL instead of a file name.
In addition, you can apply filters on the images before sending them to the GPU,
allowing video effect: blue screen, color band, gray, normal map.
``bge.texture`` uses FFmpeg to load images and videos.
All the formats and codecs that FFmpeg supports are supported by ``bge.texture``,
including but not limited to:

- AVI
- Ogg
- Xvid
- Theora
- dv1394 camera
- video4linux capture card (this includes many webcams)
- videoForWindows capture card (this includes many webcams)
- JPG

How it works
============

The principle is simple: first you identify an existing texture by object and name,
then you create a new texture with dynamic content and swap the two textures in the GPU.
The GE is not aware of the substitution and continues to display the object as always,
except that you are now in control of the texture. At the end,
the new texture is deleted and the old texture restored.

The present page is a guide to the ``bge.texture`` module with simple examples.

Game preparation
================

Before you can use the thing ``bge.texture`` module,
you must have objects with textures applied appropriately.

Imagine you want to have a television showing live broadcast programs in the game. You will
create a television object and UV-apply a different texture at the place of the screen, for example ``tv.png``.
What this texture looks like is not important;
probably you want to make it dark gray to simulate power-off state.
When the television must be turned on, you create a dynamic texture from a video capture card
and use it instead of ``tv.png``: the TV screen will come to life.

You have two ways to define textures that ``bge.texture`` can grab:

- Simple UV texture.
- Blender material with image texture channel.

Because ``bge.texture`` works at texture level,
it is compatible with all GE fancy texturing features: GLSL, multi-texture, custom shaders,
etc.

First example
=============

Let us assume that we have a game object with one or more faces assigned to a material/image on
which we want to display a video.

The first step is to create a ``Texture`` object.
We will do it in a script that runs once. It can be at the start of the game,
the video is only played when you refresh the texture; we will come to that later. The script is
normally attached to the object on which we want to display the video so that we can easily
retrieve the object reference::

import bge.texture

contr = GameLogic.getCurrentController()
obj = contr.owner

if not hasattr(GameLogic, 'video'):

The check on ``video`` attribute is just a trick to make sure we create the texture only once.

Find material
-------------

.. code-block:: python

matID = bge.texture.materialID(obj, 'IMvideo.png')

``bge.texture.materialID()``
is a handy function to retrieve the object material that is using ``video.png`` as texture.
This method will work with Blender material and UV texture.
In case of UV texture, it grabs the internal material corresponding to the faces that are assigned to this texture.
In case of Blender material,
it grabs the material that has an image texture channel matching the name as first channel.

The ``IM`` prefix indicates that we are searching for a texture name but we can also
search for a material by giving the ``MA`` prefix. For example,
if we want to find the material called ``VideoMat`` on this object, the code becomes::

matID = bge.texture.materialID(obj, 'MAVideoMat')

Create texture
--------------

``bge.texture.Texture`` is the class that creates the ``Texture`` object that loads the dynamic texture on the GPU.
The constructor takes one mandatory and three optional arguments:

``gameObj``
The game object.
``materialID``
Material index as returned by ``bge.texture.materialID()``, 0 = first material by default.
``textureID``
Texture index in case of multi-texture channel, 0 = first channel by default.
In case of UV texture, this parameter should always be 0.
``textureObj``
Reference to another ``Texture`` object of which we want to reuse the texture.
If we use this argument,
we should not create any source on this texture and there is no need to refresh it either:
the other ``Texture`` object will provide the texture for both materials/textures.

.. code-block:: python

GameLogic.video = bge.texture.Texture(obj, matID)

Make texture persistent
-----------------------

Note that we have assigned the object to a ``GameLogic``, ``video``
attribute that we create for the occasion.
The reason is that the ``Texture`` object must be persistent across the game scripts.
A local variable would be deleted at the end of the script and the GPU texture deleted at the
same time. ``GameLogic`` module object is a handy place to store persistent objects.

Create a source
---------------

Now we have a ``Texture`` object but it cannot do anything because it does not have
any source. We must create a source object from one of the possible sources available in
``bge.texture``:

``VideoFFmpeg``
Moving pictures.
Video file, video capture, video streaming.

``ImageFFmpeg``
Still pictures.
Image file, image on web.

``ImageBuff``
Image from application memory.
For computer generated images, drawing applications.

``ImageViewport``
Part or whole of the viewport (=rendering of the active camera displayed on screen).

``ImageRender``
Render of a non active camera.

``ImageMix``
A mix of two or more of the above sources.

In this example we use a simple video file as source.
The ``VideoFFmpeg`` constructor takes a file name as argument.
To avoid any confusion with the location of the file, we will use ``GameLogic.expandPath
()`` to build an absolute file name,
assuming the video file is in the same directory as the blend-file::

movie = GameLogic.expandPath('//trailer_400p.ogg')
GameLogic.video.source = bge.texture.VideoFFmpeg(movie)

We create the video source object and assign it to the ``Texture`` object
``source`` attribute to set the source and make it persistent:
as the ``Texture`` object is persistent, the source object will also be persistent.

Note that we can change the ``Texture`` source at any time.
Suppose we want to switch between two movies during the game.

We can do the following::

GameLogic.mySources[0] = bge.texture.VideoFFmpeg('movie1.avi')
GameLogic.mySources[1] = bge.texture.VideoFFmpeg('movie2.avi')

And then assign (and reassign) the source during the game::

GameLogic.video.source = GameLogic.mySources[movieSel]

Setup the source
----------------

The ``VideoFFmpeg`` source has several attributes to control the movie playback:

``range``
[start,stop] (floats).
Set the start and stop time of the video playback, expressed in seconds from beginning.
By default the entire video.

``repeat``
(integer).
Number of video replay, -1 for infinite.

``framerate``
(float).
Relative frame rate, &lt;1.0 for slow, &gt;1.0 for fast.

``scale``
(bool).
Set to True to activate fast nearest neighbor scaling algorithm.
Texture width and height must be a power of 2.
If the video picture size is not a power of 2, rescaling is required.
By default ``bge.texture`` uses the precise but slow ``gluScaleImage()`` function.
Best is to rescale the video offline so that no scaling is necessary at runtime!

``flip``
(bool).
Set to True if the image must be vertically flipped.
FFmpeg always delivers the image upside down, so this attribute is set to True by default.

``filter``
Set additional filter on the video before sending to GPU.
Assign to one of ``bge.texture`` filter object.
By default the image is send unchanged to the GPU.
If an alpha channel is present in the video, it is automatically loaded and sent to the GPU as well.

We will simply set the ``scale`` attribute to True because the ``gluScaleImage
()`` is really too slow for real time video.
In case the video dimensions are already a power of 2, it has no effect. ::

GameLogic.video.source.scale = True

Play the video
--------------

We are now ready to play the video::

GameLogic.video.source.play()

Video playback is not a background process: it happens only when we refresh the texture.
So we must have another script that runs on every frame and calls the ``refresh
()`` method of the ``Texture`` object::

if hasattr(GameLogic, 'video'):
GameLogic.video.refresh(True)

If the video source is stopped, ``refresh()`` has no effect.
The argument of ``refresh
()`` is a flag that indicates if the texture should be recalculated on next refresh.
For video playback, you definitively want to set it to True.

Checking video status
---------------------

Video source classes (such as VideoFFMpeg) have an attribute ``status``.
If video is playing, its value is 2, if it's stopped, it's 3.
So in our example::

if GameLogic.video.source.status == 3:
#video has stopped

Advanced work flow
------------------

True argument in ``Texture.refresh()`` method simply invalidates the image buffer
after sending it to the GPU so that on next frame, a new image will be loaded from the source.
It has the side effect of making the image unavailable to Python.
You can also do it manually by calling the ``refresh
()`` method of the source directly.

Here are some possible advanced work flow:

- Use the image buffer in Python (does not effect the Texture)::

GameLogic.video.refresh(False)
image = GameLogic.video.source.image
# image is a binary string buffer of row major RGBA pixels
# ... use image
# invalidates it for next frame
GameLogic.video.source.refresh()

- Load image from source for Python processing without download to GPU:
- Note that we do not even call refresh on the Texture.
- We could also just create a source object without a Texture object::

image = GameLogic.video.source.image
# ... use image
GameLogic.video.source.refresh()

- If you have more than one material on the mesh and you want to modify a texture of one particular material,
get its ID::

matID = bge.texture.materialID(gameobj, "MAmat.001")

GLSL material can have more than one texture channel,
identify the texture by the texture slot where it is defined, here two::

tex=bge.texture.Texture(gameobj, matID, 2)

Advanced demos
==============

Here is a `demo &lt;http://www.graphicall.org/ftp/ben2610/VideoTextureDemo2video.blend&gt;`__
that demonstrates the use of two videos alternatively on the same texture.
Note that it requires an additional video file which is the elephant dream teaser.
You can replace with another other file that you want to run the demo.

Here is a `demo &lt;http://www.graphicall.org/ftp/ben2610/VideoTextureDemo2videoMix.blend&gt;`__
that demonstrates the use of the ``ImageMix`` source.
``ImageMix`` is a source that needs sources,
which can be any other ``Texture`` source, like ``VideoFFmpeg``,
``ImageFFmpeg`` or ``ImageRender``. You set them with ``setSource
()`` and their relative weight with ``setWeight()``.
Pay attention that the weight is a short number between 0 and 255,
and that the sum of all weights should be 255.
``ImageMix`` makes a mix of all the sources according to their weights.
The sources must all have the same image size
(after reduction to the nearest power of two dimension). If they do not,
you get a Python error on the console.

************************
Game Logic Screen Layout
************************

The design, construction, debugging and running of a game use a wide range of Blender functions.
To help with the process, Blender incorporates a suggested screen layout for setting up BGE games.
This includes many already-familiar panels but also a new
:doc:`Logic Editor &lt;/editors/logic_editor&gt;` panel (4) concerned solely with the BGE.

The diagram below shows this default Game Logic screen layout,
together with the appropriate options for game setup/debug/running
(these should be set up in the order shown).

.. figure:: /images/bge_game_logic_screen_layout1.jpg

Game Logic Screen Layout.

.. figure:: /images/bge_game_logic_screen_layout4.png

Game Logic Menu.

.. rubric:: 1) Game Logic

Selected from the list of screen layouts for various applications.
This includes many already-familiar panels (Information, 3D View,
Properties) but also a new Logic Editor panel concerned solely with the BGE.

.. figure:: /images/bge_game_logic_screen_layout2.png

Render Engine Menu.

.. rubric:: 2) Blender Game

Selected from the render engine menu.
This specifies that all output will be output by the real-time Blender Game Engine renderer.
It also opens various other menu options such as the Game options (see below)
and a range of Properties for the BGE renderer properties (see below)

.. figure:: /images/bge_game_logic_screen_layout3.png

Game Options.

.. rubric:: 3) Game

This menu gives various options for conditions for running the Game Engine.
Note that this menu is only available when the render engine is set to Blender Game.

Start Game
Run game in Game Engine (:kbd:`P` or :kbd:`Shift-P` when the mouse cursor is over the 3D View editor).
Show Debug Properties
Show properties marked for debugging while game runs.
Show framerate and profile
Show framerate and profiling information while game runs.
Show Physics visualization
Show a vizualisation of physics bounds and interactions.
Deprecation warnings
Print warnings when using deprecated features in the Python API.
Record animation
Record animation to F-Curves.
Auto Start
Automatically start game at load time.

.. rubric::  4) Logic Editor panel

The :doc:`Logic Editor &lt;/editors/logic_editor&gt;` is where the
:doc:`logic, properties and states &lt;/game_engine/logic/index&gt;` are set up to control the behavior of
the objects in the game.
(The Logic Editor panel can also be displayed by selecting Logic Editor in the Display Editor menu,
by pressing :kbd:`Shift-F2`, or by pressing :kbd:`Ctrl-Right`).

.. rubric::  5) Properties

.. tip:: Two Meanings for the Same Word

Note that the name "Property" has two different uses in Blender terminology --
firstly in the wider use of the Property Display Panel as described here,
and secondly as the term used for specific Game Engine logic variables which are also called "properties".

The Property panel of the screen is selected as usual from the main Information menu.
However, note that several sections of the Property panel are changed when the render engine
(2) is changed from Blender Render to Blender Game.

See following sections for details of the content of :doc:`Physics &lt;/game_engine/physics/index&gt;` Properties panels.

################
Game Settings
################

.. toctree::
:maxdepth: 2

render.rst
object.rst

***************
Level of Detail
***************

When creating visual assets it is often desirable to have a high amount of detail in the asset
for up close viewing. However,
this high amount of detail is wasted if the object is viewed from a distance,
and brings down the scene's performance. To solve this,
the asset can be swapped out at certain viewing distances.
This is commonly referred to as a level of detail system.
Each visual step of the asset is known as a level of detail. Levels of detail are most
appropriate to use when you have a large scene where certain objects can be viewed both up
close and from a distance.

Settings
========

.. note:: Modifiers on Level of Detail Objects

Any level of detail objects that have a modifier do not display correctly in the Game Engine.
You will need to apply any modifiers for level of detail objects to appear correctly.
A fix for this is being looked into.

.. figure:: /images/bge_level-of-detail-panel.png

Level of detail settings can be found in the Object settings when the renderer is set to
Blender Game.
In the Levels of Detail panel is a button to add a new level of detail to the current object.
The settings for each level of detail are displayed in its own box.
The exception to this is the base level of detail.
This is automatically setup as the current object with a distance setting of 0.
To remove a level of detail,
click on the X button in the top right corner of the box of the level to be removed.

Object
The object to use for this level of detail.
Distance
The distance at which this level of detail becomes visible.
Use Mesh
When this option is enabled,
the mesh from the level of detail object is used until a lower level of detail overrides it.
Use Material
When this option is enabled,
the material from the level of detail object is used until a lower level of detail overrides it.

Tools
=====

Some tools for making levels of detail easier to manage and create can be found from
the select menu next to the add button in the Levels of Detail panel.

Set By Name
-----------

Searches the scene for specifically named objects and attempts to set them up as levels of
detail on the currently selected object. The selected object must be the base level of detail
(e.g. LOD0). This can be useful to quickly setup levels of detail on imported assets.
In order to make use of this tool, your naming must be consistent, and each level must be
prefixed or suffixed with "lodx" where x is the level that object is intended for.
The case on "lod" must be consistent across all objects.
Below are some example names that the tool will recognize.

- LOD0_Box, LOD1_Box, LOD2_Box
- Box.lod0, Box.lod1, Box.lod2
- LoD0box, LoD1box, LoD2box

Generate
--------

.. figure:: /images/bge_level-of-detail-generation.jpg

This tool generates and sets up levels of details based on the selected object.
Generation is done using the Decimate Modifier.
Generation does not apply the modifier to allow further changing the settings.
Generated objects are automatically named based on the level they are generated for.
Below are some settings for the operator.

Count
The number of levels desired after generation. This operator creates Count-1 new objects.
Target Size
The ratio setting for the Decimate Modifier on the last level of detail.
The ratio settings for the other levels are determined by linear interpolation.
Package into Group
With this setting enabled the operator performs some extra tasks
to make the asset ready for easy linking into a new file.
The base object and all of its levels of detail are placed into a group based on the base object's name.
Levels other than the base are hidden for both the viewport and rendering.
This simplifies the appearance of the system and does not affect the appearance of the base object.
Finally, all levels are parented to the base object to remove clutter from the Outliner.

Clear All
---------

Clears the level of detail settings from the current object.

***************
Render Settings
***************

.. figure:: /images/bge_camera_properties.png
:width: 300px

Camera Properties.

The camera (or cameras) used in a Blender game have a wide-ranging effect on the way in which
the game is rendered and displayed.
Mostly this is controlled using the Properties panel of the camera(s) used in the game.

There are two separate game "players" for previewing the game during development.
The Embedded Player renders onto the 3D scene pane in the Blender GUI using the current perspective
and zoom level of the 3D preview.
The Standalone Player renders the scene from the perspective of the active scene camera
and either creates a new desktop window or switches into fullscreen rendering mode.
Note that while the Game Engine is running in either player,
the computer's mouse and keyboard are captured by the game and by default,
the mouse cursor is not visible. To exit the game, press the &lt;ESC&gt; key.

.. tip:: Render Engine

Make sure that the render engine is set to Blender Game when attempting to set these controls,
otherwise this description will not tally with what you see!

In the Camera Properties area, there are seven panels available, as shown.
Each can be expanded or contracted using the usual triangle button.
The features in each panel will be described in detail below.

Embedded Player
===============

.. figure:: /images/bge_camera_properties_embedded.png
:width: 300px

Game Panel.

This panel provides information for the Embedded Game Player which allows games to be run
inside a Blender render pane.

Note that the *Resolution* settings are independent of the size of the viewport preview pane.
In fact, the *Resolution* controls seem to have no effect at all.
The resolution and aspect ratio of the embedded preview are always fixed to the 3D preview pane,
which behaves much like the *Extend* framing mode for the standalone player as described below.
The *Framing* selection under the *Display* heading has no effect on the embedded preview.

Start
Starts the Game Engine inside the blender viewport preview pane. Shortcut :kbd:`P`.
Resolution
X
Sets the internal X rendering resolution.
Y
Sets the internal Y rendering resolution.

Standalone Player
=================

.. figure:: /images/bge_camera_properties_standalone.png
:width: 300px

Standalone Panel.

This panel provides information for the Standalone Game Player which allows games to be run without Blender.
See :doc:`Standalone Player &lt;/game_engine/blender_player&gt;` for further details.

The semantics of the Standalone Player *Resolution* controls differ for Windowed and Fullscreen modes.
In Windowed mode (*Fullscreen* checkbox unchecked),
the *Resolution* controls set the initial dimensions of the desktop window.
The user may resize the window at any time, causing the rendering resolution to change accordingly.
In Fullscreen mode (*Fullscreen* checkbox checked), the *Resolution* controls set the internal rendering resolution.
The actual display resolution will be a best fit depending on the user's hardware.
In either mode, the aspect ratio/cropping/scaling are determined
by the *Framing* selection under the *Display* heading.

Regarding *Fullscreen* mode, it is important to remember that the *Resolution* settings in *Fullscreen* mode
are only hints to the operating system. Each display and monitor combination will have a different set of
resolutions that they are capable of displaying; so there can be little confidence that all end-users will actually
get the resolution you suggest; unless you choose one of the most standard resolutions (e.g. 800x600 or 1024x768).
If you insist on using higher resolutions, then you may want to state clearly in your documentation that
only certain resolutions are supported. In most other cases, the user's machine may select a resolution that is
close to the one suggested; but the results can be unpredictable, especially in *Letterbox* mode.

Note that the *Desktop* checkbox has no effect in Windowed mode.

Start
Lanuches the current .blend file with the Standalone Player.
Resolution
X
Sets the X window size or full-screen display resolution.
Y
Sets the Y window size or full-screen display resolution.
Fullscreen
Off
Opens standalone game as a new window.
On
Opens standalone game in full-screen.
Desktop
Off
Attempts to obey the *Resolution* specified above when in *Fullscreen* mode.
On
Keeps the current desktop resolution when in *Fullscreen* mode.
Quality
AA Samples
The number of AA samples to use for MSAA.
Bit Depth
Number of bits used to represent color of each pixel in full-screen display.
Refresh Rate
Number of frames per second of full-screen display.

Stereo
======

.. figure:: /images/bge_camera_properties_stereo.png
:width: 300px

Stereo Panel.

Select a stereo mode that will be used to capture stereo images of the game (and also,
by implication, that stereo displays will use to render images in the standalone player).

None
Render single images with no stereo.
Stereo
Render dual images for stereo viewing using appropriate equipment.
See :doc:`Stereo Camera &lt;/game_engine/camera/stereo&gt;` for full details of available options.
Dome
Provides facilities for an immersive dome environment in which to view the game.
See :doc:`Dome Camera &lt;/game_engine/camera/dome&gt;` for full details of available options.

Shading
=======

.. figure:: /images/bge_camera_properties_shading.png
:width: 300px

Shading Panel.

Specifies the shading mode to be used in rendering the game.
The shading facilities available in Blender for use in
:doc:`Materials &lt;/render/blender_render/materials/index&gt;` and :doc:`Textures &lt;/render/blender_render/textures/index&gt;`
are essentially the same in the Blender Game Engine.
However, the constraints of real-time display mean that only some of the facilities are available.

Multitexture
Use Multitexture shading.
GLSL
Use GLSL shading whenever possible for real-time image rendering.

.. _game-engine-settings-render-system:

System
======

The *System* panel at the Render tab of the Properties editor lets the game
developer specify options about the system performance regarding to frame discards and
restrictions about frame renderings, the key to stop the Blender Game Engine,
and whether to maintain geometry in the internal memory of the Graphic card.

.. figure:: /images/gameengine_performance_render_system.png
:width: 300px

System panel in the Render tab.

Use Frame Rate
Respect the frame rate rather than rendering as many frames as possible.
When unchecked, this will inform Blender to run freely without frame rate restrictions.
The frame rate is specified at the *Display* panel in the *Render* tab of the Properties editor.
For more information about frame rates,
see the :ref:`Display panel &lt;game-engine-settings-render-display&gt;` page.
Display Lists
Use display lists to speed up rendering by keeping geometry on the GPU.
When checked, this will tell Blender to maintain the lists of the meshes geometry allocated at the GPU memory.
This can help to speed up viewport rendering during the game if
you have enough GPU memory to allocate geometry and textures.
Restrict Animation Updates
Restrict number of animation updates to the animation FPS
(this is better for performance but can cause issues with smooth playback).
When checked, this will force the Game Engine to discard frames (even at the middle of redrawing,
sometimes causing *tearing* artifacts) if the rate of frames rendered by the GPU is greater than
the specified in the :ref:`Display panel &lt;game-engine-settings-render-display&gt;`.
Use Material Caching
Cache materials in the converter.
This is faster but can cause problems with older single-texture and multi-texture games.
Vsync
Change Vsync settings.
Storage
Set the storage node used by the rasterizer.
Exit Key
This button specifies which keypress will exit the game.

.. _game-engine-settings-render-display:

Display
=======

The *Display* panel in the *Render* tab of the *Properties* editor
lets the game developer specify the maximum frame rate of the animations shown during
the game execution, whether to see informations like framerate and profile, debug properties,
physics geometry visualization, warnings,
whether the mouse cursor is shown during the game execution, and options to specify the framing
style of the game to fit the window with the specified resolution.

.. figure:: /images/gameengine_performance_render_display.jpg

Display panel at the Render tab.

Animation Frame Rate
This number button/slider specify the maximum frame rate at which the game will run.
Minimum is 1, maximum is 120.
Debug Properties
When checked, the values of any properties which are selected to be debugged in the *Game Properties* panel
will be shown with the *Framerate and Profile* contents.
Framerate and Profile
When checked, this will show values for each of the calculations Blender is doing while the game is running,
plus the properties marked to be debugged if *Debug Properties* above is also checked.
Physics visualization
Shows a visualization of physics bounds and interactions (like hulls and collision shapes), and their interaction.
Deprecation Warnings
Every time when the game developer uses a deprecated functionality
(which in some cases are outdated or crippled OpenGL Graphic cards functions),
the system will emit warnings about the deprecated function.
Mouse Cursor
Whether to show or not the mouse cursor when the game is running.
Framing
Selects how the scene is to be fitted onto the display window or screen.
There are three types of framing available:

Letterbox
In Windowed mode:
Maintains a 4:3 aspect ratio by scaling to fit the current window dimensions without cropping,
covering any portions of the display that lie outside of the aspect ratio with color bars.
In Fullscreen mode:
The behavior of this combination seems to be heavily dependent on the user's hardware.
The result can be quite unpredictable, especially with resolutions and aspect ratios that
differ too much from the machine's capabilities. For this reason, *Extend* mode
should be preferred for *Fullscreen* applications.
Extend
This mode behaves much like *Letterbox* mode, maintaining a 4:3 aspect ratio by scaling whenever possible;
except that the camera frustrum is expanded or contracted wherever necessary to fill
any portions of the display that lie outside of the aspect ratio, instead of covering those portions
of the scene with color bars, as with *Letterbox* mode, or distorting then scene, as with *Scale* mode.
Scale
In this mode, no attempt is made to maintain a particular aspect ratio.
The scene and objects within will be stretched or squashed to fit the display exactly.
Color Bar
This will let the game developer choose the bar colors when using the *Letterbox* Framing mode.

.. _game-engine-settings-render-bake:

Bake
====

The *Bake* panel in the *Render* tab of the *Properties* editor is very similar to it's
Blender Render couterpart and serves much the same purpose.
See :doc:`Render Baking &lt;/render/blender_render/bake&gt;` for further details.

.. figure:: /images/gameengine_performance_render_bake.png

Bake panel at the Render tab (showing different bake modes).

Bake
Bake image textures of selected objects.
Bake Mode
Shading information to bake into the image.

Full Render
Bakes all materials, textures, and lighting except specularity and SSS.
Ambient Occlusion
Bakes ambient occlusion as specified in the World panels. Ignores all lights in the scene.
Shadows
Bakes shadows and lighting.
Normals
Bakes tangent and camera-space normals (amongst many others) to an RGB image.
Textures
Bakes colors of materials and textures only, without shading.
Displacement
Similar to baking normal maps, displacement maps can also be baked from a high-res object
to an unwrapped low-res object, using the Selected to Active option.
Derivative
Bake derivative map.
Vertex Colors
Bake vertex colors.
Emissions
Bakes Emit, or the Glow color of a material.
Alpha
Bakes Alpha values, or transparency of a material.
Mirror Intensity
Bake mirror intensity values.
Mirror Colors
Bake mirror colors.
Specular Intensity
Bake specular intensity values.
Specular Colors
Bake specular colors.
Bake from Multires
Bake directly from Multires object.
Normalized
In Displacement Mode:
Normalize to the distance.
In Ambient Occlusion Mode:
Normalize without using material’s settings.
Normal Space
Normals can be baked in different spaces:

Camera space
Default method.
World space
Normals in world coordinates, dependent on object transformation and deformation.
Object space
Normals in object coordinates, independent of object transformation,
but dependent on deformation.
Tangent space
Normals in tangent space coordinates, independent of object transformation and deformation.
This is the new default, and the right choice in most cases, since then the normal map
can be used for animated objects too.
Bake to Vertex Color
Bake to vertex colors instead of to a UV-mapped image.
Clear
If selected, clears the image to selected background color (default is black) before baking render.
Margin
Baked result is extended this many pixels beyond the border of each UV "island", to soften seams in the texture.
Selected to Active
Bake shading on the surface of selected objects to the active object.

Distance
Maximum distance in blender units from active object to other object.
Bias
Bias in blender units toward faces further away from the object.
Split
The method used to split a quad into two triangles for baking.

Fixed
Split quads predictably (0,1,2)(0,2,3).
Fixed Alternate
Split quads predictably (1,2,3)(1,3,0).
Automatic
Split quads to give the least distortion while baking.
User Scale
Apply a custom scale to the derivative map instead of normalizing to the default (0.1).

*****
World
*****

.. figure:: /images/bge_world_materials.png
:align: right

BGE World Panel.

World settings enable you to set some basic effects which affect all scenes throughout your
game, so giving it a feeling of unity and continuity. These include ambient light,
depth effects (mist) and global physics settings. These effects are a limited subset of the
more extensive range of effects available with the Blender internal or Cycles renderer.

.. tip::

While world settings offer a simple way of adding effects to a scene,
:doc:`compositing nodes &lt;/compositing/index&gt;` are often preferred, though more complex to master,
for the additional control and options they offer.
For example, filtering the Z value (distance from camera) or normals (direction of surfaces)
through compositing nodes can further increase the depth and spacial clarity of a scene.

World
=====

These two color settings allow you to set some general lighting effects for your game.

Horizon Color
The RGB color at the horizon;
i.e. the color and intensity of any areas in the scene which are not filled explicitly.
Ambient Color
Ambient light mimics an overall background illumination obtained from diffusing surfaces
(see :doc:`Ambient Light &lt;/render/blender_render/lighting/index&gt;`,
:doc:`Exposure &lt;/render/post_process/color_management&gt;` and
:doc:`Ambient Occlusion &lt;/render/blender_render/world/ambient_occlusion&gt;`).
Its general color and intensity are set by these controls.

Environmental Lighting
======================

Environment light provides light coming from all directions.

Light is calculated with a ray-traced method which is the same as that used by Ambient Occlusion.
The difference is that Environment lighting takes into account the "ambient" parameter of the material
shading settings, which indicates the amount of ambient light/color that that material receives.

Also, you can choose the environment color source (white, sky color, sky texture) and the light energy.

Energy
Defines the strength of environment light.
Environment Color
Defines where the color of the environment light comes from.

Using both settings simultaneously produces better global lighting.

It is good for mimicking the sky in outdoor lighting. Environment lighting can be fairly noisy at times.

Mist
====

Mist can greatly enhance the illusion of depth in your rendering.
To create mist, Blender makes objects farther away more transparent (decreasing their Alpha value)
so that they mix more of the background color with the object color.
With Mist enabled, the further the object is away from the camera the less its alpha value will be.
For full details, see :doc:`Mist &lt;/render/blender_render/world/mist&gt;`.

Mist
Toggles mist on and off.
Falloff
Sets the shape of the falloff of the mist.
Start
The starting distance of the mist effect. No misting will take place for objects closer than this distance.
Depth
The depth at which the opacity of objects falls to zero.
Minimum intensity
Overall minimum intensity of the mist.

*********************
The Blender Community
*********************

Being freely available from the start, even while closed source,
helped considerably for Blender's adoption by the community.
A large, stable, and active community of users has gathered around Blender since 1998.
The community showed its support for Blender in 2002 when they helped raise
€100,000 in seven weeks to enable Blender to go Open Source under the
`GNU GPL License &lt;https://www.gnu.org/copyleft/gpl.html&gt;`__.

Independent Sites
=================

There are `several independent websites &lt;https://www.blender.org/support/user-community/&gt;`__
such as forums, blogs, news, and tutorial sites dedicated to Blender.

One of the largest community forums is `Blender Artists &lt;http://blenderartists.org/forum/&gt;`__,
where Blender users gather to show off their creations,
get feedback, ask and offer help and, in general, discuss Blender.

Getting Support
===============

Blender's community is one of its greatest features, so apart from this user manual,
there are many different ways to get support from other users, such as :ref:`IRC &lt;irc-channels&gt;`
and `Stack Exchange &lt;https://blender.stackexchange.com/&gt;`__.

There are also more official sources of support,
such as `Certified Trainers &lt;https://www.blender.org/certification/&gt;`__
and the `Blender Cloud &lt;https://cloud.blender.org/&gt;`__.
If you think you have found an issue with Blender, you can easily `report a bug
&lt;https://developer.blender.org/maniphest/task/edit/form/1/&gt;`__.

More details about support can be found on the `support page &lt;https://www.blender.org/support/&gt;`__.

Development
===========

Being open source, most of Blender's development is done solely by volunteers.
Communication between developers is done mostly through three platforms:

- The `developer.blender.org &lt;https://developer.blender.org/&gt;`__ system
- Various `mailing lists &lt;https://lists.blender.org/mailman/listinfo&gt;`__
- The #blendercoders IRC channel (see below)

If you are interested in helping develop Blender,
see the `Get Involved &lt;https://www.blender.org/get-involved/&gt;`__ page.

.. _irc-channels:

IRC Channels
============

For real-time discussion, there are some Blender IRC channels on the Freenode network.
You can join these with your favorite IRC client:

- `#blender &lt;irc://irc.freenode.net/blender&gt;`__
For getting answers from the community.
- `#blenderchat &lt;irc://irc.freenode.net/blenderchat&gt;`__
For general discussion or off topic chat.
- `#blendercoders &lt;irc://irc.freenode.net/blendercoders&gt;`__
For developers to discuss Blender development.
- `#blenderpython &lt;irc://irc.freenode.net/blenderpython&gt;`__
For support for developers using the Python API.
- `#gameblender &lt;irc://irc.freenode.net/gameblender&gt;`__
For discussion on issues related to game creation with the GE.
- `#blenderwiki &lt;irc://irc.freenode.net/blenderwiki&gt;`__
For discussion related to Blender's documentation.

.. note::

If you do not have an IRC client, you can access IRC using `webchat &lt;https://webchat.freenode.net/&gt;`__.

There also several more Blender-related channels not listed here
(e.g. channels for speakers of a particular language).
We recommend you search Freenode to see them all.

Other Useful Links
==================

- `Blender FAQ &lt;https://www.blender.org/support/faq/&gt;`__ (Can I use Blender commercially? What is GPL/GNU? ...)
- `Demo and benchmark files &lt;https://www.blender.org/download/demo-files/&gt;`__
- Developers `Ask Us Anything! &lt;https://wiki.blender.org/index.php/Dev:Doc/AskUsAnything&gt;`__

*****************
Blender's History
*****************

In 1988, Ton Roosendaal co-founded the Dutch animation studio NeoGeo. NeoGeo quickly became
the largest 3D animation studio in the Netherlands and one of the leading animation houses in
Europe. NeoGeo created award-winning productions (European Corporate Video Awards 1993 and 1995)
for large corporate clients such as multinational electronics company Philips.
Within NeoGeo Ton was responsible for both art direction and internal software development.
After careful deliberation Ton decided that the current in-house 3D toolset for NeoGeo was
too old and cumbersome to maintain, and needed to be rewritten from scratch. In
1995 this rewrite began and was destined to become the 3D software creation we all know as
Blender. As NeoGeo continued to refine and improve Blender it became apparent to Ton that
Blender could be used as a tool for other artists outside of NeoGeo.

In 1998, Ton decided to found a new company called Not a Number (NaN)
as a spin-off of NeoGeo to further market and develop Blender.
At the core of NaN was a desire to create and distribute a compact,
cross-platform 3D application for free. At the time, this was a revolutionary concept as most
commercial 3D applications cost thousands of dollars. NaN hoped to bring professional
level 3D modeling and animation tools within the reach of the general computing public.
NaN's business model involved providing commercial products and services around Blender. In
1999 NaN attended its first SIGGRAPH conference in an effort to more widely promote Blender.
Blender's first SIGGRAPH convention was a huge success and gathered a tremendous amount of
interest from both the press and attendees. Blender was a hit and its huge potential confirmed!

Following the success of the SIGGRAPH conference in early 2000, NaN secured financing of €4.5M from
venture capitalists. This large inflow of cash enabled NaN to rapidly expand its operations.
Soon NaN boasted as many as fifty employees working around the world trying to improve and promote Blender.
In the summer of 2000, Blender 2.0 was released.
This version of Blender added the integration of a game engine to the 3D application.
By the end of 2000, the number of users registered on the NaN website surpassed 250,000.

Unfortunately, NaN's ambitions and opportunities did not match the company's capabilities and
the market realities of the time. This over-extension resulted in restarting NaN with new
investor funding and a smaller company in April 2001.
Six months later NaN's first commercial software product, Blender Publisher was launched.
This product was targeted at the emerging market of interactive web-based 3D media.
Due to disappointing sales and the ongoing difficult economic climate,
the new investors decided to shut down all NaN operations.
The shutdown also included discontinuing the development of Blender.
Although there were clearly shortcomings in the then current version of Blender,
such as a complex internal software architecture,
unfinished features and a non-standard way of providing the GUI, the enthusiastic support from
the user community and customers who had purchased Blender Publisher in the past meant that
Ton could not justify leaving Blender to fade into insignificance.
Since restarting a company with a sufficiently large team of developers was not feasible,
Ton Roosendaal founded the non-profit organization Blender Foundation in March 2002.

The Blender Foundation's primary goal was to find a way to continue developing and promoting
Blender as a community-based `open source &lt;https://opensource.org/&gt;`__ project. In July 2002,
Ton managed to get the NaN investors to agree to a unique Blender Foundation plan to attempt
to release Blender as open source. The "Free Blender" campaign sought to raise €100,000 so
that the Foundation could buy the rights to the Blender source code and intellectual property
rights from the NaN investors and subsequently release Blender to the open source community.
With an enthusiastic group of volunteers, among them several ex-NaN employees,
a fundraising campaign was launched to "Free Blender".
To everyone's surprise and delight the campaign reached the €100,000 goal in only seven short weeks.
On Sunday, October 13, 2002,
Blender was released to the world under the terms of the `GNU GPL &lt;https://www.gnu.org/copyleft/gpl&gt;`__.
Blender development continues to this day driven by a team of dedicated volunteers from around the
world led by Blender's original creator, Ton Roosendaal.

Version/Revision Milestones
===========================

The start!
----------

- 1.00 -- January 1994: Blender
`in development &lt;https://code.blender.org/2013/12/how-blender-started-twenty-years-ago/&gt;`__
at animation studio NeoGeo.
- 1.23 -- January 1998: SGI version published on the web, IrisGL.
- 1.30 -- April 1998: Linux and FreeBSD version, port to OpenGL and X11.
- 1.3x -- June 1998: NaN founded.
- 1.4x -- September 1998: Sun and Linux Alpha version released.
- 1.50 -- November 1998: First Manual published.
- 1.60 -- April 1999: C-key (new features behind a lock, $95), MS-Windows version released.
- 1.6x -- June 1999: BeOS and PPC version released.
- 1.80 -- June 2000: End of C-key, Blender full freeware again.
- 2.00 -- August 2000: Interactive 3D and real-time engine.
- 2.10 -- December 2000: New engine, physics, and Python.
- 2.20 -- August 2001: Character animation system.
- 2.21 -- October 2001: Blender Publisher launch.
- 2.2x -- December 2001: macOS version.

Blender goes Open Source
------------------------

- **13 October 2002: Blender goes Open Source, 1st Blender Conference**.
- 2.25 -- October 2002:
`Blender Publisher &lt;https://download.blender.org/release/Publisher2.25/&gt;`__ becomes freely available,
and the experimental tree of Blender is created, a coder's playground.
- 2.26 -- February 2003: The first truly open source Blender release.
- 2.27 -- May 2003: The second open source Blender release.
- 2.28x -- July 2003: First of the 2.28x series.
- `2.30 &lt;https://archive.blender.org/development/release-logs/blender-230/&gt;`__ -- October 2003:
Preview release of the 2.3x UI makeover presented at the 2nd Blender Conference.
- `2.31 &lt;https://archive.blender.org/development/release-logs/blender-231/&gt;`__ -- December 2003:
Upgrade to stable 2.3x UI project.
- `2.32 &lt;https://archive.blender.org/development/release-logs/blender-232/&gt;`__ -- January 2004:
A major overhaul of internal rendering capabilities.
- `2.33 &lt;https://archive.blender.org/development/release-logs/blender-233/&gt;`__ -- April 2004:
Game Engine returns, ambient occlusion, new procedural textures.
- `2.34 &lt;https://archive.blender.org/development/release-logs/blender-234/&gt;`__ -- August 2004:
Particle interactions, LSCM UV mapping, functional YafRay integration, weighted creases in subdivision surfaces,
ramp shaders, full OSA, and many many more.
- `2.35 &lt;https://archive.blender.org/development/release-logs/blender-235a/&gt;`__ -- November 2004:
Another version full of improvements: object hooks, curve deforms and curve tapers,
particle duplicators and much more.
- `2.36 &lt;https://archive.blender.org/development/release-logs/blender-236/&gt;`__ -- December 2004:
A stabilization version, much work behind the scene, normal and displacement mapping improvements.
- `2.37 &lt;https://archive.blender.org/development/release-logs/blender-237a/&gt;`__ -- June 2005:
Transformation tools and widgets, softbodies, force fields, deflections,
incremental subdivision surfaces, transparent shadows, and multi-threaded rendering.
- `2.40 &lt;https://wiki.blender.org/index.php/Dev:Ref/Outdated/Release_Notes/2.40&gt;`__ -- December 2005:
Full rework of armature system, shape keys, fur with particles, fluids, and rigid bodies.
- `2.41 &lt;https://wiki.blender.org/index.php/Dev:Ref/Outdated/Release_Notes/2.41&gt;`__ -- January 2006:
Lots of fixes, and some Game Engine features.
- `2.42 &lt;https://wiki.blender.org/index.php/Dev:Ref/Outdated/Release_Notes/2.42&gt;`__ -- July 2006:
The nodes release, array modifier, vector blur, new physics engine, rendering, lip sync, and many other features.
This was the release following `Project Orange &lt;https://orange.blender.org/&gt;`__.
- `2.43 &lt;https://wiki.blender.org/index.php/Dev:Ref/Outdated/Release_Notes/2.43&gt;`__ -- February 2007:
Multi-resolution meshes, multi-layer UV textures, multi-layer images and multi-pass rendering and baking,
sculpting, retopology, multiple additional mattes, distort and filter nodes, modeling and animation improvements,
better painting with multiple brushes, fluid particles,
proxy objects, sequencer rewrite, and post-production UV texturing.
- `2.44 &lt;http://archive.blender.org/development/release-logs/blender-244/index.html&gt;`__ -- May 2007:
The big news, in addition to two new modifiers and re-awakening the 64-bit OS support, was the addition
of subsurface scattering, which simulates light scattering beneath the surface of organic and soft objects.
- `2.45 &lt;http://archive.blender.org/development/release-logs/blender-245/index.html&gt;`__ -- September 2007:
Serious bug fixes, with some performance issues addressed.
- `2.46 &lt;https://wiki.blender.org/index.php/Dev:Ref/Outdated/Release_Notes/2.46&gt;`__ -- May 2008:
The Peach release was the result of a huge effort of over 70 developers providing enhancements to
provide hair and fur, a new particle system, enhanced image browsing, cloth, a seamless
and non-intrusive physics cache, rendering improvements in reflections, AO, and render baking, a mesh deform
modifier for muscles and such, better animation support via armature tools and drawing, skinning,
constraints and a colorful Action Editor, and much more. It was the release following
`Project Peach &lt;https://peach.blender.org/&gt;`__.
- `2.47 &lt;https://wiki.blender.org/index.php/Dev:Ref/Outdated/Release_Notes/2.47&gt;`__ -- August 2008:
Bugfix release.
- `2.48 &lt;http://archive.blender.org/development/release-logs/blender-248/index.html&gt;`__ -- October 2008:
The Apricot release, cool GLSL shaders, lights and GE improvements, snap, sky simulator, shrinkwrap
modifier, and Python editing improvements.
This was the release following `Project Apricot &lt;https://apricot.blender.org/&gt;`__.
- `2.49 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.49&gt;`__ -- June 2009:
Node-based textures, armature sketching (called Etch-a-Ton), boolean mesh operation improvements,
JPEG2000 support, projection painting for direct transfer of images to models, and a significant Python
script catalog. GE enhancements included video textures, where you can play movies in-game, upgrades
to the Bullet physics engine, dome (fish-eye) rendering, and more API GE calls made available.

Blender 2.5x -- The Recode!
---------------------------

`2.5x &lt;https://wiki.blender.org/index.php/Dev:2.5/Source&gt;`__ -- From 2009 to August 2011:
This series released four `pre-version &lt;https://archive.blender.org/development/release-logs/blender-256-beta&gt;`__
(from Alpha 0 in November 2009 to Beta in July 2010) and three stable versions (from 2.57 - April 2011
to 2.59 - August 2011). It is one of the most important development projects, with a total refactor of
the software with new functions, redesign of the internal window manager and event/tool/data handling system,
and new Python API. The final version of this project was Blender 2.59 in August 2011.

.. rubric:: Video: From Blender 1.60 to 2.50

.. vimeo:: 8567074

Blender 2.6x to 2.7x -- Improvements &amp; Stabilizing
--------------------------------------------------

- `2.60 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.60&gt;`__ -- October 2011:
Internationalization of the UI, improvements in animation system and the GE, vertex weight groups modifiers,
3D audio and video, and bug fixes.
- `2.61 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.61&gt;`__ -- December 2011:
The Cycles renderer was added in trunk, the camera tracker was added, dynamic paint for modifying textures
with mesh contact/approximation, the Ocean modifier to simulate ocean and foam, new add-ons, bug fixes,
and more extensions added for the Python API.
- `2.62 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.62&gt;`__ -- February 2012:
The `Carve library &lt;https://code.google.com/archive/p/carve/&gt;`__ was added to improve boolean operations,
support for object tracking was added, the Remesh modifier was added, many improvements in the GE,
matrices and vectors in the Python API were improved, new add-ons, and many bug fixes.
- `2.63 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.63&gt;`__ -- April 2012:
Bmesh was merged to trunk with full support for n-sided polygons, sculpt hiding, a panoramic camera
for Cycles, mirror ball environment textures and float precision textures, render layer mask layers,
ambient occlusion and viewport display of background images and render layers, new import and export
add-ons were added, and 150 bug fixes.
- `2.64 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.64&gt;`__ -- October 2012:
Mask editor, improved motion tracker, OpenColorIO, Cycles improvements, sequencer improvements,
better mesh tools (Inset and Bevel were improved), new keying nodes, sculpt masking, Collada improvements,
new skin modifier, new compositing nodes backend, and many bugs were fixed.
- `2.65 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.65&gt;`__ -- December 2012:
Fire and smoke improvements, anisotropic shader for Cycles, modifier improvements,
bevel tool now includes rounding,
new add-ons, and over 200 bug fixes.
- `2.66 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.66&gt;`__ -- February 2013:
Dynamic topology, rigid body simulation, improvements in UI and usability (including retina display
support), Cycles now supports hair, the bevel tool now supports individual vertex beveling,
new :doc:`Mesh Cache &lt;/modeling/modifiers/modify/mesh_cache&gt;` modifier and the
new :doc:`UV Warp &lt;/modeling/modifiers/modify/uv_warp&gt;` modifier,
new SPH particle fluid solver. More than 250 bug fixes.
- `2.67 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.67&gt;`__ -- May 2013:
Freestyle was added, paint system improvements, subsurface scattering for Cycles, Ceres library in the
motion tracker, new custom Python nodes, new mesh modeling tools, better support for UTF-8 text and
improvements in text editors, new add-ons for 3D printing, over 260 bug fixes.
- `2.68 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.68&gt;`__ -- July 2013:
New and improved modeling tools, three new Cycles nodes, big improvements in the motion tracker,
Python scripts and drivers are disabled by default when loading files for security reasons, and over 280 bug fixes.
- `2.69 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.69&gt;`__ -- October 2013:
Even more modeling tools, Cycles improved in many areas, plane tracking is added to the motion tracker,
better support for FBX import/export, and over 270 bugs fixed.
- `2.70 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.70&gt;`__ -- March 2014:
Cycles gets basic volumetric support on the CPU, more improvements to the motion tracker, two new modeling
modifiers, some UI consistency improvements, and more than 560 bug fixes.
- `2.71 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.71&gt;`__ -- June 2014:
Deformation motion blur and fire/smoke support is added to Cycles, UI pop-ups are now draggable,
performance optimizations for sculpting mode, new interpolation types for animation, many improvements
to the GE, and over 400 bug fixes.
- `2.72 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.72&gt;`__ -- October 2014:
Cycles gets volume and SSS support on the GPU, pie menus are added and tooltips greatly improved,
the intersection modeling tool is added, new sun beam node for the compositor, Freestyle now works with
Cycles, texture painting workflow is improved, and more than 220 bug fixes.
- `2.73 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.73&gt;`__  -- January 2015:
Cycles gets improved volumetric support, major upgrade to grease pencil,
MS-Windows gets Input Method Editors (IMEs)
and general improvements to painting, freestyle, sequencer and add-ons.
- `2.74 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.74&gt;`__ -- March 2015:
Support for custom-normals, viewport compositing and improvements to hair dynamics.
- `2.75 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.75&gt;`__  -- July 2015:
Integrated stereo/multi-view pipeline, corrective smooth modifier
and new dependency graph *(enable as a command line option)*.
- `2.76 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.76&gt;`__  -- November 2015:
Pixar OpenSubdiv support, Viewport and File Browser performance boost,
node auto-offset, and a text effect strip for the Sequencer.
- `2.77 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.77&gt;`__ -- March 2016:
OpenVDB support for caching for smoke/volumetric simulations, improved Cycles Subsurface Scattering,
Grease pencil stroke sculpting and improved workflow,
and reworked library handling to manage missing and deleted data-blocks.
- `2.78 &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.78&gt;`__ -- September 2016:
Cycles support for spherical stereo images for VR,
Grease Pencil works more similar to other 2D drawing softwares,
Alembic import and export support, and improvements to Bendy Bones for easier and simpler rigging.
.. _introduction-index:

################
About Blender
################

.. toctree::
:maxdepth: 2

introduction.rst
history.rst
license.rst
community.rst

************
Introduction
************

Welcome to Blender, the free and open source 3D creation suite.

Blender can be used to create 3D visualizations such as still images, video, and real-time interactive video games.

Blender is well suited to individuals and small studios who
benefit from its unified pipeline and responsive development process.

Blender is a cross-platform application, running on Linux, macOS, and MS-Windows systems.
Blender also has a relatively small memory and drive requirements compared to other 3D creation suites.
Its interface uses OpenGL to provide a consistent experience across all supported hardware and platforms.

.. figure:: /images/getting-started_intro_bigbuckbunny.jpg

Blender 2.5 with a Big Buck Bunny scene open.

Who uses Blender?
=================

Blender has a wide variety of tools making it suitable for almost any sort of media production.
People and studios around the world use it for hobby projects, commercials, feature films,
games and other interactive applications like kiosks, games and scientific research.

Check out the `User Stories page &lt;https://www.blender.org/features/user-stories/&gt;`__
on the Blender website for more examples.

Key Features
============

- Blender is a fully integrated 3D content creation suite, offering a broad range of essential tools, including
:doc:`Modeling &lt;/modeling/introduction&gt;`,
:doc:`Rendering &lt;/render/introduction&gt;`,
:doc:`Animation &lt;/animation/introduction&gt;`,
:doc:`Video Editing &lt;/editors/vse/index&gt;`,
:doc:`VFX &lt;/editors/movie_clip_editor/index&gt;`,
:doc:`Compositing &lt;/compositing/introduction&gt;`,
:doc:`Texturing &lt;/editors/uv_image/uv_editing/overview&gt;`,
:doc:`Rigging &lt;/rigging/introduction&gt;`,
many types of :doc:`Simulations &lt;/physics/introduction&gt;`,
and :doc:`Game Creation &lt;/game_engine/introduction&gt;`.
- Cross platform, with an OpenGL GUI that is uniform on all major platforms (and customizable with Python scripts).
- High-quality 3D architecture enabling fast and efficient creation work-flow.
- Excellent community support from `forums &lt;http://blenderartists.org/forum/&gt;`__ and :ref:`IRC &lt;irc-channels&gt;`.
- Small executable size, optionally portable.

You can download the latest version of Blender `here &lt;https://www.blender.org/download/&gt;`__.

.. figure:: /images/getting-started_intro_postprocessing.jpg

A rendered image being post-processed.

Blender makes it possible to perform a wide range of tasks, and it may seem daunting when first
trying to grasp the basics. However, with a bit of motivation and the right learning material,
it is possible to familiarize yourself with Blender after a few hours of practice.

This manual is a good start though it serves more as a reference.
There are also many online video tutorials from specialized websites, and several
books and training DVDs available in the `Blender Store &lt;https://store.blender.org/&gt;`__
and on the `Blender Cloud &lt;https://cloud.blender.org/&gt;`__.

Despite everything Blender can do, it remains a tool. Great artists do not create masterpieces
by pressing buttons or manipulating brushes, but by learning and practicing subjects
such as human anatomy, composition, lighting, animation principles, etc.

3D creation software such as Blender have the added technical complexity and
jargon associated with the underlying technologies.
Terms like UV maps, materials, shaders, meshes, and "subsurf" are the mediums of the
digital artist, and understanding them, even broadly, will help you to use Blender to its best.

So keep reading this manual, learn the great tool that Blender is, keep your mind open to
other artistic and technological areas and you too can become a great artist.

*******************************
About Free Software and the GPL
*******************************

.. figure:: /images/getting-started_about_license_gnu-logo.png
:align: right

When one hears about "free software", the first thing that comes to mind might be "no cost".
While this is typically true, the term "free software" as used by the Free Software Foundation
(originators of the GNU Project and creators of the GNU General Public License)
is intended to mean "free as in freedom" rather than the "no cost" sense
(which is usually referred to as "free as in free beer" or *gratis*).
Free software in this sense is software which you are free to use, copy, modify, redistribute, with no limit.
Contrast this with the licensing of most commercial software packages,
where you are allowed to load the software on a single computer,
are allowed to make no copies, and never see the source code.
Free software allows incredible freedom to the end user.
Since the source code is universally available, there are also many more chances for bugs to be caught and fixed.

When a program is licensed under the GNU General Public License (the GPL):

- You have the right to use the program for any purpose.
- You have the right to modify the program and have access to the source codes.
- You have the right to copy and distribute the program.
- You have the right to improve the program, and release your own versions.

In return for these rights, you have some responsibilities if you distribute a GPL'd program,
responsibilities that are designed to protect your freedoms and the freedoms of others:

- You must provide a copy of the GPL with the program,
so that recipients are aware of their rights under the license.
- You must include the source code or make the source code freely available.
- If you modify the code and distribute the modified version,
you must license your modifications available under the GPL (or a compatible license).
- You may not restrict the licensing of the program beyond the terms of the GPL.
(you may not turn a GPL'd program into a proprietary product.)

For more on the GPL, check its page on the
`GNU Project website &lt;https://www.gnu.org/licenses/licenses.html#GPL&gt;`__.

.. note::

The GPL only applies to the Blender application and **not** the artwork you create with it;
for more info see the `Blender License &lt;https://www.blender.org/about/license/&gt;`__.

***********
Help System
***********

Blender has a range of built-in and web-based help options.

Tooltips
========

.. figure:: /images/getting_started_help_tooltip.png

Tooltip of the Render Engine selector in the Info Editor.

When hovering the mouse cursor over a button or setting, after a few instants a tooltip appears.

Elements
---------

The context-sensitive Tooltip might contain some of these elements:

Short Description
Related details depending on the control.
Shortcut
A keyboard or mouse shortcut associated to the tool.
Value
The value of the property.
Python
For :ref:`scripting &lt;scripting-index&gt;` -- A Python command associated to
the control (usually an operator or property).

.. _help-manual-access:

Context Sensitive Manual Access
===============================

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :kbd:`RMB`, :menuselection:`Online Manual`
| Hotkey:   :kbd:`Alt-F1`

You may want to access help for a tool or area from within Blender.

Use the key-shortcut, or context menu to visit pages from this reference manual within Blender.
This opens a webpage relating to the button under the cursor, supporting both tool and value buttons.

.. note::

We do not currently have 100% coverage,
you may see an alert in the info header if some tools do not have a link to the manual.

Other times buttons may link to more general sections of the documentation.

.. _help-menu:

Help Menu
=========

The *Help* menu in the Info Editor header.

.. figure:: /images/getting_started-help_menu.png
:align: right

Help Menu.

Web Links
---------

The first options of this menu provide direct links to Blender related websites:
The same links can also be found in the :ref:`splash`.

Manual
This is a link to the :doc:`Official Blender Manual &lt;/index&gt;`
which you are now reading.
Release Log
The `release notes &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/&gt;`__ on the Web
for the changes made for the current Blender version.
Blender Website
The `blender.org &lt;https://www.blender.org/&gt;`__ home page.
Blender Store
The `Blender Store &lt;https://store.blender.org/&gt;`__ , where you can buy
Training DVD's, books, t-shirts and other products.
Developer Community
The *blender.org* `Get Involved &lt;https://www.blender.org/get-involved/&gt;`__ page.
This is the launch page for Blender software development, bug tracking, patches and scripts,
education and training, documentation development and functionality research.
User Community
Lists of many different `support venues &lt;https://www.blender.org/support/user-community/&gt;`__.
Report a Bug
The `Blender Bug Tracker &lt;https://developer.blender.org/maniphest/task/edit/form/1/&gt;`__ (registration needed).

.. tip:: Browser and Internet Connection

Some forms of Help start up your web browser and access the Blender Foundation's web servers.
In order to do this, you must have configured a default web browser for your Operating System,
and have a connection to the Internet.

Scripting Reference
-------------------

Python API Reference
Python application programming interface (API)
`Reference &lt;https://www.blender.org/api/blender_python_api_current/&gt;`__.
Operator Cheat Sheet
Creates the ``OperatorList.txt`` text-block, which you can access in the *Text Editor*.
You can also use Blender Search to generate the file. It lists the available Python operators.

.. _help-system-info:

Save System Info
----------------

Access :menuselection:`Help --&gt; Save System Info`.

This extracts system information which can be useful to include in bug reports,
inspecting the configuration or diagnosing problems.

You will be prompted to save a text file ``system-info.txt``.

The text file contains sections:

Blender
This section shows you the Blender version, details about the build configuration,
and the path in which Blender is running.
Python
The Python version you are using, showing the paths of the Python programming language paths.
Directories
Paths used for scripts, data-files, presets and temporary files.

Those directories are configured using the :doc:`User Preferences &lt;/preferences/file&gt;` Editor.
OpenGL
This section shows the OpenGL version, the name of the manufacturer,
and lists the capabilities of your hardware and driver.

Splash Screen
-------------

Shows the :ref:`splash`.
.. _getting-started-index:

##################
Getting Started
##################

.. keep up to date with :doc:`&lt;/index&gt;`

.. toctree::
:maxdepth: 2

about/index.rst
installing/index.rst
help.rst
.. _getting-started_installing-config-directories:

***********************
Configuring Directories
***********************

There are three different directories Blender may use,
their exact locations are operating system dependent.

LOCAL
Location of configuration and runtime data (for self-contained bundle)
USER
Location of configuration files (normally in the user's home directory).
SYSTEM
Location of runtime data for system wide installation (may be read-only).

For system installations both **SYSTEM** and **USER** directories are needed.

For locally extracted Blender distributions, the user configuration and data runtime data are
kept in the same sub-directory, allowing multiple Blender versions to run without conflict,
ignoring the **USER** and **SYSTEM** files.

.. note::

You may need to have the "show hidden files" option checked in your file browser settings.

Platform Dependent Paths
========================

Here are the default locations for each system:

Linux
-----

LOCAL
.. parsed-literal:: ./|BLENDER_VERSION|/
USER
.. parsed-literal:: $HOME/.config/blender/|BLENDER_VERSION|/
SYSTEM
.. parsed-literal:: /usr/share/blender/|BLENDER_VERSION|/

.. note::
The path ./|BLENDER_VERSION|/ is relative to the Blender Executable &amp;
used for self-contained bundles distributed by official blender.org builds.

.. note::
The **USER** path will use ``$XDG_CONFIG_HOME`` if its set:

.. parsed-literal:: $XDG_CONFIG_HOME/blender/|BLENDER_VERSION|/

macOS
-----

LOCAL
.. parsed-literal:: ./|BLENDER_VERSION|/
USER
.. parsed-literal:: /Users/$USER/Library/Application Support/Blender/|BLENDER_VERSION|/
SYSTEM
.. parsed-literal:: /Library/Application Support/Blender/|BLENDER_VERSION|/

.. note::

macOS stores the Blender binary in ``./blender.app/Contents/MacOS/blender``,
so the local path to data &amp; config is:

.. parsed-literal:: ./blender.app/Contents/MacOS/|BLENDER_VERSION|/

.. MS-Windows no longer works loke this: update paths (TODO).

MS-Windows
----------

LOCAL
.. parsed-literal:: .\\\ |BLENDER_VERSION|\\.
USER
.. parsed-literal::

C:\\Documents and Settings\\$USERNAME\\AppData\\Roaming\\Blender Foundation\\Blender\\\ |BLENDER_VERSION|\\
SYSTEM
.. parsed-literal::

C:\\Documents and Settings\\All Users\\AppData\\Roaming\\Blender Foundation\\Blender\\\ |BLENDER_VERSION|\\

Path Layout
===========

This is the path layout which is used within the directories described above.

Where ``./config/startup.blend`` could be ~/.blender/|BLENDER_VERSION|/config/startup.blend
for example.

``./autosave/ ...``
Autosave blend-file location. (Windows only, temp directory used for other systems).

Search order: ``LOCAL, USER``.

``./config/ ...``
Defaults &amp; session info.

Search order: ``LOCAL, USER``.

``./config/startup.blend``
Default file to load on startup.

``./config/userpref.blend``
Default preferences to load on startup.

``./config/bookmarks.txt``
File Browser bookmarks.

``./config/recent-files.txt``
Recent file menu list.

``./datafiles/ ...``
Runtime files.

Search order: ``LOCAL, USER, SYSTEM``.

``./datafiles/locale/{language}/``
Static precompiled language files for UI translation.

``./datafiles/icons/*.png``
Icon themes for Blender's user interface. (Not currently selectable in the theme preferences).

``./datafiles/brushicons/*.png``
Images for each brush.

``./scripts/ ...``
Python scripts for the user interface and tools.

Search order: ``LOCAL, USER, SYSTEM``.

``./scripts/addons/*.py``
Python add-ons which may be enabled in the User Preferences include import/export format support,
render engine integration and many handy utilities.

``./scripts/addons/modules/*.py``
Modules for add-ons to use (added to Python's sys.path).

``./scripts/addons_contrib/*.py``
Another add-ons directory which is used for community maintained add-ons (must be manually created).

``./scripts/addons_contrib/modules/*.py``
Modules for ``addons_contrib`` to use (added to Python's sys.path).

``./scripts/modules/*.py``
Python modules containing our core API and utility functions for other scripts to import
(added to Python's ``sys.path``).

``./scripts/startup/*.py``
Scripts which are automatically imported on startup.

``./scripts/presets/{preset}/*.py``
Presets used for storing user defined settings for cloth, render formats etc.

``./scripts/templates_py/*.py``
Example scripts which can be accessed from :menuselection:`Text Editor --&gt; Templates --&gt; Python`.

``./scripts/templates_osl/*.py``
Example OSL shaders which can be accessed from
:menuselection:`Text Editor --&gt; Templates --&gt; Open Shading Language`.

``./python/ ...``
Bundled Python distribution, only necessary when the system Python installation is absent or incompatible.

Search order: ``LOCAL, SYSTEM``.

.. _temp-dir:

Temporary Directory
===================

The temporary directory is used to store various files at runtime
(including render layers, physics cache, copy-paste buffer and crash logs).

The temporary directory is selected based on the following priority:

- User Preference (see :ref:`prefs-file-paths`).
- Environment variables (``TEMP`` on MS-Windows, ``TMP`` &amp; ``TMP_DIR`` on other platforms).
- The ``/tmp/`` directory.

***********************
Configuring Peripherals
***********************

Displays
========

Todo.

.. Include HMD for the future

Multi-Monitor Setup
-------------------

.. figure:: /images/getting_started_multi_monitor.jpg

This is an example of Blender's multi-monitor support.

Input Devices
=============

.. Add note about emulate 3D button mouse and numpad.

Blender supports various types of input devices:

- Keyboard (recommended: keyboard with numeric keypad, English layout works best)
- Mouse (recommended: 3 button mouse with scroll wheel)
- NDOF Devices (also known as *3D Mouse*)
- Graphic Tablets

Mice
----

Mouse Button Emulation
^^^^^^^^^^^^^^^^^^^^^^

If you do not have a 3 button mouse,
you will need to emulate it by checking the option in the :doc:`User Preferences &lt;/preferences/input&gt;`.

The following table shows the combinations used:

.. list-table::
:stub-columns: 1

* - 3-button Mouse
- :kbd:`LMB`
- :kbd:`MMB`
- :kbd:`RMB`
* - 2-button Mouse
- :kbd:`LMB`
- :kbd:`Alt-LMB`
- :kbd:`RMB`

Keyboards
---------

Numpad Emulation
^^^^^^^^^^^^^^^^

If you do not have a numeric Numpad on the side of your keyboard,
you may want to emulate one (uses the numbers at the top of the keyboard instead,
however, removes quick access to layer visibility).

.. seealso::

Read more about *Numpad Emulation* in the :doc:`User Preferences &lt;/preferences/input&gt;`

Non English Keyboards
^^^^^^^^^^^^^^^^^^^^^

If you use a keyboard with a non-english keyboard layout, you still may benefit from switching
your computer to the UK or US layout as long as you work with Blender.

.. note::

You can also change the default keymap and default hotkeys from the
:doc:`User Preferences &lt;/preferences/input&gt;`, however, this manual assumes you are using the default keymap.

.. _hardware-tablet:

Graphic Tablets
---------------

Graphics tablets can be used to provide a more traditional method of controlling the mouse cursor using a pen.
This can help to provide a more familiar experience for artists
who are used to painting and drawing with similar tools,
as well as provide additional controls such as pressure sensitivity.

.. note::

If you are using a graphic tablet instead of a mouse and pressure sensitivity does not work properly,
try to place the mouse pointer in the Blender window and then unplug/replug your graphic tablet. This might help.

3D Mice
-------

3D Mice or :abbr:`NDOF (N-Degrees of Freedom)` devices are hardware that you can use to navigate a scene in Blender.
Currently only devices made by 3Dconnexion are supported.
These devices allow you to explore a scene, as well as :ref:`Walk/Fly modes &lt;3dview-walk-fly&gt;`.

.. seealso::

See :doc:`Input Preference &lt;/preferences/input&gt;` for more information on configuring peripherals.

######################
Configuring Blender
######################

.. toctree::
:maxdepth: 2

introduction.rst
hardware.rst
directories.rst

************
Introduction
************

Here are some preferences that you may wish to set initially.
The full list and explanation of the user preferences are documented in the section
:doc:`User Preferences &lt;/preferences/index&gt;`.

Language
========

At :menuselection:`File --&gt; User Preferences --&gt; System`, enable *International Fonts* to choose the
*Language* and what to translate from *Interface*, *Tooltips* and *New Data*.

See :ref:`prefs-system-international` for details.

Input
=====

If you have a compact keyboard without a separate number pad enable
:menuselection:`File --&gt; User Preferences --&gt; Emulate Numpad`.

If you do not have a middle mouse button you can enable
:menuselection:`File --&gt; User Preferences --&gt; Emulate 3 Button Mouse`.

See :doc:`Input Preferences &lt;/preferences/input&gt;` for details.

File and Paths
==============

At :menuselection:`File --&gt; User Preferences --&gt; File`
you can set options such as what external *Image Editor* to use,
such as GIMP or Krita, and the Animation Player.

The :ref:`temp-dir` sets where to store files such as temporary renders and auto-saves.

.. tip::

The ``//`` at the start of each path in Blender means the directory of the currently opened blend-file,
used to reference relative paths.

If you trust the source of your blend-files, you can enable *Auto Run Python Scripts*.
This option is meant to protect you from malicious Python scripts that someone can include inside a blend-file.
This would not happen by accident,
and most users leave this option on to automatically run scripts often used in advanced rigs
(such as "Rigify" that controls the skeleton of a human rig).

See :doc:`File Preferences &lt;/preferences/file&gt;` for details.

#####################
Installing Blender
#####################

.. toctree::
:maxdepth: 2

introduction.rst
configuration/index.rst

************
Introduction
************

Blender is available for download for Linux, macOS and MS-Windows.

Minimum Requirements
====================

Check if your system meets the
`minimum or recommended requirements &lt;https://www.blender.org/download/requirements/&gt;`__.

Always check that the graphics drivers are up to date and that OpenGL is well supported.

Support for other hardware such as graphic tablets and 3D mice are covered later in
:doc:`Supported Hardware &lt;/getting_started/installing/configuration/hardware&gt;`.

Download Blender
================

The Blender Foundation distributes Blender in three different ways
that you can choose from, to better suit your needs.

The options comprise binary packages for all the supported platforms and the source code. Within the binary packages,
you can choose from a stable release or a daily build. The first has the benefit of being more reliable, the latter
provides the newest features, as they are developed. Blender is released approximately every three months.
You can keep up to date with the newest changes
through the `release notes &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/&gt;`__.

`Latest Stable Release &lt;https://www.blender.org/download/&gt;`__
This is a binary distribution of the latest version of Blender.
It is considered stable and without regressions.
`Daily Builds &lt;https://builder.blender.org/download&gt;`__
This is a binary distribution of Blender that is updated daily to include the newest changes in development.
These versions are not as thoroughly tested as the stable release, and might break,
although they are official and generally not highly experimental.
`Build from Source &lt;https://wiki.blender.org/index.php/Dev:Doc/Building_Blender&gt;`__
Blender's source is available for reference and installation, with the following advantages:

- Blender is always up to date,
- it allows access to any version or branch where a feature is being developed,
- it can be freely customized.

.. note::

This is included for completeness, but it is **not** expected
that regular users should have to compile their own Blender builds.

Install Blender
===============
The procedure for installing a binary, either the last stable release or a daily build, is the same.
Follow the steps for your operative system:

.. toctree::
:maxdepth: 1

linux.rst
macos.rst
windows.rst

*******************
Installing on Linux
*******************

Check the :doc:`minimum requirements and where to get Blender &lt;/getting_started/installing/introduction&gt;`,
if you have not done so yet.

Specific packages for distributions
===================================

Some Linux distributions may have on their repositories a specific package for Blender.

Installing Blender via the distribution's native mechanisms ensures consistency with other packages on the system
and may provide other features (given by the package manager),
such as listing of packages, update notifications and automatic menu configuration.
Be aware, though, that the package may be outdated comparing to the latest official release,
or not include some features of Blender.
For example, some distributions do not build Blender with CUDA support for licensing reasons.

If there is a specific package for your distribution, you may choose what is preferable and most convenient,
otherwise, there is nothing wrong with the official binary on `blender.org &lt;https://www.blender.org/download/&gt;`__.

Download from blender.org
=========================

Download the Linux version for your architecture and uncompress the file to the desired location
(eg. ``~/software`` or ``/usr/local``).

Blender can now be launched by double-clicking the executable.

For easy access, you can configure your system by adding a menu entry or shortcut for Blender and associate and open
blend-files with Blender when opening from the file browser.
These settings typically belong to the Window Manager (KDE, Gnome, Unity).

Running from the terminal
=========================

To run Blender from the terminal without needing to be in the executable directory,
add the extracted folder to the environment ``PATH``.

Add the following command to ``~/.bashrc`` or ``~/.profile`` pointing to the directory with Blender's binary:

.. code-block:: sh

export PATH=/path/to/blender/directory:$PATH

.. tip::

If you use daily builds and update Blender frequently,
you can link or always rename your folder to 'blender' and use this name for the ``PATH``
environment variable and for keeping the window manager menu up to date.

Avoiding Alt+Mouse Conflict
===========================

Many Window Managers default to :kbd:`Alt-LMB` for moving windows,
which is a shortcut that Blender uses to simulate a three button mouse.
You can either have this feature disabled :menuselection:`User Preferences --&gt; Input --&gt; Emulate 3 Button Mouse`
or you can change the Window Manager settings to use the *Meta* key instead (also called *Super* or *Windows key*):

- **KDE:** System Settings &gt; Window Behavior &gt; Window Behavior &gt; Window Actions , Switch 'Alt' for 'Meta' key
- **Unity/Gnome:** enter the following in a command line (effective at next login):

.. code-block:: sh

gsettings set org.gnome.desktop.wm.preferences mouse-button-modifier '&lt;Super&gt;'

*******************
Installing on macOS
*******************

Check the :doc:`Installing Blender &lt;/getting_started/installing/introduction&gt;`
page to find the minimum requirements and where to get Blender (if you have not done so yet).

After downloading Blender for macOS, uncompress the file and drag ``blender.app`` into the Applications folder.

.. tip::

Blender does not use the standard macOS menu system so, you will likely have a redundant menu-bar at the top.

To remove it see `this post &lt;http://www.macworld.com/article/1055321/hidemenubar.html&gt;`__
on Macworld, but beware that it is somewhat complex. As an alternative: simply make Blender
full screen by :kbd:`Alt-F11` or by :menuselection:`Info --&gt; Window --&gt; Toggle Window Fullscreen`.

************************
Installing on MS-Windows
************************

Check the :doc:`minimum requirements and where to get Blender &lt;/getting_started/installing/introduction&gt;`,
if you have not done so yet.

You will also need the
`Visual C++ 2013 Redistributable Package &lt;https://www.microsoft.com/en-us/download/details.aspx?id=40784&gt;`__.

Download the ``.zip`` or ``.msi`` for your architecture (64-bit is preferable if your machine supports it).

The ``.msi`` will run an installer to choose where to place Blender
and to configure MS-Windows to have an entry on the menu and to open .blend-files with Blender.
Administrator rights are needed to install Blender on your system.

.. figure:: /images/getting_started_installing_windows.png

MS-Windows installer.

.. note::

With ``.zip`` you have to manually extract Blender to the desired folder,
where you can double-click the executable to run Blender.

There is no installer to place Blender on the menu, but there is also no need for administrator rights.
With this option, it is possible to have multiple versions of Blender without conflicting,
as they are not actually installed on the system.

However, if you want a particular version to be registered with your computer the simply run ``blender -r``
from the :doc:`Command Line &lt;/advanced/command_line/arguments&gt;`.
.. _glossary:

###########
Glossary
###########

.. For writing style guide, see: :doc:`/about/contribute/style_guides/writing_guide`
If you add new entries, keep the alphabetical sorting!

This page lists definitions for terms used in Blender and this manual.

.. glossary::
:sorted:

Active
One of the three :ref:`selection states &lt;object-active&gt;`.
Only one object or item can be active at any given time.

Action Safe
Area of the screen visible on most devices. Place content inside it to ensure it does not get cut off.

Actuator
A :term:`logic brick` that acts like a muscle of a lifeform. It can move the object or make a sound.

Aliasing
Rendering artifacts in the form of jagged lines.

Alpha Channel
Additional channel in an image for transparency.

Straight Alpha
Method where RGBA channels are stored as (R, G, B, A)
channels, with the RGB channels unaffected by the alpha channel.
This is the alpha type used by paint programs such as Photoshop or Gimp,
and used in common file formats like PNG, BMP or Targa.
So, image textures or output for the web are usually straight alpha.

Premultiplied Alpha
Method where RGBA channels are stored as (R × A, G × A, B × A, A),
with the alpha multiplied into the RGB channel.

This is the natural output of render engines,
with the RGB channels representing the amount of light that comes toward the viewer,
and alpha representing how much of the light from the background is blocked.
The OpenEXR file format uses this alpha type.
So, intermediate files for rendering and compositing are often stored as premultiplied alpha.

Conversion (Straight/Premultiplied) Alpha
Conversion between the two alpha types is not a simple operation and can involve data loss,
as both alpha types can represent data that the other cannot though it is often subtle.

Straight alpha can be considered to be an RGB color image with a separate alpha mask.
In areas where this mask is fully transparent, there can still be colors in the RGB channels.
On conversion to premultiplied alpha, this mask is *applied'*
and the colors in such areas become black and are lost.

Premultiplied alpha, on the other hand, can represent renders
that are both emitting light and letting through light from the background.
For example, a transparent fire render might be emitting light,
but also letting through all light from objects behind it.
On converting to straight alpha, this effect is lost.

Ambient Light
The light that comes from the surrounding environment as a whole.

Ambient Occlusion
A ratio of how much :term:`ambient light` a surface point would be likely to receive.
If a surface point is under a foot or table,
it will end up much darker than the top of someone's head or the tabletop.

Animation
Simulation of motion.

Anti-aliasing
See :term:`oversampling`.

Armature
An :term:`Object` consisting of :term:`bones &lt;bone&gt;`. Used to :term:`rig` characters, props, etc.

Axis
A reference line which defines coordinates along one cardinal direction in n-D space.

Axis Angle
Rotation method where X, Y, and Z correspond to the axis definition,
while W corresponds to the angle around that axis, in radians.

Baking
The process of computing and storing the result of a potentially time-consuming calculation
so as to avoid needing to calculate it again.

Bevel
The operation to chamfer or bevel edges of an object.

BU
Blender Units
Internal units used by Blender, equivalent to meters. Often abbreviated to "BU".

Bone
The building block of an :term:`Armature`. Made up of a :term:`Head`, :term:`Tail`
and :term:`Roll Angle` which define a set of local axes and a point of rotation at the :term:`Head`.

Boolean
A type of logic dealing with binary true/false states.

See also :doc:`Boolean Modifier &lt;/modeling/modifiers/generate/booleans&gt;`.

Bounding Box
The box that encloses the shape of an object. The box is aligned with the local space of the object.

Bump Mapping
Technique for simulating slight variations in surface height using a grayscale "height-map" texture.

Bézier
A computer graphics technique for generating and representing curves.

BVH
Bounding Volume Hierarchy
A hierarchical structure of geometric objects.

See also `Bounding Volume Hierarchy &lt;https://en.wikipedia.org/wiki/Bounding_volume_hierarchy&gt;`__ on Wikipedia.

Caustics
Bright concentrations of light focused by specularly reflecting or refracting objects.

Child
An :term:`Object` that is affected by its :term:`Parent`.

Chromaticities
The coordinates of the :term:`primaries` on the CIE 1931 xy chromaticity diagram.

Chroma
Chrominance
In general, a resulting image color decomposition, where its (*L* or *Y*) luminance channel is separated.
There are two different contexts whereas this term is used:

Video systems
Refers to the general color decomposition resulting in *Y* (Luminance) and *C* (Chrominance) channels,
whereas the chrominance is represented by: U = ( Blue minus Luminance ) and V = ( Red minus Luminance ).
Matte compositing
Refers to a point in the color gamut surrounded by a mixture
of a determined spectrum of its RGB neighboring colors.
This point is called *Chroma key* and this key
(a chosen color) is used to create an *Alpha Mask*.
The total amount of gamut space for this chrominance point is defined
by users in a circular or square shaped format.

Clamp
Clamping
Limits a variable to a range. The values over or under the range are set
to the constant values of the ranges minimum or maximum.

Blend Modes
Color Blend Modes
Methods for blending two colors together.

See also `Blend Modes &lt;https://docs.gimp.org/en/gimp-concepts-layer-modes.html&gt;`__ on GIMP docs.

Color Gamut
A gamut traditionally refers to the volume of color a particular color model/space can cover.
In many instances, it is often illustrated via a 2D model using CIE Yxy coordinates.

Color Space
A coordinate system in which a vector represent a color value.
By doing so, the color space defines three things:

- The exact color of each of the :term:`primaries`
- The :term:`White Point`
- A transfer function

sRGB
A color space that uses the Rec .709 :term:`primaries` and white point but,
with a slightly different transfer function.
HSV
Three values often considered as more intuitive (human perception) than the RGB system.

Hue
The Hue of the color.
Saturation
Also known has colorfulness, saturation is the quantity of hue in the color
(from desaturated -- a shade of gray -- to saturated -- brighter colors).
Value
The brightness of the color (dark to light).
HSL
Hue, Saturation
See HSV.
Luminance
See :term:`Luminance`.
YUV
Luminance-Chrominance standard used in broadcasting analog PAL (European) video.
YCbCr
Luminance-ChannelBlue-ChannelRed Component video for digital broadcast use,
whose standards have been updated for HDTV and commonly referred to as the HDMI format for component video.
\+A
The color space holds an additional :term:`Alpha Channel`.

Concave Face
Face in which one vertex is inside a triangle formed by other vertices of the face.

Constraint
A way of controlling one :term:`object` with data from another.

Controller
A :term:`logic brick` that acts like the brain of a lifeform.
It makes decisions to activate muscles (:term:`actuators &lt;actuator&gt;`),
using either simple logic or complex Python scripts.

Convex Face
Face where, if lines were drawn from each vertex to every other vertex, all lines would remain in the face.
Opposite of a :term:`concave face`.

Coplanar
Refers to any set of elements that are all aligned to the same 2D plane in 3D space.

Crease
Property of an :term:`edge`. Used to define the sharpness of edges in :term:`subdivision surface` meshes.

Curve
A type of object defined in terms of a line interpolated between Control Vertices.
Available types of curves include :term:`Bézier` and :term:`NURBS`.

Cyclic
Often referring to an object being circular. This term is often associated with :term:`Curve`.

DOF
Depth Of Field
The distance in front of and behind the subject which appears to be in focus.
For any given lens setting, there is only one distance at which a subject is precisely in focus,
but focus falls off gradually on either side of that distance,
so there is a region in which the blurring is tolerable.
This region is greater behind the point of focus than it is in front,
as the angle of the light rays change more rapidly; they approach being parallel with increasing distance.

Diffuse Light
Even, directed light coming off a surface.
For most things, diffuse light is the main lighting we see.
Diffuse light comes from a specific direction or location and creates shading.
Surfaces facing towards the light source will be brighter,
while surfaces facing away from the light source will be darker.

Directional Light
The light that has a specific direction, but no location.
It seems to come from an infinitely far away source, like the sun.
Surfaces facing the light are illuminated more than surfaces facing away, but their location does not matter.
A Directional Light illuminates all objects in the scene, no matter where they are.

Displacement Mapping
A method for distorting vertices based on an image or texture.
Similar to :term:`Bump Mapping`, but instead operates on the mesh's actual geometry.
This relies on the mesh having enough geometry to represent details in the image.

Display Referenced
Refers to an image whose :term:`Luminance` channel is limited to a certain range of values (usually 0-1).
The reason it is called display referenced is because a display cannot display an infinite range of values.
So, the term :term:`Scene Referenced` must go through a transfer function to be converted from one to the other.

Double Buffer
Technique for drawing and displaying content on the screen.
Blender uses two buffers (images) to draw the interface in.
The content of one buffer is displayed while drawing occurs on the other buffer.
When drawing is complete, the buffers are switched.

Edge
Straight segment (line) that connects two :term:`vertices &lt;vertex&gt;`, and can be part of a :term:`face`.

Edge Loop
Chain of :term:`edges &lt;edge&gt;` belonging to consecutive :term:`quads &lt;quad&gt;`.
An edge loop ends at a pole or a boundary. Otherwise, it is cyclic.

Edge Ring
Path of all :term:`edges &lt;edge&gt;` along a :term:`face loop` that share two faces belonging to that loop.

Empty
An :term:`Object` without any :term:`Vertices`, :term:`Edges &lt;Edge&gt;` or :term:`Faces &lt;Face&gt;`.

Environment Map
A method of calculating reflections.
It involves rendering images at strategic positions and applying them as textures to the mirror.
Now in most cases obsoleted by Raytracing, which though slower is easier to use and more accurate.

Euler
Euler Rotation
Rotation method where rotations applied on each X, Y, Z-axis component.

Face
Mesh element that defines a piece of surface. It consists of three or more :term:`edges &lt;edge&gt;`.

Face Loop
Chain of consecutive :term:`quads &lt;quad&gt;`. A face loop stops at a :term:`triangle` or :term:`N-gon`
(which do not belong to the loop), or at a boundary. Otherwise, it is cyclic.

Face Normal
The normalized vector perpendicular to the plane that a :term:`face` lies in. Each face has its own normal.

F-Curve
A curve that holds the animation values of a specific property.

Field of View
The area in which objects are visible to the camera. Also see :term:`Focal Length &lt;focal length&gt;`

Focal Length
The distance required by a lens to focus collimated light.
Defines the magnification power of a lens. Also see :term:`Field of View &lt;field of view&gt;`.

FSAA
Full-Screen Anti-Aliasing
A method of :term:`Anti-aliasing` on the graphics card, so the entire image is displayed smooth.
Also known as *Multi-Sampling*.

This can be enabled in the :ref:`User Preferences &lt;prefs-system-multi-sampling&gt;`.
On many graphics cards, this can also be enabled in the driver options.

Gamma
An operation used to adjust the brightness of an image.

See also `Gamma correction &lt;https://en.wikipedia.org/wiki/Gamma_correction&gt;`__ on Wikipedia.

Geometric Center
The mean average of the positions of all vertices making up the object.

Gimbal
A pivoted support that allows the rotation of an object about a single axis.

See also `Gimbal &lt;https://en.wikipedia.org/wiki/Gimbal&gt;`__ on Wikipedia.

Gimbal Lock
The limitation where axes of rotation can become aligned,
losing the ability to rotate on an axis (typically associated with :term:`euler rotation`).

- See also `Gimbal lock &lt;https://en.wikipedia.org/wiki/Gimbal_lock&gt;`__ on Wikipedia.
- See also `Gimbal lock &lt;https://blender.stackexchange.com/questions/469&gt;`__ on Stackexchange.

Global Illumination
A superset of radiosity and ray tracing.
The goal is to compute all possible light interactions in a given scene,
and thus, obtain a truly photo-realistic image.
All combinations of diffuse and specular reflections and transmissions must be accounted for.
Effects such as color bleeding and caustics must be included in a global illumination simulation.

Global Space
See :term:`World Space`.

Gouraud Shading
Used to achieve smooth lighting on low-polygon surfaces without the
heavy computational requirements of calculating lighting for each pixel.
The technique was first presented by Henri Gouraud in 1971.

Glossy Map
See :term:`Roughness Map`.

Head
A subcomponent of a :term:`Bone`. The point of rotation for that :term:`Bone`.
Has X, Y and Z coordinates measured in the :term:`Local Space` of the :term:`Armature` :term:`Object`.
Used in conjunction with the :term:`Tail` to define the :term:`local &lt;Local Space&gt;` Y axis of the :term:`Bone`
in :term:`Pose Mode`. The larger of the two ends when drawn as an :term:`Octahedron`.

HDRI
High Dynamic Range Image
A set of techniques that allow a far greater dynamic range of exposures than normal digital imaging techniques.
The intention is to accurately represent the wide range of intensity levels found in real scenes,
ranging from direct sunlight to the deepest shadows.

See also `HDRI &lt;https://en.wikipedia.org/wiki/HDRI&gt;`__ on Wikipedia.

IOR
Index Of Refraction
A property of transparent materials.
When a light ray travels through the same volume it follows a straight path.
However, if it passes from one transparent volume to another, it bends.
The angle by which the ray is bent can be determined by the IOR of the materials of both volumes.

Interpolation
The process of calculating new data between points of known value, like :term:`keyframes &lt;keyframe&gt;`.

Inverse Kinematics
The process of determining the movement of interconnected segments of a body or model.
Using ordinary Kinematics on a hierarchically structured object you can, for example,
move the shoulder of a puppet. The upper and lower arm and hand will automatically follow that movement.
IK will allow you to move the hand and let the lower and upper arm go along with the movement.
Without IK the hand would come off the model and would move independently in space.

Keyframe
A frame in an animated sequence drawn or otherwise constructed directly by the user.
In classical animation, when all frames were drawn by animators,
the senior artist would draw these frames, leaving the "in between" frames to an apprentice.
Now, the animator creates only the first and last frames of a simple sequence (keyframes);
the computer fills in the gap.

Keyframing
Inserting :term:`Keyframes &lt;Keyframe&gt;` to build an animated sequence.

Lattice
A type of object consisting of a non-renderable three-dimensional grid of vertices.

See also :doc:`Lattice Modifier &lt;/modeling/modifiers/deform/lattice&gt;`.

Layer
A device for organizing objects. See also :doc:`Layers &lt;/editors/3dview/object/properties/relations/layers&gt;`.

Light Bounces
Refers to the reflection or transmission of a light ray upon interaction with a material.
See also :doc:`Light Paths &lt;/render/cycles/settings/light_paths&gt;`.

Local Space
A 3D coordinate system that originates (for Objects) at the :term:`Object Origin`.
or (for Bones) at the :term:`Head` of the :term:`Bone`.

Compare to :term:`World Space`.

Logic brick
A graphical representation of a functional unit in Blender's game logic.
A Logic brick can be a :term:`Sensor`, :term:`Controller` or :term:`Actuator`.

Luminance
The intensity of light either in an image/model channel,
or emitted from a surface per square unit in a given direction.

Manifold
Manifold meshes, also called *water tight* meshes,
define a *closed non-self-intersecting volume* (see also :term:`non-manifold`).
A manifold mesh is a mesh in which the structure of the connected
faces in a closed volume will always point the normals (and there
surfaces) to the outside or to the inside of the mesh without any overlaps.
If you recalculate those normals, they will always point at
a predictable direction (To the outside or to the inside of the volume).
When working with non-closed volumes, a manifold mesh is a mesh in which
the normals will always define two different and non-consecutive surfaces.
A manifold mesh will always define an even number of non-overlapped surfaces.

Matte
Mask
A grayscale image used to include or exclude parts of an image.
A matte is applied as an :term:`Alpha Channel`,
or it is used as a mix factor when applying :term:`Color Blend Modes`.

Mesh
Type of object consisting of :term:`vertices &lt;vertex&gt;`, :term:`edges &lt;edge&gt;` and :term:`faces &lt;face&gt;`.

Micropolygons
A polygon roughly the size of a pixel or smaller.

MIP
Mipmap
Mipmapping
'MIP' is an acronym of the Latin phrase 'multum in parvo', meaning 'much in little'.
Mipmaps are progressively lower resolution representations of an image,
generally reduced by half squared interpolations using antialiasing.
Mipmapping is the process used to calculate lower resolutions of the
same image, reducing memory usage to help speed visualization, but increasing
memory usage for calculations and allocation. Mipmapping is also a process
used to create small antialiased samples of an image used for texturing.
The mipmapping calculations are made by CPUs, but modern graphic processors
can be selected for this task and are way faster.

See the Mipmap option present in the :doc:`System Preferences &lt;/preferences/system&gt;`.

Motion Blur
The phenomenon that occurs when we perceive a rapidly moving object.
The object appears to be blurred because of our persistence of vision.
Simulating motion blur makes computer animation appear more realistic.

Multi-sampling
See :term:`FSAA`.

N-gon
A :term:`face` that contains more than four :term:`vertices &lt;vertex&gt;`.

Non-linear Animation
Animation technique that allows the animator to edit motions as a whole,
not just the individual keys. Nonlinear animation allows you to combine,
mix, and blend different motions to create entirely new animations.

Non-manifold
Non-Manifold meshes essentially define geometry which cannot exist in the real world.
This kind of geometry is not suitable for several types of operations,
especially those where knowing the volume (inside/outside) of the object is important
(refraction, fluids, booleans, or 3D printing, to name a few).
A non-manifold mesh is a mesh in which the structure of a
non-overlapped surface (based on its connected faces) will not determine
the inside or the outside of a volume based on its normals, defining
a single surface for both sides, but ended with flipped normals.
When working with non-closed volumes, a non-manifold mesh will always
determine at least one discontinuity in the normal directions, either
by an inversion of a connected loop, or by an odd number of surfaces.
A non-manifold mesh will always define an odd number of surfaces.

There are several types of non-manifold geometry:

- Some borders and holes (edges with only a single connected face), as faces have no thickness.
- Edges and vertices not belonging to any face (wire).
- Edges connected to three or more faces (interior faces).
- Vertices belonging to faces that are not adjoining (e.g. two cones sharing the vertex at the apex).

See also: :ref:`Select Non-Manifold &lt;mesh-select-non-manifold&gt;` tool.

Normal
The normalized vector perpendicular to a surface.

Normals can be assigned to vertices,
faces and modulated across a surface using :term:`normal mapping`.

Normal Mapping
Is similar to :term:`Bump mapping`, but instead of the image being a grayscale heightmap,
the colors define in which direction the normal should be shifted,
the three color channels being mapped to the three directions X, Y and Z.
This allows more detail and control over the effect.

NURBS
Non-uniform Rational Basis Spline
A computer graphics technique for generating and representing curves and surfaces.

Object
Container for a type (Mesh, Curve, Surface, Metaball, Text, Armature,
Lattice, Empty, Camera, Lamp) and basic 3D transform data (:term:`Object Origin`).

Object Center
Object Origin
A reference point used to position, rotate, and scale an :term:`Object`
and to define its :term:`Local Space` coordinates.

Octahedron
An eight-sided figure commonly used to depict the :term:`Bones &lt;Bone&gt;` of an :term:`Armature`.

OpenGL
The graphics system used by Blender (and many other graphics applications)
for drawing 3D graphics, often taking advantage of hardware acceleration.

See also `OpenGL &lt;https://en.wikipedia.org/wiki/OpenGL&gt;`__ on Wikipedia.

Oversampling
Is the technique of minimizing :term:`aliasing` when representing a high-resolution
signal at a lower resolution.

Also called Anti-Aliasing.

Overscan
The term used to describe the situation.
when not all of a televised image is present on a viewing screen.

See also `Overscan &lt;https://en.wikipedia.org/wiki/Overscan&gt;`__ on Wikipedia.

Parent
An :term:`Object` that affects its :term:`Child` objects.

Parenting
Creating a :term:`Parent`-:term:`Child` relationship between two :term:`objects &lt;Object&gt;`.

Particle system
Technique that simulates certain kinds of fuzzy phenomena,
which are otherwise very hard to reproduce with conventional rendering techniques.
Common examples include fire, explosions, smoke, sparks, falling leaves, clouds, fog, snow, dust,
meteor tails, stars, and galaxies, or abstract visual effects like glowing trails, magic spells.
Also used for things like fur, grass or hair.

Phong
Local illumination model that can produce a certain degree of realism in three-dimensional
objects by combining three elements: diffuse, specular and ambient for each considered point on a surface.
It has several assumptions -- all lights are points, only surface geometry is considered,
only local modeling of diffuse and specular, specular color is the same as light color,
ambient is a global constant.

Pivot Point
The pivot point is the point in space around which all rotations,
scalings and mirror transformations are centered.

See also the :doc:`Pivot Point &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;` docs.

Pixel
The smallest unit of information in a 2D raster image,
representing a single color made up of red, green, and blue channels.
If the image has an :term:`alpha channel`, the pixel will contain a corresponding fourth channel.

Pole
:term:`Vertex` where three, five, or more edges meet.
A vertex connected to one, two, or four edges is not a pole.

Pose Mode
Used for :term:`posing`, :term:`keyframing`, :term:`weight painting`,
:term:`constraining &lt;Constraint&gt;` and :term:`parenting` the :term:`bones &lt;Bone&gt;` of an :term:`armature`.

Posing
Moving, Rotating and Scaling the :term:`bones &lt;Bone&gt;` of an :term:`armature`
to achieve an aesthetically pleasing pose for a character.

Premultiplied Alpha
See :term:`Alpha Channel`.

Primaries
In color theory, a primary (often known as primary color) is the abstract lights,
using an absolute model, that make up a :term:`color space`.

Primitive
A basic object that can be used as a basis for modeling more complicated objects.

Procedural Texture
Computer generated (generic) textures that can be configured via different parameters.

Projection
In computer graphics, there are two common camera projections used.

Perspective
A *perspective* view is geometrically constructed by taking a scene in 3D
and placing an observer at point *O*.
The 2D perspective scene is built by placing a plane (e.g. a sheet of paper)
where the 2D scene is to be drawn in front of point *O*,
perpendicular to the viewing direction.
For each point *P* in the 3D scene a *PO* line is drawn,
passing by *O* and *P*. The intersection point *S* between
this *PO* line and the plane is the perspective projection of that point.
By projecting all points *P* of the scene you get a perspective view.
Orthographic
In an *orthographic* projection,
you have a viewing direction but not a viewing point *O*. The line is then drawn
through point *P* so that it is parallel to the viewing direction. The intersection
*S* between the line and the plane is the orthographic projection of the point *P*.
By projecting all points *P* of the scene you get the orthographic view.

Quad
Quadrilateral
Quadrangle
:term:`Face` that contains exactly four :term:`vertices &lt;vertex&gt;`.

Quaternion
Quaternion Rotation
Rotation method where rotations are defined by four values (X, Y, Z, and W).
X, Y, and Z also define an :term:`axis`, and W an angle,
but it is quite different from :term:`Axis Angle`.

Radiosity
A global lighting method.
that calculates patterns of light and shadow for rendering graphics images from three-dimensional models.
One of the many different tools which can simulate diffuse lighting in Blender.

See also
`Radiosity (computer graphics) &lt;https://en.wikipedia.org/wiki/Radiosity_%28computer_graphics%29&gt;`__
on Wikipedia.

Raytracing
Rendering technique that works by tracing the path taken by a ray of light through the scene,
and calculating reflection, refraction, or absorption of the ray whenever it intersects an object in the world.
More accurate than :term:`scanline`, but much slower.

Refraction
The change in direction of a wave due to a change in velocity.
It happens when waves travel from a medium with a given :term:`index of refraction` to a medium with another.
At the boundary between the media, the wave changes direction;
its wavelength increases or decreases but frequency remains constant.

Render
The process of computationally generating a 2D image from 3D geometry.

RGB
A color model based on the traditional primary colors, Red/Green/Blue.
RGB colors are also directly broadcasted to most computer monitors.

Rig
A system of relationships that determine how something moves. The act of building of such a system.

Roll
Roll Angle
The orientation of the local X and Z axes of a :term:`Bone`.
Has no effect on the local Y axis as local Y is determined by the location of the :term:`Head` and :term:`Tail`.

Roughness Map
A grayscale texture that defines how rough or smooth the surface of a material is.
This may also be known as a :term:`Glossy Map`.

Scanline
Rendering technique. Much faster than :term:`raytracing`,
but allows fewer effects, such as reflections, refractions, motion blur and focal blur.

Scene Referenced
An image whose :term:`Luminance` channel is not limited.

See also :term:`Display Referenced`.

Sensor
A :term:`logic brick` that acts like a sense of a lifeform. It reacts to touch, vision, collision etc.

Shading
Process of altering the color of an object/surface in the 3D scene,
based on its angle to lights and its distance from lights to create a photorealistic effect.

Smoothing
Defines how :term:`faces &lt;face&gt;` are shaded. Face can be either solid (faces are rendered flat)
or smooth (faces are smoothed by interpolating the normal on every point of the face).

Specular Light
A light which is reflected precisely, like a mirror.
Also used to refer to highlights on reflective objects.

Straight Alpha
See :term:`Alpha Channel`.

Subsurface Scattering
Mechanism of light transport in which light penetrates the surface of a translucent object,
is scattered by interacting with the material, and exits the surface at a different point.
All non-metallic materials are translucent to some degree.
In particular, materials such as marble, skin,
and milk are extremely difficult to simulate realistically without taking subsurface scattering into account.

Subdividing
Technique for adding more geometry to a mesh.
It creates new vertices on subdivided edges, new edges between subdivisions and new faces based on new edges.
If new edges cross a new vertex is created at their crossing point.

Subsurf
Subdivision Surface
A method of creating smooth higher poly surfaces which can take a low polygon mesh as input.

Sometimes abbreviated to **Subsurf**.

See also
`Catmull-Clark subdivision surface &lt;https://en.wikipedia.org/wiki/Catmull%E2%80%93Clark_subdivision_surface&gt;`__
on Wikipedia.

Tail
A subcomponent of a :term:`Bone`. Has X, Y and Z coordinates measured in the :term:`Local Space`
of the Armature Object. Used in conjunction with the :term:`Head`
to define the :term:`local &lt;Local Space&gt;` Y axis of a :term:`Bone` in :term:`Pose Mode`.
The smaller of the two ends when drawn as an :term:`Octahedron`.

Tessellation
The tiling of a plane using one or more geometric shapes usually resulting in :term:`Micropolygons`.

Texture
Specifies visual patterns on surfaces and simulates physical surface structure.

Texture Space
The bounding box to use when using *Generated* mapping to add a :term:`Texture` to an image.

Timecode
A coded signal on videotape or film giving information about the frame number, time of recording, or exposure.

Title Safe
Area of the screen visible on all devices.
Place text and graphics inside this area to make sure they do not get cut off.

Topology
The arrangement of *Vertices*, *Edges*, and *Faces* which define the shape of a mesh.
See :term:`vertex`, :term:`edge`, and :term:`face`.

Transforms
The combined idea of location, rotation, and scale.

Triangle
:term:`Face` with exactly three :term:`vertices &lt;vertex&gt;`.

UV map
Defines a relation between the surface of a mesh and a 2D texture. In detail,
each face of the mesh is mapped to a corresponding face on the texture.
It is possible and often common practice to map several faces of the mesh to the same
or overlapping areas of the texture.

Vertex
Vertices
A point in 3D space containing a location. It may also have a defined color.
Vertices are the terminating points of :term:`edges &lt;edge&gt;`.

Vertex Group
Collection of :term:`vertices &lt;vertex&gt;`.
Vertex groups are useful for limiting operations to specific areas of a mesh.

Voxel
A cubicle 3D equivalent to the square 2D pixel.
The name is a combination of the terms "Volumetric" and ":term:`Pixel &lt;pixel&gt;`".
Used to store smoke and fire data from physics simulations.

Walk Cycle
In animation, a walk cycle is a character that has just the walking function animated.
Later on in the animation process, the character is placed in an environment
and the rest of the functions are animated.

Weight Painting
Assigning :term:`vertices` to :term:`Vertex Groups &lt;Vertex Group&gt;` with a weight of 0.0 - 1.0.

White Point
A reference value for white light defined by what happens when all the primaries,
of the particular color model, are combined evenly.

A white point is defined by a set of CIE illuminates which correspond to a color temperature.
For example, D65 corresponds to 6500K light, D70 corresponding to 7000K and so on.

World Space
A 3D coordinate system that originates at a point at the origin of the world.
Compare to :term:`Local Space`.

Z-buffer
Raster-based storage of the distance measurement between the camera and the surface points.
Surface points which are in front of the camera have a positive Z value and
points behind have negative values. The Z-Depth map can be visualized as a grayscale image.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
Blender Reference Manual
%%%%%%%%%%%%%%%%%%%%%%%%%%%

Welcome to the Blender Manual!

This is the manual for the 3D animation software from `Blender.org &lt;https://www.blender.org&gt;`__.

.. use /dev only for now

.. only:: builder_html

.. |vertical_separator| unicode:: U+02758

- Other languages:
`En &lt;https://docs.blender.org/manual/en/dev/&gt;`__ |vertical_separator|
`De &lt;https://docs.blender.org/manual/de/dev/&gt;`__ |vertical_separator|
`Es &lt;https://docs.blender.org/manual/es/dev/&gt;`__ |vertical_separator|
`Fr &lt;https://docs.blender.org/manual/fr/dev/&gt;`__ |vertical_separator|
`It &lt;https://docs.blender.org/manual/it/dev/&gt;`__ |vertical_separator|
`Ja &lt;https://docs.blender.org/manual/ja/dev/&gt;`__ |vertical_separator|
`Pt &lt;https://docs.blender.org/manual/pt/dev/&gt;`__ |vertical_separator|
`Ru &lt;https://docs.blender.org/manual/ru/dev/&gt;`__ |vertical_separator|
`Zh (Simplified) &lt;https://docs.blender.org/manual/zh.cn/dev/&gt;`__ |vertical_separator|
`Zh (Traditional) &lt;https://docs.blender.org/manual/zh.tw/dev/&gt;`__
- This site can be downloaded for offline use:
:download:`Download the full manual (zipped HTML files) &lt;blender_manual.zip&gt;`
- :doc:`/about/whats_new`

Getting Started
===============

- :doc:`/getting_started/about/index`
- :doc:`/getting_started/installing/index`
- :doc:`/getting_started/help`

Sections
========

.. The image ratio is: width: 350px; height: 350/4 + (2x5) ~= 98px

.. only:: builder_html and (not singlehtml)

.. container:: tocdescr

.. container:: descr

.. figure:: /images/contents_interface.jpg
:target: interface/index.html

:doc:`/interface/index`
An introduction to Blender's window system, widgets and tools.

.. container:: descr

.. figure:: /images/contents_editors.jpg
:target: editors/index.html

:doc:`/editors/index`
Overview of the editors describing the interface and functionality of each one.

.. container:: descr

.. figure:: /images/contents_data.jpg
:target: data_system/index.html

:doc:`/data_system/index`
Blender's data management of scene data and the structure of blend-files.

.. container:: descr

.. figure:: /images/contents_modeling.jpg
:target: modeling/index.html

:doc:`/modeling/index`
The various supported geometry types, modeling tools, and modifiers.

.. container:: descr

.. figure:: /images/contents_painting.jpg
:target: sculpt_paint/index.html

:doc:`/sculpt_paint/index`
The 3D texture painting and sculpting modes.

.. container:: descr

.. figure:: /images/contents_rigging.jpg
:target: rigging/index.html

:doc:`/rigging/index`
Overview of armatures, pose mode and constraints.

.. container:: descr

.. figure:: /images/contents_animation.jpg
:target: animation/index.html

:doc:`/animation/index`
Keyframe animation, graph interpolation, drivers, and shape keys.

.. container:: descr

.. figure:: /images/contents_physics.jpg
:target: physics/index.html

:doc:`/physics/index`
Physics simulations, particle systems and dynamic paint.

.. container:: descr

.. figure:: /images/contents_render.jpg
:target: render/index.html

:doc:`/render/index`
Render engines (Internal, Cycles), shading, post-processing, and Freestyle (NPR). [1]_

.. container:: descr

.. figure:: /images/contents_compositing.jpg
:target: compositing/index.html

:doc:`/compositing/index`
Post-processing with the Compositor.

.. container:: descr

.. figure:: /images/contents_game.jpg
:target: game_engine/index.html

:doc:`/game_engine/index`
Blender's Game engine, including scripting, logic and physics.

.. container:: descr

.. figure:: /images/contents_preferences.jpg
:target: preferences/index.html

:doc:`/preferences/index`
Blender's settings.

.. container:: descr

.. figure:: /images/contents_advanced.jpg
:target: advanced/index.html

:doc:`/advanced/index`
Python scripting, how to write add-ons and a reference for command line arguments.

.. container:: descr

.. figure:: /images/contents_troubleshooting.jpg
:target: troubleshooting/index.html

:doc:`/troubleshooting/index`
Compatibility errors related to other software (graphics drivers, Python),
how to write a bug report and recover data.

.. container:: descr

:doc:`Glossary &lt;/glossary/index&gt;`
A list of terms and definitions used in Blender and this manual.

.. container:: descr

:ref:`Manual Index &lt;genindex&gt;`
A list of terms linked to the Glossary.

.. only:: latex or epub or singlehtml

.. toctree::
:maxdepth: 1

getting_started/index.rst
interface/index.rst
editors/index.rst
data_system/index.rst
modeling/index.rst
sculpt_paint/index.rst
rigging/index.rst
animation/index.rst
physics/index.rst
render/index.rst
compositing/index.rst
game_engine/index.rst
preferences/index.rst
advanced/index.rst
pipeline/index.rst
troubleshooting/index.rst
glossary/index.rst

Get Involved
============

This manual is maintained largely by volunteers.

Please consider to join the effort and :ref:`Contribute to this Manual &lt;about-user-contribute&gt;`.

.. [1] The White Room model by Jay Hardy.

.. just so this is included in the toc (not user visible).

.. toctree::
:hidden:

about/index.rst

****************
Common Shortcuts
****************

There are shortcuts shared among many button types.

Mouse
=====

In Blender the :kbd:`RMB` (Right Mouse Button) is generally used for Selection
and the :kbd:`LMB` (Left Mouse Button) initiates or confirms actions.

.. list-table::
:widths: 15 85

* - :kbd:`RMB`
- To select an item.
* - :kbd:`Shift-RMB`
- To add more items to the selection.
* - :kbd:`LMB`
- To perform an action on the selection.

Video: `Learn more about Blender's Mouse Button usage &lt;https://vimeo.com/76335056&gt;`__.

.. note::

There are a few corner cases where :kbd:`LMB` is used for selection.
For example, the :doc:`File Browser &lt;/editors/file_browser/introduction&gt;`.

Hovering
========

While hovering (when the cursor is held over a button).

Properties
----------

- :kbd:`Ctrl-C` -- Copy the value of the button.
- :kbd:`Ctrl-V` -- Paste the value of the button.
- :kbd:`RMB` -- Open the context menu.
- :kbd:`Backspace` -- Clear the value (sets to zero or clears a text field).
- :kbd:`Minus` -- Negate number values (multiply by -1.0).
- :kbd:`Ctrl-Wheel` -- Change the value incremental steps.

For pop-up option menus buttons, this cycles the value.
- :kbd:`Enter` -- Activates menus or toggles the value.

Animation
---------

- :kbd:`I` -- Insert a keyframe.
- :kbd:`Alt-I` -- Clear the keyframe.
- :kbd:`Alt-Shift-I` -- Clear all keyframes (removing all F-Curves).
- :kbd:`Ctrl-D` -- Assign a driver.
- :kbd:`Ctrl-Alt-D` -- Clear the driver.
- :kbd:`K` -- Add a Keying Set.
- :kbd:`Alt-K` -- Clear the Keying Set.

Python Scripting
----------------

- :kbd:`Ctrl-C` -- Over any :ref:`ui-operation-buttons` copies their Python command into the clipboard.

This can be used in the Python console or in the text editor when writing scripts.
- :kbd:`Ctrl-Shift-C` -- Over property buttons copies their data-path for this property
(also available from the right-click menu).

Useful when writing drivers or scripts.
- :kbd:`Ctrl-Alt-Shift-C` -- Over property buttons copies their *full* data-path for the Data-Block and property.

Note that in most cases it is best to access values based on the context, instead of by name.

Dragging
========

- :kbd:`Ctrl` -- While dragging snap the discrete steps.
- :kbd:`Shift` -- Gives precision control over the value.
- :kbd:`Ctrl-Shift` -- Precise snap will move the object with high precision
along with the snapping constraint.

.. _ui-text-editing:

Text Editing
============

- :kbd:`Home` -- Go to the start.
- :kbd:`End` -- Go to the end.
- :kbd:`Left`, :kbd:`Right` -- Move the cursor a single character.
- :kbd:`Ctrl-Left`, :kbd:`Ctrl-Right` -- Move the cursor an entire word.
- :kbd:`Backspace`, :kbd:`Delete` -- Delete characters.
- :kbd:`Ctrl-Backspace`, :kbd:`Ctrl-Delete` -- Deletes words.
- :kbd:`Shift` -- While holding the key and moving the cursor selects.
- :kbd:`Ctrl-A` -- Select all text.
- :kbd:`Ctrl-C` -- Copy the selected text.
- :kbd:`Ctrl-X` -- Cut the selected text.
- :kbd:`Ctrl-V` -- Paste text at the cursor position.

Confirm and Chancel
===================

- :kbd:`Esc`, :kbd:`RMB` -- Cancels.
- :kbd:`Enter`, :kbd:`LMB` -- Confirms.

.. (todo?) deactivation: Some controls can be disabled, in Blender deactivated controls are still editable.
That can be due to the current state or context. In that case, they appear in a lighter color.

*******
Buttons
*******

.. rename to tool, operator?

.. _ui-operation-buttons:

Operation Buttons
=================

.. figure:: /images/interface_button.png
:align: right

Operation button.

These are buttons that perform an operation when clicked with :kbd:`LMB`.
They can be identified by their gray color in the default color scheme.

Text Fields &amp; Search Fields
===========================

.. figure:: /images/interface_text_search.png
:align: right

Text and Search.

Text fields have a light gray background and a darker outline.
They hold text strings, and provide the means to edit it
by :doc:`standard &lt;/interface/common_shortcuts&gt;` text editing.
Search fields show a magnifying glass icon on the left side. Start typing in the field to search.
Only items with matching text will be shown.

For text fields with an icon and gray pop-up see :ref:`ui-data-id`.

Color Buttons
=============

.. figure:: /images/interface_color_button.png
:align: right

Color Buttons.

Without and with alpha.

The color button stores a color value shown in its background.
:kbd:`LMB` color buttons opens the :doc:`/interface/controls/templates/color_picker`.
Color buttons with an alpha channel are divided in half: On the left the color is shown without an alpha channel and
on the right the color with an alpha channel drawn over a checker pattern.
Colors can be drag and dropped.
.. _ui-eye-dropper:

**********
Eyedropper
**********

The eyedropper (pipette icon) allows you to sample from anywhere in the Blender window.
The eyedropper can be used to select different kinds of data:

Color
This is the most common usage.
Objects/Object-Data
This is used with object buttons such as parent, constraints or modifiers to
select an object from the 3D View.
Camera Depth
Number buttons effecting distance can also use the eye-dropper.

This is used to set the cameras depth of field so the depth chosen is in focus.

- :kbd:`E` will activate the eye-dropper while hovering over a button.
- :kbd:`LMB` dragging will mix the colors you drag over, which can help when sampling noisy imagery.
- :kbd:`Spacebar` resets and starts mixing the colors again.
.. |specials-button| image:: /images/interface_controls_buttons_menus_specials.png

*****
Menus
*****

Blender uses a variety of different menus for accessing options and tools.

.. _ui-header-menu:

Header Menus
============

.. figure:: /images/interface_menu_button.png
:align: right

The Info Editor menu buttons.

Most :ref:`headers &lt;ui-region-header&gt;` exhibit a set of menus, located immediately next
to the first *Editor Type* selector.
Header menus are used to configure the editor and access tools.
All Menu entries show the relevant shortcut keys, if any.

Collapsing Menus
----------------

Sometimes it's helpful to gain some extra horizontal space in the header by collapsing menus,
this can be accessed from the header context menu,
simply :kbd:`RMB` click on the header and enable it to collapse.

.. list-table::

* - .. figure:: /images/interface_header_menu_expand.jpg
:width: 320px

Right-click on any of the header menus.

- .. figure:: /images/interface_header_menu_collapsed.jpg
:width: 320px

Access the menu from the collapsed icon.

Select Menus
============

.. figure:: /images/interface_controls_buttons_menus_select-menu.png
:align: right

The 3D View mode select menu.

The Select menu or short selector lets you choose between a set of options. They can show a text and/or a icon.
The options are shown in a pop-up. The selected option is then shows as active.

Pop-Up Menus
============

.. figure:: /images/interface_popup-menu.jpg
:align: right

The Viewport Shading pop-up menu.

Pop-up menus are overlays.
They are spawned by menus showing up and down triangles on the right or
after a key input at the mouse position.

If the content is too large to fit on the screen, small indicator triangles appear.
When moving the mouse over them scrolls the pop-up.

For example, the *Viewport Shading* button will produce a pop-up menu
with the available shading options.

Mouse selection
:kbd:`LMB` on the desired item.
Numerical selection
You can use the number keys or :kbd:`Numpad` to input an item in the list to select.
For example, :kbd:`Numpad-1` will select the first item and so on.

Pop-ups can be moved by dragging their title.

.. todo duplicate: selection

Shortcuts
---------

- Use :kbd:`Wheel` while hovering with the mouse.
- Arrow keys can be used to navigate.
- Each menu item has an underlined character which can be pressed to activate it.
- Number keys or numpad can be used to access menu items.
(Where :kbd:`1` is the first menu item, :kbd:`2` the second... etc.
For larger menus :kbd:`Alt-1` the 11th... up to :kbd:`Alt-0` the 20th)
- Press :kbd:`Enter` to activate the selected menu item.
- Press :kbd:`Esc` to cancel the menu, or move the mouse cursor far from the pop-up,
or by :kbd:`LMB` clicking anywhere out of it.

Context Menu
============

Context menus are pop-ups opened with the :kbd:`RMB`.
Only the common options are listed below:

.. for the property associated with the control.

*Single* sets or gets the value of the button under the mouse pointer.
*All* on the other hand includes all combined buttons.

Reset All/Single to Default Value(s)
Replaces the current value by the default :kbd:`Backspace`.
Unset
ToDo
Copy Data Path
For scripting -- Copies the Python path of the property, relative to the data-block.
Copy To Selected
Copies the property value to the selected object's corresponding property.
A use case is if the Properties editor context is pinned.
Add Shortcut
Lets you define a keyword or mouse shortcut and associates it with the control.
To define the shortcut you must first move the mouse cursor over the button that pops up,
and when "Press a key" appears you must press and/or click the desired shortcut.
Change Shortcut
Lets you redefine the shortcut.
Remove Shortcut
Unlinks the existing shortcut.
Online Manual
See :ref:`help-manual-access`.
Online Python Reference
Context-sensitive access to the
`Python API Reference &lt;https://www.blender.org/api/blender_python_api_current/&gt;`__.
Edit Source
For UI development -- Creates a text data-block with the source code associated with the control,
in case the control is based on a python script.
In the Text Editor it points at the code line where the element is defined.
Edit Translation
For UI development -- Points at the translation code line.

.. seealso::

:doc:`/interface/common_shortcuts`.

.. move paragraph there?

.. _ui-specials-menu:

Specials Menu
=============

The Specials pop-up menu contains a context-sensitive list of operators.
It is opened by a button with a down arrow on dark background |specials-button| or
with :kbd:`W` in most editors giving quick access to tools sensitive to the editors mode.

Pie Menus
=========

A pie menu is a menu whose items are spread radially around the mouse.
Pie menus have to be activated in the User Preferences through
:menuselection:`Add-ons --&gt; UI --&gt; Pie Menus Official`.

.. figure:: /images/interface_pie-menu.jpg
:width: 350px

The shade pie menu.

Interaction
-----------

The pie menu is spawned by a key press,
which are listed in the :ref:`Add-on Preferences &lt;user-prefs-addons-prefs&gt;`.

Releasing the key without moving the mouse will keep the menu open and
the user can then move the mouse pointer towards the direction of a pie menu item and select it by clicking.
Releasing the key after moving the mouse towards a pie menu item will cause the menu to close and
the selected menu item to activate.

An open disc widget at the center of the pie menu shows the
current direction of the pie menu. The selected item is also highlighted.
A pie menu will only have a valid direction for item selection,
if the mouse is touching or extending beyond the disc widget at the center of the menu.

Pie menu items support key accelerators, which are the letters underlined on each menu item.
Also number keys can be used to select the items.

If there are sub-pies available, it is indicated by a plus icon.

See :ref:`Pie menu settings &lt;prefs-pie-menu&gt;`.
.. rename to numeric input?

**************
Number Buttons
**************

.. figure:: /images/interface_number_button.png
:align: right

Number buttons.

(grouped or single).

Number buttons hold numeric values.

Number buttons can be identified by the triangles pointing left (◂) and right (▸) on the sides of the button.
The second type number sliders have a bar in the background and are used for values in a range,
e.g. percentage values. Both types have round corners.
In most cases they contain a name and a colon followed by the number.
The value can be edited in several ways:

In/Decremental Steps
To change the value in steps, click :kbd:`LMB` on the small triangles (number button only).
Dragging
To change the value in a wider range, hold down :kbd:`LMB` and drag the mouse to the left or right.
Hold :kbd:`Ctrl` to snap to the discrete steps while dragging or :kbd:`Shift` for precision input.
Text Input
Press :kbd:`LMB` or :kbd:`Enter` to edit the value as a text field.

When entering values by hand, this button works like any other text field:

- Press :kbd:`Enter` or :kbd:`LMB` outside the field to apply the change.
- Press :kbd:`Esc` or :kbd:`RMB` will cancel the value.
- Press :kbd:`Tab` to jump to the next number button or :kbd:`Ctrl-Tab` for the previous.

Press :kbd:`Minus` while hovering over the button to negate the value.

Multi-Value Editing
===================

.. figure:: /images/interface_multi_value_edit.png
:align: right

Multi-value editing.

Number buttons can be edited multiple values at once (object scale or render resolution for example).
This can be done by clicking on the button and dragging vertically to include buttons above/below.
After the vertical motion you can drag from side to side, or release the :kbd:`LMB` to type in a value.

Limits
======

Most *Number Buttons* has two types of "limits" imposed on them. The first of these is a "soft limit",
this means that the property cannot surpassed the value of the "soft limit" without having to :kbd:`LMB`
and input the value with the :kbd:`Numpad`. The second is the "hard limit",
this is the value that cannot be surpassed even by :kbd:`LMB` and inputing a value.

Expressions
===========

.. Do not use mathjax here

You can also enter expressions such as ``3*2`` instead of ``6``. or ``5/10+3``.
Even constants like ``pi`` (3.142) or functions like ``sqrt(2)`` (square root of 2)
may be used.

.. seealso::

These expressions are evaluated by Python; for all available math expressions see:
`math module reference &lt;https://docs.python.org/3/library/math.html&gt;`__

Expressions as Drivers
----------------------

You may want your expression to be re-evaluated after it is entered.
Blender supports this using :doc:`Drivers &lt;/animation/drivers/index&gt;` (a feature of the animation system).

Expression beginning with ``#``, have a special use.
Instead of evaluating the value and discarding the expression,
a driver is added to the property with the expression entered.

The expression ``#frame`` is a quick way to access map a value to the current frame,
but more complex expressions are also supported ``#fmod(frame, 24) / 24`` for example.

This is simply a convenient shortcut to add drivers which can also be added via the :kbd:`RMB` menu.

Units
=====

As well as expressions, you can mix units with numbers; for this to work,
units need to be set in the :ref:`scene settings &lt;data-scenes-props-units&gt;`.

To use units simply write either the unit abbreviation or the full name after the value.

Examples of valid units include:

.. hlist::
:columns: 2

- ``1cm``
- ``1m 3mm``
- ``1m, 3mm``
- ``2ft``
- ``3ft/0.5km``
- ``2.2mm + 5' / 3" - 2yards``

.. note:: Some notes about using units:

- Commas are optional.
- You can mix between metric and imperial even though you can only show one at a time.
- Plurals of the names are recognized too, so ``meter`` and ``meters`` can both be used.

**********************
Toggle &amp; Radio Buttons
**********************

Checkboxes &amp; Toggle Buttons
===========================

.. figure:: /images/interface_controls_buttons_toggle-radio_checkbox.png
:align: right

Toggle Buttons.

These buttons are used to activate or deactivate options. Use :kbd:`LMB` to change their state.

On checkboxes a tick is shown when the option is activated.
Toggle buttons are used to set an on/off status. When state is on, they appear like pressed (dark).
Clicking this type of button will toggle a state but will not perform any operation.
Some toggle buttons have an icon version for each state.

Dragging
--------

To change many values at once, you can :kbd:`LMB` drag over multiple buttons,
This works for checkboxes, toggles and to select a radio button value.

.. tip::

For layer buttons (a type of toggle button) it is often useful to hold :kbd:`Shift` at the same time,
to set or clear many layers at once.

Radio Buttons
=============

.. figure:: /images/interface_controls_buttons_toggle-radio_radio.png
:align: right

Radio Buttons.

Radio buttons are used to choose from a small selection of "mutually exclusive" options.

Cycling
-------

Use :kbd:`Ctrl-Wheel`, while hovering with the mouse over it, to cycle between the options.
Cycling works also for number button and select menus.
.. _ui-color-picker:

************
Color Picker
************

.. figure:: /images/interface_controls_templates_color-picker_circle-hsv.png
:align: right

Circle HSV.

The color picker is a pop-up that lets you define a color value.
Holding :kbd:`Ctrl` while dragging snaps the hue to make it quick to select primary colors.

Color field
Lets you pick the first and second color component. The shape can be selected by the `Types`_.
Color slider
The slider with a gradient in the background lets you define the third color component.
It can also be controlled with the :kbd:`Wheel`.

Color space
Selects the :term:`Color Space` for the number buttons below.

RGB, HSV/HSL, Hex
Color values
Blender uses (0 to 1.0) values to express colors for RGB and HSV colors.

Hexadecimal (Hex) values are expressed as RRGGBB.
Shorthand hex colors are also supported as RGB,
e.g. dark-yellow FFCC00, can be written as FC0.

For operations that are capable of using Alpha, another slider "A" is added.
Eyedropper
The :doc:`/interface/controls/buttons/eye_dropper` (pipette icon) can be used
to sample a color value from inside the Blender window.

.. note::

In Blender, the *Hex* and HSV/HSL values are automatically :term:`gamma` corrected however,
for the RGB values, they are in Scene Linear colorspace, and are therefor not gamma corrected.
For more information, see the :doc:`Color Management and Exposure &lt;/render/post_process/color_management&gt;` page.

Types
=====

The default color picker type can be selected in the User Preferences,
see: :doc:`System &lt;/preferences/system&gt;`.

Circle
The color values ranging from center to the borders. The center is a mix of the colors.
Square
The Borders of the square are the axis for the two color components, with the center on the bottom right.

.. list-table:: Color Picker types.

* - .. figure:: /images/interface_controls_templates_color-picker_circle-hsv.png

Circle HSV.

- .. figure:: /images/interface_controls_templates_color-picker_circle-hsl.png

Circle HSL.

- ..

* - .. figure:: /images/interface_controls_templates_color-picker_square-sv-h.png

Square (SV + H).

- .. figure:: /images/interface_controls_templates_color-picker_square-hs-v.png

Square (HS + V).

- .. figure:: /images/interface_controls_templates_color-picker_square-hv-s.png

Square (HV + S).
.. _ui-color-ramp-widget:

*****************
Color Ramp Widget
*****************

.. figure:: /images/interface_color_ramp.png

Color-Ramp.

*Color Ramps* enables the user to specify a range of colors based on color-stops.
Color-stops are similar to a mark indicating where exactly the chosen color should be.
The interval from each of the color-stops added to the ramp is a result of the color interpolation and
chosen interpolation method. The available options for Color Ramps are:

Add ``+``
Clicking on this button will add a stop to your custom weight paint map.
The stops are added from the last selected stop to the next one, from left to right and
they will be placed in the middle of both stops.
Delete ``-``
Deletes the selected color-stop from the list.
Flip ``&lt;-&gt;``
Flips the color band, inverting the values of the custom weight paint range.
Color Mode
Selection of the :term:`color space` used for interpolation.

RGB
Blends color by mixing each color channel and combining.
HSV/HSL
Blends colors by first converting to HSV or HSL, mixing, then combining again.
This has the advantage of maintaining saturation between different hues,
where RGB would de-saturate, this allows for a richer gradient.
Interpolation Options
Enables the user to choose the types of calculations for the color interpolation for each color stop.

B-Spline
Uses a *B-Spline* Interpolation for the color stops.
Cardinal
Uses a *Cardinal* Interpolation for the color stops.
Linear
Uses a *Linear* Interpolation for the color stops.
Ease
Uses a *Ease* Interpolation for the color stops.
Constant
Uses a *Constant* Interpolation for the color stops.
Active Color Stop
Index of the active color-stop (shown as a dashed line).
Allows you to change the active color when colors may be too close to easily select with the cursor.
Position
This slider controls the positioning of the selected color stop in the range.
Color Button
Opens a color picker for the user to specify color and Alpha for the selected color stop.
When a color is using Alpha, the Color button is then divided in two, with the left side
showing the base color and the right side showing the color with the alpha value.

Shortcuts
---------

- :kbd:`LMB` (drag) moves colors.
- :kbd:`Ctrl-LMB` (click) adds a new control point.
.. _ui-curve-widget:

************
Curve Widget
************

.. figure:: /images/interface_curve.png
:align: right

Curve Widget.

The purpose of the *Curve Widget* is to allow the user to modify an input
(such as an image) in an intuitive manner by
smoothly adjusting the values up and down using the curve.

The input values are mapped to the X-axis of the graph, and the output values are mapped to the Y-axis.

Control Points
==============

Like all curves in Blender, the curve of the *Curve Widget* is controlled using *control points*.

By default, there are two control points: one at (0.0, 0.0) and one at (1.0, 1.0),
meaning the input is mapped directly to the output (unchanged).

Move
Simply click and drag it around.
Add
Click anywhere on the curve where there is not already a control point.
Remove
Select it and click the ``X`` button at the top right.

Controls
========

Above the curve graph is a row of controls. These are:

Zoom In
Zoom into the center of the graph to show more details and provide more accurate control.
To navigate around the curve while zoomed in, click and drag in an empty part of the graph.
Zoom Out
Zoom out of the graph to show fewer details and view the graph as a whole.
You cannot zoom out further than the clipping borders (see *Clipping* below).

Tools
Reset View
Resets the view of the curve.
Vector Handle
Vector type of curve point's handle.
Breaks the tangent at the curve handle, making it an angle.
Auto Handle
Automatic type of curve point's handle.
Extend Horizontal
Causes the curve to stay horizontal before the first point and after the last point.

.. figure:: /images/interface_curve-extendhorizontal.png
:width: 150px

Extend Horizontal.

Extend Extrapolated
Causes the curve to extrapolate before the first point and after the last point,
based on the shape of the curve.

.. figure:: /images/interface_curve-extendextrapolate.png
:width: 150px

Extend Extrapolate.

Reset Curve
Resets the curve in default (removes all points added to the curve).
Clipping
Use Clipping
Forces curve points to stay between specified values.
Min X/Y and Max X/Y
Set the minimum and maximum bounds of the curve points.
Delete
Remove the selected control point. The first and last points cannot be deleted.
X, Y
The coordinates of the selected control point.
Copy/Paste :kbd:`Ctrl-C`, :kbd:`Ctrl-V`
The whole curve can be copied from one Curve widget to another by hovering over
the curve graph and pressing :kbd:`Ctrl-C`, :kbd:`Ctrl-V`.
.. _ui-data-block:

***************
Data-Block Menu
***************

A set of menu buttons used to link :doc:`/data_system/data_blocks` to each other.
Data-blocks are items like meshes, objects, materials, textures, and so on.
If data-blocks are linked the data will be updated across all of the users when edited.

.. figure:: /images/interface_data-block.jpg
:align: right

The Data-Block menu with a search input.

Type
Shows an icon indicating the data-block type. It opens up the following pop-up menu.
The data-block can be dragged from here e.g to drag an material onto an object in the 3D View or
into a :ref:`ui-data-id` field.

List
A list of data-block available in the current blend-file or link in to select an item from.
The menu may show a preview besides the items and
a search box to search the items in the list by name.
Name
Displays the internal name of the linked Data-Block, which can be edited as a regular text field.
If a name already is in assigned Blender will add a digit to the name like ".001".
User count
Displays the number of users of the data. Clicking on it to make it a single-user copy,
with it linked only to the active object/object's data.
Fake User ``F``
Keeps the data-block saved in the blend-file, even if it has no real users.
New/Add ``+``
Creates a new data-block or duplicates the current data-block and applies it.
Open file
Opens the :doc:`File Browser &lt;/editors/file_browser/introduction&gt;`.
Unpack file
:ref:`Unpack &lt;pack-unpack-data&gt;` the file packed into the current blend-file to external ones.
Unlink data-block ``X``
Clears the link, :kbd:`Shift-LMB` to set the users to zero
allowing the data to be fully deleted from the blend-file.

Sometimes there is a :ref:`list &lt;ui-list-view&gt;` of applied data-blocks
(such as a list of materials used on the object).

.. seealso::

Data-blocks are discussed farther in the :doc:`Data System chapter &lt;/data_system/data_blocks&gt;`.

Preview
=======

.. figure:: /images/interface_data_block_preview.png

The Data-Block menu with preview.

In the Tool Shelf is a version of the data-block menu with a bigger preview.

.. rename to selector?

.. _ui-data-id:

Data ID
=======

.. figure:: /images/interface_data_id.png

The Data ID.

A Data ID is a text field with icon on the left, which opens a gray pop-up.
It is used to reference data-blocks selected by their name.

Type
The icon on the left specifies the accepted data-block type.
Name
The text field functions as a search field by matching elements in the list.
Press of :kbd:`Tab` for auto-complete names to the level a match is found.
If more than match exists you have to continue typing.
If you type an invalid name, the value will remain unchanged.
List
Lets you select the data-block directly.
Eye Dropper
In some Data IDs there is an :doc:`/interface/controls/buttons/eye_dropper`
available through the pipette icon on the right side.
Remove ``X``
Click  the ``X`` button on the right to remove the reference.

Sub IDs
-------

.. figure:: /images/interface_controls_templates_data_subids.png

Vertex Group
If selected object in the *Name* field is a mesh or a lattice,
an additional field is displayed where a vertex group can be selected.
Bone
If selected object in the *Name* field is an armature,
a new field is displayed offering the choice to specify
an individual bone by entering its name in the *Bone* data ID.

Head/Tail
If a Bone is set, a new field is displayed offering
the choice of whether the head or tail of a Bone will be pointed at.
The slider defines where along this bone the point lies interpolating along the bone axis in a straight line.
A value of zero will point at the Head/Root of a Bone,
while a value of one will point at the Tail/Tip of a Bone.

Use B-Bone Shape
When the bone is a :doc:`/rigging/armatures/bones/properties/bendy_bones`,
click on this button to make the point follow the curvature of the B-Spline between head and tail.
.. _ui-list-view:

********************
List Views &amp; Presets
********************

List Views
==========

.. figure:: /images/interface_templates_list-presets_view_filter.png
:align: right

This control is useful to manage lists of items.
They can be found in example in the object data properties.

Select
To select an item, :kbd:`LMB` on it.
Rename
By double clicking on an item, you can edit its name via a text field.
This can also be achieved by pressing :kbd:`Ctrl-LMB` over it.
Resize
The list view can be resized to show more or fewer items.
Hover the mouse over the handle (==) then click and drag the handle to expand or shrink the list.
Filter
Click the *Show filtering options* button (+) to toggle filter option buttons.

Search
Type part of a list item's name in the filter text field to filter items by part of their name.

Filter Include
When the magnifying glass icon has a ``+`` sign then only items that match the text will be displayed.
Filter Exclude
When the magnifying glass icon has a ``-`` sign then only items that do not match text will be displayed.

Sort
Sort list items.

Alphabetical
This button switches between alphabetical and non-alphabetical ordering.
Inverse
Sort objects in ascending or descending order. This also applies to alphabetical sorting, if selected.

On the right of the list view are additional buttons:

Add ``+``
Adds a new item.
Remove ``-``
To remove the selected item.
Specials
A :ref:`Specials &lt;ui-specials-menu&gt;` menu with operators context-sensitive to the item type.
e.g. copy paste, or operations on all items.

Move Up
The button showing an up arrow moves the selected item up one position.
Move Down
The down arrow moves the item down.

.. _ui-presets:

Presets
=======

.. figure:: /images/interface_preset.png
:align: right

Presets without and with specials.

.. Share between properties. i.e different nodes color presets.

Selector
A list of available presets. A selection will overrides the included properties.
Add ``+``
New presets can be added based on the in the preset included properties,
which will be saved for later re-use.
A pop-up opens where you can set a name
after which you can select it from the list and
in some cases additional settings.
Remove ``-``
Deletes the selected preset.
Specials
A :ref:`Specials &lt;ui-specials-menu&gt;` menu with operators context-sensitive to the preset type.
e.g. copy paste.

.. saving preset: data-system?

***************
Operator Search
***************

A menu with access to all Blender tools is available by pressing
:kbd:`Spacebar`. Simply start typing the name of the tool you want to refine the list.
When the list is sufficiently narrowed, :kbd:`LMB` on the desired tool or navigate
with :kbd:`Down` and :kbd:`Up`, activate it by pressing :kbd:`Enter`.

.. figure:: /images/interface_controls_templates_operator-search.png

The operator search pop-up.
.. This page should be a general workflow page (TODO).

******************
Animating Sketches
******************

You can use Grease Pencil to create 2D animations (e.g. in flipbook style) and
mixing it with 3D objects and composition.

Sketches are stored on the frame that they were drawn on, as a separate drawing
(only on the layer that they exist on). A keyframe is automatically add per layer.
Each drawing is visible until the next drawing for that layer is encountered.
The only exception to this is the first drawing for a layer,
which will also be visible before the frame it was drawn on.

Therefore, it is simple to make a pencil-test/series of animated sketches:

#. Go to first relevant frame. Draw.
#. Jump to next relevant frame. Draw some more.
#. Keep repeating process, and drawing until satisfied. Voila! Animated sketches.

.. (todo) keyframes, on properties.

.. seealso::

Grease Pencil mode in the :doc:`Dope Sheet &lt;/editors/dope_sheet/grease_pencil&gt;` editor.

Compositing
===========

The grease pencil layers create a pass inside :doc:`OpenGL &lt;/render/opengl&gt;` render result.
This result can be exported to ``EXR multilayer`` and used in composition.

ToDo.

Example
=======

.. only:: builder_html and (not singlehtml)

.. youtube:: vSD5mN7LT_g

.. only:: not builder_html and (singlehtml)

A video can be found at https://www.youtube.com/watch?v=vSD5mN7LT_g

*******************
Convert to Geometry
*******************

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Grease Pencil --&gt; Grease Pencil --&gt; Tools: Convert to Geometry...`
| Menu:     :menuselection:`GPencil --&gt; Convert to Geometry...`
| Hotkey:   :kbd:`Alt-C`

.. figure:: /images/interface_grease-pencil_convert.png
:align: right

The Convert to Curve options.

In the 3D View, sketches on the active layer can be converted to geometry,
based on the current view settings, by transforming the points recorded when drawing
(which make up the strokes) into 3D-space. Currently, all points will be used,
so it may be necessary to simplify or subdivide parts of the created geometry for standard use.

Sketches can currently be converted into curves,
as proposed by the *Convert Grease Pencil* menu popped-up by the *Convert* button in the grease pencil properties.

Options
=======

Type
The type of object to convert to.

Path
Create NURBS 3D curves of order 2 (i.e. behaving like polylines).
Bézier Curve
Create Bézier curves, with free "aligned" handles (i.e. also behaving like polylines).
Polygon Curve
Bézier Curve with strait line segments (auto handles).

.. note:: Converting to Mesh

If you want to convert your sketch to a mesh,
simply choose first *NURBS*, and then convert the created curve to a mesh.

Normalize Weight
Will scale weights value so that they tightly fit into the (0.0 to 1.0) range. (enabled by default)

All this means that with a pressure tablet,
you can directly control the radius and weight of the created curve, which can affect e.g.
the width of an extrusion, or the size of an object through a *Follow Path*
Constraint or *Curve* Modifier!

Link Strokes
Will create a single spline, i.e. curve element. (enabled by default)
from all strokes in active grease pencil layer. This especially useful if you want to use the curve as a path.
All the strokes are linked in the curve by "zero weights/radii" sections.

Timing
------

Grease pencil stores "dynamic" data, i.e. how fast strokes are drawn.
When converting to curve,
this data can be used to create an *Evaluate Time* F-Curve (in other words,
a path animation), that can be used e.g. to control another object's position along that curve
(*Follow Path* constraint, or, trough a driver, *Curve* modifier).
So this allows you to reproduce your drawing movements.

.. important::

All those "timing" options need *Link Stroke* to be enabled,
else they would not make much sense!

Timing Mode
This control let you choose how timing data are used.

No Timing
Just create the curve, without any animation data (hence all following options will be hidden).
Linear
The path animation will be a linear one.
Original
The path animation will reflect to original timing, including for the "gaps"
(i.e. time between strokes drawing).
Custom Gaps
The path animation will reflect to original timing, but the "gaps" will get custom values.
This is especially useful if you have very large pauses between some of your strokes,
and would rather like to have "reasonable" ones!

Frame Range
The "length" of the created path animation, in frames. In other words, the highest value of *Evaluation Time*.
Start Frame
The starting frame of the path animation.
Realtime
When enabled, the path animation will last exactly the same duration it took you do draw the strokes.
End Frame
When *Realtime* is disabled, this defines the end frame of the path animation.
This means that the drawing timing will be scaled up or down to fit into the specified range.
Gap Duration
*Custom Gaps* only. The average duration (in frames) of each gap between actual strokes.
Please note that the value entered here will only be exact if *Realtime* is enabled,
else it will be scaled, exactly as the actual strokes' timing is!

Example
=======

Here is a simple "hand writing" video created with curves converted from sketch data:

.. only:: builder_html and (not singlehtml)

.. youtube:: VwWEXrnQAFI

.. only:: not builder_html and (singlehtml)

A video can be found at https://www.youtube.com/watch?v=VwWEXrnQAFI

The blend-file from the above example can be found
`here &lt;https://wiki.blender.org/index.php/file:ManGreasePencilConvertToCurveDynamicExample.blend&gt;`__.

*******
Brushes
*******

Drawing Brushes
===============

.. admonition:: Reference
:class: refbox

| Mode:     Stroke Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Grease Pencil --&gt; Drawing Brushes`

Brushes
A :ref:`ui-list-view` of preset brushes.
You can switch between the brushes using keyboard numbers from :kbd:`1` to :kbd:`0`.
The selected drawing brush is the brush in the list located at that position.
Thickness
Width of full pressure strokes in pixels constant to the viewport i.e. not affected by the zoom.
The thickness can be lower depending of the pressure.
Sensibility
Adjust the sensibility of the thickness to the pressure of the pencil on the tablet.
This pressure can be disabled using the right small button.
Strength
Similar to sensibility, but affect the alpha value of the color.
This parameter allows to get effects as color fading or watercolor.
Randomness
The properties for *Sensibility* and *Strength* additionally have a randomness factor which
can be enabled using the jagged line icon to the right of the number sliders.

Jitter
Define a jitter randomness in the stroke.
Angle
Defines the angle when the thickness of the stroke will be 100%.
Any change in the direction will change the thickness.

Factor
Defines the effect for drawing angle changes in the thickness.

.. tip::

The *Angle* and *Angle Factor* parameters allow to create drawing brushes such as markers
that change the thickness depending of the angle of drawing.
This gets a more artistic drawing and less "computer" lines.

.. figure:: /images/interface_grease-pencil_drawing_brushes.png

Preset Brushes.

Stoke Quality
-------------

These settings are per-brush settings that are applied after each stroke is drawn
(when converting from 2D/screen space coordinates to 3D/data space coordinates).
These are per-brush settings so that you can apply varying proprieties to different types of brushes.
E.g higher smoothing and/or subdivision for final "beauty",
and less smoothing/subdivision for initial "blocking" strokes.

Smooth
Defines how much smoothing is applied (using the same method as the "Smooth" Brush).
It is used to get rid of jagged edges and jitter/hand shake.

Smoothing Iterations
Defines how many times smoothing is applied. On each additional round of smoothing performed,
the strength of the smoothing applied is halved,
i.e. on the first round, it will be 100% of smoothing factor, then 50%, then 25%, etc.
This setting is most useful for improving the quality of heavily subdivided strokes,
where the multiple rounds of smoothing can help reduce "faceting" artifacts.

Subdivision Steps
Defines how many times the stroke will be subdivided.
Each time the stroke is subdivided, extra stroke points are added between each pair of existing stroke points.
The main use of this setting is to make strokes look less "faceted" (especially large strokes drawn quickly).
Strokes are subdivided before smoothing is applied.

Randomness
Amount of randomness to add new new strokes after subdivision.

Brush Curves
============

.. admonition:: Reference
:class: refbox

| Mode:     Stroke Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Grease Pencil --&gt; Brush Curves`

This panel allows you to adjust the parameters used with tablets to get personal preferences.
The available curves that can be edited are:

- Sensitivity
- Strength
- Jitter

Read more about using the :ref:`ui-curve-widget`.

******
Colors
******

.. admonition:: Reference
:class: refbox

| Mode:     Stroke Edit Mode
| Panel:    :menuselection:`Properties region--&gt; Grease Pencil Colors`

Palette
A :ref:`ui-data-block` to select a palette, which is a set of colors.
Switching palettes will change all strokes color in all layers if the same color are linked.

New ``+``
If there are more than one palette,
all colors of the old palette will be transferred to the new selected palette.

- If the color exist in the new palette (same name),
the stroke is linked to new color.
- If the color does not exist in the new palette,
a new color is added to the palette in order to keep the stroke.
Colors
A :ref:`ui-list-view` of colors grouped in the palette linked as stroke or fill colors.
If a color with strokes is removed, all strokes of this color are removed.
Any change to line color or fill color, will change any stroke of any layer using this color.
A palette must contain at least one color, so the last one cannot be deleted.

Lock (padlock icon)
ToDo.
Hide (eye icon)
ToDo.
Ghost (ghost icon)
ToDo.

Specials
ToDo.

Stroke
Sets the line color and the maximum opacity (which is also affected by the brush strength).
Fill
Sets the color of the interior space enclosed by the strokes.
Increase the opacity from zero to make the fill visible.
Fill works best on convex shapes, unless you are using *High Quality Fill* (see below).

Volumetric Strokes
An alternative drawing technique by drawing strokes as a series of filled screen-aligned discs.
Get best results with partial opacity and large stroke widths.
High Quality Fill
Uses a better fill algorithm that works better for concave drawings.
.. _grease-pencil-drawing-index:

###################
Drawing Strokes
###################

.. toctree::
:maxdepth: 2

introduction.rst
layers.rst
colors.rst
brushes.rst

************
Introduction
************

Enable the *Grease Pencil* by clicking *Draw, Line, Poly or Erase* from the Tool Shelf :kbd:`T`.
A new layer will be automatically added for you to draw on.

A new layer can be added from the Grease Pencil panel in the Properties region.
This panel can also be used to customize the color, opacity and thickness of the pencil lines.
Changes to these settings will affect all strokes on the current layer.

.. figure:: /images/interface_grease-pencil_example-simple.png

An example of Blender's Grease Pencil.

*Grease Pencil* sketches can be converted to editable geometry and used to aid the animation process.

Drawing
=======

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Grease Pencil --&gt; Grease Pencil`

The Tool Shelf provides a number of options for drawing with the *Grease Pencil* which are detailed below.

Draw :kbd:`D-LMB`
Draw a new stroke (multiple short, connected lines). The stroke will finish when you release the mouse button.
Line :kbd:`Ctrl-D-LMB`
Draw a new line in rubber band mode. The line will finish when you release the mouse button.
Poly :kbd:`Ctrl-D-RMB`
Draw connected lines by clicking on position you want to add the next point.
Lines will be automatically added to connect the two points.
Holding :kbd:`LMB` down and sliding mouse lets you place the new point/segment preview.
The transformation of the point is locked to X/Y axis set by initial direction of the mouse movement.
Erase :kbd:`D-RMB`, :kbd:`Eraser`
Erases segments of strokes that fall within the radius of the eraser "brush"
(with a linear falloff from the center of the eraser circle).
The erasing will continue until the mouse button is released,
while trying to reduce the thickness of strokes before removing them.
The eraser operates on all visible and editable layers.
If begun with *Erase*, either :kbd:`RMB` or :kbd:`LMB` will erase strokes.
Its cursor is a red circle with a dashed outline.

The size of the eraser "brush" can be controlled with :kbd:`Wheel`, or with
:kbd:`NumpadPlus` and :kbd:`NumpadMinus`, while still holding :kbd:`RMB`.

Additive Drawing
----------------

With the "Additive Drawing" option enabled the active frame's
strokes will be carried over/copied if you start drawing on an empty frame
(i.e. one without any keyframe already). This saves the effort of keeping a Dopes sheet
open, and to remember to duplicate the current frame before starting to draw the
next pose (or risk managing to draw the perfect pose, but without everything else).

This option makes it easier to animate shots where you're building on a result from a previous frame.
Examples of cases where this comes in handy includes animating facial expressions
(when all outlines are on the same layer), or animating "growing" things
(e.g. vines, or concentric circles growing from a central point).

.. note::

Even without this option enabled, this is the default behavior when using
the eraser on an "empty" frame. This makes it easier to do shots where you're just
changing parts of the facial expression, or if you're animating an "eraser" effect.

Continuous Drawing
------------------

Continuous Drawing allows for rapid sketching with the *Grease Pencil* when
multiple strokes are desired. So that you only have to hold :kbd:`D` once for the first stroke.
Besides the checkbox Continuous Drawing is also enabled
if the :kbd:`D` key is released while pressing :kbd:`LMB`.
The eraser for one-off strokes (:kbd:`RMB`) is still available.
Note that with the *Eraser* both :kbd:`LMB` or :kbd:`RMB` can be used
when drawing has started.

Use :kbd:`Esc` or :kbd:`Enter` or clicking outside the current viewport
(e.g. another region or editor) to exit the mode.
Continuous drawing can be disabled using :kbd:`E` key in order to get fast access to sculpt mode.

Draw on Back
------------

New strokes are moved behind the drawing when confirming the drawing tool (lowered to the bottom of the stack).

Stroke Placement
================

.. figure:: /images/interface_grease-pencil_tools_panel.png
:figwidth: 148px
:align: right

Grease Pencil panel.

Defines how the strokes are converted to 3D (or 2D) space.

View
New strokes are placed in screen space (2D) and are locked to the view.
Cursor
New strokes are drawn in 3D-space,
with position determined by the 3D cursor and the view rotation at the time of drawing.
*Cursor* is available as an option in the *UV/Image Editor*
but it functions identically to the *View* option.  *(3D View only)*
Surface
New strokes are drawn in 3D-space, with their position projected onto the first visible surface.
*(3D View only)*
Stroke
New strokes are drawn in 3D-space, with their position projected onto existing visible strokes.
Note that strokes created with *View* are not in 3D-space and are not considered for this projection.
*(3D View only)*

Only Endpoints
Applies the drawing setting only to the endpoints of the stroke.
The part of the stroke between the endpoints is adjusted to lie on a plane passing through the endpoints.

.. figure:: /images/interface_grease-pencil_stroke_placement.png

The effect of different Drawing Settings on Grease Pencil strokes.

.. tip:: Notes For Tablet Users:

- The thickness of a stroke at a particular point is affected
by the pressure used when drawing that part of the stroke.
- The "eraser" end of the stylus can be used to erase strokes.

Enable Editing
See :doc:`/interface/grease_pencil/stroke_edit`.
A overlay is displayed in the top-right corner of editors when enabled.

Tools
======

- :doc:`Convert to Geometry &lt;/interface/grease_pencil/convert_to_geometry&gt;`
- :doc:`/interface/ruler_and_protractor`
..    TODO/Review: {{review|partial=x|fixes=[]}}.

******
Layers
******

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Properties region--&gt; Grease Pencil Layers`

Grease Pencil sketches are organized in layers,
much like the image layers in the GIMP or Photoshop\ :sup:`®`\ .
These layers are not related to any of the other layer systems in Blender.

The layers' main purpose is to gather sketches that are related in some
meaningful way (e.g. "blocking notes", "director's comments on blocking", or "guidelines").
For this reason, all the strokes on a layer (not just those made after a particular change)
are affected by that layer's color, opacity, and stroke thickness settings.

Layers are managed in the *Grease Pencil Panel* of the *Properties region* :kbd:`N` shown here.

.. figure:: /images/interface_grease_pencil_layers_list.jpg

Grease Pencil Panel.

Grease Pencil Data
==================

Use the following controls to Add, Remove or adjust the position of a layer in the list.

Source
Scene
Grease Pencil data is attached to the current scene is used,
unless the active object already has Grease Pencil data (i.e old files).
Object
Grease Pencil data is attached to the active object are used.
This is required when using pre 2.73 add-ons.

Grease Pencil
Used to select the Grease Pencil data-block to use for layers. For controls see :ref:`ui-data-block`.

Active Layer
A :ref:`ui-list-view` of layers attached to each scene or object.

Parent (bone icon)
Indicates that a parent has been set for the layer.
Lock (padlock icon)
Locks the ability to edit the current layers layer.
Hide (eye icon) :kbd:`H`
Hides the current layer in the drawing region.
Unlock Color (palette with arrow icon)
Unprotects selected colors from further editing and/or frame changes.

Isolate (padlock icon) :kbd:`NumpadAsterix`
To restrict editing to the active layer only.
Isolate (visible) (eye icon)
An option of *Isolate* to also affect the visibility.

Specials
Duplicate Layer
Creates a copy of the current layer.
Show All :kbd:`Alt-H`
Makes all hidden layers visible.
Hide Others :kbd:`Shift-H`
Makes all non selected layers hidden.
Lock/Unlock All
Locks/Unlocks all of the layers. This can be useful to prevent unwanted editing.
Merge Down
Merges the current layer with the layer below it.

.. note::

By default, most operations occur only on the *active* layer highlighted in the list.

Appearance Settings
===================

These settings can be used to change how the active layer appears.

Opacity
The transparency of the layer.
X-Ray
Makes the lines visible when they pass behind other objects in the scene.
Show Points
Draws the start/end points that make up the stroke.

Tint
Color
The color to tint the layer.
Factor
The amount that the *Tint Color* has on the layer.

Thickness Change
A relative change in pixels to apply to the thickness of all stroke in the active layer
(works like a modifier).

Apply (hand and bulged in blue line icon)
If the apply button is pressed, the thickness change is applied and
the value is reset to zero.

Animation
=========

Parent
An :ref:`ui-data-id` to select the :term:`parent` object.
The strokes of the layer will follow parent transformations.

Type
Type of :doc:`parent relation &lt;/editors/3dview/object/properties/relations/parents&gt;`.

Object, Armature, Bone

Lock Frame
Locks the current frame displayed by layer.
Delete Frame
Deletes the active frame for the active Grease Pencil Layer.

.. _grease-pencil-onion:

Onion Skinning
--------------

Onion-skinning, also known as ghosting, helps an animator by displaying the neighboring frames as a faded trail.

.. figure:: /images/interface_grease_pencil_layers_onion.jpg

Grease Pencil Onion Skinning.

A: Use Custom Colors

Onion Skinning
Checkbox to enable onion skinning.
Always Use (camera icon)
If enabled ghosts are displayed when scrubbing the view and/or playing back animation.
Use Custom Colors (palette icon)
Toggles to use the *Before* and *After* controls to change the color of the ghosted frames.

Before/After
Color
The color of the strokes before/after the current frame.
Before/After Range
The maximum number of ghosts to show before/after the current frame.
0 will only show the previous/next sketch, and -1 will not show any frames before/after current.
.. _grease-pencil-index:

################
Grease Pencil
################

.. toctree::
:maxdepth: 2

introduction.rst
drawing/index.rst
stroke_edit.rst
animating.rst
convert_to_geometry.rst

************
Introduction
************

Years ago people needed a way to quickly draw on their monitors,
they did this with a tool called a grease pencil.
This is especially helpful for animators who need to add notes directly on their screen.
However, not everyone wants to draw on their monitors.
So a digital version was made, also called a grease pencil.

You can use the Grease Pencil tool to draw freehand sketches and
annotations in most of the :doc:`Editors &lt;/editors/index&gt;`.
The sketches that are made are saved with the blend-file so they can be seen at any time,
an advantage over the old grease pencil.
However, you can also do much more with the digital grease pencil such as:

- Planning animation poses and motion curves.
- Sketching out model topology.
- Hand-drawn storyboarding in 3D.
- As director's tool to review shots.
- 2D animations

An advanced use of *Grease Pencil* is for different tools (e.g. add-ons).
Allowing you to draw where the tool is to take effect.

.. vimeo:: 155635261

****************
Stroke Edit Mode
****************

Enter Stroke Edit Mode with the *Mode* select menu in the 3D Views header or
toggle the *Enable Editing* in the Grease Pencil panel
*(only available in 2D editors such as UV-Image editor, Node editor, etc.)*, or use :kbd:`D-Tab`.
In this mode, many common editing tools will operate on Grease Pencil stroke points instead.

These tools let you move and reshape grease pencil strokes after they have been drawn.

Open the Grease Pencil tab on the Tool Shelf.
Look for the tools in the Edit Strokes panel shown here:

.. figure:: /images/interface_grease_pencil_drawing_edit_strokes_panel.png

Edit panel with grease pencil strokes.

Selecting
=========

Grease pencil strokes are formed from a series of connected vertex points.
To make changes, first select points on the strokes that you want to edit.
You can only select points on the active layer.
The selected points are highlighted as in the image above.

.. hint::

Set the layer's *Stroke Thickness* to 1 to make the points more visible.

Use the mouse to select the points, or one of the selection buttons in the panel as detailed in
:doc:`Basic Selection &lt;/modeling/meshes/selecting/introduction&gt;`.

Various selection functions similar to those available when editing meshes can be used:

.. list-table::
:stub-columns: 1

* - Select All
- :kbd:`A`
* - Border Select
- :kbd:`B`
* - Circle Select
- :kbd:`C`
* - Lasso Select
- :kbd:`Ctrl-LMB`
* - Select Linked
- :kbd:`L`, :kbd:`Ctrl-L`
* - Select More
- :kbd:`Ctrl-NumpadPlus`
* - Select Less
- :kbd:`Ctrl-NumpadMinus`
* - Select Stroke
- :kbd:`Alt-LMB`

Editing
=======

Header
------

Some tools can be access through the 3D View header. e.g. Copy/Paste.

Onion Skinning
Toggles :ref:`grease-pencil-onion`.
Selection Mask, Alpha
See `Further Options`_.

.. (todo) move to a better place

Menu
----

Shrink/Flatten :kbd:`Alt-S`
Adjust the pressure values of selected stroke points.
This provides a way to modify the thickness of strokes by moving the mouse or the :kbd:`Wheel`.
Delete All Active Frame :kbd:`D-X`
Deletes all strokes in the active frame. It can be accessed using :kbd:`D-X` (anywhere),
as well as :kbd:`Shift-X` (Edit Strokes Mode only) or the :menuselection:`GPencil --&gt; Delete` menu.
This makes it easier to quickly get rid of throwaway scribbles.
Move to Layer :kbd:`M`
Can be used to move strokes between layers (including to a new layer).

Edit Strokes Panel
------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Stroke Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Grease Pencil --&gt; Edit Strokes`
| Menu:     :menuselection:`GPencil`

Copy :kbd:`Ctrl-C`
Copies the selected Grease Pencil strokes (or actually, points and segments).
Paste :kbd:`Ctrl-V`
Pastes the previously copied strokes.
Paste &amp; Merge
Pastes the previously copied strokes and merge in active layer.

Delete :kbd:`X`
Points
Delete the selected points, leaving a gap in the stroke.
Dissolve
Reconnect the ends so there is no gap in the stroke.
Strokes
Delete the entire stroke containing any selected points.
Frame
Delete a frame when doing :doc:`Animating Sketches &lt;/interface/grease_pencil/drawing/layers&gt;`.
Duplicate :kbd:`Shift-D`
Make a copy of the selected points at the same location. Use the mouse to *Translate* them into position.
:kbd:`LMB` places them at their new position. :kbd:`RMB` cancels and removes the duplicates.
Toggle Cyclic
Close or open the selected stroke by adding an edge from the last to first point.

Bend :kbd:`Shift-W`
Bends selected item between the 3D cursor and the mouse.
Mirror :kbd:`Ctrl-M`
Mirrors selected strokes along one or more axises.
Shear :kbd:`Shift-Ctrl-Alt-S`
Shears selected items along the horizontal screen axis.
To Sphere :kbd:`Shift-Alt-S`
Move selected vertices outward in a spherical shape around the midpoint.

Arrange Strokes
Arranges the selection of strokes up/down in the drawing order of the active layer.

Bring Froward, Send Backward, Bring to Front, Send to Back
Move to Color
Sets the active color as the new color to all selected strokes.
Interpolate
Interpolate `Ctrl-Alt-E`
Interpolates grease pencil strokes between frames.
Sequence `Shift-Ctrl-E`
Interpolates full grease pencil strokes sequence between frames.
Interpolate All Layers
Checkbox to interpolates all layers, not only active.
Interpolate Selected Strokes
Checkbox to interpolates only the selected strokes in the original frame.
Join Strokes
Type
Join `Ctrl-J`
Joins selected strokes.
Join &amp; Copy `Shift-Ctrl-J`
Joins selected strokes as a new stroke.
Leave Gaps
Leaves gaps between joined strokes instead of linking them.
Flip Direction
Flips the start and end of a stroke.
Show Directions
Displays stroke drawing direction with a bigger green dot of the start point
and a smaller red dot for the end point.

Reproject Strokes
Reprojects the selected strokes from the current viewpoint to get all points on the same plane again.
This can be useful to fix problem from accidental 3D cursor movement, or viewport changes.

Sculpt Strokes Panel
--------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Stroke Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Grease Pencil --&gt; Sculpt Strokes`
| Menu:     :menuselection:`GPencil --&gt; Sculpt Strokes/Brushes`
| Hotkey:   :kbd:`E-LMB`

Several tools for editing Grease Pencil strokes are provided in the form of brushes which
you can use to "paint" or "sculpt" the appearance of the strokes without having to keep doing
a tedious select-tweak-select-tweak pattern of edits.

Hold :kbd:`E-LMB` and drag to sculpt.

Brushes
^^^^^^^

The brushes currently implemented are:

Smooth
Allows you to selectively relax jitter/shake and bumpiness, to tidy up messy parts of your sketches.

Affect Pressure
Use this option to perform smoothing on stroke thickness values.

Thickness
The Thickness Brush can be used to increase (Add) or decrease (Subtract) the thickness of
the parts of the stroke under the cursor.
Strength
Increase/decrease (:kbd:`Ctrl`) the alpha value of the stroke, E.g. for creating fading effects.
Grab
Takes the stroke points which fall within the brush circle when the sculpting action begins,
and allows you to translate this set of points.
Push
The Push Brush is very similar to the Grab brush, in that it also allows the user to translate stroke points.
However, unlike the Grab Brush, the Push Brush is not restricted to operating only on the first set of points
which were under the brush when the sculpt action was initiated. Instead, on each brush movement,
the points currently under the brush get moved based on the amount
the brush has moved since the last time it was evaluated.
Twist
Used to twist/rotate points around the cursor, creating a "swirling" effect.
It is useful for applying low levels of distortion to stroke points.
The *Direction* controls whether the points are rotated in a clockwise (CW) or anti-clockwise (CCW) direction.
Pinch/Inflate
Used to draw points away from the cursor, or towards it.

Pinch
Draw points towards the cursor.
Inflate
Push points away from the cursor.
Randomize
Randomizes the stoke attributes.
e.g. with *Position* enabled it displaces the points randomly in screen space to create jittered/jagged lines.
Clone Brush
Used to paste the previously copied points (in the Copy/Paste buffer on the active layer),
located at the point where you clicked.

Hold :kbd:`LMB` and drag to position and adjust the pasted strokes.
The strokes center follows the movements of the brush/cursor ("Stamp Mode").

Use Falloff
When the *Use Falloff* option is enabled, instead of moving all the newly pasted strokes by the same amount,
only the points that are currently under the cursor get affected. Thus, this in this mode of operation,
the brush is closer to a Paste and Push operation instead ("Stamp and Smudge").

.. Ed: not available any more? 2.78
Continuous: As the brush moves, repeatedly just paste new copies for where the brush is now.
In effect, this treats the contents of the copy buffer as the "brush template/kernel"
used for "dabbing" samples all over the canvas.

Common Options
^^^^^^^^^^^^^^

Radius :kbd:`Shift-F`/:kbd:`Wheel`
The size of the brush. Increase/decrease brush size with :kbd:`Shift-F` when not sculpting or
with :kbd:`Wheel` while sculpting (i.e. with the pen tip down, or mouse button held).
Strength :kbd:`Ctrl-F`/:kbd:`Shift-Wheel`
The Strength off the brush, can be changed by the pressure of the stylus.
(In/decrease see *Radius*).
Use Falloff
Enables a linear falloff to calculate the influence of the brush on a point.
That is, a point closer to the midpoint of the brush (i.e. the point under the cursor)
will get affected more than the ones at the edges.
Direction :kbd:`E-Ctrl-LMB`
Radio button to invert the brush effect.
Affect
Enable sculpt for position, strength (alpha value) and thickness in Smooth and Randomize brush.

Further Options
^^^^^^^^^^^^^^^

Selection Mask
Used to restrict the brush to only operating on the selected points.
Alpha :kbd:`Ctrl-H`
Alpha value of the visualization for selected vertices.
The visibility can be toggled (hide/unhide) using :kbd:`Ctrl-H`.
.. _interface-index:

#################
User Interface
#################

.. toctree::
:maxdepth: 2

splash.rst

Window System
=============

.. toctree::
:maxdepth: 1

window_system/introduction.rst
window_system/screens.rst
window_system/areas.rst
window_system/regions.rst
window_system/tabs_panels.rst

Interface Controls
==================

Buttons and Controls
--------------------

.. toctree::
:maxdepth: 1

controls/buttons/buttons.rst
controls/buttons/menus.rst
controls/buttons/toggle_radio.rst
controls/buttons/number.rst
controls/buttons/eye_dropper.rst

Extended Controls
-----------------

.. toctree::
:maxdepth: 1

controls/templates/data_block.rst
controls/templates/list_presets.rst
controls/templates/color_picker.rst
controls/templates/color_ramp.rst
controls/templates/curve.rst
controls/templates/operator_search.rst

common_shortcuts.rst

Tools
=====

.. toctree::
:maxdepth: 1

undo_and_redo.rst
ruler_and_protractor.rst
grease_pencil/index.rst
..    TODO/Review: {{review|text = Blender version|fixes=move page}}.

********************
Ruler and Protractor
********************

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Menu:     :menuselection:`Tool Shelf --&gt; Grease Pencil --&gt; Tools:Ruler/Protractor`

The ruler is an interactive tool where you can drag lines in the scene to measure distances or angles.
Optionally snapping to geometry could be activated for better accuracy or to measure wall thickness.
The ruler can be accessed from the Tool Shelf.

.. figure:: /images/editors_3dview_ruler_example.jpg
:width: 500px

Example of the ruler and protractor.

.. figure:: /images/editors_3dview_ruler_thickness.jpg
:width: 592px

Example using the ruler to measure thickness.

Usage
=====

.. figure:: /images/editors_3dview_ruler_basic.png

Here are common steps for using the ruler:

#. Activate the Ruler from the Tool Shelf.
#. Click and drag in the view-port to define the initial start/end point for the ruler.
#. Orbit the view and click on either end of the ruler to re-position it.
Holding :kbd:`Ctrl` enables snap to elements.
#. Click on the middle to measure angles.
#. Press :kbd:`Enter` to store the ruler for later use or :kbd:`Esc` to cancel.

.. note::

Editing operations can be used while the ruler is running,
however, tools like the knife cannot be used at the same time.

.. note::

Unit settings and scale from the scene are used for displaying dimensions.

Shortcuts
=========

- :kbd:`Ctrl-LMB` Adds new ruler.
- :kbd:`LMB` Drag end-points to place them, Hold Ctrl to snap, Hold :kbd:`Shift` to measure thickness.
- :kbd:`LMB` Drag center-point to measure angles, drag out of the view to convert back to a ruler.
- :kbd:`Delete` Deletes the ruler.
- :kbd:`Ctrl-C` Copies the rulers value to the clipboard.
- :kbd:`Esc` Exit tool.
- :kbd:`Enter` Saves the rulers for the next time the tool is activated.
.. _splash:

*************
Splash Screen
*************

When starting Blender, the splash screen appears in the center of the window.
It contains help options under link and the recently open blend-files.
A more detailed description can be found below.

.. figure:: /images/interface_splash_current.png
:align: center

Blender Splash Screen.

To close the splash screen and start a new project,
click anywhere outside the splash screen (but inside the Blender Window) or press :kbd:`Esc`.
The splash screen will disappear revealing the default screen.

To reopen the splash click on the Blender icon in the :doc:`Info Editor &lt;/editors/info/index&gt;`
header or select :menuselection:`Info Editor --&gt; Help --&gt; Splash Screen`.

Title
Besides the Blender icon and text, it shows the Blender version. e.g. the current version is |BLENDER_VERSION|.
Image
An image where you can identify package and version.
Date
At the top-right corner, you can see the date on that Blender version was compiled.
Hash
The Git Hash. This can be useful to give to support personnel, when diagnosing a problem.
Branch
Optional branch id.

Interaction
Key configuration the same as :menuselection:`User preferences --&gt; Input`.
Links
Links official web pages, the same could be found in the *Help* Menu of the Info Editor.
See :ref:`help-menu`.
Recent
Your most recently opened blend-files. This gives quick and easy access to your recent projects.
Recover Last Session
Blender will try to recover the last session based on temporary files. See :doc:`/troubleshooting/recover`.
.. _bpy.ops.ed.:

*************
Undo and Redo
*************

The tools listed below will let you roll back an accidental action,
redo your last action, or let you choose to recover to a specific point,
by picking from a list of recent actions recorded by Blender.

.. _bpy.ops.ed.undo:

Undo
====

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; History --&gt; Undo`
| Menu:     :menuselection:`Object/Object types --&gt; Undo`
| Hotkey:   :kbd:`Ctrl-Z`

If you want to undo your last action, just press :kbd:`Ctrl-Z`.

.. seealso::

:doc:`Editing Preferences &lt;/preferences/editing&gt;` section on undo to change defaults.

.. _bpy.ops.ed.redo:

Redo
====

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; History --&gt; Redo`
| Menu:     :menuselection:`Object/Object types --&gt; Redo`
| Hotkey:   :kbd:`Ctrl-Shift-Z`

To roll back the Undo action, press :kbd:`Ctrl-Shift-Z`.

.. _ui-redo-last:

Redo Last
=========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Operator panel`
| Hotkey:   :kbd:`F6`

*Redo Last* is short for *Redo(ing the) Last (Action)*.
:kbd:`F6` after an action will present you a context-sensitive
Pop-Up menu based on your last action taken and the Mode and Editor in which Blender is being used.

For example, if your last action was a rotation in *Object Mode*,
Blender will show you the last value changed for the angle (see Fig. :ref:`fig-interface-redo-last` left),
where you can change your action back completely by typing :kbd:`Numpad0`.
There are other useful options, based on your action context,
and you cannot only Undo actions, but change them completely using the available options.

If you are in *Edit Mode*,
Blender will also change its contents based on your last action taken.
In our second example (at the right), the last action taken was a Vertex Move;
we did a *Scale* on a Face, and, as you can see,
the contents of the Pop-Up menu are different, because of your mode (Edit Mode)
(See Fig. :ref:`fig-interface-redo-last` right).

.. _fig-interface-redo-last:

.. figure:: /images/interface_undo-redo_last.png

Redo last.

Left Image: Redo Last- Rotation (Object Mode, 60 degrees),
Right Image: Redo Last- Scale (Edit Mode, Resize face)

.. tip:: Operations using Redo Last

Some operations produce particularly useful results if you tweak their parameters with the :kbd:`F6` Menu.
Take, for example, adding a Circle. If you reduce the Vertex count to three,
you get a perfect equilateral triangle.

Undo History
============

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; History --&gt; Undo History`
| Menu:     :menuselection:`Object/Object types --&gt; Undo History`
| Hotkey:   :kbd:`Ctrl-Alt-Z`

.. figure:: /images/interface_undo-and-redo_undo-history-menu.png
:align: right

The Undo History Menu.

There is also an Undo History of the last actions taken, recorded by Blender.
You can access the history pop-up with :kbd:`Ctrl-Alt-Z`.

First positions correspond to most recent actions.
A small icon of an eye next to one of the entries indicates the current status.
Rolling back actions using the *Undo History* feature will take you back to the
action you choose. Much like how you can alternate between going backward in
time with *Undo* and then forward with *Redo*,
you can hop around on the Undo timeline as much as you want as long as you do not make a new change.
Once you do make a new change, the Undo History is truncated at that point.
Selecting one of the entries in the list takes the current status to that position.

Repeat Last
===========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; History --&gt; Repeat: Repeat Last`
| Hotkey:   :kbd:`Shift-R`

The Repeat Last feature will repeat your last action when you press :kbd:`Shift-R`.

In the example Images below, we duplicated a *Monkey* mesh,
and then we moved the Object a bit.
Using repeat :kbd:`Shift-R`, the *Monkey* was also duplicated and moved.

.. list-table::

* - .. figure:: /images/interface_undo-redo_repeat-last1.png

Suzanne.

- .. figure:: /images/interface_undo-redo_repeat-last2.jpg

After a :kbd:`Shift-D` and move.

- .. figure:: /images/interface_undo-redo_repeat-last3.jpg

After a :kbd:`Shift-R`.

.. _bpy.ops.ed.undo_history:

Repeat History
==============

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; History --&gt; Repeat: History...`
| Hotkey:   :kbd:`F3`

.. figure:: /images/interface_undo-and-redo_repeat-history-menu.png
:align: right

The Repeat History Menu.

The *Repeat History* feature will present you a list of the last repeated actions,
and you can choose the actions you want to repeat.
It works in the same way as the Undo History, explained above,
but the list contains only repeated actions. To access Repeat History, use :kbd:`F3`.

.. container:: lead

.. clear

.. note::

Blender uses two separate Histories, one dedicated for the *Edit Mode*,
and one dedicated for the *Object Mode*.

.. important::

When you quit Blender, the complete list of user actions will be lost, even if you save your file before quitting.

.. seealso::

Troubleshooting section on :doc:`Recovering your lost work &lt;/troubleshooting/recover&gt;`

*****
Areas
*****

The application window is always a rectangle on your desktop.
It is divided up into a number of re-sizable areas.
An area contains the workspace for a particular type of editor,
like a 3D View Editor, or an Outliner.

Arranging
=========

Blender uses a novel screen-splitting approach to arrange areas.
The idea is that you split up that big application window into any number of smaller
(but still rectangular) non-overlapping areas. That way,
each area is always fully visible,
and it is very easy to work in one area and hop over to work in another.

Changing the Size
-----------------

You can resize areas by dragging their borders with :kbd:`LMB`.
Simply move your mouse cursor over the border between two areas,
until it changes to a double-headed arrow, and then click and drag.

Splitting and Joining
---------------------

Area Split Widget
^^^^^^^^^^^^^^^^^

.. figure:: /images/interface-window_system-arranging_areas-split_widget.jpg

In the upper right and lower left corners of an area are the area split widgets,
and they look like a little ridged thumb grip. It both splits and combines areas.
When you hover over it, your cursor will change to a cross (✛).

:kbd:`LMB` and drag it inward *split* the area.
You define the direction of that border by either dragging horizontally or vertically.

In order to *join* two areas :kbd:`LMB` click and drag the area splitter outward.
They must be the same dimension (width or height) in the direction you wish to join.
This is so that the combined area space results in a rectangle.

.. figure:: /images/interface-window_system-arranging_areas-join_areas.png
:width: 250px

The Properties Editor is being merged "over" the Outliner.

The area that will closed gets a dark overlaid with an arrow.
Now you can select the area to be closed by moving the mouse over it.

Release the :kbd:`LMB` to complete the join.
If you press :kbd:`Esc` or  :kbd:`RMB` before releasing the mouse, the operation will be aborted.

Area Options
^^^^^^^^^^^^

:kbd:`RMB` on the border opens the *Area Options*.

Split Area
Shows a indicator line that lets you select the area and position where to split.
:kbd:`Tab` switches between vertical/horizontal.
Join Areas
Shows the join direction overlay.

Confirm or cancel works as described above.

Swapping Contents
-----------------

You can swap the contents between two areas with :kbd:`Ctrl-LMB`
on one of the splitters of the initial area, dragging towards the target area,
and releasing the mouse there. The two areas do not need to be side by side,
though they must be inside the same window.

Duplicate Area into new Window
==============================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`View --&gt; Duplicate Area into new Window`

The new window is a fully functional window, which is part of the same instance of Blender.
This can be useful, e.g. if you have multiple monitors.

A new window can be created from :menuselection:`View --&gt; Duplicate Area into new Window`.

You can also create a new window from an existing area by :kbd:`Shift-LMB`
on the area splitter widget, then drag slightly.

The window can be closed with the OS *Close Window* button.

Toggle Maximize Area
====================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`View --&gt; Toggle Maximize Area`
| Hotkey:   :kbd:`Ctrl-Up`, :kbd:`Shift-Spacebar`

The maximized area fill the whole application window.
It contains the Info Editor and the select area.

You can maximize an area with the
:menuselection:`View --&gt; Toggle Maximize Area` menu entry.
To return to normal size use again menu entry,
or :kbd:`RMB` on the editors header and select *Maximize Area* and
*Tiled Area* to return.
In the Info Editor header the *Back to Previous* button on the right of the menus
also returns to tiled areas.

A quicker way to achieve this is to use the shortcuts: :kbd:`Shift-Spacebar`,
:kbd:`Ctrl-Down` or :kbd:`Ctrl-Up` to toggle between maximized and normal areas.

.. note::

The area your mouse is currently hovering over is the one that will be maximized using
the keyboard shortcuts.

Toggle Fullscreen Area
======================

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`View --&gt; Toggle Full Screen`
| Hotkey:   :kbd:`Alt-F10`

The fullscreen area contains only the main region.
The headers visibility can still be toggled with the shortcut.
To exit the fullscreen move the mouse to the top right corner of the area to reveal the return icon or
use the shortcut :kbd:`Alt-F10`.

************
Introduction
************

After starting Blender and closing the :ref:`Splash Screen &lt;splash&gt;`
your Blender window should look something similar to the image below.
Blender's user interface is consistent across all platforms.

.. figure:: /images/interface_default_startup.png
:align: center

The default startup Blender window.

Interface Elements
==================

.. code-block:: none

Window ‣ Screen ‣ Areas ‣ Editors ‣ Regions ‣ (Tabs) ‣ Panels ‣ Controls

The interface can be customized to match specific tasks using
:doc:`Screen Layouts &lt;/interface/window_system/screens&gt;`,
which can then be named and saved for later use. The default screen is described below.

A screen is organized into one or more :doc:`Areas &lt;/interface/window_system/areas&gt;`
with each area containing an *Editor*.

The Default Screen
==================

By default Blender starts up showing the default screen, which is separated into five areas
containing the Editors listed below:

- The Info Editor at the top.
- A large 3D View.
- A Timeline at the bottom.
- An Outliner at the top right.
- A Properties Editor at the bottom right.

.. figure:: /images/interface_introduction_default_screen.png

Blender's default Screen Layout with five Editors.

Info (1), 3D View (2), Outliner (3), Properties (4) and Timeline (5).

Components of an Editor
=======================

In general an editor provides a way to view and
modify your work through a specific part of Blender.
Editors are divided into :doc:`/interface/window_system/regions`.
Regions can have smaller structuring elements like
:doc:`tabs and panels &lt;/interface/window_system/tabs_panels&gt;`
with buttons, controls and widgets placed within them.

.. figure:: /images/interface_introduction_editor.png

The 3D View editor.

Yellow: Main Region, green: Header, blue: Tool Shelf, purple: Operator Panel,
red: Properties Region.

User Interface Principles
=========================

Non Overlapping
The UI is designed to allow you to view all relevant options and tools at a glance
without pushing or dragging editors around.

Non Blocking
Tools and interface options do not block the user from any other parts of Blender.
Blender typically does not use pop-up boxes
(requiring users to fill in data before running an operation).

Non Modal Tools
Tools can be accessed efficiently without taking time to select between different tools.
Many tools use consistent and predictable, mouse and keyboard actions for interaction.

Customization
=============

Blender also makes heavy use of keyboard shortcuts to speed up work.
These can also be customized in the :ref:`Keymap Editor &lt;prefs-input-keymap-editor&gt;`.

.. rubric:: Theme colors

Blender allows for most of its interface color settings to be changed to suit the needs of the user.
If you find that the colors you see on screen do not match those mentioned
in the Manual then it could be that your default theme has been altered.
Creating a new theme or selecting/altering a pre-existing one can be done by selecting the
:doc:`User Preferences &lt;/preferences/index&gt;` editor and clicking on the *Themes* tab.

*******
Regions
*******

An Editor is subdivided into regions.

Main Region
===========

At least one region is always visible.
It is called the main region and is the most prominent part of the editor.

Each editor has a specific purpose, so the main region and
the availability of additional regions are different between editors.
See specific documentation about each editor in the
:doc:`Editors &lt;/editors/index&gt;` chapter.

.. _ui-region-header:

Header
======

A header is a small horizontal strip with a lighter gray background,
which sits either at the top or bottom of the area.
All editors have a header acting as a container for menus and commonly used tools.
:ref:`Menus &lt;ui-header-menu&gt;` and buttons will change with the editor type and
the selected object and mode.

.. figure:: /images/modeling_meshes_introduction_3d-view-header-object-mode.png

The Header of the 3D View editor.

If you move the mouse over an area,
the header of its editor changes to a slightly lighter shade of gray.
This means that it is "focused".
All hotkeys you press will now affect the contents of this editor.
The header can be hidden with :kbd:`Alt-F9`.

Tool Shelf
==========

The *Tool Shelf* by default on the left side contains the tool settings.
:kbd:`T` toggles the visibility of Tool Shelf Region.

Operator Panel
--------------

The Operator panel is a region that is part of the Tool Shelf containing only one panel.
In the 3D View it displays the properties of the :ref:`last operator &lt;ui-redo-last&gt;` executed and
in the File Browser the file import/export options.

Properties Region
=================

The *Properties Region* is by default on the right side.
It contains :ref:`Panels &lt;ui-panels&gt;`
with settings of objects within the editor and the editor itself.
:kbd:`N` toggles the visibility of Properties Region.

Arranging
=========

Scrolling
---------

A region can be scrolled vertically and/or horizontally by dragging it with the :kbd:`MMB`.
If the region has no zoom level, it can be scrolled by using the :kbd:`Wheel`,
while the mouse hovers over it.

Changing the Size and Hiding
----------------------------

Resizing regions works the same way as :doc:`/interface/window_system/areas`
by dragging their border.

To hide a region scale it down to nothing.
A hidden region leaves a little plus sign (see picture).
By :kbd:`LMB` on this, the region will reappear.

The Tool Shelf and Properties region have a shortcut assigned to
toggle between hide and show.

.. list-table:: Hiding and showing the Header.

* - .. figure:: /images/interface-window_system-headers-hide.png

- .. figure:: /images/interface-window_system-headers-show_02.png

Position
--------

To flip a region from one side to the opposite press :kbd:`F5`,
while the Region is under the mouse pointer.

The header can also be flip by :kbd:`RMB` on it and
select the appropriate item from the pop-up menu.
If the header is at the top, the item text will read "Flip to Bottom",
and if the header is at the bottom the item text will read "Flip to Top".

*******
Screens
*******

.. figure:: /images/interface_screen_data-block.png
:align: right

The Screen data-block menu with pop-up.

*Screens* are essentially pre-defined window layouts.
Blender's flexibility with areas lets you create customized working environments for
different tasks such as modeling, animating, and scripting.
It is often useful to quickly switch between different environments within the same file.
See :doc:`area controls &lt;/interface/window_system/areas&gt;` for how to move frame borders,
split and consolidate areas.

The Screen data-block menu, that lets you select the layouts,
is located in the *Info Editors* header.

Controls
========

Screen Layout
A list of available Screen layouts. See `Default Screens`_.
Add ``+``
Click on the *Add* button and a new frame layout will be
created based on your current layout.
Delete ``X``
You can delete the selected screen by using the *Delete* button.

.. hint::

By default, each screen layout 'remembers' the last :doc:`scene &lt;/data_system/scenes/introduction&gt;`
it was used on. Selecting a different screen layout will switch to the layout **and** jump to that scene.

Shortcuts
---------

To cycle between screens use :kbd:`Ctrl-Right` and :kbd:`Ctrl-Left`.

.. note::

On macOS you may need to disable the shortcuts for "Mission Control" in your computer's preferences.
These can be found in :menuselection:`System Preferences --&gt; Keyboard --&gt; Shortcuts`.

Default Screens
---------------

:3D View Full: A full screen 3D View, used to preview your scene.
:Animation: Making actors and other objects move about, change shape or color, etc.
:Compositing: Combining different parts of a scene
(e.g. background, actors, special effects) and filter them (e.g. color correction).
:Default: The default layout used by Blender for new files. Useful for modeling new objects.
:Game Logic: Planning and programming of games within Blender.
:Motion Tracking: Used for motion tracking with the movie clip editor.
:Scripting: Documenting your work and/or writing custom scripts to automate Blender.
:UV Editing: Flattening a projection of an object mesh in 2D to control how a texture maps to the surface.
:Video Editing: Cutting and editing of animation sequences.

Save and Override
=================

The screen layouts are saved in the blend-file.
When you open a file, enabling the *Load UI* in the file browser indicates that Blender should
use the file's screen layouts and overriding the current layout.
See :ref:`Load UI &lt;file-load-ui&gt;`.

A custom set of screen layouts can be saved as a part of the :doc:`/data_system/files/startup_file`.

Additional Layouts
==================

As you become more experienced with Blender, consider adding some other screen layouts to suit
your workflow as this will help increase your productivity. Some examples could include:

:Modeling: Four 3D Views (top, front, side and perspective), Properties editor for Editing.
:Lighting: 3D Views for moving lights, UV/Image editor for displaying Render Result,
Properties editor for rendering and lamp properties and controls.
:Materials: Properties editor for Material settings, 3D View for selecting objects, Outliner,
Library script (if used), Node Editor
(if using :doc:`Node based materials &lt;/render/blender_render/materials/nodes/index&gt;`).
:Painting: UV/Image Editor for texture painting image,
3D View for painting directly on object in UV Face Select mode,
three mini-3D Views down the side that have background
reference pictures set to full strength, Properties editor.

*************
Tabs &amp; Panels
*************

Tabs
====

.. figure:: /images/interface_tabs.png
:align: right

Tools tab (selected), Create, etc.

Tabs are overlapping sections in the user-interface.
The Tabs header can be vertical (Tool Shelf) or
horizontal (Properties Editor, User Preferences).

Vertical tabs can be switched with the :kbd:`Wheel` within the tab header and
:kbd:`Ctrl-Wheel` changes tabs from anywhere in the region.

.. figure:: /images/game-engine_physics_introduction_tab-header.png

Horizontal tab header.

.. container:: lead

.. clear

.. _ui-panels:

Panels
======

.. figure:: /images/interface_panels.png
:align: right

Tool Shelf panels.

Orange: Panel Headers.

The smallest organizational unit in the user interface is a panel.
Panels can be collapsed to hide its contents.
They are used in the *Properties Editor*, but also
for example in the *Tool Shelf* and the *Properties region*.

In the image on the right there are three panels: *Transform*, *Edit* and *History*.
The *Edit* panel is expanded and the other two panels are collapsed.

Collapsing and expanding
------------------------

A triangle on the left of the title shows the expanded (▼) and collapsed (►) state of the panel.

- A click with the :kbd:`LMB` on the panel header expands or collapses it.
- Pressing :kbd:`A` expand/collapses the panel under the mouse pointer.
- A :kbd:`Ctrl-LMB` click on the header of a specific panel will collapse
all other panels and make this the only expanded one.
- Dragging with :kbd:`LMB` over the headers will expand or collapse many at once.

Position
--------

You can change the position of a panel within its region by clicking and
dragging it with the :kbd:`LMB` on the grip widget (\:\:\:\:) in the upper right corner.

Pinning
-------

Often it is desirable to view panels from different tabs at the same time.
This has been solved by making panels pinnable.

A pinned panel remains visible regardless of which tab has been selected.
You can pin a panel by :kbd:`Shift` clicking its header,
or by :kbd:`RMB` clicking on the header and choosing *Pin* in the context menu.

In the image shown to the right,
is an example of the *Mesh Options* pinned in the tools tab.

Zoom
----

The zoom factor of a whole region with panels can be changed by
:kbd:`Ctrl-MMB` clicking and moving the mouse anywhere within that region
or use the :kbd:`NumpadPlus` and :kbd:`NumpadMinus` to zoom in and out the contents.
Pressing :kbd:`Home` (Show All) will reset the zooming at the screen/panel focused by the mouse pointer.

Alignment
---------

The alignment of the panels in the *Properties Editor* can be changed
between vertical and horizontal. To do this click with :kbd:`RMB` somewhere
within the main region of the *Properties Editor* and choose either
*Horizontal* or *Vertical* from the appearing menu. Keep in mind though that
the panels are optimized for vertical alignment.

*************
Curve Display
*************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:     :menuselection:`Properties region --&gt; Curve Display`

.. figure:: /images/modeling_curves_display.png
:align: right

Curve Display Panel.

When in Edit Mode, the Properties region contains options in the
*Curve Display* panel for how curves are displayed in the 3D View.

Handles
Toggles the option to draw the Bézier handles.
Normals
Toggles the display of the curve normals.

Normal Size
Length of the axis that points the direction of the normal.

Draw Curve
==========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Create --&gt; Draw Curve`
| Menu:     :menuselection:`Add --&gt; Draw Curve`
| Hotkey:   :kbd:`Shift-LMB`

The Curve draw tool allows you to freehand draw curves.

Stroke Options
--------------

.. figure:: /images/modeling_curves_editing_draw_curve-stroke-panel.png
:align: right

Curve Stroke panel.

These options can be found in :menuselection:`Tool Shelf --&gt; Options --&gt; Curve Stroke`.

Type
Type of curve to use for drawing.

Poly
Bézier Curve with strait line segments (auto handles).
Bézier
Tolerance
Lower values give a result that is closer to the drawing stroke,
while higher values give more smoothed results.

Method
Refit
Incrementally re-fits the curve (gives best results).
Split
Splits the curve until the tolerance is met (gives better drawing performance).

Detect Corners
Detects corners and uses non-aligned handles for them.

Corner Angle
Any angles above this are considered corners.

Pressure Radius
Min
Minimum radius when the minimum pressure is applied (also the minimum when tapering)
Max
Radius to use when the maximum pressure is applied (or when a tablet is not used).

Projection Depth
Options to control how where/how the curves are drawn.

Cursor
Uses the depth under the cursor to draw curves.

Surface
Used to draw on top of other objects.

Offset
Distance to offset the curve from the surface.
Absolute Offset
Applies a fixed offset (does not scale by the curve radius).
Only First
Only uses the start of the stroke for the depth.

Normal/View
Draws perpendicular to the surface.
Normal/Surface
Draws aligned to the surface.
View
Draws aligned to the viewport.

Draw Options
------------

.. figure:: /images/modeling_curves_editing_draw_draw-curve-panel.png
:align: right

Draw Curve panel.

These option can be found in the :ref:`Redo Last Panel &lt;ui-redo-last&gt;`.

Error
Error distance in object units. This can be seen similar to a subdivision rate for the curve.
Lower values give a result that is closer to the drawing stroke while higher values give more smoothed results.
Fit Method
Refit
Incrementally re-fits the curve (gives best results).
Split
Splits the curve until the tolerance is met (gives better drawing performance).
Corner Angle
Any angles above this are considered corners.
Cyclic
Toggles whether or not the curve is :term:`Cyclic`.
.. _modeling-curves-editing-index:

##########
Editing
##########

.. toctree::
:maxdepth: 2

introduction.rst
draw.rst
.. (todo) spin, split tool; control point: recalc normals, set curve radius = Shrink/Fatten

************
Introduction
************

This page covers the basics of curve editing.

Transform
=========

A Bézier curve can be edited by transforming the locations of both control points and handles.
NURBS curve on the other hand have only control points.

Translation, Rotation, Scale
----------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Transform`
| Menu:     :menuselection:`Curve --&gt; Transform --&gt; Grab/Move, Rotate, Scale, ...`
| Hotkey:   :kbd:`G`, :kbd:`R`, :kbd:`S`

Like other elements in Blender, curve control points and handles can be grabbed/moved :kbd:`G`,
rotated :kbd:`R` or scaled :kbd:`S`
as described in the :doc:`Basic Transformations &lt;/editors/3dview/object/editing/transform/introduction&gt;` section.
When in *Edit Mode*, :doc:`proportional editing
&lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`
is also available for transformation actions.

.. _modeling-curves-transform-panel:

Transform Panel
---------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Properties region --&gt; Transform`

When nothing is selected, the panel is empty.
When more than one vertex is selected, the median values is edited
and "Median" is added in front of the labels.

Control Point, Vertex
The first controls (X, Y, Z) show the coordinates of the selected point or handle (vertex).
In case of a NURBS curve, there is a fourth component available (W),
which defines the weight of the selected control point or the median weight.
Space
The Space radio buttons let you choose if those coordinates are relative to the object origin (local) or
the global origin (global).

Global, Local

Data
^^^^

Weight
ToDo.
Radius
Radius is used for beveling.
Tilt
ToDo.

Tools
-----

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Curve --&gt; Transform`

The *To Sphere*, *Shear*, *Warp* and *Push/Pull* transform tools are described in the
:doc:`Transformations &lt;/modeling/meshes/editing/transform/index&gt;` sections.
The two other tools, *Tilt* and *Shrink/Fatten Radius* are related to
:doc:`Curve Extrusion &lt;/modeling/curves/properties/geometry&gt;`.

Mirror
======

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Curve --&gt; Mirror`
| Hotkey:   :kbd:`Ctrl-M`

The *Mirror* tool is also available, behaving exactly as with
:doc:`mesh vertices &lt;/modeling/meshes/editing/transform/mirror&gt;`.

Snap
====

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Curve --&gt; Snap`
| Hotkey:   :kbd:`Shift-S`

:doc:`Mesh snapping &lt;/editors/3dview/object/editing/transform/control/snap&gt;`
also works with curve components.
Both control points and their handles will be affected by snapping,
except for within itself (other components of the active curve).
Snapping works with 2D curves but points will be constrained to the local XY axes.

.. _modeling-curves-extrude:

Extrude Curve and Move
======================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Modeling: Extrude`
| Menu:     :menuselection:`Curve --&gt; Extrude Curve and Move`
| Hotkey:   :kbd:`E`

Extrudes points by duplicating the selected points, which then can be translated.
If the selection is an end point a new point will be connected to the selected point,
else a new unconnected point is created.

Mode
ToDo.

Duplicate or Extrude to Cursor
==============================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Hotkey:   :kbd:`Ctrl-LMB`

Interactively places new points with :kbd:`Ctrl-LMB` at the cursor position.
With the selection it deals in same manner as the *Extrude Curve and Move* tool.

Add Duplicate
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Curves: Duplicate`
| Menu:     :menuselection:`Curve --&gt; Add Duplicate`
| Hotkey:   :kbd:`Shift-D`

This tool duplicates the selected control points,
along with the curve segments implicitly selected (if any).
If only a handle is selected, the full point will be duplicated too.
The copy is selected and placed in *Grab* mode, so you can move it to another place.

Separate
========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Curve --&gt; Separate`
| Hotkey:   :kbd:`P`

Curve objects that are made of multiple distinct curves can be separated into their own
objects by selecting the desired segments and pressing :kbd:`P`.
Note, if there is only one curve in a Curve object,
*Separate* will create a new Curve object with no control points.

.. _modeling-curves-make-segment:

Make Segment
============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Curve --&gt; Make Segment`
| Hotkey:   :kbd:`F`

Connects two disconnected control points.
The selection must be loose points, or the first/last point of a curve, then press :kbd:`F`.
If the points belong to different curves, these are joined by a segment to become a single curve.

.. figure:: /images/editing_curves_two-curves-joined.png
:width: 600px

Curves before and after joining.

Note that you can only join curves of the same type (i.e. Bézier with Bézier, NURBS with NURBS)
Additionally, you can close a curve by toggling cyclic.

.. _modeling-curves-toggle-cyclic:

Toggle Cyclic
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Curves: Delete`
| Menu:     :menuselection:`Curve --&gt; Toggle Cyclic`
| Hotkey:   :kbd:`Alt-C`

This toggles between an open curve and closed curve (Cyclic).
Only curves with at least one selected control point will be closed/open.
The shape of the closing segment is based on the start and end handles for Bézier curves,
and as usual on adjacent control points for NURBS.
The only time a handle is adjusted after closing is if the handle is an *Auto* one.
Fig. :ref:`fig-curves-editing-open-close` is the same Bézier curve open and closed.

This action only works on the original starting control-point or the last control-point added.
Deleting a segment(s) does not change how the action applies;
it still operates only on the starting and last control-points. This means that
:kbd:`Alt-C` may actually join two curves instead of closing a single curve! Remember
that when a 2D curve is closed, it creates a renderable flat face.

.. _fig-curves-editing-open-close:

.. figure:: /images/modeling_curves_editing_introduction_open-closed-cyclic.png

Open and Closed curves.

Delete
======

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Curves: Delete`
| Menu:     :menuselection:`Curve --&gt; Delete...`
| Hotkey:   :kbd:`X`, :kbd:`Delete`; :kbd:`Ctrl-X`

Options for the *Erase* pop-up menu:

Vertices
This will delete the selected control points, *without* breaking the curve (i.e.
the adjacent points will be directly linked, joined, once the intermediary ones are deleted).
Remember that NURBS order cannot be higher than its number of control points,
so it might decrease when you delete some control point.
Of course, when only one point remains, there is no more visible curve,
and when all points are deleted, the curve itself is deleted.
Segment
Deletes the segment that connects the selected control points and disconnecting them.
Dissolve Vertices :kbd:`Ctrl-X`
Deletes the selected control points, while the remaining segment is fitted to the deleted curve
by adjusting its handles.

.. list-table::

* - .. figure:: /images/editing_curves_delete-selected.png
:width: 320px

Deleting Curve Selected.

- .. figure:: /images/editing_curves_delete-segment.png
:width: 320px

Deleting Curve segments.

Control Points
==============

Tilt
----

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Transform --&gt; Tilt`
| Menu:     :menuselection:`Curve --&gt; Control Points --&gt; Tilt/Clear Tilt`
| Hotkey:   :kbd:`Ctrl-T`, :kbd:`Alt-T`

Tilt :kbd:`Ctrl-T`
Lets you define the tilt of the selected control points.
The tilt will be interpolated from point to point (you can check it with the normals).
The tilt angle is defined interactively first, and then it can be adjusted in the Operator panel *Angle*.
Clear Tilt :kbd:`Alt-T`
Brings the tilt of those selected control points back to 0.

Set Handle Type
---------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Handles:`
| Menu:     :menuselection:`Curve --&gt; Control Points --&gt; Set Handle Type`
| Hotkey:   :kbd:`V`

Handle types are a property of :ref:`Bézier curves &lt;curve-bezier&gt;` and
can be used to alter features of the curve.
For example, switching to *Vector handles* can be used to create curves with sharp corners.
Read the :ref:`Bézier curves &lt;curve-bezier-handle-type&gt;` page for more details.

Toggle Free/Align :kbd:`V-T`
Additionally, the this shortcut can be used to toggle between Free and Aligned handle types.

.. _modeling-curve-weight:

Set Goal Weight
---------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Specials --&gt; Set Goal Weight`

This sets the "goal weight" of selected control points,
which is used when a curve has :doc:`Soft Body &lt;/physics/soft_body/index&gt;` physics,
forcing the curve to "stick" to their original positions, based on the weight.

Smooth
------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Modeling: Smooth`
| Menu:     :menuselection:`Specials --&gt; Smooth`

Curve smoothing is available through the specials menu. For Bézier curves, this smoothing
operation reduces the distance between the selected control point/s and
their neighbors, while keeping the neighbors anchored.
Does not effect control point tangents.

.. figure:: /images/modeling_curves_smoothing_example1.jpg

Original, unsmoothed Curve.

.. figure:: /images/modeling_curves_smoothing_example2.jpg

Entire curve smoothed over 200 times by holding :kbd:`Shift-R` to repeat last step.

.. figure:: /images/modeling_curves_smoothing_example3.jpg

Only three control points in the center smoothed over 200 times.

Hooks
------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Curve --&gt; Control Points --&gt; Hooks`
| Hotkey:   :kbd:`Ctrl-H`

:doc:`Hooks &lt;/modeling/modifiers/deform/hooks&gt;` can be added to control one or more points with other objects.

Segments
========

.. _modeling-curves-subdivision:

Subdivision
-----------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Modeling: Subdivide`
| Menu:     :menuselection:`Curve --&gt; Segments --&gt; Subdivide`

Curve subdivision simply subdivides all selected segments by adding one or
more control points between the selected segments.

Number of Cuts
The number of cuts can be adjusted from the Operator panel.

.. _curve-switch-direction:

Switch Direction
----------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Curves: Switch Direction`
| Menu:     :menuselection:`Curve --&gt; Segments --&gt; Switch Direction`,
:menuselection:`Specials --&gt; Switch Direction`

This tool will "reverse" the direction of any curve with at least one selected element
(i.e. the start point will become the end one, and *vice versa*).
This is mainly useful when using a curve as path, or using the bevel and taper options.

.. _curves-show-hide:

Show/Hide
=========

When in *Edit Mode*, you can hide and reveal elements from the display.
You can only show or hide control points, as segments are always shown,
unless all control points of the connected curve are hidden,
in which case the curve is fully hidden.

See :ref:`object-show-hide` in *Object Mode*.
See also the :doc:`/modeling/curves/curve_display` panel.

.. _curve-convert-type:

Set Spline Type
===============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Curve Tools --&gt; Curves: Set Spline type`

.. figure:: /images/modeling_curves_editing_introduction_set-spline-type.png
:align: right

Set Spline Type button.

You can convert splines in a curve object between Bézier, NURBS, and Poly curves.
Press :kbd:`T` to bring up the Tool Shelf. Clicking on the *Set Spline Type*
button will allow you to select the Spline type (Poly, Bézier or NURBS).

Note, this is not a "smart" conversion, i.e. Blender does not try to keep the same shape,
nor the same number of control points. For example, when converting a NURBS to a Bézier,
each group of three NURBS control points become a unique Bézier one (center point and two handles).

.. seealso::

:ref:`object-convert-to`/from Mesh.

Curve Parenting
===============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Hotkey:   :kbd:`Ctrl-P`

You can make other selected objects :ref:`children &lt;object-parenting&gt;`
of one or three control points :kbd:`Ctrl-P`, as with mesh objects.

To select a mesh (that is in view) while editing a curve, :kbd:`Ctrl-P` click on it.
Select either one or three control points,
then :kbd:`Ctrl-RMB` the object and use :kbd:`Ctrl-P` to make a vertex parent.
Selecting three control points will make the child follow
the median point between the three vertices. An alternative would be to use a
:doc:`Child of Constraint &lt;/rigging/constraints/relationship/child_of&gt;`.
See also the :doc:`Curve Modifier &lt;/modeling/modifiers/deform/curve&gt;`.
.. _modeling-curves-index:

#########
Curves
#########

.. toctree::
:maxdepth: 2

introduction.rst
structure.rst
primitives.rst
selecting.rst
editing/index.rst
properties/index.rst
curve_display.rst

************
Introduction
************

Curves and :doc:`Surfaces &lt;/modeling/surfaces/introduction&gt;` are particular types of Blender Objects.
They are expressed by mathematical functions rather than a series of points.

Blender offers both :ref:`curve-bezier` and :ref:`curve-nurbs`.
Both Bézier curves and NURBS curves and surfaces are defined in terms of a set of "control points"
(or "control vertices") which define a "control polygon".

.. figure:: /images/modeling_curves_introduction_logo.png

Blender logo made from Bézier curves.

Both Bézier and NURBs curves are named after their mathematical definitions, and choosing between them
is often more a matter of how they are computed behind the scenes than how they appear from a modeler's
perspective. Bézier curves are generally more intuitive because they start and end at the
control points that you set,
but NURBs curves are more efficient for the computer to calculate when there are many twists and turns in a curve.

The main advantage to using curves instead of polygonal meshes is that curves are defined by
less data and so can produce results using less memory and storage space at modeling
time. However, this procedural approach to surfaces can increase demands at render time.

Certain modeling techniques, such as
:doc:`extruding a profile along a path &lt;/modeling/curves/properties/geometry&gt;`,
are possible only using curves. On the other hand, when using curves,
vertex-level control is more difficult and if fine control is necessary,
:doc:`mesh editing &lt;/modeling/meshes/editing/introduction&gt;` may be a better modeling option.

Bézier curves are the most commonly used curves for designing letters or logos.

They are also widely used in animation, both as for objects to move along (see constraints below)
and as :doc:`F-Curves &lt;/editors/graph_editor/fcurves/introduction&gt;`
to change the properties of objects as a function of time.

.. seealso:: Modifiers &amp; Constraints

- :doc:`Curve Modifier &lt;/modeling/modifiers/deform/curve&gt;`
- :doc:`Follow Path Constraint &lt;/rigging/constraints/relationship/follow_path&gt;`
- :doc:`Clamp To Constraint &lt;/rigging/constraints/tracking/clamp_to&gt;`

**********
Primitives
**********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Create --&gt; Add Primitive/Curve`
| Menu:     :menuselection:`Add --&gt; Curve`
| Hotkey:   :kbd:`Shift-A`

.. figure:: /images/modeling_curves_introduction_add-curve-menu.png
:align: right

Add Curve menu.

In Object Mode, the *Add Curve* menu, provides five different curve primitives:

Bézier Curve
============

Adds an open 2D Bézier curve with two control points.

Bézier Circle
=============

Adds a closed, circle-shaped 2D Bézier curve (made of four control points).

NURBS Curve
===========

Adds an open 2D :term:`NURBS` curve, with four control points, with *Uniform* knots.

NURBS Circle
============

Adds a closed, circle-shaped 2D :term:`NURBS` curve (made of eight control points).

Path
====

Adds a :term:`NURBS` open 3D curve made of five aligned control points,
with *Endpoint* knots and the *Curve Path* setting enabled.

Draw Curve
==========

A freehand :doc:`draw tool &lt;/modeling/curves/editing/draw&gt;` for curve creation by dragging the mouse.

Common Options
==============

Radius, Align to View, Location, Rotation
See :ref:`Common Object Options &lt;object-common-options&gt;`.

***********
Object Data
***********

The curve properties can be set from the *Object Data* tab
in the *Properties Header* (shown below in blue).

.. figure:: /images/modeling_curves_properties_header.png

Shape
=====

.. figure:: /images/modeling_curves_properties_curves-shape-panel.png

Curves Shape panel.

Dimensions
By default, new curves are set to be 3D, which means that control points can be placed anywhere in 3D space.
Curves can also be set to 2D which constrain the control points to the curve's local XY axis.

2D, 3D

.. _curve-resolution:

Resolution
The *resolution* property defines the number of points that are computed between every pair of control points.
Curves can be made more or less smooth by increasing and decreasing the resolution respectively.
The *Preview U* setting determines the resolution in the 3D View while the *Render U* setting
determines the curve's render resolution. If *Render U* is set to zero (0),
then the *Preview U* setting is used for both the 3D View and render resolution.

.. figure:: /images/modeling_curves_shape-resolution.jpg

Curves with a resolution of 3 (left) and 12 (right).

Twisting
A 3D curve has control points that are not located on the curve's local XY plane.
This gives the curve a twist which can affect the curve normals.
You can alter how the twist of the curve is calculated by choosing from *Minimum,
Tangent* and *Z-Up* options from the select menu.

.. figure:: /images/modeling_curves_shape-twist.jpg

Curves with a twist of minimum (left) and tangent (right).

Fill
Fill determines the way a curve is displayed when it is beveled (see below for details on Beveling).
When set to *Half* (the default) the curve is displayed as half a cylinder.

Fill Deformed
Fills the curve after applying all modification that might deform the curve (i.e. shape keys and modifiers).

.. figure:: /images/modeling_curves_shape-fill.jpg

Curves with a fill of half (left) and full (right).

.. _curve-shape-path-curve-deform:

Path/Curve-Deform
These options are primarily utilized when using a curve as a path or when using the Curve Deform Modifier.
They control how objects use the curve and are dealt with in more detail in the appropriate links below.

Radius
Causes the deformed object to be scaled by the set curve radius.
Stretch
The *Stretch* curve option allows you to let the mesh object stretch, or squeeze, over the entire curve.
Bounds Clamp
ToDo.

.. seealso::

- :doc:`/rigging/constraints/relationship/follow_path`
- :doc:`/modeling/modifiers/deform/curve`

.. _curve-path-animation:

Path Animation
==============

The *Path Animation* settings can be used to determine how child objects move along a certain path.

Frames
The number of frames that are needed to traverse the path,
defining the maximum value for the *Evaluation Time* setting.
Evaluation Time
Parametric position along the length of the curve that object following it should be at
(the position is evaluated by dividing by the *Path Length* value).
By default, it is linked to the global frame number,
but could be keyframed to give more control over the path animation.
Follow
Make the curve path children rotate along the curvature of the path.

.. note::

Deprecated, but still available use.
A more future-proof method is the :doc:`/rigging/constraints/relationship/follow_path`.

Active Spline
=============

.. figure:: /images/modeling_curves_properties_active-spline-panel-curves.png

Curves Active Spline panel.

The *Active Spline* panel becomes available during *Edit Mode*.

Cyclic
Closes the curve.
Resolution
Alters the smoothness of each segment by changing the number of subdivisions.
Interpolation
Tilt
Alters how the tilt of a segment is calculated.
Radius
Alters how the radius of a beveled curve is calculated.
The effects are easier to see after Shrinking/Fattening a control point :kbd:`Alt-S`.
Smooth
Smooths the normals of the curve.

NURBS Curves
------------

.. figure:: /images/modeling_curves_properties_active-spline-panel-nurbs.png

NURBS Active Spline panel.

.. _modeling-curve-knot:

Knots
One of the characteristics of a NURBS object is the *knot vector*. This is a sequence of
numbers used to determine the influence of the control points on the curve.
While you cannot edit the knot vectors directly, you can influence them through the
*Endpoint* and *Bézier* options in the Active Spline panel. Note that the
*Endpoint* and *Bézier* settings only apply to open NURBS curves.

Cyclic
Makes the NURBS curve cyclic.

.. figure:: /images/modeling_curves_nurbs-cyclic.png

A NURBS curve with Cyclic applied.

Bézier
Makes the NURBS curve act like a Bézier curve.
Endpoint
Makes the curve contact the end control points. Cyclic must be disabled for this option to work.

.. figure:: /images/modeling_curves_nurbs-endpoint.png

A NURBS curve with Endpoint enabled.

.. _modeling-curve-order:

Order
The order of the NURBS curve determines the area of influence of the control points over the curve.
Higher order values means that a single control point has a greater
influence over a greater relative proportion of the curve.
The valid range of *Order* values is 2-6 depending on the number of control points present in the curve.

.. figure:: /images/modeling_curves_nurbs-order.png

NURBS curves with orders of 2 (left), 4 (middle) and 6 (right).

********
Geometry
********

.. figure:: /images/modeling_curves_properties_geometry-panel.png

Curves Geometry panel.

Modification
============

Offset
Moves the extrusion parallel to the curve normals.

.. figure:: /images/modeling_curves_editing_extrude_example-6_offset.png
:width: 320px

-1 offset, 0.5 extrusion, 0.25 Bevel Depth, 10 Bevel resolution.

Extrude
Will extrude the curve along both the positive and negative local Z axes.
Turns an one dimensional curve into a two dimensional curve by giving it height.
With a scale is the sum of both directions, perpendicular to the curves normals.

.. list-table::

* - .. figure:: /images/modeling_curves_editing_extrude_example-1_bezier-circle.png
:width: 320px

Bézier Circle 0.0 extrude (Edit Mode).

- .. figure:: /images/modeling_curves_editing_extrude_example-2_extrude.png
:width: 320px

Extruded by 0.5 (Object Mode).

Examples
--------

We have three sub-classes of results, depending on whether the curve is open or closed or 3D:

Open 2D Curve
The extrusion will create a "wall" or "ribbon" following the curve shape. If using a *Bevel Depth*,
the wall becomes a sort of slide or gutter.
If your normals are facing the wrong way you can switch their direction as shown
:ref:`here &lt;curve-switch-direction&gt;`

.. figure:: /images/modeling_curves_editing_extrude_example-8_open-curve.png
:width: 320px

Open 2D Curve with :kbd:`Alt-C`, fill set to none,
zero offset, 0.5 extrusion, 0.25 Bevel Depth, 10 Bevel resolution.

Closed 2D Curve
This is probably the most useful situation, as it will quickly create a volume, with (by default)
two flat and parallel surfaces filling the two sides of the extruded "wall". You can remove one or both of these
faces by choosing the fill mode: both, front, back, or none.

The optional bevel depth will always create a 90 degree bevels here.

.. figure:: /images/modeling_curves_editing_extrude_example-9_closed-curve.png
:width: 320px

Closed 2D Curve, 0.5 extrude, 0.25 Bevel Depth, 10 Bevel resolution, Fill: Both.

3D Curve
Here the fact that the curve is closed or not has no importance --
you will never get a volume with an extruded 3D curve, only a wall or ribbon, like with open 2D curves.

However, there is one more feature with 3D curves: the *Tilt* of the control points (see above).
It will make the ribbon twist around the curve to create a mobius strip, for example.

Bevel
=====

Depth
Changes the size of the bevel.

.. figure:: /images/modeling_curves_geometry-bevel-depth.png

A Curve with different Bevel depths applied.

Resolution
Alters the smoothness of the bevel.

.. figure:: /images/modeling_curves_geometry-bevel-resolution.png

A Curve with different resolutions applied.

Bevel Object
The Bevel Object controls the cross section of the extruded curve.
The Bevel Object can only be another curve both 2D or 3D, and opened or closed.
Editing the handles and control points of the Bevel Object will cause the original Object to change shape.

.. figure:: /images/modeling_curves_geometry-bevel.jpg

A curve with the Bevel Object as a Bézier curve (left) and as a Bézier circle (right).

Bevel Factor
------------

Mapping
Allows to control the relation between bevel factors (number between 0 and 1) and
the rendered start and end point of a beveled spline. Map the bevel factor:

Resolution
To the number of subdivisions of a spline (U resolution).
Segments
To the length of its segments. Mapping to segments treats the subdivisions in each segment of a curve as
if they would have all the same length.
Spline
The length of a spline.
Start, End
These options determine where to start/end the Bevel operation on the curve.
This allows to make a bevelled curve which is not fully covered with a bevel.

Increasing the *Start Bevel Factor* to 0.5 will start beveling the curve 50% of the distance from the start
of the curve (in effect shortening the curve).
Decreasing the *End Bevel Factor* by 0.25 will start beveling the curve 25% of the distance from the end
of the curve (again, shortening the curve).

.. figure:: /images/modeling_curves_geometry-bevel-start-end-factor.jpg

A curve with no Bevel factor applied (left),
with a 50% Start Bevel Factor (middle) and with a 25% End Bevel Factor (right).

Caps
----

Fill Caps
Seals the ends of a beveled curve.

Taper
=====

Taper Object
The taper curve is evaluated along the local X axis,
using the local Y axis for width control. Note also that:
Tapering a curve causes it to get thinner towards one end.
You can also alter the proportions of the Taper throughout the tapered object
by moving/scaling/rotating the control points of the Taper Object.
The Taper Object can only be another curve.
Editing the handles and control points of the Taper Object will cause the original Object to change shape.

.. figure:: /images/modeling_curves_geometry-taper.jpg

A curve before (left) and after (right) a Bézier curve Taper Object was applied.

Map Taper
For curves using a Taper Object and with modifications to the *Start/End Bevel Factor*
the *Map Taper* option will apply the taper to the beveled part of the curve (not the whole curve).

.. figure:: /images/modeling_curves_geometry-map-taper.jpg

A curve without (left) and with (right) Map Taper applied.

Details
-------

- It must be an *open curve*.
- The taper is applied independently to all curves of the extruded object.
- Only the first curve in a *Taper Object* is evaluated, even if you have several separated segments.
- The scaling starts at the first control-point on the left
and moves along the curve to the last control-point on the right.
- Negative scaling, (negative local Y on the taper curve) is possible as well.
However, rendering artifacts may appear.
- Might need to increase the curve resolution to see more detail of the taper
- With closed curves, the taper curve in *Taper Object* acts along the whole curve (perimeter of the object),
not just the length of the object, and varies the extrusion depth. In these cases,
you want the relative height of the *Taper Object*
Taper curve at both ends to be the same, so that the cyclic point
(the place where the endpoint of the curve connects to the beginning) is a smooth transition.

Examples
========

.. TODO: add some "simple" extrusion examples.
TODO: add some "bevel" extrusion with *Radius* examples.

Let us taper a simple curve circle extruded object using a taper curve. Add a curve,
then exit *Edit Mode*. Add another one (a closed one, like a circle); call it "BevelCurve",
and enter its name in the *Bevel Object* field of the first curve
(*Curve* tab). We now have a pipe.
Add a third curve while in *Object Mode* and call it "TaperCurve".
Adjust the left control-point by raising it up about 5 units.

Now return to the Object tab,
and edit the first curve's *Taper Object* field in the Geometry panel to reference the new taper curve
which we called "TaperCurve".
When you hit enter the taper curve is applied immediately,
with the results shown in Fig. :ref:`fig-curves-extrude-taber-curve`.

.. list-table::

* - .. _fig-curves-extrude-taber-curve:

.. figure:: /images/modeling_curves_editing_extrude_example-10_bevel-object.png
:width: 320px

Circle curve set as Bevel Object.

- .. figure:: /images/modeling_curves_editing_extrude_example-11_taper-object.png
:width: 320px

Taper extruded curve.

You can see the *taper curve* being applied to the *extruded object*.
Notice how the pipe's volume shrinks to nothing as the taper curve goes from left to right.
If the taper curve went below the local Y axis the pipe's inside would become the outside,
which would lead to rendering artifacts.
Of course as an artist that may be what you are looking for!

.. _fig-curves-extrude-taber1:

.. figure:: /images/modeling_curves_editing_extrude_example-12_taper-curve-closer.png

Taper example 1.

In Fig. :ref:`fig-curves-extrude-taber1`
you can clearly see the effect the left taper curve has on the right curve object. Here the
left taper curve is closer to the object origin and that results in a smaller curve object to
the right.

.. _fig-curves-extrude-taber2:

.. figure:: /images/modeling_curves_editing_extrude_example-13_taper-curve-away.png

Taper example 2.

In Fig. :ref:`fig-curves-extrude-taber2` a control point in the taper curve to the left is moved away from the
origin and that gives a wider result to the curve object on the right.

.. _fig-curves-extrude-taber3:

.. figure:: /images/modeling_curves_editing_extrude_example-14_taper-curve-irregular.png

Taper example 3.

In Fig. :ref:`fig-curves-extrude-taber3` we see the use of a more irregular taper curve applied to a curve circle.

.. figure:: /images/modeling_curves_editing_extrude_example-15_bevel-curve-tilt.png

Bevel extrusion with *Tilt* example.

##############
Properties
##############

.. toctree::
:maxdepth: 2

introduction.rst
data.rst
geometry.rst
.. (todo) generalize from extrude

************
Introduction
************

Attributes
==========

Weight
------

ToDo.

Radius
------

The Radius allows you to directly control the width of the extrusion along the "spinal" curve.
The *Radius* of the points is set using the *Shrink/Fatten Radius* transform tool :kbd:`Alt-S`,
the :menuselection:`Curve --&gt; Transform --&gt; Shrink/Fatten Radius`,
or the :menuselection:`Properties region --&gt; Transform --&gt; Radius`.

.. figure:: /images/modeling_curves_editing_extrude_example-7_radius.png
:width: 320px

One control point radius set to zero.

.. tip::

Remember, these curves can be converted into meshes with :kbd:`Alt-C` in Object Mode

Tilt
----

This setting controls how the normals (visualization: arrows)
twist around each control point -- so it is only relevant with 3D curves!
You set it using the *Tilt* transform tool in the Tool Shelf,
the :menuselection:`Properties region --&gt; Transform --&gt; Tilt`,
:menuselection:`Curve --&gt; Transform --&gt; Tilt`.

You can also reset it to its default value (i.e. perpendicular to the original curve plane)
with :kbd:`Alt-T`, :menuselection:`Curve --&gt; Control Points --&gt; Clear Tilt`.
With NURBS, the tilt is always smoothly interpolated.
However, with Bézier, you can choose the interpolation algorithm between
Linear, Ease, B-Spline, and Cardinal, in the
:menuselection:`Properties Editor --&gt; Object Data --&gt; Active Spline --&gt; Tilt`.

.. figure:: /images/modeling_curves_editing_extrude_example-3_mean-tilt.png
:width: 320px

30 degree Mean Tilt of all control points.
..    TODO/Review: {{review|im = add images}}.

*********
Selecting
*********

.. figure:: /images/modeling_curves_selecting.png
:align: right

Select Menu.

Curve selection in *Edit Mode* has fewer options than with meshes.
Mainly this is, because there is only one selectable element type, the control points
(no select mode needed here...). These points are a bit more complex than simple vertices,
however, especially for Béziers, as there is the central vertex, and its two handles...

The basic tools are the same as with :doc:`meshes &lt;/modeling/meshes/selecting/introduction&gt;`,
so you can select a simple control point with a :kbd:`RMB`,
add to current selection with :kbd:`Shift-RMB`, :kbd:`B` border-select, and so on.

One word about the Bézier control points: when you select the main central vertex,
the two handles are automatically selected too, so you can grab it as a whole,
without creating an angle in the curve. However, when you select a handle,
only this vertex is selected, allowing you to modify this control vector...

Note that unlike mesh edges you cannot directly select a segment. Instead,
select all of the control points that make up the segment you want to edit.

Select Menu
===========

With curves, all "advanced" selection options are regrouped in the *Select* menu of
the 3D Views header. Let us detail them:

- Random...
- Inverse
- Select/Deselect All

Border/ Circle Select
All these options have the same meaning and behavior as in
:doc:`Object Mode &lt;/editors/3dview/object/selecting/tools&gt;`
(and the specifics of *Border Select* in *Edit Mode* have already been discussed
:doc:`here &lt;/modeling/meshes/selecting/introduction&gt;`).

Select Linked
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Select Linked`
| Hotkey:  :kbd:`L`, :kbd:`Ctrl-L`, :kbd:`Shift-L`

:kbd:`L` (or :kbd:`Ctrl-L` for all) will add to the selection the cursor's nearest control point,
and all the linked ones, i.e. all points belonging to the same curve. Note that for Bézier,
using :kbd:`L` with a handle selected will select the whole control point and all the linked ones.

Select Similar
==============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Select Similar`
| Hotkey:  :kbd:`Shift-G`

ToDo.

Type
ToDo.
Compare
ToDo.
Threshold
ToDo.

Shortest Path
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Operator Search --&gt; Pick Shortest Path`
| Hotkey:  :kbd:`Ctrl`

ToDo.

Select/Deselect First/Last
==========================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Select/Deselect First`, :menuselection:`Select --&gt; Select/Deselect Last`
| Hotkey:   None

These operators will toggle the selection of the first or last control point(s) of the curve(s)
in the object. This is useful to quickly find the start of a curve
(e.g. when using it as path...).

Select Next/Previous
====================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Select Next`, :menuselection:`Select --&gt; Select Previous`
| Hotkey:   None

These operators will select the next or previous control point(s),
based on the current selection
(i.e. the control points following or preceding the selected ones along the curve).
In case of a cyclic curve, the first and last points are not considered as neighbors.

Select More/Less
================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; More/Less`
| Hotkey:   :kbd:`Ctrl-NumpadPlus`, :kbd:`Ctrl-NumpadMinus`

Their purpose, based on the currently selected control points, is to reduce or enlarge this selection.

More
For each selected control point, select *all* its linked points (i.e. one or two...).
Less
For each selected control point, if *all* points linked to this point are selected, keep this one selected.
Otherwise, de-select it.

This implies two points:

- First, when *all* control points of a curve are selected, nothing will happen (as for *Less*,
all linked points are always selected, and of course, *More* cannot add any).
Conversely, the same goes when no control points are selected.
- Second, these tools will never "go outside" of a curve
(they will never "jump" to another curve in the same object).

*********
Structure
*********

.. _curve-bezier:

Bézier Curves
=============

The main elements used in editing Bézier curves are the control points and handles.
A segment (the actual curve) is found between two control points.
The handles define the curvature of the segment.

In the image below,
the control points can be found in the middle of the pink line,
while the handles comprise the extensions from the control point.
The arrows visualize the normals of the curve, which indicate i.a.
the direction and the tilt.

.. figure:: /images/modeling_curves_control-points-handles.png

Bézier Curve in Edit Mode.

.. _curve-bezier-handle-type:

Handle Types
------------

There are four Bézier curve handle types.
They can be accessed by pressing :kbd:`V` and selecting from the list that appears,
or by pressing the appropriate hotkey combination.

.. figure:: /images/modeling_curves_bezier_handle-types.png
:align: right

Bézier Curve Handle Types.

.. _curve-handle-type-auto:

Automatic :kbd:`V-A`
This handle has a completely automatic length and direction
which is set by Blender to ensure the smoothest result.
These handles convert to *Aligned* handles when moved. (Yellow handles.)
Vector :kbd:`V-V`
Both parts of a handle always point to the previous handle or the next handle which allows
you to create curves or sections thereof made of straight lines or with sharp corners.
Vector handles convert to *Free* handles when moved. (Green handles.)
Aligned :kbd:`V-L`
These handles always lie in a straight line,
and give a continuous curve without sharp angles. (Purple handles.)
Free :kbd:`V-F`
The handles are independent of each other. (Black handles.)

.. _curve-nurbs:

NURBS
=====

N.U.R.B.S. is the abbreviation of Non-Uniform Rational B-Splines.
One of the major differences between Bézier objects and NURBS objects is that Bézier curves
are approximations. For example, a Bézier circle is an *approximation* of a circle,
whereas a NURBS circle is an *exact* circle.
NURBS theory can be a *very* complicated topic. For an introduction,
please consult the `Wikipedia page. &lt;https://en.wikipedia.org/wiki/NURBS&gt;`__.
.. (todo) Needs more detailed use cases.

*******
Empties
*******

The "Empty" is a single coordinate point with no additional geometry.
Because an Empty has no volume and surface, it cannot be rendered.
Still it can be used as a handle for many purposes.

Editing
=======

An Empty can only be edited in *Object Mode*, which includes its transformation and parenting properties.

Apply Scale :kbd:`Ctrl-A`
While Empties don't exactly have any object data attached to them which can be used for supporting
"true" apply scale (i.e. with non-uniform scaling), they do have a draw size value which controls how
large the empties are drawn (before scaling). This works by taking the scale factor on the most-scaled axis,
and combines this with the existing empty draw size to maintain the correct dimensions on that axis.

Properties
==========

.. _object-empty-display:

.. figure:: /images/modeling_empties_draw-types.png
:align: right

Empty Draw Types.

Display
Plain Axes
Draws as six lines, initially with one pointing in each of the +X, -X, +Y, -Y, +Z, and -Z axis directions.
Arrows
Draws as arrows, initially pointing in the positive X, Y, and Z axis directions, each with a label.
Single Arrow
Draws as a single arrow, initially pointing in the +Z axis direction.
Circle
Draws as a circle initially in the XZ plane.
Cube
Draws as a cube, initially aligned to the XYZ axes.
Sphere
Draws as an implied sphere defined by three circles.
Initially, the circles are aligned, one each, to the X, Y, and Z axes.
Cone
Draws as a cone, initially pointing in the +Y axis direction.
Image
Empties can display images. This can be used to create reference images,
including blueprints or character sheets to model from, instead of using background images.
The image is displayed regardless of the 3D display mode.
The settings are the same as in
:doc:`Background Image Settings &lt;/editors/3dview/properties/background_images&gt;`

.. note::

While alpha-images can be used, there is a known limitation with object draw order,
where alphas will not always draw on top of other objects when unselected.

Size
Controls the size of the empties visualization. This does not change its scale, but functions as an offset.

Usage
=====

Empties can serve as transform handles. Some examples of ways to use them include:

.. rubric:: Parent object for a group of objects

An Empty can be parented to any number of other objects.
This gives the user the ability to control a group of objects easily, and without affecting a render.

.. rubric:: Target for constraints

An empty can also be used as a target for normal, or bone constraints.
This gives the user far more control; for instance,
a rig can easily be set up to enable a camera to point towards an empty using the *Track to* constraint.

.. rubric:: Array offset

An empty can be used to offset an Array Modifier,
meaning complex deformations can be achieved by only moving a single object.

.. list-table::

* - .. figure:: /images/modeling_modifiers_generate_array_example-fractal-1.jpg
:width: 200px

An example of an empty being used to control an array.

- .. figure:: /images/modeling_empties_example-track-to-simple.png
:width: 200px

An example of an empty being used to control the track to constraint.

.. rubric:: Other common uses:

- Placeholders
- Rigging controls
- DOF distances
- Reference Images
.. _modeling-index:

###########
Modeling
###########

.. toctree::
:maxdepth: 2

introduction.rst
meshes/index.rst
curves/index.rst
surfaces/index.rst
metas/index.rst
texts/index.rst
empties.rst
modifiers/index.rst

************
Introduction
************

The creation of a 3D scene needs at least three key components: Models, Materials and Lights.
In this part, the first of these is covered, that being modeling.
Modeling is simply the art and science of creating a surface that either mimics the shape
of a real-world object or expresses your imagination of abstract objects.

Modeling can take many forms in Blender depending on the type of
:ref:`object &lt;objects-types&gt;` you are trying to model.
Some objects are not able to be modeled, these being:

- Speakers
- Cameras
- Lamps

Modes
=====

Depending on the type of object you are trying to model, there are different types
of modeling :doc:`mode &lt;/editors/3dview/modes&gt;`.
Because modes are not specific to modeling they are covered in different parts of the manual.

Edit Mode
---------

Edit mode is the main mode that modeling takes place.
Edit mode is used to edit the following types of objects:

- Meshes
- Curves
- Surfaces
- Metaballs
- Text objects
- Lattice

Because each of these are different types of object they have different types of transforms
and therefore have different set of tool. Because of this each has its own section described below.

:doc:`Mesh Modeling &lt;/modeling/meshes/index&gt;`
Typically begins with a :doc:`Mesh Primitive &lt;/modeling/meshes/primitives&gt;`
shape (e.g. circle, cube, cylinder...).
:doc:`Curve Modeling &lt;/modeling/curves/index&gt;`
Uses control points to define the shape of the curve.
:doc:`Surface Modeling &lt;/modeling/surfaces/index&gt;`
Similar to curve modeling,
but instead of being limited to simple linear paths,
they allow the creation of three dimensional surfaces, potentially with volume.
:doc:`Metaball Modeling &lt;/modeling/metas/index&gt;`
Begins similarly to mesh modeling (see above), with a base shape like a cube or sphere,
but instead of extruding these base shapes, these objects are clumped together to form a larger object.
In order to accomplish this, the metaballs have a liquid-like quality, when two or more are brought
together, they merge by smoothly rounding out the point of connection, appearing as one unified object.

This can also be a quick way to get started with a rough shape which can be converted to a mesh later.
:doc:`Text Modeling &lt;/modeling/texts/index&gt;`
Text modeling is an easy way to create logos and to simply add text to a scene.

:doc:`Modifiers &lt;/modeling/modifiers/introduction&gt;`
Modifiers are automatic operations that affect an object in a non-destructive way.
With modifiers, you can perform many effects automatically that would otherwise be tedious to do manually.

***************
Adding Geometry
***************

In Blender, for modeling, you have several ways of adding mesh elements.

Duplicate or Extrude to Cursor
==============================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Hotkey:   :kbd:`Ctrl-LMB`

Interactively places new vertices with :kbd:`Ctrl-LMB` at the cursor position.

Creating Vertices
-----------------

The most basic element, a vertex, can be added with a left button mouse click while pressing :kbd:`Ctrl`
when no other vertices are selected, or :kbd:`Ctrl-LMB`.
Because the camera space (computer screen) is two-dimensional,
Blender cannot determine all three vertex coordinates from a single mouse click,
so the new vertex is placed at the depth of the 3D cursor.

To create interconnected vertices, you can add a vertex and continuously make subsequent :kbd:`Ctrl-LMB`
operations with the last one vertex selected.
This will link the last selected vertex with the vertex created at the mouse position with an edge
(See Fig. :ref:`fig-mesh-basics-add-one`),
and will continuously connect them creating vertices if you continue repeating this operation.
(see Fig. 3 Creating simple connected vertices with :kbd:`Ctrl-LMB`).

.. _fig-mesh-basics-add-one:

.. figure:: /images/modeling_meshes_editing_basics_adding_vertex.png

Adding vertices one by one.

Creating Faces
--------------

.. figure:: /images/modeling_meshes_editing_basics_adding_quad.png

Quad from an Edge with source automatically rotated.

If you have two vertices selected and already connected with an edge, left-click while pressing :kbd:`Ctrl-LMB`
will create a planar face, also known as a quad. Blender will follow your mouse cursor
and will use the planar view from your viewport to create those quads.

For :kbd:`Ctrl-LMB`, Blender will automatically rotate the last selected Edge (the source)
for the subsequent operations if you have at least one face created, dividing the angles created between
the newly-created edge and the last two edges, performing a smooth angle between them. Blender will calculate
this angle using the last positive and negative position of the last X and Y coordinates
and the last connected unselected edge. If this angle exceeds a negative limit (following a quadrant rule)
between the recently created edge and the last two, Blender will wrap the faces.
But if you do not want Blender rotating and smoothing edges automatically when extruding from :kbd:`Ctrl-LMB`,
you can also inhibit Blender from rotating sources using the shortcut :kbd:`Ctrl-Shift-LMB`.
In this case, Blender will not rotate the source dividing the angle between those edges when creating a face.

For both cases, Blender will inform the user about the source rotation during the creation process.
If you look at the Bottom of the Mesh Tools Panel, if you press :kbd:`Ctrl-LMB`,
you will see that the Rotate Source is automatically checked and if :kbd:`Ctrl-Shift-LMB` is used,
it will be automatically unchecked. Examples:

- Creating Faces with shortcut :kbd:`Ctrl-LMB`, (see Fig. - Faces created with source automatically rotated)
- Creating Faces with shortcut :kbd:`Ctrl-Shift-LMB`, (see Fig. Faces created with no source rotation)

If you have three or more vertices selected, and left click with mouse while pressing :kbd:`Ctrl-LMB`,
you will also create planar faces, but along the vertices selected, following the direction of the cursor.
This operation is similar to an extrude operation,
which is explained in the :doc:`Extrude &lt;/modeling/meshes/editing/duplicating/extrude&gt;` page.

.. tip::

When adding Objects with :kbd:`Ctrl-LMB`, The extrusions of the selected elements,
being vertices, edges and faces with the :kbd:`Ctrl-LMB`, is viewport dependent.
This means, once you change your viewport, for example, from top to left, bottom or right,
the extrusion direction will also follow your viewport and align your extrusions with your planar view.

.. seealso::

:doc:`Duplicate tools &lt;/modeling/meshes/editing/duplicating/index&gt;`
..    TODO/Review: {{review|}}.

**************
Make Edge/Face
**************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Make Face/Edge`
| Hotkey:   :kbd:`F`

This is a context-sensitive tool which creates geometry by filling in the selection.
When only two vertices are selected it will create an edge, otherwise it will create faces.

The typical use case is to select vertices and press :kbd:`F`,
however, Blender also supports creating faces from different selections to help quickly build
up geometry.

Methods
=======

The following methods are used automatically depending on the context.

Isolated vertices
------------------

.. list-table::

* - .. figure:: /images/bmesh_make_face_verts_simple_before.png
:width: 200px

Before.

- .. figure:: /images/bmesh_make_face_verts_simple_after.png
:width: 200px

After.

Isolated edges
--------------

.. list-table::

* - .. figure:: /images/bmesh_make_face_edges_simple_before.png
:width: 200px

Before.

- .. figure:: /images/bmesh_make_face_edges_simple_after.png
:width: 200px

After.

N-gon from edges
----------------

When there are many edges Blender will make an n-gon,
note that this does not support holes, to support holes you need to use the
:ref:`modeling-meshes-editing-fill` Faces tool.

.. list-table::

* - .. figure:: /images/bmesh_make_face_edges_ngon_before.png
:width: 200px

Before.

- .. figure:: /images/bmesh_make_face_edges_ngon_simple_after.png
:width: 200px

After.

Mixed vertices/edges
--------------------

Existing edges are used to make the face as well as an extra vertex.

.. list-table::

* - .. figure:: /images/bmesh_make_face_mix_simple_before.png
:width: 200px

Before.

- .. figure:: /images/bmesh_make_face_mix_simple_after.png
:width: 200px

After.

Edge-Net
--------

Sometimes you may have many connected edges without interior faces.

.. list-table::

* - .. figure:: /images/bmesh_make_face_net_before.png
:width: 200px

Before.

- .. figure:: /images/bmesh_make_face_net_after.png
:width: 200px

After.

Point Cloud
------------

When there are many isolated vertices,
Blender will calculate the edges for an n-gon.

.. list-table::

* - .. figure:: /images/bmesh_make_face_cloud_before.png
:width: 200px

Before.

- .. figure:: /images/bmesh_make_face_cloud_after.png
:width: 200px

After.

Single Vertex Selection
-----------------------

With a single vertex selected on a boundary,
the face will be created along the boundary,
this saves manually selecting the other two vertices.
Notice this tool can run multiple times to continue creating faces.

.. figure:: /images/mesh_face_create_boundary.png

.. seealso::

For other ways to create faces see:

- :ref:`Fill &lt;modeling-meshes-editing-fill&gt;`
- :ref:`Grid Fill &lt;modeling-meshes-editing-grid-fill&gt;`
- :ref:`Bridge Edge Loops &lt;modeling-meshes-editing-bridge-edge-loops&gt;`

***********************
Deleting and Dissolving
***********************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Remove: Delete`
| Menu:     :menuselection:`Mesh --&gt; Delete`

These tools can be used to remove components.

Delete
======

.. admonition:: Reference
:class: refbox

| Hotkey:   :kbd:`X`, :kbd:`Delete`

Deletes selected vertices, edges, or faces. This operation can also be limited to:

Vertices
Delete all vertices in current selection, removing any faces or edges they are connected to.
Edges
Deletes any edges in the current selection. Removes any faces that the edge shares with it.
Faces
Removes any faces in current selection.
Only Edges &amp; Faces
Limits the operation to only selected edges and adjacent faces.
Only Faces
Removes faces, but edges within face selection are retained.

Dissolve &amp; Limited Dissolve
===========================

Dissolve operations are also accessed from the delete menu.
Dissolve will remove the geometry and fill in the surrounding geometry.
Instead of removing the geometry, which may leave holes that you have to fill in again,

Dissolve
--------

.. admonition:: Reference
:class: refbox

| Hotkey:   :kbd:`Ctrl-X`

Removes selected geometry, but without creating holes, effectively turning the selection into a single n-gon.
Dissolve works slightly different based on if you have edges, faces or vertices selected.
You can add detail where you need it, or quickly remove it where you do not.

Dissolve Vertices
ToDo.
Face Split
When dissolving vertices into surrounding faces, you can often end up with very large, uneven n-gons.
The face split option limits dissolve to only use the corners of the faces connected to the vertex.

.. figure:: /images/bmesh_dissolve_face_split.png
:width: 500px

Dissolve Face Split option.

Left: the input, middle: regular dissolve, right: Face Split enabled.
Tear Boundaries
ToDo.

Examples
^^^^^^^^

.. figure:: /images/modeling_meshes_editing_basics_delete_dissolve-examples.png

\1) Original mesh 2) Face Split: Off, Tear Boundaries: Off 3) Face Split: On, Tear Boundaries: Off
\4) Face Split: On/Off, Tear Boundaries: On

Limited Dissolve
----------------

Limits the dissolve on selected vertices and/or edges *not* touching a hole.

.. figure:: /images/bmesh_limited-dissolve.jpg
:width: 400px

Example showing the how Limited Dissolve can be used.

Max Angle
Reduces detail on planar faces and linear edges with an adjustable angle threshold.
All Boundaries
ToDo.
Delimit
ToDo.

Edge Collapse
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Delete --&gt; Edge Collapse`
| Hotkey:   :kbd:`Alt-M`, :menuselection:`Collapse`

Merges each edge into single vertices.
This is useful for taking a ring of edges and collapsing it,
removing the face loop it ran through.

.. list-table::

* - .. figure:: /images/collapse1.png
:width: 320px

Selected Edge Ring.

- .. figure:: /images/collapse2.png
:width: 320px

Edge Ring Collapsed.

Edge Loop
=========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Vertex or Edge select modes)
| Menu:     :menuselection:`Mesh --&gt; Delete --&gt; Edge Loop`
| Hotkey:   :kbd:`X` or :kbd:`Delete`, :menuselection:`Edge Loop`

*Edge Loop* allows you to delete a selected edge loop if it is between two other edge loops.
This will create one face-loop where two previously existed.

.. note::

The *Edge Loop* option is very different to the *Edges* option,
even if you use it on edges that look like an edge loop.
Deleting an edge loop merges the surrounding faces together to preserve the surface of the mesh.
By deleting a chain of edges, the edges are removed, deleting the surrounding faces as well.
This will leave holes in the mesh where the faces once were.

Example
-------

The selected edge loop on the UV Sphere has been deleted and the faces have been merged with
the surrounding edges. If the edges had been deleted by choosing *Edges* from the
(*Erase* menu)
there would be an empty band of deleted faces all the way around the sphere instead.

.. list-table::

* - .. figure:: /images/deleteedgeloop1.png
:width: 320px

Selected Edge Loop.

- .. figure:: /images/deleteedgeloop2.png
:width: 320px

Edge Loop Deleted.

.. seealso::

- :ref:`Vertex merging &lt;vertex-merging&gt;`.
- :ref:`mesh-faces-tristoquads`.
- :ref:`mesh-unsubdivide`.

#########
Basics
#########

.. toctree::
:maxdepth: 2

translation_rotation_scale.rst
adding.rst
deleting.rst
creating_faces_and_edges.rst
symmetry.rst

********
Symmetry
********

Snap to Symmetry
================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Snap to Symmetry`

The Snap to Symmetry tool lets you snap a meshes vertices to their mirrored neighbors.

Useful when dealing with meshes which are mostly symmetrical,
but have vertices which have been moved enough that Blender
does not detect then as mirrored (when x-mirror option is enable for example).

This can be caused by accident when editing without x-mirror enabled. Sometimes models
imported from other applications are asymmetrical enough that mirror fails too.

Direction
Specify the axis and direction to snap. Can be any of the three axes,
and either positive to negative, or negative to positive.
Threshold
Specify the search radius to use when finding matching vertices.
Factor
Support for blending mirrored locations from one side to the other (0.5 is an equal mix of both).
Center
Snap vertices in the center axis to zero.

.. list-table::

* - .. figure:: /images/mesh_snap_to_symmetry.png
:width: 320px

Before Snap to Symmetry.

- .. figure:: /images/mesh_snap_to_symmetry_after.png
:width: 320px

After Snap to Symmetry.

Symmetrize
==========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Symmetrize`

The *Symmetrize* tool is a quick way to make a mesh symmetrical.
*Symmetrize* works by cutting the mesh at the pivot point of the object,
and mirroring over the geometry in the specified axis, and merges the two halves together
(if they are connected). Also the mesh data is copied from one side to the other:
e.g. UVs, vertex colors, vertex weights.

Direction
Specify the axis and direction of the effect. Can be any of the three axes,
and either positive to negative, or negative to positive.
Threshold
ToDo.

.. list-table::

* - .. figure:: /images/symmetrize1.png
:width: 320px

Mesh before Symmetrize.

- .. figure:: /images/symmetrize2.png
:width: 320px

Mesh after Symmetrize.

.. seealso::

See :doc:`Mirror &lt;/modeling/meshes/editing/transform/mirror&gt;`
for information on mirroring, which allows you to flip geometry across an axis.
..    TODO/Review: {{review|}}.

****************************
Translation, Rotation, Scale
****************************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Transform`
| Menu:     :menuselection:`Mesh --&gt; Transform --&gt; Grab/Move, Rotate, Scale, ...`
| Hotkey:   :kbd:`G`, :kbd:`R`, :kbd:`S`

Once you have a selection of one or more elements, you can grab/move :kbd:`G`,
rotate :kbd:`R` or scale :kbd:`S` them, like many other things in Blender,
as described in the :doc:`Manipulation in 3D Space &lt;/editors/3dview/object/editing/transform/introduction&gt;` section.

To move, rotate and scale selected components, either use the *Translate*, *Rotate*, and *Scale* buttons,
the :doc:`transform manipulators &lt;/editors/3dview/object/editing/transform/control/manipulators&gt;`,
or the shortcuts:

:kbd:`G`, :kbd:`R`, and :kbd:`S` respectively.
After moving a selection, the options in the Tool Shelf allow you to fine-tune your changes,
limit the effect to certain axes, turn proportional editing on and off, etc.

Of course, when you move an element of a given type (e.g. an edge),
you also modify the implicitly related elements of other kinds (e.g. vertices and faces).

Pressing :kbd:`G` twice enters either *Edge Slide* or *Vertex Slide* tool depending on the selection.

You also have in *Edit Mode* an extra option when using these basic manipulations:
the :doc:`proportional editing &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`.

Transform Panel
===============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Properties region --&gt; Transform`

When nothing is selected, the panel is empty.
When more than one vertex is selected, the median values is edited
and "Median" is added in front of the labels.

Vertex
The first controls (X, Y, Z) show the coordinates of the selected vertex or the median point.
Space
The Space radio buttons let you choose if those coordinates are relative to the object origin (local) or
the global origin (global).

Global, Local

Vertex Data
-----------

Bevel Weight
ToDo.

Edge Data
---------

When an edge is selected, the following options are available. more buttons appear:

Bevel Weight
See :ref:`Edge bevel weight &lt;modeling-edges-bevel-weight&gt;`.
Crease
The :ref:`crease &lt;modeling-edges-crease-subdivision&gt;` value of the edge.

********
Clean up
********

These tools are to help cleanup degenerate geometry and fill in missing areas of a mesh.

Decimate Geometry
=================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Clean up --&gt; Decimate Geometry`

The Decimate Geometry tool allows you to reduce the vertex/face count of a mesh with minimal shape changes.

Ratio
Ratio of triangles to reduce to.
Vertex Group
Use the active vertex group as an influence.

Weight
Strength of the vertex group.
Invert
Inverts the vertex group.
Symmetry
Maintain symmetry on either the *X*, *Y*, or *Z* axis.

.. seealso::

This tool works similar to the :doc:`Decimate Modifier &lt;/modeling/modifiers/generate/decimate&gt;`.

Fill Holes
==========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Clean up --&gt; Fill Holes`

This tool is can take a large selection and detect the holes in the mesh, filling them in.

This is different from the face creation operator in three important respects:

- Holes are detected, so there is no need to manually find and select the edges around the holes.
- Holes can have a limit for the number of sides (so only quads or tris are filled in for example).
- Mesh data is copied from surrounding geometry (UVs, vertex-colors, multi-res, all layers),
since manually creating this data is very time consuming.

Make Planar Faces
======================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Clean up --&gt; Make Planar Faces`

ToDo

Split Non-Planar Faces
======================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Clean up --&gt; Split Non-Planar Faces`

This tool avoids ambiguous areas of geometry by splitting non-flat faces when they are bent
beyond a given limit.

Split Concave Faces
======================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Clean up --&gt; Split Concave Faces`

ToDo

Delete Loose Geometry
=====================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Clean up --&gt; Delete Loose`

This tool removes disconnected vertices and edges (optionally faces).

Degenerate Dissolve
===================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Clean up --&gt; Degenerate Dissolve`

This tool collapses / removes geometry which you typically will not want.

- Edges with no length.
- Faces with no areas (faces on a point or thin faces).
- Face corners with no area.

*************
Data Transfer
*************

The *Data Transfer* tool transfers several types of data from one mesh to another.
Data types include vertex groups, UV maps, vertex colors, custom normals...

Transfer works by generating a mapping between source mesh’s items (vertices, edges, etc.)
and destination ones, either on an one-to-one basis, or mapping several source items
to a single destination one by interpolated mapping.

Data
====

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Edit --&gt; Data`
| Hotkey:   :kbd:`Shift-Ctrl-T`

Transfers layout of data layer(s) from active to selected meshes.

Freeze Operator
Prevent changes to settings to re-run the operator.
This is useful if you are editing several settings at once with heavy geometry
Data Type
Which data to transfer.

.. figure:: /images/modeling_meshes_editing_data-transfer.png

Data types.

Create Data
Add data layers on destination meshes if needed.
Vertex Mapping
Method used to map source vertices to destination ones.
Because the options change depending on the *Data Type*
options are explained in `Vertex Mapping`_ below.

Vertex Mapping
--------------

.. ToDo sub headlines

Topology
The simplest option, expects both meshes to have identical number of items, and match them by order (indices).
Useful e.g. between meshes that were identical copies, and got deformed differently.

One-To-One Mappings
Those always select only one source item for each destination one, often based on shortest distance.

Vertices
Nearest Vertex
Uses source’s nearest vertex.

Nearest Edge Vertex
Uses source’s nearest vertex of source’s nearest edge.

Nearest Face Vertex
Uses source’s nearest vertex of source’s nearest face.

Edges
Nearest Vertices
Uses source’s edge which vertices are nearest from destination edge’s vertices.

Nearest Edge
Uses source’s nearest edge (using edge’s midpoints).
Nearest Face Edge
Uses source’s nearest edge of source’s nearest face (using edge’s midpoints).
Face Corners
A face corner is not a real item by itself, it’s some kind of split vertex attached to a specific face.
Hence both vertex (location) and face (normal, ...) aspects are used to match them together.

Nearest Corner and Best Matching Normal
Uses source’s corner having the most similar *split* normal with destination one,
from those sharing the nearest source’s vertex.
Nearest Corner and Best Matching Face Normal
Uses source’s corner having the most similar *face* normal with destination one,
from those sharing the nearest source’s vertex.
Nearest Corner of Nearest Face
Uses source’s nearest corner of source’s nearest face.
Faces
Nearest Face
Uses source’s nearest face.
Best Normal-Matching:
Uses source’s face which normal is most similar with destination one.
Interpolated Mappings
Those use several source items for each destination one, interpolating their data during the transfer.

Vertices
Nearest Edge Interpolated
Uses nearest point on nearest source’s edge, interpolates data from both source edge’s vertices.
Nearest Face Interpolated
Uses nearest point on nearest source’s face, interpolates data from all that source face’s vertices.
Projected Face Interpolated
Uses point of face on source hit by projection of destination vertex along its own normal,
interpolates data from all that source face’s vertices.
Edges
Projected Edge Interpolated
This is a sampling process. Several rays are cast from along the destination’s edge
(interpolating both edge’s vertex normals), and if enough of them hit a source’s edge,
all hit source edges’ data are interpolated into destination one.
Face Corners
A face corner is not a real item by itself, it’s some kind of split vertex attached to a specific face.
Hence both vertex (location) and face (normal, ...) aspects are used to match them together.

Nearest Face Interpolated
Uses nearest point of nearest source’s face, interpolates data from all that source face’s corners.
Projected Face Interpolated
Uses point of face on source hit by projection of destination corner along its own normal,
interpolates data from all that source face’s corners.
Faces
Projected Face Interpolated
This is a sampling process. Several rays are cast from the whole destination’s face (along its own normal),
and if enough of them hit a source’s face, all hit source faces’ data are interpolated into destination one.

------------------

Auto Transform
Automatically computes the transformation to get the best possible match between source and destination meshes.
Object Transform
Evaluate source and destination meshes in global space.
Only Neighbor Geometry
Source elements must be closer than given distance from destination one.

Max Distance
Maximum allowed distance between source and destination element (for non-topology mappings).

.. The below definition is confusing for users. Change?

Ray Radius
Width of rays. Useful when raycasting against vertices or edges.
Mix Mode
How to affect destination elements with source values.

All
Replaces everything in destination (note that *Mix Factor* is still used).
Above Threshold
Only replaces destination value if it is above given threshold *Mix Factor*.
How that threshold is interpreted depends on data type,
note that for boolean values this option fakes a logical AND.
Below Threshold
Only replaces destination value if it is below given threshold *Mix Factor*.
How that threshold is interpreted depends on data type,
note that for boolean values this option fakes a logical OR.
Mix, Add, Subtract, Multiply
Apply that operation, using mix factor to control how much of source or destination value to use.
Only available for a few types (vertex groups, vertex colors).
Mix Factor
How much of the transfered data gets mixed into existing one (not supported by all data types).

Data Layout
===========

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Edit --&gt; Data Layout`

Transfers layout of data layer(s) from active to selected meshes.

Data Type
Which data to transfer.

.. figure:: /images/modeling_meshes_editing_data-transfer.png

Data types.

Exact Match
Also Delete some data layers from destination if necessary, so that it matches the source exactly.
Source Layers Selection
Which layers to transfer, in case of multi-layer types.

Active Layer
Only transfer the active data layer.
All Layers
Transfer all data layers.

Destination Layers Matching
How to match source and destination layers.

By Name
Match target data layers to affect by name.
By Order
Match target data layers to affect by order (indices).
..    TODO/Review: {{review|im=needs example}}.

*********
Duplicate
*********

Duplicate
=========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Duplicate`
| Menu:     :menuselection:`Mesh --&gt; Add Duplicate`
| Hotkey:   :kbd:`Shift-D`

This tool simply duplicates the selected elements,
without creating any connections with the rest of the mesh (unlike extrude, for example),
and places the duplicate at the location of the original. Once the duplication is done,
only the *new* duplicated elements are selected,
and you are automatically placed in grab/move mode, so you can translate your copy elsewhere...

In the *Tool Shelf* are settings for *Vector* offset, *Proportional Editing*,
*Duplication Mode* (non-functional?), and *Axis Constraints*.

Note that duplicated elements belong to the same
:doc:`vertex groups &lt;/modeling/meshes/properties/vertex_groups/index&gt;` as the "original" ones.
The same goes for the :ref:`material indices &lt;bi-multiple-materials&gt;`,
the edge's *Sharp* and *Seam* flags, and probably for the other vertex/edge/face properties...
.. (todo) Extrude Edges and Vertices Only needs a rewrite.

*******
Extrude
*******

Extrusion tools duplicate vertices, while keeping the new geometry connected with the original vertices.
Vertices are turned into edges and edges will form faces.

.. list-table::

* - .. figure:: /images/extrude-vert.png
:width: 320px

Single vertex extruded.

- .. figure:: /images/extrude-edge.png
:width: 320px

Single edge extruded.

This tool is of paramount importance for creating new geometry.
It allows you to create parallelepipeds from rectangles and cylinders from circles,
as well as easily create such things as tree limbs.

The axis on which vertices and edges are extruded along can be set interactively.
Faces are extruded by default along their averaged normal.
The extrusion can be limited to a single axis by specifying an axis;
see :doc:`/editors/3dview/object/editing/transform/control/precision/axis_locking`.

The extrude tools differentiate in how the new geometry is connected in itself.

Extrude Region
==============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Extrude Region`
| Menu:     :menuselection:`Mesh --&gt; Extrude --&gt; Extrude Region`
| Hotkey:   :kbd:`E`

Only the border loop gets extruded.
The inner region of the selection gets moved unchanged with the extrusion.

.. list-table::

* - .. figure:: /images/extrude-face-before.png
:width: 200px

Selected face.

- .. figure:: /images/extrude-face-after.png
:width: 200px

During extrude.

- .. figure:: /images/extrude-face-after-zaxiz.png
:width: 200px

Set to Z axis.

Details
-------

Although the process is quite intuitive,
the principles behind *Extrude* are fairly elaborate as discussed below:

- First, the algorithm determines the outside edge-loop of the extrude; that is,
which among the selected edges will be changed into faces. By default (see below),
the algorithm considers edges belonging to two or more selected faces as internal, and hence not part of the loop.
- The edges in the edge-loop are then changed into faces.
- If the edges in the edge-loop belong to only one face in the complete mesh,
then all of the selected faces are duplicated and linked to the newly created faces. For example,
rectangles will result in parallelepipeds during this stage.
- In other cases, the selected faces are linked to the newly created faces but not duplicated.
This prevents undesired faces from being retained "inside" the resulting mesh.
This distinction is extremely important since it ensures the construction of consistently coherent,
closed volumes at all times when using *Extrude*.
- When extruding completely closed volumes (like e.g. a cube with all its six faces),
extrusion results merely in a duplication, as the volume is duplicated, without any link to the original one.
- Edges not belonging to selected faces, which form an "open" edge-loop,
are duplicated and a new face is created between the new edge and the original one.
- Single selected vertices which do not belong to selected edges
are duplicated and a new edge is created between the two.

Extrude Individual
==================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Extrude Individual`
| Menu:     :menuselection:`Mesh --&gt; Extrude --&gt; Individual Faces`
| Hotkey:   :kbd:`Alt-E`

*Extrude Individual* allows you to extrude a selection of multiple faces as individuals, instead of as a region.
The faces are extruded along their own normals, rather than their average.
This has several consequences: first, "internal" edges
(i.e. edges between two selected faces) are no longer deleted (the original faces are).

.. list-table::

* - .. figure:: /images/extrude-face-multi.png
:width: 200px

Selection of multiple faces.

- .. figure:: /images/extrude-face-multi-region.png
:width: 200px

Extruded using extrude region.

- .. figure:: /images/extrude-face-multi-individual.png
:width: 200px

Extruded using Extrude Individual.

Extrude Edges and Vertices Only
===============================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode, Vertex and Edge
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Extrude`
| Menu:     :menuselection:`Mesh --&gt; Extrude --&gt; Extrude Edges/Vertices Only`
| Hotkey:   :kbd:`Alt-E`

If vertices are selected while doing an extrude, but they do not form an edge or face,
they will extrude as expected, forming a :term:`non-manifold` edge. Similarly,
if edges are selected that do not form a face, they will extrude to form a face.

When a selection of vertices forms an edge or face,
it will extrude as if the edge was selected. Likewise for edges that form a face.

To force a vertex or edge selection to extrude as a vertex or edge, respectively, use
:kbd:`Alt-E` to access the Extrude *Edges Only* and *Vertices Only*.

.. list-table::

* - .. figure:: /images/extrude-verts-before.png
:width: 320px

Vertex selected.

- .. figure:: /images/extrude-verts-after.png
:width: 320px

Vertices Only extrude.

* - .. figure:: /images/extrude-edges-before.png
:width: 320px

Edge selected.

- .. figure:: /images/extrude-edges-after.png
:width: 320px

Edge Only extrude.

Extrude Repeat Mesh
===================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Operator Search --&gt; Extrude Repeat Mesh`

This tool has to be called from :doc:`/interface/controls/templates/operator_search`.
If the selection is not manifold it's extruded the specified number of times, else
it behaves similar to the  :doc:`/modeling/modifiers/generate/array`.
The extrusion is aligned along the Z axis of the view.

Offset
Distance between the instances.
Steps
Number of instances.

##############
Duplicating
##############

.. toctree::
:maxdepth: 2

introduction.rst
duplicate.rst
extrude.rst
inset.rst
spin.rst
screw.rst

***********
Inset Faces
***********

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Inset Faces`
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Inset Faces`
| Hotkey:   :kbd:`I`

This tool takes the currently selected faces and creates an inset of them,
with adjustable thickness and depth. Think of it as like creating an edge loop,
but relative to the selected edges, even in complex meshes.

The tool is modal, such that when you activate it,
you may adjust the thickness with your mouse position. You may also adjust the depth of the
inset during the modal operation by holding :kbd:`Ctrl`.

.. list-table::

* - .. figure:: /images/mesh_tool_inset_before.png
:width: 320px

Selection to inset.

- .. figure:: /images/mesh_tool_inset_after.png
:width: 320px

Selection with inset.

Options
=======

.. figure:: /images/mesh_tool_inset_settings.png

Inset Operator Settings.

Boundary
Determines whether open edges will be inset or not.
Offset Even
Scale the offset to give more even thickness.
Offset Relative
Scale the offset by surrounding geometry.
Edge Rail
ToDo.
Thickness
Set the size of the offset.
Depth
Raise or lower the newly inset faces to add depth.
Outset
Create an outset rather than an inset.
Causes the geometry to be created surrounding selection (instead of within).
Select Outer
Toggle which side of the inset is selected after operation.
Individual
By default the Inset tool operates on the region around selected faces,
but with this option each selected face can be inset on its own.
Interpolate
Interpolate mesh data: e.g. UV's, vertex colors, weights... etc.

************
Introduction
************

This section covers mesh editing tools that add additional geometry by duplicating existing
geometry in some way.

- :doc:`Duplicate Geometry &lt;/modeling/meshes/editing/duplicating/duplicate&gt;`.
- :doc:`Extrusion &lt;/modeling/meshes/editing/duplicating/extrude&gt;`.
- :doc:`Spin &lt;/modeling/meshes/editing/duplicating/spin&gt;`.
- :doc:`Screw &lt;/modeling/meshes/editing/duplicating/screw&gt;`.

.. note:: Multiple Viewports

When you use one of the duplication tools in the *Mesh Tools* panel,
Blender cannot guess which view you want to work in (if you have more than one opened, of course...)
As the view is often important for these tools, once you have activated one,
your cursor turns into a sort of question mark. Click with it inside the area you want to use.

**********
Screw Tool
**********

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Screw`

he *Screw* tool combines a repetitive *Spin* with a translation,
to generate a screw-like, or spiral-shaped, object. Use this tool to create screws, springs,
or shell-shaped structures (Sea shells, Wood Screw Tips, Special profiles, etc).

The main difference between the Screw Tool and the :doc:`Screw Modifier &lt;/modeling/modifiers/generate/screw&gt;`
is that the Screw Tool can calculate the angular progressions using the basic profile angle automatically.
Or it can adjusting the Axis angular vector without using a second modifier (for example,
using the Screw Modifier with a Bevel Modifier, Curve Modifier, etc...),
resulting in a much cleaner approach for vertex distribution and usage.

This tool works using open or closed profiles, as well as profiles closed with faces.
You can use profiles like an open-edge part that is a part of a complete piece,
as well as a closed circle or a half-cut sphere, which will also close the profile end.

You can see some examples of Meshes generated with the *Screw* tool
in Fig. :ref:`fig-mesh-screw-wood` and Fig. :ref:`fig-mesh-screw-spring`.

.. list-table::

* - .. _fig-mesh-screw-wood:

.. figure:: /images/modeling_mesh_screw_screw_example_shell.png

Wood Screw tip done with the screw tool.

- .. _fig-mesh-screw-spring:

.. figure:: /images/modeling_mesh_screw_screw_example_spring.png

Spring done with the screw tool.

Usage
=====

This tool works only with Meshes.
In *Edit Mode*, the button for the *Screw* tool operation is located in the *Mesh Tools* Panel,
:menuselection:`Tool Shelf --&gt; Mesh Tools --&gt; Add: Screw`.
To use this tool, you need to create at least one open profile or line to be used as a vector for the height,
angular vector and to give Blender a direction.

The *Screw* function uses two points given by the open line to create an initial vector to calculate the height
and basic angle of the translation vector that is added to the "Spin" for each full rotation (see examples below).
If the vector is created with only two vertices at the *same* (X, Y, Z) location
(which will not give Blender a vector value for height), this will create a normal "Spin".

Having at least one vector line,
you can add other closed support profiles that will follow this vector during the extrusions (See limitations).
The direction of the extrusions is calculated by two determinant factors,
your point of view in Global Space and the position of your cursor in the 3D View using Global coordinates.
The profile and the vector must be fully selected in *Edit Mode* before you click the *Screw Button*
(See Limitations.)
When you have the vector for the open profile and the other closed profiles selected, click the *Screw* Button.

Limitations
===========

There are strict conditions about your profile selection when you want to use this tool.
You must have at least one open line or open profile,
giving Blender the starting Vector for extrusion,
angular vector and height. (e.g. a simple edge, a half circle, etc...).
You need only to ensure that at least one reference line has two "free" ends.
If two open Lines are given, Blender will not determine which of them is the vector,
and will then show you an error message,
``"You have to select a string of connected vertices too"``.
You need to select all of the profile vertices that will participate in the *Screw*
Tool operation; if they are not properly selected,
Blender will also show you the same message.

Note that the open line is always extruded, so if you only use it to "guide" the screw,
you will have to delete it after the tool completion (use linked-selection,
:kbd:`Ctrl-L`, to select the whole extrusion of the open line).

If there is any problem with the selection or profiles,
the tool will warn you with the error message:
``"You have to select a string of connected vertices too"`` as seen
in Fig. :ref:`fig-mesh-screw-error-info` and Fig. :ref:`fig-mesh-screw-error-popup`,
both in the Info Editor and at the place where you clicked to start performing the operation
(when you click the Screw Button).

.. _fig-mesh-screw-error-info:

.. figure:: /images/modeling_mesh_screw_error_msg_info_editor.png

Screw Error message in the Header of the Info editor.

.. _fig-mesh-screw-error-popup:

.. figure:: /images/modeling_mesh_screw_error_msg_screw_tool.png

Error message when clicking in the Screw Tool with an incorrect or bad selection.

You may have as many profiles as you like (like circles, squares, and so on)
-- Note that not all vertices in a profile need to be in the same plane,
even if this is the most common case. You may also have other, more complex,
selected closed islands, but they have to be closed profiles because Blender will seek for
only one open profile for the translation, height and angular vector.
Some closed meshes that overlap themselves may not screw correctly (for example:
Half UV-sphere works fine, but
more than half could cause the Screw Tool to have wrong behavior or errors),
and profiles that are closed with faces (like a cone or half sphere)
will be closed automatically at their ends, like if you were extruding a region.

.. tip:: Simple way to not result in error

Only one open Profile, all of the others can be closed, avoid volumes and some profiles closed with faces...

Options
=======

This tool is an interactive and modal tool, and only works in the *Edit Mode*.

Once you click in the *Screw* tool in the Mesh Tools Panel,
Blender will enter in the *Screw* interactive mode, and the Operator Panel at the
end of the Mesh Tools Panel will be replaced so you can adjust the values explained below.
To show the Mesh Tools Panel,
use the shortcut :kbd:`T` in the Edit Mode of the 3D View editor.

Once you perform any other operation,
Blender leaves the interactive mode and accepts all of the values. Because it is modal, you
cannot return to the interactive mode after completing/leaving the operation or changing from
*Edit Mode* to *Object Mode*.
If you want to restart the operation from its beginning,
you can press :kbd:`Ctrl-Z` at any time in *Edit Mode*.

The basic location of the cursor at the point of view (using Global coordinates)
will determine around which axis the selection is extruded and spun at first
(See Fig. :ref:`fig-mesh-screw-transform-panel`).
Blender will copy your cursor location coordinates to the
values present in the *Center* values of the *Screw* interactive Panel.
Depending on the Global View position, Blender will automatically add a value of 1 to one of the Axis Vectors,
giving the profiles a starting direction for the Screw Operation and also giving a direction for the extrusions.
(See examples below.)

The position of the 3D cursor will be the starting center of the rotation.
Subsequent operations (e.g. pressing the Screw button again), will start from the last selected element.
Continuous operations without changing the selection will repeat the operation continuously from the last point.

.. _fig-mesh-screw-transform-panel:

.. figure:: /images/editors_3dview_3d-cursor_panel.png

:menuselection:`Properties region --&gt; Cursor`.

.. _fig-mesh-screw-interactive-panel:

.. figure:: /images/modeling_mesh_screw_screw_interactive_panel.png

Screw Tools Operator Panel (Edit Mode).

Center
These number buttons specify the center of the spin. When the tool is called for the first time,
it will copy the (X, Y, Z) location (Global Coordinates)
of the cursor presently in the 3D View to start the operation.
You can specify the cursor coordinates using the Transform Panel in 3D View,
using shortcut :kbd:`T` to toggle the Panel, and typing in the 3D Cursor Location coordinates.
You can adjust these coordinates interactively and
specify another place for the spin center during the interactive session.
(See Fig. :ref:`fig-mesh-screw-interactive-panel`)
Steps
This number button specifies how many extrusion(s) will be done for each 360 degree turn.
The steps are evenly distributed by dividing 360 degree by the number of steps given. The minimum value is 3;
the maximum is 256 (See Fig. :ref:`fig-mesh-screw-interactive-panel`)
Turns
This number button specifies how many turns will be executed.
Blender will add a new full 360 degree turn for each incremental number specified here.
The minimum value is 1; the maximum is 256. (See Fig. :ref:`fig-mesh-screw-interactive-panel`)
Axis
These three numeric fields vary from (-1.0 to 1.0) and are clamped above those limits.
These values correspond to angular vectors from (-90 to 90) degrees. Depending on the position where you
started your cursor location and Object operation in the viewport and its axis positions in Global View space and
coordinates, Blender will give the proper Axis vector a value of 1, giving the angular vector of the profile
a starting direction and giving the extrusions a starting direction based on your view. Blender will let you
adjust your axis angular vectors and you can tweak your object such that you can revert the direction of the screw
operation (by reverting the angular vector of the height),
meaning you can revert the clockwise and counterclockwise direction of some operations,
and also adjust the angular vectors of your profile, bending it accordingly.
(See Fig. :ref:`fig-mesh-screw-interactive-panel`)

Examples
========

The Spring example
------------------

.. _fig-mesh-screw-circle:

.. figure:: /images/modeling_mesh_screw_screw_circle_moved_x_-3bu.png

Circle placed at X (-3, 0, 0).

#. Open Blender and delete the default Cube.
#. Change from perspective to orthographic view using shortcut :kbd:`Numpad5`.
#. Change your view from *User Ortho* to *Front Ortho*, using the shortcut :kbd:`Numpad1`.
You will see the X (red) and Z (blue) coordinate lines.
#. In case you have moved your cursor by clicking anywhere in the screen, again place your cursor at the Center,
using the shortcut :kbd:`Shift-S` choosing *Cursor to Center* or the Transform Panel,
placing your cursor at (0, 0, 0) typing directly into the Cursor 3D Location.
#. Add a circle using shortcut :kbd:`Shift-A` :menuselection:`--&gt; Mesh --&gt; Circle`.
#. Rotate this circle using the shortcut :kbd:`R X 9 0` and :kbd:`Enter`.
#. Apply the Rotation using :kbd:`Ctrl-A` and choosing *Rotation*
#. Grab and move this circle three Blender Units on the *X-Axis* to the left;
you can use the shortcut :kbd:`Ctrl` while grabbing with the mouse using the standard transform widgets
(clicking on the red arrow shown with the object and grabbing while using shortcut
:kbd:`Ctrl` until the down left info in the 3D View marks ``D. -3.0000 (3.0000) Global`` ),
or press the shortcut :kbd:`G X Minus 3` and :kbd:`Enter`.
You can use the Transform Panel (toggled with the shortcut :kbd:`T` ,
and type  :kbd:`Minus 3` and :kbd:`Enter` in the Location too.
(See the Fig. :ref:`fig-mesh-screw-circle`).
#. You will have to scale your circle using the shortcut :kbd:`S . 5`, then :kbd:`Enter`.
#. Now enter *Edit Mode* using shortcut :kbd:`Tab`.
#. De-select all vertices using the shortcut :kbd:`A`.

Now we will create a height vector for Blender:

.. _fig-mesh-screw-profile:

.. figure:: /images/modeling_mesh_screw_spring_profile_ready.png

Profile and vector created.

#. Press :kbd:`Ctrl` and Left click :kbd:`LMB` near the circle,
in more or less at the light gray line of the square above the circle,
and, while still pressing :kbd:`Ctrl`, Left Click :kbd:`LMB` again in the gray line below the circle.
You have created two vertices and an Edge, which Blender will use as the first height and angle vector.
#. Now, in the Transform Panel, in the median, clicking in the Global coordinates,
for the (X, Y, Z) coordinates, put (-2, 0, -1).
#. Right Click :kbd:`RMB` in the other vertex,
and again, type its coordinates for (X, Y, Z) to (-2, 0, 1).
This will create a straight vertical line with 2 Blender units of Height.
#. De-select and select everything again with the shortcut :kbd:`A`.
(See Fig. :ref:`fig-mesh-screw-profile`)
#. Place again your cursor at the center. (Repeat step 2)
#. At this point, we will save this blend-file to recycle the
Spring for another exercise; click with :kbd:`LMB` in *File*,
it is placed at the header of the Info editor, (At the top left side), and choose *Save as*.
Our suggestion is to name it *Screw Spring Example.blend* and click in *Save as blend-file*.
You can also use the shortcut :kbd:`Shift-Ctrl-S`
to open the File Browser in order to save your blend-file.
#. Click Screw and adjust the Steps and Turns as you like and we have a nice spring,
but now here comes the interesting part!

Clockwise and Counterclockwise using the Spring Example
-------------------------------------------------------

Still in the interactive session of the *Screw Tool*,
you will see that the *Z-Axis* Value of the *Screw* Panel is set to 1.000.
Left click :kbd:`LMB` in the middle of the Value and set this value to -1.000.
At first, the Spring was being constructed in a Counterclockwise direction,
and you reverted the operation 180 degrees in the *Z-Axis*. This is because you have
changed the angular vector of the height you have given to Blender to the opposite direction
(remember, -90 to 90 = 180 degrees ?). See Fig. :ref:`fig-mesh-screw-clock`.

.. _fig-mesh-screw-clock:

.. list-table:: Spring direction.

* - .. figure:: /images/modeling_mesh_screw_screw_spring_counterclockwise.png

Counterclockwise direction.

- .. figure:: /images/modeling_mesh_screw_screw_spring_clockwise.png

Flipped to Clockwise direction.

It is also important to note that this vector is related to the same height vector axis used
for the extrusion and we have created a parallel line with the *Z-Axis*, so, the
sensibility of this vector is in practical sense reactive only to negative and positive values
because it is aligned with the extrusion axis. Blender will clamp the positive and negative to
its maximum values to make the extrusion follow a direction,
even if the profile starts reverted. The same rule applies to other Global axes when creating
the Object for the *Screw* Tool;
this means if you create your Object using the Top View
(Shortcut :kbd:`Numpad7` with a straight parallel line following another axis
(for the Top View, the *Y-Axis*), the vector that gives the height for extrusion will also
change abruptly from negative to positive and vice versa to give the extrusion a direction,
and you will have to tweak the corresponding Axis accordingly to achieve the Clockwise and
Counterclockwise effect.

.. note:: Vectors that are not parallel with Blender Axis

The high sensibility for the vector does not apply to vectors that give the Screw Tool a starting angle
(Ex: any non-parallel vector),
meaning Blender will not need to clamp the values to stabilize a direction for the extrusion, as the inclination of
the vector will be clear for Blender and you will have the full degree of freedom to change the vectors. Our
example is important because it only changes the direction of the profile without the tilt and/or bending effect,
as there is only one direction for the extrusion, parallel to one of the Blender Axes.

Bending the Profiles using the Spring Example
---------------------------------------------

Still using the Spring Example, we can change the remaining vector for the angles that are not
related to the extrusion Axis of our Spring, thus bending our spring with the remaining
vectors and creating a profile that will also open and/or close because of the change in
starting angular vector values. What we are really doing is changing the starting angle of the
profile prior to the extrusions. It means that Blender will connect each of the circles
inclined with the vector you have given.
Below we show two bent Meshes using the Axis vectors and the Spring example.
See Fig. :ref:`fig-mesh-screw-angle`. These two Meshes generated
with the *Screw* tool were created using the Top Ortho View.

.. _fig-mesh-screw-angle:

.. list-table:: Bended Mesh.

* - .. figure:: /images/modeling_mesh_screw_angular_vector_example_1.png

The Axis will give the profile a starting vector angle.

- .. figure:: /images/modeling_mesh_screw_angular_vector_example_2.png

The vector angle is maintained along the extrusions.

Creating perfect Screw Spindles
-------------------------------

Using the Spring Example, it is easy to create perfect Screw Spindles
(like the ones present in normal screws that we can buy in hardware stores).
Perfect Screw Spindles use a profile with the same height as its vector, and the beginning and
ending vertex of the profile are placed at a straight parallel line with the axis of
extrusion. The easiest way of achieving this effect is to create a simple profile where the
beginning and ending vertices create a straight parallel line. Blender will not take into account
any of the vertices present in the middle but those two to take its angular vector,
so the spindles of the screw (which are defined by the turns value)
will assembly perfectly with each other.

#. Open Blender and click in *File* located at the header of the Info editor again,
choose *Open Recent* and the file we saved for this exercise.
All of the things will be placed exactly the way you saved before.
Choose the last saved blend-file; in the last exercise,
we gave it the name *Screw Spring Example.blend*.
#. Press the shortcut :kbd:`A` to de-select all vertices.
#. Press the shortcut :kbd:`B`, and Blender will change the cursor; you are now in border selection mode.
#. Open a box that selects all of the circle vertices except the
two vertices we used to create the height of the extrusions in the last example.
#. Use the shortcut :kbd:`X` to delete them.
#. Press the shortcut :kbd:`A` to select the remaining vertices.
#. Press the shortcut :kbd:`W`, and select :menuselection:`Specials --&gt; Subdivide`.
#. Now, click with the Right Mouse button at the middle vertex.
#. Grab this vertex using the shortcut :kbd:`G X Minus 1` and :kbd:`Enter`.
See Fig. :ref:`fig-mesh-screw-spindle`.
#. At this point, we will save this blend-file to recycle the generated Screw for another exercise;
click with :kbd:`LMB` in *File* --
it is in the header of the Info editor (at the top left side), and choose *Save as*.
Our suggestion is to name it *Screw Hardware Example.blend* and click in *Save as blend-file*.
You can also use the shortcut :kbd:`Shift-Ctrl-S` to open the
File Browser in order to save your blend-file.
#. Press shortcut :kbd:`A` twice to de-select and select all vertices again.
#. Now press Screw.
#. Change Steps and Turns as you like.
Fig. :ref:`fig-mesh-screw-generated-mesh` - Shows you an example of the results.

.. list-table::

* - .. _fig-mesh-screw-spindle:

.. figure:: /images/modeling_mesh_screw_screw_perfect_spindle_profile.png

Profile for a perfect screw spindle.

The starting and ending vertices are forming a parallel line with the Blender Axis.

- .. _fig-mesh-screw-generated-mesh:

.. figure:: /images/modeling_mesh_screw_screw_generated_perfect_spindle.png

Generated Mesh.

You can use this technique to perform normal screw modeling.

Here, in Fig. :ref:`fig-mesh-screw-ramp`, we show you an example using a different profile,
but maintaining the beginning and ending vertices at the same position.
The generated mesh looks like a medieval ramp!

.. _fig-mesh-screw-ramp:

.. list-table:: Ramp.

* - .. figure:: /images/modeling_mesh_screw_ramp_like_profile.png

Profile with starting and ending vertices forming a parallel line with the Blender Axis.

- .. figure:: /images/modeling_mesh_screw_ramp_like_generated.png

Generated Mesh with the profile at the left. We have inclined the visualization a bit.

As you can see, the Screw spindles are perfectly assembled with each other,
and they follow a straight line from top to bottom.
You can also change the Clockwise and Counterclockwise direction using this example,
to create right and left screw spindles. At this point,
you can give the screw another dimension, changing the Center of the Spin Extrusion, making it
more suitable to your needs or calculating a perfect screw and merging its vertices with a
cylinder, modeling its head, etc.

A Screw Tip
-----------

As we have explained before,
the *Screw* tool generates clean and simple meshes to deal with; they are light,
well-connected and are created with very predictable results.
This is due to the Blender calculations taking into account not only the height of the vector,
but also its starting angle. It means that Blender will connect the vertices with each other
in a way that they follow a continuous cycle along the extruded generated profile.

In this example, you will learn how to create a simple Screw Tip
(like the ones we use for wood; we have shown an example at the beginning of this page).
To make this new example as short as possible, we will recycle our last example (again).

#. Open Blender and click in *File* located in the header of the Info editor again;
choose *Open Recent* and the file we saved for this exercise.
All of the things will be placed exactly the way you saved before.
Choose the last saved blend-file; in the last exercise, we gave it the name *Screw Hardware Example.blend*.
#. Grab the upper vertex and move a bit to the left, but no more than you have moved your last vertex.
(See Fig. :ref:`fig-mesh-screw-start`)
#. Press the shortcut :kbd:`A` twice to de-select and select all.
#. Press the shortcut :kbd:`Shift-S` and select *Cursor to Center*
#. Press Screw.

.. list-table::

* - .. _fig-mesh-screw-start:

.. figure:: /images/modeling_mesh_screw_profile_with_vector_angle.png

Profile With Starting Vector Angle.

- .. _fig-mesh-screw-start-mesh:

.. figure:: /images/modeling_mesh_screw_generated_with_base_vector_angle.png

Generated Mesh with the Profile.

As you can see in Fig. :ref:`fig-mesh-screw-start-mesh`,
Blender follows the basic angular vector of the profile, and the
profile basic angle determines whether the extruded subsequent configured turns will open or
close the resulting mesh following this angle. The vector of the extrusion angle is determined
by the starting and ending Vertex of the profile.
..    TODO/Review: {{review|text=reorganize, elaborate}}.

****
Spin
****

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Spin`
| Hotkey:   :kbd:`Alt-R`

The *Spin* tool extrudes (or duplicates if it the selection is manifold) the selected elements,
rotating around a specific point and axis.

Use the tool to create the sort of objects that you would produce on a lathe
(this tool is often called a "lathe"-tool or a "sweep"-tool in the literature,
for this reason). In fact, it does a sort of circular extrusion of your selected elements,
centered on the 3D cursor, and around the axis perpendicular to the working view...

- The point of view will determine around which axis the extrusion spins...
- The position of the 3D cursor will be the center of the rotation.

Options
=======

Steps
Specifies how many copies will be extruded along the "sweep".
Dupli
When enabled, will keep the original selected elements as separated islands in the mesh
(i.e. unlinked to the result of the spin extrusion).
Angle
Specifies the angle "swept" by this tool, in degrees (e.g. set it to 180 for half a turn).
Center
Specifies the center of the spin. By default it uses the cursor position.
Axis
Specify the spin axis as a vector. By default it uses the view axis (viewport).

Example
=======

.. _fig-mesh-spin-glass:

.. figure:: /images/spin1.png
:width: 300px

Glass profile.

First, create a mesh representing the profile of your object.
If you are modeling a hollow object, it is a good idea to thicken the outline.
Fig. :ref:`fig-mesh-spin-glass` shows the profile for a wine glass we will model as a demonstration.

Go to the *Edit Mode* and select all the vertices of the Profile with :kbd:`A`.

We will be rotating the object around the cursor in the top view,
so switch to the top view with :kbd:`Numpad7`.

.. _fig-mesh-spin-glass-top:

.. figure:: /images/spin2.png
:width: 300px

Glass profile, top view in Edit Mode, just before spinning.

Place the cursor along the center of the profile by selecting one of the vertices along the
center, and snapping the 3D cursor to that location with :menuselection:`Mesh --&gt; Cursor --&gt; Selection`.
(Fig. :ref:`fig-mesh-spin-glass-top`)
shows the wine glass profile from top view, with the cursor correctly positioned.

Click the *Spin* button. If you have more than one 3D View open, the cursor will
change to an arrow with a question mark and you will have to click in the area containing
the top view before continuing. If you have only one 3D View open,
the spin will happen immediately. Fig. :ref:`fig-mesh-spin-profile` shows the result of a successful spin.

Angle
=====

.. _fig-mesh-spin-profile:

.. list-table:: Spun profile.

* - .. figure:: /images/spin3.png
:width: 320px

Spun profile using an angle of 360.

- .. figure:: /images/spin4.png
:width: 320px

Spun profile using an angle of 120.

Dupli
=====

.. list-table::

* - .. figure:: /images/spin6.png
:width: 320px

Result of spin operation.

- .. figure:: /images/spin7.png
:width: 320px

Result of Dupli enabled.

Merge Duplicates
================

.. _fig-mesh-screw-duplicate:

.. figure:: /images/spin8.png
:width: 300px

Duplicate vertices.

The spin operation leaves duplicate vertices along the profile.
You can select all vertices at the seam with Box select :kbd:`B` shown in
Fig. :ref:`fig-mesh-screw-duplicate` Seam vertex selection and
perform a *Remove Doubles* operation.

Notice the selected vertex count before and after the *Remove Doubles* operation
``Vertex count after removing doubles``. If all goes well, the final vertex count
(38 in this example) should match the number of the original profile noted in
:menuselection:`Mesh data --&gt; Vertex and face numbers`.
If not, some vertices were missed and you will need to weld them manually.
Or, worse, too many vertices will have been merged.

.. note:: Merging two vertices in one

To merge (weld) two vertices together, select both of them by :kbd:`Shift-RMB`
clicking on them. Press :kbd:`S` to start scaling and hold down :kbd:`Ctrl`
while scaling to scale the points down to 0 units in the X, Y and Z axis. :kbd:`LMB`
to complete the scaling operation and click the *Remove Doubles* button in
the Tool shelf in *Edit Mode* (also available with :menuselection:`Specials --&gt; Remove Doubles`).

Alternatively, you can use :menuselection:`Specials --&gt; Merge` from the same *Specials* menu
(or :kbd:`Alt-M`). Then, in the new pop-up menu, choose whether the merged vertex will
be at the center of the selected vertices or at the 3D cursor.
The first choice is better in our case!

Recalculate Normals
===================

All that remains now is to recalculate the normals to the outside by selecting all vertices,
pressing :kbd:`Ctrl-N` and validating *Recalc Normals Outside* in the pop-up menu.
..    TODO/Review: {{review|}}.

**********
Edge Tools
**********

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Edges`
| Hotkey:   :kbd:`Ctrl-E`

Make Edge/Face
==============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Make Edge/Face`
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Make Edge/Face`
| Hotkey:   :kbd:`F`

It will create an edge or some faces, depending on your selection.

See also :doc:`Creating Geometry &lt;/modeling/meshes/editing/basics/creating_faces_and_edges&gt;`.

Set Edge Attributes
===================

Edges can have several different attributes that affect how certain other tools affect the mesh.

Mark Seam and Clear Seam
------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Vertex or Edge select modes)
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Mark Seam/Clear Seam`

Seams are a way to create separations, "islands", in UV maps.
See the :ref:`UVTexturing section &lt;editors-uv-image-index&gt;` for more details.
These operators set or unset this flag for selected edges.

Mark Sharp and Clear Sharp
--------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Vertex or Edge select modes)
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Mark Seam/Clear Seam` (or the same options in *Edge Specials* menu)

The *Sharp* flag is used by the :doc:`Edge Split Modifier &lt;/modeling/modifiers/generate/edge_split&gt;`,
which is part of the smoothing techniques.
As seams, it is a property of edges, and these operators set or unset it for selected ones.

.. _modeling-edges-bevel-weight:

Adjust Bevel Weight
-------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Vertex or Edge select modes)
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Edge Bevel Weight`

This edge property, a value between (0.0 to 1.0),
is used by the :doc:`Bevel Modifier &lt;/modeling/modifiers/generate/bevel&gt;` to control the bevel intensity of the edges.
This operator enters an interactive mode (a bit like transform tools),
where by moving the mouse (or typing a value with the keyboard)
you can set the (average) bevel weight of selected edges.

.. _modeling-edges-crease-subdivision:

Edge Crease
-----------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Vertex or Edge select modes)
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Edge Crease`
| Hotkey:   :kbd:`Shift-E`

This edge property, a value between (0.0 to 1.0), is used by the
:doc:`Subdivision Surface Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`
to control the sharpness of the edges in the subdivided mesh.
This operator enters an interactive mode (a bit like transform tools),
where by moving the mouse (or typing a value with the keyboard) you can set the (average)
crease value of selected edges.
A negative value will subtract from the actual crease value, if present.
To clear the crease edge property, enter a value of -1.

.. _modeling-meshes-editing-edge-slide:

Edge Slide
==========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Vertex or Edge select modes)
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Deform: Slide Edge`
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Slide Edge`

Slides one or more edges across adjacent faces with a few restrictions involving the selection
of edges (i.e. the selection *must* define a valid loop, see below.)

Even :kbd:`E`
Forces the edge loop to match the shape of the adjacent edge loop.
You can flip to the opposite vertex using :kbd:`F`. Use :kbd:`Alt-Wheel` to change the control edge.
Flip :kbd:`F`
When Even mode is active, this flips between the two adjacent edge loops the active edge loop will match.
Clamp :kbd:`Alt` or :kbd:`C`
Toggle clamping the slide within the edge extents.

In *Proportional* mode, :kbd:`Wheel`, or :kbd:`Left` and :kbd:`Right`
changes the selected edge for calculating a proportion.
Unlike *Percentage* mode, *Proportional*

Factor
Determines the amount of slide performed.
Negative values correspond to slides toward one face, while positive ones, refer to the other one.
It is also displayed in the 3D View footer.
Mirror Editing
Lets you propagate the operation to the symmetrical elements of the mesh (if present, in local X direction).
Correct UVs
Corrects the corresponding UV coordinates, if these exist, to avoid image distortions.

Usage
-----

By default, the position of vertices on the edge loop move as a percentage of the distance
between their original position and the adjacent edge loop, regardless of the edges' lengths.

.. list-table::

* - .. figure:: /images/edgeslide1.png
:width: 320px

Selected Edge Loop.

- .. figure:: /images/edgeslide2.png
:width: 320px

Repositioned Edge Loop.

Even mode
^^^^^^^^^

*Even* mode keeps the shape of the selected edge loop the same as one of the edge loops adjacent to it,
rather than sliding a percentage along each perpendicular edge.

In *Even* mode, the tool shows the position along the length of the currently selected edge
which is marked in yellow, from the vertex that as an enlarged red marker.
Movement of the sliding edge loop is restricted to this length. As you move the mouse the
length indicator in the header changes showing where along the length of the edge you are.

To change the control edge that determines the position of the edge loop,
use the :kbd:`Alt-Wheel` to scroll to a different edge.

.. list-table::

* - .. figure:: /images/edgeslide3.png
:width: 320px

Even Mode Enabled.

- .. figure:: /images/edgeslide4.png
:width: 320px

Even Mode with Flip Enabled.

Moving the mouse moves the selected edge loop towards or away from the start vertex,
but the loop line will only move as far as the length of the currently selected edge,
conforming to the shape of one of the bounding edge loops.

Limitations &amp; Workarounds
^^^^^^^^^^^^^^^^^^^^^^^^^

There are restrictions on the type of edge selections that can be operated upon.
Invalid selections are:

Loop crosses itself
This means that the tool could not find any suitable faces that were adjacent to the selected edge(s).
Fig. Loop crosses is an example that shows this by selecting two edges that share the same face.
A face cannot be adjacent to itself.
Multiple edge loops
The selected edges are not in the same edge loop, which means they do not have a common edge.
You can minimize this error by always selecting edges end to end or in a "Chain".
If you select multiple edges just make sure they are connected.
This will decrease the possibility of getting looping errors.
Border Edge
When a single edge was selected in a single sided object.
An edge loop cannot be found because there is only one face.
Remember, edge loops are loops that span two or more faces.

A general rule of thumb is that if multiple edges are selected they should be connected end to
end such that they form a continuous chain. This is *literally* a general rule because you
can still select edges in a chain that are invalid because some of the edges in the chain are
in different edge loops.

.. _modeling-meshes-editing-edges-rotate:

Rotate Edge
===========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Vertex or Edge select modes)
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Rotate Edge CW / Rotate Edge CCW`

Rotating an edge clockwise or counter-clockwise spins an edge between two faces around their
vertices. This is very useful for restructuring a mesh's topology.
The tool can operate on one explicitly selected edge,
or on two selected vertices or two selected faces that implicitly share an edge between them.

.. list-table::

* - .. figure:: /images/edgeflip1.png
:width: 320px

Selected Edge.

- .. figure:: /images/edgeflip2.png
:width: 320px

Edge, rotated CW.

Using Face Selection
--------------------

To rotate an edge based on faces you must select two faces, Fig. Adjacent selected faces,
otherwise Blender notifies you with an error message,
``"ERROR: Could not find any select edges that can be rotated"``. Using either *Rotate Edge CW*
or *Rotate Edge CCW* will produce exactly the same results as if you had
selected the common edge shown in Fig. Selected edge rotated CW and CCW.

Edge Split
==========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Edge Split`

*Edge Split* is similar to the *Rip* tool. When two or more touching interior edges,
or a border edge is selected when using *Edge Split*,
a hole will be created, and the selected edges are duplicated to form the border of the hole.

.. list-table::

* - .. figure:: /images/edgesplit1.png
:width: 320px

Selected Edges.

- .. figure:: /images/edgesplit2.png
:width: 320px

Adjacent face moved to reveal hole left by split.

.. _modeling-meshes-editing-bridge-edge-loops:

Bridge Edge Loops
=================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Bridge Edge Loops`

*Bridge Edge Loops* connects multiple edge loops with faces.

Connect Loops
Open Loop
Loops connected with open ends.
Closed Loop
Tries to connect to a circular loop (where start and end is merged).
Loop pairs
Connects each even count of loops individually.
Merge
ToDo.
Merge Factor
ToDo.
Twist
Determines which vertices in both loops are connected to each other.
Number of Cuts
The number of intermediate edge loops used to bridge the distance between two loops.
Interpolation
Linear, Blend Path, Blend Surface
Smoothness
Smoothness of the *Blend Path* and *Blend Surface*.
Profile Factor
ToDo.
Profile Shape
ToDo. Compare to Proportional Editing Falloff.

Examples
--------

Simple example showing two closed edge loops.

.. list-table::

* - .. figure:: /images/mesh_bridge_simple_before.png
:width: 320px

Input.

- .. figure:: /images/mesh_bridge_simple_after.png
:width: 320px

Bridge Result.

Example of bridge tool between edge loops with different numbers of vertices.

.. list-table::

* - .. figure:: /images/mesh_bridge_uneven_before.png
:width: 320px

Input.

- .. figure:: /images/mesh_bridge_uneven_after.png
:width: 320px

Bridge Result.

Example using the bridge tool to punch holes in face selections and connect them.

.. list-table::

* - .. figure:: /images/mesh_bridge_faces_before.png
:width: 320px

Input.

- .. figure:: /images/mesh_bridge_faces_after.png
:width: 320px

Bridge Result.

Example showing how bridge tool can detect multiple loops and loft them in one step.

.. list-table::

* - .. figure:: /images/mesh_bridge_multi_before.png
:width: 320px

Input.

- .. figure:: /images/mesh_bridge_multi_after.png
:width: 320px

Bridge Result.

Example of the subdivision option and surface blending with UV's.

.. list-table::

* - .. figure:: /images/mesh_bridge_advanced_before.png
:width: 320px

Input.

- .. figure:: /images/mesh_bridge_advanced_after.png
:width: 320px

Bridge Result.

**********
Face Tools
**********

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces`
| Hotkey:   :kbd:`Ctrl-F`

These are tools that manipulate faces.

Make Edge/Face
==============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Make Edge/Face`
| Hotkey:   :kbd:`F`

This will create an edge or some faces, depending on your selection.
Also see :doc:`Creating Geometry &lt;/modeling/meshes/editing/basics/creating_faces_and_edges&gt;`.

.. list-table::

* - .. figure:: /images/fill1.png
:width: 320px

A closed perimeter of edges.

- .. figure:: /images/fill2.png
:width: 320px

Filled using fill.

.. _modeling-meshes-editing-fill:

Fill
====

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Fill/Beautify Fill`
| Hotkey:   :kbd:`Alt-F`

The *Fill* option will create *triangular* faces from any group of selected edges
or vertices, as long as they form one or more complete perimeters.

.. figure:: /images/fill3.png
:width: 300px

Filled using fill.

Note, unlike creating n-gons, fill supports holes.

.. list-table::

* - .. figure:: /images/fill1_holes.png
:width: 320px

A closed perimeter of edges with holes.

- .. figure:: /images/fill2_holes.png
:width: 320px

Filled using fill.

Beauty Fill
-----------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Fill/Beautify Fill`
| Hotkey:   :kbd:`Alt-Shift-F`

*Beautify Fill* works only on selected existing faces.
It rearrange selected triangles to obtain more "balanced" ones (i.e. less long thin triangles).

Max Angle
An angle delimiter option to limit edge rotation to flat surfaces.

.. list-table::

* - .. figure:: /images/mesh_beauty_fill_before.png
:width: 320px

Text converted to a mesh.

- .. figure:: /images/mesh_beauty_fill_after.png
:width: 320px

Result of Beauty Fill, :kbd:`Alt-Shift-F`.

.. _modeling-meshes-editing-grid-fill:

Grid Fill
---------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Fill/Grid Fill`

*Grid Fill* uses a pair of connected edge-loops or a single, closed edge-loop to fill in a grid
that follows the surrounding geometry.

Span
ToDo
Offset
ToDo
Simple Blending
ToDo

.. list-table::

* - .. figure:: /images/mesh_fill_grid_surface_before.png
:width: 320px

Input.

- .. figure:: /images/mesh_fill_grid_surface_after.png
:width: 320px

Grid Fill Result.

Solidify
========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Solidify`

This takes a selection of faces and solidifies them by extruding them
uniformly to give volume to a :term:`non-manifold` surface.
This is also available as a :doc:`Modifier &lt;/modeling/modifiers/generate/solidify&gt;`.
After using the tool, you can set the offset distance in the Operator Panel.

Thickness
Amount to offset the newly created surface.
Positive values offset the surface inward relative to the normals direction.
Negative values offset outward.

.. list-table::

* - .. figure:: /images/solidify-before.png
:width: 200px

Mesh before solidify operation.

- .. figure:: /images/solidify-after.png
:width: 200px

Solidify with a positive thickness.

- .. figure:: /images/solidify-after2.png
:width: 200px

Solidify with a negative thickness.

Intersect
=========

Intersect (Knife)
-----------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Intersect (Knife)`

The Intersect tool lets you cut intersections into geometry.
It is a bit like Boolean Tool, but, does not calculate interior/exterior.
Faces are split along the intersections, leaving new edges selected.

Source
Selected/Unselected
Operate between the selected and unselected geometry.
Self Intersect
Operate on the overlapping geometry of the mesh.
Separate
Splits the geometry at the new edge.
Merge Threshold
*See Intersect (Boolean)*

Intersect (Boolean)
-------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Intersect (Boolean)`

Performs boolean operations with the selection on the unselected geometry.
While the :doc:`/modeling/modifiers/generate/booleans` is useful for non-destructive edits,
access to booleans as an edit-mode tool can be useful to quickly perform edits.

Boolean
Difference, Union, Intersect
Swap
Changes the order of the operation.
Merge Threshold
Tolerance for close faces to be considered touching,
It may be useful to increase this when some intersections aren't detected that should be and
when extra geometry is being created because edges aren't detected as overlapping.

.. warning::

A threshold approaching size of faces may cause very slow calculation,
in general keep this value small.

Wireframe
=========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Wire frame`

The wireframe tool makes a wireframe from faces by to turning edges into wireframe tubes,
similar to the :doc:`/modeling/modifiers/generate/wireframe`.

Poke Faces
==========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Poke Faces`
| Hotkey:   :kbd:`Alt-P`

This tool fan-fills each face around a central vertex.
This can be useful as a way to triangulate n-gons, or the *Offset* can be used to make spikes or depressions.

Poke Offset
ToDo.
Offset Relative
ToDo.
Poke Center
Weighted Mean, Mean, Bounds

Triangulate Faces
=================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Triangulate Faces`
| Hotkey:   :kbd:`Ctrl-T`

As its name intimates, this tool converts each selected quadrangle into two triangles.
Remember that quads are just a set of two triangles.

.. _mesh-faces-tristoquads:

Triangles to Quads
==================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Triangles to Quads`
| Hotkey:   :kbd:`Alt-J`

This tool converts the selected triangles into quads by taking adjacent tris and
removes the shared edge to create a quad, based on a threshold.
This tool can be performed on a selection of multiple triangles.

This same action can be done on a selection of two tris,
by selecting them and using the shortcut :kbd:`F`, to create a face, or by selecting the
shared edge and dissolving it with the shortcut :kbd:`X` :menuselection:`--&gt; Dissolve`.

To create a quad, this tool needs at least two adjacent triangles.
If you have an even number of selected triangles,
it is also possible not to obtain only quads. In fact,
this tool tries to create "squarishest" quads as possible from the given triangles,
which means some triangles could remain.

.. list-table::

* - .. figure:: /images/fill5.png
:width: 320px

Before converting tris to quads.

- .. figure:: /images/quadtotris.png
:width: 320px

After converting tris to quads.

All the menu entries and hotkey use the settings defined in the *Mesh Tools* panel:

Max Angle
This values, between (0 to 180), controls the threshold for this tool to work on adjacent triangles.
With a threshold of 0.0,
it will only join adjacent triangles that form a perfect rectangle
(i.e. right-angled triangles sharing their hypotenuses).
Larger values are required for triangles with a shared edge that is small,
relative to the size of the other edges of the triangles.
Compare UVs
When enabled, it will prevent union of triangles that are not also adjacent in the active UV map.
Compare Vertex Color
When enabled, it will prevent union of triangles that have no matching vertex color.
Compare Sharp
When enabled, it will prevent union of triangles that share a edge marked as sharp.
Compare Materials
When enabled, it will prevent union of triangles that do not have the same material assigned.

Weld Edges into Faces
=====================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Weld Edges into Faces`

A Tool to split selected faces by loose wire edges.
This can be used in a similar way to the knife tool, but the edges are manually setup first.

Rotate Edges
============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Rotate Edge CW`

This tool functions the same edge rotation in edge mode.

It works on the shared edge between two faces and rotates that edge if the edge was selected.

.. list-table::

* - .. figure:: /images/rotateedgefacemode1.png
:width: 320px

Two Faces Selected.

- .. figure:: /images/rotateedgefacemode2.png
:width: 320px

Full Render.

See :ref:`Rotate Edge &lt;modeling-meshes-editing-edges-rotate&gt;` for more information.

Rotate &amp; Reverse
================

Rotate UVs
Todo.
Reverse UVs
Todo.
Rotate Colors
Todo.
Reverse Colors
Todo.

Normals
-------

See :ref:`Editing Normals &lt;modeling-meshes-editing-normals-editing&gt;` for more information.

##########
Editing
##########

.. toctree::
:maxdepth: 2

introduction.rst
basics/index.rst
mesh_options.rst
vertices.rst
edges.rst
faces.rst
normals.rst
smoothing.rst
transform/index.rst
duplicating/index.rst
subdividing/index.rst
cleanup.rst
misc.rst
data_transfer.rst

************
Introduction
************

Blender provides a variety of tools for editing meshes.
These are tools used to add, duplicate, move and delete elements.

These are available through the *Mesh Tools* shelf,
the Mesh menu in the 3D View header, and context menus in the 3D View,
as well as individual shortcut keys.

.. note::

All the "transform precision/snap" keys :kbd:`Ctrl` and/ or :kbd:`Shift`
work also for all these advanced operations... However, most of them do not have
:doc:`axis locking &lt;/editors/3dview/object/editing/transform/control/precision/axis_locking&gt;` possibilities,
and some of them do not take into account
:doc:`pivot point &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;` and/or
:doc:`transform orientation &lt;/editors/3dview/object/editing/transform/control/orientations&gt;`
either.

These transform tools are available in the *Transform* section of the
*Mesh* menu in the header.
Note that some of these can also be used on other editable objects, like curves, surfaces,
and lattices.

Accessing Mesh Tools
====================

The mesh tools are found in various places, and available through shortcuts as well.

Mesh Tools Shelf
----------------

When you select a mesh and :kbd:`Tab` into edit mode,
the *Tool Shelf* changes from *Object Tools* to *Mesh Tools*.
These are only some of the mesh editing tools.

Menus
-----

The *Mesh* menu is located in the header.
Some of the menus can be accessed with shortcuts:
:kbd:`Ctrl-F` brings up the Face tool menu
:kbd:`Ctrl-E` brings up the Edge tool menu
:kbd:`Ctrl-V` brings up the Vertex tool menu

************
Mesh Options
************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Options tab --&gt; Mesh Options panel`

X-Mirror
========

The *X-mirror* option of the *Mesh Options* panel allows you edit symmetrical vertices on the other side
of the mesh in a single action. When you transform an element (vertex, edge or face),
if there is its exact X-mirrored counterpart (in local space),
it will be transformed accordingly, through a symmetry along the local X axis.

.. note::

The conditions for *X-Mirror* to work are quite strict, which can make it difficult to use.
To have an exact mirrored version of a (half) mesh,
its easier and simpler to use the :doc:`Mirror Modifier &lt;/modeling/modifiers/generate/mirror&gt;`

Topology Mirror
===============

.. note::

For *Topology Mirror* to work the *X Mirror* option must be enabled.

When using the *X Mirror* option to work on mirrored Mesh Geometry the vertices that
are mirrored must be perfectly placed. If they are not exactly positioned in their mirror
locations then *X Mirror* will not treat those vertices as mirrored.

*Topology Mirror* tries to address this problem by determining which vertices are mirrored vertices not only by
using their positions but also by looking at how those vertices are related to others in the Mesh Geometry.
It looks at the overall topology to determine if particular vertices will be treated as mirrored.
The effect of this is that mirrored vertices can be non-symmetrical and yet still be treated as mirrored when
*X Mirror* and *Topology Mirror* are both active.

.. note::

The *Topology Mirror* functionality will work more reliably on mesh geometry
which is more detailed. If you use very simple geometry for example,
a *Cube* or *UV Sphere* the *Topology Mirror* option will often not work.

Example
-------

For an example of how to use *Topology Mirror* open up a new Blender scene,
then delete the default cube and add a Monkey object to the 3D View.

#. Press :kbd:`Tab` to put the Monkey object into *Edit Mode*.
#. With the *X Mirror* option disabled move one of the Monkey object's vertices slightly.
#. Then Turn *X Mirror* option on again but leave *Topology Mirror* disabled
#. If you now move that vertice again *X Mirror* will not work and the mirrored
vertices will not be altered.
#. If you then enable *Topology Mirror* and move the same vertices again,
then *X Mirror* should still mirror the other vertice,
even though they are not perfectly positioned.

Further Options
===============

Edge Select Mode
This select button indicates what should be done when selecting a vertex path with :kbd:`Ctrl-RMB`:

Select
Just selects all the edges in the path.
Seam
Marks all edges in the path as seams for UV unwrapping.
Sharp
Marks all edges in the path as sharp for the Edge Split Modifier.
Crease
Marks all edges in the path as creases for the Subdivision Surface Modifier, with weight 1.0.
Bevel
Gives bevel weight 1.0 (for the Bevel Modifier) to all edges in the path.

Live Unwrap
If *Live Unwrap* is checked, every time an edge has its seam property changed,
UV unwrap is automatically re-calculated.
Double Threshold
Defines the maximum distance between vertices that are merged by
the *AutoMerge Editing* tool.

..    TODO/Review: {{review|partial=X}}.

***************************
Miscellaneous Editing Tools
***************************

Sort Elements
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Sort Elements...`

This tool (available from the *Specials*, *Vertices*,
*Edges* and *Faces* menus)
allows you to reorder the matching selected mesh elements, following various methods.
Note that when called from the *Specials* menu,
the affected element types are the same as the active select modes.

View Z Axis
Sort along the active view's Z axis, from farthest to nearest by default
(use *Reverse* if you want it the other way).
View X Axis
Sort along the active view's X axis, from left to right by default (again, there is the *Reverse* option).
Cursor Distance
Sort from nearest to farthest away from the 3D cursor position (*Reverse* also available).
Material
Sort faces, and faces only, from those having the lowest material's index to those having the highest.
Order of faces inside each of those "material groups" remains unchanged.
Note that the *Reverse* option only reverses the order of the materials,
*not* the order of the faces inside them.
Selected
Move all selected elements to the beginning (or end, if *Reverse* enabled),
without affecting their relative orders.
Warning: This option will also affect **unselected** elements' indices!
Randomize
Randomizes indices of selected elements (*without* affecting those of unselected ones).
The seed option allows you to get another randomization --
the same seed over the same mesh/set of selected elements will always give the same result!
Reverse
Simply reverse the order of the selected elements.

.. note:: To enable viewing indeces:

Type "bpy.app.debug = True" into the Python Console and a checkbox will appear in the
properties region under :menuselection:`Mesh Display --&gt; Edge Info --&gt; Indices`

.. _object-separate:

Separate
========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Separate`
| Hotkey:   :kbd:`P`

At some point, you will come to a time when you need to cut parts away from a mesh to be separate.

To separate an object, the vertices (or faces) must be selected and then separated,
though there are several different ways to do this.

.. figure:: /images/modeling_meshes_editing_misc_separate-example.png

Suzanne dissected neatly.

Selected
This option separates the selection to a new object.
All Loose Parts
Separates the mesh in its unconnected parts.
By Material
Creates separate mesh objects for each material.

.. seealso::

:ref:`Joining objects &lt;object-join&gt;`.

*******
Normals
*******

Introduction
============

Todo.

.. Explain what are normals

.. figure:: /images/modeling_meshes_editing_normals.png

Normals visualization.

.. _modeling-meshes-editing-normals-editing:

Editing
=======

Flip Direction
--------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Shading/UVs --&gt; Shading --&gt; Normals: Flip Direction`
| Menu:     :menuselection:`Mesh --&gt; Normals --&gt; Flip` or :menuselection:`Specials --&gt; Flip Normals`

Well, it will just reverse the normals direction of all selected faces.
Note that this allows you to precisely control the direction (**not** the orientation,
which is always perpendicular to the face) of your normals, as only selected ones are flipped.

Recalculate Normals
-------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Shading/UVs --&gt; Shading --&gt; Normals: Recalculate`
| Menu:     :menuselection:`Mesh --&gt; Normals --&gt; Recalculate Outside` and
:menuselection:`Mesh --&gt; Normals --&gt; Recalculate Inside`
| Hotkey:   :kbd:`Ctrl-N` and :kbd:`Ctrl-Shift-N`

These tools will recalculate the normals of selected faces so that they point outside
(respectively inside) the volume that the face belongs to.
This volume do not need to be closed. In fact, this means that the face of interest must be
adjacent with at least one non-coplanar other face.
For example, with a *Grid* primitive, recalculating normals does not have a meaningful result.

.. tip::

For Visualization in *Edit Mode* see :ref:`mesh-display-normals`.

*********
Smoothing
*********

Mesh Shading
============

.. list-table::
Example mesh rendered flat, smoothed using edge split, and using Subdivision Surface.
Note how edges are rendered differently.
`Sample blend-file &lt;https://wiki.blender.org/index.php/:File:25-manual-meshsmooth-example.blend&gt;`__.

* - .. figure:: /images/modeling_meshes_editing_smoothing_example-01-flat.png
:width: 200px

- .. figure:: /images/modeling_meshes_editing_smoothing_example-04-edge-split.png
:width: 200px

- .. figure:: /images/modeling_meshes_editing_smoothing_example-09-edge-loops.png
:width: 200px

As seen in the previous sections, polygons are central to Blender.
Most objects are represented by polygons and truly curved objects
are often approximated by polygon meshes. When rendering images,
you may notice that these polygons appear as a series of small, flat faces.

Sometimes this is a desirable effect, but usually we want our objects to look nice and smooth.
This section shows you how to visually smooth an object, and how to apply the *Auto Smooth*
filter to quickly and easily combine smooth and faceted polygons in the same object.

The last section on this page shows possibilities for smoothing a mesh's geometry,
not only its appearance.

Smooth Shading
==============

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:     :menuselection:`Tool Shelf --&gt; Tools --&gt; Edit --&gt; Shading:`

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:     :menuselection:`Tool Shelf --&gt; Shading/ UVs --&gt; Shading`
| Menu:     :menuselection:`Mesh --&gt; Faces --&gt; Shade Smooth / Shade Flat`

.. figure:: /images/modeling_meshes_editing_smoothing_shading-smooth-flat.png
:align: right

Shading buttons in Tool Shelf.

.. figure:: /images/modeling_meshes_editing_smoothing_example-02-smooth.png
:width: 220px

Same mesh smooth shaded.

The easiest way is to set an entire object as smooth or faceted by selecting a mesh object,
and in *Object Mode*, click *Smooth* in the *Tool Shelf*.
This button does not stay pressed;
it forces the assignment of the "smoothing" attribute to each face in the mesh,
including when you add or delete geometry.

Notice that the outline of the object is still strongly faceted.
Activating the smoothing features does not actually modify the object's geometry;
it changes the way the shading is calculated across the surfaces (normals will be interpolated),
giving the illusion of a smooth surface.

Click the *Flat* button in the
*Tool Shelf* 's *Shading panel* to revert the shading back (normals will be constant)
to that shown in the first image above.

Smoothing Parts of a Mesh
-------------------------

Alternatively, you can choose which edges to smooth by entering *Edit Mode*,
then selecting some faces and clicking the *Smooth* button.
The selected edges are marked in yellow.

When the mesh is in *Edit Mode*,
only the selected edges will receive the "smoothing" attribute. You can set edges as flat
(removing the "smoothing" attribute)
in the same way by selecting edges and clicking the *Flat* button.

.. _auto-smooth:

Auto Smooth
===========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Object Data`

.. list-table:: Example mesh with *Auto Smooth* enabled.

* - .. figure:: /images/modeling_meshes_editing_smoothing_example-03-auto-smooth.png
:width: 180px

- .. figure:: /images/modeling_meshes_properties_object-data_normals-panel.png

Normals panel with *Auto Smooth* enabled.

It can be difficult to create certain combinations of smooth and solid faces using the above
techniques alone. Though there are workarounds
(such as splitting off sets of faces by selecting them and pressing :kbd:`Y`),
there is an easier way to combine smooth and solid faces, by using *Auto Smooth*.
Auto smoothing can be enabled in the mesh tab in the Properties Editor in the :ref:`mesh-data-normals` panel.

Edge Split Modifier
===================

With the :doc:`Edge Split Modifier &lt;/modeling/modifiers/generate/edge_split&gt;`  a result
similar to *Auto Smooth* can be achieved with the ability to choose which edges should be split,
based on angle. Those Angles are marked as sharp.

.. list-table::

* - .. figure:: /images/modeling_meshes_editing_smoothing_example-04-edge-split.png
:width: 200px

Edge Split Modifier enabled, based on angle.

- .. figure:: /images/modeling_meshes_editing_smoothing_example-06-mark-sharp.png
:width: 200px

Edges marked as sharp.

- .. figure:: /images/modeling_meshes_editing_smoothing_example-05-mark-sharp.png
:width: 200px

Resulting render with sharp edge weighting.

Smoothing the Mesh Geometry
===========================

The above techniques do not alter the mesh itself, only the way it is displayed and rendered.
Instead of just making the mesh look like a smooth surface,
you can also physically smooth the geometry of the mesh with these tools:

Mesh Editing Tools
------------------

You can apply one of the following in *Edit Mode*:

:doc:`Smooth &lt;/modeling/meshes/editing/transform/smooth&gt;`
This relaxes selected components, resulting in a smoother mesh.
:doc:`Laplacian Smooth &lt;/modeling/meshes/editing/transform/smooth&gt;`
Smooths geometry by offers controls for better preserving larger details.
:doc:`Subdivide Smooth &lt;/modeling/meshes/editing/subdividing/subdivide&gt;`
Adjusting the *smooth* parameter after using the *subdivide*
tool results in a more organic shape. This is similar to using the Subdivision Surface Modifier.
:doc:`Bevel &lt;/modeling/meshes/editing/introduction&gt;`
This Bevels selected edged, causing sharp edges to be flattened.

Modifiers
---------

Alternatively,
you can smooth the mesh non-destructively with one or several of the following modifiers:

:doc:`Smooth Modifier &lt;/modeling/modifiers/deform/smooth&gt;`
Works like the *Smooth* tool in *Edit Mode*;
can be applied to specific parts of the mesh using vertex groups.
:doc:`Laplactian Smooth Modifier &lt;/modeling/modifiers/deform/laplacian_smooth&gt;`
Works like the *Laplacian Smooth* tool in *Edit Mode*;
can be applied to specific parts of the mesh using vertex groups.
:doc:`Bevel Modifier &lt;/modeling/modifiers/generate/bevel&gt;`
Works like the *Bevel* tool in *Edit Mode*;
Bevel can be set to work on an angle threshold, or on edge weight values.
:doc:`Subdivision Surface Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`
Catmull-Clark subdivision produces smooth results. Sharp edges can be defined with
:ref:`subdivision creases &lt;modifiers-generate-subsurf-creases&gt;`
or by setting certain edges to "sharp" and adding an
:doc:`Edge Split Modifier &lt;/modeling/modifiers/generate/edge_split&gt;`
(set to *From Marked As Sharp*) before the Subdivision Surface Modifier.

.. list-table::
Example mesh with *Auto Smooth* enabled.

* - .. figure:: /images/modeling_meshes_editing_smoothing_example-07-subsurf.png
:width: 320px

Subdivision Surface.

- .. figure:: /images/modeling_meshes_editing_smoothing_example-08-edge-crease.png
:width: 320px

Using creased edges, and resulting subdivision artifacts.

* - .. figure:: /images/modeling_meshes_editing_smoothing_example-09-edge-loops.png
:width: 320px

Extra edge loops added.

- .. figure:: /images/modeling_meshes_editing_smoothing_example-10-edge-loops.png
:width: 320px

3D View showing creased edges (pink) and added edges loops (yellow).
..    TODO/Review: {{review|}}.

*****
Bevel
*****

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Bevel` or :menuselection:`Specials --&gt; Bevel`
| Hotkey:   :kbd:`Ctrl-B`
| Menu (vertex-only):    :menuselection:`Mesh --&gt; Vertices --&gt; Bevel`
| Hotkey (vertex-only):  :kbd:`Shift-Ctrl-B`

The bevel tool allows you to create chamfered or rounded corners to geometry.
A bevel is an effect that smooths out edges and corners.

True world edges are very seldom exactly sharp.
Not even a knife blade edge can be considered perfectly sharp.
Most edges are intentionally beveled for mechanical and practical reasons.

Bevels are also useful for giving realism to non-organic models. In the real world,
the blunt edges on objects catch the light and change the shading around the edges.
This gives a solid, realistic look,
as opposed to un-beveled objects which can look too perfect.

.. figure:: /images/modeling_meshes_editing_subdividing_bevel_cubes.jpg

Cubes with and without bevel.

Usage
=====

The *Bevel* tool works only on selected edges with exactly two adjacent faces.
It will recognize any edges included in a vertex or face selection as well,
and perform the bevel the same as if those edges were explicitly selected.
In "vertex only" mode, the *Bevel* tool works on selected vertices instead of edges.
The *Bevel* tool smooths the edges and/or "corners" (vertices)
by replacing them with faces making smooth profiles with a specified number of *segments*
(see the options below for details about the bevel algorithm).

Use :kbd:`Ctrl-B` or a method listed above to run the tool.
Move the mouse to interactively specify the bevel offset,
and scroll the :kbd:`Wheel` to increase or decrease the number of segments. (see below)

.. list-table::

* - .. figure:: /images/modeling_meshes_editing_subdividing_bevel_example-1.png
:width: 320px

Selected edge before beveling.

- .. figure:: /images/modeling_meshes_editing_subdividing_bevel_example-2.png
:width: 320px

Result of bevel (one segment).

- .. figure:: /images/modeling_meshes_editing_subdividing_bevel_example-3.png
:width: 320px

Result of bevel (vertex only).

.. note::

Normal (edge) beveling only works on edges that have exactly two faces
attached to them. Vertex bevel has no such restriction.

Options
=======

.. figure:: /images/modeling_meshes_editing_subdividing_bevel_panel.png
:align: right

Amount
You can change the bevel amount by moving the mouse towards and away from the object,
a bit like with transform tools.
The exact meaning of the value depends on the *Amount Type* option (see below).
As usual, the scaling can be controlled to a finer degree by holding :kbd:`Shift` to scale in 0.001 steps.
:kbd:`LMB` finalizes the operation, :kbd:`RMB` or :kbd:`Esc` aborts the action.

Amount Type :kbd:`M`
Selects how the *Amount* value controls the size of the bevel. According to the selection, the amount is:

Offset
The distance of a new edge from the original.
Width
The width of the bevel face.
Depth
The perpendicular distance from the original edge to the bevel face.
Percent
The percentage of the length of adjacent edges that the new edges slide.

Segments :kbd:`S`
The number of segments in the bevel can be defined by scrolling the
mouse :kbd:`Wheel` to increase or decrease this value.
The greater the number of segments, the smoother the bevel.
Or press :kbd:`S` to change the number with mouse movements, as well as numeric input.

Alternatively, you can manually enter a segment number value while using the tool,
or in the Mesh Tool options panel after using the tool.

.. figure:: /images/modeling_meshes_editing_subdividing_bevel_example-4.png
:width: 320px

Bevel with four segments.

Profile :kbd:`P`
This is a number between 0 and 1 that controls the shape of the profile (side view of a beveled edge).
The default value, 0.5, gives a circular arc (if the faces meet at right angles).
Values less than that give a flatter profile, with 0.25 being exactly flat,
and values less than that giving a concave bevel.
Values more than 0.5 give a more convex profile.
Similarly as *Segments* it can be set with mouse movements and numeric input after toggling :kbd:`P`.
Vertex Only :kbd:`V`
When selected, the tool is in "vertex only" mode, and only vertices will be beveled.
Clamp Overlap :kbd:`C`
When selected, the bevel amount is not allowed to go larger than an amount that causes
overlapping collisions with other geometry.
Loop Slide
If there are unbeveled edges along with beveled edges into a vertex,
the bevel tries to slide along those edges when possible.
Turning the option off can lead to more even bevel widths.
Material
The *Material* number specifies which material should be assigned to the new faces created by the *Bevel* tool.
With the default, -1, the material is inherited from the closest existing face ("closest" can be a bit ambiguous).
Otherwise, the number is the slot index of the material to use for all newly created faces.

Examples
========

.. list-table::

* - .. figure:: /images/modeling_meshes_editing_subdividing_bevel_example-5.png
:width: 320px

Result of beveling multiple edges.

- .. figure:: /images/modeling_meshes_editing_subdividing_bevel_example-6.png
:width: 320px

Another example of beveling multiple edges.

- .. figure:: /images/modeling_meshes_editing_subdividing_bevel_example-7.png
:width: 320px

An example using Profile=0.150.

.. seealso:: Bevel Modifier

The :doc:`Bevel Modifier &lt;/modeling/modifiers/generate/bevel&gt;`
is a non destructive alternative to the bevel tool.

******
Bisect
******

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Bisect`
| Menu:     :menuselection:`Mesh --&gt; Bisect`

The bisect tool is a quick way to cut a mesh in-two along a custom plane.

Plane Point, Plane Normal
The plane can be numerically adjusted for precise values.
Fill
Cuts can optionally fill in the holes created,
with materials, UV maps, and vertex-colors based on the surrounding geometry.
Clear Inner, Clear Outer
Cuts may remove geometry on one side.
Axis Threshold
Cut along the straight plane or along the existing geometry below the distance from the plane.

Examples
========

.. list-table::

* - .. figure:: /images/mesh_bisect.png
:width: 300px

Example of a common use of bisect.

- .. figure:: /images/mesh_bisect_uv.jpg
:width: 320px

Example of bisect with fill option

##############
Subdividing
##############

.. toctree::
:maxdepth: 2

introduction.rst
subdivide.rst
loop_subdivide.rst
knife_subdivide.rst
bisect.rst
vertex_connect.rst
bevel.rst
..    TODO/Review: {{review|}}.

************
Introduction
************

Subdividing adds resolution by cutting existing faces and edges into smaller pieces.
There are several tools that allow you to do this:

:doc:`Subdivide &lt;/modeling/meshes/editing/subdividing/subdivide&gt;`
Divide a face or edge into smaller units, adding resolution.
:doc:`Loop Subdivide &lt;/modeling/meshes/editing/subdividing/loop_subdivide&gt;`
Insert a loop of edges between existing ones.
:doc:`Vertex Connect &lt;/modeling/meshes/editing/subdividing/vertex_connect&gt;`
Connects selected vertices with edges that split faces.
:doc:`Knife Subdivide &lt;/modeling/meshes/editing/subdividing/knife_subdivide&gt;`
Cut edges and faces interactively.
:doc:`Bevel &lt;/modeling/meshes/editing/subdividing/bevel&gt;`
Subdivides edges or vertices, making them faceted or rounded.

**********
Knife Tool
**********

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Knife/Select`
| Hotkey:   :kbd:`K` or :kbd:`Shift-K`

The knife tool can be used to interactively subdivides (cuts up)
geometry by drawing lines or closed loops to create holes.

Usage
=====

When you press :kbd:`K` (or :kbd:`Shift-K`), the Knife tool becomes active.

Drawing the Cut Line
--------------------

When using *Knife*, the cursor changes to an icon of a scalpel
and the header changes to display options for the tool.
You can draw connected straight lines by clicking :kbd:`LMB`,
marked with small green squares. Red squares are already defined cuts.
Surrounding red squares mean that there is a cut already in that very position,
so no additional vertex will be created (besides the first one).

.. list-table::

* - .. figure:: /images/knife1.png
:width: 200px

Mesh before knife cut.

- .. figure:: /images/knife2.png
:width: 200px

Knife cut active.

- .. figure:: /images/knife3.png
:width: 200px

After confirming knife cut.

Options
=======

Knife selection :kbd:`Shift-K`
Activates the knife with another set of options so only selected faces are cut and
*Cut through* is on by default.

New cut :kbd:`E`
Begins a new cut. This allows you to define multiple distinct cut lines.
If multiple cuts have been defined, they are recognized as new snapping points.

.. list-table::

* - .. figure:: /images/knife4.png
:width: 320px

Creating multiple cuts.

- .. figure:: /images/knife5.png
:width: 320px

Result of starting new cuts while in the tool.

Midpoint snap :kbd:`Ctrl`
Hold to snap the cursor to the midpoint of edges,
meaning that all cuts will be performed at the exact center of each cut edge.
Ignore snap :kbd:`Shift`
Hold to make the tool ignore snapping,
unlike the default where mouse cursor snaps to near edges.
Cut through: :kbd:`Z`
Allow the cut tool to cut through to obscured faces, instead of only the visible ones.
Angle constrain :kbd:`C`
Constrains the cut to 45 degree increments.
Close loop: Double click :kbd:`LMB`
This is a quick way to close the loop you are currently cutting.
Draw a continuous line: :kbd:`LMB` drag.
So you can draw a freehand line over a surface,
points will be created at edge intersections.

.. list-table::

* - .. figure:: /images/knife6.png
:width: 320px

Constraining cut angle.

- .. figure:: /images/knife7.png
:width: 320px

Result of constraining cut angle.

Confirming and selection
========================

Pressing :kbd:`Esc` or :kbd:`RMB` at any time cancels the tool,
and pressing :kbd:`LMB` or :kbd:`Enter` confirms the cut, with the following options:

:kbd:`Enter` will leave selected every edge except the new edges created from the cut.

Limitations
===========

Cuts that begin or end in the middle of a face, will be ignored.
This is a limitation of the current geometry that can be modeled in Blender.

Knife Project
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Knife Project`

Knife projection is a non-interactive tool where you can use objects to cookie-cut into the
mesh rather than hand drawing the line.

This works by using the outlines of other selected objects in edit-mode to cut into the mesh,
resulting geometry inside the cutters outline will be selected.

Outlines can be wire or boundary edges.

To use Knife Project, first while in *Object Mode* select the "cutting object"
then add to that selection with :kbd:`Shift-RMB` the "object to be cut".
Now, enter *Edit Mode* and press *Knife Project* (found in the Tool Shelf).

Examples
--------

.. list-table::

* - .. figure:: /images/knife_project_text_before.jpg
:width: 320px

Before projecting from a text object.

- .. figure:: /images/knife_project_text_after.jpg
:width: 320px

Resulting knife projection.

* - .. figure:: /images/knife_project_mesh_before.jpg
:width: 320px

Before projecting from a mesh object.

- .. figure:: /images/knife_project_mesh_after.jpg
:width: 320px

Resulting knife projection (extruded after).

* - .. figure:: /images/knife_project_curve_before.png
:width: 320px

Before projecting from a 3D curve object.

- .. figure:: /images/knife_project_curve_after.jpg
:width: 320px

Resulting knife projection (extruded after).

Known Issues
------------

Cutting holes into single faces may fail,
this is the same limitation as with the regular knife tool but more noticeable for text,
this can be avoided by projecting onto more highly subdivided geometry.
..    TODO/Review: {{review|}}.

**************
Loop Subdivide
**************

Loop Cut and Slide
==================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Loop Cut and Slide`
| Hotkey:   :kbd:`Ctrl-R`

*Loop Cut* splits a loop of faces by inserting a new edge loop intersecting the chosen edge.
The tool is interactive and has two steps:

Usage
-----

Pre-visualizing the Cut
^^^^^^^^^^^^^^^^^^^^^^^

After the tool is activated, move the cursor over a desired edge.
The cut to be made is marked with a magenta colored line as you move the mouse over the various edges.
The to-be-created edge loop stops at the poles (tris and n-gons) where the existing face loop terminates.

Sliding the new Edge Loop
^^^^^^^^^^^^^^^^^^^^^^^^^

Once an edge is chosen via :kbd:`LMB`,
you can move the mouse along the edge to determine where the new edge loop will be placed.
This is identical to the :ref:`Edge Slide tool &lt;modeling-meshes-editing-edge-slide&gt;`.
Clicking :kbd:`LMB` again confirms and makes the cut at the pre-visualized location,
or clicking :kbd:`RMB` forces the cut to exactly 50%.
This step is skipped when using multiple edge loops (see below)

.. list-table::

* - .. figure:: /images/loopcut-before.png
:width: 200px

Mesh before inserting edge loop.

- .. figure:: /images/loopcut-preview.png
:width: 200px

Preview of edge loop location.

- .. figure:: /images/loopcut-placement.png
:width: 200px

Interactive placement of edge loop between adjacent loops.

Options
-------

The options are available while the tool is in use, and later in the Operator panel.

Loop Cut
^^^^^^^^

Number of Cuts :kbd:`Wheel` or :kbd:`PageUp` / :kbd:`PageDown`
After activating the tool, but before confirming initial loop location,
you can increase and decrease the number of cuts to create,
by entering a number with the keyboard, scrolling :kbd:`Wheel` or using :kbd:`PageUp` and :kbd:`PageDown`.

.. note::

When creating multiple loops, these cuts are uniformly distributed in the original face loop,
and you will *not* be able to control their positions.

.. list-table::

* - .. figure:: /images/loopcut-multicut.png
:width: 250px

Preview of multiple edge loops.

- .. figure:: /images/loopcut-multicut-after.png
:width: 250px

Result of using multiple cuts.

Smoothing :kbd:`Alt-Wheel`
Smoothing causes edge loops to be placed in an interpolated position, relative to the face it is added to,
causing them to be shifted outwards or inwards by a given percentage,
similar to the *Subdivide Smooth* tool. When not using smoothing,
new vertices for the new edge loop are placed exactly on the pre-existing edges.
This keeps subdivided faces flat, but can distort geometry,
particularly when using :doc:`Subdivision Surfaces &lt;/modeling/modifiers/generate/subsurf&gt;`.
Smoothing can help maintain the curvature of a surface once it is subdivided.

.. list-table::

* - .. figure:: /images/loopcut-unsmooth.png
:width: 250px

Added edge loops without smoothing.

- .. figure:: /images/loopcut-smooth.png
:width: 250px

Same edge loops, but with smoothing value.

Falloff
ToDo.

Edge Slide
^^^^^^^^^^

Even :kbd:`E`
Only available for single edge loops.
This matches the shape of the edge loop to one of the adjacent edge loops.
(See :ref:`Edge Slide tool &lt;modeling-meshes-editing-edge-slide&gt;` for details).
Flip :kbd:`F`
When Even is enabled, this flips the target edge loop to match.
(See :ref:`Edge Slide tool &lt;modeling-meshes-editing-edge-slide&gt;` for details).

Offset Edge Slide
=================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Offset Edge Slide`
| Hotkey:   :kbd:`Ctrl-Shift-E`

Add two edge loops on either side of selected loops.

Cap Endpoint
ToDo.
Edge Slide
See :ref:`Edge Slide tool &lt;modeling-meshes-editing-edge-slide&gt;`.
..    TODO/Review: {{review|}}.

*********
Subdivide
*********

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Add: Subdivide`
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Subdivide`,
:menuselection:`Specials --&gt; Subdivide/Subdivide Smooth`

Subdividing splits selected edges and faces by cutting them in half or more,
adding necessary vertices, and subdividing accordingly the faces involved,
following a few rules, depending on the settings:

- When only one edge of a face is selected (Triangle mode),
triangles are subdivided into two triangles, and quads, into three triangles.
- When two edges of a face are selected:

- If the face is a triangle, a new edge is created between the two new vertices,
subdividing the triangle in a triangle and a quad.
- If the face is a quad, and the edges are neighbors, we have *three* possible behaviors,
depending on the setting of *Corner Cut Type* (the select menu next to the *Subdivide* button,
in *Mesh Tools* panel) See below for details.
- If the face is a quad, and the edges are opposite,
the quad is just subdivided in two quads by the edge linking the two new vertices.

- When three edges of a face are selected:

- If the face is a triangle, this means the whole face is selected and
it is then sub-divided in four smaller triangles.
- If the face is a quad, first the two opposite edges are subdivided as described above.
Then, the "middle" edge is subdivided, affecting its new "sub-quad" as described above for only one edge.
- When four edges of a face (a quad) are selected, the face is subdivided into four smaller quads.

Options
=======

These options are available in the *Tool Panel* after running the tool;

Number of Cuts
Specifies the number of cuts per edge to make.
By default this is 1, cutting edges in half. A value of 2 will cut it into thirds, and so on.
Smoothness
Displaces subdivisions to maintain approximate curvature,
The effect is similar to the way the Subdivision Surface Modifier might deform the mesh.

.. list-table::

* - .. figure:: /images/subdivide-smooth-before.png
:width: 200px

Mesh before subdividing.

- .. figure:: /images/subdivide-smooth-none.png
:width: 200px

Subdivided with no smoothing.

- .. figure:: /images/subdivide-smooth-after.png
:width: 200px

Subdivided with smoothing of 1.

Quad/Tri Mode
Forces subdivide to create triangles or quads instead of n-gons (see examples below).
This mode doesn't allow the use of *Straight Cut* on quad corners.
Corner Cut Type
This select menu controls the way quads with only two adjacent selected edges are subdivided.

Fan
The quad is sub-divided in a fan of four triangles,
the common vertex being the one opposite to the selected edges.
Inner vertices
The selected edges are sub-divided, then an edge is created between
the two new vertices, creating a small triangle.
This edge is also sub-divided,
and the "inner vertex" thus created is linked by another edge to the one opposite
to the original selected edges. All this results in a quad sub-divided in a triangle and two quad.
Path
First an edge is created between the two opposite ends of the selected edges,
dividing the quad in two triangles. Then, the same goes for the involved triangle as described above.
Straight Cut
.. (Todo) Au: Currently non functioning...

.. list-table::

* - .. figure:: /images/subdivide-twoedgesquad-fan2.png
:width: 200px

Fan cut type.

- .. figure:: /images/subdivide-twoedgesquad-innervert.png
:width: 200px

Inner vertices cut type.

- .. figure:: /images/subdivide-twoedgesquad-path.png
:width: 200px

Path cut type.

Fractal
Displaces the vertices in random directions after the mesh is subdivided.

.. list-table::

* - .. figure:: /images/subdivide-fractal-before.png
:width: 200px

Plane before subdivision.

- .. figure:: /images/subdivide-fractal-none.png
:width: 200px

Regular subdivision.

- .. figure:: /images/subdivide-fractal-after1.png
:width: 200px

Same mesh with fractal added.

Along Normal
Causes the vertices to move along the their normals, instead of random directions.

.. figure:: /images/subdivide-fractal-alongnormal.png
:width: 200px

Along normal set to 1.

Random Seed
Changes the random seed of the *Fractal* noise function, producing a different result for each seed value.

.. figure:: /images/subdivide-fractal-after2.png
:width: 200px

Same mesh with a different seed value.

Examples
========

Below are several examples illustrating the various possibilities of the *Subdivide*
and *Subdivide Multi* tools. Note the selection after subdivision.

.. figure:: /images/subdivide-before.png
:width: 300px

The sample mesh.

One Edge
--------

.. list-table::

* - .. figure:: /images/subdivide-oneedge.png
:width: 250px

One Edges.

- .. figure:: /images/subdivide-oneedge-tri.png
:width: 250px

Quad/Tri Mode.

Two Tri Edges
-------------

.. list-table::

* - .. figure:: /images/subdivide-twoedgestri.png
:width: 250px

- .. figure:: /images/subdivide-twoedgestri-tri.png
:width: 250px

Quad/Tri Mode.

Two Opposite Quad Edges
-----------------------

.. list-table::

* - .. figure:: /images/subdivide-twoedgesopposite.png
:width: 250px

- .. figure:: /images/subdivide-twoedgesopposite-tri.png
:width: 250px

Quad/Tri Mode.

Two Adjacent Quad Edges
-----------------------

.. list-table::

* - .. figure:: /images/subdivide-twoedgesquad-fan2.png
:width: 250px

Fan cut type.

- .. figure:: /images/subdivide-twoedgesquad-fan.png
:width: 250px

Quad/Tri Mode.

.. list-table::

* - .. figure:: /images/subdivide-twoedgesquad-innervert.png
:width: 250px

Innervert cut type.

- .. figure:: /images/subdivide-twoedgesquad-innervert-tri.png
:width: 250px

Quad/Tri Mode.

.. list-table::

* - .. figure:: /images/subdivide-twoedgesquad-path.png
:width: 250px

Path cut type.

- .. figure:: /images/subdivide-twoedgesquad-path-tri.png
:width: 250px

Quad/Tri Mode.

Three Edges
-----------

.. list-table::

* - .. figure:: /images/subdivide-threeedges.png
:width: 250px

- .. figure:: /images/subdivide-threeedges-tri.png
:width: 250px

Quad/Tri Mode.

Tri
---

.. list-table::

* - .. figure:: /images/subdivide-threeedgestri.png
:width: 250px

- .. figure:: /images/subdivide-threeedgestri-tri.png
:width: 250px

Quad/Tri Mode.

Quad/Four Edges
---------------

.. list-table::

* - .. figure:: /images/subdivide-fouredges.png
:width: 250px

- .. figure:: /images/subdivide-fouredges-tri.png
:width: 250px

Quad/Tri Mode.

Multicut
--------

.. list-table::

* - .. figure:: /images/subdivide-tri-multi.png
:width: 250px

Tri with two cuts.

- .. figure:: /images/subdivide-quad-multi.png
:width: 250px

Quad with two cuts

.. _mesh-unsubdivide:

Un-Subdivide
============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Edges --&gt; Un-Subdivide`

Unsubdivide functions as the reverse of subdivide by attempting to remove edges that were the
result of a subdivide operation.
If additional editing has been done after the subdivide operation,
unexpected results may occur.

Iterations
How many subdivisions to remove.

**************
Vertex Connect
**************

Connect Vertex Path
===================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Connect Vertex Path`
| Hotkey:   :kbd:`J`

This tool connects vertices in the order they are selected, splitting the faces between them.

When there are only two vertices selected, a cut will be made across unselected faces,
a little like the knife tool; however, this is limited to straight cuts across connected faces.

.. list-table::

* - .. figure:: /images/bmesh_connect_verts_pair_before.png

Two disconnected vertices.

- .. figure:: /images/bmesh_connect_verts_pair_after.png

Result of connecting.

Running a second time will connect the first/last endpoints.

When many vertices are selected, faces will be split by their selected vertices.

.. list-table::

* - .. figure:: /images/bmesh_connect_verts_multi_before.png

Before.

- .. figure:: /images/bmesh_connect_verts_multi_after.png

After.

Vertices not connected to any faces will create edges,
so this can be used as a way to quickly connect isolated vertices too.

Connect Vertices
================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Connect Vertices`

This tool connects selected vertices by creating edges between them and splitting the face.

This tool can be used on many faces at once.

.. list-table::

* - .. figure:: /images/modeling_vertexconnect-before.png
:width: 180px

Vertices before connecting.

- .. figure:: /images/modeling_vertexconnect-after.png
:width: 180px

After connecting vertices.

- .. figure:: /images/modeling_vertexconnect-after-faces.png
:width: 180px

Resulting face pair.

The main difference between this tool and `Connect Vertex Path`_,
is this tool ignores selection order and connects all selected vertices that share a face.

****
Bend
****

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Menu:     :menuselection:`Object/Mesh/Curve/Surface --&gt; Transform --&gt; Bend`
| Hotkey:   :kbd:`Shift-W`

.. figure:: /images/modeling_meshes_editing_deforming_bend.jpg

Bend Transform with Clamp on and off.

This tool rotates a line of selected elements forming an arc between the mouse-cursor and the 3D-cursor.

Usage
=====

The bend tool can be used in any case where you might want to bend a shape in two
with a gradual transition between both sides.

This may take a little getting used to, the basics are listed below controls are noted here:

- The initial position of the cursors define the axis to bend on.
- The distance of the mouse-cursor to the 3D-cursor controls how sharp the bend will be.
- The relative angle of the mouse-cursor to the initial axis defines the bend angle.

If this seems overly complicated, its probably best to try the tool where it becomes quickly apparent
how the tool reacts to your input.

Bend Angle
The amount of rotation.
Radius
The sharpness of the bend.
Clamp
Normally the arc turns through a clamped rotation angle with the selected elements extended along a
tangent line beyond that (see above left).
When the clamp is deactivated, the arc continues around aligning the selected elements into a circle (right).

When off :kbd:`Alt` all selected elements follow a circle,
even when outside the segment between the 3D cursor and the mouse.

.. note::

Unlike most other transform modes *Bend* is not effected by *Pivot Point* or *Transform Orientation*,
always using the View Plane instead.

.. hint::

You can turn the bend angle through multiple rotations potentially forming a spiral shape.

##################
Transformation
##################

.. toctree::
:maxdepth: 1

mirror.rst
shrink-fatten.rst
smooth.rst
noise.rst
push_pull.rst
shear.rst
to_sphere.rst
warp.rst
bend.rst
..    TODO/Review: {{review|}}.

******
Mirror
******

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Mirror --&gt; Desired Axis`
| Hotkey:   :kbd:`Ctrl-M`

The mirror tool mirrors a selection across a selected axis.

The mirror tool in *Edit Mode* is similar to
:doc:`Mirroring in Object Mode &lt;/editors/3dview/object/editing/transform/mirror&gt;`.
It is exactly equivalent to scaling by -1 vertices,
edges or faces around one chosen pivot point and in the direction of one chosen axis, only it is faster/handier.

After this tool becomes active, select an axis to mirror the selection
on entering :kbd:`X`, :kbd:`Y`, or :kbd:`Z`.

You can also interactively mirror the geometry by holding the :kbd:`MMB` and dragging in
the direction of the desired mirror direction.

Axis of Symmetry
================

For each transformation orientation,
you can choose one of its axes along which the mirroring will occur.

As you can see, the possibilities are infinite and the freedom complete:
you can position the pivot point at any location around which we want the mirroring to occur,
choose one transformation orientation and then one axis on it.

Pivot Point
===========

:doc:`Pivot points &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;` must be set first.
Pivot points will become the center of symmetry.
If the widget is turned on it will always show where the pivot point is.

In Fig. :ref:`fig-mesh-deform-mirror-center` the pivot point default to
median point of the selection of vertices in *Edit Mode*.
This is a special case of the *Edit Mode* as explained on the
:doc:`pivot point page &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`.

.. _fig-mesh-deform-mirror-center:

.. list-table:: Mirror around the Individual Centers.

* - .. figure:: /images/mirrortool1.jpg
:width: 320px

Mesh before mirror.

- .. figure:: /images/mirrortool2.png
:width: 320px

Mesh after mirrored along X axis.

In Fig. :ref:`fig-mesh-deform-mirror-cursor` the pivot point is the *3D Cursor*,
the transformation orientation is *Local*, a.k.a. the Object space,
and the axis of transformation is X.

.. _fig-mesh-deform-mirror-cursor:

.. list-table:: Mirror around the 3D Cursor.

* - .. figure:: /images/mirrortool3.png
:width: 320px

Mesh before mirror.

- .. figure:: /images/mirrortool4.png
:width: 320px

Mesh after mirrored along X axis using the 3D cursor as a pivot point.

Transformation Orientations
===========================

:doc:`Transformation Orientations &lt;/editors/3dview/object/editing/transform/control/orientations&gt;`
are found on the 3D View header, next to the *Widget* buttons.
They decide which coordinate system will rule the mirroring.

Mirror Vertex Group
===================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Mirror --&gt; Mirror Vertex Group`

This tool works only with a perfectly symmetrical mesh (along the local X axis).
Those vertices that have no corresponding vertex on the other side will not be affected.

Mirror Weights
With this option checked, every selected vertex receives
the group/weight information of its symmetrical counterpart.
If both vertices are selected, it will be a group/weight information exchange;
if only one is selected, information from the unselected will be copied into the selected one,
that loses its own information. Information on group/weight is passed for the active group only,
unless *All Groups* is checked, in which case it is passed for all groups.
Flip Groups Names
Works with selected vertices that belong to vertex groups with "symmetrical names"
(with components like "L", "R", "right", "left").
All selected vertices that belong to the active group, or to the symmetrical of the active group,
will have their assignation to that group replaced by an assignation to the symmetrical one;
however, its weight will be preserved.
All Groups
If *All Groups* is checked, all assignations to these kind of groups
will be replaced by the symmetrical counterpart, also keeping the old weights.
Topology Mirror
Todo.

Usually only one of those operations (*Mirror Weights*, *Flip Groups Names*)
will be performed, though you can tick both at the same time,
if you know what you are doing (these 2 operations could even cancel each other).

*****
Noise
*****

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Deform: Noise`

.. note::

*Noise* is an old feature. The :doc:`Displace Modifier &lt;/modeling/modifiers/deform/displace&gt;`
is a non-destructive alternative to the Noise tool and is a more flexible way to realize these sort of effects.
The key advantages of the modifier are that it can be canceled at any moment,
you can precisely control how much and in which direction the displacement is applied, and much more...

The *Noise* function allows you to displace vertices in a mesh based on the gray
values of the first texture slot of the material applied to the mesh.

The mesh must have a material and a texture assigned to it for this tool to work.
To avoid having the texture affect the material's properties,
it can be disabled in the texture menu.

The *Noise* function displaces vertices along the object's ±Z-Axis only.

*Noise* permanently modifies your mesh according to the material texture.
Each click adds onto the current mesh.
For a temporary effect, map the texture to Displacement for a render-time effect.
In *Object Mode* or *Edit Mode*, your object will appear normal, but will render deformed.

The deformation can be controlled by modifying the *Mapping* panel and/or the
texture's own panel (e.g. *Clouds*, *Marble*, etc.).

.. list-table::

* - .. figure:: /images/modeling_meshes_editing_deforming_noise_example-before.png
:width: 320px

Mesh before noise is added.

- .. figure:: /images/modeling_meshes_editing_deforming_noise_example-after.png
:width: 320px

Mesh after noise is added, using basic cloud texture.

*********
Push/Pull
*********

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Transform --&gt; Push/Pull`
| Menu:     :menuselection:`Object/Mesh --&gt; Transform --&gt; Push Pull`

.. figure:: /images/modeling_meshes_editing_deforming_push-pull_operator-panel.png
:align: right

Push/Pull distance.

*Push/Pull* will move the selected elements (Objects, vertices, edges or faces)
closer together (Push) or further apart (Pull).
Specifically, each element is moved towards or away from the center by the same distance.
This distance is controlled by moving the mouse up (Push) or down (Pull), numeric input or through slider control.

Usage
=====

Select the elements you want to operate on and activate the Push/Pull transform function. The
Push/Pull option can be invoked from the :menuselection:`Object/Mesh --&gt; Transform --&gt; Push/Pull` menu option
or by pressing :kbd:`Spacebar` and using the search menu to search for *Push* or
*Pull*. The amount of movement given to the selection can be determined
interactively by moving the mouse or by typing a number.
Pressing :kbd:`Enter` will confirm the transformation. The confirmed transformation can
be further edited by pressing :kbd:`F6` or by going into the Tool Shelf :kbd:`T` and altering
the Distance slider provided that no other actions take place between the
*Push/Pull* transform confirmation and accessing the slider.

Note that the result of the *Push/Pull* transform is also dependant on the number
and type of selected elements (Objects, vertices, faces etc).
See below for the result of using *Push/Pull* on a number of different elements.

.. figure:: /images/modeling_meshes_editing_deforming_push-pull_objects-equidistant.png

Equidistant Objects being pushed together.

.. figure:: /images/modeling_meshes_editing_deforming_push-pull_objects-random.png

Random Objects being pushed together.

.. figure:: /images/editors_3dview_transformations-advanced-push_pull_vertices-push-pull.png

Vertices being pushed together, then pulled apart.

.. figure:: /images/editors_3dview_transformations-advanced-push_pull_edges-push-pull.png

Edges on separate meshes being pushed together, then pulled apart.

*****
Shear
*****

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Menu:     :menuselection:`Object/Mesh/Curve/Surface --&gt; Transform --&gt; Shear`
| Hotkey:   :kbd:`Shift-Ctrl-Alt-S`

Shearing is a form of movement where parallel surfaces move past one another. During this transform,
movement of the selected elements will occur along the horizontal axis of the current view.
The axis location will be defined by the
:doc:`Pivot Point &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`.
Everything that is "above" this axis will move (Shear)
in the same direction as your mouse pointer (but always parallel to the horizontal axis).
Everything that is "below" the horizontal axis will move in the opposite direction.

.. figure:: /images/modeling_meshes_editing_deforming_shear_operator-panel.png

Shear Offset Factor.

Usage
=====

Select the elements you want to operate on and activate the *Shear* transform
function. The *Shear* option can be invoked from the
:menuselection:`Object/Mesh/Curve/Surface --&gt; Transform --&gt; Shear` menu option or by pressing
:kbd:`Shift-Ctrl-Alt-S`. The amount of movement given to the selection can be determined
interactively by moving the mouse or by typing a number.
Pressing :kbd:`Enter` will confirm the transformation. The confirmed transformation can
be further edited by pressing :kbd:`F6` or by going into the Tool Shelf and altering
the Offset slider provided that no other actions take place between the *Shear*
transform confirmation and accessing the slider.

Note that the result of the *Shear* transform is also dependant on the number and
type of selected elements (Objects, vertices, faces etc).
See below for the result of using *Shear* on a number of different elements.

.. figure:: /images/editors_3dview_transformations-advanced-shear_mesh.png

The effects of a Shear transform with different Pivot Points.
See the text below for additional information.

The three frames of the image above show the effects of shearing on the selected vertices when
the pivot point is altered.
In frame B, the :doc:`Pivot Point &lt;/editors/3dview/object/editing/transform/control/pivot_point/index&gt;`
is set to *Median Point* (indicated by the yellow line)
and the mouse was moved to the left during the transform. In frame C,
the *Pivot Point* is set to the 3D cursor which is located above the mesh
(indicated again by the yellow line). When the mouse is moved to the left during a
*Shear* transform the selected vertices are moved to the right as they are below the horizontal axis.

.. tip:: Shear transform magnitude

The magnitude of the *Shear* transform applied to the selected elements is
directly proportional to the distance from the horizontal axis.
i.e. the further from the axis, the greater the movement.

.. figure:: /images/editors_3dview_transformations-advanced-shear_objects.png

The effects of a Shear transform on Objects with different Pivot Points.
See the text below for additional information.

The three frames of the image above show the effects of shearing on the selected Objects when
the *Pivot Point* is altered. In frame B,
the *Pivot Point* is set to *Median Point* (indicated by the yellow line)
and the mouse was moved to the left during the transform. In frame C,
the *Pivot Point* is set to the 3D cursor which is located above the Objects
(indicated again by the yellow line). When the mouse is moved to the left during a
*Shear* transform all of the selected Objects are moved to the right as they are
below the horizontal axis. Again, note that the magnitude of the transform is proportional to
the distance from the horizontal axis. In this case,
the lower Objects move further than the upper ones.

*************
Shrink Fatten
*************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Transform --&gt; Shrink/Fatten`
| Menu:     :menuselection:`Mesh --&gt; Transform --&gt; Shrink/Fatten`
| Hotkey:   :kbd:`Alt-S`

This tool translates selected vertices/edges/faces along their own normal
(perpendicular to the face), which, on "standard normal meshes", will shrink/fatten them.

This transform tool does not take into account the pivot point or transform orientation.

.. list-table::

* - .. figure:: /images/shrinkflatten1.png
:width: 200px

Mesh before shrink/flatten.

- .. figure:: /images/shrinkflatten2.png
:width: 200px

Inflated using a positive value.

- .. figure:: /images/shrinkflatten3.png
:width: 200px

Shrunk using a negative value.

******
Smooth
******

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Deform: Smooth Vertex`
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Smooth Vertex`

This tool smooths the selected components by averaging the angles between faces.
After using the tool, options appear in the *Tool Shelf*:

Number of times to smooth
The number of smoothing iterations
Axes
Limit the effect to certain axes.

.. list-table::

* - .. figure:: /images/smoothvertex1.png
:width: 200px

Mesh before smoothing.

- .. figure:: /images/smoothvertex2.png
:width: 200px

Mesh after one smoothing iteration.

- .. figure:: /images/smoothvertex3.png
:width: 200px

Mesh after ten smoothing iterations.

Laplacian Smooth
================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Specials --&gt; Laplacian Smooth`

See the :doc:`Laplacian Smooth Modifier &lt;/modeling/modifiers/deform/laplacian_smooth&gt;` for details.

Laplacian smooth is uses an alternative smoothing algorithm that better preserves the overall
mesh shape. Laplacian smooth exists as a mesh operation and as a non-destructive modifier.

.. note::

The :doc:`Smooth Modifier &lt;/modeling/modifiers/deform/smooth&gt;`, which can be limited to a *Vertex Group*,
is a non-destructive alternative to the smooth tool.

.. note:: Real Smoothing versus Shading Smoothing

Do not mistake this tool with the shading smoothing options described at
:doc:`this page &lt;/modeling/meshes/editing/smoothing&gt;`, they do not work the same!
This tool modifies the mesh itself, to reduce its sharpness, whereas *Set Smooth* / *AutoSmooth* and co.
only control the way the mesh is shaded,
creating an *illusion* of softness, but without modifying the mesh at all...

*********
To Sphere
*********

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Transform --&gt; To Sphere`
| Hotkey:   :kbd:`Shift-Alt-S`

The *To Sphere* transformation will give the selection spherical qualities. The
Fig. :ref:`fig-mesh-deform-to-sphere-monkey` below shows the results of applying the
*To Sphere* transformation to the monkey mesh.

.. _fig-mesh-deform-to-sphere-monkey:

.. figure:: /images/editors_3dview_transformations-advanced-to_sphere_suzanne-spherical.jpg

Monkey with increasing sphericity.

The sequence above shows a monkey mesh with a
0, 0.25 (25%), 0.5 (50%) and 1 (100%) To Sphere transform applied.

Usage
=====

.. figure:: /images/modeling_meshes_editing_deforming_to-sphere_operator-panel.png

To Sphere Factor.

Select the elements you want to operate on and activate the *To Sphere* transform function.
The *To Sphere* option can be invoked from the :menuselection:`Mesh --&gt; Transform --&gt; To Sphere`
menu option or by pressing :kbd:`Shift-Alt-S`. The amount of sphericity given
to the selection can be determined interactively by moving the mouse or by typing a number
between 0 and 1. Pressing :kbd:`Enter` will confirm the transformation.
The confirmed transformation can be further edited by pressing :kbd:`F6`
or by going into the *Tool Shelf* and altering the *Factor* slider provided
that no other actions take place between the *To Sphere* transform confirmation and
accessing the slider.

Note that the result of the *To Sphere* transform is also dependant on the number of
selected mesh elements (vertices, faces etc). As can be seen in the below image, the result
will be smoother and more spherical when there are more mesh elements available to work with.

.. figure:: /images/editors_3dview_transformations-advanced-to_sphere_cubes-spherical.jpg

To Sphere applied to cubes with different subdivision levels.

In this image sequence, To Sphere was applied to the entire cube
at levels of 0, 0.25 (25%), 0.5 (50%) and 1 (100%) respectively.

The *To Sphere* transform will generate different results depending on the number
and arrangement of elements that were selected (as shown by the below image).

.. figure:: /images/editors_3dview_transformations-advanced-to_sphere_other-spherical.jpg

To Sphere applied to different selections.

****
Warp
****

.. admonition:: Reference
:class: refbox

| Mode:     Object and Edit Modes
| Menu:     :menuselection:`Object/Mesh/Curve/Surface --&gt; Transform --&gt; Warp`

.. figure:: /images/modeling_meshes_editing_deforming_warp_operator-panel.png
:align: right

Warp tool options.

In *Edit Mode*, the *Warp* transformation takes selected elements and
warps them around the 3D cursor by a certain angle.
Note that this transformation is always dependent on the location of the 3D cursor.
The Pivot Point is not taken into account.
The results of the *Warp* transformation are also view dependent.

In *Object Mode*, the *Warp* transformation takes the selected Objects and
causes them to move in an orbit-like fashion around the 3D cursor.
Similar to *Edit Mode*,
the Pivot Point is not taken into account and the results are view dependent.

.. TODO: there is no Warp in Object Mode, maybe Bend?

Usage
=====

.. figure:: /images/editors_3dview_transformation_advanced_warp_warp-mesh.png

In this example, a plane is warped around the 3D cursor by the indicated number of degrees.

Select the elements you want to operate on and activate the *Warp* transform function.
The *Warp* option can be invoked from the
:menuselection:`Object/Mesh/Curve/Surface --&gt; Transform --&gt; Warp` menu option.
The amount of warping given to the selection can be determined
interactively by moving the mouse or by typing a number. Pressing :kbd:`Enter`
will confirm the transformation. The confirmed transformation can
be further edited by pressing :kbd:`F6` or by going into the Tool Shelf
and altering the Angle slider provided that no other actions take place between the
*Warp* transform confirmation and accessing the slider.

Cursor position and view
------------------------

The location of the 3D cursor can be used to alter the results of the *Warp*
transformation. As can be seen from the example in this section, the *Warp* radius
is dependent on the distance of the cursor from the selected elements.
The greater the distance, the greater the radius.

The result of the *Warp* transform is also influenced by your current view. The
example in this section shows the results of a 180 degree *Warp* transform applied
to the same Suzanne mesh when in different views. A 3D render is also provided for comparison.

.. figure:: /images/editors_3dview_transformation_advanced_warp_warp-cursor-view.jpg

The left side of this image shows how the Warp transform is influenced by the location of the cursor.
The right hand side shows the influence of the current view.

.. note:: Warping text

If you want to warp text, you will need to convert it from a Text Object to Mesh
by pressing :kbd:`Alt-C` and selecting the *Mesh from Curve/Meta/Surf/Text* option.

Example
=======

.. figure:: /images/editors_3dview_transformation_advanced_warp_warp-text.jpg

Text wrapped around logo.

This was made by creating the Blender logo and text as separate Objects.
The text was converted to a mesh and then warped around the Blender logo.

************
Vertex Tools
************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices`
| Hotkey:   :kbd:`Ctrl-V`

This page covers many of the tools in the :menuselection:`Mesh --&gt; Vertices` menu.
These are tools that work primarily on vertex selections, however,
some also work with edge or face selections.

.. _vertex-merging:

Merging
=======

Merging Vertices
----------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Remove: Merge`
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Merge...`,
:menuselection:`Specials --&gt; Merge`
| Hotkey:   :kbd:`Alt-M`

This tool allows you to merge all selected vertices to a unique one, dissolving all others.
You can choose the location of the surviving vertex in the menu this tool pops up before
executing:

At First
Only available in *Vertex* select mode,
it will place the remaining vertex at the location of the first one selected.
At Last
Only available in *Vertex* select mode,
it will place the remaining vertex at the location of the last one selected (the active one).
At Center
Available in all select modes,
it will place the remaining vertex at the center of the selection.
At Cursor
Available in all select modes,
it will place the remaining vertex at the 3D Cursor.
Collapse
Every island of selected vertices (connected by selected edges) will merge on its own median center,
leaving one vertex per island.
It is also available *via* the :menuselection:`Mesh --&gt; Edges --&gt; Collapse` menu option...

Merging vertices of course also deletes some edges and faces. But Blender will do everything
it can to preserve edges and faces only partly involved in the reunion.

.. note::

*At First* and *At Last* depend on that the selection order is saved:
the order is lost, for instance, after changing selection mode.

UVs
If *UVs* is ticked in the Operator panel, the UV mapping coordinates,
if existing, will be corrected to avoid image distortion.

AutoMerge Editing
-----------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; AutoMerge Editing`

The *Mesh* menu as a related toggle option: *AutoMerge Editing*.
When enabled,
as soon as a vertex moves closer to another one than the *Limit* setting
(:menuselection:`Mesh Tools panel --&gt; Double Threshold`), they are automatically merged.
This option affects interactive operations only (tweaks made in the Operator panel are considered interactive too).
If the exact spot where a vertex is moved contains more than one vertex,
then the merge will be performed between the moved vertex and one of those.

Remove Doubles
--------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Remove: Remove Doubles`
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Remove Doubles`,
:menuselection:`Specials --&gt; Remove Doubles`

Remove Doubles is a useful tool to simplify a mesh by merging the selected vertices that
are closer than a specified distance to each other.
An alternate way to simplify a mesh is to use the :doc:`Decimate Modifier &lt;/modeling/modifiers/generate/decimate&gt;`.

Merge Distance
Sets the distance threshold for merging vertices, in Blender units.
Unselected
Allows vertices in selection to be merged with unselected vertices.
When disabled, selected vertices will only be merged with other selected ones.

Separating
==========

Rip
---

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Rip`
| Hotkey:   :kbd:`V`

Rip creates a "hole" into a mesh by making a copy of selected vertices and edges,
still linked to the neighbor non-selected vertices,
so that the new edges are borders of the faces on one side, and the old ones,
borders of the faces of the other side of the rip.

Examples
^^^^^^^^

.. list-table::

* - .. figure:: /images/rip-before.png
:width: 320px

Selected vertex.

- .. figure:: /images/rip-after.png
:width: 320px

Hole created after using rip on vertex.

* - .. figure:: /images/rip-edges-before.png
:width: 320px

Edges selected.

- .. figure:: /images/rip-edges-after.png
:width: 320px

Result of rip with edge selection.

* - .. figure:: /images/rip-complexselection-before.png
:width: 320px

A complex selection of vertices.

- .. figure:: /images/rip-complexselection-after.png
:width: 320px

Result of rip operation.

Limitations
^^^^^^^^^^^

Rip will only work when edges and/or vertices are selected.
Using the tool when a face is selected (explicitly or implicitly), will return an error
message *"Cannot perform ripping with faces selected this way"*
If your selection includes some edges or vertices that are not "between" two faces :term:`manifold`,
it will also fail with message *"No proper selection or faces include"*.

Rip Fill
--------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Rip Fill`
| Hotkey:   :kbd:`Alt-V`

Rip fill works the same as the Rip tool above, but instead of leaving a hole,
it fills in the gap with geometry.

.. list-table::

* - .. figure:: /images/rip-edges-before.png
:width: 320px

Edges selected.

- .. figure:: /images/ripfill-result.png
:width: 320px

Result of rip fill.

Split
-----

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Split`
| Hotkey:   :kbd:`Y`

Splits (disconnects) the selection from the rest of the mesh.
The border edge to any non-selected elements are duplicated.

Note that the "copy" is left exactly at the same position as the original, so you must move it
:kbd:`G` to see it clearly...

Extend Vertices
----------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Extend Vertices`
| Hotkey:   :kbd:`Alt-D`

This tool takes any number of selected vertices and duplicate-drags them along the closest edge to the mouse,
When extending an edge loop, it extends the vertices at the endpoints of the loop.
Which is similar behavior like *Extrude* tool, but it creates a n-gon.

It helps to easily add details to existing edges.

Separate
--------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Separate`
| Hotkey:   :kbd:`P`

The Separate tool will `Split`_ mesh elements in another mesh object.

Selection
Separates the selected elements.
By Material
Separates fragments based on the materials assigned to the different faces.
By loose parts
Creates one object for every independent (disconnected) fragment of the original mesh.

Vertex Slide
============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Deform: Vertex`
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Vertex Slide`
| Hotkey:   :kbd:`Shift-V`

Vertex Slide will transform a vertex along one of its adjacent edges.
Use :kbd:`Shift-V` to enter tool. Highlight the desired edge by moving the mouse,
then confirm with :kbd:`LMB`.
Drag the cursor to specify the position along the line formed by the edge,
then :kbd:`LMB` again to move the vertex.

Even :kbd:`E`
ToDo.
Flip :kbd:`F`
ToDo.
Clamp :kbd:`Alt` or :kbd:`C`
Toggle clamping the slide within the edge extents.

.. list-table::

* - .. figure:: /images/modeling_vertexslide1.png
:width: 200px

Selected vertex.

- .. figure:: /images/modeling_vertexslide2.png
:width: 200px

Positioning vertex interactively.

- .. figure:: /images/modeling_vertexslide3.png
:width: 200px

Repositioned vertex.

Smooth Vertex
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Mesh Tools --&gt; Deform: Smooth Vertex`
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Smooth Vertex`,
:menuselection:`Specials --&gt; Smooth`

This will apply once the :doc:`Smooth Tool &lt;/modeling/meshes/editing/transform/smooth&gt;`.

.. (todo) images from https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.64/BMesh

Convex Hull
============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Convex Hull`

The Convex Hull operator takes a point cloud as input and outputs a convex hull surrounding those vertices.
If the input contains edges or faces that lie on the convex hull, they can be used in the output as well.
This operator can be used as a bridge tool as well.

Delete Unused
Removes vertices, edges, and faces that were selected, but not used as part of the hull.
Note that vertices and edges that are used
by other edges and faces not part of the selection will not be deleted.
Use Existing Faces
Where possible, use existing input faces that lie on the hull.
This allows the convex hull output to contain n-gons rather than triangles
(or quads if the *Join Triangles* option is enabled.)
Make Holes
Delete edges and faces in the hull that were part of the input too.
Useful in cases like bridging to delete faces between the existing mesh and the convex hull.
Join Triangles
Joins adjacent triangles into quads.
Has all the same properties as the *Tris to Quads* operator (angle limit, compare UVs, etc.)
Max Face Angle
ToDo.
Max Shape Angle
ToDo.

Make Vertex Parent
==================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Make Vertex Parent`
| Hotkey:   :kbd:`Ctrl-P`

This will parent the other selected object(s) to the vertices/edges/faces selected,
as described :doc:`here &lt;/editors/3dview/object/properties/relations/parents&gt;`.

Add Hook
========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Mesh --&gt; Vertices --&gt; Add Hook`
| Hotkey:   :kbd:`Ctrl-H`

Adds a :doc:`Hook Modifier &lt;/modeling/modifiers/deform/hooks&gt;` (using either a new empty,
or the current selected object) linked to the selection.
Note that even if it appears in the history menu,
this action cannot be undone in *Edit Mode* -- because it involves other objects...

When the current object has no hooks associated, only the 2 first options will appear on the menu.

Hook to New Object
Creates a new Hook Modifier for the active object and assigns it to the selected vertices;
it also creates an empty at the center of those vertices, which are hooked to it.
Hook to Selected Object
Does the same as *Hook to New Object*, but instead of hooking the vertices to a new empty,
it hooks them to the selected object (if it exists).
There should be only one selected object (besides the mesh being edited).
Hook to Selected Object Bone
Does the same as *Hook to New Object*,
but it sets the last selected bone in the also selected armature as a target.
Assign to Hook
The selected vertices are assigned to the chosen hook. For that to happen,
a list of the hooks associated to the object is displayed.
All the unselected vertices are removed from it (if they were assigned to that particular hook).
One vertex can be assigned to more than one hook.
Remove Hook
Removes the chosen hook (from the displayed list) from the object:
the specific Hook Modifier is removed from the modifier stack.
Select Hook
Selects all vertices assigned to the chosen hook (from the hook list).
Reset Hook
It's equivalent to the *Reset* button of the specific Hook Modifier (chosen from the hook list).
Recenter Hook
It's equivalent to the *Recenter* button of the specific Hook Modifier (chosen from the hook list).

.. _modeling-meshes-editing-vertices-shape-keys:

Blend From Shape, Propagate Shapes
==================================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`(Vertex) Specials --&gt; Blend From Shape` and
:menuselection:`Mesh --&gt; Vertices --&gt; Shape Propagate`

These are options regarding :doc:`shape keys &lt;/animation/shape_keys/index&gt;`.

Shape Propagate
Apply selected vertex locations to all other shape keys.
Blend From Shape
Blend in the shape from a shape key.

#########
Meshes
#########

.. toctree::
:maxdepth: 2

introduction.rst
structure.rst
primitives.rst
selecting/index.rst
editing/index.rst
properties/index.rst
mesh_display.rst
mesh_analysis.rst
..    TODO/Review:

************
Introduction
************

Mesh Modeling typically begins with a
:doc:`Mesh Primitive &lt;/modeling/meshes/primitives&gt;` shape (e.g. circle, cube, cylinder...).
From there you might begin editing to create a larger, more complex shape.

Modeling Modes
==============

The 3D View has three principal modes that allow for the creation of,
editing and manipulation of the mesh models.
Each of the three modes have a variety of tools. Some tools may be found in one or more of the modes.

Modes that used for modeling:

- Object Mode
- Edit Mode
- Sculpt Mode

Creation of a mesh primitive typically starts by adding a mesh object in *Object Mode*.
Limited types of editing such as size, location, and orientation can be accomplished in *Object Mode*.
*Object Mode* also provides the means to Join and Group multiple mesh primitives.

More detailed editing of the mesh model shape is done in *Edit Mode*, and *Sculpt Mode*.
The nature of these three modes determines the tools that are available
within the various panels of the 3D View. Switching between modes while modeling is common.
Some tools may be available in more than one mode while others may be unique to a particular mode.

You can work with geometric objects in two modes.

Object Mode
-----------

:doc:`Object Mode &lt;/editors/3dview/object/editing/transform/introduction&gt;`
Operations in *Object Mode* affect the whole object.
*Object Mode* has the following header in the 3D View:

.. figure:: /images/modeling_meshes_introduction_3d-view-header-object-mode.png

Object Mode Header.

Edit Mode
---------

Operations in *Edit Mode* affect only the geometry of an object,
but not global properties such as location or rotation.

You can only modify the mesh of the object you are editing.
To modify other objects you need to leave, select them and re-enter Edit Mode.

*Edit Mode* has the following header in the 3D View:

.. figure:: /images/modeling_meshes_introduction_3d-view-header-edit-mode.png

Edit Mode Header.

Tools and modes in the 3D View header are (left to right):

- View, Select, and Mesh menus
- Blender Mode
- Display method for 3D View
- Pivot center
- 3D manipulator widget
- Selection mode
- Limit Selection to Visible
- Proportional editing
- Snap
- OpenGL render

You can switch between the Object and Edit Modes with :kbd:`Tab`.
You can change to any mode by selecting the desired *Mode* in the menu in the 3D View header.

Visualization
=============

.. list-table::

* - .. figure:: /images/editmode-cubeselect-1.png
:width: 315px

One cube selected.

- .. figure:: /images/editmode-cubeselect-2.png
:width: 315px

Two cubes selected before entering Edit Mode.

By default, Blender highlights selected geometry in orange in both *Object Mode* and *Edit Mode*.

In *Object Mode* with *Wireframe* shading enabled :kbd:`Z`,
objects are displayed in black when unselected and in orange when selected.
If more than one object is selected, all selected objects except the active object,
typically the object last selected, are displayed in a darker orange color.

Similarly, in *Edit Mode*, unselected geometry is drawn in black while selected faces, edges,
or vertices are drawn in orange. The active face is highlighted in white.
If two vertices joined by an edge are selected in *Vertex selection mode*,
the edge between them is highlighted too. Similarly,
if enough vertices or edges are selected to define a face, that face is also highlighted.

If multiple objects are selected before entering *Edit Mode*,
all the selected objects remain highlighted in orange indicating that they are part of the active selection set.

Tool Shelf
==========

.. figure:: /images/modeling_meshes_introduction_tool-shelf-region.png

The Tool Shelf panel in edit mode.

Open/close the *Mesh Tools* panel using :kbd:`T`.
When entering *Edit Mode*, several mesh tools become available.

Most of these tools are also available as shortcuts
(displayed in the *Tooltips* for each tool) and/or in the *Specials* menu
:kbd:`W`, the *Edge* menu :kbd:`Ctrl-E`, and *Face* menu :kbd:`Ctrl-F`.
The properties of each tool are displayed in the operator panel at the bottom of the *Tool Shelf*.

Even more mesh editing tools can be enabled in the :menuselection:`User Preferences --&gt; Add-ons`.

Properties Region
=================

.. figure:: /images/modeling_meshes_introduction_properties-region.png

The Properties region in edit mode.

Open/close the *Properties region* using :kbd:`N`.

In the *Properties region*,
panels directly related to mesh editing are the *Transform* panel,
where numeric values can be entered, and the *Mesh Display* panel,
where for example normals and numeric values for distances, angles,
and areas can be turned on.

Other useful tools are found in the *Properties Editor* under the
*Object* and *Object Data* tabs,
including display options and *Vertex groups*.
..    TODO/Review: {{review|split=X|text=splitted mesh - mesh analysis}}.

*************
Mesh Analysis
*************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:     :menuselection:`Properties region --&gt; Mesh Analysis`

Mesh analysis is useful for displaying attributes of the mesh,
that may impact certain use cases.

The mesh analysis works in *Edit Mode* and *Solid* Viewport shading.
It shows areas with a high value in red, and areas with a low value in blue.
Geometry outside the range is displayed gray.

Currently the different modes target 3D-printing as their primary use.

.. warning::

There are some known limitations with mesh analysis:

- Currently only displayed with Deform Modifiers.
- For high-poly meshes is slow to use while editing the mesh.

Overhang
========

Extrusion 3D printers have a physical limit to the overhang that can be printed,
this display mode shows the overhang with angle range and axis selection.

.. figure:: /images/modeling_meshes_mesh-analysis_overhang.png
:width: 350px
:align: center

Overhang.

Thickness
=========

Printers have a limited *wall-thickness* where very thin areas cannot be printed,
this test uses ray casting and a distance range to the thickness of the geometry.

.. figure:: /images/modeling_meshes_mesh-analysis_thickness.png
:width: 400px
:align: center

Thickness.

Intersections
=============

Another common cause of problems for printing are intersections between surfaces,
where the inside/outside of a model cannot be reliably detected.

Unlike other display modes, intersections have no variance and are either on or off.

.. figure:: /images/modeling_meshes_mesh-analysis_intersections.png
:width: 400px
:align: center

Intersecting faces.

Distortion
==========

Distorted geometry can cause problems since the triangulation of a distorted n-gon is undefined.

Distortion is measured by faces which are not flat,
with parts of the face pointing in different directions.

.. figure:: /images/modeling_meshes_mesh-analysis_distortion.png
:width: 300px
:align: center

Distorted Faces.

Sharp Edges
===========

Similar to wall-thickness, sharp edges can form shapes that are too thin to be able to print.

.. figure:: /images/modeling_meshes_mesh-analysis_sharp-edges.png
:width: 350px
:align: center

Sharp edges.

************
Mesh Display
************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:     :menuselection:`Properties region --&gt; Mesh Display`

.. figure:: /images/modeling_meshes_display.png
:align: right

Mesh Display Panel.

This panel is available only in edit mode, when the object being edited is a mesh.

Overlays
========

The Overlays section provides controls for highlighting parts of the mesh.

Edges
Toggles the option to see the selected edges highlighted.
If enabled the edges that have both vertices selected will be highlighted.
This only affects in vertex selection mode and when
:doc:`UV Unwrapping &lt;/editors/uv_image/uv_editing/unwrapping/seams&gt;`.
Faces
Defines if the selected faces will be highlighted in the
:doc:`3D View &lt;/editors/3dview/properties/index&gt;`.
This affects all selection modes.
Creases and Bevel Weight
Highlights edges marked with a crease weight for the
:doc:`Subdivision Surface Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`
and/or a bevel weight for the :doc:`Bevel Modifier &lt;/modeling/modifiers/generate/bevel&gt;`,
respectively. In both cases, the higher the weight, the brighter the highlight.
Seams and Sharp
Highlights edges marked as a UV seam for unwrapping and/or sharp edges for the
:doc:`Edge Split Modifier &lt;/modeling/modifiers/generate/edge_split&gt;`
Edge Marks and Face Marks
Used by Freestyle.

Show Weight
Displays the vertex weights as a texture.

.. _mesh-display-normals:

Normals
=======

Show
Displays the normals of faces and/or vertices using the Face and Vertex checkboxes.

Vertex, Loop, Face
Size
You can also change the length of the axis that points the direction of the normal.

Show Extra
==========

Numerical measures of the selected elements on screen.
The :ref:`data-scenes-props-units` can be set in the Scene tab.

Edge Length and Edge Angle
Shows the length and angle of the selected edges.
Face Area and Face Angle
Show the area and angles of the selected faces.
..    TODO/Review: {{review|}}.

**********
Primitives
**********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Create --&gt; Add Primitive/Mesh`
| Menu:     :menuselection:`Add --&gt; Mesh`
| Hotkey:   :kbd:`Shift-A`

A common object type used in a 3D scene is a mesh.
Blender comes with a number of "primitive" mesh shapes that you can start modeling from.
You can also add primitives in Edit Mode at the 3D cursor.

.. figure:: /images/editors_3dview_objects_types_primitives.png

Blender's standard primitives.

.. note:: Note about planar primitives

You can make a planar mesh three-dimensional by moving one or more of the vertices out of its plane
(applies to *Plane*, *Circle* and *Grid*).
A simple circle is actually often used as a starting point to create even the most complex of meshes.

.. hint::

When you are modeling, that, in order to facilitate the modeling,
the best solution is to imagine what primitive type suits better for your model.
If you will model a cuboid, the best solution is to start with a primitive cube, and so on.

Common Options
==============

These options can be specified in the Operator panel in the *Tool Shelf*,
which appears when the object is created.
Options included in more than one primitive are:

Generate UVs
Generates a default UV-unwrapping of new geometry.
This will be defined in the first UVLayer (which will get added if needed).
(available for plane, cube, circle, UV-/icosphere, tube and cone).
Radius/Size, Align to View, Location, Rotation
See :ref:`Common Object Options &lt;object-common-options&gt;`.

Plane
=====

The standard plane is a single quad face, which is composed out of four vertices, four edges, and one face.
It is like a piece of paper lying on a table;
it is not a three-dimensional object because it is flat and has no thickness.
Objects that can be created with planes include floors, tabletops, or mirrors.

Cube
====

A standard cube contains eight vertices, twelve edges, and six faces,
and is a three-dimensional object. Objects that can be created out of cubes include dice,
boxes, or crates.

Circle
======

Vertices
The number of vertices that define the circle or polygon.
Fill Type
Set how the circle will be filled.

Triangle Fan
Fill with triangular faces which share a vertex in the middle.
N-gon
Fill with a single :term:`n-gon`.
Nothing
Do not fill. Creates only the outer ring of vertices.

UV Sphere
=========

A standard UV sphere is made out of quad faces and a triangle fan at the top and bottom.
It can be used for texturing.

Segments
Number of vertical segments. Like the Earth's meridians, going pole to pole.
Rings
Number of horizontal segments. These are like the Earth's parallels.

.. note::

Rings are face loops and not edge loops, which would be one less.

Icosphere
=========

An icosphere is a polyhedra sphere made up of triangles.
Icospheres are normally used to achieve a more isotropical layout of
vertices than a UV sphere.

Subdivisions
How many recursions are used to define the sphere.
At level 1 the Icosphere is an icosahedron, a solid with 20 equilateral triangular faces.
Any increasing level of subdivision splits each triangular face into four triangles.

.. note::

Subdividing an icosphere rises the vertex count very high even with few iterations
(10 times creates 5,242,880 triangles),
Adding such a dense mesh is a sure way to cause the program to crash.

Cylinder
========

Objects that can be created out of cylinders include handles or rods.

Vertices
The number of vertical edges between the circles used to define the cylinder or prism.
Depth
Sets the starting height of the cylinder.

Cap Fill Type
Similar to circle (see above). When set to none, the created object will be a tube.
Objects that can be created out of tubes include pipes or drinking glasses
(the basic difference between a cylinder and a tube is that the former has closed ends).

Cone
====

Objects that can be created out of cones include spikes or pointed hats.

Vertices
The number of vertical edges between the circles or tip, used to define the cone or pyramid.
Radius 1
Sets the radius of the circular base of the cone.
Radius 2
Sets the radius of the tip of the cone. which will creates a frustum.
A value of 0 will produce a standard cone shape.
Depth
Sets the starting height of the cone.

Base Fill Type
Similar to circle (see above).

Torus
=====

A dough-nut-shaped primitive created by rotating a circle around an axis.
The overall dimensions can be defined by two methods.

Operator Presets
Torus preset settings for reuse. These presets are stored as scripts in the proper presets directory.
Major Segments
Number of segments for the main ring of the torus.
If you think of a torus as a "spin" operation around an axis, this is how many steps in the spin.
Minor segments
Number of segments for the minor ring of the torus.
This is the number of vertices of each circular segment.

Torus Dimensions
----------------

Add Mode
Change the way the torus is defined.

Major/Minor, Exterior/Interior

Major Radius
Radius from the origin to the center of the cross sections.
Minor Radius
Radius of the torus's cross section.

Exterior Radius
If viewed along the major axis,
this is the radius from the center to the outer edge.
Interior Radius
If viewed along the major axis,
this is the radius of the hole in the center.

Grid
====

A regular quadratic grid which is a subdivided plane.
Example objects that can be created out of grids include landscapes
and organic surfaces.

X Subdivisions
The number of spans in the X axis.
Y Subdivisions
The number of spans in the Y axis.

Monkey
======

This is a gift from old NaN to the community and is seen as a programmer's joke or "Easter
Egg". It creates a monkey's head once you press the *Monkey* button.
The Monkey's name is "Suzanne" and is Blender's mascot.
Suzanne is very useful as a standard test mesh,
much like the `Utah Tea Pot &lt;https://en.wikipedia.org/wiki/Utah_teapot&gt;`__
or the `Stanford Bunny &lt;https://en.wikipedia.org/wiki/Stanford_Bunny&gt;`__.

.. note:: Add-ons

In addition to the basic geometric primitives, Blender has a number of script
generated meshes to offer as pre-installed add-ons. These become available when
enabled in the :doc:`User Preferences &lt;/preferences/addons&gt;` (filter by *Add Mesh*).

##############
Properties
##############

.. toctree::
:maxdepth: 2

object_data.rst
vertex_groups/index.rst

***********
Object Data
***********

Meshes
The mesh :ref:`Data-Block Menu &lt;ui-data-block&gt;` can be used to link the data between objects.

.. _mesh-data-normals:

Normals
=======

.. figure:: /images/modeling_meshes_properties_object-data_normals-panel.png

Normals panel

Auto Smooth
Edges where an angle between the faces is smaller than specified in the *Angle* button will be smoothed,
when shading of these parts of the mesh is set to smooth.

Angle
Angle number button.

Double Sided
Lighting with positive normals on the backside of the mesh in the viewport (OpenGL).

Example
-------

.. figure:: /images/modeling_meshes_editing_smoothing_example-03-auto-smooth.png
:width: 250px

Example mesh with *Auto Smooth* enabled.

.. _properties-texture-space:

Texture Space
=============

.. (todo) object --&gt; transform --&gt; tex space

These are settings of the texture space used by the generated texture mapping.
The visualization of the texture space can be activated in the :doc:`/editors/3dview/object/properties/display`.

Texture Mesh
.. Au: too buggy to doc? transformation in vertex leads to distortion.

Auto Texture Space
Location, Size

Vertex Groups
=============

See :doc:`/modeling/meshes/properties/vertex_groups/vertex_groups`.

TODO.

Shape Keys
==========

See :doc:`/animation/shape_keys/shape_keys_panel`.

TODO.

UV Maps
=======

See :ref:`uv-maps-panel`.

TODO.

Vertex Colors
=============

TODO.

Geometry Data
=============

TODO.

************************
Assigning a Vertex Group
************************

Creating Vertex Groups
======================

.. figure:: /images/modeling-meshes-vertex-group-panel-empty.png
:align: right

Empty Vertex Group Panel.

Vertex Groups are maintained within the *Mesh* tab (1) in the Properties Editor.
As long as no Vertex groups are defined (the default for new Mesh Objects),
the Panel is empty (2).

You create a vertex group by :kbd:`LMB` on the *Add* button (+) on the right Panel
border (3). Initially the group is named "Group"
(or "Group.nnn" when the name already exists) and gets displayed in the Panel (2)
(see next image).

.. container:: lead

.. clear

Vertex Groups Panel Controls
----------------------------

.. figure:: /images/modeling-meshes-vertex-group-panel-one.jpg
:align: right

One Vertex Group.

Once a new Vertex Group has been added, the new Group appears in the
vertex Groups panel. There you find three clickable elements:

Group Name
The Groupname can be changed by double clicking :kbd:`LMB` on the name itself.
Then you can edit the name as you like.

Plus Icon
When the little icon in the left lower corner can be clicked, a new
row opens up where you can enter a search term. This becomes handy when
the number of vertex groups gets big.

Drag Handle
If you have a large number of vertex groups and you want to see more
then a few Groups, you can :kbd:`LMB` on the small drag handle to tear
the vertex groups list larger or smaller.

Active Group
When a Vertex Group is created,
then it is also automatically marked as the *Active Group*.
This is indicated by setting the background of the panel entry
to a light blue color. If you have two or more groups in the list,
then you can change the active group by :kbd:`LMB` on the
corresponding entry in the Vertex Group panel.

Deleting Vertex Groups
======================

.. figure:: /images/modeling-meshes-vertex-group-panel-dg.png
:align: right

Delete a Vertex Group.

You delete a Vertex Group by first making it the active group
(select it in the panel) and then :kbd:`LMB`
the *Remove* button (-) at the right Panel border.

Deleting a Vertex Group only deletes the vertex assignments to the Group.
The vertices themselves are not deleted.

Locking Vertex Groups
=====================

.. figure:: /images/modeling-meshes-vertex-group-panel-lg.png
:align: right

Lock a Vertex Group.

Right after creation of a Vertex Group,
an open padlock icon shows up on the right side of the Vertex Group List entry.
This icon indicates that the Vertex Group can be edited.
You can add vertex assignments to the group or remove assignments from the group.
And you can change it with the weight paint brushes, etc.

When you click on the icon,
it changes to a closed padlock icon and all vertex group modifications get disabled.
You can only rename or delete the group, and unlock it again.
No other operations are allowed on locked Vertex Groups,
thus all corresponding function buttons become disabled for locked Vertex Groups.

Working with Content of Vertex Groups
=====================================

Assigning Vertices to a Group
-----------------------------

.. figure:: /images/modeling-meshes-vertex-group-panel-assign.png
:align: right

Assign weights to active group.

You add vertices to a group as follows:

- Select the group from the group list, thus make it the Active Group (1).
- From the 3D View select :kbd:`Shift-RMB` all vertices that you want to add to the group.
- Set the weight value that shall be assigned to all selected vertices (2).
- :kbd:`LMB` the *Assign* button to assign the selected vertices to the active group using the given weight (3).

Note that weight Assignment is not available for locked Vertex Groups.
The Assign button is grayed out in that case.

.. note:: Assign is additive

The *Assign* button only adds the currently
selected vertices to the active group. Vertices already
assigned to the group are not removed from the group.

Also keep in mind that a vertex can be assigned to multiple groups.

Checking Assignments
--------------------

To be sure the selected vertices are in the desired Vertex Group,
you can try press the deselect button.
If the vertices remain selected then they are not yet in the current Vertex Group.

At this point you may assign then, but take care since all selected vertices
will have their weight set to the value in the *Weight:* field.

Removing Assignments from a Group
---------------------------------

You remove vertices from a group as follows:

- Select the group from the group list (make it the active group).
- Select all vertices that you want to remove from the group.
- Press the *Remove* button.

Note that Removing weight Assignments is not available for locked Vertex Groups.
The Remove button is grayed out in that case.

Using Groups for Selecting/Deselecting
--------------------------------------

You can quickly select all assigned vertices of a group:

- (optionally) press :kbd:`A` once or twice to unselect all vertices.
- Select the group from the group list (make it the active group).
- When you now :kbd:`LMB` click the *Select* button,
then the vertices assigned to the active group will be selected and highlighted in the 3D View.
- When you :kbd:`LMB` click the *Deselect* button instead,
then the vertices assigned to the active group will be deselected in the 3D View.

.. note:: Selecting/Deselecting is additive

If you already have vertices selected in the 3D View,
then selecting the vertices of a group will add the vertices
but also keep the already-selected vertices selected.
Vice versa, deselecting the vertices of a vertex group
will only deselect the vertices assigned to the group
and keep all other vertices selected.

Finding Ungrouped Vertices
--------------------------

You can find ungrouped vertices as follows:

- Press :kbd:`A` once or twice to unselect all vertices.
- In the header of the 3D View: Navigate to :menuselection:`Select --&gt; Ungrouped Vertices`

################
Vertex Groups
################

.. toctree::
:maxdepth: 2

introduction.rst
vertex_groups.rst
assigning_vertex_group.rst
vertex_weights.rst

************
Introduction
************

.. figure:: /images/modeling_meshes_vgroups_01.jpg
:align: right

The Vertex Group Panel.

Vertex Groups are mainly used to tag the vertices belonging
to parts of a Mesh Object or :term:`Lattice`. Think of the legs of a chair or
the hinges of a door, or hands, arms, limbs, head, feet, etc. of a character.
In addition you can assign different *weight values*
(in the range [ 0.0, 1.0 ] ) to the vertices within a Vertex Group.
Hence Vertex Groups are sometimes also named *Weight Groups*.

Vertex Groups are most commonly used for Armatures
(See also :doc:`Skinning Mesh Objects &lt;/rigging/armatures/skinning/introduction&gt;`).
But they are also used in many other areas of Blender, like for example:

- Shape keys
- Modifiers
- Particle Generators
- Physics Simulations

Many more usage scenarios are possible.
Actually you can use Vertex Groups for whatever makes sense to you.
In some contexts Vertex Groups can also be automatically generated
(e.g. for rigged objects). However, in this section we will focus
on manually created (user-defined) Vertex Groups.

.. note:: Vertex groups only apply to Mesh and Lattice Objects

Any other Object type has no vertices, hence it cannot have Vertex Groups.

Usage
=====

Typical use cases for vertex groups.

Skinning an Armature
--------------------

If you want to animate your mesh and make it move, you will
define an armature which consists of a bunch of bones.
Vertex Groups are used to associate parts of the Mesh
to Bones of the Armature, where you can specify an influence
*weight* in the range (0.0 - 1.0) for each vertex
in the Vertex Group.

Obviously, the same vertex can belong to several groups, and hence be affected by several bones,
with a fine tuning of each bone's influence using these vertex weights.
Quite useful when you want to have a smooth joint. For example, when you skin an elbow,
the upperarm vertex group contains the vertices of this part at full weight (*1.0*),
and when reaching the elbow area, these weights decrease progressively to *0.0*
when reaching the forearm zone and vice versa for the forearm group weights...
Of course, this is a very raw example skinning a realistic joint is a big job,
as you have to carefully find good weights for each vertex,
to have the most realistic behavior, when bending -- and this is not an easy thing!

Modifiers
---------
Many modifiers contain the ability to control the modifier
influence on each vertex separately.
This is also done via Vertex Groups and the weight values
associated to the vertices.

Mesh Selection
--------------

By defining mesh regions with Vertex Groups you can easily
select entire parts of your mesh with three clicks and work
on them in isolation without having to create separate objects.
With the hide function you can even remove a vertex
group from the view (for later unhide).

*******************
Vertex Groups Panel
*******************

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Object Data tab --&gt; Vertex Groups`

.. figure:: /images/modeling_meshes_vgroups_01.jpg
:align: right

The Vertex Group Panel.

Vertex Groups are maintained within the *Object Data* Properties Editor,
and there in the *Vertex Groups* panel.

Active Vertex Group
A :ref:`ui-list-view`.

Lock
Locks the group from being edible. You can only rename or delete the group.

Add ``+``
Create a empty vertex group.
Remove ``-``
Deletes the active vertex group.

Specials
Sort Vertex Groups
Sorts Vertex Groups alphabetically.
Copy Vertex Group
Add a Copy of the active Vertex Group as a new Group.
The new group will be named like the original group with "_copy" appended at the end of its name.
And it will contain associations to exactly the same vertices
with the exact same weights as in the source vertex group.
Copy Vertex Groups to Linked
Copy Vertex Groups of this Mesh to all linked Objects which use the same mesh data (all users of the data).
Copy Vertex Group to Selected
Copy all Vertex Groups to other Selected Objects provided they have matching indices
(typically this is true for copies of the mesh which are only deformed and not otherwise edited).
Mirror Vertex Group
Mirror all Vertex Groups, flip weights and/or names, editing only selected vertices,
flipping when both sides are selected; otherwise copy from unselected.
Note this function will be reworked (and fully documented) in a future release.
Remove from All Groups
(not available for locked groups) Unassigns the selected Vertices from all groups.
After this operation has been performed, the vertices will no longer be contained in any vertex group.
Clear Active Group
Remove all assigned vertices from the active Group. The group is made empty.
Note that the vertices may still be assigned to other Vertex Groups of the Object.
(not available for locked groups).
Delete All Groups
Remove all Vertex Groups from the Object.

Lock All
Lock all groups.
Unlock All
Unlock all groups.
Lock_Invert All
Invert Group Locks.

Editing Vertex Groups
=====================

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Object Data tab --&gt; Vertex Groups`
| Menu:     :menuselection:`Mesh --&gt; Vertex --&gt; Vertex Groups`
| Hotkey:   :kbd:`Ctrl-G`

.. figure:: /images/modeling-meshes-vertex-group-panel-edit.png
:align: right

Vertex Group Panel in Edit or Weight Paint Mode.

When you switch either to *Edit Mode* or to *Weight Paint Mode* Vertex weights can be edited.
The same operations are available in the 3D Views menu
:menuselection:`Mesh --&gt; Vertices --&gt; Vertex Groups` or :kbd:`Ctrl-G`.

Assign
To assign the Selected vertices to the active group with the weight as defined in the *Weight* (see below).
Remove
To remove the selected vertices from the active group (and thus also delete their weight values).
Select
To select all vertices contained in the group.
Deselect
To deselect all vertices contained in the group.

Weight
The weight value that gets assigned to the selected vertices.

Set Active Group
Lets you select the group that will become the active one (menu only).

.. hint::

Multiple objects sharing the same mesh data have the
peculiar property that the group names are stored on the object,
but the weights in the mesh. This allows you to name groups
differently on each object, but take care because removing a
vertex group will remove the group from all objects sharing this mesh.

**************
Vertex Weights
**************

.. admonition:: Reference
:class: refbox

| Mode:     Edit and Weight Paint Modes
| Panel:    :menuselection:`Properties region --&gt; Vertex Weights`

.. figure:: /images/modeling-meshes-vertex-weights-panel-overview.png
:width: 235px

Vertex Weights Panel.

Vertex Group Categories (1), Weight Table (2), Function Bar (3).

As mentioned before in :doc:`Vertex Groups &lt;/modeling/meshes/properties/vertex_groups/index&gt;`
each entry in a Vertex Group also contains a weight value in the range of (0.0 to 1.0).
Blender provides a *Vertex Weights* panel from where you can get (and edit)
information about the weight values of each Vertex of a mesh.
That is: to which Vertex Groups the vertex is assigned with which weight value.

The Vertex Weights panel can be found in the right Properties region of the 3D View.
It is available in Edit Mode and in Weight Paint Mode
(when Vertex Selection masking is enabled as well).

Vertex Group Categories
=======================

Actually we do not have any strict categories of Vertex Groups in Blender.
Technically they all behave the same way.
However, we can identify two implicit categories of Vertex Groups:

Deform Groups
-------------

These Vertex Groups are sometimes also named *Weight Groups* or *Weight Maps*.
They are used for defining the weight tables of Armature bones.
All Deform Groups of an Object are strictly related to each other via their weight values.

Strictly speaking, the sum of all deform weights for any vertex of a mesh should be exactly 1.
0. In Blender this constraint is a bit relaxed (see below). Nevertheless,
Deform Groups should always be seen as related to each other. Hence we have provided a filter
that allows restricting the Vertex Weight panel to display only the Deform bones of an Object.

Other Groups
------------

All other usages of Vertex Groups are summarized into the *Other* category.
These vertex groups can be found within Shape keys, Modifiers, etc...
There is really no good name for this category,
so we kept it simple and named it *Other*.

Weight Table
============

The Weight Table shows all weights associated to the *active vertex*.
Note that a vertex does not necessarily have to be associated to any vertex groups.
In that case the Vertex Weights Panel is not displayed.

.. tip:: The active Vertex

That is the most recently selected vertex.
This vertex is always highlighted so that you can see it easily in the mesh.
If the active Vertex does not have weights, or there is no active vertex selected at the moment,
then the Vertex Weights Panel disappears.

Each row in the Weight table contains four active elements:

.. figure:: /images/modeling-mesh_vertex-weight-editor-name.png
:width: 335px

Change Active Group.

Set the Active Group
--------------------

As soon as you select any of the Vertex Group Names in the Weight table,
the referenced Vertex Group becomes the new Active group.

.. figure:: /images/modeling-meshes-vertex-weights-show.png
:width: 235px

Enable display of Weights in Edit Mode.

Display Weights in Edit Mode
----------------------------

When you are in edit mode, you can make the Weights of the active Group visible on the mesh:

Search the *Mesh Display* panel in the Properties region.
And there enable the *Show Weights* option.
Now you can see the weights of the active Vertex Group displayed on the mesh surface.

.. figure:: /images/modeling-meshes-weights-in-edit-mode.jpg
:width: 235px

Weights in Edit Mode.

Edit Weights in Edit Mode
-------------------------

It is now very easy to work with Vertex Groups in Edit Mode. All edit options of the mesh are
available and you have direct visual control over how your Weights change when you edit the
weight values.

.. figure:: /images/modeling_mesh_vertex-weight-editor-weight.png
:width: 235px

Change Weight Value.

Change a Weight
---------------

You can either enter a new weight value manually (click on the number and edit the value),
or you can change the weight by :kbd:`LMB` and while holding down the mouse button,
drag right or left to increase/decrease the weight value. You also can use the right/left
arrows displayed around the weight value to change the weight in steps.

.. figure:: /images/modeling_mesh_vertex-weight-editor-paste.png
:width: 235px

Paste weights.

Pasting
-------

:kbd:`LMB` the Paste Icon allows you to forward a single weight of the active Vertex to all selected vertices.
But note that weights are only pasted to vertices which already have a weight value in the affected Vertex Group.

.. figure:: /images/modeling-meshes-vertex-weight-editor-delete.png
:width: 235px

Delete weights.

Deleting
--------

:kbd:`LMB` the Delete Icon will instantly remove the weight from the active vertex.
Thus the entire row disappears when you click on the delete icon.

Function Bar
============

.. figure:: /images/modeling-meshes-vertex-weight-editor-functions.png
:width: 235px

Vertex Weights panel.

The function bar contains two functions:

Normalize
Normalizes the weights of the active Vertex.
That is all weights of the active vertex are recalculated
such that their relative weight is maintained and the weight sum is 1.0.
Copy
Copies all weights defined for the active Vertex to all selected vertices.
Thus all previously defined weights are overwritten.

.. tip:: The filter setting is respected

Note that both functions only work on the Vertex Groups currently displayed in the Weights Table.
So if for example only the *Deform weights* are displayed,
then Normalize and Copy only affect the Deform bones.

Locking
=======

.. figure:: /images/modeling-meshes-vertex-weight-editor-locked.png
:width: 235px

Vertex Weights panel Locked.

Whenever a Weight Group is locked, all data changing functions get disabled:

- Normalize the vertex Weights.
- Copy the Vertex weights.
- Change the Weight of the active vertices.
- Paste to selected vertices.

.. tip:: The filter setting is respected

If you have for example all deform weight groups unlocked and all other vertex groups locked,
then you can safely select *Deform* from the Filter row
and use all available functions from the Weight table again.
..    TODO/Review: {{review|partial=X|text= expand advanced selection tools|im=examples}}.

********
Advanced
********

The select menu in edit mode contains additional tool for selecting components:

Sharp Edges
This tool selects all edges between two faces forming an angle greater than the angle value,
Where an increasing angle selects sharper edges.
Linked Flat Faces :kbd:`Ctrl-Shift-Alt-F`
Select connected faces based on a threshold of the angle between them.
This is useful for selecting faces that are planar.
Mirror
Select mesh items at the mirrored location across the chosen axis.
Side of Active
Selects all vertices on the mesh in a single axis relative to the active vertex.
In Vertex selection mode only.
Linked
Selects all components that are connected to the current selection. (see `Select Linked`_)

Checker Deselect
================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Checker Deselect`
| Hotkey:   None

This tool applies a alternating selected/deselected checker pattern.
This only works if you already have more than one mesh element selected.

Nth Selection
Using the current selection, it will deselected every nth element.
Skip
Number of steps to skip the pattern and keep selected.
Offset
Offsets at what point to start at.

Select All by Traits
====================

.. _mesh-select-non-manifold:

Non Manifold :kbd:`Ctrl-Shift-Alt-M`
Selects the :term:`non-manifold` geometry of a mesh.
This entry is available when editing a mesh, in Vertex and Edge selection modes only.
The Operator panel provides several selection options:

Extend
Lets you extend the current selection.
Wire
Selects all the edges that do not belong to any face.
Boundaries
Selects edges in boundaries and holes.
Multiple Faces
Selects edges that belong to three or more faces.
Non Contiguous
Selects edges that belong to exactly two faces with opposite normals.
Vertices
Selects vertices that belong to *wire* and *multiple face* edges, isolated vertices,
and vertices that belong to non adjoining faces.
Interior Faces
Selects faces where all edges have more than two faces.
Select Faces by Sides
Selects all faces that have a specified number of edges.
Loose Geometry
Selects all vertices or edges that do not form part of a face.
Ungrouped Vertices
Selects all vertices which are not part of a :doc:`vertex group &lt;/modeling/meshes/properties/vertex_groups/index&gt;`.

Select Linked
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Linked`
| Hotkey:   :kbd:`Ctrl-L`

Select geometry connected to already selected elements.
This is often useful when a mesh has disconnected, overlapping parts,
where isolating it any other way would be tedious.

To give more control, you can also enable delimiters in the Operator panel,
so the selection is constrained by seams, sharp-edges, materials or UV islands.

With *Pick Linked* you can also select connected geometry directly under the cursor,
using the :kbd:`L` shortcut to select or :kbd:`Shift-L` to deselect linked.

This works differently in that it uses the geometry under the cursor instead of the existing selection.

Select Similar
==============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Similar...`
| Hotkey:   :kbd:`Shift-G`

Select geometry that have similar certain properties to the ones selected,
based on a threshold that can be set in tool properties after activating the tool.
Tool options change depending on the selection mode:

Vertex Selection Mode:
Normal
Selects all vertices that have normals pointing in similar directions to those currently selected.
Amount of Adjacent Faces
Selects all vertices that have the same number of faces connected to them.
Vertex Groups
Selects all vertices in the same :doc:`vertex group &lt;/modeling/meshes/properties/vertex_groups/index&gt;`.
Amount of Connecting Edges
Selects all vertices that have the same number of edges connected to them.
Face Regions
Select matching features on a mesh that has multiple similar areas based on the topology.

Edge Selection Mode:
Length
Selects all edges that have a similar length as those already selected.
Direction
Selects all edges that have a similar direction (angle) as those already selected.
Amount of Faces Around an Edge
Selects all edges that belong to the same number of faces.
Face Angles
Selects all edges that are between two faces forming a similar angle, as with those already selected.
Crease
Selects all edges that have a similar :ref:`Crease &lt;modeling-edges-crease-subdivision&gt;`
value as those already selected.
Bevel
Selects all edges that have the same *Bevel Weight* as those already selected.
Seam
Selects all edges that have the same *Seam* state as those already selected.
*Seam* is a true/false setting used in :ref:`UV-texturing &lt;editors-uv-image-index&gt;`.
Sharpness
Selects all edges that have the same *Sharp* state as those already selected.
*Sharp* is a true/false setting (a flag) used by the
:doc:`Edge Split Modifier &lt;/modeling/modifiers/generate/edge_split&gt;`.

Face Selection Mode:
Material
Selects all faces that use the same material as those already selected.
Image
Selects all faces that use the same UV-texture as those already selected
(see :ref:`UV-texturing &lt;editors-uv-image-index&gt;` pages).
Area
Selects all faces that have a similar area as those already selected.
Polygon Sides
Selects all faces that have the same number of edges.
Perimeter
Selects all faces that have a similar perimeter (added values of its edge lengths).
Normal
Selects all faces that have a similar normal as those selected.
This is a way to select faces that have the same orientation (angle).
Co-planar
Selects all faces that are (nearly) in the same plane as those selected.

.. (todo) check type: Image in Cycles

More/Less
=========

More :kbd:`Ctrl-NumpadPlus`
Expands the selection to the adjacent elements of the selection type.
Less :kbd:`Ctrl-NumpadMinus`
Contracts the selection from the adjacent elements of the selection type.

.. todo how to handle face step

Next Active :kbd:`Ctrl-Shift-NumpadPlus`
This uses selection history to select the next vertex/edge/face based on surrounding topology.
Previous Active :kbd:`Ctrl-Shift-NumpadMinus`
Select previous just removes the last selected element.

Select Loops
============

You can easily select loops of components:

Edge Loops
----------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode --&gt; Vertex or Edge select mode
| Menu:     :menuselection:`Select --&gt; Edge Loop`
| Hotkey:   :kbd:`Alt-RMB`

Holding :kbd:`Alt` while selecting an edge selects a loop of edges that are connected in
a line end to end, passing through the edge under the mouse pointer.
Holding :kbd:`Alt-Shift` while clicking adds to the current selection.

Edge loops can also be selected based on an existing edge selection,
using either :menuselection:`Select --&gt; Edge Loop`,
or the *Edge Loop Select* option of the *Edge Specials* menu :kbd:`Ctrl-E`.

.. note:: *Vertex* mode

In *Vertex* select mode, you can also select edge loops, by using the same hotkeys,
and clicking on the *edges* (not on the vertices).

.. figure:: /images/modeling_meshes_selection_edge-loops.png

Longitudinal and latitudinal edge loops.

The left sphere shows an edge that was selected longitudinally. Notice how the loop is open.
This is because the algorithm hit the vertices at the poles and terminated because the
vertices at the pole connect to more than four edges. However,
the right sphere shows an edge that was selected latitudinally and has formed a closed loop.
This is because the algorithm hit the first edge that it started with.

Face Loops
----------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode --&gt; Face or Vertex select modes
| Hotkey:   :kbd:`Alt-RMB`

In face select mode, holding :kbd:`Alt` while selecting an *edge* selects a loop of
faces that are connected in a line end to end, along their opposite edges.

In vertex select mode,
the same can be accomplished by using :kbd:`Ctrl-Alt` to select an edge,
which selects the face loop implicitly.

.. figure:: /images/modeling_meshes_selection_face-loops.png

Face loop selection.

This face loop was selected by clicking with :kbd:`Alt-RMB` on an edge,
in *face* select mode.
The loop extends perpendicular from the edge that was selected.

.. figure:: /images/modeling_meshes_selection_face-loops-vertex.png

:kbd:`Alt` versus :kbd:`Ctrl-Alt` in vertex select mode.

A face loop can also be selected in *Vertex* select mode.
Technically :kbd:`Ctrl-Alt-RMB` will select an *Edge Ring*,
however, in *Vertex* select mode, selecting an *Edge Ring* implicitly
selects a *Face Loop* since selecting opposite edges of a face implicitly selects
the entire face.

Edge Boundary
-------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode --&gt; Vertex or Edge select modes
| Hotkey:   :kbd:`Alt-RMB`

Loop-select on edge boundaries.
To extend the selection to all boundaries if the current boundary is already selected
use :kbd:`Alt-RMB` again.

Edge Ring
---------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Edge Ring`
| Hotkey:   :kbd:`Ctrl-Alt-RMB`

In *Edge* select mode, holding :kbd:`Ctrl-Alt`
while selecting an edge (or two vertices) selects a sequence of edges that are not connected,
but on opposite sides to each other continuing along a :doc:`face loop &lt;/modeling/meshes/structure&gt;`.

As with edge loops, you can also select edge rings based on current selection,
using either :menuselection:`Select --&gt; Edge Ring`,
or the *Edge Ring Select* option of the *Edge Specials* menu :kbd:`Ctrl-E`.

.. note:: *Vertex* mode

In *Vertex* select mode, you can use the same hotkeys when *clicking on the edges* (not on the vertices),
but this will directly select the corresponding face loop...

.. _fig-mesh-select-advanced-loop-ring:

.. figure:: /images/modeling_meshes_selection_edge-ring.png

A selected edge loop, and a selected edge ring.

In Fig. :ref:`fig-mesh-select-advanced-loop-ring` the same edge was clicked on,
but two different "groups of edges" were selected, based on the different tools.
One is based on edges during computation and the other is based on faces.

Shortest Path
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Hotkey:   :kbd:`Ctrl-RMB` and the menu item :menuselection:`Select --&gt; Shortest Path`

.. figure:: /images/modeling_meshes_selection_shortest-path.png

Select a face or vertex path with :kbd:`Ctrl-RMB`.

Selects all geometry along the shortest path from the active vertex/edge/face to the one which
was selected.

Face Stepping
Supports diagonal paths for vertices and faces, and
selects edge-rings with edges.
Topological Distance
Which only takes into account the number of edges of the path and
not the length of the edges to calculate the distances,
Fill Region :kbd:`Ctrl-Shift-RMB`
Selects all elements in the shortest paths from the active selection to the clicked area.
Checker Deselect
See `Checker Deselect`_.

Loop Inner-Region
=================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode --&gt; Edge select mode
| Menu:     :menuselection:`Select --&gt; Select Loop Inner-Region`

*Select Loop Inner-Region* selects all faces that are inside a closed loop of edges.
While it is possible to use this operator in *Vertex* and *Face* selection modes, results may be unexpected.
Note that if the selected loop of edges is not closed,
then all connected edges on the mesh will be considered inside the loop.

.. figure:: /images/modeling_meshes_selection_inner-region1.png

Loop to Region.

.. figure:: /images/modeling_meshes_selection_inner-region2.png

This tool handles multiple loops fine, as you can see.

.. figure:: /images/modeling_meshes_selection_inner-region3.png

This tool handles "holes" just fine as well.

Boundary Loop
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode --&gt; Edge select mode
| Menu:     :menuselection:`Select --&gt; Select Boundary Loop`

*Select Boundary Loop* does the opposite of *Select Loop Inner-Region*,
based on all regions currently selected, it selects only the edges at the border(contour) of these islands.
It can operate in any select mode, but when in *Face* mode it will switch to *Edge* select mode after running.

All this is much more simple to illustrates with examples:

.. figure:: /images/modeling_meshes_selection_boundary-loop.png

Select Boundary Loop does the opposite and forces into Edge Select Mode.

*************
Edges &amp; Faces
*************

Edges
=====

.. figure:: /images/selection-mode_buttons_edge-activated.png

Buttons for the selection modes.

Edges can be selected in much the same way as vertices and faces
by :kbd:`RMB`-clicking them while Edge Select Mode is activated.
Pressing :kbd:`Shift` while clicking will add/subtract to the existing selection.

.. _modeling-meshes-selecting-edge-loops:

Edge Loops
----------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Mesh)
| Menu:     :menuselection:`Select --&gt; Edge Loop`
| Hotkey:   :kbd:`Alt-RMB`, or :kbd:`Shift-Alt-RMB` for modifying existing selection

Edge loops can be selected by first selecting an edge (vertex or edge selection mode),
and then going to :menuselection:`Select --&gt; Edge Loop`. The shortcut :kbd:`Alt-RMB` on an edge
(either vertex or edge select mode) is a quicker and more powerful way of doing so.
More powerful, because you can add/remove loops from an existing selection if you press
:kbd:`Shift` too.

Note, that if you want to select a loop while being in vertex select mode,
you still have to perform the shortcut on an edge -- while you,
for just selecting vertices, would :kbd:`RMB` on a vertex.

.. figure:: /images/select_edge_loop_example.png

An edge loop.

Edge Rings
----------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Mesh)
| Menu:     :menuselection:`Select --&gt; Edge Ring`
| Hotkey:   :kbd:`Alt-Ctrl-RMB`, or :kbd:`Shift-Alt-Ctrl-RMB` for modifying existing selection

Edge Rings are selected similarly.
Based on the selection of an edge go to :menuselection:`Select --&gt; Edge Ring`.
Or use :kbd:`Alt-Ctrl-RMB` on an edge.

.. figure:: /images/select_edge_ring_example.png

An Edge Ring.

.. note:: Convert selection to whole faces

If the edge ring selection happened in Edge Select Mode, switching to Face Select Mode will erase the selection.

This is because none of those faces had all its (four) edges selected,
just two of them.

Instead of selecting the missing edges manually or by using :kbd:`Shift-Alt-RMB` twice,
it is easier to first switch to Vertex Select Mode, which will kind of "flood" the selection.
A subsequent switch to Face Select Mode will then properly select the faces.

Faces
=====

.. figure:: /images/selection-mode_buttons_face-activated.png

Activated the Face Select Mode.

To select parts of a mesh face-wise, you have to switch to Face Select Mode.
Do this by clicking the button shown above, or press :kbd:`Ctrl-Tab` to spawn a menu.
The selection works as usual with :kbd:`RMB` ;
to add/remove to an existing selection, additionally press :kbd:`Shift`.
The Border,Circle and Lasso Selection Tools must intersect the face indicators
usually represented by small pixel squares; one at the center of each face.

.. _modeling-meshes-selecting-face-loops:

Face Loops
----------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode (Mesh)
| Hotkey:   :kbd:`Alt-RMB` or :kbd:`Shift-Alt-RMB` for modifying existing selection

Face Loops are pretty much the same as Edge Rings. If you want to select a Face Loop,
there is no menu entry that works based on a selected face. Using :menuselection:`Select --&gt; Edge Ring`
would select a "cross" with the prior selected face as the middle.
If you want to avoid switching to Edge Select Mode to select a Face Loop,
use the :kbd:`Alt-RMB` shortcut.

.. figure:: /images/face-mode_different-loop-selections.png

Different Loopselect Operations on a grid in Face Select Mode.

- Just the selected face.
- Select the face, then :menuselection:`Select --&gt; Edge Ring`.
See, how Blender selects edges, even if being in Face Select Mode.
If these edges are desired and you want to work on them, switch in Edge Select Mode.
Switching to Vertex Select Mode would flood the selection and leave you with the 4th image as result,
after going back to Face Select Mode.
- Select the face, the :menuselection:`Select --&gt; Edge Loop`.
As in the example above, Blender pretends to be in Edge Select Mode and takes the four edges of the selected face
as base for the selection operation.
- This selection was created by :kbd:`Alt-RMB` on the left edge of the center face,
followed by twice :kbd:`Shift-Alt-RMB` on the top edge of the center face. Two times,
because the first click will remove the selected face loop (in this case, just the original selected face),
while the second click will add the whole vertical running loop to the selection, creating the cross.

N-gons in Face Select Mode
--------------------------

.. figure:: /images/face-mode_ngon_visual-problem.png

N-gon-Face having its center dot inside another face.

As already known, faces are marked with a little square dot in the middle of the face.
With n-gons that can lead in certain cases to a confusing display.
The example shows the center dot of the U-shaped n-gon being inside of the oblong face inside the "U".
It is not easy to say which dot belongs to which face (the orange dot in the image is the object origin).
Luckily, you do not need to care much, because to select a face, you do not have to click the center dot,
but the face itself.

.. tip:: Face selection

*To select a face*: Click the face, not the dot!

############
Selecting
############

.. toctree::
:maxdepth: 2

introduction.rst
advanced.rst
edges_faces.rst
..    TODO/Review: {{review|}}.

************
Introduction
************

There are many ways to select elements, and it depends on what *Mesh Select Mode*
you are in as to what selection tools are available.
First we will go through these modes and after that a look is taken at basic selection tools.

Selection Mode
==============

Select Mode Header Widgets
--------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`3D View Header --&gt; Select Mode`
| Hotkey:   :kbd:`Ctrl-Tab`

.. figure:: /images/modeling-meshes-selection-mode-buttons.png
:align: right
:width: 190px

Edit Mode selection buttons.

In *Edit Mode* there are three different selection modes.
You can enter the different modes by selecting one of the three buttons in the header.

Vertices
In this mode vertices are drawn as points.

Selected vertices are drawn in orange, unselected vertices in black,
and the active or last selected vertex in white.
Edges
In this mode the vertices are not drawn.

Instead the selected edges are drawn in orange,
unselected edges black, and the active or last selected edge in white.
Faces
In this mode the faces are drawn with a selection point in the middle which is used for selecting a face.

Selected faces and their selection point are drawn in orange,
unselected faces are drawn in black, and the active or last selected face is highlighted in white.

When using these buttons, you can make use of modifier keys, see: `Switching Select Mode`_.

Almost all tools are available in all three mesh selection modes.
So you can *Rotate*, *Scale*, *Extrude*, etc. in all modes.
Of course rotating and scaling a *single* vertex will not do anything useful
(*without* setting the pivot point to another location),
so some tools are more or less applicable in some modes.

Switching Select Mode
---------------------

When switching modes in an "ascendant" way (i.e. from simpler to more complex), from
*Vertices* to *Edges* and from *Edges* to *Faces*,
the selected parts will still be selected if they form a complete element in the new mode.

For example, if all four edges in a face are selected,
switching from *Edges* mode to *Faces* mode will keep the face selected.
All selected parts that do not form a complete set in the new mode will be unselected.

Hence, switching in a "descendant" way (i.e. from more complex to simpler),
all elements defining the "high-level" element (like a face) will be selected
(the four vertices or edges of a quadrangle, for example).

Multiple Selection Modes
^^^^^^^^^^^^^^^^^^^^^^^^

By holding :kbd:`Shift-LMB` when selecting a selection mode,
you can enable multiple *Selection Modes* at once.

This allows you to quickly select Vertices/Edges/Faces,
without first having to switch modes.

Expanding/Contracting Selection
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

By holding :kbd:`Ctrl` when selecting a higher selection mode,
all elements touching the current selection will be added,
even if the selection does not form a complete higher element.

See Fig. :ref:`fig-mesh-select-intro-selection-modes` for examples of the different modes.

Or contracting the selection when switching to a lower mode.

.. _fig-mesh-select-intro-selection-modes:

.. list-table:: Selection Modes.

* - .. figure:: /images/modeling_meshes_selection_vertex-mode-example.png
:width: 320px

Vertices mode example.

- .. figure:: /images/modeling_meshes_selection_edge-mode-example.png
:width: 320px

Edges mode example.

* - .. figure:: /images/modeling_meshes_selection_face-mode-example.png
:width: 320px

Faces mode example.

- .. figure:: /images/modeling_meshes_selection_mixed-mode-example.png
:width: 320px

Mixed mode example.

Limit Selection to Visible
==========================

If you are in solid, shaded, or textured viewport shading mode
(not bounding box or wireframe),
you will have a fourth button in the header that looks like a cube,
just right of the select mode ones.

When enabled, this limits your ability to view and select vertices occluded by the objects geometry
(as if the object was solid). This is done by the viewport with depth buffer clipping.

Selection Tools
===============

The select menu in edit mode contains tools for selecting components.
These are described in more detail in the following pages.

Border Select
-------------

Enables a rectangular region for selection :kbd:`B`.

.. list-table::

* - .. _fig-mesh-select-basics-start:

.. figure:: /images/modeling-meshes-selection-borderselect1.png
:width: 200px

Start.

- .. _fig-mesh-select-basics-selecting:

.. figure:: /images/modeling-meshes-selection-borderselect2.png
:width: 200px

Selecting.

- .. _fig-mesh-select-basics-complete:

.. figure:: /images/modeling-meshes-selection-borderselect3.png
:width: 200px

Complete.

In Fig. :ref:`fig-mesh-select-basics-start`, *Border Select* has been activated and is indicated by showing a
dotted cross-hair cursor. In Fig. :ref:`fig-mesh-select-basics-selecting`
the *selection region* is being chosen by drawing a rectangle with the :kbd:`LMB`.
The selection area is only covering the selection handles of three faces. Finally,
by releasing :kbd:`LMB` the selection is complete; see Fig. :ref:`fig-mesh-select-basics-complete`.

Circle Select
-------------

Enables a circular shaped region for selection :kbd:`C`.

.. _fig-mesh-select-basic-circle:

.. list-table:: Circle Region Select.

* - .. figure:: /images/modeling-meshes-selection-circularselect1.png
:width: 320px

Before.

- .. figure:: /images/modeling-meshes-selection-circularselect2.png
:width: 320px

After.

Fig. :ref:`fig-mesh-select-basic-circle` is an example of selecting edges while in *Edge Select Mode*.
As soon as an edge intersects the circle the edge becomes selected.
The tool is interactive such that edges are selected while the circle region is being dragged with the :kbd:`LMB`.

If you want to deselect elements, hold :kbd:`MMB` and begin clicking or dragging again.

For *Faces* select mode, the circle must intersect the face indicators usually represented by small pixel squares;
one at the center of each face.

Lasso Select
------------

Fig. :ref:`fig-mesh-select-basic-lasso` is an example of using the *Lasso select tool* in *Vertex Select Mode*.

.. _fig-mesh-select-basic-lasso:

.. list-table:: Lasso selection.

* - .. figure:: /images/modeling-meshes-selection-lassoselect1.png
:width: 200px

Start.

- .. figure:: /images/modeling-meshes-selection-lassoselect2.png
:width: 200px

Selecting.

- .. figure:: /images/modeling-meshes-selection-lassoselect3.png
:width: 200px

Complete.

More Tools
----------

(De)select All :kbd:`A`
Select all or none of the mesh components.
Inverse :kbd:`Ctrl-I`
Selects all geometries that are not selected, and deselect currently selected components.
Random
Selects a random group of vertices, edges, or faces, based on a percentage value.

More :kbd:`Ctrl-NumpadPlus`
Propagates selection by adding geometry that are adjacent to selected elements.
Less :kbd:`Ctrl-NumpadMinus`
Deselects geometry that form the bounds of the current selection.

*********
Structure
*********

With meshes, everything is built from three basic structures:
*Vertices*, *Edges* and *Faces*.

.. figure:: /images/mesh_structure.png

Example of mesh structure.

.. The geometry of the faces performing the model is called topology.

Vertices
========

The most elementary part of a mesh is the vertex which is a single point or position in 3D space.
The vertices (the plural form of vertex) are stored in an array of coordinates.

It is usually invisible in rendering and in *Object Mode*.
Do not mistake the origin point of an object for a vertex. It looks similar,
but it is bigger and you cannot select it.

.. figure:: /images/mesh-structures-cubeexample.png

Vertex example.

The origin is labeled as "A"; "B" and "C" are vertices.

In the image above, the vertex labeled "C" is a new vertex added to the cube with a
new edge added between "B" and "C".

Edges
=====

An edge always connects two vertices by a straight line.
The edges are the "wires" you see when you look at a mesh in wireframe view.
They are usually invisible on the rendered image. They are used to construct faces.

Faces
=====

Faces are used to build the actual surface of the object.
They are what you see when you render the mesh.
If this area does not contain a face,
it will simply be transparent or non-existent in the rendered image.

A face is defined as the area between either three (triangles), four (quadrangles) or more (n-gons) vertices,
with an edge on every side. These are often abbreviated to *tris, quads &amp; n-gons*.

Triangles are always flat and therefore easy to calculate. On the other hand,
quadrangles "deform well" and are therefore preferred for animation and subdivision modeling.

While you could build a cube with triangular faces,
it would just look more confusing in *Edit Mode*.

Loops
=====

.. _fig-mesh-topo-loop:

.. figure:: /images/mesh-structures-edge-and-face-loops.png

Edge and Face Loops.

*Edge* and *Face Loops* are sets of faces or edges that form continuous "loops" as shown in
Fig. :ref:`fig-mesh-topo-loop`. The top row (1 - 4) shows a solid view,
the bottom row (5 - 8) a wireframe view of the same loops.

.. note::

Note that loops (2 and 4) do not go around the whole model.
Loops stop at so called poles because there is no unique way to continue a loop from a pole.
Poles are vertices that are connected to either three, five, or more edges. Accordingly,
vertices connected to exactly one, two or four edges are not poles.

In the image above, loops that do not end in poles are cyclic (1 and 3).
They start and end at the same vertex and divide the model into two partitions.
Loops can be a quick and powerful tool to work with specific,
continuous regions of a mesh and are a prerequisite for organic character animation.
For a detailed description of how to work with loops in Blender, see:
:doc:`Advanced Selection &lt;/modeling/meshes/selecting/advanced&gt;`.

.. _modeling-mesh-structure-edge-loops:

Edge Loops
----------

Loops (1 and 2) in Fig Edge and Face Loops are edge Loops.
They connect vertices so that each one on the loop has exactly two neighbors that are not on the
loop and placed on both sides of the loop (except the start and end vertex in case of poles).

Edge Loops are an important concept especially in organic (subsurface)
modeling and character animation. When used correctly, they allow you to build models with
relatively few vertices that look very natural when used as subdivision surfaces and deform
very well in animation.

Take Fig. :ref:`fig-mesh-topo-loop` in organic modeling as an example: the edge loops follow the natural
contours and deformation lines of the skin and the underlying muscles and are more dense in
areas that deform more when the character moves, for example at the shoulders or knees.

Further details on working with Edge Loops can be found in
:ref:`Edge Loop Selection &lt;modeling-meshes-selecting-edge-loops&gt;`.

Face Loops
----------

These are a logical extension of Edge Loops in that they consist of the faces between two Edge
Loops, as shown in loops (3 and 4) in Fig. :ref:`fig-mesh-topo-loop`.
Note that for non-circular loops (4)
the faces containing the poles are not included in a Face Loop.

Further details on working with Face Loops can be found in
:ref:`Face Loop Selection &lt;modeling-meshes-selecting-face-loops&gt;`.

*******
Editing
*******

Active Element
==============

When in *Edit Mode*, the *Active Element* panel appears.
These settings apply only to the selected meta element.

.. figure:: /images/modeling_metas_properties_active-element-panel.png
:width: 300px

Active element panel.

Type
The *Type* menu lets you change the shape of the meta object.

Stiffness
---------

Together with *Threshold*, *Stiffness* controls the influencing range.
While the threshold is common to all metas in the same object
(or even the same `Object Families`_),
the stiffness is specific to each meta.

Scaling the inner green circle changes the *Stiffness* value.
Stiffness defines how much the meta object is filled.
This essentially defines how sensitive a meta is to being affected by other metas.
With a low stiffness, the meta will begin to deform from further away.
A higher value means the meta needs to be close to another one to begin merging.

When a *Meta* object comes within "range" of another meta,
the two will begin to interact with each other. They do not necessarily need to intersect,
and depending on the *Threshold* and *Stiffness* settings,
they most likely will not need to.
*Stiffness* is materialized by the *green ring*

The range is from (0.0 to 10.0). But to be visible,
the *Stiffness* must be slightly larger than the *Threshold* value. You
can also visually adjust the *Stiffness* ring by using the :kbd:`RMB` to
select it and activate *Scale* mode with :kbd:`S`.

.. _fig-meta-edit-stiffness:

.. figure:: /images/metastiffness.png
:width: 630px

Stiffness.

In Fig. :ref:`fig-meta-edit-stiffness`, the meta ball labeled "A",
has a smaller *Stiffness* value than the one labeled "B".
As you can see, the radius (green ring) is different for each of them.

Negative Influence
------------------

.. _fig-meta-ball-negative:

.. figure:: /images/metaobject-metaball-negative-ex.jpg
:width: 630px

Negative.

The opposite effect of a *positive* influence would be a *negative* influence:
the objects repel each other. Fig. :ref:`fig-meta-ball-negative`
shows a meta ball and a meta plane where the first is negative and the second, positive.
Notice how the negative meta is not visible: only the surrounding circles appear.
This is how Blender indicates that the object is negative.

Moving the sphere to the plane causes the plane's mesh to "cave in" or collapse inward.
If you move the plane away from the sphere, the plane's mesh will restore itself.

To make a meta *negative*, just select the meta in edit mode,
and check *negative* in the *active element* panel.

Hiding Elements
---------------

As in :ref:`object-show-hide` in *Object Mode*, you can hide the selected meta(s),
and then reveal what was hidden. This is very handy for cleaning your views up a bit... Note
that the two red and green rings always remain visible in *Edit Mode*,
as well as the select circle (in *Object Mode*...).

Deleting Elements
=================

There is no *Erase* menu for metas,
just a confirmation pop-up asking you if you want to delete the selected metas.
Clear and simple!

Conversion
==========

.. figure:: /images/metaconverttomesh.jpg
:width: 300px

Convert Menu.

You can only convert metas to meshes,
but here you have the option to keep the original *Meta* object (i.e.
create a new *Mesh* one, instead of a "real" conversion...).
Note that the resolution used for the new mesh is the *Wiresize* one,
not the *Rendersize* one.

To convert the meta, press :kbd:`Alt-C` in *Object Mode*, and select *Mesh/Text*,

Object Families
===============

*Meta* objects have different behavior in *Object Mode* than other object types.
They can be "regrouped" into so-called "families".

A "family" is a way to regroup several meta objects,
producing something very similar to having several metas inside the same object.

A family is defined by the left part of an object's name (the one before the dot). Remember,
an object's name is the one in the *OB* field, in most panels,
**not** the *MB* field, which is the meta data-block's name... For example,
the *family* part of "MetaPlane.001" is ``MetaPlane``.
Each meta object in the same "family" is associated with one another as discussed below.

.. _fig-meta-ball-base:

.. figure:: /images/metaobject-base-ex.jpg
:width: 300px

Meta ball base.

Families of metas are controlled by a *base* meta object which is identified by
an object name **without** a right number part. For example,
if we have five metas called "MetaThing", "MetaThing.001",
"MetaThing.002", "MetaThing.003" and "MetaThing.004",
the *base* meta object would be "MetaThing".

The *base* meta object determines the basis, the resolution, the threshold,
*and* the transformations. It also has the material and texture area.
The *base* meta is effectively the parent of
(or perhaps a better word to use is "the owner of") the other metas in the group (i.e.
it is as if the other metas were "included" or joined into the base one).

.. hint::

When working with multiple scenes,
take care naming your meta objects so the *base* is always in the same scene as other metas.

Failing to do this will give confusing behavior (invisible meta objects).

Examples
========

Fig. :ref:`fig-meta-ball-base` shows the *base* meta labeled "B".
The other two *Meta* objects are *children*. Children's selection rings are always black,
while the group's mesh is orange.
Because the metas are grouped,
they form a unified mesh which can always be selected by selecting the mesh of any meta in the group.
For example, in the example Fig. :ref:`fig-meta-ball-base`, only the lower sphere (the parent) has been selected,
and you see that both the parent's mesh *and* all of the children's meshes are now highlighted.

.. _fig-meta-ball-scale:

.. figure:: /images/metaobject-base-scale-ex.png
:width: 300px

Scaling the "base".

The *base* meta object controls the *polygonalization* (mesh structure)
for the group, and as such, also controls the polygonalization for the children (non-base)
metas. If we transform the *base* meta, the children's polygonalization changes. However,
if we transform the children, the polygonalization remains unchanged.

.. hint::

This discussion of "polygonization" does *not* mean that the various meshes do not deform
towards or away from each other (meta objects always influence one another in the usual way,
whether or not they are members of the same family). Rather,
it means that the underlying mesh structure changes only when the *base* object transforms.
For example, if you scale the *base*, the children's mesh structure changes. In
Fig. :ref:`fig-meta-ball-scale`, the *base* has been scaled down,
which has the effect of scaling the mesh structure of each of the children. As you can see,
the children's mesh resolution has increased, while the *base* decreased.
The children did *not* change size!
.. _modeling-metas-index:

############
Metaball
############

.. toctree::
:maxdepth: 2

introduction.rst
structure.rst
primitives.rst
editing.rst
properties.rst

************
Introduction
************

.. admonition:: Reference
:class: refbox

| Mode:     Object or Edit Modes
| Menu:     :menuselection:`Add --&gt; Meta`
| Hotkey:   :kbd:`Shift-A`

Meta objects are *implicit surfaces*,
meaning that they are *not explicitly* defined by vertices (as meshes are)
or control points (as surfaces are): they exist *procedurally*.
Meta objects are literally mathematical formulas that are calculated on-the-fly by Blender.

A very distinct visual characteristic of metas is that they are fluid *mercurial*,
or *clay-like* forms that have a "rounded" shape. Furthermore,
when two meta objects get close to one another, they begin to interact with one another.
They "blend" or "merge", as water droplets do, especially in zero-g (which, by the way, makes
them very handy for modeling streams of water when you do not want to do a fluid simulation).
If they subsequently move away from one another, they restore their original shape.

Each of these is defined by its own underlying mathematical structure (:doc:`/modeling/metas/structure`),
and you can at any time switch between them using the *Active Element* panel.

Typically *Meta* objects are used for special effects or as a basis for modeling.
For example, you could use a collection of metas to form the initial shape of your model and
then convert it to a mesh for further modeling. Meta objects are also very efficient for ray-tracing.

.. note::

*Meta* objects have a slightly different behavior in *Object Mode*.

Visualization
=============

In Object Mode, the calculated mesh is shown, along with a black "selection ring" (becoming pink when selected).

.. _fig-meta-ball-example:

.. figure:: /images/metainfluenceandselection.jpg
:width: 350px

Meta Ball example.

In *Edit Mode* (Fig. :ref:`fig-meta-ball-example`), a meta is drawn as a mesh (either shaded or as black wireframe,
but without any vertex of course), with two colored circles: a red one for selection (pink when selected),
and a green one for a direct control of the meta's stiffness (light green when active).
Note that except for the *Scale* :kbd:`S` transformation,
having the green circle highlighted is equivalent to having the red one.

**********
Primitives
**********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Create --&gt; Add Primitive/Metaball`
| Menu:     :menuselection:`Add --&gt; Meta`
| Hotkey:   :kbd:`Shift-A`

There are five predefined meta "primitives" (or configurations)
available in the :menuselection:`Add --&gt; Meta` sub-menu:

.. figure:: /images/metaprimitives.jpg
:width: 600px

The five Meta primitives.

Options
=======

Primitive
Meta Ball
Adds a meta with a point underlying structure.
Meta Tube
Adds a meta with a line segment underlying structure.
Meta Plane
Adds a meta with a planar underlying structure.
Meta Ellipsoid
Adds a meta with an ellipsoidal underlying structure.
Meta Cube
Adds a meta with a volumetric cubic underlying structure.

Radius, Align to View, Location, Rotation
See :ref:`Common Object Options &lt;object-common-options&gt;`.

**********
Properties
**********

All Meta objects in a scene interact with each other.
The settings in the *Metaball* section apply to all meta objects.
In *Edit Mode*,
the *Active Element* panel appears for editing individual meta elements.

.. list-table::

* - .. figure:: /images/modeling_metas_properties_metaball-panel.png

global meta properties.

- .. figure:: /images/modeling_metas_properties_active-element-panel.png

individual meta properties.

Resolution
==========

The *Resolution* controls the resolution of the resultant mesh as generated by the Meta object.

View
The 3D View resolution of the generated mesh. The range is from (0.05 to 1.0) (finest to coarsest).
Render
The rendered resolution of the generated mesh. The range is from (0.05 to 1.0) (finest to coarsest).

One way to see the underlying mathematical structure is to lower the *Resolution*,
increase the *Threshold* and set the *Stiffness* (see below)
a fraction above the *Threshold*. Fig. :ref:`fig-meta-intro-underlying` is a *Meta cube*
with the above mentioned configuration applied as follows:
*Resolution* of 0.410, *Threshold* of 5.0 and *Stiffness* a fraction above at 5.01.

.. _fig-meta-intro-underlying:

.. figure:: /images/metaunderlyingstructure.png
:width: 600px

Underlying.

Left: Underlying structure, Right: the shape.

You can clearly see the underlying cubic structure that gives the meta cube its shape.

Threshold (Influence)
=====================

.. admonition:: Reference
:class: refbox

| Mode:     Object or Edit Modes
| Panel:    Metaball

*Threshold* defines how much a meta's surface "influences" other metas.
It controls the *field level* at which the surface is computed.
The setting is global to a group of *Meta* objects.
As the threshold increases, the influence that each meta has on each other increases.

There are two types of influence: *positive* or *negative*. The type can be toggled on
the *Active Element* panel while in *Edit Mode*,
using the *Negative* button.
You could think of *positive* as attraction and *negative* as repulsion of meshes.
A negative meta will push away or repel the meshes of positive *Meta* objects.

.. _fig-meta-intro-positive:

.. figure:: /images/metaintersection.jpg
:width: 400px

Positive.

A *positive* influence is defined as an attraction,
meaning the meshes will stretch towards each other as the *rings of influence* intersect.
Fig. :ref:`fig-meta-intro-positive` shows two meta balls' *rings of influence*
intersecting with a *positive* influence.

Notice how the meshes have pulled towards one another.
The area circled in white shows the green *influence* rings intersecting.

Update
======

While transforming metas (grab/move, scale, etc.), you have four "modes" of visualization,
located in the *Update* buttons group of the *Metaball* panel:

Always
fully draw the meta during transformations.
Half Res
During transformations, draw the meta at half its *Wiresize* resolution.
Fast
Do not show meta mesh during transformations.
Never
Never show meta mesh (not a very recommended option, as the meta is only visible at render time!).

This should help you if you experience difficulties (metas are quite compute-intensive...),
but with modern computers, this should not happen, unless you use many metas,
or very high resolutions...

*********
Structure
*********

Technical Details
=================

A more formal definition of a meta object can be given as a *directing structure* which can
be seen as the source of a static field. The field can be either positive or negative and
hence the field generated by neighboring directing structures can attract or repel.

The implicit surface is defined as the surface where the 3D field generated by all the
directing structures assume a given value. For example a meta ball,
whose directing structure is a point, generates an isotropic (i.e.
identical in all directions) field around it and the surfaces at constant field value are
spheres centered at the directing point.

*Meta* objects are nothing more than mathematical formula that perform logical operations on one another
(AND, OR), and that can be added and subtracted from each other.
This method is also called *Constructive Solid Geometry* (CSG).
Because of its mathematical nature, CSG uses little memory, but requires lots of processing power to compute.

Underlying Structure
====================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Properties region --&gt; Transform panel --&gt; Type`,
:menuselection:`Metaball tab --&gt; Active Element panel --&gt; Type`

Blender has five types of metas, each determined by its underlying (or directing) structure.

In *Edit Mode*, you can change this structure,
either using the relevant buttons in the :menuselection:`Metaball tab --&gt; Active Element panel`,
or the selector in the *Transform* panel in the Properties region.
Depending on the structure, you might have additional parameters,
located in both *Transform* panel and *Active Element* panel.

Ball (point, zero-dimensional structure)
This is the simplest meta, without any additional setting. As it is just a point,
it generates an isotropic field, yielding a spherical surface
(this is why it is called *Meta Ball* or *Ball* in Blender).
Tube (straight line, uni-dimensional structure)
This is a meta which surface is generated by the field produced by a straight line of a given length.
This gives a cylindrical surface, with rounded closed ends. It has one additional parameter:

dx
The length of the line (and hence, of the tube).
Plane (rectangular plane, bi-dimensional structure)
This is a meta which surface is generated by the field produced by a rectangular plane.
This gives a parallel-epipedal surface, with a fixed thickness,
and rounded borders. It has two additional parameters:

dx, dy
The length, width of the rectangle.

Note that by default, the plane is a square.
Ellipsoid (ellipsoidal volume, tri-dimensional structure)
This is a meta which surface is generated by the field produced by an ellipsoidal volume.
This gives an ellipsoidal surface. It has three additional parameters:

dx, dy, dz
The length, width, height of the ellipsoid (defaults set to 1.0).

Note that by default, the volume is a sphere, producing a spherical meta, as the *Ball* option...
Cube (parallel-epipedal volume, tri-dimensional structure)
This is a meta which surface is generated by the field produced by a parallel-epipedal volume.
This gives a parallel-epipedal surface, with rounded edges.
As you might have guessed, it has three additional parameters:

dx, dy, dz
The length, width, height of the parallelepiped (defaults set to 1.0).

Note that by default, the volume is a cube.
.. _bpy.types.ArmatureModifier.:

*****************
Armature Modifier
*****************

The Armature Modifier is used for building skeletal systems for animating the
poses of characters and anything else which needs to be posed.

By adding an armature system to an object,
that object can be deformed accurately so that geometry does not have to be animated by hand.

.. seealso::

For more details on armatures usage, see the :doc:`armature section &lt;/rigging/armatures/index&gt;`.

Options
=======

.. figure:: /images/modifier-armature.png

Armature Modifier.

Object
The name of the armature object used by this modifier.
Preserve Volume
Use quaternions for preserving volume of object during deformation. It can be better in many situations.

Without *Preserve Volume*, rotations at joints tend to scale down the neighboring geometry,
up to nearly zero at 180 degrees from rest position.
With *Preserve Volume*, the geometry is no longer scaled down, but there is a "gap",
a discontinuity when reaching 180 degrees from rest position.

.. list-table:: Example of Quaternion option effects.
Note that the IcoSphere is deformed using the envelopes weights.

* - .. figure:: /images/rigging_skinning_preserve-volume-1.png
:width: 200px

Initial state.

- .. figure:: /images/rigging_skinning_preserve-volume-2.png
:width: 200px

100° rotation, Preserve Volume disabled.

- .. figure:: /images/rigging_skinning_preserve-volume-3.png
:width: 200px

180° rotation, Preserve Volume disabled.

* - .. figure:: /images/rigging_skinning_preserve-volume-4.png
:width: 200px

100° rotation, Preserve Volume enabled.

- .. figure:: /images/rigging_skinning_preserve-volume-5.png
:width: 200px

179.9° rotation, Preserve Volume enabled.

- .. figure:: /images/rigging_skinning_preserve-volume-6.png
:width: 200px

180.1° rotation, Preserve Volume enabled.

Vertex Group
The name of a vertex group of the object, the weights of which will be used to determine the influence of this
Armature Modifier's result when mixing it with the results from other *Armature* ones.

Only meaningful when having at least two of these modifiers on the same object,
with *Multi Modifier* activated.

Invert
Inverts the influence set by the vertex group defined in previous setting
(i.e. reverses the weight values of this group).

Bind To
-------

Methods to bind the armature to the mesh.

Vertex Groups
Meshes and lattices only -- When enabled, bones of a given name will deform vertices which belong to
:doc:`vertex groups &lt;/modeling/meshes/properties/vertex_groups/index&gt;` of the same name.
e.g. a bone named "forearm" , will only affect the vertices in the "forearm" vertex group.

The influence of one bone on a given vertex is controlled by the weight of this vertex in the relevant group.
A much more precise method than *Bone Envelopes*, but also generally longer to set up.
Bone Envelopes
When enabled, bones will deform vertices or control points near them,
defined by each bones envelope radius and distance.
Enable/Disable bone :ref:`envelopes &lt;armature-bones-envelope&gt;` defining the deformation
(i.e. bones deform vertices in their neighborhood).

.. list-table:: Example of vertex groups skinning method.

* - .. figure:: /images/rigging_skinning_vertex-groups-skinning-1.png
:width: 320px

The weights of the arm vertex group.

- .. figure:: /images/rigging_skinning_vertex-groups-skinning-2.png
:width: 320px

The weights of the forearm vertex group.

* - .. figure:: /images/rigging_skinning_vertex-groups-skinning-3.png
:width: 320px

The result when posing the armature.

- .. figure:: /images/rigging_skinning_vertex-groups-skinning-4.png
:width: 320px

The same pose, but using envelopes method rather that vertex groups.

.. _modifier-armature-multi-modifier:

Multi Modifier
--------------

Use the same data as a previous modifier (usually also an Armature Modifier) as input.
This allows you to use several armatures to deform the same object, all based on the "non-deformed" data
(i.e. this avoids having the second Armature Modifier deform the result of the first one...).

The results of the Armature Modifiers are then mixed together, using the weights of the
*Vertex Group* as "mixing guides".

.. tip::

Armature Modifiers can quickly be added to objects using the parenting shortcut
:kbd:`Ctrl-P` when the active object is an armature.

*************
Cast Modifier
*************

This modifier shifts the shape of a mesh, curve,
surface or lattice to any of a few pre-defined shapes (sphere, cylinder, cuboid).

It is equivalent to the *To Sphere* tool in *Edit Mode*
:menuselection:`Mesh --&gt; Transform --&gt; To Sphere`, :kbd:`Alt-Shift-S`
and what other programs call "Spherify" or "Spherize", but, as written above,
it is not limited to casting to a sphere.

.. tip::

The :doc:`Smooth Modifier &lt;/modeling/modifiers/deform/smooth&gt;` is a good companion to *Cast*,
since the cast shape sometimes needs smoothing to look nicer or even to fix shading artifacts.

.. note::

For performance reasons, this modifier only works with local coordinates.
If the modified object looks wrong, you may need to apply its rotation :kbd:`Ctrl-A`,
especially when casting to a cylinder.

Options
=======

.. figure:: /images/modifier-cast.png

Cast Modifier.

Cast Type
Menu to choose target shape of the projection.

Sphere, Cylinder, Cuboid
Axis
Toggle buttons to enable/disable the modifier in the X, Y, Z axes directions
(X and Y only for *Cylinder* cast type).

X, Y, Z
Factor
The factor to control blending between original and cast vertex positions.
It is a linear interpolation: 0.0 gives original coordinates (i.e. modifier has no effect),
1.0 casts to the target shape.
Values below 0.0 or above 1.0 exaggerate the deformation, sometimes in interesting ways.
Radius
If non-zero, this radius defines a sphere of influence.
Vertices outside it are not affected by the modifier.
Size
Alternative size for the projected shape. If zero,
it is defined by the initial shape and the control object, if any.
From radius
If activated, calculate *Size* from *Radius*, for smoother results.

Vertex Group
A vertex group name, to restrict the effect to the vertices in it only.
This allows for selective, real-time casting, by painting vertex weights.
Control Object
The name of an object to control the effect.
The location of this object's origin defines the center of the projection.
Also, its size and rotation transform the projected vertices.

.. hint::

Animating (keyframing) this control object also animates the modified object.

Example
=======

.. figure:: /images/modifier-cast-example.jpg
:width: 400px

Top: Suzanne without modifiers. Middle: Suzanne with each type of Cast Modifier (Sphere, Cylinder and Cuboid).
Bottom: Same as above, but now only X axis is enabled.
`Sample blend-file &lt;https://wiki.blender.org/index.php/Media:263-Cast-Modifier.blend&gt;`__.

*****************
Corrective Smooth
*****************

This modifier is used to reduce highly distorted areas of a mesh by smoothing the deformations.

This is typically useful *after* an Armature Modifier,
where distortion around joints may be hard to avoid, even with careful weight painting.

To use this modifier effectively, it is useful to understand the basics of how it works.

Rest State
Used as a reference to detect highly distorted areas.
The original vertex locations are used by default.
Smoothing
Many options for this modifier relate to smoothing which is used internally
to correct the distorted regions.

Options
=======

.. figure:: /images/modifier-corrective_smooth_ui.png

Corrective Smooth Modifier.

The modifier also uses a *Rest* state, to use as a reference
Internally this modifier uses smoothing, so some of the options adjust the kind of smoothing.

.. Shares description with ``smooth.rst``

Factor
The factor to control the smoothing amount.
Higher values will increase the effect.
Values outside this range (above 1.0 or below 0.0) distort the mesh.
Repeat
The number of smoothing iterations.
Higher values generally improve the quality of the smoothing, but the operation is slowed down.
Smooth Type
Select the smoothing method used.

Simple
This simply relaxes vertices to their connected edges.
Length Weight
Uses a method of relaxing that weights by the distance of surrounding vertices.
This option can give higher quality smoothing in some cases, by
better preserving the shape of the original form.
Vertex Group
Use to manually select regions to smooth.
Only Smooth
This option is included to preview the smoothing used, before correction is applied.
Pin Boundaries
Prevent boundary vertices from smoothing.
Rest Source
Select the source for reference vertex positions that defines the undeformed state.

Original Coords
Use the original input vertex positions.
This relies on the original mesh having the same number of vertices as the original mesh.
Bind Coords
Optionally you may bind the modifier to a specific state.
This requires that there are constructive modifiers such as Subdivision Surface or Mirror
being applied before this modifier in the stack.

Example
=======

.. list-table::
An example of a rig using bone envelopes and not weight painting.

* - .. figure:: /images/modifier-corrective_smooth_example_pose_before.png
:width: 350px

Armature only.

- .. figure:: /images/modifier-corrective_smooth_example_pose_after.png
:width: 350px

Armature &amp; corrective smooth

**************
Curve Modifier
**************

The Curve Modifier provides a simple but efficient method of deforming a mesh along a curve object.

The Curve Modifier works on a (global) dominant axis, X, Y, or Z.
This means that when you move your mesh in the dominant direction (by default, the X-axis),
the mesh will traverse along the curve. Moving the mesh perpendicularly to this axis,
the object will move closer or further away from the curve.

When you move the object beyond the curve endings the object will continue
to deform based on the direction vector of the curve endings.

If the curve is 3D, the *Tilt* value of its control points will be used
to twist the deformed object.
In the :menuselection:`Curve tab --&gt; Shape panel` under
:ref:`Path/Curve-Deform &lt;curve-shape-path-curve-deform&gt;`
are options that influence the modifier.

Options
=======

.. figure:: /images/modifier-curve.jpg

Curve Modifier.

Object
The name of the curve object that will affect the deformed object.
Vertex Group
A vertex group name within the deformed object. The modifier will only affect vertices assigned to this group.
Deformation Axis
This is the axis that the curve deforms along.

X, Y, Z, -X, -Y, -Z

Example
=======

Let us make a simple example:

- Remove default cube object from scene and add a Monkey with :menuselection:`Add --&gt; Mesh --&gt; Monkey`
- Now add a curve with :menuselection:`Add --&gt; Curve --&gt; Bézier Curve`

.. _fig-modifier-curve-edit:

.. figure:: /images/modeling_modifiers_deform_curve_example-edit-curve.png
:width: 300px

Edit Curve.

- While in Edit Mode, move the control points of the curve as shown in Fig. :ref:`fig-modifier-curve-edit`,
then exit Edit Mode :kbd:`Tab`.
- Select the Monkey :kbd:`RMB` in *Object Mode*
- Assign the curve to the modifier, as shown below. The Monkey should be positioned on the curve:

.. figure:: /images/modifier-curve.jpg

Assign the Bézier curve to the Curve Modifier (for Monkey).

.. figure:: /images/modeling_modifiers_deform_curve_example-monkeyoncurve1.png
:width: 200px

Monkey on a Curve.

- Now if you select the Monkey, and move it in the Y-direction :kbd:`G-Y`,
the monkey will deform nicely along the curve.

.. tip::

If you press :kbd:`MMB` (or one of :kbd:`X`, :kbd:`Y`, :kbd:`Z`)
while moving the Monkey you will constrain the movement to one axis only.

.. figure:: /images/modeling_modifiers_deform_curve_example-monkeyoncurve2.png
:width: 250px

Monkey deformations.

- In the image above you can see the Monkey at different positions along the curve.
To get a cleaner view over the deformation, a :doc:`Subdivision Surface &lt;/modeling/modifiers/generate/subsurf&gt;`
Modifier with two subdivision levels was applied,
and :doc:`smooth &lt;/modeling/meshes/editing/smoothing&gt;` shading was used.

*****************
Displace Modifier
*****************

The Displace Modifier displaces vertices in a mesh based on the intensity of a texture.
Either procedural or image textures can be used.
The displacement can be along a particular local axis, along the vertex normal,
or the separate RGB components of the texture can be used to displace vertices in the local X,
Y and Z directions simultaneously (sometimes referred to as *Vector Displacement*).

Options
=======

.. figure:: /images/modifier-displace.png

Displace Modifier.

Texture
The name of the texture from which the displacement for each vertex is derived.
If this field is empty, the modifier defaults to 1.0 (white).

Direction
The direction along which to displace the vertices.
Can be one of the following:

X, Y, Z
Displace along a local axis.
Normal
Displace along the vertex normal.
Custom Normal
ToDo.

.. Displace along the average vertex normal (vertex loop?).
RGB to XYZ
Displace along local XYZ axes individually using the RGB components of the texture
(Red values displaced along the X-axis, Green along the Y, Blue along the Z).
This is sometimes referred to as *Vector Displacement*.

Texture Coordinates
The texture coordinate system to use when retrieving values from the texture for each vertex.
Can be one of the following:

UV
Take texture coordinates from face UV coordinates.

UV Map
The UV map from which to take texture coordinates.
If the object has no UV coordinates, it uses the *Local* coordinate system.
If this field is blank, but there is a UV map available
(e.g. just after adding the first UV map to the mesh),
it will be overwritten with the currently active UV map.

.. note::

Since UV coordinates are specified per face, the UV texture coordinate system currently determines the UV
coordinate for each vertex from the first face encountered which uses that vertex;
any other faces using that vertex are ignored.
This may lead to artifacts if the mesh has non-contiguous UV coordinates.

Object
Take the texture coordinates from another object's coordinate system (specified by the *Object* field).

Object
The object from which to take texture coordinates.
Moving the object will therefore alter the coordinates of the texture mapping.

Take note that moving the original object will **also** result in a texture coordinate update.
As such, if you need to maintain a displacement coordinate system while moving the modified object,
consider parenting the coordinate object to the modified object.

If this field is blank, the *Local* coordinate system is used.

Global
Take the texture coordinates from the global coordinate system.

Local
Take the texture coordinates from the object's local coordinate system.

Vertex Group
The name of a vertex group which is used to control the influence of the modifier.
If left empty, the modifier affects all vertices equally.

Midlevel
The texture value which will be treated as no displacement by the modifier.
Texture values below this value will result in negative displacement along the selected direction,
while texture values above this value will result in positive displacement.

*displacement* = *texture_value* - *Midlevel*

Recall that color/ luminosity values are typically between (0.0 to 1.0) in Blender,
and not between (0 to 255).

Strength
The strength of the displacement. After offsetting by the *Midlevel* value,
the displacement will be multiplied by the *Strength* value to give the final vertex offset.

*vertex_offset* = *displacement* × *Strength*.

A negative strength can be used to invert the effect of the modifier.

Example
=======

.. figure:: /images/modifier-displace-braille.jpg

A highly subdivided plane with an image of the Braille alphabet used as the displacement texture.

*************
Hook Modifier
*************

The Hook Modifier is used to deform a *Mesh*, *Curve* a *Lattice* using another object
(usually an *Empty* or a *Bone* but it can be any object).

As the hook moves, it pulls vertices from the mesh with it.
You can think of it as animated
:doc:`proportional editing &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`.

While hooks do not give you the fine control over vertices movement that shape keys do,
they have the advantage that you can grab vertices directly for manipulation.

.. figure:: /images/modifier-hook-example1.png

Two spheres used as Hooks to deform a subdivided cube.

Options
=======

.. figure:: /images/modifier-hook.jpg

Hook Modifier.

Object
The name of the object to hook vertices to.
Vertex Group
Allows you to define the influence per-vertex.

Useful when you do not something other than a spherical field of influence.
Radius
The size of the hooks influence.
Strength
Adjust this hooks influance on the vertices, were (0.0 to 1.0) (no change to fully follows the hook).

Since multiple hooks can work on the same vertices, you can weight the influence of a hook using this property.
Falloff Type
This can be used to adjust the kind of curve that the hook has on the mesh,
You can also define a custom-curve to get a much higher level of control.
Uniform Falloff
This setting is useful when using hooks on scaled objects,
especially in cases where non-uniform scale would stretch the result of the hook.

This is especially useful for lattices, where its common to use non-uniform scaling.

The following settings are only available in Edit Mode:

Reset
Recalculate and clear the offset transform of hook.
Recenter
Set hook center to the 3D cursor position.

Select
Select the vertices affected by this hook.
Assign
Assigns selected vertices to this hook.

.. note::

The Hook Modifier stores vertex indices from the original mesh to determine what to effect;
this means that modifiers that generate geometry, like a Subdivision Surface Modifier,
should always be applied **after** the Hook Modifier;
otherwise the generated geometry will be left out of the hook's influence.

*************************
Laplacian Deform Modifier
*************************

The Laplacian Deform Modifier allows you to pose a mesh while preserving geometric
details of the surface.

The user defines a set of 'anchor' vertices, and then moves some of them around.
The modifier keeps the rest of the anchor vertices in fixed positions, and calculates the best
possible locations of all the remaining vertices to preserve the original geometric details.

This modifier captures the geometric details with the uses of differential coordinates. The
differential coordinates captures the local geometric information how curvature and direction
of a vertex based on its neighbors.

.. note::

You must define a *Anchors Vertex Group*. Without a Vertex Group Modifier does nothing.

Options
=======

.. figure:: /images/modeling_modifiers_deform_laplacian-deform_panel.png

Laplacian Deform Modifier

Repeat
Repetitions iteratively improve the solution found.
The objective is to find the rotation of the differential
coordinates preserving the best possible geometric detail.
Details are retained better if more repetitions are used,
however, it will take longer to calculate.

.. list-table::

* - .. figure:: /images/modeling_modifiers_deform_laplacian-deform_cactus_09.png
:width: 130px

Original Model.

- .. figure:: /images/modeling_modifiers_deform_laplacian-deform_cactus_repeat_1.png
:width: 130px

Repeat: 1.

- .. figure:: /images/modeling_modifiers_deform_laplacian-deform_cactus_repeat_2.png
:width: 130px

Repeat: 2.

- .. figure:: /images/modeling_modifiers_deform_laplacian-deform_cactus_repeat_5.png
:width: 130px

Repeat: 5.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-deform_horse_repeat_0.jpg
:width: 130px

Original Model.

- .. figure:: /images/modeling_modifiers_deform_laplacian-deform_horse_repeat_1.jpg
:width: 130px

Repeat: 1.

- .. figure:: /images/modeling_modifiers_deform_laplacian-deform_horse_repeat_2.jpg
:width: 130px

Repeat: 2.

- .. figure:: /images/modeling_modifiers_deform_laplacian-deform_horse_repeat_10.jpg
:width: 130px

Repeat: 10.

Anchors Vertex Group
A vertex group name, to define the group of vertices that the user uses to transform the model.
The weight of each vertex does not affect the behavior of the modifier;
the method only takes into account vertices with weight greater than 0.

Bind
The *Bind* button is what tells the Laplacian Deform Modifier to actually capture the geometry details
of the object, so that altering the anchors vertices actually alters the shape of the deformed object.

Unbind
After binding the modifier, you may later decide to make changes to the Anchors Vertex Group.
To do so you will first need to *Unbind* the modifier before binding again.

Error Messages
==============

Vertex group *group_name* is not valid
This message is displayed when a user deletes a Vertex Group or when the user changes the
name of the Vertex Group.
Vertices changed from X to Y
This message is displayed when a user add or delete vertices to the mesh.
Edges changed from X to Y
This message is displayed when a user add or delete edges to the mesh.
The system did not find a solution
This message is displayed if the solver SuperLU did not find a solution for the linear system.

.. note::

If the mesh is dense, with a number of vertices greater than 100,000,
then it is possible that the nonlinear optimization system will fail.

History
=======

`Laplacian Surface Editing
&lt;http://igl.ethz.ch/projects/Laplacian-mesh-processing/Laplacian-mesh-editing/laplacian-mesh-editing.pdf&gt;`__
is a method developed by Olga Sorkine and others in 2004.
This method preserves geometric details as much as possible while the user makes editing operations.
This method uses `differential coordinates
&lt;http://igl.ethz.ch/projects/Laplacian-mesh-processing/Laplacian-mesh-editing/diffcoords-editing.pdf&gt;`__
corresponding to the difference between a vector and the weighted average
of its neighbors to represent the local geometric detail of the mesh.

.. figure:: /images/modeling_modifiers_deform_laplacian-deform_diagram_differential_coordinate.png
:width: 369px

Differential Coordinate.

.. seealso::

- `Laplacian Surface Editing (Original paper)
&lt;http://igl.ethz.ch/projects/Laplacian-mesh-processing/Laplacian-mesh-editing/laplacian-mesh-editing.pdf&gt;`__
- `Differential Coordinates for Interactive Mesh Editing
&lt;http://igl.ethz.ch/projects/Laplacian-mesh-processing/Laplacian-mesh-editing/diffcoords-editing.pdf&gt;`__

*************************
Laplacian Smooth Modifier
*************************

The Laplacian Smooth Modifier allows you to reduce noise on a mesh's surface with minimal changes to its shape.

It can also exaggerate the shape using a negative *Factor*.

The Laplacian Smooth is useful for objects that have been reconstructed from the
real world and contain undesirable noise. It removes noise while still
preserving desirable geometry as well as the shape of the original model.

The Laplacian Smooth Modifier is based on a curvature flow Laplace Beltrami operator in a diffusion equation.

Options
=======

.. figure:: /images/modeling_modifiers_deform_laplacian-smooth_panel.png

Laplacian Smooth Modifier.

Repeat
Repetitions allow you to run the Laplacian smoothing multiple times.
Each repetition causes the flow curvature of the mesh to be recalculated again,
and as a result it removes more noise with every new iteration using a small *Factor* &lt; 1.0.

When on 0, no smoothing is done.

.. note::

More repetitions will take longer to calculate.
So beware of doing so on meshes with a large number of vertices.

.. list-table:: With a factor of 0.5.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_repeat0.jpg
:width: 130px

Repeat: 0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_repeat1.jpg
:width: 130px

Repeat: 1.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_repeat5.jpg
:width: 130px

Repeat: 5.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_repeat10.jpg
:width: 130px

Repeat: 10.

.. list-table:: With a factor of 2.0.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_repeat0.png
:width: 130px

Repeat: 0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_repeat1.png
:width: 130px

Repeat: 1.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_repeat5.png
:width: 130px

Repeat: 5.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_repeat10.png
:width: 130px

Repeat: 10.

.. list-table:: With a factor of -0.5.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_repeat0.jpg
:width: 130px

Repeat: 0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_repeat1.jpg
:width: 130px

Repeat: 1.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_repeat5.jpg
:width: 130px

Repeat: 5.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_repeat10.jpg
:width: 130px

Repeat: 10.

Factor
Controls the amount of displacement of every vertex along the curvature flow.

- Using a small *Factor*, you can remove noise from the shape without affecting desirable geometry.
- Using a large *Factor*, you get smoothed versions of the shape at the cost of fine geometry details.
- Using a negative *Factor*, you can enhance the shape, preserving desirable geometry.
- When the *Factor* is negative, multiple iterations can magnify the noise.

.. list-table::

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_lambda0_0.jpg
:width: 130px

Factor: 0.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_lambda0_5.jpg
:width: 130px

Factor: 0.5.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_lambda.jpg
:width: 130px

Factor: 2.5.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_lambda5_0.jpg
:width: 130px

Factor: 5.0.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_lambda0_0.png
:width: 130px

Factor: 0.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_lambda1_0.jpg
:width: 130px

Factor: 1.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_lambda10_0.jpg
:width: 130px

Factor: 10.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_lambda50_0.jpg
:width: 130px

Factor: 50.0.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_lambda0_0.jpg
:width: 130px

Factor: 0.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_lambda20_0.jpg
:width: 130px

Factor: -20.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_lambda50_0.jpg
:width: 130px

Factor: -50.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_lambda300_0.jpg
:width: 130px

Factor: -300.0.

Border
Since there is no way to calculate the curvature flow on border edges, they must be controlled separately.
Border edges are smoothed using a much simpler method, using this property to control the influence.

Positive values will smooth the vertex positions,
while negative values will "enhance" them by transforming them in the opposite direction.

.. list-table:: With a factor of 2.5.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_border0_0.jpg
:width: 130px

Border: 0.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_border1_0.jpg
:width: 130px

Border: 1.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_border.jpg
:width: 130px

Border: 2.5.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_border10_0.jpg
:width: 130px

Border: 10.0.

.. list-table:: With a factor of 20.0.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_border0_0.jpg
:width: 130px

Border: 0.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_border1_0.jpg
:width: 130px

Border: 1.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_border5_0.jpg
:width: 130px

Border: 5.0.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_border20_0.jpg
:width: 130px

Border: 20.0.

.. list-table:: With a factor of -30.0.

* - .. figure:: /images/modifier_laplacian-smooth_example_cup0_0.jpg
:width: 130px

Border: 0.0.

- .. figure:: /images/modifier_laplacian-smooth_example_cup20_0.jpg
:width: 130px

Border: -20.0.

- .. figure:: /images/modifier_laplacian-smooth_example_cup50_0.jpg
:width: 130px

Border: -50.0.

- .. figure:: /images/modifier_laplacian-smooth_example_cup200_0.jpg
:width: 130px

Border: -200.0.

Axis
Toggle buttons to enable/disable deforming vertices in the X, Y and/or Z axis directions.

X, Y, Z

.. list-table::

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_axis.png
:width: 130px

X, Y, Z: Unselected.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_axis_xyz.jpg
:width: 130px

X, Y, Z: Selected.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_axis_xy.jpg
:width: 130px

X, Y: Selected.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_axis_x.png
:width: 130px

X: Selected.

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_axis.png
:width: 130px

X, Y, Z: Unselected.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_axis_xyz.jpg
:width: 130px

X, Y, Z: Selected.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_axis_xy.jpg
:width: 130px

X, Y: Selected.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_axis_x.png
:width: 130px

X: Selected.

Preserve Volume
The smoothing process can produce shrinkage.
That is significant for large *Factor* or large *Repeat* values;
to reduce that effect you can use this option.

.. list-table::

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_volumefalse.png
:width: 130px

Off.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_volumetrue.jpg
:width: 130px

On.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_volume2false.jpg
:width: 130px

Off.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_cube_volume2true.jpg
:width: 130px

On.

Vertex Group
A vertex group name, to constrain the effect to a group of vertices only.
Allows for selective, real-time smoothing or enhancing, by painting vertex weights.

.. list-table::
:header-rows: 1

* - Original Geometry
- No Group Chosen
- Vertex Weights
- Result
* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_repeat0.jpg
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_lambda.jpg
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_femme_paint.jpg
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_femme_wgroup.jpg
:width: 130px

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_normal.png
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_smooth.jpg
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_paint.jpg
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_wgroup.png
:width: 130px

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_vertex0.jpg
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_vertex1.jpg
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_vertex2.jpg
:width: 130px

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_camel_vertex3.jpg
:width: 130px

Normalized
When enabled, the results will depend on face sizes. When disabled, geometry spikes may occur.

.. list-table::

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_monkey_normalized0.jpg
:width: 130px

Original Geometry.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_monkey_normalized1.jpg
:width: 130px

On.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_monkey_normalized2.jpg
:width: 130px

Off.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_monkey_normalized3.jpg
:width: 130px

Off, High Factor.

.. hint::

Meshes with a great number of vertices, more than ten thousand (10,000),
may take several minutes for processing; you can use small portions of the mesh for testing
before executing the modifier on the entire model.

Examples
========

.. list-table::

* - .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_repeat0.jpg
:width: 200px

`Femme Front blend-file
&lt;https://wiki.blender.org/index.php/Media:Apinzonf_GSOC_2012_Media_femme_front.blend&gt;`__.

- .. figure:: /images/modeling_modifiers_deform_laplacian-smooth_t_wgroup.png
:width: 200px

`Cube Smooth blend-file
&lt;https://wiki.blender.org/index.php/Media:Apinzonf_GSOC_2012_Media_cube_smooth.blend&gt;`__.

.. seealso::

:doc:`Smooth Modifier &lt;/modeling/modifiers/deform/smooth&gt;`.

****************
Lattice Modifier
****************

The Lattice modifier deforms the base object according to the shape of a
:doc:`Lattice &lt;/rigging/lattice&gt;` object.
Objects to be deformed can be meshes, curves,
surfaces, text, lattices and even particles.

.. tip::

A Lattice Modifier can quickly be added to selected objects by selecting them all,
then selecting the lattice object last and pressing :kbd:`Ctrl-P` and choosing *Lattice Deform*.
This will both add Lattice Modifiers to the selected objects and parent them to the lattice.

Options
=======

.. figure:: /images/reference-panels-modifier-lattice.jpg

Lattice Modifier.

Object
The :doc:`Lattice &lt;/rigging/lattice&gt;` object with which to deform the base object.
Vertex Group
An optional vertex group name which lets you limit the modifier effect to a part of the base mesh.
Strength
A factor to control blending between original and deformed vertex positions.

Hints
=====

Why would you use a lattice to deform a mesh instead of deforming the mesh itself in
Edit Mode ? There are a couple of reasons for that:

- If your object has a large number of vertices, it would be difficult to edit portions of it quickly in Edit Mode.
Using a lattice will allow you to deform large portions efficiently.
- The smooth deformation you get from a Lattice Modifier can be hard to achieve manually in Edit Mode.
- Multiple objects can use the same lattice, thus allowing you to edit multiple objects at once.
- Like all modifiers, it is non-destructive. Meaning all changes happen on top of the original geometry,
which you can still go back and edit without affecting the deformation.
- A lattice does not affect the texture coordinates of a mesh's surface.

.. note::

When using a lattice to deform particles,
always remember to place the Lattice Modifier after the Particle System Modifier.
Read more about the importance of the modifier stack :ref:`Here &lt;modifier-stack&gt;`.

********************
Mesh Deform Modifier
********************

The Mesh Deform Modifier allows an arbitrary mesh (of any closed shape)
to act as a deformation cage around another mesh.

Options
=======

.. figure:: /images/modifiers_mesh-deform.png

Mesh Deform Modifier.

The Mesh Deform Modifier is reasonably easy to use but it can be very slow to do
the calculations needed to properly map the deform mesh cage to the deformed object.

Object
The name of the mesh object to be used as a deforming mesh cage.

Vertex Group
An optional vertex group of the object's mesh to restrict the vertices that
will be affected by this modifier.
Vertices not in this group will not be deformed.

Invert ``&lt;-&gt;``
Inverts the influence of the selected vertex group, meaning that the group
now represents vertices that will not be deformed by the modifier.

(The setting reverses the weight values of the group).

Precision
The *Precision* number button controls the accuracy with which the
deform mesh cage alters the deformed object, when the points on the cage are moved.
Raising this value higher can greatly increase the time it takes
the Mesh Deform Modifier to complete its binding calculations,
but it will get more accurate cage mapping to the deformed object.

This setting becomes unavailable once a cage has been bound.

Dynamic
When activated, other mesh altering features (such as other modifiers and shape keys)
are taken into account when binding, increasing deformation quality.

The setting is deactivated by default to save memory and processing time when binding.
Like with *Precision*, this setting is unavailable once a cage has been bound.

Bind
Links the current vertex positions of both the modified geometry and the deformer *Object* chosen together.
An unbound Mesh Deform Modifier has no effect --
it must be bound so that altering the shape of the deform mesh cage
actually alters the shape of the modified object.

.. warning::

Depending on the settings of the Mesh Deform Modifier and complexity of the deform mesh cage and/or
deformed object, it can take a long time for this operation to complete.
This can result in Blender not responding to user's actions until it has completed.

It is also possible that Blender will run out of memory and crash.

To be safe, save your blend-file before proceeding!

Unbind
When a deformed object has been associated to a deform mesh cage, it can later be disassociated by clicking the
*Unbind* button which replaced the *Bind* one.
When *Unbind* is clicked, the *deform mesh cage* will keep its current shape;
it will not reset itself back to its original start shape.

If you need its original shape, you will have to save a copy of it before you alter it.

The deformed object will, however, reset back to its original shape that it had
before it was bound to the deform mesh cage.

.. warning::

Significant changes to the entire change mesh *(such as rotating the cage upside down)*
can cause noticeable artifacts.

These can be reduced by binding with a higher *Precision*,
however, it is a known limitation with this modifier and cannot be avoided entirely.

Hints
=====

- Ensure that the normals on the cage mesh point to the outside;
they are used to determine the inside and outside of the cage.
- Besides the outer cage, more faces within the cage, either loose or forming another smaller cage,
can be used for extra control. Such smaller cages may also overlap with the main cage;
for example, to get extra control over eyes, two small sphere cages could be added around them.

.. seealso::

- The :doc:`Lattice Modifier &lt;/modeling/modifiers/deform/lattice&gt;`.
- `Original paper &lt;http://graphics.pixar.com/library/HarmonicCoordinatesB/&gt;`__

*******************
Shrinkwrap Modifier
*******************

The *Shrinkwrap* Modifier allows an object to "shrink" to the surface of another
object. It moves each vertex of the object being modified to the closest position on the
surface of the given mesh (using one of the three methods available).

It can be applied to meshes, lattices, curves, surfaces and texts.

Options
=======

.. figure:: /images/modifier-shrinkwrapnsp.jpg

Nearest Surface Point.

Target
Shrink target, the mesh to shrink to/wrap around.
Offset
The distance that must be kept from the calculated target position, in Blender Units.

Vertex Group
The vertex group to control whether and how much each vertex is displaced to its target position.
If a vertex is not a member of this group, it is not displaced (same as weight 0).

Mode
----

This selector specifies the method to be used to determine the nearest point on the target's surface
for each vertex of the modified object. Some options will add some extra, specific controls to the panel.

Nearest Surface Point
^^^^^^^^^^^^^^^^^^^^^^

This will select the nearest point over the surface of the shrink target.
It adds the extra option *Above surface*,
which always keep the computed vertices above their "floor faces".
This is only meaningful when *Offset* is not null.

Projection
^^^^^^^^^^

This will project vertices along a chosen axis until they touch the shrink target.
Vertices that never touch the shrink target are left in their original position.

.. figure:: /images/modifier-shrinkwrapp.jpg

Projection options.

Subdivision Surface Levels
This applies a (temporary) *Catmull-Clark* subdivision to the modified object,
before computing the wrap when using Projection mode.
Limit
This is a distance limit between original vertex and surface.
If the distance is larger than this limit vertex would not be projected onto the surface,
Axis
Along which local axis of the modified object the projection is done.
These options can be combined with each other, yielding a "median axis" of projection.

X, Y, Z
Direction
This allows you to select the allowed direction(s) of the shrink along the selected axis.
With more than one Shrinkwrap Modifier, negative and positive axes can be combined.

Negative, Positive
Cull Faces
This radio button allows you to prevent any projection over the "front side"
(respectively the "back side") of the target's faces. The "side" of a face is determined
by its normal (front being the side "from where" the normal "originates").
Auxiliary Target
An additional object to project over.

Nearest Vertex
^^^^^^^^^^^^^^

This will snap vertices to the nearest vertex of the shrink target. It adds no extra options.

.. figure:: /images/modifier-shrinkwrapnv.jpg

Nearest Vertex options.

.. seealso::

:doc:`Shrinkwrap Constraint &lt;/rigging/constraints/relationship/shrinkwrap&gt;`.

**********************
Simple Deform Modifier
**********************

The Simple Deform Modifier allows easy application of a simple deformation to an
object (meshes, lattices, curves, surfaces and texts are supported).

Using another object, it is possible to define the axis and origin of the deformation,
allowing application of very different effects.

Options
=======

.. figure:: /images/modifier-simpledeform.png

Simple Deform.

Mode
This radio button defines the deform function applied, among four available:

Twist
Rotates around the Z axis.
Bend
Bends the mesh over the Z axis.
Taper
Linearly scales along Z axis.
Stretch
Stretches the object along the Z axis (negative *Factor* leads to squash),
preserving volume by scaling inversely on the X and Y axes.

Vertex Group
The name of the vertex group that indicates whether and how much each vertex is influenced by the deformation.

Origin
The name of an object that defines the origin of deformation (usually an empty). This object can be:

- Rotated to control the axis (its local Z-axis is now used as the deformation axis).
- Translated to control the origin of deformation.
- Scaled to change the deform factor.

.. note::

When the object controlling the origin (the one in the *Origin* field)
is a child of the deformed object, this creates a cyclic dependency in Blender's data system.
The workaround is to create a new empty and parent both objects to it.

Angle/Factor
The amount of deformation. Can be negative to reverse the deformation.

Limits
These settings allow you to set the lower and upper limits of the deformation.
The upper limit cannot be lower than lower limit.

Lock X Axis / Lock Y Axis (Taper and Stretch modes only)
These controls whether the X and/or Y coordinates are allowed to change or not.
Thus it is possible to squash the X coordinates of an object and keep the Y coordinates intact.

***************
Smooth Modifier
***************

The Smooth Modifier smooths a mesh by flattening the angles between adjacent faces in it,
just like :menuselection:`Specials --&gt; Smooth` in Edit Mode.
It smooths without subdividing the mesh - the number of vertices remains the same.

.. figure:: /images/modifier-mesh-smooth-example01.png

Smooth Modifier applied to a subdivided cube.

This modifier is not limited to smoothing, though.
Its control factor can be configured outside the (0.0 to 1.0) range
(including negative values), which can result in interesting deformations.

Options
=======

Axis
Toggle buttons to enable/disable the modifier in the X, Y and/or Z axes directions.

X, Y, Z
Factor
The factor to control the smoothing amount.
Higher values will increase the effect.
Values outside this range (above 1.0 or below 0.0) distort the mesh.
Repeat
The number of smoothing iterations,
equivalent to executing the smooth tool multiple times.
Vertex Group
A vertex group name, to restrict the effect to the vertices in it only.
This allows for selective, real-time smoothing, by painting vertex weights.

Algorithm
=========

The calculation done by the Smooth Modifier is a simple and logical one,
and can be thought of as the geometric equivalent of blurring images.

Each new vertex position is simply the average position of surrounding vertices
(the vertices connected to the same edge as it).

.. Add diagrams (TODO).

***********************
Surface Deform Modifier
***********************

The Surface Deform Modifier allows an arbitrary mesh surface to
control the deformation of another, essentially transferring its motion/deformation.
One great use for this is to have a proxy mesh for cloth simulation,
which will in turn drive the motion of your final and more detailed mesh,
which would otherwise not be suitable for simulation.

Options
=======

.. TODO update image

.. figure:: /images/modifier-simpledeform.png

Surface Deform.

Target
The object to which to bind. (This setting is unavailable after
binding)
Interpolation falloff
How much a vertex bound to one face of the target will be affected by the surrounding faces.
This essentially controls how smooth the deformations are.
Note that while lower values result in smoother deformations,
they may also introduce slight artifacts.
(This setting is unavailable after binding)
Bind
Bind the current state of the modified mesh to the current state of
the target mesh, such that any later change in the target mesh will
deform the modified mesh as well. Note that until the bind has been
executed, this modifier will have no effect whatsoever.
(This does not affect the target object)
Unbind
Once the mesh is bound, the *Bind* button changes to *Unbind*.
Executing this frees the modified mesh from the target, and resets it its original shape.
(This does not affect the target object)

.. note::

The meshes are bound with regard to global coordinates,
but later transformations on the objects are ignored.
This means that one can freely transform the target or modified object after binding,
without affecting the modified object.
The modified mesh will only pick up changes to the target object's mesh itself.

.. note::

The further a mesh deviates from the target mesh surface, the more
likely it is to get undesirable artifacts. This is an inherent
characteristic of surface binding in general, so it is recommended
to have reasonably well matching meshes, in order to get a good
bind.

.. warning::

Target Mesh Validity

While there are no restrictions with regard to the modified mesh,
the target object's mesh has a few constraints, which if not followed, will prevent a successful bind.
The target mesh has to follow these conditions:

- Must **not** contain edges with more than two faces.
- Must **not** contain concave faces.
- Must **not** contain overlapping vertices (doubles).
- Must **not** contain faces with collinear edges.
..    TODO/Review: {{Review|im= Requires image to show function.}}.

*************
Warp Modifier
*************

This deformation modifier can be used to warp parts of a mesh to a new location in a very
flexible way by using two objects to select the "from" and "to" regions,
with options for using a curve falloff, texture and vertex group.

.. figure:: /images/modifier-warp-example02.png

Warp Modifier applied to a grid.

The Warp Modifier is a bit tricky at first, but it helps to understand how it works.
The modifier requires two points, specified by object origins.
The "from" point designates a point in space that is pulled toward the "to" point.
It is akin to using the
:doc:`Proportional Editing &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`
in Edit Mode.

Options
=======

.. figure:: /images/modifier-warp-example01.png

Warp Modifier.

From
Specify the origin object transformation of the warp.
To
Specify the destination object transformation of the warp.
Preserve Volume
Enables volume preservation when rotating one of the transforms.
Vertex Group
Limit the deformation to a specific vertex group.

Strength
Sets how strong the effect is.
Radius
Sets the distance from the transforms that can be warped by the transform handles.
Falloff Type
Sets the way the strength of the warp change as it goes from the center of the transform to the Radius value.
See :doc:`Proportional Editing &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`
for descriptions of the falloff types.
Texture
Specify a texture the strength is offset by to create variations in the displacement.
Texture Coordinates
Set the way textures are applied to the mesh when using a textured warp.

Object
Specify an object to use when set to Object.
UV Map
Specify a UV map when set to UV.

Usage
=====

The *Warp Modifier* can be awkward to use sometimes and the use case is rather small however,
there are a couple of uses. For example, The *Warp Modifier* can be used to have an interactive
:doc:`Proportional Editing &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`
that can be used for animation.

Another way to use the *Warp Modifier* is to use it similar to the
:doc:`Deform Modifier &lt;/modeling/modifiers/deform/mesh_deform&gt;`.
This allows you to deform parts of the mesh without having to make a vertex group.
.. _bpy.types.WaveModifier.:

*************
Wave Modifier
*************

The Wave Modifier adds a ripple-like motion to an object's geometry.

This modifier is available for meshes, lattices, curves,
surfaces and texts.

.. list-table::

* - .. figure:: /images/modifier-wave-example-circular.jpg
:width: 180px

Circular wave front.

- .. figure:: /images/modifier-wave-example-linear.jpg
:width: 180px

Linear wave front.

- .. figure:: /images/modifier-wave-example-normals.jpg
:width: 180px

Motion enabled for X,
Normals enabled for Y.

Options
=======

.. figure:: /images/modifier-wave.png

Wave Modifier.

Motion
------

Axis
The wave effect deforms vertices/control points in the Z direction,
originating from the given starting point and propagating along the object with circular wave fronts
(if both X and Y are enabled),
or with rectilinear wave fronts (if only one axis is enabled),
then parallel to the axis corresponding to the X or Y button activated.

X, Y
Cyclic
Repeats the waves cyclically, rather than a single pulse.
Normals
For meshes only. Displaces the mesh along the surface normals (instead of the object's Z-axis).

Time
----

Settings to control the animation.

Offset
Time offset in frames. The frame at which the wave begins (if *Speed* is positive),
or ends (if *Speed* is negative). Use a negative frame number to prime and pre-start the waves.
Life
Duration of animation in frames. When set to zero, loops the animation forever.
Damping
An additional number of frames in which the wave slowly damps from the *Height* value
to zero after *Life* is reached.
The dampening occurs for all the ripples and begins in the first frame after the *Life* is over.
Ripples disappear over *Damping* frames.

Position
--------

Position
Coordinates of the center of the waves, in the object's local coordinates.

X, Y
Falloff
Controls how fast the waves fade out as they travel away from the coordinates above
(or those of the *Start Position Object*).

Start Position Object
Use another object as the reference for the starting position of the wave.
Note that you then can animate this object's position, to change the wave's origin across time.

Delimiter &amp; Noise
-----------------

Vertex Group
For meshes only. A vertex group name, used to control the parts of the mesh affected by the wave effect,
and to what extent (using vertex weights). Note a newly created vertex group has empty weights
Texture
Use this texture to control the object's displacement level.
Animated textures can give very interesting results here.

Texture Coordinates
This menu lets you choose the texture's coordinates for displacement:

Local
Object's local coordinates.
Global
Global coordinates.
Object
Adds an additional field just below,
to type in the name of the object from which to get the texture coordinates.
UV
Adds an extra *UV map* property, to select the UV map to be used.

Arguments
---------

The arguments of the wave function.

Speed
The speed, in BU (for "Blender Units") per frame, of the ripple.
Height
The height or amplitude, in BU, of the ripple.
Width
Half of the width, in BU, between the tops of two subsequent ripples (if *Cyclic* is enabled).
This has an indirect effect on the ripple amplitude. If the pulses are too near to each other,
the wave may not reach the zero Z-position, so in this case Blender actually lowers the whole wave
so that the minimum is zero and, consequently, the maximum is lower than the expected amplitude.
See :ref:`modifier-wave-detailhint` below.
Narrowness
The actual width of each pulse: the higher the value the narrower the pulse.
The actual width of the area in which the single pulse is apparent is given by 4/ *Narrowness*.
That is, if *Narrowness* is 1 the *pulse* is 4 units wide, and if *Narrowness*
is 4 the *pulse* is 1 unit wide.

.. important::

All the values described above must be multiplied with the corresponding *Scale* values of the
object to get the real dimensions.

.. _modifier-wave-detailhint:

Technical Details and Hints
===========================

The relationship of the above values is described here:

.. figure:: /images/modeling_modifiers_deform_wave_front-characteristics.png

Wave front characteristics.

To obtain a nice wave effect similar to sea waves and close to a sinusoidal wave,
make the distance between following ripples and the ripple width equal; that is,
the *Narrowness* value must be equal to 2/ *Width*.
E.g. for *Width* to be 1, set *Narrow* to 2.

**************
Array Modifier
**************

The Array Modifier creates an array of copies of the base object, with each copy being offset from the previous
one in any of a number of possible ways. Vertices in adjacent copies can be merged if they are nearby,
allowing smooth :doc:`Subdivision Surface &lt;/modeling/modifiers/generate/subsurf&gt;` frameworks to be generated.

This modifier can be useful when combined with tileable meshes for quickly developing large
scenes. It is also useful for creating complex repetitive shapes.

Multiple Array Modifiers may be active for an object at the same time
(e.g. to create complex three dimensional constructs).

Options
=======

.. figure:: /images/modeling_modifiers_generate_array.png
:align: right

Array Modifier.

Fit Type
Controls how the length of the array is determined. There are three choices, activating respectively the
display of the *Curve*, *Length* or *Count* settings explained below:

Fit Curve
Generates enough copies to fit within the length of the curve object specified in *Curve*.
Fit Length
Generates enough copies to fit within the fixed length given by *Length*.
Fixed Count
Generates the number of copies specified in *Count*.

.. note::

- Both *Fit Curve* and *Fit Length* use the local coordinate system size of the base object, which means that
scaling the base object in *Object Mode* will not change the number of copies generated by the Array Modifier.
- *Fit Length* uses the local coordinate system length of the curve, which means that scaling the curve in
*Object Mode* will not change the number of copies generated by the Array Modifier.
- Applying the scale with :kbd:`Ctrl-A` can be useful for each one.

Offset
------

Constant Offset, X, Y, Z
Adds a constant translation component to the duplicate object's offset.
X, Y and Z constant components can be specified.

Relative Offset, X, Y, Z
Adds a translation equal to the object's bounding box size along each axis, multiplied by a scaling factor,
to the offset. X, Y and Z scaling factors can be specified.

.. figure:: /images/modeling_modifiers_generate_array_offset-relative.png

Relative offset (0.5, 1.0 and 1.5) examples.

Object Offset
Adds a transformation taken from an object (relative to the current object) to the offset.
It is good practice to use an Empty object centered or near to the initial object.
E.g. by rotating this Empty a circle or helix of objects can be created.

.. figure:: /images/modeling_modifiers_generate_array_offset-object.png

Object offset example.

Merge
-----

Merge
If enabled, vertices in each copy will be merged with vertices
in the next copy that are within the given *Distance*.
First Last
If enabled **and** *Merge* is enabled, vertices in the first copy will be merged with vertices
in the last copy (this is useful for circular objects).

.. list-table:: First Last merge example.

* - .. figure:: /images/modeling_modifiers_generate_array_first-last-off.png

Subdivision discontinuity caused by not merging vertices between first and last copies (*First Last* off).

- .. figure:: /images/modeling_modifiers_generate_array_first-last-on.png

Subdivision discontinuity eliminated by merging vertices between first and last copies (*First Last* on).

Distance
Controls the merge distance for *Merge*.

Cap
---

Start Cap / End Cap
This allows either endpoints of the array to have a different mesh subsisted.

For the *start*: as if it was in position -1, i.e. one "array step" before the first "regular" array copy.
For the *end*: as if it was in position *n* + 1, i.e. one "array step" after the last "regular" array copy.

When *Merge* is activated, and the *cap* vertices are within the distance threshold, they will be merged.

.. note::

The start/end cap objects currently do not support the *First Last* option.

Hints
=====

Offset Calculation
------------------

The transformation applied from one copy to the next is calculated as the sum of the three
different components (*Relative*, *Constant* and *Object*),
each of which can be enabled/disabled independently of the others. This allows, for example,
a relative offset of (1.0, 0.0, 0.0) and a constant offset of (0.1, 0.0, 0.0),
giving an array of objects neatly spaced along the X axis with a constant 0.1
unit between them, whatever the original object's size.

Examples
========

.. figure:: /images/modeling_modifiers_generate_array_example-mechanical-chain.png

A chain created from a single link.
`Sample blend-file &lt;https://wiki.blender.org/index.php/Media:Dev-ArrayModifier-Chain01.blend&gt;`__.

.. figure:: /images/modeling_modifiers_generate_array_example-organic-tentacle.jpg

A tentacle created with an Array Modifier followed by a Curve Modifier.

The segment in the foreground is the base mesh for the tentacle; the tentacle is capped by two
specially-modeled objects deformed by the same Curve object as the main part of the tentacle.
`Sample blend-file &lt;https://wiki.blender.org/index.php/Media:Manual-Modifier-Array-Tentacle01.blend&gt;`__.

Mechanical
----------

.. list-table::

* - .. figure:: /images/modeling_modifiers_generate_array_example-mechanical-bridge.jpg
:width: 320px

A bridge made from a tileable mesh.

- .. figure:: /images/modeling_modifiers_generate_array_example-mechanical-track.png
:width: 320px

A track.
`Sample blend-file &lt;https://wiki.blender.org/index.php/Media:Tracktest.blend&gt;`__.

* - .. figure:: /images/modeling_modifiers_generate_array_example-mechanical-cog.jpg
:width: 320px

A cog created from a single segment.
`Blend &lt;https://wiki.blender.org/index.php/Media:Dev-ArrayModifier-Cog01.blend&gt;`__.

- .. figure:: /images/modeling_modifiers_generate_array_example-mechanical-crankshaft.jpg
:width: 320px

A crankshaft.
`Sample blend-file &lt;https://wiki.blender.org/index.php/Media:Dev-ArrayModifier-Crankshaft01.blend&gt;`__.

Fractal
-------

.. list-table::

* - .. figure:: /images/modeling_modifiers_generate_array_example-fractal-1.jpg
:width: 320px

Multi-level array animated with motion blur.

- .. figure:: /images/modeling_modifiers_generate_array_example-fractal-2.png
:width: 320px

Fractal created with multiple arrays.
`Blend &lt;https://wiki.blender.org/index.php/Media:Dev-ArrayModifier-Fractal01.blend&gt;`__.

* - .. figure:: /images/modeling_modifiers_generate_array_example-fractal-3.jpg
:width: 320px

A fractal fern image created with two Array Modifiers and one mirror applied to a cube.

- ..

Organic
-------

.. list-table::

* - .. figure:: /images/modeling_modifiers_generate_array_example-organic-fractal.jpg
:width: 320px

Subdivided cube array with one object offset,
four cubes and a high vertex merge setting to give the effect of skinning.

- .. figure:: /images/modeling_modifiers_generate_array_example-organic-spiral.png
:width: 320px

A double spiral created with two Array Modifiers and one Subdivision Surface Modifier applied to a cube.
As above, the vertex merge threshold is set very high to give the effect of skinning.
`Sample blend-file &lt;https://wiki.blender.org/index.php/Media:Dev-ArrayModifier-Spiral01.blend&gt;`__.

Tutorials
=========

- `Neal Hirsig's Array Modifier Screencast on Vimeo &lt;https://vimeo.com/46061877&gt;`__.
- `Creating A Double Helix With Modifiers &lt;https://wiki.blender.org/index.php/Doc:2.4/Tutorials/Modifiers/A_Double_Helix&gt;`__.

The 'Double Helix' tutorial explains the Array Modifier.
It is for an old Blender Version (2.44) but except for the keyboard
shortcuts it is still valid.

**************
Bevel Modifier
**************

The Bevel Modifier adds the ability to bevel the edges of the mesh it is applied
to, allowing control of how and where the bevel is applied to the mesh.

The Bevel Modifier is a non-destructive alternative to the
:doc:`Bevel Operation &lt;/modeling/meshes/editing/subdividing/bevel&gt;` in edit mode.

.. list-table::

* - .. figure:: /images/modifier_generate_bevel_square_not.png
:width: 150px

Not beveled.

- .. figure:: /images/modifier_generate_bevel_square.png
:width: 150px

Beveled.

The images above show the side views of a plain (Not beveled) cube and a beveled one.

Options
=======

.. figure:: /images/modifier_generate_bevel_none_if.png

Bevel Modifier panel.

Width
The size of the bevel affect. See *Width Method* below.

.. figure:: /images/modifier_generate_bevel_cubes.png
:width: 610px

Three Cubes with 0.1, 0.3 and 0.5 bevel Widths.

Segments
The number of edge loops added along the bevel's face.
Profile
The shape of the bevel, from concave to convex. It has no effect if *Segments* is less than 2.
Material
The index of the material slot to use for the bevel.
When set to -1, the material of the nearest original face will be used.
Only Vertices
When enabled, only the areas near vertices are beveled; the edges are left not beveled.

.. figure:: /images/modifier_generate_bevel_cubes_vertices_only.png
:width: 610px

Three cubes with 0.1, 0.3 and 0.5 bevel Widths, with Only Vertices option enabled.

Clamp Overlap
When enabled, the width of each beveled edge will be limited such that they cannot intersect each other.
Edges that are far apart will still bevel with the full width, only edges too close to each other are affected.
Loop Slide
If there are unbeveled edges along with beveled edges into a vertex,
the bevel tries to slide along those edges when possible.
Turning the option off can lead to more even bevel widths.

Limit Method
Used to control where a bevel is applied to the mesh.

None
No limit, all edges will be beveled.
Angle
Only edges where the adjacent faces form an angle smaller than the defined threshold will be beveled.
Intended to allow you to bevel only the sharp edges of an object without affecting its smooth surfaces.
Weight
Use each edge's bevel weight to determine the width of the bevel.
When the bevel weight is 0.0, no bevel is applied.
See :doc:`here &lt;/modeling/meshes/editing/edges&gt;` about adjusting bevel weights.
Vertex Group
Use weights from a vertex group to determine the width of the bevel.
When the vertex weight is 0.0, no bevel is applied.
An edge is only beveled if both of its vertices are in the vertex group.
See :doc:`here &lt;/modeling/meshes/properties/vertex_groups/vertex_groups&gt;` about adjusting vertex group weights.

.. TODO someone who understands these should write them in plain English, for now just copied the tool-tips.

Width Method
Used to control how the *Width* is measured.

Offset
Amount is offset of new edges from original.
Width
Amount is width of new face.
Depth
Amount is perpendicular distance from original edge to bevel face.
Percent
Amount is percent of adjacent edge length.

****************
Boolean Modifier
****************

The Boolean Modifier performs operations on meshes that are otherwise too complex
to achieve with as few steps by editing meshes manually. The Boolean Modifier
uses one of three Boolean operations that can be used to create a single mesh out of two mesh objects:

:Difference: Negation
:Union: Disjunction
:Intersect: Conjunction

.. TODO: Update image with 'Show all Edges' enabled
.. figure:: /images/modifier_generate_boolean_union_intersect_difference_examples.png

The Union, Intersection and Difference between a Cube and a UV Sphere,
with the modifier applied to the Sphere and using the cube as target.

.. note::

- The Boolean Modifier works with open and closed volumes.
- The Boolean Modifier does not work on edges without faces.
- The target topology determines the new topology of the modified mesh.
- The face normals are taken into account for the calculations.
- Whether faces are marked for smooth or flat for shading does not affect the calculations of this modifier.
- The line at which this modifier is calculated is delimited by the first tangential contact
between faces of the modified mesh and target.

.. tip:: This is a dynamic real-time modifier!

If you have marked your Objects to show the Edges
(in :menuselection:`Properties Editor --&gt; Object --&gt; Display`, enable *Wire*),
you will see the Edge creation process while you are moving your Objects. Depending on your mesh topology,
you can also enable X-Ray and Transparency and see the topology being created in real time.

Usage
=====

To use the *Boolean Modifier* select the desired mesh Object then add a *Boolean Modifier*.
When you add the Boolean Modifier for an object, Blender will need a second object to
be the target of the operation. You can use open or closed meshes,
as long as they have available face normals for the calculations to take effect.
You can add one or more modifiers of this type for an Object but you can only apply one
operation for the Boolean Modifier at a time.

Options
=======

.. figure:: /images/modeling_modifiers_generate_booleans.png

Boolean Modifier Options.

Operations
----------

Operation
Which boolean operation will be used.

Difference
The modified mesh is subtracted from the target mesh.

- If the target Mesh has inverted normals, Blender will Intersect the modified mesh.
- If the modified Mesh has inverted normals, Blender will add both meshes (Union).
- If both Meshes use inverted normals, Blender will Intersect the target Mesh.

Union
The target mesh is added to the modified mesh.

- If the target Mesh has inverted normals, Blender will Intersect the target Mesh.
- If the modified Mesh has inverted normals, Blender will subtract the target Mesh.
- If both Meshes use inverted normals, Blender will Intersect the modified Mesh.

Intersect
The target mesh is subtracted from the modified mesh.

- If the target Mesh has inverted normals, Blender will subtract the target Mesh.
- If the modified Mesh has inverted normals, Blender will intersect the target Mesh.
- If both Meshes use inverted normals, Blender will add both meshes (Union).

Object
The name of the target mesh object.

Solver
TODO

.. _boolean-materials:

Materials
=========

The Boolean Modifier preserves the Materials of the participant Meshes,
including their basic textures and mappings, and the modified mesh will receive its first
active material index assigned to its new topology (the first active material).

Below, some examples are shown to exemplify how materials work with the Boolean Modifier;
we took the cube as the modified mesh, and the icosphere as the target with one material
(white). We added four different indexes to one of the faces of the cube,
leaving another basic material in the other faces.
The top left image shows how the Boolean Modifier interacts with the materials.
The other three images show the three different Boolean operations applied to the modified mesh.
In all the images the meshes have normals pointed outwards with the Icosphere as the target,
and the Cube being the modified mesh.

.. list-table::

* - .. figure:: /images/modifier_generate_boolean_multi_materials_example_base.png

Cube with Multi-Materials and Icosphere with basic Material.

- .. figure:: /images/modifier_generate_boolean_multi_materials_example_union.png

Union: The first active Material of the Cube is added to the new topology.

* - .. figure:: /images/modifier_generate_boolean_multi_materials_example_difference_.png

Difference: The Icosphere was subtracted from the Cube.

- .. figure:: /images/modifier_generate_boolean_multi_materials_example_intersect_.png

Intersect: The resulting Mesh was copied and rotated 180.

The only exception is the difference operation when the normals of the target and modified
mesh are inverted. In this case, Blender will project the textures in an
inverted direction over the target using the center contact of the meshes as a pivot and the
resulting mesh will have the modified mesh subtracted from the target.
For complex target meshes in some particular cases,
you may have to reassign materials to faces because Blender will use the possible projection,
and this may result in a sub-optimal texture assignment. You can see this in the last example below.

.. list-table::

* - .. figure:: /images/modifier_generate_boolean_multi_materials_example_inverted_normals_back.png

Front of the target with the modified mesh materials.

- .. figure:: /images/modifier_generate_boolean_multi_materials_example_inverted_normals_front.png

Back of the target with the modified mesh materials.

UV Mappings
-----------

When you map UV Images to your target, Blender will add a map for each of the faces of the target.
When you apply the Boolean Modifier, Blender will follow the UV maps already assigned to the faces
of the target topology that will be the result of the operation on the modified mesh.
Blender will also use the same image mapped to the target faces in the modified mesh.

.. warning::

Depending on the way you have assigned textures to the faces during the UV unwrap,
and the complexity of your meshes, the boolean operation may generate imperfect UVs for the new faces.

Below we have four Images, a UV sphere mapped with a test grid tinted blue and the other face tinted in purple,
one face of the cube tinted in a light orange and the other faces using the normal test grid.
The first image shows the operation at the start (difference), and on to the right of that shows the resulting mesh.
And in the bottom row we show the unwrap in the Blender UV/Image Editor.

.. list-table::

* - .. figure:: /images/modifier_generate_boolean_uv_boolean_difference_operation_op_start.png

A UV Sphere and a Cube with different UV Maps.

- .. figure:: /images/modifier_generate_boolean_uv_boolean_difference_operation_applied.png

Difference operation applied.

* - .. figure:: /images/modifier_generate_boolean_uv_map_face_modified_mesh.png

Faces of the modified mesh mapped.

- .. figure:: /images/modifier_generate_boolean_uv_map_face_modified_mesh_new_topology.png

New topology mapped and UV faces assigned.

Other Modifiers
===============

The Boolean Modifier calculation is performed using the target modified mesh
topology and dimensions. Other modifiers added to the modified mesh are bypassed.
This means that if a target is using another modifier, like Subdivision Surface,
the resulting topology for the modified mesh will take into account the subdivision of the target;
but for the modified mesh, the basic topology is used anyway (see examples).

If you add Subdivision Surface to the modified mesh with a Boolean Modifier,
Blender will visually add the subdivision for the modified mesh, but not for its calculations;
it will only take into account its basic mesh topology.
If you want to have a Subdivision Surface modifier added to the modified mesh,
you have to apply the Subdivision Surface to the Boolean modified mesh before applying the Boolean operation.

The Boolean Modifier can be added together with other modifiers in the modified mesh,
but depending on the modifier, the calculations cannot be done and/or the modifier cannot execute.
When the modifier cannot execute, it will show the message ``"Cannot execute boolean operation"``,
and when the modifier cannot be applied to the mesh,
Blender will show the message ``"Modifier is disabled, Skipping Apply."``.
In this case, you either have to remove some modifiers or apply the necessary ones.

The most common case is when you add or copy a Boolean Modifier to use the
modified mesh in conjunction with another target later; Blender will place the warning in the
subsequent Boolean Modifiers in the stack depending on the operation,
because you may be creating concurrent Boolean operations for the same modified mesh,
which in most cases is impossible to execute depending on the chosen target. In this case, you
can apply the first Boolean Modifier of the stack for the target and then use the
other Boolean Modifier(s) in the stack for subsequent operations.

Also, if some other modifiers are placed above this modifier and you click on Apply,
Blender will warn you with the message ``"Applied Modifier was not first,
results may not be as expected"``. The best usage scenario for this modifier is to
prepare your modified mesh and target to work with the Boolean Modifier.

When the Boolean Modifier is the first of the stack and is applied, the other Modifiers will
act over the resulting meshes using the resulting topology and will remain in the modifiers stack.

Below are two images: one with the Subdivision Surface modifier added to the target,
and another with the resulting topology.

.. list-table::

* - .. figure:: /images/modifier_generate_boolean_subsurf_added_to_the_target.png

Modifier with Subdivision Surface Target.

- .. figure:: /images/modifier_generate_boolean_resulting_mesh_subsurf_added_to_the_target.png

The Resulting Topology.

As you can see, the added (not applied) Subdivision Surface modifier to the target was taken into consideration.
The topology of the Icosphere with (Level 2) subdivision was completely transferred to the modified mesh.

.. tip:: The target topology determines the resulting topology

The target topology determines the results of the Boolean Modifier operation.
It means that any modifier added to the target which modifies its topology
will affect the resulting mesh of the operation.

Concurrent Operations
=====================

For the modified meshes, you can only apply one operation at a time, but you can use the same
target for other modified meshes and use modified meshes as a target for other meshes as well.
Also, you can copy or add the same modifier to the modifiers stack as many times as you wish
to suit the number of operations you need,
but be aware that if you choose concurrent targets which are, at the same time,
modified meshes pointing to each other, you can cause Blender to crash with closed loops!

Hints
-----

Be aware that other modifiers and their stack position could cause this modifier to fail in
certain circumstances.

.. tip::

The best way to work with this modifier when you need to make lots of sequential operations
of the same modifier is to define the target at the time you need to apply the changes to the topology.

Face Normals
============

When using the Boolean Modifier,
Blender will use the face normal directions to calculate the three Boolean operations.
The direction of the normals will define the result of the three available operations.
When one of the participants has inverted normals, you are in fact multiplying the operation by -1
and inverting the calculation order. You can, at any time, select your modified mesh,
enter Edit Mode and flip the normals to change the behavior of the Boolean Modifier.
See Tips: Fixing Mixed Normals below.

Blender also cannot perform any optimal Boolean operation when one or more of the
mesh Normals of the participants that are touching has outwards/inwards normals mixed.

This means you can use the normals of the meshes pointed completely towards the inside or
outside of your participants in the operation, but you cannot mix normals pointed inwards and
outwards for the faces of the topology used for calculations. In this case,
Blender will enable the modifier and you may apply the modifier, but with bad to no effects.
We made some examples with a cube and an icosphere showing the results.

In the images below, all face normals are pointing outwards (Normal meshes).

.. list-table::

* - .. figure:: /images/modifier_generate_boolean_normals_pointing_outwards.png

Faces with normals pointing outwards.

- .. figure:: /images/modifier_boolean_difference_normals_pointing_outwards.png

Normal Boolean Modifier operation (Difference operation).

In the images below, all face normals are inverted and using the intersection operation

.. list-table::

* - .. figure:: /images/modifier_generate_boolean_normals_pointing_inwards.png

Boolean Operation with inverted normals.

- .. figure:: /images/modifier_generate_boolean_intersection_normals_pointing_inwards.png

Normal Boolean Modifier operation.

Now, let us see what happens when the normal directions are mixed for one of the
participants in the Boolean Modifier operation. The images below show face normals mixed,
pointed to different directions and the resulting operation,
you can see that the modifier has bad effects when applied, leaving faces opened:

.. list-table::

* - .. figure:: /images/modifier_generate_boolean_normals_mixed_inwards_outwards.png

Face normals mixed, pointed to different directions.

- .. figure:: /images/modifier_generate_boolean_resulting_mesh_normals_mixed.png

Resulting operation leaves faces opened.

As you can see, the normal directions can be pointing to any of the Mesh sides,
but cannot be mixed in opposite directions for the faces of the participants.
The Library cannot determine properly what is positive and negative for the operation, so the
results will be bad or you will have no effect when using the Boolean Modifier operation.

A quick way to fix this is to use Blender's
:doc:`Recalculate Normals &lt;/modeling/meshes/editing/normals&gt;` operation in Edit Mode.

If you still have some ugly black gouges you will have to
:doc:`Manually Flip the Normals &lt;/modeling/meshes/editing/normals&gt;`.

Empty or Duplicated Faces
=========================

This modifier does not work when the modified and/or the target mesh uses empty faces in the
topology used for calculations. If the modifier faces a situation where you have empty faces mixed with normal faces,
the modifier will try, as much as possible, to connect the faces and apply the operation.
For situations where you have two concurrent faces at the same position,
the modifier will operate on the target mesh using both faces,
but the resulting normals will get messed. To avoid duplicated faces,
you can remove doubles for the vertices before recalculating the normals outside or inside.
The button for remove doubles is located in the *Mesh Tools* Panel in the 3D View, while in Edit Mode.

The best usage scenario for this modifier is when you have clean meshes with faces pointing
clearly to a direction (inwards/outwards)

Below we show an example of meshes with open faces mixed with normal faces being used to create a new topology.
In this example, a difference between the cube and the icosphere is applied,
but Blender connected a copy of the icosphere to the Cube mesh, trying to apply what was possible.

.. list-table::

* - .. figure:: /images/modifier_generate_boolean_mesh_with_mixed_empty_faces.png

Mesh with two empty faces mixed with normal faces.

- .. figure:: /images/modifier_generate_boolean_mesh_with_mixed_empty_faces_result.png

Result of a difference operation applied.

Open Volumes
============

The Boolean Modifier permits you to use open meshes or non-closed volumes (not open faces).

When using open meshes or non-closed volumes, the Boolean Modifier will not perform
any operation in faces that do not create a new topology filled with faces using the faces of the target.

In the images below, is the resulting operation when using two non-closed volumes with faces forming a new topology.

.. list-table::

* - .. figure:: /images/modifiers_generate_boolean_complete_face_shape.png

Non-closed volumes forming a new topology.

- .. figure:: /images/modifier_generate_boolean_resulting_complete_face_shape.png

Resulting operation using two open volumes.

Now, let us see what happens when we use meshes that are partially open,
incomplete, or meshes that are not forming a new topology.

As you can see in the images below the faces of one participant in the Boolean operation
gives incomplete information to the modifier. The resulting edges get messy and there is
not enough information to create faces for the resulting Mesh.
This example uses a smooth shaded UV-sphere cut in half. As explained before,
the shading (smooth/flat) does not affect the calculations of the modifier.

.. list-table::

* - .. figure:: /images/modifiers_boolean_incomplete_face_shape.png

Open volumes that are not forming a new topology.

- .. figure:: /images/modifier_generate_boolean_resulting_incomplete_face_shape.png

Resulting Operation of image on the left

**************
Build Modifier
**************

The Build Modifier causes the faces of the mesh object to appear or disappear one after the other over time.

By default, faces appear in the order in which they are stored in memory (by default, the order of creation).
The face/vertex order can be altered in Edit Mode by selecting
:doc:`Sort Mesh Elements &lt;/modeling/meshes/editing/misc&gt;` from the *Search Menu* :kbd:`Spacebar`

.. note::

When using Blender Render, if the material of the mesh is a halo rather than a standard one,
then the vertices of the mesh, not the faces, appear one after another.

Options
=======

Start
The start frame of the building process.
Length
The number of frames over which to rebuild the object.

Randomize
Randomizes the order in which the faces are built.
Seed
The random seed.
Changing this value gives a different "random" order when *"Randomize"* is checked --
this order is always the same for a given seed/object set.
Reversed
The modifier will operate in reverse, essentially allowing it to be used as a "deconstruction" effect.
This is useful for making a set of dupli-objects gradually disappear.

Example
=======

The Build Modifier is often useful when needing a way to get a large number of items to progressively appear,
without resorting to animating the visibility of each one by one.
Examples of this include a mesh containing vertices only, which is used as a duplivert emitter,
and has the build modifier on it. Such a setup is a workaround/technique for being able to
art-direct some semi-random layout of a collection of objects (i.e. leaves/balls forming a carpet of sorts)
when doing so with particles is not desirable
(e.g. due to undesirable distribution of items leaving random gaps and overlapping in other places).

.. only:: builder_html

.. figure:: /images/build_modifier_animated.gif
:width: 285px

Build Modifier in action.

.. only:: latex or epub

An example of the build modifier at work can be found at:
https://docs.blender.org/manual/en/dev/_images/build_modifier_animated.gif

*****************
Decimate Modifier
*****************

The Decimate Modifier allows you to reduce the vertex/face count of a mesh with minimal shape changes.

This is not usually used on meshes which have been created by modeling carefully and economically
(where all vertices and faces are necessary to correctly define the shape).
But if the mesh is the result of complex modeling,
sculpting and/or applied Subdivision Surface/Multiresolution Modifiers,
the Decimate Modifier can be used to reduce the polygon count for a performance increase,
or simply remove unnecessary vertices and edges.

The Decimate Modifier is a quick and easy way of reducing the polygon count of a
mesh non-destructively. This modifier demonstrates the advantages of a mesh modifier system
because it shows how an operation which is normally permanent and destroys original mesh data,
can be done interactively and safely using a modifier.

Unlike the majority of existing modifiers, the Decimate Modifier does not allow
you to visualize your changes in Edit Mode.

Options
=======

.. figure:: /images/modifier-decimate.jpg

Decimate Modifier.

Decimate Type
-------------

Collapse
^^^^^^^^

Merge vertices together progressively, taking the shape of the mesh into account.

Ratio
The ratio of faces to keep after decimation.

- On 1.0: the mesh is unchanged.
- On 0.5: edges have been collapsed such that half the number of faces remain (See *Note* below).
- On 0.0: all faces have been removed.

.. note::

Although the *Ratio* is directly proportional to the number of remaining faces,
triangles are used when calculating the ratio.

This means that if your mesh contains quads, the number of remaining faces will be larger than expected,
because quads remain unchanged if their edges are not collapsed.

This is only true if the *Triangulate* option is disabled.

Vertex Group
A vertex group that controls what parts of the mesh are reduced.
Factor
ToDo.
Triangulate
ToDo.
Symmetry
Maintains symmetry on a single axis.

Un-Subdivide
^^^^^^^^^^^^

Can be thought of as the reverse of subdivide.
Attempts to remove edges that were the result of a subdivide operation.
For meshes with a mainly grid based topology (without giving uneven geometry).
If additional editing has been done after the subdivide operation, the results may be unexpected.

Iterations
The number of times to perform the un-subdivide operation.
Two iterations is the same as one subdivide operation, so you will usually want to use even numbers.

Planar
^^^^^^

Reduces detail on forms comprised of mainly flat surfaces.

Angle Limit
Dissolve geometry which form angles lower than this setting.

All Boundaries
When enabled, all vertices along the boundaries of faces are dissolved.
This can give nicer results when using a high *Angle Limit*.

Delimit
Prevent dissolving geometry in certain places.

Normal
Does not dissolve edges on the borders of areas where the face normals are reversed.
Material
Does not dissolve edges on the borders of where different materials are assigned.
Seam
Does not dissolve edges marked as seams.

Further Options
---------------

Face Count
This label shows the number of remaining faces as a result of applying the Decimate Modifier.

*******************
Edge Split Modifier
*******************

The Edge Split Modifier splits edges within a mesh.
The edges to split can be determined from the edge angle (i.e. angle between faces forming this edge),
and/or edges marked as sharp.

Splitting an edge affects vertex normal generation at that edge, making the edge appear sharp.
Hence, this modifier can be used to achieve the same effect as :ref:`Auto Smooth &lt;auto-smooth&gt;`,
making edges appear sharp when their angle is above a certain threshold.
It can also be used for manual control of the smoothing process,
where the user defines which edges should appear smooth or sharp
(see :doc:`Mesh Smoothing &lt;/modeling/meshes/editing/smoothing&gt;` for other ways to do this).
If desired, both modes can be active at once.

The output of the Edge Split Modifier is available to export scripts,
making it quite useful for creators of game content.

Options
=======

.. figure:: /images/modeling_modifiers_generate_edge-split.png

Edge Split Modifier.

Edge Angle
When enabled, edges will be split if the angle between its
two adjacent faces is greater than the *Split Angle*.

Split Angle
On 0: all edges are split. On 180: no edges are split.

Sharp Edges
When enabled, edges will be split if they were marked as sharp using :menuselection:`Edge Specials --&gt; Mark Sharp`
(Menu shortcut: :kbd:`Ctrl-E` in Edit Mode).

.. note::

:term:`Non-manifold` edges (edges shared by more than two faces) will always be split.

Examples
========

.. list-table::

* - .. figure:: /images/modeling_modifiers_generate_edge-split_example-1.png

Flat Shading.

- .. figure:: /images/modeling_modifiers_generate_edge-split_example-2.png

Smooth Shading.

* - .. figure:: /images/modeling_modifiers_generate_edge-split_example-3.png

Smooth Shading with Edge Split.

- .. figure:: /images/modeling_modifiers_generate_edge-split_example-4.png

Smooth Shading with Edge Split and Subdivision Surface.

.. note::

Splitting edges can also be performed manually in Edit Mode using:
:menuselection:`Edge Specials --&gt; Edge Split` (Menu shortcut: :kbd:`Ctrl-E`).

*************
Mask Modifier
*************

The Mask Modifier allows vertices of an object to be hidden dynamically based on vertex groups.

Options
=======

Mode
The Mask Modifier can hide parts of a mesh based on two different modes, selectable from this select menu.

Vertex Group
When the *Vertex Group* option is selected,
all vertices belonging to the chosen Vertex Group (with a weight above zero) will be visible,
and all other vertices will be hidden.

.. figure:: /images/modifier-mask-vg.png
:width: 350px

Vertex Group.

Armature
When in Pose Mode,
vertices belonging to the Vertex Group associated with the active bone (same names) will be visible.
Vertices not in that group will be hidden.

.. figure:: /images/modifier-mask-a.png
:width: 350px

Armature.

Inverse
Normally, vertices belonging to the selected Vertex Group (or group associated with the active pose-bone)
will be shown. The *Invert* toggle allows you to reverse this behavior, instead showing all vertices
which do not belong to the Vertex Group, and hiding those that do.

***************
Mirror Modifier
***************

.. figure:: /images/modifiers_mirror_example_cube.png
:width: 350px

The corner of a cube mirrored across three axes to form... well... a cube.

The Mirror Modifier mirrors a mesh along its *local* X-, Y- and/or Z-Axes, across the object's center
(the mirror plane is then defined by the two other axes).

It can also use another object as the mirror center, then use that object's local axes instead of its own.

Options
=======

.. figure:: /images/modifiers_mirror.png

Mirror Modifier.

Axis
----

The X-, Y-, Z-axis along which to mirror
(i.e. the axis perpendicular to the mirror plane of symmetry).

To understand how the axis applies to the mirror direction, if you were to mirror on the X axis,
the positive X values of the original mesh would become the negative X values on the mirrored side.

You can select more than one of these axes. And will then get more mirrored copies.
With one axis you get a single mirror, with two axes four mirrors, and with all three axes eight mirrors.

Options
-------

Merge
Where a vertex is in the same place (within the *Merge Limit* distance) as its mirror it will be
merged with the mirrored vertex.
Clipping
Prevents vertices from moving through the mirror plane(s) while the user is transforming them in Edit Mode.

If *Clipping* is enabled but vertices are beyond the mirror plane and outside of the
*Merge Limit*, the vertices will not be merged. But as soon as the vertices are within
*Merge Limit* they are snapped together and cannot be moved beyond the mirror plane.

.. note::

Vertices on the mirror plane will be unable to move away from the mirror plane
as long as *Clipping* is enabled.
You must disable *Clipping* to be able to move the vertices along the mirror axis again.

Vertex Groups
When enabled, the Mirror Modifier will try to mirror existing vertex groups.

A very nice feature, but one that has very specific prerequisites:

- The vertex groups you want to mirror must be named following the usual left/right pattern
(i.e. suffixed by something like ".R", ".right", ".L", etc).
- The mirror side vertex group must already exist (it will not be created automatically).
It must also be completely empty (no vertices assigned to it).

Textures
--------

The U and V options allows you to mirror the UV texture coordinates across the middle
of the image.

E.g. if you have a vertex with UV coordinates of (0.3, 0.9),
its mirror copy will have UV coordinates of (0.7, 0.1).

Further Options
---------------

Merge Limit
The maximum distance between a vertex and its mirror copy before they are merged together.
In other words, a vertex may be half this distance away from the mirror plane before it snaps to it.
Mirror Object
An :ref:`Object Selector &lt;ui-eye-dropper&gt;` to select an object (usually an empty),
to be used as the reference for the mirror process:
its center and axes will drive the plane(s) of symmetry.
You can of course animate its position/rotation to animate the mirror effect.

Hints
=====

Many modeling tasks involve creating objects that are symmetrical. However, there used to be
no quick way to model both halves of an object without using one of the workarounds that have
been discovered by clever Blender artists over the years. A common technique was to model one
half of an object and use :kbd:`Alt-D` to create a linked duplicate which can then be
scaled on one axis by -1 to produce a perfect mirror-image copy which updates in real time as you edit.

The Mirror Modifier offers a simpler way to do this. Once your modeling is completed you can either
click *Apply* to make a real version of your mesh or leave it as is for future editing.

Using the Mirror Modifier with a Subdivision Surface Modifier
-------------------------------------------------------------

When using the Mirror Modifier along with a
:doc:`Subdivision Surface &lt;/modeling/modifiers/generate/subsurf&gt;`
modifier, the order in which the modifiers are placed is important.

.. figure:: /images/modifier-mirror-subsurf2.png
:width: 300px

Subdivision Surface Modifier before Mirror Modifier.

The above image shows the Subdivision Surface Modifier placed before the Mirror one; as you
can see the effect of this is that the mesh is split down the center line of the mirror effect.
This is because the Subdivision calculation moves vertices away from the mirror plane, too far away from the
*Merge Limit*.

.. figure:: /images/modifier-mirror-subsurf1.png
:width: 300px

Mirror Modifier before Subdivision Surface Modifier.

The above image shows the Mirror Modifier placed before the Subdivision Surface Modifier.
In this order, the mirror calculation is done and the vertices are merged together.
Only after that does the Subdivision Surface Modifier move any vertices.

Accurately Positioning the Mirror Plane
---------------------------------------

To apply a Mirror Modifier, it is common to have to move the object's center onto
the edge or face that is to be the axis for mirroring.
This can be tricky when attempted visually.

A good technique to achieve an exact position is
to select the edge, then use :kbd:`Shift-S` and choosing *Cursor to Selection*.
This will position the 3D Cursor in the center of the edge.
Finally, press :kbd:`Ctrl-Alt-Shift-C` for the *Set Origin* menu,
then select *Origin to 3D Cursor*. This will move the object's center
(and thus, the mirror plane) to where the 3D cursor is located,
and the mirroring will be exact.

An alternative is to use an Empty as a *Mirror Object* that you move to the correct position.
..    TODO/Review: {{review|im=needs examples}}.

************************
Multiresolution Modifier
************************

The Multiresolution Modifier (often shortened to "Multires") gives you the ability to subdivide a mesh similarly
to the :doc:`Subdivision Surface Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`,
but also allows you to edit the new subdivision levels in sculpt mode.

.. note::

The Multiresolution Modifier is the only modifier that cannot be repositioned in the stack if it means that
there will be geometry or other object data created or removed before it
(e.g. all *Generate*, some *Modify* and some *Simulate* modifiers
cannot come before the Multiresolution Modifier.)

Options
=======

.. figure:: /images/modeling_modifiers_generate_multiresolution.png

Multiresolution Modifier.

Type
Sets the type of subdivision.

Simple
Maintains the current shape, and simply subdivides edges.
Catmull-Clark
Creates a smooth surface, usually smaller than the original, using the standard
`Catmull-Clark &lt;https://en.wikipedia.org/wiki/Catmull%E2%80%93Clark_subdivision_surface&gt;`__
subdivision surface algorithm.

Levels
------

Preview
Set the level of subdivisions to show in the 3D View.
Sculpt
Set the number of subdivisions to use in Sculpt Mode.
Render
Set the number of subdivisions to show when rendering.

Operations
----------

Subdivide
Add another level of subdivision.
Delete Higher
Deletes all subdivision levels that are higher than the current one.
Reshape
Copies vertex coordinates from another mesh.
To use, first select a different mesh object with matching topology and vertex indexes,
then :kbd:`Shift` select the object you wish to copy vertex coordinates to and click *Reshape*.
Apply Base
Modifies the original unsubdivided mesh to match the form of the subdivided mesh.

Further Options
---------------

Subdivide UVs
When enabled, the UV maps will also be subdivided.
(i.e. Blender will add "virtual" coordinates for all sub-faces created by this modifier).
Optimal Display
When drawing the wireframe of this object, the wires of the new subdivided edges will be skipped
(only draws the edges of the original geometry).

Save External
Saves displacements to an external ``.btx`` file.

***************
Remesh Modifier
***************

The Remesh modifier is a tool for generating new mesh topology.
The output follows the surface curvature of the input, but its topology contains only quads.

.. figure:: /images/modeling_modifiers_generate_remesh_screenshot-00.png
:width: 600px

Options
=======

Mode
There are three basic modes available in the Remesh Modifier: Blocks, Smooth and Sharp.

.. figure:: /images/modeling_modifiers_generate_remesh_mode-cone-example.png

This example shows a cone with each of the different remesh modes.
From left to right: original cone, Blocks, Smooth, and Sharp.

The output topology is almost identical between the three modes;
what changes is the smoothing.

Blocks
There is no smoothing at all.
Smooth
Output a smooth surface.
Sharp
Similar to *Smooth*, but preserves sharp edges and corners.
In the above image, the circular bottom of the cone and the top
point of the cone are more accurately reproduced in Sharp mode.

Octree Depth
The Octree Depth sets the resolution of the output. Low values will generate larger faces relative to the input,
higher values will generate a denser output.

.. figure:: /images/modeling_modifiers_generate_remesh_depth-cone-example.png

Input mesh, and the low to high resolution output meshes.

Scale
The result can be tweaked further by setting the Scale;
lower values effectively decrease the output resolution.
Sharpness
Shown when using the *Sharp Mode* -- Higher values produce edges more similar to the input,
while lower values filter out noise.
Smooth Shading
Output faces with smooth shading rather than flat shading.
The smooth/flat shading of the input faces is not preserved.
Remove Disconnected Pieces
Filter out small disconnected pieces of the output.

Threshold
Use this to control how small a disconnected component must be to be removed.

.. figure:: /images/modeling_modifiers_generate_remesh_remove-disconnected-example.png

The input mesh (left) is fairly noisy,
so the initial output of the Remesh Modifier (center) contains small disconnected pieces.
Enabling Remove Disconnected Pieces (right) deletes those faces.

Usage
=====

In the Modifier panel, add a Remesh Modifier.
The input mesh should have some thickness to it; if the input is completely flat,
add a :doc:`Solidify Modifier &lt;/modeling/modifiers/generate/solidify&gt;` above the Remesh Modifier.

Examples
========

.. figure:: /images/modeling_modifiers_generate_remesh_text-00.png

Remesh Modifier applied to text to improve topology.

.. only:: builder_html and (not singlehtml)

.. youtube:: Mh-gUnS2c0Y

.. vimeo:: 21096739

.. only:: not builder_html and (singlehtml)

A video can be found at https://www.youtube.com/watch?v=Mh-gUnS2c0Y and https://vimeo.com/21096739

**************
Screw Modifier
**************

The Screw Modifier is similar to the *Screw tool* in the *Tool Shelf*
in that it takes a profile object, a Mesh or a Curve, to create a helix-like shape.

.. figure:: /images/modifier-screw-align.jpg
:width: 600px

Properly aligning the profile object is important.

The profile should be properly aligned to the cardinal direction of the object rather than to the screw axis.

Options
=======

.. figure:: /images/modifier-screw.png

Screw Modifier.

Axis
The axis along which the helix will be built.

Screw
The height of one helix iteration.
Axis Object
The name of an object to define the axis direction.

Object Screw
Use the distance from the *Axis Object* to define the height of one helix iteration.
Angle
Degrees for a single helix revolution.
Steps
Number of steps used for a single revolution displayed in the 3D View. Beware of setting this higher than
*Render Steps*, which is the value used for rendering.
Render Steps
As above, but used during render time. Increase to improve quality.
Smooth Shading
Output faces with smooth shading rather than flat shading.
The smooth/flat shading of the input geometry is not preserved.
Calc Order
Order of edges is calculated to avoid problems with normals and shading. Only needed for meshes, not curves.
Flip
Flip normals direction.
Iterations
Number of revolutions.
Stretch U/V
Stretch the UV coordinates from (0.0 to 1.0) when UVs are present.

*************
Skin Modifier
*************

The Skin Modifier uses vertices and edges to create a skinned surface,
using a per-vertex radius to better define the shape.
The output is mostly quads, although some triangles will appear around intersections.

It is a quick way to generate base meshes for sculpting and/or smooth organic shapes with
arbitrary topology.

.. note::

Faces in the original geometry are ignored by the Skin Modifier.

Options
=======

.. figure:: /images/modeling_modifiers_generate_skin.jpg
:width: 300px

Skin Modifier.

Create Armature
---------------

Create an armature on top of the object. Each edge becomes a bone.

.. note::

If the root vertex has more than one adjacent edge,
an extra bone will be created to serve as the root.

This function does the following:

#. A new armature object is added with bones matching the input mesh.
The active selection is switched to the new armature.
#. Weight groups are added to the input mesh. The Skin Modifier propagates these weights to the output as well.
#. An Armature Modifier is added directly below the Skin Modifier.
Note that the Armature Modifier is being applied after the
Skin Modifier because it should only deform the output,
whereas if it were above the Skin Modifier it might change the resulting topology.

Smoothing
---------

Branch Smoothing
A branch point is a vertex with three or more connected edges.
These areas tend to produce more complicated topology, some of which may overlap.
The *Branch Smoothing* setting relaxes the surface around these points,
with the side effect of shrinking the surface.

Smooth Shading
Output faces with smooth shading rather than flat shading.
The smooth/flat shading of the input geometry is not preserved.

Selected Vertices
-----------------

Mark/Clear Loose
By default, a branch vertex (vertex with three or more connected edges)
will generate extra edge loops along adjacent edges in order to keep the output tight.
Branches can be made loose by clicking *Mark Loose*, which will allow the output to stretch between
all adjacent vertices. This can be disabled again by clicking *Clear Loose* with the vertex selected.
Mark Root
Marking a vertex as root causes that vertex to be used for calculating rotations for connected limbs.
Root vertices also affect the armature output; they will be used as the origin for the root bones.

Roots are shown in the 3D View with a red dashed circle around the vertex.

Each set of connected vertices should have one root node.
*Mark Root* enforces the one-root per set rule, so it is not necessary to manually unmark roots.
Equalize Radii
Makes the skin radii of selected vertices equal on each axis.

Symmetry Axes
-------------

The Symmetry Axes checkboxes are used to keep the output topology symmetrical in their respective axes.
In other words, using it avoids merging triangles across an axis unless the triangles form a symmetric quad.

.. note::

These symmetry axes checkboxes do not add geometry flipped across an axis.
For that, the Mirror Modifier should be used, typically placed above the Skin Modifier.

Usage
=====

Add the Skin Modifier to a mesh. Disable *Limit selection to visible* in the 3D View so that you can see
the vertices inside the new geometry. Ensure the modifier is enabled for display in Edit Mode (on by default).

The Skin Modifier uses ordinary vertices and edges as input.
All of the regular Edit Mode tools (such as extrude, subdivide, grab, scale, and rotate) can be used when building
a skinned mesh.

Skin Resize
-----------

The radii of input vertices can be individually scaled in Edit Mode
to alter the thickness of the skin by pressing :kbd:`Ctrl-A`.
Non-uniform scaling of the X and Y axes is accessible by locking it with :kbd:`X` or :kbd:`Y`.
The radius can also be adjusted in the *Transform* panel of the *Properties* region.

Examples
========

.. _fig-modifier-skin-creature:

.. figure:: /images/modeling_modifiers_generate_skin_example.png

Simple creature, made with only the Skin Modifier.

#. In the *modifiers* menu, add a Skin Modifier.
#. :kbd:`Tab` into edit mode and start extruding.
#. Try to sketch results similar to Fig. :ref:`fig-modifier-skin-creature`,
through extruding the vertices of the object.
#. Use :kbd:`Ctrl-A` to change the size of the different regions within the creature.
#. Use *Mark Loose* at regions like the neck, to merge these faces more together.
#. To get smoother results, activate *Smooth Shading* and add a
:doc:`Subdivision Surface &lt;/modeling/modifiers/generate/subsurf&gt;`

External links
==============

- `Skin Modifier Development at Blender Nation
&lt;http://www.blendernation.com/2011/03/11/skin-modifier-development/&gt;`__ --
An early demonstration of the Skin Modifier by Nicholas Bishop (March 2011).
- Ji, Zhongping; Liu, Ligang; Wang, Yigang (2010).
`B-Mesh: A Fast Modeling System for Base Meshes of 3D Articulated Shapes
&lt;http://www.math.zju.edu.cn/ligangliu/CAGD/Projects/BMesh/&gt;`__,
Computer Graphics Forum 29(7), pp. 2169-2178. -- The work this modifier is based on
(`direct link to PDF &lt;http://www.math.zju.edu.cn/ligangliu/cagd/projects/bmesh/paper/bmesh.pdf&gt;`__).
- `Related thread on Blender artists
&lt;http://blenderartists.org/forum/showthread.php?209551-B-mesh-modeling-tools-papers-better-than-zsfere&gt;`__.

*****************
Solidify Modifier
*****************

The Solidify Modifier takes the surface of any mesh and adds depth to it.

Options
=======

.. figure:: /images/modifier-solidify.png

Solidify Modifier.

Thickness
The depth to be solidified.
Offset
A value between (-1 to 1) to locate the solidified output inside or outside the original mesh.
Set to 0.0, the solidified output will be centered on the original mesh.
Clamp
A value between (0 to 2) to clamp offsets to avoid self intersection.

.. figure:: /images/modifier-solidify-clamp.png

Clamp Offset.

Vertex Group
Only vertices in this group are solidified. Their weights are multiplied by the thickness,
so vertices with lower weights will be less thick.

Invert
Reverses the vertex group, so that only vertices which are **not** in the vertex group are solidified.
Factor
How much the vertex weights are taken into account.

- On 0.0 , vertices with zero weight will have no thickness at all.
- On 0.5 , vertices with zero weight will be half as thick as those with full weight.
- On 1.0 , the weights are ignored and the *thickness* value is used for every vertex.

Crease
These options are intended for usage with the :doc:`Subdivision Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`.

.. figure:: /images/modifier-solidify-rims.png
:width: 350px

Rim and edges. In this example, the object was assigned a second material used to color the rim red.

Inner
Set a crease to the inner edges.
Outer
Set a crease to the outer edges.
Rim
Set a crease to the rim.

Flip Normals
Reverse the normals of all geometry (both the inner and outer surfaces).
Even Thickness
Maintain thickness by adjusting for sharp corners.
Sometimes improves quality but also increases computation time.
High Quality Normals
Normals are calculated to produce a more even thickness.
Sometimes improves quality but also increases computation time.
Fill Rim
Fills the gap between the inner and outer edges.
Only Rim
Will not have an extruded surface parallel to the original but instead will only have the perpendicular rim.

.. note::

*Fill Rim* and *Only Rim* only make a difference on :term:`non-manifold` objects,
since the "rims" are generated from the borders of the original geometry.

Material Index Offset
Choose a different material to use for the new geometry;
this is applied as an offset from the original material of the face from which it was solidified.

- A value of 0 means it will use the same material.
- A value of 1 means it will use the material immediately below the original material.
- A value of -2 means the material two positions above the original material will be used.

These are clamped to the top-most and bottom-most material slots.

Rim
Similarly, you can give another material to the rim faces.

.. important::

The modifier thickness is calculated using local vertex coordinates. If the object has non-uniform scale,
the thickness will vary on different sides of the object.

To fix this, either apply :kbd:`Ctrl-A` or clear :kbd:`Alt-S` scale.

Known Limitations
=================

Even Thickness
--------------

Solidify thickness is an approximation.
While "Even Thickness" and "High Quality Normals" should yield good results,
the final wall thickness is not guaranteed and may vary depending on the mesh topology.

In order to maintain precise wall thickness in every case, we would need to add/remove faces on the offset shell,
something this modifier does not do since this would add a lot of complexity and slow down the modifier.

****************************
Subdivision Surface Modifier
****************************

The Subdivision Surface Modifier is used to split the faces of a mesh into smaller faces giving a smooth appearance.
Using this modifier, enables you to model complex smooth surfaces with simple, low-vertex meshes.
This allows high resolution mesh modeling without the need to save and maintain
huge amounts of data and gives a smooth *organic* look to the object.

This process creates virtual geometry that is generated non-destructively without modifying the original mesh,
but it can be converted to real geometry that you could edit with the *Apply* button.

Also, like the rest of the Modifiers, order of execution has an important bearing on the results.
For this, see the documentation on the :ref:`modifier stack &lt;modifier-stack&gt;`.

Keep in mind that this is a different operation than its companion,
:doc:`Smooth Shading &lt;/modeling/meshes/editing/smoothing&gt;`.
You can see the difference between the two in the grid image below.

.. figure:: /images/modeling_modifiers_subsurf_grid.png

Subdivisions levels 0 to 3, without and with Smooth Shading.

.. tip::

The Subdivision Surface Modifier does not allow you to edit the new subdivided geometry without applying it,
but the :doc:`Multiresolution Modifier &lt;/modeling/modifiers/generate/multiresolution&gt;` does (in sculpt mode).

Options
=======

.. figure:: /images/modeling_modifiers_generate_subsurf.png

Modifier's Panel.

Type
This toggle button allows you to choose the subdivision algorithm:

Catmull-Clark
The default option, subdivides and smooths the surfaces.
According to its `Wikipedia page &lt;https://en.wikipedia.org/wiki/Catmull%E2%80%93Clark_subdivision_surface&gt;`__,
the "arbitrary-looking formula was chosen by Catmull and Clark based on the aesthetic appearance of the
resulting surfaces rather than on a mathematical derivation."
Simple
Only subdivides the surfaces, without any smoothing
(the same as :menuselection:`Specials --&gt; Subdivide`, in Edit Mode).
Can be used, for example, to increase base mesh resolution when using displacement maps.

Subdivisions
Recursively adds more geometry. For details on polygon counts, see the :ref:`subsurf-performance` section.

View
The number of subdivision levels shown in the 3D View.
Render
The number of subdivision levels shown in renders.

The right combination of these settings will allow you to keep a fast and lightweight
approximation of your model when interacting with it in 3D, but use a higher quality version when rendering.

.. tip::

Be careful not to set the *View* subdivisions higher than the *Render* subdivisions,
this would mean the 3D View will be higher quality than the render.

Options
Subdivide UVs
When enabled, the UV maps will also be subdivided
(i.e. Blender will add "virtual" coordinates for all sub-faces created by this modifier).

.. figure:: /images/modifier-generate-subsurf-subdivideuvs.png

Subdivide UVs on and off.

Optimal Display
When drawing the wireframe of this object, the wires of the new subdivided edges will be skipped
(only draws the edges of the original geometry)
Opensubdiv
See the `OpenSubdiv`_ section.

.. _modeling-modifiers-opensubdiv:

OpenSubdiv
==========

When *OpenSubdiv* is enabled, the modifier evaluation will happen on a compute device.
To enable OpenSubdiv you must first choose the fastest compute device in the
:ref:`User Preferences &lt;prefs-system-opensubdiv&gt;`. Most of the time the
best performance will be achieved when using *GLSL*.
As a result performance of the modifier will be much higher which is great for animations.

.. seealso::

To find more on OpenSubdiv read the
`Release Notes &lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.76/OpenSubdiv&gt;`__.

Improving Performance
---------------------

In order to utilize maximum performance form OpenSubdiv the following things are required:

- The modifier must be last in the :ref:`modifier stack &lt;modifier-stack&gt;`.
- There should be no modifiers prior to the  which changes mesh topology across the time.
- Other objects should not use geometry of OpenSubdiv mesh

Control
=======

Catmull-Clark subdivision rounds off edges, and often this is not what you want.
There are several solutions that allow you to control the subdivision.

.. _modifiers-generate-subsurf-creases:

Weighted Edge Creases
---------------------

Weighted edge creases for subdivision surfaces allows you to change the way
the Subdivision Surface modifier subdivides the geometry to give the edges a smooth or sharp appearance.

.. figure:: /images/subsurfwithcrease.png

A Subdivided Cube with Creased Edges.

The crease weight of selected edges can be changed in the *Transform* panel of the properties region
:kbd:`N`, or by using the shortcut :kbd:`Shift-E` and moving the mouse closer
or further from the selected edges to adjust the crease weight.
A higher value makes the edge "stronger" and more resistant to the smoothing effect of subdivision surfaces.

Edge Loops
----------

.. figure:: /images/cubewithedgeloops.png

Subdivision Level 2 Cube, the same with an extra Edge Loop, and the same with six extra Edge Loops.

The Subdivision Surface Modifier demonstrates why good, clean topology is so important.
As you can see in the figure, the Subdivision Surface Modifier has a drastic effect on a default Cube.
Until you add in additional Loops (with :kbd:`Ctrl-R`), the shape is almost unrecognizable as a cube.

A mesh with deliberate topology has good placement of Edge Loops,
which allow the placement of more Loops (or removal of Loops,
with :kbd:`X` :menuselection:`--&gt; Edge Loop`) to control the sharpness/smoothness of the resultant mesh.

.. _subsurf-performance:

Performance Considerations
==========================

Higher levels of subdivisions mean more vertices, and more vertices means more memory will be used
(both video memory for display (VRAM), and system RAM for rendering).
Blender could potentially crash or hang if you do not have enough memory.

When using high levels of subdivision with a graphics card that has a low total amount
of VRAM, some parts of the geometry will disappear visually. Your mesh will actually be intact,
because the render is generated using your Object Data,
(even though it cannot be shown by your graphics card).

.. tip::

To improve performance in the viewport try enabling :ref:`OpenSubdiv &lt;modeling-modifiers-opensubdiv&gt;`
or if you are using the Cycles render engine consider using
:ref:`Adaptive Subdivision &lt;render-cycles-settings-object-subdivision&gt;`

Keyboard Shortcuts
==================

To quickly add a Subdivision Surface Modifier to one or more objects, select it/them and press :kbd:`Ctrl-1`.
That will add a Subdivision Surface Modifier with *View Subdivisions* on 1.

You can use other numbers too, such as :kbd:`Ctrl-2`, :kbd:`Ctrl-3`, etc,
to add a Subdivision Surface Modifier with that number of subdivisions.
The *Render Subdivisions* will always be on 2 when added like this.

If an object already has a Subdivision Surface Modifier,
doing this will simply change its subdivision level instead of adding another modifier.

Known Limitations
=================

Non Contiguous Normals
----------------------

Blender's subdivision system produces nice smooth subdivided meshes, but any subdivided face
(that is, any small face created by the algorithm from a single face of the original mesh),
shares the overall normal orientation of that original face.

.. list-table::

* - .. figure:: /images/modeling_modifiers_generate_subsurf_normal-orientation-1.png
:width: 320px

Comparison of good normals and bad normals.

- .. figure:: /images/modeling_modifiers_generate_subsurf_normal-orientation-2.png
:width: 320px

Side view of image on left.

Abrupt normal changes can produce ugly black gouges even though
these flipped normals are not an issue for the shape itself.

A quick way to fix this is to use Blender's
:doc:`Recalculate Normals &lt;/modeling/meshes/editing/normals&gt;` operation in Edit Mode.

If you still have some ugly black gouges you will have to
:doc:`Manually Flip the Normals &lt;/modeling/meshes/editing/normals&gt;`.

Concave N-Gons
--------------

While n-gons are supported,
concave n-gons may give ugly overlapping results.

.. figure:: /images/modifier-subsurf_ngon_concave.png
:width: 300px

The n-gons on the right show overlapping results.

********************
Triangulate Modifier
********************

The Triangulate Modifier converts all faces in a mesh (whether it be quads or n-gons) to triangular faces.
This modifier does the exact same function as the Triangulate tool in Edit Mode.

.. list-table::

* - .. figure:: /images/modeling_modifiers_generate_triangulate-before.png
:width: 320px

Mesh before Triangulate Modifier.

- .. figure:: /images/modeling_modifiers_generate_triangulate-after.png
:width: 320px

Mesh after Triangulate Modifier.

Options
=======

Quad Method
Beauty
Split the quads in nice triangles, slower method.
Fixed
Split the quads on the 1st and 3rd vertices.
Fixed Alternate
Split the quads on the 2nd and 4th vertices.
Shortest Diagonal
Split the quads based on the distance between the vertices.

N-gon Method
Beauty
Arrange the new triangles nicely, slower method.
Scanfill
Split the n-gons using a scanfill algorithm.

******************
Wireframe Modifier
******************

The Wireframe Modifier transforms a mesh into a wireframe by iterating over its
faces, collecting all edges and turning those edges into four sided polygons.
Be aware of the fact that your mesh needs to have faces to be wireframed.
You can define the thickness, the material and several other parameters of the generated
wireframe dynamically via the given modifier options.

Options
=======

.. figure:: /images/modifier_wireframe.jpg

Wireframe Modifier.

Thickness
The depth or size of the wireframes.
Offset
A value between (-1 to 1) to change whether the wireframes are
generated inside or outside the original mesh.
Set to zero, *Offset* will center the wireframes around the original edges.
Vertex Group
Restrict the modifier to only this vertex group.

Invert
Inverts the vertex group weights.
Factor
ToDo,

.. figure:: /images/modifier_wireframe_result.jpg
:width: 350px

Wireframes on a displaced plane.
In this example, the wireframes carry a second (dark) material while the displaced plane uses its original one.

Crease Edges
This option is intended for usage with the :doc:`Subdivision Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`.
Enable this option to crease edges on their junctions and prevent large curved intersections.

Crease Weight
Define how much crease (0 to 1) (no to full) the junctions should receive.
Even Thickness
Maintain thickness by adjusting for sharp corners. Sometimes improves quality but also increases computation time.
Relative Thickness
Determines the edge thickness by the length of the edge. Longer edges will be thicker.
Boundary
Creates wireframes on mesh island boundaries.
Replace Original
If this option is enabled, the original mesh is replaced by the generated wireframe.
If not, the wireframe is generated on top of it.
Material Offset
Uses the chosen material index as the material for the wireframe;
this is applied as an offset from the first material.

Examples
========

When you got more Faces that meet at one point they are forming a star like pattern like seen
in the examples below.

.. figure:: /images/modeling_modifiers_generate_wireframe_example-cube.png

Original / Wireframe / Original and Wireframe.

.. figure:: /images/modeling_modifiers_generate_wireframe_example-suzanne.png

Vertex Group weighting: One half 0 weighted, one half 1 weighted.

.. figure:: /images/modeling_modifiers_generate_wireframe_example-crease.png

Cube and Subdivision Surface with 0 / 0.5 / 1 crease weight.

.. warning::

Wireframe thickness is an approximation. While *Even Thickness* should yield good results in many cases,
skinny faces can cause ugly spikes. In this case you can either reduce the extreme angles in the geometry
or disable the *Even Thickness* option.
.. _modifiers-index:

############
Modifiers
############

.. toctree::
:maxdepth: 2

introduction.rst

Modify
======

.. toctree::
:maxdepth: 1

modify/data_transfer.rst
modify/mesh_cache.rst
modify/mesh_sequence_cache.rst
modify/normal_edit.rst
modify/uv_project.rst
modify/uv_warp.rst
modify/weight_edit.rst
modify/weight_mix.rst
modify/weight_proximity.rst

Generate
========

.. toctree::
:maxdepth: 1

generate/array.rst
generate/bevel.rst
generate/booleans.rst
generate/build.rst
generate/decimate.rst
generate/edge_split.rst
generate/mask.rst
generate/mirror.rst
generate/multiresolution.rst
generate/remesh.rst
generate/screw.rst
generate/skin.rst
generate/solidify.rst
generate/subsurf.rst
generate/triangulate.rst
generate/wireframe.rst

Deform
======

.. toctree::
:maxdepth: 1

deform/armature.rst
deform/cast.rst
deform/corrective_smooth.rst
deform/curve.rst
deform/displace.rst
deform/hooks.rst
deform/laplacian_smooth.rst
deform/laplacian_deform.rst
deform/lattice.rst
deform/mesh_deform.rst
deform/shrinkwrap.rst
deform/simple_deform.rst
deform/smooth.rst
deform/surface_deform.rst
deform/warp.rst
deform/wave.rst

Simulate
========

.. toctree::
:maxdepth: 1

simulate/explode.rst
simulate/ocean.rst
simulate/particle_instance.rst

************
Introduction
************

Modifiers are automatic operations that affect an object in a non-destructive way. With modifiers,
you can perform many effects automatically that would otherwise be too tedious to do manually
(such as subdivision surfaces) and without affecting the base geometry of your object.

They work by changing how an object is displayed and rendered, but not the geometry which you can edit directly.
You can add several modifiers to a single object to form `The Modifier Stack`_
and *Apply* a modifier if you wish to make its changes permanent.

.. figure:: /images/modeling_modifiers_introduction_menu.png

Modifiers Menu.

There are four types of modifiers:

Modify
The *Modify* group of modifiers include tools similar to the *Deform Modifiers* (see below),
but which do not directly affect the shape of the object;
rather they affect some other data, such as vertex groups.

Generate
The *Generate* group of modifiers include constructive tools that either change the
general appearance of or automatically add new geometry to an object.

Deform
The *Deform* group of modifiers only changes the shape of an object without adding new geometry,
and are available for meshes, and often texts, curves, surfaces and/or lattices.

Simulate
The *Simulate* group of modifiers activates simulations. In most cases, these
modifiers are automatically added to the modifiers stack whenever a *Particle System*
or *Physics* simulation is enabled. Their only role is to define the
place in the modifier stack used as base data by the tool they represent. Generally,
the attributes of these modifiers are accessible in separate panels.

Interface
=========

.. _fig-modifiers-panel-layout:

.. figure:: /images/modeling_modifiers_introduction_panel-layout.png

Panel Layout (Subdivision Surface as an example).

Each modifier has been brought in from a different part of Blender,
so each has its own unique settings and special considerations. However,
each modifier's interface has the same basic components, see Fig. :ref:`fig-modifiers-panel-layout`.

At the top is the *panel header*.
The icons each represent different settings for the modifier (left to right):

Arrow
Collapse modifier to show only the header and not its options.
Icon
A quick visual reference of the modifier's type.
Name
Every modifier has a unique name per object. Two modifiers on one object must have unique names,
but two modifiers on different objects can have the same name. The default name is based off the modifier type.
Camera
Toggles visibility of the modifier effect in the render.
Eye
Toggles visibility of the modifier effect in the 3D View.
Box
Displays the modified geometry in edit mode, as well as the original geometry which you can edit.
Triangle
When enabled, the final modified geometry will be shown in Edit Mode and can be edited directly.
Up arrow
Moves modifier up in the stack.
Down arrow
Moves modifier down in the stack.
Cross
Deletes the modifier.

.. note::

The *Box* and *Triangle* icons may not be available depending on the type of modifier.

Below the header are two buttons:

Apply
Makes the modifier "real" - converts the object's geometry to match the applied modifier,
and deletes the modifier.
Copy
Creates a duplicate of the modifier at the bottom of the stack.

.. warning::

Applying a modifier that is not first in the stack will ignore the stack order and
could produce undesired results.

Below this header, all of the options unique to each modifier will be displayed.

.. _modifier-stack:

The Modifier Stack
------------------

Modifiers are a series of non-destructive operations which can be applied on top of an object's geometry.
They can be applied in just about any order the users chooses.

This kind of functionality is often referred to as a "modifier stack"
and is also found in several other 3D applications.

In a modifier stack the order in which modifiers are applied has an effect on the result.
Fortunately modifiers can be rearranged easily by clicking the convenient up and down arrow icons.
For example, the image below shows :doc:`Subdivision Surface &lt;/modeling/modifiers/generate/subsurf&gt;`
and :doc:`Mirror &lt;/modeling/modifiers/generate/mirror&gt;` modifiers that have switched places.

.. list-table:: Modifier Stack example.

* - .. figure:: /images/modifier-mirror-subsurf2.png
:width: 320px

The Mirror modifier is the last item in the stack and
the result looks like two surfaces.

- .. figure:: /images/modifier-mirror-subsurf1.png
:width: 320px

The Subdivision surface modifier is the last
item in the stack and the result is a single merged surface.

Modifiers are calculated from top to bottom in the stack.
In this example, the desired result (on right) is achieved by first mirroring the object,
and then calculating the subdivision surface.

Example
^^^^^^^

.. figure:: /images/modeling_modifiers_introduction_stack-example-3.png

In this example a simple subdivided cube has been transformed into a rather complex object using
a stack of modifiers.

`Download example file &lt;https://wiki.blender.org/index.php/:File:25-Manual-Modifiers-example.blend&gt;`__.

**********************
Data Transfer Modifier
**********************

The Data Transfer Modifier transfers several types of data from one mesh to another.
Data types include vertex groups, UV maps, vertex colors, custom normals...

Transfer works by generating a mapping between source mesh’s items (vertices, edges, etc.)
and destination ones, either on an one-to-one basis, or mapping several source items
to a single destination one by interpolated mapping.

.. figure:: /images/modifier-data_transfer_normals_example.png

From left to right, a flat-shaded beveled cube, a smooth-shaded beveled cube,
and an autosmooth-shaded beveled cube copying its normals from the reference,
flat-shaded cube shown as wire here, to achieve the 'fake round corners' effect.

Options
=======

.. figure:: /images/modifier-data_transfer_ui.png

Data Transfer Modifier.

Source Object
Mesh object to copy data from.

If the button to the right of the field is unset, source and destination geometries
are considered in global space when generating the mapping, otherwise they are evaluated
in local space (i.e. as if both object's centers were at the same place).

Max Distance
When the icon "finger" button to the right is enabled, this is the maximum distance
between source and destination to get a successful mapping. If a destination item cannot find
a source one withing that range, then it will get no transfered data.

This allows to transfer a small sub-detailed mesh onto a more complete one
(e.g. from a "hand" mesh towards a "full body" one).

Ray Radius
For ray-casting-based mapping methods, the radius of the cast rays. Especially important for 1D and 2D
items (i.e. vertices and edges), without some width there would be nearly no ray-casting matches...

Mix Mode
Controls how destination data are affected:

All
Replaces everything in destination (note that *Mix Factor* is still used).
Above Threshold
Only replaces destination value if it’s above given threshold *Mix Factor*.
How that threshold is interpreted depends on data type,
note that for boolean values this option fakes a logical AND.
Below Threshold
Only replaces destination value if it’s below given threshold *Mix Factor*.
How that threshold is interpreted depends on data type,
note that for boolean values this option fakes a logical OR.
Mix, Add, Subtract, Multiply
Apply that operation, using mix factor to control how much of source or destination value to use.
Only available for a few types (vertex groups, vertex colors).

Mix Factor
How much of the transfered data gets mixed into existing one (not supported by all data types).

Vertex Group
Allows per-item fine control of the mix factor. Vertex group influence can be reverted using the small
"arrow" button to the right.

Generate Data Layers
This modifier cannot generate needed data layers itself. Once the set of source data to transfer is selected,
this button shall be used to generate matching destination layers.

Selection of Data to Transfer
-----------------------------

To keep the size of the modifier reasonable, the kind of items to be affected must be selected first
(vertices, edges, face corners and/or faces).

Mapping Type
How is generated the mapping between those source and destination items. Each type has its own options,
see `Geometry Mapping`_ below for details.

Data Types
The left column of toggle buttons, to select which data types to transfer.

Multi-layers Data Types Options
In those cases (vertex groups, vertex colors, UVs), one can select which source layers to transfer
(usually, either all of them, or a single specified one), and how to affect destination (either by matching
names, matching order/position, or, if a single source is selected, by specifying manually destination layer).

Islands Handling Refinement
This setting only affects UV transfer currently. It allows to avoid a given destination face to get
UV coordinates from different source UV islands. Keeping it at 0.0 means no island handling at all.
Typically, small values like 0.02 are enough to get good results, but if you are mapping from
a very high poly source towards a very low poly destination, you may have to raise it quite significantly.

Usage
=====

First key thing to keep in mind when using this modifier is that it will **not** create destination data layers.
*Generate Data Layers* button shall always be used for this purpose, once set of source data to transfer
is selected. It should also be well understood that creating those data layers on destination mesh is **not**
part of the modifier stack, which means e.g. that they will remain even once the modifier is deleted, or if
source data selection is modified.

Geometry Mapping
----------------

Geometry mapping is the process by which a given destination vertex/edge/... knows **which part** of the source mesh
to get its data from. It is crucial to understand this topic well to get good results with this modifier.

Topology
The simplest option, expects both meshes to have identical number of items, and match them by order (indices).
Useful e.g. between meshes that were identical copies, and got deformed differently.

One-To-One Mappings
Those always select only one source item for each destination one, often based on shortest distance.

Vertices
Nearest Vertex
Uses source’s nearest vertex.

Nearest Edge Vertex
Uses source’s nearest vertex of source’s nearest edge.
Nearest Face Vertex
Uses source’s nearest vertex of source’s nearest face.

Edges
Nearest Vertices
Uses source’s edge which vertices are nearest from destination edge’s vertices.
Nearest Edge
Uses source’s nearest edge (using edge’s midpoints).
Nearest Face Edge
Uses source’s nearest edge of source’s nearest face (using edge’s midpoints).

Face Corners
A face corner is not a real item by itself, it’s some kind of split vertex attached to a specific face.
Hence both vertex (location) and face (normal, ...) aspects are used to match them together.

Nearest Corner and Best Matching Normal
Uses source’s corner having the most similar *split* normal with destination one,
from those sharing the nearest source’s vertex.
Nearest Corner and Best Matching Face Normal
Uses source’s corner having the most similar *face* normal with destination one,
from those sharing the nearest source’s vertex.
Nearest Corner of Nearest Face
Uses source’s nearest corner of source’s nearest face.

Faces
Nearest Face
Uses source’s nearest face.
Best Normal-Matching
Uses source’s face which normal is most similar with destination one.

Interpolated Mappings
Those use several source items for each destination one, interpolating their data during the transfer.

Vertices
Nearest Edge Interpolated
Uses nearest point on nearest source’s edge, interpolates data from both source edge’s vertices.
Nearest Face Interpolated
Uses nearest point on nearest source’s face, interpolates data from all that source face’s vertices.
Projected Face Interpolated
Uses point of face on source hit by projection of destination vertex along its own normal,
interpolates data from all that source face’s vertices.

Edges
Projected Edge Interpolated
This is a sampling process. Several rays are cast from along the destination’s edge
(interpolating both edge’s vertex normals), and if enough of them hit a source’s edge,
all hit source edges’ data are interpolated into destination one.

Face Corners
A face corner is not a real item by itself, it’s some kind of split vertex attached to a specific face.
Hence both vertex (location) and face (normal, ...) aspects are used to match them together.

Nearest Face Interpolated
Uses nearest point of nearest source’s face, interpolates data from all that source face’s corners.
Projected Face Interpolated
Uses point of face on source hit by projection of destination corner along its own normal,
interpolates data from all that source face’s corners.

Faces
Projected Face Interpolated
This is a sampling process. Several rays are cast from the whole destination’s face (along its own normal),
and if enough of them hit a source’s face, all hit source faces’ data are interpolated into destination one.

*******************
Mesh Cache Modifier
*******************

The Mesh Cache Modifier is used so animated mesh data can be applied to a mesh and
played back, deforming the mesh.

This works in a similar way to shape-keys but is aimed at playing back external files and is
often used for interchange between applications.

.. note:: When using this modifier, the vertex locations are overwritten.

Options
=======

.. figure:: /images/modifiers_mesh_cache.jpg

Mesh Cache Modifier.

Format
The input file format (currently ``.mdd`` and ``.pc2`` are supported).
File Path
Path to the cache file.

Evaluation
----------

Influence
Factor to adjust the influence of the modifiers deformation, useful for blending in/out from the cache data.

Deform Mode
This setting defaults to 'Overwrite' which will replace the vertex locations with those in the cache file.
However, you may want to use shape-keys, for example, and mix them with the mesh-cache.
In this case you can select the 'Deform' option which integrates deformations with the mesh-cache result.

.. note::

This feature is limited to making smaller, isolated edits and
will not work for larger changes such as re-posing limbs.

Interpolation
None or Linear which will blend between frames;
use linear when the frames in the cache file do not match up exactly with the frames in the blend-file.

Time Mapping
------------

Time Mode
Select how time is calculated.

Frame
Allows you to control the frames,
which will ignore timing data in the file but is often useful since it gives simple control.
Time
Evaluates time in seconds,
taking into account timing information from the file (offset and frame-times).
Factor
Evaluates the entire animation as a value from (0 - 1).

Play Mode
Select how playback operates.

Scene
Use the current frame from the scene to control playback.

Frame Start
Play the cache starting from this frame.
Frame Scale
Scale time by this factor (applied after the start value).

Custom
Control animation timing manually.

Evaluation Value
Property used for animation time,
this gives more control of timing -- typically this value will be animated.

Axis Mapping
------------

Forward/Up Axis
The axis for forward and up used in the source file.
Flip Axis
In rare cases you may also need to flip the coordinates on an axis.

.. tip::

Both MDD and PC2 depend on the vertex order on the mesh remaining unchanged;
this is a limitation with the method used so take care not to add/remove vertices once this modifier is used.

****************************
Mesh Sequence Cache Modifier
****************************

The *Mesh Sequence Cache Modifier* is used to **TODO**.
Despite its name, this modifier supports meshes and curves.
It also handles file sequences, as well as meshes and curves with varying number of vertices/control points.

Options
=======

Cache File
Data-block menu to select the Alembic file.

File Path
Path to Alembic file.
Is sequence
Whether or not the cache is separated in a series of files.
Override Frame
Whether to use a custom frame for looking up data in the cache file,
instead of using the current scene frame.

Frame
The time to use for looking up the data in the cache file,
or to determine which to use in a file sequence.
Manual Transform Scale
Value by which to enlarge or shrink the object with respect to the world's origin.
(only applicable through a
:doc:`Transform Cache Constraint &lt;/rigging/constraints/transform/transform_cache&gt;`)
Object Path
The path to the Alembic object inside the archive.

Read Data
Type of data to read for a mesh object respectively: vertices,
polygons, UV maps and Vertex Color layers.

Vertices, Faces, UV, Color

********************
Normal Edit Modifier
********************

The Normal Edit Modifier affects (or generates) custom normals. It uses a few simple parametric methods
to compute normals (quite useful in game development and architecture areas), and mixes back those generated normals
with existing ones.

.. (todo) nice image

Options
=======

.. figure:: /images/modifier-normal_edit_ui.png

Normal Edit Modifier.

Mode
The two modes currently available to generate normals.

Radial aligns normals with the (origin, vertex coordinates) vector, in other words all normals seems to radiate
from the given center point, as if they were emitted from an ellipsoid surface.

Directional makes all normals point (converge) towards a given target object.

Radial/Directional

Target Object
Uses this object’s center as reference point when generating normals.

Optional in *Radial* mode, mandatory in *Directional* one.
Parallel Normals
Makes all normals parallel to the line between both objects’ centers,
instead of converging towards target’s center.

Only relevant in *Directional* mode.

Offset
Gives modified object’s center an offset before using it to generate normals.

Only relevant in *Radial* mode if no *Target Object* is set,
and in *Directional* mode when *Parallel Normals* is set.

Mix Mode
--------

Mix Mode
How to affect existing normals with newly generated ones.

Note the *Multiply* option is **not** a cross product, but a mere component-by-component multiplication.
Mix Factor
How much of the generated normals get mixed into existing ones.
Vertex Group
Allows per-item fine control of the mix factor. Vertex group influence can be reverted using the small
"arrow" button to the right.

Usage
=====

This modifier can be used to quickly generate radial normals for low-poly tree foliage or
"fix" shading of toon-like rendering by partially bending default normals...

The only mandatory prerequisite to use it is to enable *Auto Smooth* option in Mesh properties, *Normals* panel.

.. tip::

More complex normal manipulations can be achieved by copying normals from one mesh to another,
see the :doc:`Data Transfer Modifier &lt;/modeling/modifiers/modify/data_transfer&gt;`.

*******************
UV Project Modifier
*******************

.. figure:: /images/modeling_modifiers_modify_uvproject_example.jpg
:align: center
:width: 350px

Projecting the Blender logo onto Suzanne.

The *UV Project* Modifier acts like a slide projector.
It emits a UV map from the negative Z-axis of a controller object
(such as an :doc:`empty &lt;/modeling/empties&gt;`),
and applies it to the object as the "light" hits it. It can optionally override the objects face texture.

`Download an example &lt;https://wiki.blender.org/index.php/File:Uvproject.blend&gt;`__.

Options
=======

.. figure:: /images/modeling_modifiers_modify_uvproject.png

UV Map
Which UV map to modify. Defaults to the active rendering layer.

Image
The image associated with this modifier. Not required; you can just project a UV for use elsewhere.
*Override Image*, below, defines how the image is used.
Override Image
- When true, the Face Texture of all vertices on the mesh is replaced with the Image.
This will cause the image to repeat, which is usually undesirable.
- When false, the modifier is limited to faces with the Image as their Face Texture.

Projectors
Up to ten projector objects are supported.
Each face will choose the closest and aligned projector with its surface normal.
Projections emit from the negative Z-axis (i.e. straight down a camera or lamp).
If the projector is a camera, the projection will adhere to its perspective/orthographic setting.
Objects
Specify the projector Object.

Aspect X/Y and Scale X/Y
These allow simple manipulation of the image. Only apply when a camera is used as projector *Object*.

Usage
=====

General
-------

UV Project is great for making spotlights more diverse, and also for creating decals to break up repetition.

The modifier's Image property is not generally used.
Instead, a texture mapped to the UV map that the modifier targets is added to the object's Material.
This allows you to prevent the image from repeating by setting
:menuselection:`Texture --&gt; Image Mapping --&gt; Extension to Clip`.

Perspective Cameras
-------------------

When using perspective cameras or spot lamps,
you will likely want to enable the *UV Project* Material Option
(available in the materials panel),
This uses a different UV interpolation to prevent distortion.

.. note::

This option is not yet available for Cycles

****************
UV Warp Modifier
****************

The UV Warp Modifier uses two objects to define a transformation which is applied to the chosen UV coordinates.

Its purpose is to give you direct control over the object's UVs in the 3D View,
allowing you to directly translate, rotate and scale existing UV coordinates using controller objects or bones.

Options
=======

.. figure:: /images/modeling_modifiers_modify_uvwarp.png

UV Center
The center point of the UV map to use when applying scale or rotation.
With (0, 0) at the bottom left and (1, 1) at the top right. Defaults to (0.5, 0.5).
UV Axis
The axes to use when mapping the 3D coordinates into 2D.
From, To
The two objects used to define the transformation. See *Usage* below.
Vertex Group
The vertex group can be used to scale the influence of the transformation per-vertex.
UV Map
Which UV map to modify.
Defaults to the active rendering layer.

Usage
=====

How the UVs are warped is determined by the difference between the transforms (location, rotation and scale)
of the *from* and *to* objects.

If the *to* object has the same transforms as the *from* object, the UVs will not be changed.

Assuming the *UV Axis* of the modifier is X/Y and the scale of the objects are (1, 1, 1), if the *to* object is
one unit away from the *from* object on the X-axis, the UVs will be transformed on the U-axis (horizontally)
by one full UV space (the entire width of the image)

***************************
Vertex Weight Edit Modifier
***************************

.. figure:: /images/modifiersweightvgedit.jpg
:width: 300px

The Vertex Weight Edit Modifier panel.

This modifier is intended to edit the weights of one vertex group.

The general process is the following, for each vertex:

- (Optional) It does the mapping, either through one of the predefined functions, or a custom mapping curve.
- It applies the influence factor, and optionally the vertex group or texture mask
(0.0 means original weight, 1.0 means fully mapped weight).
- It applies back the weight to the vertex, and/or it might optionally remove the vertex
from the group if its weight is below a given threshold, or add it if it is above a given threshold.

.. important::

This modifier does implicit clamping of weight values in the standard (0.0 to 1.0) range.
All values below 0.0 will be set to 0.0, and all values above 1.0 will be set to 1.0.

Options
=======

Vertex Group
The vertex group to affect.
Default Weight
The default weight to assign to all vertices not in the given vertex group.

Group Add
Adds vertices with a final weight over *Add Threshold* to the vertex group.
Group Remove
Removes vertices with a final weight below *Remove Threshold* from the vertex group.

Falloff Type
Type of mapping:

Linear
No mapping.
Custom Curve
Allows the user to manually define the mapping using a curve.
Sharp, Smooth, Root and Sphere
These are classical mapping functions, from spikiest to roundest.
Random
Uses a random value for each vertex.
Median Step
Creates binary weights (0.0 or 1.0), with 0.5 as cutting value.

Influence/Mask Options
----------------------

Global Influence
The overall influence of the modifier
(0.0 will leave the vertex group's weights untouched, 1.0 is standard influence).

.. important::

Influence only affects weights, adding/removing of vertices
to/from vertex group is not prevented by setting this value to 0.0.

Vertex Group Mask
^^^^^^^^^^^^^^^^^

Vertex Group Mask
An additional vertex group, the weights of which will be
multiplied with the global influence value for each vertex.
If a vertex is not in the masking vertex group, its weight will be not be affected.

Texture Mask
^^^^^^^^^^^^

Texture Mask
An additional texture, the values of which will be multiplied with the global influence value for each vertex.

This is a standard texture :doc:`data-block &lt;/data_system/data_blocks&gt;` control.
When set, it reveals other settings:

Texture Coordinates
How the texture is mapped to the mesh.

Local
Use local vertex coordinates.
Global
Use vertex coordinates in global space.
Object
Use vertex coordinates in another object's space.

Object
The object to be used as reference for *Object* mapping.
UV
Use a UV map's coordinates.

UV Map
The UV map to be used for *UV* mapping.

Use Channel
Which channel to use as weight factor source.

Red/Green/Blue/Alpha
One of the color channels' values.
Intensity
The average of the RGB channels (if RGB(1.0, 0.0, 0.0) value is 0.33).
Value
The highest value of the RGB channels (if RGB(1.0, 0.0, 0.0) value is 1.0).
Hue
Uses the hue value from the standard color wheel (e.g. blue has a higher hue value than yellow).
Saturation
Uses the saturation value (e.g. pure red's value is 1.0, gray is 0.0)

.. note::

All of the channels above are gamma corrected, except for *Intensity*.

.. note::

You can view the modified weights in *Weight Paint Mode*.
This also implies that you will have to disable the *Vertex Weight Edit Modifier*
if you want to see the original weights of the vertex group you are editing.

Example
=======

.. rubric:: Using Distance from a Target Object's Geometry

We are going to illustrate this with a Displace Modifier.

Add a (10×10 BU) 100×100 vertices grid, and in *Edit Mode*,
add to it a vertex group containing all of its vertices, as above.
You can even further sub-divide it with a first Subdivision Surface Modifier.

Now add a curve circle, and place it 0.25 BU above the grid. Scale it up a bit (e.g. 4.0 BU).

Back to the grid object, add to it a Vertex Weight Proximity Modifier,
in *Geometry Distance* mode. Enable *Edge*
(if you use *Vertex* only, and your curve has a low U definition,
you would get wavy patterns, see Fig. :ref:`fig-modifier-vertex-weight-wavy`).

.. _fig-modifier-vertex-weight-wavy:

.. list-table:: Wavy patterns.

* - .. figure:: /images/modifiersweightvgroupgeometryex1-0pf.jpg
:width: 320px

Distance from edges.

- .. figure:: /images/modifiersweightvgroupgeometryex1-0pfwavyweights.jpg
:width: 320px

Distance from vertices.

Set the *Lowest Distance* to 0.2, and the *Highest Distance* to 2.0,
to map back the computed distances into the regular weight range.

Add a third Displace Modifier and affect it the texture you like. Now,
we want the vertices of the grid nearest to the curve circle to remain undisplaced.
As they will get weights near zero, this means that you have to set the *Midlevel*
of the displace to 0.0. Make it use our affected vertex group,
and that is it! Your nice mountains just shrink to a flat plane near the curve circle.

As in the previous example,
you can insert a Vertex Weight Edit Modifier before the *Displace* one,
and play with the *Custom Curve* mapping to get a larger/narrower "valley"...

.. list-table::
*Curve Map* variations.

* - .. figure:: /images/modifiersweightvgroupgeometryex-5-0pf.jpg
:width: 200px

Concave-type mapping curve.

- .. figure:: /images/modifiersweightvgroupgeometryex1-0pf.jpg
:width: 200px

No mapping curve (linear).

- .. figure:: /images/modifiersweightvgroupgeometryex5-0pf.jpg
:width: 200px

Convex-type mapping curve.

.. figure:: /images/modifiersweightvgroupgeometryexremverts.jpg
:width: 200px

Vertices with a computed weight below 0.1 removed from the vertex group.

You can also add a fifth Mask Modifier, and enable Vertex Weight Edit's *Group Remove* option,
with a *Remove Threshold* of 0.1, to see the bottom of your valley disappear.

.. vimeo:: 30188564

`The blend-file &lt;https://wiki.blender.org/index.php/Media:ManModifiersWeightVGroupEx.blend&gt;`__, TEST_2 scene.

**************************
Vertex Weight Mix Modifier
**************************

.. figure:: /images/modifiersweightvgmix.png
:width: 300px

The Vertex Weight Mix Modifier panel.

This modifier mixes a second vertex group (or a simple value) into the affected vertex group,
using different operations.

.. important::

This modifier does implicit clamping of weight values in the standard (0.0 to 1.0) range.
All values below 0.0 will be set to 0.0, and all values above 1.0 will be set to 1.0.

Options
=======

Vertex Group A
The vertex group to affect.
Default Weight A
The default weight to assign to all vertices not in the given vertex group.

Vertex Group B
The second vertex group to mix into the affected one. Leave it empty if you only want to mix in a simple value.
Default Weight B
The default weight to assign to all vertices not in the given second vertex group.

Mix Mode
How the vertex group weights are affected by the other vertex group's weights.

Replace weights
Replaces affected weights with the second group's weights.
Add to weights
Adds the values of *Group B* to *Group A*.
Subtract from weights
Subtracts the values of *Group B* from *Group A*.
Multiply weights
Multiplies the values of *Group B* with *Group A*.
Divide weights
Divides the values of *Group A* by *Group B*.
Difference
Subtracts the smaller of the two values from the larger.
Average
Adds the values together, then divides by 2.
Mix Set
Choose which vertices will be affected.

All vertices
Affects all vertices, disregarding the vertex groups content.
Vertices from group A
Affects only vertices belonging to the affected vertex group.
Vertices from group B
Affects only vertices belonging to the second vertex group.
Vertices from one group
Affects only vertices belonging to at least one of the vertex groups.
Vertices from both groups
Affects only vertices belonging to both vertex groups.

.. important::

When using *All vertices*, *Vertices from group B* or *Vertices from one group*,
vertices might be added to the affected vertex group.

Influence/Mask Options
----------------------

Global Influence
The overall influence of the modifier
(0.0 will leave the vertex group's weights untouched, 1.0 is standard influence).

.. important::

Influence only affects weights, adding/removing of vertices
to/from vertex group is not prevented by setting this value to 0.0.

Vertex Group Mask
^^^^^^^^^^^^^^^^^

Vertex Group Mask
An additional vertex group, the weights of which will be
multiplied with the global influence value for each vertex.
If a vertex is not in the masking vertex group, its weight will be not be affected.

Texture Mask
^^^^^^^^^^^^

Texture Mask
An additional texture, the values of which will be multiplied with the global influence value for each vertex.

This is a standard texture :doc:`data-block &lt;/data_system/data_blocks&gt;` control.
When set, it reveals other settings:

Texture Coordinates
How the texture is mapped to the mesh.

Local
Use local vertex coordinates.
Global
Use vertex coordinates in global space.
Object
Use vertex coordinates in another object's space.

Object
The object to be used as reference for *Object* mapping.
UV
Use a UV map's coordinates.

UV Map
The UV map to be used for *UV* mapping.

Use Channel
Which channel to use as weight factor source.

Red/Green/Blue/Alpha
One of the color channels' values.
Intensity
The average of the RGB channels (if RGB(1.0, 0.0, 0.0) value is 0.33).
Value
The highest value of the RGB channels (if RGB(1.0, 0.0, 0.0) value is 1.0).
Hue
Uses the hue value from the standard color wheel (e.g. blue has a higher hue value than yellow).
Saturation
Uses the saturation value (e.g. pure red's value is 1.0, gray is 0.0).

.. note::

All of the channels above are gamma corrected, except for *Intensity*.

.. note::

You can view the modified weights in *Weight Paint Mode*.
This also implies that you will have to disable the *Vertex Weight Mix Modifier*
if you want to see the original weights of the vertex group you are editing.

Example
=======

.. rubric:: Using a Texture and the Mapping Curve

Here we are going to create a sort of strange alien wave (yes,
another example with the Wave Modifier... but it is a highly visual one;
it is easy to see the vertex group effects on it...).

So as above, add a 100×100 grid. This time, add a vertex group,
but without assigning any vertex to it -- we will do this dynamically.

Add a first Vertex Weight Mix Modifier,
set the *Vertex Group A* field with a *Default Weight A* of 0.0,
and set *Default Weight B* to 1.0.

Leave the *Mix Mode* to *Replace weights*, and select *All vertices* as *Mix Set*.
This way, all vertices are affected. As none are in the affected vertex group,
they all have a default weight of 0.0, which is replaced by the second default weight
of 1.0. And all those vertices are also added to the affected vertex group.

Now, select or create a masking texture.
The values of this texture will control how much of the "second weight" of 1.0
replaces the "first weight" of 0.0... In other words, they are taken as weight values!

You can then select which texture coordinates and channel to use.
Leave the mapping to the default *Local* option, and play with the various channels...

.. list-table::
Texture channel variations.

* - .. figure:: /images/modifiersweightvgrouptexexintensity.jpg
:width: 200px

Using intensity.

- .. figure:: /images/modifiersweightvgrouptexexred.jpg
:width: 200px

Using Red.

- .. figure:: /images/modifiersweightvgrouptexexsaturation.jpg
:width: 200px

Using Saturation.

Do not forget to add a Wave Modifier, and select your vertex group in it!

You can use the weights created this way directly,
but if you want to play with the curve mapping,
you must add the famous Vertex Weight Edit Modifier,
and enable its *Custom Curve* mapping.

By default, it is an one-to-one linear mapping -- in other words,
it does nothing! Change it to something like in Fig. :ref:`fig-modifier-vertex-weight-custom`,
which maps (0.0, 0.5) to (0.0, 0.25) and (0.5, 1.0) to (0.75, 1.0),
thus producing nearly only weights below 0.25,
and above 0.75: this creates great "walls" in the waves...

.. _fig-modifier-vertex-weight-custom:

.. list-table:: Custom mapping curve.

* - .. figure:: /images/modifiersweightvgrouptexexcmapcurve.png
:width: 200px

A customized mapping curve.

- .. figure:: /images/modifiersweightvgrouptexexred.jpg
:width: 200px

Custom Mapping disabled.

- .. figure:: /images/modifiersweightvgrouptexexredcmap.jpg
:width: 200px

Custom Mapping enabled.

.. vimeo:: 30188814

`The blend-file &lt;https://wiki.blender.org/index.php/Media:ManModifiersWeightVGroupEx.blend&gt;`__, TEST_4 scene.

********************************
Vertex Weight Proximity Modifier
********************************

.. figure:: /images/modifiersweightvgproximity.png
:width: 300px

The Vertex Weight Proximity Modifier panel.

This modifier sets the weights of the given vertex group,
based on the distance between the object (or its vertices),
and another target object (or its geometry).

.. warning::

This modifier does implicit clamping of weight values in the standard (0.0 to 1.0) range.
All values below 0.0 will be set to 0.0, and all values above 1.0 will be set to 1.0.

Options
=======

Vertex Group
The vertex group to affect.

Target Object
The object from which to compute distances.

Proximity mode
Object Distance
Use the distance between the modified mesh object and the target object as
weight for all vertices in the affected vertex group.
Geometry Distance
Use the distance between each vertex and the target object, or its geometry.

Vertex
This will set each vertex's weight from its distance to the nearest vertex of the target object.
Edge
This will set each vertex's weight from its distance to the nearest edge of the target object.
Face
This will set each vertex's weight from its distance to the nearest face of the target object.

.. note::

If you enable more than one of them, the shortest distance will be used.
If the target object has no geometry (e.g. an empty or camera),
it will use the location of the object itself.

Lowest
Distance mapping to 0.0 weight.
Highest
Distance mapping to 1.0 weight.

.. tip::

*Lowest* can be set above *Highest* to reverse the mapping.

Falloff Type
Type of mapping:

Linear
No mapping.
Custom Curve
Allows the user to manually define the mapping using a curve.
Sharp, Smooth, Root and Sphere
These are classical mapping functions, from spikiest to roundest.
Random
Uses a random value for each vertex.
Median Step
Creates binary weights (0.0 or 1.0), with 0.5 as cutting value.

Influence/Mask Options
----------------------

Global Influence
The overall influence of the modifier
(0.0 will leave the vertex group's weights untouched, 1.0 is standard influence).

.. warning::

Influence only affects weights, adding/removing of vertices
to/from vertex group is not prevented by setting this value to 0.0.

Vertex Group Mask
^^^^^^^^^^^^^^^^^

Vertex Group Mask
An additional vertex group, the weights of which will be
multiplied with the global influence value for each vertex.
If a vertex is not in the masking vertex group, its weight will be not be affected.

Texture Mask
^^^^^^^^^^^^

Texture Mask
An additional texture, the values of which will be multiplied with the global influence value for each vertex.

This is a standard texture :doc:`data-block &lt;/data_system/data_blocks&gt;` control.
When set, it reveals other settings:

Texture Coordinates
How the texture is mapped to the mesh.

Local
Use local vertex coordinates.
Global
Use vertex coordinates in global space.
Object
Use vertex coordinates in another object's space.

Object
The object to be used as reference for *Object* mapping.
UV
Use a UV map's coordinates.

UV Map
The UV map to be used for *UV* mapping.

Use Channel
Which channel to use as weight factor source.

Red/Green/Blue/Alpha
One of the color channels' values.
Intensity
The average of the RGB channels (if RGB(1.0, 0.0, 0.0) value is 0.33).
Value
The highest value of the RGB channels (if RGB(1.0, 0.0, 0.0) value is 1.0).
Hue
Uses the hue value from the standard color wheel (e.g. blue has a higher hue value than yellow).
Saturation
Uses the saturation value (e.g. pure red's value is 1.0, gray is 0.0).

.. note::

All of the channels above are gamma corrected, except for *Intensity*.

.. note::

You can view the modified weights in *Weight Paint Mode*.
This also implies that you will have to disable the *Vertex Weight Proximity Modifier*
if you want to see the original weights of the vertex group you are editing.

Example
=======

.. rubric:: Using Distance from a Target Object

In this example let us dynamically control a Wave Modifier with a modified vertex group:

#. Add a *Grid* mesh with (100×100) x/y subdivisions and a 5 BU Radius.
#. Switch to *Edit Mode* :kbd:`Tab`, and in the *Object Data* properties, *Vertex Groups* panel,
add a vertex group. Assign to it all your mesh's vertices with 1.0 weight.
#. Go back to *Object Mode*. Then, go to the *Modifiers* properties, and add a Vertex Weight Proximity Modifier.
Set the Distance mode to *Object*. Select your vertex group, and the target object you want.

You will likely have to adjust the linear mapping of the weights produced by the
Vertex Weight Proximity Modifier. To do so, edit *Lowest Distance* and
*Highest Distance* so that the first corresponds to the distance between your target
object and the vertices you want to have lowest weight,
and similarly with the second and highest weight...
#. If your lamp is at Z-hight of 2 then set the settings for the Weight Proximity Modifier to:
Lowest: 2 and highest: 7 (this will stop the waves under the lamp)
If you want waves to be only under the lamp, set the lowest to 7 and highest to 2.
#. Now add a Wave Modifier, set it to your liking, and use the same vertex group to control it.
Example settings-speed: 0.10 , Height: 1.0 , Width 1.50 , Narrowness: 1.50.
#. Animate your target object, making it move over the grid. As you can see, the waves are only
visible around the reference object! Note that you can insert a *Vertex Weight Edit*
modifier before the *Wave* one,
and use its *Custom Curve* mapping to get larger/narrower "wave influence's slopes".

.. vimeo:: 30187079

`The blend-file &lt;https://wiki.blender.org/index.php/Media:ManModifiersWeightVGroupEx.blend&gt;`__, TEST_1 scene.

****************
Explode Modifier
****************

The Explode Modifier is used to alter the mesh geometry by moving/rotating its faces in a way that roughly
tracks particles emitted by that object, making it look as if the mesh is being exploded
(broken apart and pushed outward).

For the Explode Modifier to have a visible effect, there needs to be particle system on it.
The particle system on the mesh is what controls how the mesh will be exploded,
and therefore without the particle system the mesh will not appear to alter.

Both the number of emitted particles and number of faces determine how granular the Explode Modifier will be.
More faces and more particles will mean more individual pieces.

Here is a
`demo video &lt;https://wiki.blender.org/uploads/7/7b/Manual_-_Explode_Modifier_-_Exploding_Cube_-_2.5.ogg&gt;`__
showing a cube with a particle system and Explode Modifier.
(`Blend file &lt;https://wiki.blender.org/index.php/Media:Manual_-_Explode_Modifier_-_Exploding_Cube_-_2.5.blend&gt;`__)

.. note::

The Explode Modifier must come after the Particle System Modifier
because the Particle System Modifier has the information needed to drive the Explode Modifier.

Options
=======

.. figure:: /images/modeling_modifiers_simulate_explode.png

Explode Modifier panel with Particle System Modifier above it.

Vertex group
Vertices in this group may not be affected by the Explode Modifier.
Vertices with full weight are not affected at all,
while vertices with less weight have a higher chance of being affected.

Vertices with no weight will be treated like those which do not belong to the group at all and explode normally.

Protect
Clean vertex group edges. Depending on the weights assigned to that vertex group;
either completely protect those faces from being affected by the Explode Modifier
(which would happen if the faces had a weight value of 1) or completely remove protection from those faces
(which would happen if the faces had a weight value 0).

Particle UV
UV map to change with particle age.

Cut Edges
Cut face edges for nicer shrapnel.

Unborn
Show mesh when particles are unborn.
Alive
Show mesh when particles are alive.
Dead
Show mesh when particles are dead.
Size
Use particle size for shrapnel.

Refresh
Refresh data in the Explode Modifier.

**************
Ocean Modifier
**************

The *Ocean Modifier* is an ocean simulation tool to simulate and generate a deforming ocean surface,
and associated texture, used to render the simulation data.
It is intended to simulate deep ocean waves and foam.

The *Ocean Modifier* is a port from the open source Houdini Ocean Toolkit.

Options
=======

.. figure:: /images/modeling_modifiers_simulate_ocean.png
:width: 240px

Ocean Modifier.

Geometry
--------

Geometry
Generate
Creates a tiled mesh grid that exactly corresponds with the resolution of the simulation data.

When generating a mesh surface, the existing mesh object is completely overridden with the ocean grid.
A UV channel is also added, mapping the (0.0 to 1.0) UV space to the simulation grid.
Displace
Uses the existing geometry rather than replacing it. Vertices are displaced along the local Z-axis.
Repeat X, Repeat Y
When generating a mesh surface, controls the number of times the grid is tiled in X and Y directions.
UVs for these tiled mesh areas continue outside of the (0.0 to 1.0) UV space.

Time
The time at which the ocean surface is being evaluated.
To make an animated ocean, you will need to insert keyframes :kbd:`RMB` and animate this time value.
The speed that the time value is changing will determine the speed of the wave animation.
Depth
The constant depth of the ocean floor under the simulated area.
Lower values simulate shallower waters by producing
higher frequency details and smaller waves.
Random Seed
A different seed will produce a different simulation result.
Resolution
The main control of quality vs speed in the simulation engine.
This determines the resolution of the internal 2D grids generated by the simulation.

The internal grids are powers of two of the resolution value,
so a resolution value of 16, will create simulation data of size 256×256.
The higher the resolution, the more detail will be produced, but the slower it will be to calculate.

.. note::

When using the *Generate* modifier geometry option,
this resolution value also determines the resolution of the generated mesh surface,
equal to the resolution of the internal simulation data.

Size
A simple scaling factor that does not affect the height of the waves or behavior of the simulation.
Spatial Size
The width of the ocean surface area being simulated, in meters.
This also determines the size of the generated mesh, or the displaced area, in Blender units.
Of course you can scale the object with Ocean Modifier in *Object Mode*
to tweak the apparent size in your scene.

Wave
----

Choppiness
The choppiness of the wave peaks.
With a choppiness of 0, the ocean surface is only displaced up and down in the Z direction,
but with higher choppiness, the waves are also displaced laterally in X and Y, to create sharper wave peaks.
Scale
An overall scale control for the amplitude of the waves.
It approximates the height or depth of the waves above or below zero.
Rather than just scaling the ocean object in Z, it scales all aspects of the simulation,
displacement in X and Y, and corresponding foam and normals too.
Alignment
The directionality of the wave shapes due to wind.
At a value of 0, the wind and waves are randomly, uniformly oriented.
With higher Alignment values, the wind is blowing in a more constant direction,
making the waves appear more compressed and aligned to a single direction.
Direction
When using Alignment, the direction in degrees that the waves are aligned to.
Damping
When using Alignment, amount that inter-reflected waves are damped out.
This has the effect of making the wave motion more directional (not just the wave shape).
With damping of 0.0, waves are reflected off each other every direction, with damping of 1.0,
these inter-reflected waves are damped out, leaving only waves traveling in the direction of the wind.
Smallest Wave
A minimum limit for the size of generated waves.
Acts similarly to a low-pass filter, removing higher frequency wave detail.
Wind Velocity
Wind speed in meters/second. With a low velocity, waves are restricted to smaller surface waves.

Simulation Data Generation Options
----------------------------------

.. figure:: /images/modeling_modifiers_simulate_ocean_foam_layer_name.jpg
:width: 240px

Using foam vertex colors with a named data layer.

By default, the simulator only generates displacement data,
since it takes the least amount of work and gives the fastest feedback.
Additional simulation data can be generated for rendering as well.

Generate Normals
Simulates additional normal map data.
This can be used by the Ocean texture, when mapped to Normals,
as a bump map, and enables generating normal map image sequences when baking.
Generate Foam
Simulates additional foam data.
This can be retrieved by the Ocean texture for use in texturing (perhaps as a mask),
and enables generating foam map image sequences when baking.
Coverage
Tweaks the amount of foam covering the waves, negative values will reduce the amount of foam
(leaving only the topmost peaks), positive values will add it. Typically ranges from (-1.0 to 1.0)
Foam Data Layer Name
Optional name for the vertex data layer,
used by the Ocean Modifier to store foam maps as vertex colors.
This is required for accessing the foam data in the renderer.

Baking
======

Rather than simulating the ocean data live, the ocean data can be baked to a file on a drive.
When a simulation is baked, the simulator engine is completely bypassed,
and the modifier/texture retrieves all information from the baked files.

Baking can be advantageous for a few reasons:

- It is faster to use the stored data rather than re-calculating it.
- Allows rendering ocean data in external renderers.
- Enables more advanced foam maps.

Data Files
----------

Simulation data is stored on a drive as sequences of ``OpenEXR`` image maps,
one for each of displacement, normals, and foam (if enabled to be generated).
Upon loading the data from these baked files, when a frame of the bake sequence is read from a drive,
it is cached in memory. This means that accessing loaded frames subsequent times is fast,
not incurring the overhead of drive access.

Since these baked files are plain ``OpenEXR``\ s,
they can also be opened and rendered in any other application or renderer that supports them.

Baking Foam
-----------

Baking also provides improved foam capabilities. When simulating live,
the ocean simulator retrieves data for that current frame only. In the case of the foam map,
this represents the tips of wave crests for that given frame. In reality,
after foam is created by wave interactions,
it remains sitting on the top of the wave surface for a while, as it dissipates. With baking,
it is possible to approximate that behavior, by accumulating foam from previous frames,
leaving it remaining on the surface.

.. vimeo:: 17517981
:width: 500
:height: 256

Baking Options
--------------

Start, End
Frames of the simulation to bake (inclusive).
The start and end frames of the bake are repeated when accessing frames outside the baked range.
Cache Path
Folder to store the baked EXR files in.
The sequences will be in the form ``disp_####.exr``, ``normal_####.exr``,
and ``foam_####.exr`` where ``####`` is the four digit frame number.
If the cache path folder does not exist, it will be created.

Simulation Internals
====================

The simulator itself uses FFT methods to generate 2D grids of simulation information internally,
very similar to 2D texture maps.
The simulator can generate three types of data: displacement, normals,
and extra data, that is used to calculate wave crest intersections (i.e. foam).
After simulation, these maps are used to displace the ocean surface geometry in 3D,
and also can be used for shading via the Ocean texture. The internal simulation engine is
multi threaded with OpenMP to take advantage of multiple cores.

Examples
========

.. vimeo:: 18911131
:width: 500
:height: 256

Simulated and baked to image maps in Blender, rendered in 3Delight.
..    TODO/Review: {{Review|im=new?}}.

**************************
Particle Instance Modifier
**************************

When a Particle Instance Modifier is added to an object, that object will be used
as a particle shape on an object which has a particle system associated with it. This means
that to use this modifier you must also have another object which has a particle system on it,
otherwise the Particle Instance Modifier will appear to do nothing.

.. figure:: /images/modifier-particle_instance_modifier-planes.jpg
:width: 500px

Particle system on left has no Particle Instance modified object associated with it.
The one on the right is associated with cube shown by using a Particle Instance Modifier on the cube.

Options
=======

.. figure:: /images/particle_instance_modifier.png
:width: 250px

Particle Instance Modifier.

Because of the co-dependent way in which the Particle Instance Modifier is
influenced by the underlying particle systems on other objects, some of the apparent effects
generated by the Particle Instance Modifier can look and act vastly different,
depending on the underlying settings of the particle systems it is associated with. This is
worth taking account of if the Particle Instance Modifier settings do not appear to
be giving the results expected, as it may indicate that the particle system settings may need
altering rather than the Particle Instance Modifier settings.

Object
The *Object* field, associates this Particle Instance Modifier with another object (usually an
object having a particle system...).
This indicates that when the object named in this field emits particles, those
particles will have the mesh shape of the current Particle Instance Modifier's mesh.
If for example a sphere has a Particle Instance Modifier added to it, when the *Object* field
of this modifier is filled in with the name of an object that emits particles, those particle will be sphere
shaped. Even though most of the time the *Object* field will have the name of an object with a particle
system, this is not mandatory,
you can enter an object's name which does not have a particle system, and it will be
accepted by the *Object* field, as there do not appear to be any checks made to make sure the object's
name entered into this field is "valid".
Particle System
The *Particle System* field is used to select which particle system number to apply the
Particle Instance Modifier to,
when the mesh which has the particle system on it has more than one of these.
The *Particle System* field can have a value between (1 to 10).
It is possible to select any of the ten particle system numbers, however, a check will **not** be made with the
underlying particle emitting object specified previously in the *Object* field.
If you select a particle system number which does not exist on the particle emitting object, then the particles on
the emitting mesh will keep their normal particle shapes. No warning will be given that the chosen particle
system does not exist on a particular particle emitting mesh.

As an example, below is a single plane mesh with two areas (the first area shown in red and the second in white),
with different particle systems applied to each area. The left side using a Particle Instance Modifier
which has the shape of a sphere and the right side having a Particle Instance Modifier which has the
shape of a cube.

.. figure:: /images/modifier-particle_instance_modifiers-split_plane_2.jpg
:width: 610px

Render showing a single Plain mesh object assigned to two different vertex groups
and each of those vertex groups is assigned a separate and independent particle system,
with each particle system being assigned a different Particle Instance modifier.
In the case shown the Particle Instance modifiers are a sphere and a cube.
`Example Blend file
&lt;https://wiki.blender.org/index.php/Media:Manual_-_Modifiers_-_Particle_Instance_Modifiers_-_Split_Plane.blend&gt;`__.

Creation
--------

Normal
When selected, the *Normal* button tells the Particle Instance Modifier
to draw instances of itself wherever normal particle types are
emitted from the underlying particle system. So if the current modifier is a sphere shape,
when normal particles are emitted they will be spheres.
Children
When selected, the *Children* button tells the modifier
to draw instances of itself wherever children/child particles are
emitted/used on the underlying particle system. So if the current modifier is a sphere shape,
when children/child particles are emitted they will be spheres.
Size
Scale the instanced objects by the particle size attribute.
When this is disabled, all the copies appear the same size as the origin.

Display
-------

Unborn
When selected, the *Unborn* button tells the modifier
to draw instances of itself wherever unborn particles will be
emitted/used on the underlying particle system.
So if the current Particle Instance Modifier is a sphere shape,
when unborn particles are present they will be spheres.
Alive
When selected, the *Alive* button tells the modifier
to draw instances of itself wherever alive particles will be
emitted/used on the underlying particle system.
So if the current Particle Instance Modifier is a sphere shape,
when alive particles are present they will be spheres.
Dead
When selected, the *Dead* button tells the modifier to draw instances of itself
wherever dead particles will occur on the underlying particle system.
So if the current Particle Instance Modifier is a sphere shape,
when dead particles are present they will be spheres.

Using Paths
-----------

Create Along Paths
This option tries to make the underlying mesh object of the modifier
deform its mesh shape in such a way as to try and match the path traveled by
the particles/hair strands of the system associated with it.
For example, below is a screen shot showing the path of a single keyed
particle as it travels its way through each of the different way points (1 to 4) (target particle systems),
when it reaches way point 4 the particle dies and ends its journey.
Rotation Axis
Specify which pole axis to use for the rotation.

X, Y, Z
Keep Shape
Enabling this prevents the object from being deformed.
It instead simply aligns to the end of the path at the object's center.
Position
Specify what percentage of the path the object fills.
You could create a growing effect by animating this value over time.
Random
Scales the position value of each instance a random value.

.. figure:: /images/particle_instance_modifier-keyed_particle_example_1.png
:width: 500px

Keyed particle following way points (showing one particle).
`Example Blend file
&lt;https://wiki.blender.org/index.php/Media:Manual_-_Particle_Instance_Modifier_-_Keyed_Particle_Example_1.blend&gt;`__.

When a Particle Instance Modifier is added to a cylinder object
and then associated with the way point particle system,
the particle position is copied by the cylinder and placed at the particles position.
So the mesh object follows the location of the particle.
The cylinder does not alter any of its other properties when following the particle,
only the cylinders location gets altered, shape and rotation do not get altered.
See screenshot below:

.. figure:: /images/particle_instance_modifier-keyed_particle_example_2.png
:width: 500px

Keyed particle following way points showing a mesh object
(Particle Instance Modifier) in place of the original particle.
`Example Blend file
&lt;https://wiki.blender.org/index.php/Media:Manual_-_Particle_Instance_Modifier_-_Keyed_Particle_Example_2.blend&gt;`__.

Both of the above examples had the Particle Instance Modifier *Path* button deactivated.
When the *Path* button is activated the effect can be seen in the screenshot below:

.. figure:: /images/particle_instance_modifier-keyed_particle_example_3.png
:width: 500px

Keyed particle following way points showing a mesh object (Particle Instance Modifier)
in place of the original particle, that is also being deformed to fit the travel path of the original particle.
`Example Blend file
&lt;https://wiki.blender.org/index.php/Media:Manual_-_Particle_Instance_Modifier_-_Keyed_Particle_Example_3.blend&gt;`__.

Instead of the cylinder location just following the position of the particle (and not altering its shape),
the cylinder tries to fit its mesh to the shape of the path followed by the particle.
The mesh geometry of the object which is trying to deform can have an
impact on how well the deformation is carried out.
In the case of the cylinder, it has many loop cuts along its length so
that it can bend at those points to deform along the particle path.
For example here is the same scene with the number of loop cuts along the length of the cylinder reduced,
showing the effect on the deformation of the cylinder along the particle path.

.. list-table::

* - .. figure:: /images/particle_instance_modifier-keyed_particle_example_4.png
:width: 320px

The cylinder has most of its edge loops so most of the path deform is very regular
apart from at the very end of the curve.

- .. figure:: /images/particle_instance_modifier-keyed_particle_example_5.png
:width: 320px

The cylinder has some of its edge loops removed so the path of the deform starts to become less regular.

* - .. figure:: /images/particle_instance_modifier-keyed_particle_example_6.png
:width: 320px

Now the deform path is very rough.

- .. figure:: /images/particle_instance_modifier-keyed_particle_example_7.png
:width: 320px

At this point there are not any vertices to bend the cylinder to follow the path,
and instead the cylinder just goes directly to the last way point 4.

Once all the extra edge loops around cylinder are removed so that there is only the top and bottom vertices left,
meaning that the cylinder does not have enough geometry to bend,
in that case it cannot follow the path of the particle,
so it just goes from the start way point 1 to the ending way point 4.
The Particle Instance Modifier *Path* button works for hair (strand)
particles as well as with keyed particles.
In this case the mesh of the Particle Instance Modifier will follow the length and profile of the hair strands paths.
Below is a screenshot showing the effect of the *Path* button on hair:

.. figure:: /images/particle_instance_modifier-strand_mesh_deform.png
:width: 500px

Strand with a Particle Instance Modifier associated with it and deforming the cylinder along the hair profile.
`Example Blend file
&lt;https://wiki.blender.org/index.php/Media:Manual_-_Particle_Instance_Modifier_-_Strand_Mesh_Deform.blend&gt;`__.

.. note::

Strands when they are generated instantly die when created so for the *Path* button
to be of any use, you must also have the *Dead* button activated.
Otherwise the path a mesh took will not be visible!

.. seealso::

:doc:`Particles &lt;/physics/particles/index&gt;`
..    TODO/Review: {{review|split=X|text=split selection and editing}}.

*******
Editing
*******

Surface editing has even fewer tools and options than its curve counterpart,
but has many common points with it...
So this page covers (or tries to cover) all the subjects,
from the basics of surface editing to more advanced topics, like retopology.

Translation, Rotation, Scale
============================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Surface --&gt; Transform --&gt; Grab/Move, Rotate, Scale, ...`
| Hotkey:   :kbd:`G`, :kbd:`R`, :kbd:`S`

Once you have a selection of one or more control points,
you can grab/move :kbd:`G`, rotate :kbd:`R` or scale :kbd:`S` them, like many other things in Blender,
as described in the :doc:`Manipulation in 3D Space &lt;/editors/3dview/object/editing/transform/introduction&gt;` section.

You also have in *Edit Mode* an extra option when using these basic manipulations: the
:doc:`proportional editing &lt;/editors/3dview/object/editing/transform/control/proportional_edit&gt;`.

Transform Panel
---------------

See :ref:`modeling-curves-transform-panel`.

Advanced Transform Tools
========================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Surface --&gt; Transform`

The *To Sphere*, *Shear*, *Warp* and *Push/Pull* transform tools are described in the
:doc:`Mesh Transformation &lt;/modeling/meshes/editing/transform/index&gt;` section.
Surfaces have no specific transform tools.

NURBS Control Points Settings
=============================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:     Curve Tools (Edit Mode) and Transform

We saw in a :ref:`previous page &lt;modeling-surfaces-weight&gt;` that NURBS control points have a weight,
which is the influence of this point on the surface.
You set it either using the big *Set Weight* button in the *Curve Tools* panel
(after having defined the weight in the number button to the right),
or by directly typing a value in the *W* number button of the *Transform* panel.

Adding or Extruding
===================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Surface --&gt; Extrude`
| Hotkey:   :kbd:`E`, :kbd:`Ctrl-LMB`

Unlike meshes or curves, you cannot generally directly add new control points to a surface
(with :kbd:`Ctrl-LMB` clicks), as you can only extend a surface by adding a whole U- or V-row at once.
The only exception is when working on a NURBS surface curve, i.e.
a surface with only one control point on each U- or V-row. In this special case,
all works exactly as with :ref:`curves &lt;modeling-curves-extrude&gt;`.

Most of the time, only extrusion is available. As usual, once the tool is activated the
extrusion happens immediately and you are placed into *Grab mode*,
ready to drag the new extruded surface to its destination.

There are two things very important to understand:

- Surfaces are *2D* objects. So you cannot extrude anything *inside* a surface
(e.g. "inner" row); it would not make any sense!
- The control "grid" *must* remain "squarish",
which means that you can only extrude a whole row, not parts of rows here and there...

To summarize, the *Extrude* tool will only work, when one and only one whole border
row is selected, otherwise nothing happens.

As for curves, you cannot create a new surface in your object out of nowhere,
by just :kbd:`Ctrl-LMB` - clicking with nothing selected.
However, unlike for curves, there is no "cut" option allowing you to separate a surface into several parts,
so you only can create a new surface by copying (`Duplication`_) an existing one
:kbd:`Shift-D`, or adding a new one with the *Add* menu.

Examples
--------

Images Fig. :ref:`fig-surface-edit-select-point` to Fig. :ref:`fig-surface-edit-extruding`
show a typical extrusion along the side of a surface.

In Fig. :ref:`fig-surface-edit-select-point` and :ref:`fig-surface-edit-select-row`,
a border row of control points were highlighted by selecting a single control point,
and then using the handy row select tool :kbd:`Shift-R`
to select the rest of the control points.

.. list-table::

* - .. _fig-surface-edit-select-point:

.. figure:: /images/modeling_surfaces_editing_selecting-point.png

Selecting control-point.

- .. _fig-surface-edit-select-row:

.. figure:: /images/modeling_surfaces_editing_selecting-row.png

Shift-R

The edge is then extruded using :kbd:`E` as shown in Fig. :ref:`fig-surface-edit-extruding`.
Notice how the mesh has bunched up next to the highlighted edge.
That is because the *new* extruded surface section is bunched up there as well.

.. _fig-surface-edit-extruding:

.. figure:: /images/modeling_surfaces_editing_extruding.png

Extruding.

By moving the new section away from the area, the surface begins to "unbunch".

You can continue this process of extruding or adding
new surface sections until you have reached the final shape for your model.

Opening or Closing a Surface
============================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Surface --&gt; Toggle Cyclic`
| Hotkey:   :kbd:`Alt-C`

As in :ref:`curves &lt;modeling-curves-toggle-cyclic&gt;`,
surfaces can be closed (cyclic) or open. However, as surfaces are 2D,
you can control this property independently along the U and V axes.

To toggle the cyclic property of a surface along one axis,
use :kbd:`Alt-C` and choose either *cyclic U* or *cyclic V* from the pop-up menu.
The corresponding surface's outer edges will join together to form a "closed" surface.

.. note:: Inner and Outer

Surfaces have an "inner" and "outer" face, the first being black whereas the latter is correctly shaded.
(There does not seem to be any "double sided" shading option for surfaces...).
When you close a surface in one or two directions, you might get an entirely black object! In this case,
just `Switch Direction`_ of your surface...

Duplication
===========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Curve --&gt; Duplicate`
| Hotkey:   :kbd:`Shift-D`

Similar as with meshes and curves, this tool duplicates the selection.
The copy is selected and placed in *Grab* mode, so you can move it to another place.

However, with surfaces there are some selections that cannot be duplicated,
in which case they will just be placed in *Grab* mode... In fact,
only selections forming a *single* valid sub-grid are copyable; let us see this in practice:

- You can copy a single control point.
From it, you will be able to "extrude" a "surface curve" along the U axis,
and then extrude this unique U-row along the V axis to create a real new surface.
- You can copy a single continuous part of a row (or a whole row, of course).
This will give you a new *U-row*, even if you selected (part of) a V-row!
- You can copy a single whole sub-grid.

.. note::

Trying to duplicate several valid "sub-grids" (even being single points)
at once will not work; you will have to do it one after the other...

Deleting Elements
=================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Curve --&gt; Delete...`
| Hotkey:   :kbd:`X`, :kbd:`Delete`

The *Erase* pop-up menu of surfaces offers you two options:

Selected
This will delete the selected rows, *without* breaking the surface
(i.e. the adjacent rows will be directly linked, joined, once the intermediary ones are deleted).
The selection must abide by the following rules:

- Whole rows, and only whole rows must be selected.
- Only rows along the same axis must be selected (i.e. you cannot delete both U- and V-rows at the same time).

Also remember that NURBS order cannot be higher than its number of control points in a given axis,
so it might decrease when you delete some control points...
Of course, when only one row remains, the surface becomes a "surface curve"; when only one point remains,
there is no more visible surface; and when all points are deleted, the surface itself is deleted.

All
As with meshes or curves, this deletes everything in the object!

Example
-------

.. figure:: /images/modeling_surfaces_editing_deleting.png

Before and after.

In Fig. *Before and after (left)* a row of control points has been selected by initially
selecting the one control point and using :kbd:`Shift-R` to select the remaining
control points. Then, using the *Delete Menu* :kbd:`X`,
the *selected* row of control points is erased, resulting in Fig. *Before and after (right)*.

Joining or Merging Surfaces
===========================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Surface --&gt; Make Segment`
| Hotkey:   :kbd:`F`

Just like :ref:`curves &lt;modeling-curves-make-segment&gt;`,
merging two surfaces requires that a single edge, a border row of control points,
from two separate surfaces is selected. This means that the surfaces must be part of the same object. For example,
you cannot join two surfaces while in *Object Mode* - but you can of course, as with any objects of the same type,
join two or more *Surface* objects
into one object :kbd:`Ctrl-J` - they just will not be "linked" or merged in a single one... Yes, it's a bit confusing!

This tool is equivalent to creating edges or faces for meshes
(hence its shortcut), and so it only works in *Edit Mode*.
The selection must contains only border rows of the same resolution
(with the same number of control points),
else Blender will try to do its best to guess what to merge with what, or the merge will fail
(either silently, or stating that ``Resolution does not match`` if rows with
different number of points are selected, or that there is ``Too few selections to merge``
if you only selected points in one surface...).
To select control points of different surfaces,
in the same object, you must use either border select or circle select.
Holding down :kbd:`Ctrl` while :kbd:`LMB` will not work.

So to avoid problems, you should always only select border rows with the same number of
points... Note that you can join a border U-row of one surface with a border V-row of another
one, Blender will automatically "invert" the axis of one surface for them to match correctly.

NURBS surface curves are often used to create objects like hulls,
as they define cross sections all along the object,
and you just have to "skin" them as described above to get a nice, smooth and harmonious shape.

Examples
--------

Fig. Joining ready is an example of two NURBS surface curves, **not** NURBS curves,
in *Edit Mode*, ready to be joined.
Fig. Joining complete is the result of joining the two curves.

.. list-table::

* - .. _fig-surface-edit-join-ready:

.. figure:: /images/modeling_surfaces_editing_joining-ready.png

Joining ready.

- .. _fig-surface-edit-join-complete:

.. figure:: /images/modeling_surfaces_editing_joining-complete.png

Joining complete.

Subdivision
===========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    Curve Tools
| Menu:     :menuselection:`Surface tools --&gt; Modeling --&gt; Subdivide`, :menuselection:`Specials --&gt; Subdivide`

Surface subdivision is most simple:
using either the *Subdivide* entry in the *Specials* menu
:kbd:`W`, or the *Subdivide* button of the *Curve Tools1* panel,
you will subdivide once all *completely* selected grids by subdividing each "quad" into four
smaller ones.

If you apply it to a 1D surface (a "surface curve"),
this tool works exactly as with :ref:`curves &lt;modeling-curves-subdivision&gt;`.

Spin
====

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    Curve Tools

This tool is a bit similar to its :doc:`mesh counterpart &lt;/modeling/meshes/editing/duplicating/spin&gt;`
but with less control and options (in fact, there is none!).

It only works on selected "surfaces" made of *one U-row* (and not with one V-row),
so-called "surface curves", by "extruding" this "cross section" in a square pattern,
automatically adjusting the weights of control points to get a perfect circular extrusion
(this also implies closing the surface along the V axis), following exactly the same principle
as for the *NURBS Tube* or *NURBS Donut* primitives.

Switch Direction
================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Surface --&gt; Segments --&gt; Switch Direction`,
:menuselection:`Specials --&gt; Switch Direction`

This tool will "reverse" the direction of any curve with at least one selected element
(i.e. the start point will become the end one, and *vice versa*).
Mainly useful when using a curve as path, or the bevel and taper options...

Other Specials Options
======================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     Specials
| Hotkey:   :kbd:`W`

The *Specials* menu contains exactly the same additional options as for
curves, except for *Set Radius* and *Smooth Radius*.

Conversion
----------

As there are only NURBS surfaces, there is no "internal" conversion here.

However, there is an "external" conversion available, from surface to mesh,
that only works in *Object Mode*.
It transforms a *Surface* object into a *Mesh* one,
using the surface resolutions in both directions to create faces, edges and vertices.

Misc Editing
------------

You have some of the same options as with meshes, or in *Object Mode*.
You can :ref:`separate &lt;object-separate&gt;` a given surface :kbd:`P`,
make other selected objects :ref:`children &lt;object-parenting&gt;`
of one or three control points
:kbd:`Ctrl-P`,
or :doc:`add hooks &lt;/modeling/modifiers/deform/hooks&gt;` to control some points with other objects.

The *Mirror* tool is also available, behaving exactly as with
:doc:`mesh objects &lt;/modeling/meshes/editing/transform/mirror&gt;`.
.. _modeling-surfaces-index:

###########
Surfaces
###########

.. toctree::
:maxdepth: 2

introduction.rst
structure.rst
primitives.rst
selecting.rst
editing.rst
properties.rst

************
Introduction
************

Curves are 2D objects, and surfaces are their 3D extension. Note however, that in Blender,
you only have NURBS surfaces, no Bézier (you have the *Bézier* knot type, though;
see below), nor polygonal (but for these, you have meshes!).
Even though curves and surfaces share the same object type (with texts also...),
they are not the same thing; for example,
you cannot have in the same object both curves and surfaces.

.. _fig-surface-intro-surface:

.. figure:: /images/modeling_surfaces_introduction_nurbs-surface.png

Nurbs surface in Edit Mode.

As surfaces are 2D, they have two interpolation axes, U (as for curves) and V.
It is important to understand that you can control the interpolation rules (knot, order,
resolution) *independently* for each of these two dimensions
(the U and V fields for all these settings, of course).

You may ask yourself "but the surface appears to be 3D, why is it only 2D?".
In order to be 3D, the object needs to have "Volume", and a surface, even when it is closed,
does not have volume; it is infinitely thin.
If it had a volume the surface would have a thickness (its third dimension). Hence,
it is only a 2D object, and has only two interpolation dimensions or axes or coordinates
(if you know a bit of math, think of non-euclidean geometry -- well,
surfaces are just non-euclidean 2D planes...). To take a more "real life" example,
you can roll a sheet of paper to create a cylinder; well, even if it "draws" a volume,
the sheet itself will remain a (nearly...) 2D object!

In fact, surfaces are very similar to the results you get when
:doc:`extruding a curve &lt;/modeling/curves/properties/geometry&gt;`.

Finding Surface Tools
=====================

As usual, you have the *Select* and *Surface*
menus in the 3D View headers, and the *Specials* menu :kbd:`W`.

Visualization
=============

There is nearly no difference from NURBS curves,
except that the U direction is indicated by yellow grid lines,
and the V one is materialized by pink grid lines, as you can see in
Fig. :ref:`fig-surface-intro-surface`.

You can :ref:`hide and reveal &lt;curves-show-hide&gt;` control points just as with curves.

**********
Primitives
**********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Create --&gt; Add Primitive/Surface`
| Menu:     :menuselection:`Add --&gt; Surface`
| Hotkey:   :kbd:`Shift-A`

To help get started in creating surfaces there are four preset :term:`NURBS` surfaces,
found in the :menuselection:`Add --&gt; Surface --&gt; NURBS Surface`, :menuselection:`NURBS Tube`,
:menuselection:`NURBS Sphere` and :menuselection:`NURBS Torus`.

.. figure:: /images/modeling_surfaces_introduction_primitives-surface.png

NURBS surface primitives.

There are also two preset NURBS surface curves (with only one control point on each V-row):
*NURBS Curve* and *NURBS Circle*.

.. figure:: /images/modeling_surfaces_introduction_primitives-curve.png

NURBS curve primitives.

Note how a circle :term:`NURBS` surface is never filled, unlike its "real" curve counterpart...

Common Options
==============

Radius, Align to View, Location, Rotation
See :ref:`Common Object Options &lt;object-common-options&gt;`.

**********
Properties
**********

.. figure:: /images/modeling_surfaces_introduction_nurbs-properties.png

Surface Properties.

The panels of the *Curve and Surface* tab are the same as for
:doc:`curves &lt;/modeling/curves/introduction&gt;`, just with fewer options...

Shape
=====

.. figure:: /images/modeling_surfaces_introduction_resolution-panel.png

Shape panel.

You can adjust the resolution separately for both preview and render,
to not slow things down in the viewport, but still get good render results.

Preview
U, V
Render
U, V

Active Spline
=============

Closed and Open Surfaces
------------------------

Like curves, surfaces can be closed (cyclical) or open, independently in both directions,
allowing you to easily create a tube, donut or sphere shape,
and they can be drawn as "solids" in *Edit Mode*.
This makes working with surfaces quite easy.

Bézier
------

Endpoint
--------

Just like :ref:`NURBS curves &lt;modeling-curve-knot&gt;`, NURBS surfaces have two knot vectors,
one for each U and V axis. Here again, they can be one of *Cyclic*, *Endpoint*,
or *Bézier*, with the same properties as for curves. And as with curves, only open surfaces
(in the relevant direction) are affected by this setting...

.. _fig-surface-intro-endpoint:

.. figure:: /images/modeling_surfaces_introduction_endpoint.png

Endpoint U.

In Fig. :ref:`fig-surface-intro-endpoint` the U interpolation axis is labeled as "U" and the V
interpolation axis is labeled as "V". The U's interpolation axis has
been set to *Endpoint* and as such the surface now extends to the outer edges from
E1 to E2 along the U interpolation axis.

To cause the surface to extend to all edges you would set the V's axis to
*Endpoint* as well.

Order
-----

One more time, this property is the same as with :ref:`NURBS Curves &lt;modeling-curve-order&gt;`;
it specifies how much the control points are taken into account for calculating the curve of the surface shape.
For high Orders 1 the surface pulls away from the control points,
creating a smoother surface by assuming that the
`Resolution`_ is high enough. For lowest Orders 2 the surface follows the control points,
creating a surface that tends to follow the grid cage.

.. _fig-surface-intro-order:

.. figure:: /images/modeling_surfaces_introduction_order.png

Order 2 and order 4 surface.

For illustration purposes, in both Fig. :ref:`fig-surface-intro-order`,
the knot vectors were set to *Endpoint*, causing the surface to extend to all edges.

You can set independently the order for each interpolation axis, and like curves,
it **cannot** be lower than 2,
and higher than 6 or the number of control points on the relevant axis.

Resolution
----------

Just like :ref:`NURBS curves &lt;curve-nurbs&gt;`, *Resolution* controls the detail of the surface.
The higher the *Resolution* the more detailed and smoother the surface is.
The lower the *Resolution* the rougher the surface. However, here you have two resolution settings,
one for each interpolation axis (U and V). Note that unlike with curves, you have only one resolution
(the *Resolution* U and V fields, in the *Curve Tools* panel)...

.. list-table::

* - .. figure:: /images/modeling_surfaces_introduction_resolution-1x1_wire.png

- .. figure:: /images/modeling_surfaces_introduction_resolution-3x3_wire.png

* - .. _fig-surface-intro-resolution1:

.. figure:: /images/modeling_surfaces_introduction_resolution-1x1.png

Resolution 1×1.

- .. _fig-surface-intro-resolution2:

.. figure:: /images/modeling_surfaces_introduction_resolution-3x3.png

Resolution 3×3.

Fig. :ref:`fig-surface-intro-resolution1` is an example of a surface resolution of 1 for both U and V.
Fig. :ref:`fig-surface-intro-resolution2` surface is an example of a surface resolution of 3 for both U and V.

Smooth
------

*********
Selecting
*********

Surface selection in *Edit Mode* is very similar to
:doc:`NURBS curve selection &lt;/modeling/curves/editing/introduction&gt;`.
The basic tools are the same as with :doc:`meshes &lt;/modeling/meshes/selecting/introduction&gt;`,
so you can select a simple control point with a :kbd:`LMB` -click,
add to current selection with :kbd:`Shift-LMB` clicks, :kbd:`B` order-select, and so on.

.. figure:: /images/modeling_surfaces_selecting.png
:align: right

Select Menu.

Select Menu
===========

The *Select* menu (3D View headers) is even simpler than for curves...

All these options have the same meaning and behavior as in :doc:`Object Mode &lt;/editors/3dview/object/selecting/index&gt;`
(and the specificities of *Border Select* in *Edit Mode* have already been discussed
:doc:`here &lt;/modeling/meshes/selecting/introduction&gt;`).

.. container:: lead

.. clear

Select Linked
-------------

:kbd:`L`, :kbd:`Ctrl-L` will add to the selection the mouse cursor's nearest control point,
and all the linked ones, i.e. all points belonging to the same surface.

Control Point Row
-----------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Control Point Row`
| Hotkey:   :kbd:`Shift-R`

This option works a bit like
:ref:`edge loop selection &lt;modeling-meshes-selecting-edge-loops&gt;` for meshes,
inasmuch it selects a whole :ref:`row &lt;modeling-surfaces-rows-grids&gt;` of control points,
based on the active (the last selected) one. The first time you press :kbd:`Shift-R`,
the V-row passing through (containing) the active point will be added to the *current* selection.
If you use again this shortcut, you will toggle between the U- and V-row of this point,
removing *everything else* from the selection.

More and Less
-------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; More/Less`
| Hotkey:   :kbd:`Ctrl-NumpadPlus` / :kbd:`Ctrl-NumpadMinus`

These two options are complementary and very similar to
:doc:`those for meshes &lt;/modeling/meshes/selecting/introduction&gt;`.
Their purpose, based on current selected control points, is to reduce or enlarge this selection.

The algorithm is the same as with meshes:

More
for each selected control point, select **all** its linked points (i.e. two, three or four).
Less
for each selected control point, if **all** points linked to this point are selected, keep it selected.
For all other selected control points, de-select them.

This implies two points:

- First, when **all** control points of a surface are selected, nothing will happen
(as for *Less*, all linked points are always selected, and of course, *More* cannot add any).
Conversely, the same goes when no control point is selected.
- Second, these tools will never "go outside" of a surface
(they will never "jump" to another surface in the same object).

*********
Structure
*********

Many of the concepts from :doc:`curves &lt;/modeling/curves/introduction&gt;`,
especially :ref:`NURBS &lt;curve-nurbs&gt;` ones,
carry directly over to NURBS surfaces,
such as control points, *Order*, *Weight*, *Resolution*, etc.
Here we will just talk about the differences.

It is very important to understand the difference between NURBS curves and NURBS surfaces:
the first one has one dimension, the latter has two.
Blender internally treats NURBS surfaces and NURBS curves completely differently. There are
several attributes that separate them but the most important is that a NURBS curve has a
single interpolation axis (U) and a NURBS surface has two interpolation axes (U and V).

However, you can have "2D" surfaces made of curves
(using the :doc:`extrusion tools &lt;/modeling/curves/properties/geometry&gt;`,
or, to a lesser extent, the filling of closed 2D curves). And you can have "1D" curves made of surfaces,
like a NURBS surface with only one row (either in U or V direction) of control points produces only a curve...

Visually you can tell which is which by entering *Edit Mode* and looking at the 3D View header:
either the header shows *Surface* or *Curve* as one of the menu choices. Also,
you can :doc:`extrude &lt;/modeling/curves/properties/geometry&gt;` a whole NURBS surface curve to create a surface,
but you cannot with a simple NURBS curve.

.. _modeling-surfaces-rows-grids:

Control Points, Rows and Grid
=============================

Control points for NURBS surfaces are the same as for NURBS curves. However,
their layout is quite constraining. The concept of "segment" disappears,
replaced by "rows" and the overall "grid".

A "row" is a set of control points forming one "line" in one interpolation direction
(a bit similar to :ref:`edge loops &lt;modeling-mesh-structure-edge-loops&gt;` for meshes).
So you have "U-rows" and "V-rows" in a NURBS surface.
The key point is that *all* rows of a given type (U or V) have the *same* number of control points.
Each control point belongs to exactly one U-row and one V-row.

All this forms a "grid", or "cage", the shape of which controls the shape of the NURBS surface.
A bit like a :doc:`lattice &lt;/rigging/lattice&gt;`...

This is very important to grasp: you cannot add a single control point to a NURBS surface;
you have to add a whole U- or V-row at once (in practice,
you will usually use the Extrude tool, or perhaps the Duplicate one, to add those...),
containing exactly the same number of points as the others. This also means that you will only
be able to "merge" different pieces of surfaces if at least one of their rows match together.

.. _modeling-surfaces-weight:

Weight
======

Guess what? Yes, it works exactly like :ref:`NURBS Curves &lt;modeling-curve-weight&gt;`! *Weight* specifies
how much each control point "pulls" on the curve.

In Fig. :ref:`fig-surface-intro-weight` a single control point, labeled "C",
has had its *Weight* set to 5.0 while all others are at their default of 1.0.
As you can see, that control point *pulls* the surface towards it.

.. _fig-surface-intro-weight:

.. figure:: /images/modeling_surfaces_introduction_weight.png

One control point with a weight of 5.

If all the control points have the same *Weight* then each effectively cancels each
other out. It is the difference in the weights that cause the surface to move towards or away
from a control point.

The *Weight* of any particular control point is visible in the
:doc:`/editors/3dview/object/properties/transforms`
:kbd:`N`, in the *W* field (and not the *Weight* field...).

Preset Weights
--------------

NURBS can create pure shapes such as circles, cylinders, and spheres
(note that a Bézier circle is not a pure circle). To create pure circles, globes,
or cylinders, you must set to specific values the weights of the control points.
Some of which are provided as presets in the *Curve Tools* panel (lower right corner).
This is not intuitive, and you should read more on NURBS before trying this.

To create a sphere with 2D surfaces, its the same principle as with a 2D circle.
You will note that the four different weights needed for creating a sphere
(1.0, 0.707 = sqrt(0.5), 0.354 = sqrt(2)/4, and 0.25).

.. figure:: /images/modeling_surfaces_introduction_weight-sphere.png

A sphere surface.

.. |atilde| unicode:: U+000E3
.. |aacute| unicode:: U+000E1
.. |agrave| unicode:: U+000E0
.. |aring|  unicode:: U+000E5
.. |euml|   unicode:: U+000EB
.. |oslash| unicode:: U+000F8

*******************
Editing &amp; Selecting
*******************

Editing text is quite different from other object types in Blender, and happens mainly in two areas.
First, the 3D View, of course, where you type your text, and have a few shortcuts, e.g. for applying
styles (see :ref:`modeling-text-character`) -- note however, that most Blender hotkeys you know
in *Edit Mode* do not exist for texts. The second place is the Properties Editor, especially the *Font* tab.

.. figure:: /images/modeling_text_editing_cursor.png
:width: 300px

Text in Edit Mode.

The menu of the 3D View header offers few options,
and there is no *Specials* menu... You have no transform nor mirror tools, and so on.
However, you can apply to texts the same modifiers as for curves.

Basic Editing
=============

Editing *Text* is similar to using a standard text editor but is not as
full-featured and has some differences:

Exit *Edit Mode*
:kbd:`Tab` does not insert a tab character in the text,
but rather enters and exits *Edit Mode*, as with other object types.
Copy
To copy text to the buffer, use :kbd:`Ctrl-C` or the *Copy* button in the tool shelf.
Cut and Copy
To cut and copy text to the buffer, use :kbd:`Ctrl-X` or the *Cut* button in the tool shelf.
Paste
To paste text from the buffer, use :kbd:`Ctrl-V` or the *Paste* button in the tool shelf.
Delete all text
To completely erase or delete all text, use :kbd:`Ctrl-Backspace`.

The text buffer is in sync with the desktop clipboard.
But if it is used within Blender the text formatting will be copied as well.
For other ways of inserting a text, see `Inserting Text`_ below.

Special Characters
------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Text --&gt; Special Characters`

If you need special characters (such as accented chars, which are not on your keyboard)
you can produce many of them using a combination of two other characters. To do so,
type the main char, press :kbd:`Alt-Backspace`,
and then press the desired "modifier" to produce the special character.
Some examples are given below:

.. list-table::
:widths: 20 80

* - |atilde|

- :kbd:`A`, :kbd:`Alt-Backspace`, :kbd:`~`

* - |aacute|

- :kbd:`A`, :kbd:`Alt-Backspace`, :kbd:`'`

* - |agrave|

- :kbd:`A`, :kbd:`Alt-Backspace`, :kbd:`\\`

* - |aring|

- :kbd:`A`, :kbd:`Alt-Backspace`, :kbd:`O`

* - |euml|

- :kbd:`E`, :kbd:`Alt-Backspace`, :kbd:`"`

* - |oslash|

- :kbd:`O`, :kbd:`Alt-Backspace`, :kbd:`/`

Cursor &amp; Selection
==================

.. figure:: /images/modeling_text_editing_cursor.png
:width: 300px

Text in Edit Mode.

In *Edit Mode*, your text has a white cursor, and as in any text editor,
it determines where new chars will be inserted.

Next/Previous Character
You can move the cursor with the arrow keys :kbd:`Left` or :kbd:`Right`.
Next/Previous Word
To move the cursor on a word's boundary, use :kbd:`Ctrl-Left` or :kbd:`Ctrl-Right`.
Line Begin/End
:kbd:`Home` and :kbd:`End` move the cursor to the beginning and end of a line respectively.
Next/Previous Line
To jump between lines use :kbd:`Up` or :kbd:`Down`.
Next/Previous Page
To jump back/forward ten lines at a time use :kbd:`PageUp` or :kbd:`PageDown`.

Hold :kbd:`Shift` while using the arrow keys to select a part of the text.
You can use it to specify different materials, the normal/bold/italic style,
and not much more...

Inserting Text
==============

You can insert text in two ways: from the internal text buffer
(as described above), or from a text file.

To load text from a text file, use the :menuselection:`Text --&gt; Paste File` tool.
This will bring up a :doc:`File Browser &lt;/editors/file_browser/index&gt;` for navigating to a valid UTF-8 file.
As usual, be careful that the file does not have too many characters,
as interactive response will slow down.

Converting Text Objects
=======================

Converting to Text Object
-------------------------

.. figure:: /images/modeling_text_editing_convert-to.jpg

Using an existing text-block, you can convert it to an object from the text editor's header,
select :menuselection:`Edit --&gt; Text to 3D Object`,
*One Object* or *One Object per Line* depending on your needs.

It is also possible to paste from the clipboard or a file from the *Edit* menu, while editing 3D Text.

Converting to 3D Mesh
---------------------

It is possible to convert a Text Object to a 3D Mesh object.
This can be useful so that you may edit the vertices in *Edit Mode*,
but you will lose the ability to edit the text itself.
To do this, go to *Object Mode* and select your Text Object.
Press :kbd:`Alt-C` and select *Mesh From Curve/Meta/Surf/Text*.
Now you can return to *Edit Mode* and manually edit the vertices.
They are usually a bit messy, so it may be useful to use a *Limited Dissolve* deletion or *Remesh* Object
:doc:`Modifier &lt;/modeling/modifiers/index&gt;` at a low threshold to clean up your mesh.

.. figure:: /images/modeling_text_editing_convert-from.png

left normal text, right the made text object.

Assigning Materials
===================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:   :menuselection:`Properties editor --&gt; Materials`

Each character can have a different *Material index* in order to have different
materials on different characters.

You can assign indices either as you type, or after by selecting blocks of text and clicking
on the *Assign* button in the Materials panel.

.. _fig-texts-edit-rgb:

.. figure:: /images/modeling_text_editing_material-index-example.png

Red Green Blue.

For example, to create Fig. :ref:`fig-texts-edit-rgb`
you would need to create three separate materials and three separate material indices. Each
word would be assigned a *Material index* by selecting the characters for each word
and clicking the *Assign* button. Fig. :ref:`fig-texts-edit-rgb`
is still one single *Text* object.
.. _modeling-text-index:

#######
Text
#######

.. toctree::
:maxdepth: 2

introduction.rst
editing.rst
properties.rst

************
Introduction
************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    Curve and Surface, Font and Char
| Menu:     :menuselection:`Add --&gt; Text`

.. _fig-texts-intro-example:

.. figure:: /images/modeling_text_introduction_exsamples.jpg
:width: 400px

Text Examples.

*Text* objects are exactly what they sound like: they contain some text.
They share the same object type as curves and surfaces,
as modern fonts (OpenType, TrueType, etc.) are vectorial, made of curves (generally Béziers).

Blender uses a "Font System" to manage mapping "letter codes --&gt; objects representing them in 3D
views". This implies that not only does the font system have its own *built-in* font,
but it can use external fonts too, including *PostScript Type 1*,
*OpenType* and *TrueType* fonts. And last but not least,
it can use any objects existing in the current blend-file as letters...

Texts in Bender allow you to create/render 2D or 3D text, shaded as you want,
with various advanced layout options (like justifying and frames), as we will see below.
By default, letters are just flat filled surfaces, exactly like any closed 2D curve.
But you can of course extrude them... And texts can follow other curves.

Of course, once you are happy with the shape of your text, you can convert it
(with :kbd:`Alt-C`, in *Object Mode*), either to a curve,
or directly to a mesh,
allowing you to use all the powerful features of these types of objects on it...

Fig. :ref:`fig-texts-intro-example` shows some examples of various fonts in action,
including the "blue" font that has been applied to a curve path.

.. note::

A maximum of 50000 characters is allowed per text object; however,
be forewarned that the more characters a single text object has,
the slower the object will respond interactively.

As you can see when you switch between *Object Mode* and *Edit Mode*,
the *Font* panel remains the same. This means that its settings can be applied
equally in both modes ... and this implies that you cannot apply them to just a part of the
mesh. So font, size, and so on, are common to all letters in a *Text* object.
There is just one exception:
the *Bold* or *Italic* buttons control properties specific to each letter
(this is a way to use up to four different fonts in a text).

For optimum resource usage, only characters that are being used consume memory
(rather than the entire character set).
.. (todo) split? move text style toggle to editing

**********
Properties
**********

Shape
=====

.. admonition:: Reference
:class: refbox

| Mode:     Object or Edit Mode
| Panel:    :menuselection:`Properties editor --&gt; Text --&gt; Shape`

.. figure:: /images/modeling_text_properties_shape-settings.jpg

The Shape panel.

As you can see in the Shape panel, texts have most of the same options as curves.

Resolution
----------

Preview
The surface resolution in the U direction to use in the viewport.
Render
The surface resolution in the U direction, set to zero to use the *Preview* resolution.

Fill
----

Fill
Determines the way a Curve is filled in when it is extruded and/or beveled.

Front
Fills in the front side of the surface.
Back
Fills in the back side of the surface.
Fill Deformed
Fills the curves after applying all modification that might deform the curve (i.e. shape keys and modifiers).

Display
-------

Fast Editing
Does not fill polygons while editing text.

Texture Space
=============

.. figure:: /images/modeling_text_properties_texture-settings.jpg

Texture Settings.

Use UV for Mapping
Use UV values as generated texture coordinates.
Auto Texture Space
Adjusts the active object's texture space automatically when transforming the object.

TODO.

Geometry
========

Modification
Offset
Alters the space between letters.
Extrude
Will extrude the text along both the positive and negative local Z axes.
Bevel
Depth
Changes the size of the bevel.
Resolution
Alters the smoothness of the bevel.

Taper Object
Used to select a curve object that can be used to cause the characters to get thinner towards one end.
You can also alter the proportions of the Taper throughout the tapered object by moving/scaling/rotating
the Control Points of the *Taper Object*. The *Taper Object* can only be a curve.
Editing the Handles and Control Points of the *Taper Object* will cause the original object to change shape.
Bevel Object
Used to select a curve object that can be used to give custom bevel results.

.. seealso::

:doc:`Curve geometry &lt;/modeling/curves/properties/geometry&gt;` for more details and examples.

Font
====

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    Font

The *Font* panel has several options for changing the look of characters.

Loading and Changing Fonts
--------------------------

.. figure:: /images/modeling_text_properties_load-example.png

Loading a Type 1 font file.

Blender comes with a *built-in* font by default and is displayed in
each of the four font style data-block menus .
The *built-in* font is always present and shows in this list as "Bfont".
The data-block menu contains a list displaying the currently loaded fonts.
Select one for each font style.

To load a different *Font*, click one of the *Load* buttons in the
*Font* panel and navigate to a *valid* font.
The :doc:`File Browser &lt;/editors/file_browser/index&gt;` will give all valid fonts a capital F icon,
as seen in *Loading a Type 1 font file.*

.. note:: Location of fonts on Unix

Fonts are typically located under ``/usr/lib/fonts``, or some variant like ``/usr/lib/X11/fonts``,
but not always. They may be in other locations as well,
such as ``/usr/share/local`` or ``/usr/local/share``, and possibly related sub-trees.

If you select a font that Blender cannot understand,
you will get the error ``Not a valid font``.

Remember the same font will be applied to all chars with same style in a text,
but that a separate font is required for each style. For example,
you will need to load an *Italics* font in order to make characters or words italic. Once
the font is loaded you can apply that font "Style" to the selected characters or the whole
object. In all,
you would need to load a minimum of four different types of fonts to represent each style
(Normal, Italics, Bold, Bold-Italics).

It is important to understand, that Blender does not care what font
you load for "normal", "bold", etc., styles.
This is how you can have up to four different fonts in use in the same text,
but you have to choose between different styles of a same font, or different fonts.
Blender has a number of typographic controls for changing the style and layout of text,
found in the *Font* panel.

Size and Shear
--------------

Size
Controls the size of the whole text (no way to control each char size independently).
Note however, that chars with different fonts (different styles, see below) might have different visible sizes.
Shear
Controls the inclination of the whole text.
Different to as it may seems, this is not similar to italics style.

.. figure:: /images/modeling_text_properties_shear-example.png
:width: 300px

Shear: "blender" has a shear value of 1, "2.59" a shear value of 0.

Objects as Fonts
----------------

You can also "create" your own "font" inside Blender! This is quite a complex process,
so let us detail it:

#. First, you must create your chars. Each char, of any type,  is an object (mesh, curve, meta...).
They all must have a name following the schema:
*common prefix* followed by the *char name* (e.g. "ft.a", "ft.b", etc.).
#. Then, for the *Text* object, you must enable the *Dupli Verts* button
(:menuselection:`Object --&gt; Animation Settings` panel).
#. In the *Font* tap, fill the *Object Font* field with the *common prefix* of your "font" objects.

Now, each time a char in your text matches the *suffix part* of a "font" object's name,
this object is duplicated on this char. The original chars remain visible. The objects are
duplicated so that their center is positioned at the *lower right corner* of the
corresponding characters.

Text on Curve
Used to select a curve for the text object to follow.

.. figure:: /images/modeling_text_properties_curved-lowres-example.png
:width: 200px

Text on curve.

.. tip::

You can also use the :doc:`Curve Modifier &lt;/modeling/modifiers/deform/curve&gt;`
which offers more control.

Underline
Toggled with the *Underline* button before typing.
Text can also be set to Underlined by selecting it then using the *Underline* button in the Tool Shelf.

Position
This allows you to shift vertically the position of the underline.
Thickness
This controls the thickness of the underline.

.. _modeling-text-character:

Character
---------

.. list-table::

* - .. figure:: /images/modeling_text_properties_bold-example.png
:width: 320px

Bold text.

- .. figure:: /images/modeling_text_properties_font-settings.png
:width: 320px

Character options to, for example, type bold text.

Bold
Toggled with the *Bold* button before typing.
Text can also be set to Bold by selecting it then using the *Bold* button in the Tool Shelf.
Italics
Toggled with the *Italic* button before typing.
Text can also be set to Italic by selecting it then using the *Italic* button in the Tool Shelf.
Underline
Enables underlining, as controlled by the Underline settings above.
Small Caps
Type small capital text.

Blender's *Bold* and *Italic* buttons do not work the same way as other applications,
as they also serve as placeholders for you to load up other fonts manually,
which get applied when you define the corresponding style; see `Font`_.

To apply the Bold/Italics/Underline attribute to a set of characters, you either turn on
*Bold* / *Italics* / *Underline* prior to typing characters,
or highlight (select) first and then toggle Bold/Italics/Underline.

Setting Case
------------

You can change the text case by selecting it then clicking the *To Upper* or
*To Lower* in the tool shelf.

Enable the *Small Caps* option to type characters as small caps.

The size of the *Small Caps* can be changed with the *Small Caps Scale*
setting. Note that the *Small Caps Scale* is applied the same to all *Small Caps* formatted characters.

Paragraph
=========

The *Paragraph* Panel has settings for the alignment and spacing of text.

.. figure:: /images/modeling_text_properties_paragraph-settings.png
:width: 300px

The paragraph tab.

Horizontal Alignment
--------------------

Left
Aligns text to left of frames when using them,
else uses the center point of the *Text* object as the starting point of the text (which grows to the right).
Center
Centers text in the frames when using them,
else uses the center point of the *Text* object as the mid-point of the text
(which grows equally to the left and right).
Right
Aligns text to right of frames when using them,
else uses the center point of the *Text* object as the ending point of the text (which grows to the left).
Justify
Only flushes a line when it is terminated by a wordwrap (**not** by :kbd:`Enter`),
it uses *whitespace* instead of *character spacing* (kerning) to fill lines.
Flush
Always flushes the line, even when it is still being entered;
it uses character spacing (kerning) to fill lines.

Both *Justify* and *Flush* only work within frames.

Vertical Alignment
------------------

Top Base-Line
Aligns the text base-line to top of frames when using them,
else uses the center point of the *Text* object as the starting point of the text (which grows to the bottom).
Top
Aligns top of text to the center point of the *Text* object (which grows to the bottom).
It behaves as *Top Base-Line* when using frames. *Top* only works without frames.
Center
Centers text in the frames when using them,
else uses the center point of the *Text* object as the mid-point of the text
(which grows equally to the top and bottom).
Bottom
Aligns text to bottom of frames when using them,
else uses the center point of the *Text* object as the ending point of the text (which grows to the top).

Spacing
-------

Character
A factor by which space between each character is scaled in width.
Word
A factor by which whitespace between words is scaled in width.
You can also control it by pressing :kbd:`Alt-Left` or :kbd:`Alt-Right`
to decrease/increase spacing by steps of 0.1.
Line
A factor by which the vertical space between lines is scaled.

Offset
------

X offset and Y offset
Well, these settings control the X and Y offset of the text, regarding its "normal" positioning. Note that with
frames (see :doc:`Text Boxes &lt;/modeling/texts/editing&gt;`), it applies to all frames' content...

Text Boxes
==========

.. admonition:: Reference
:class: refbox

| Mode:     Object or Edit Modes
| Panel:    Font

.. figure:: /images/modeling_text_properties_frame-upperpanel-area.png

Text frame.

Text "Boxes" allow you to distribute the text amongst rectangular areas within a single text object.
An arbitrary number of freely positionable and re-sizable text frames are allowed per text object.

Text flows continuously from the lowest-numbered frame to the highest-numbered frame with text
inside each frame word-wrapped.
Text flows between frames when a lower-numbered frame cannot fit any more text.
If the last frame is reached, text overflows out of it.

Text frames are very similar to the concept of *frames* from a desktop publishing
application, like Scribus. You use frames to control the placement and flow of text.

Frames are controlled in the *Text Boxes* panel.

Frame Size
----------

By default the first frame for a new text object, and any additional frames,
has a size of **zero** for both *Width* and *Height*,
which means the frame is initially not visible.

Frames with a width of 0.0 are ignored completely during text flow (no wordwrap happens),
and frames with a height of 0.0 flow forever (no flowing to the next text frame).

In order for the frame to become visible, the frame's *Width* must be greater than 0.0.

.. note::

Technically the height is never actually 0.0, because the font itself always contributes height.

.. _fig-texts-edit-frame:

.. figure:: /images/modeling_text_properties_frame-default-example.png

Frame width.

Fig. :ref:`fig-texts-edit-frame` is a text object with a width of 5.0.
And because the frame width is greater than 0.0
it is now visible and is drawn in the active theme color as a dashed rectangle.
The text has overflowed because the text has reached the end of the last frame, the default frame.

Adding/Deleting a Frame
-----------------------

To add a frame click the *Add Textbox* button on the *Text Boxes* panel.
A new frame is inserted just after (in text flow order) the current one, with its attributes
(position and size). Be sure to modify the offset for the new frame in the X
and/or Y fields. Just an X modification will create a new column.

To delete the current frame, click the :kbd:`Delete` button.
Any text in higher frames will be re-flowed downward into lower frames.

Examples
--------

Text Flow
^^^^^^^^^

.. _fig-texts-edit-wrap:

.. figure:: /images/modeling_text_properties_frame-example2.png

Wrapping.

With two or more frames you can organize text to a finer degree. For example,
create a text object and enter "Blender is super duper".
This text object has a frame; it just is not visible because its *Width* is 0.0.

Set the width to 5.0. The frame is now visible and text is wrapping according to the new width,
as shown in Fig. :ref:`fig-texts-edit-wrap`. Notice that the text has overflowed out of the frame.
This is because the text has reached the end of the last frame,
which just happens to be the default/initial frame.

.. figure:: /images/modeling_text_properties_frame-example3.png
:width: 300px

Text flowing from box 1 to box 2.

When we add another frame and set its width and height, the text will flow into the new frame.

Multiple Columns
^^^^^^^^^^^^^^^^

.. _fig-texts-edit-text5:

.. figure:: /images/modeling_text_properties_frame-example4.png

Text 5.

To create two columns of text just create a text object and adjust the initial frame's
*Width* and *Height* to your requirements, then insert a new frame.
The new frame will have the same size as the initial frame. Set the X position to
something greater or less than the width of the initial frame; see Fig. :ref:`fig-texts-edit-text5`.

**************************
Baking Physics Simulations
**************************

:term:`Baking` refers to the act of storing or caching the results of a calculation.

It is generally recommended to bake your physics simulations before rendering.
Aside from no longer needing to go through the time-consuming process of simulating again,
baking can help prevent potential glitches and ensure that the outcome of the simulation
remains exactly the same every time.

.. A Screenshot of the baking interface is intentionally omitted, as it
the available options vary slightly between different physics systems.

.. note::

Most physics simulators in Blender use a similar system,
but not all have exactly the same settings available. All the settings are covered here,
but individual physics types may not provide all these options.

Compression
Compression level for cache files. Some physics caches can be very large (such as smoke).
Blender can compress these caches in order to save space.

None
Do not compress the cache.
Light
Compression optimizes speed of compressing/decompressing operations over file size.
Heavy
Compression will result in smaller cache files more than *Light*,
however, requires more CPU time to compress/decompress.
External
Read and write the cache to a drive using a user-specified file path.

Index Number
This number specifies which cache should be used
when the specified cache directory contains `multiple caches`_.
``0`` refers to the top-most cache, ``1`` to the second from the top,
``2`` to the third, and so on.
Use Lib Path
Share the disk cache when the physics object is
:doc:`linked &lt;/data_system/linked_libraries&gt;` into another blend-file.

When this option is enabled, linked versions of the object will reference the same disk cache.
When disabled, linked versions of the object will use independent caches.

Start
Frame on which to start the simulation.
End
Frame on which to stop the simulation.

Cache Step
Interval for storing simulation data.

.. note::

Some physics systems (such as particles)
allow for positions to be stored only on every nth frame,
letting the positions for in-between frames be interpolated.
Using a cache step greater than one will result in a smaller cache,
but the result may differ from the original simulation.

.. _physics-bake:

Bake
Start baking.
Blender will become unresponsive during most baking operations.
The cursor will display as a number representing the bakes' progress.

.. _free-physics-bake:

Free Bake
Mark the baked cache as temporary. The data will still exist,
but will be removed with the next object modification and frame change.
This button is only available when the physics system has been baked.

.. _calc-physics-bake-to-frame:

Calculate To Frame
Bake only up to the current frame. Limited by *End* frame set in the cache settings.
Current Cache to Bake
Store any temporarily cached simulation data as a bake.
Note that playing the animation will try to simulate any visible physics simulations.
Depending on the physics type, this data may be temporarily cached.
Normally such temporary caches are cleared when an object or setting is
modified, but converting it to a bake will "save" it.

Bake All Dynamics
Bake all physics systems in the scene, even those of different types.
Useful for baking complex setups involving interactions between different physics types.

See :ref:`Bake &lt;physics-bake&gt;`
Free All Bakes
Free bakes of all physics systems in the scene, even those of different types.

See :ref:`Free Bake &lt;free-physics-bake&gt;`.
Update All To Frame
Bake all physics systems in the scene to the current frame.

See :ref:`Calculate To Frame &lt;calc-physics-bake-to-frame&gt;`

Multiple Caches
===============

Blender allows for storing and managing multiple caches at once for the same physics object.

.. figure:: /images/physics_baking_multi_cache_interface.png

Two different caches stored simultaneously.

Caches can be added and removed with the :kbd:`Plus` and :kbd:`Minus` buttons.
Renaming a cache can be done by either double clicking or pressing :kbd:`Ctrl-LMB` on the desired cache.

********
Examples
********

To start with cloth, the first thing you need, of course, is some fabric. So,
let us delete the default cube and add a plane. In order to get some good floppy and flexible fabric,
you will need to subdivide it several times, about eight is a good number.
So :kbd:`Tab` into *Edit Mode*, and press :kbd:`W` :menuselection:`Specials --&gt; Subdivide multi`,
and set it to 8.

Now, we will make this cloth by going to the Physics tab.
Scroll down until you see the *Cloth* panel, and press the *Cloth* button.
Now, a lot of settings will appear, most of which we will ignore for now.

That is all you need to do to set your cloth up for animating,
but if you press :kbd:`Alt-A`, your lovely fabric will just drop very un-spectacularly.
That is what we will cover in the next two sections about pinning and colliding.

Using Simulation to Shape/Sculpt a Mesh
=======================================

You can *Apply* the Cloth Modifier at any point to freeze the mesh in
position at that frame. You can then re-enable the cloth,
setting the start and end frames from which to run the simulation forward.

Another example of aging is a flag.
Define the flag as a simple grid shape and pin the edge against the flagpole.
Simulate for 50 frames or so, and the flag will drop to its "rest" position.
Apply the *Cloth* Modifier.
If you want the flag to flap or otherwise move in the scene,
re-enable it for the frame range when it is in camera view.

Smoothing of Cloth
==================

Now, if you followed this from the previous section, your cloth is probably looking a little blocky.
In order to make it look nice and smooth like the picture you need to apply a
Smooth and/or Subdivision Surface Modifier in the *Modifiers* tab. Then, in the same editor,
find the *Links and Materials* panel (the same one you used for vertex groups) and press *Set Smooth*.

Now, if you press :kbd:`Alt-A`, things are starting to look pretty nice, do not you think?

Cloth on armature
=================

Cloth deformed by armature and also respecting an additional collision object:
`Regression blend-file &lt;https://wiki.blender.org/index.php/Media:Cloth-regression-armature.blend&gt;`__.

Cloth with animated vertex groups
=================================

Cloth with animated pinned vertices:
`Regression blend-file &lt;https://wiki.blender.org/index.php/Media:Cloth_anim_vertex.blend&gt;`__.
UNSUPPORTED: Starting with a goal of 0 and increasing it,
but still having the vertex not pinned will not work (e.g. from goal = 0 to goal = 0.5).

Cloth with Dynamic Paint
========================

Cloth with Dynamic Paint using animated vertex groups:
`Regression blend-file &lt;https://wiki.blender.org/index.php/Media:Cloth_dynamic_paint.blend&gt;`__.
UNSUPPORTED: Starting with a goal of 0 and increasing it, but still having the vertex not pinned will not work
(e.g. from goal = 0 to goal = 0.5) because the necessary "goal springs" cannot be generated on the fly.

Using Cloth for Softbodies
==========================

.. figure:: /images/physics_cloth_examples_softbody1.jpg
:width: 200px

Using cloth for softbodies.

Cloth can also be used to simulate softbodies.
It is for sure not its main purpose but it works nonetheless.
The example image uses standard *Rubber* material, no fancy settings,
just :kbd:`Alt-A`.

Blend file for the example image:
`Using Cloth for softbodies &lt;https://wiki.blender.org/index.php/Media:Cloth-sb1.blend&gt;`__.

Cloth with Wind
===============

.. figure:: /images/physics_cloth_examples_flag2.jpg
:width: 200px

Flag with wind applied.

Regression blend-file for Cloth with wind and self collisions (also the blend for the image above):
`Cloth flag with wind and selfcollisions &lt;https://wiki.blender.org/index.php/Media:Cloth-flag2.blend&gt;`__.

####################
Cloth Simulations
####################

.. toctree::
:maxdepth: 2

introduction.rst
settings/index.rst
examples.rst
..    TODO/Review: {{review|copy=X|text=Partially}}.

************
Introduction
************

Cloth simulation is one of the hardest aspects of CG,
because it is a deceptively simple real-world item that is taken for granted,
yet actually has very complex internal and environmental interactions.
After years of development,
Blender has a very robust cloth simulator that is used to make clothing, flags, banners,
and so on. Cloth interacts with and is affected by other moving objects,
the wind and other forces, as well as a general aerodynamic model,
all of which is under your control.

.. list-table::

* - .. figure:: /images/physics_cloth_introduction_example1.jpg
:width: 150px

Cloth Example.

- .. figure:: /images/physics_cloth_introduction_oncarved-wood.jpg
:width: 150px

Cloth on carved wooden men (made by motorsep).

- .. figure:: /images/physics_cloth_introduction_example2.jpg
:width: 150px

Cloth Example.

A piece of cloth is any mesh, open or enclosed, that has been designated as cloth.
The *Cloth* panels are located in the *Physics* tab and consist of three panels of options.
Cloth is either an open or closed mesh and is mass-less, in that all cloth is assumed to have the same density,
or mass per square unit.

Cloth is commonly modeled as a mesh grid primitive, or a cube, but can also be, for example, a teddy bear.
However, Blender's :doc:`Softbody system &lt;/physics/soft_body/index&gt;` provides better simulation of closed meshes;
Cloth is a specialized simulation of fabrics.

Once the object is designated as Cloth, a Cloth :doc:`modifier &lt;/modeling/modifiers/index&gt;`
will be added to the object's modifier stack automatically. As a :doc:`modifier &lt;/modeling/modifiers/index&gt;`
then, it can interact with other modifiers, such as *Armature* and *Smooth*. In these cases,
the ultimate shape of the mesh is computed in accordance with the order of the modifier stack.
For example, you should smooth the cloth *after* the modifier computes the shape of the cloth.

So you edit the Cloth settings in two places: use the Physics buttons to edit the
properties of the cloth and use the Modifier stack to edit the Modifier properties related to
display and interaction with other modifiers.

You can *Apply* the Cloth Modifier to freeze, or lock in,
the shape of the mesh at that frame, which removes the modifier. For example,
you can drape a flat cloth over a table, let the simulation run, and then apply the modifier.
In this sense, you are using the simulator to save yourself a lot of modeling time.

Results of the simulation are saved in a cache, so that the shape of the mesh,
once calculated for a frame in an animation, does not have to be recomputed again.
If changes to the simulation are made, you have full control over clearing the cache and re-running the simulation.
Running the simulation for the first time is fully automatic and no baking or separate step interrupts the workflow.

Computation of the shape of the cloth at every frame is automatic and done in the background;
thus you can continue working while the simulation is computed. However, it is CPU-intensive
and depending on the power of your PC and the complexity of the simulation,
the amount of CPU needed to compute the mesh varies, as does the lag you might notice.

.. note:: Do not jump ahead

If you set up a cloth simulation but Blender has not computed the shapes for the duration of the simulation,
and if you jump ahead a lot of frames forward in your animation,
the cloth simulator may not be able to compute or show you an accurate mesh shape for that frame,
if it has not previously computed the shape for the previous frame(s).

Workflow
========

A general process for working with cloth is to:

- Model the cloth object as a general starting shape.
- Designate the object as a "cloth" in the *Physics* tab of the Properties editor.
- Model other deflection objects that will interact with the cloth.
Ensure the Deflection modifier is last on the modifier stack, after any other mesh deforming modifiers.
- Light the cloth and assign materials and textures, UV-unwrapping if desired.
- If desired, give the object particles, such as steam coming off the surface.
- Run the simulation and adjust Options to obtain satisfactory results.
The Timeline editors VCR controls are great for this step.
- Optionally age the mesh to some point in the simulation to obtain a new default starting shape.
- Make minor edits to the mesh on a frame-by-frame basis to correct minor tears.

.. tip::

To avoid unstable simulation, ensure that the cloth object does not penetrate any of the deflection objects,

********
Settings
********

Cloth
=====

Presets
Contains a number of :ref:`preset &lt;ui-presets&gt;` cloth examples.
Quality
Set the number of simulation steps per frame. Higher values result in better quality, but is slower.
Speed
Adjust how fast time flows in the cloth simulation.

Material
--------

Mass
The mass of the cloth material.
Structural
Overall stiffness of the cloth.
Bending
Wrinkle coefficient. Higher creates more large folds.

Damping
-------

Spring
Damping of cloth velocity. Higher values give a more smooth result (less jiggling).
Air
Air normally has some thickness which slows falling things down.
Velocity
Damps the velocity to help the cloth reach the final resting position faster.

Pinning
-------

The first thing you need when pinning cloth is a
:doc:`Vertex Group &lt;/modeling/meshes/properties/vertex_groups/index&gt;`.
There are several ways of doing this including using the Weight Paint tool to paint the areas you want to pin
(see the :doc:`/sculpt_paint/painting/weight_paint/index` section of the manual).
The weight of each vertex in the group controls how strongly it is pinned.

.. figure:: /images/physics_cloth_settings_pin-example_01.png

Cloth Pinning.

Once you have a vertex group set, things are pretty straightforward; all you have to do is
press the *Pinning of cloth* button in the *Cloth* panel and select which
vertex group you want to use, and the stiffness you want it at.

Stiffness
Target position stiffness. You can leave the stiffness as it is; the default value of 1 is fine.

Pinning Clothing To An Armature
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Clothing can be simulated and pinned to an armature.
For example, a character could have a baggy tunic pinned to the character's waist with a belt.

The typical workflow for pinning:

#. Set the armature to its bind pose.
#. Model clothing that encloses but does not penetrate the character's mesh.
#. Parent the clothing objects to the armature. The armature will now have several child meshes bound to it.
#. Create a new vertex group on each cloth object for its pinned vertices
#. Add vertexes to be pinned to this vertex group and give these vertices non-zero weights
(you probably want weight = 1).
For example the belt area of the tunic would be in the vertex group and have weight one.
#. Designate the clothing objects as "cloth" in the Physics tab of the Properties editor.
Make sure the Cloth Modifier is below the Armature Modifier in the modifier stack.
#. press the *Pinning of Cloth* button in the *Cloth* panel and select the vertex group.
#. Designate the character's mesh as "collision" object in the Physics tab of the Properties editor.
#. The clothing is now ready. Non-pinned vertices will be under control of the Cloth modifier.
Pinned vertices will be under control of the Armature modifier.

.. note::

When animating or posing the character you must begin from the bind pose.
Move the character to its initial pose over several frames so the physics engine can simulate the clothing moving.
Very fast movements and teleport jumps can break the physics simulation.

.. Note that if you move the cloth object ''after'' you have already run some simulations,
you must unprotect and clear the cache; otherwise, Blender will use the position of the
current/cached mesh's vertices when trying to represent where they are.
Editing the shape of the mesh, after simulation, is also discussed below.
You may disable the cloth and edit the mesh as a normal mesh editing process.
This is jumping ahead and not clear and not true at this point.
--[[User:Roger|Roger]] 18:42, 27 April 2008 (UTC)

Finally, use the Timeline editor Play button,
or press :kbd:`Alt-A` in the 3D View to run the simulation.
Your cloth will fall and interact with Deflection objects as it would in the real world.

.. This is jumping ahead and not clear and not true at this point.
--[[User:Roger|Roger]] 18:42, 27 April 2008 (UTC)

Dynamic Mesh
------------

Dynamic Mesh allows animating the rest shape of cloth using shape keys or
modifiers (e.g. an Armature modifier or any deformation modifier) placed above the Cloth modifier.
When it is enabled, the rest shape is recalculated every frame, allowing unpinned
cloth to squash and stretch following the character with the help of shape keys or modifiers, but
otherwise move freely under control of the physics simulation.

Normally cloth uses the state of the object in the first frame to compute the natural rest
shape of the cloth, and keeps that constant throughout the simulation. This is reasonable
for fully realistic scenes, but does not quite work for clothing on cartoon style characters
that use a lot of squash and stretch.

Cloth Stiffness Scaling
=======================

Structural Stiffness
Defines a vertex group to control over structural stiffness.
Maximum
Maximum structural stiffness value.

Bending Stiffness
Defines a vertex croup to control over bending stiffness.
Maximum
Maximum structural bending value.

Cloth Sewing Springs
====================

Another method of restraining cloth similar to pinning is sewing springs.
Sewing springs are virtual springs that pull vertices in one part of
a cloth mesh toward vertices in another part of the cloth mesh.
This is different from pinning which binds vertices of the cloth mesh in place or to another object.
A clasp on a cloak could be created with a sewing spring.
The spring could pull two corners of a cloak about a character's neck.
This could result in a more realistic simulation than pinning the cloak to
the character's neck since the cloak would be free to slide about the character's neck and shoulders.

Sewing springs are created by adding extra edges to a cloth mesh that are not included in any faces.
They should connect vertices in the mesh that should be pulled together.
For example the corners of a cloak.

To activate the springs, enable the *Cloth Sewing Springs* panel.

Options
-------

Sewing Force
Maximum force that can be applied by sewing springs. Zero means unbounded, but it is not
recommended to leave the field at zero in most cases, as it can cause instability due to
extreme forces in the initial frames where the ends of the sewing springs are far apart.

Shrinking
^^^^^^^^^

The *Cloth Sewing Springs* panel also contains controls for shrinking the actual cloth faces.

Shrinking Group
Vertex group that is used to vary the intensity of the shrinking effect over the cloth.

Min
Fraction of the size to shrink the cloth by around vertices with weight 0 (or those not in vertex group.)
The value 0.01 means shrink by 1% etc.
Max
Fraction of the size to shrink the cloth by around vertices with weight 1.

Like unbounded sewing forces, immediately applying a large amount of shrink can cause
instability, so it is advisable to keyframe these fields and ease in from 0 during draping.

Cloth Field Weights
===================

As other physics dynamics systems, Cloth simulation also are influenced external force effectors.

**********
Collisions
**********

In most cases, a piece of cloth does not just hang there in 3D space,
it collides with other objects in the environment. To ensure proper simulation,
there are several items that have to be set up and working together:

- The *Cloth* object must be told to participate in collisions.
- Optionally (but recommended) tell the cloth to collide with itself.
- Other objects must be visible to the *Cloth* object *via* shared layers.
- The other objects must be mesh objects.
- The other objects may move or be themselves deformed by other objects (like an armature or shape key).
- The other mesh objects must be told to deflect the cloth object.
- The blend-file must be saved in a directory so that simulation results can be saved.
- You then *Bake* the simulation. The simulator computes the shape of the cloth for a frame range.
- You can then edit the simulation results, or make adjustments to the cloth mesh, at specific frames.
- You can make adjustments to the environment or deforming objects,
and then re-run the cloth simulation from the current frame forward.

Collision Settings
==================

.. figure:: /images/physics_cloth_settings_collisions_panel.png
:width: 200px

Cloth Collisions panel.

Now you must tell the *Cloth* object that you want it to participate in collisions.
For the cloth object, locate the *Cloth Collision* panel, shown to the right:

Quality
A general setting for how fine and good a simulation you wish.
Higher numbers take more time but ensure less tears and penetrations through the cloth.
Distance
As another object gets this close to it (in Blender Units),
the simulation will start to push the cloth out of the way.
Repel
Repulsion force to apply when cloth is close to colliding.
Repel Distance
Maximum distance to apply repulsion force. Must be greater than minimum distance.
Friction
A coefficient for how slippery the cloth is when it collides with the mesh object.
For example, silk has a lower coefficient of friction than cotton.

Self-collisions
---------------

Real cloth cannot permeate itself, so you normally want the cloth to self-collide.

Enable Self Collisions
Click this to tell the cloth object that it should not penetrate itself. This adds to simulation compute time,
but provides more realistic results. A flag, viewed from a distance does not need this enabled,
but a close-up of a cape or blouse on a character should have this enabled.
Quality
For higher self-collision quality just increase the
*Quality* and more self collision layers can be solved.
Just keep in mind that you need to have at least the same
*Collision Quality* value as the *Quality* value.
Distance
If you encounter problems, you could also change the *Min Distance* value for the self-collisions.
The best value is 0.75; for fast things you better take 1.0. The value 0.5 is quite risky
(most likely many penetrations) but also gives some speedup.

Regression blend-file:
`Cloth selfcollisions &lt;https://wiki.blender.org/index.php/Media:Cloth-regression-selfcollisions.blend&gt;`__.

Shared Layers
=============

Suppose you have two objects: a pair of Pants on layers 2 and 3,
and your Character mesh on layers 1 and 2.
You have enabled the Pants as cloth as described above.
You must now make the Character "visible" to the Cloth object,
so that as your character bends its leg, it will push the cloth.
This principle is the same for all simulations;
simulations only interact with objects on a shared layer. In this example,
both objects share layer 2.

To view/change an object's layers,
:kbd:`RMB` click to select the object in *Object Mode* in the 3D View.
:kbd:`M` to bring up the "Move Layers" pop-up,
which shows you all the layers that the object is on. To put the object on a single layer,
:kbd:`LMB` click the layer button. To put the object on multiple layers,
:kbd:`Shift-LMB` the layer buttons. To remove an object from a selected layer,
simply :kbd:`Shift-LMB` the layer button again to toggle it.

Mesh Objects Collide
====================

If your colliding object is not a mesh object, such as a NURBS surface, or text object,
you must convert it to a mesh object. To do so, select the object in object mode,
and in the 3D View header, select :menuselection:`Object --&gt; Convert Object Type`
:kbd:`Alt-C`, and select :menuselection:`Mesh` from the pop-up menu.

Cloth - Object collisions
-------------------------

.. figure:: /images/physics_collision.png
:width: 200px

Collision settings.

The cloth object needs to be deflected by some other object. To deflect a cloth,
the object must be enabled as an object that collides with the cloth object.
To enable Cloth - Object collisions, you have to enable deflections on the collision object
(not on the cloth object).

In the Properties editor, *Object* tab and
*Physics* tab, locate the *Collision* panel shown to the right. It
is also important to note that this collision panel is used to tell all simulations that this
object is to participate in colliding/deflecting other objects on a shared layer (particles,
soft bodies, and cloth).

.. warning::

There are three different *Collision* panels, all found in the *Physics* tab.
The first (by default), a tab beside the *Fields* panel, is the one needed here. The second panel,
a tab in the *Soft Body* group, concern softbodies (and so has nothing to do with cloth).
And we have already seen the last one, by default a tab beside the *Cloth* panel.

Mesh Object Modifier Stack
==========================

.. figure:: /images/physics_cloth_settings_collitions_stack.jpg
:width: 200px

Collision stack.

The object's shape deforms the cloth,
so the cloth simulation must know the "true" shape of that mesh object at that frame.
This true shape is the basis shape as modified by shape keys or armatures. Therefore,
the Collision Modifier must be **after** any of those.
The image to the right shows the *Modifiers* panel for the Character mesh object
(not the cloth object).

Cloth Cache
===========

Cache settings for cloth are the same as with other dynamic systems.
See :doc:`Particle Cache &lt;/physics/particles/emitter/cache&gt;` for details.

Bake Collision
--------------

.. figure:: /images/physics_cloth_settings_collitions_bake.jpg
:width: 200px

After Baking.

After you have set up the deflection mesh for the frame range you intend to run the simulation
(including animating that mesh *via* armatures),
you can now tell the cloth simulation to compute (and avoid) collisions.
Select the cloth object and in the *Object* tab,
*Physics* tab, set the *Start* and *End* settings for
the simulation frames you wish to compute, and click the *Bake* button.

You cannot change *Start* or *End* without clearing the bake simulation.
When the simulation has finished, you will notice you have the option to free the bake,
edit the bake and re-bake:

There are a few things you will probably notice right away. First,
it will bake significantly slower than before,
and it will probably clip through the box pretty badly as in the picture on the right.

Editing the cached simulation
-----------------------------

The cache contains the shape of the mesh at each frame. You can edit the cached simulation,
after you have baked the simulation and pressed the *Bake Editing* button.
Just go to the frame you want to fix and :kbd:`Tab` into *Edit Mode*.
There you can move your vertices using all of Blender's mesh shaping tools. When you exit,
the shape of the mesh will be recorded for that frame of the animation.
If you want Blender to resume the simulation using the new shape going forward,
:kbd:`LMB` click *Rebake from next Frame* and play the animation.
Blender will then pick up with that shape and resume the simulation.

Edit the mesh to correct minor tears and places where the colliding object has punctured the
cloth.

If you add, delete, extrude, or remove vertices in the mesh, Blender will take the new mesh as
the starting shape of the mesh back to the *first frame* of the animation,
replacing the original shape you started with,
up to the frame you were on when you edited the mesh. Therefore,
if you change the content of a mesh, when you :kbd:`Tab` out of *Edit Mode*,
you should unprotect and clear the cache so that Blender will make a consistent simulation.

Troubleshooting
===============

If you encounter some problems with collision detection, there are two ways to fix them:

- The fastest solution is to increase the *Min Distance* setting under the *Cloth Collision* panel.
This will be the fastest way to fix the clipping; however, it will be less accurate and will not look as good.
Using this method tends to make it look like the cloth is resting on air, and gives it a very rounded look.
- A second method is to increase the *Quality* (in the first *Cloth* panel).
This results in smaller steps for the simulator and
therefore to a higher probability that fast-moving collisions get caught.
You can also increase the *Collision Quality* to perform more iterations to get collisions solved.
- If none of the methods help, you can easily edit the cached/baked result in *Edit Mode* afterwards.
- The Cloth is torn by the deforming mesh -- he "Hulks Out": Increase its structural stiffness
(*Structure Stiffness* setting, *Cloth* panel), very high, like 1000.

.. note:: Subdivision Surface Modifier

A bake/cache is done for every subdivision level so please use
**the equal** subdivision level for render and preview.

###########
Settings
###########

.. toctree::
:maxdepth: 2

cloth_settings.rst
collisions.rst

**********
Collisions
**********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Physics --&gt; Collision`

:doc:`Particles &lt;/physics/particles/index&gt;`, :doc:`Soft Bodies &lt;/physics/soft_body/index&gt;`
and :doc:`Cloth objects &lt;/physics/cloth/index&gt;` may collide with mesh objects.
:doc:`Boids &lt;/physics/particles/emitter/physics/boids&gt;` try to avoid *Collision* objects.

- The objects need to share at least one common layer to have effect.
- You may limit the effect on particles to a group of objects
(in the :doc:`Field Weights panel &lt;/physics/particles/emitter/physics/index&gt;`).
- *Deflection* for softbody objects is difficult, they often penetrate the colliding objects.
- Hair particles ignore deflecting objects
(but you can animate them as softbodies which take deflection into account).

If you change the deflection settings for an object you have to recalculate the particle,
softbody or cloth system by *Free Cache*, this is not done automatically. You can
clear the cache for all selected objects with :kbd:`Ctrl-B` :menuselection:`--&gt; Free cache selected`.

Options
=======

.. figure:: /images/physics_collision.png

Collision Panel.

Particle
--------

Permeability
Fraction of particles passing through the mesh.
Stickiness
How much particles stick to the object.
Kill Particles
Deletes Particles upon impact.

Damping Factor
Damping during a collision (independent of the velocity of the particles).
Random damping
Random variation of damping.

Friction Factor
Friction during movements along the surface.
Random friction
Random variation of friction.

.. _fig-collision-soft-plane:

.. only:: builder_html

.. figure:: /images/physics_soft-body_collision_vertex-plane1.gif

A softbody vertex colliding with a plane.

.. only:: latex or epub

An example image can be found at:
https://docs.blender.org/manual/en/dev/_images/physics_soft-body_collision_vertex-plane1.gif

Soft Body and Cloth
-------------------

Outer
Size of the outer collision zone.
Inner
Size of the inner collision zone (padding distance).

Outside and inside is defined by the face normal, depicted as blue arrow in Fig. :ref:`fig-collision-soft-plane`.

Soft Body Damping
-----------------

Damping Factor
Damping during a collision.

*Softbody* collisions are difficult to get perfect. If one of the objects move too fast,
the soft body will penetrate the mesh. See also the section about :doc:`Soft Bodies &lt;/physics/soft_body/index&gt;`.

Force Field
-----------

Absorption
A deflector can also deflect effectors. You can specify some collision/deflector objects which deflect a specific
portion of the effector force using the *Absorption* value. 100% absorption results in no force getting
through the collision/deflector object at all. If you have three collision object behind each other with e.g.
10%, 43% and 3%, the absorption ends up at around 50% :math:`100 × (1 - 0.1) × (1 - 0.43) × (1 - 0.03)`.

Examples
========

.. figure:: /images/physics_collision_defected_particles.jpg

Deflected Particles.

Here is a *Meta* object, dupliverted to a particle system emitting downwards, and deflected by a mesh cube:

Hints
=====

- Make sure that the normals of the mesh surface are facing towards the particles/points for correct deflection.
- Hair particles react directly to force fields,
so if you use a force field with a short range you do not need necessarily collision.
- Hair particles avoid their emitting mesh if you edit them in *Particle Edit Mode*.
So you can at least model the hair with collision.

*******************
Dynamic Paint Brush
*******************

.. figure:: /images/physics_dynamic-paint_brush_main-panel.png

Brush main panel.

From the first brush panel you can define how brush affects canvas color surfaces.

Absolute Alpha
This setting limits brush alpha influence.
Without it, brush is "added" on surface over and over again each frame,
increasing alpha and therefore influence of brush on canvas. In many cases however,
it is preferred to not increase brush alpha if it already is on brushes level.
Erase Paint
Makes brush dissolve exiting paint instead of adding it.
Wetness
Defines how "wet" new paint is. Wetness is visible on "Paint" surface "wetmap".
Speed of "Drip" and "Spread" effects also depends on how wet the paint is.
Use Object Material
When enabled, you can define a material to be used as brush color.
This includes material's base color and all textures linked to it, eventually matching the rendered diffuse color.
This setting is only available when using "Blender Internal" renderer at the moment.

Otherwise you can define a color for the brush from the color box below.
Alpha
Defines brush alpha or visibility. Final wetness is also affected by alpha.

Source Panel
============

.. figure:: /images/physics_dynamic-paint_brush_source-panel.png

Paint source panel.

Paint Source
------------

Paint Source setting lets you define how brush influence/intersection is defined.

Mesh Volume
The Brush affects all surface point inside the mesh volume.

.. figure:: /images/physics_dynamic-paint_brush_source_mesh-volume.png

Source: Mesh Volume.

Proximity
Only uses defined distance to the closest point on brush mesh surface.
Note that inside of the volume is not necessarily affected because it is not close to the surface.

.. figure:: /images/physics_dynamic-paint_brush_source_proximity.png

Source: Proximity. Brush affects all canvas pixels around it.

Mesh Volume + Proximity
Same as volume type, but also has influence over defined distance.

Inner Proximity
Applies proximity inside the mesh volume.
Negate Volume
Negates brush alpha within mesh volume.

.. list-table::

* - .. figure:: /images/physics_dynamic-paint_brush_source_mesh-volume-proximity-1.png

The Volume + Proximity brush with no additional settings.

- .. figure:: /images/physics_dynamic-paint_brush_source_mesh-volume-proximity-2.png

Inner Proximity. Proximity falloff is now visible inside the volume.

* - .. figure:: /images/physics_dynamic-paint_brush_source_mesh-volume-proximity-3.png

Negate Volume. Inner side of the volume has become completely transparent.

- .. figure:: /images/physics_dynamic-paint_brush_source_mesh-volume-proximity-4.png

Inner Proximity and Negate Volume enabled together.

Object Center
Instead of calculating proximity to the brush object mesh, which can be quite slow in some cases,
only distance to only center is calculated. This is much faster and often good enough.

.. figure:: /images/physics_dynamic-paint_brush_source_object-center.png

Source: Object Center.

Particle System
Brush influence is defined by particles from a selected particle system.

Particle Effect: Solid Radius
ToDo.
Use Particle Radius
Smooth Radius

.. figure:: /images/physics_dynamic-paint_brush_source_particle-system.png

Source: Particle System.

Common Options
--------------

Paint Distance
ToDo.
Project
Projects brush to the canvas from a defined direction.
Basically this can be considered as "direction aligned" proximity.

.. figure:: /images/physics_dynamic-paint_brush_source_project.png

The Project option enabled. See how brush only affects canvas in normal direction.
Falloff
Falloff type can be "Smooth", "Sharp" or tweaked with a color ramp.

Velocity Panel
==============

.. figure:: /images/physics_dynamic-paint_brush_velocity-panel.png

Velocity panel.

This panel shows brush options that are based on object velocity.

On top you have a color ramp and several related settings.
Basically the color ramp represents brush velocity values:
left side being zero velocity and right side being the "Max velocity".
Speed is measured in "Blender units per frame".

Checkboxes above can be used to define color ramp influence.

Multiply Alpha
Uses color ramp's alpha value depending on current velocity and multiplies brush alpha with it.
Replace Color
Replaces the brush color with the values from the :ref:`ui-color-ramp-widget`.
Multiply Depth
Multiplies brushes "depth intersection" effect.
Basically you can adjust displace and wave strength depending on brush speed.
Do Smudge
Enabling Smudge makes the brush "smudge" (or "smear") existing colors on the surface as it moves.
The strength of this effect can be defined from the *Smudge Strength* property.

Even when smudge is enabled brush still does its normal paint effect.
If you want a purely smudging brush use zero alpha.
It is also possible to have *Erase* option enabled together with smudge.

Waves Panel
===========

.. figure:: /images/physics_dynamic-paint_brush_waves-panel.png

Brush Waves panel.

This panel is used to adjust brush influence to "Wave" surfaces.

Wave Type
Select what effect the brush has on the wave simulation.

Depth Change
This option makes brush create waves when the intersection depth with the surface is *changed* on that point.
If the brush remains still it will not have influence.

Using a negative "Factor" with this type can create a nice looking "wake" for moving objects like ships.
Obstacle
Constantly affects surface whenever intersecting.
Waves are also reflected off this brush type.
However, due the nature of wave simulation algorithm this type creates
an unnatural "dent" in the surface if brush remains still.
Force
Directly affects the velocity of wave motion.
Therefore the effect is not one to one with brush intersection depth, yet the force strength depends on it.
Reflect Only
This type has no visible effect on the surface alone but reflects waves that are already on the surface.
Factor
Adjusts how strongly brush "depth" affects the simulation.
You can also use negative values to make brush pull water up instead of down.
Clamp Waves
In some cases the brush goes very deep inside the surface messing whole simulation up.
You can use this setting to "limit" influence to only certain depth.

********************
Dynamic Paint Canvas
********************

.. figure:: /images/physics_dynamic-paint_canvas_main-panel.png
:align: right

Canvas main panel.

Paint Surface
A :ref:`list &lt;ui-list-view&gt;` of Dynamic Paint surfaces.
These surfaces are basically layers of paint, that work independently from each other.
You can define individual settings for them and bake them separately.

Show Preview (eye icon)
If surface type/format allows previewing results in 3D View,
this toggle is visible.
Is Active
The checkbox toggles whether surface is active at all.
If not selected, no calculations or previews are done.

Below you can set surface type and adjust quality and timing settings.

Format
Each surface has a certain format and type.
Format determines how data is stored and outputted.

Vertex
Dynamic Paint operates directly on mesh vertex data.
Results are stored by point cache and can be displayed in viewports.
However, using vertex level also requires a highly subdivided mesh to work.
Image Sequences
Dynamic Paint generates UV wrapped image files of defined resolution as output.

Quality: Resolution
For image sequences -- From quality settings you can adjust the output image dimensions.
Anti-aliasing
:term:`Anti-aliasing` smoothen paint edges using a 5x multisampling method.
Frames: Start, End
Defines surface processing start and end frame.
Sub-steps
Sub-steps are extra samples between frames, usually required when there is a very fast brush.

Advanced Panel
==============

.. figure:: /images/physics_dynamic-paint_canvas_advanced-panel.png

Canvas advanced panel.

From "Advanced" panel you can adjust surface type and related settings.

Surface Type
------------

Each surface has a "type" that defines what surface is used for.

Paint
^^^^^

.. figure:: /images/physics_dynamic-paint_canvas_surface-type_paint.jpg
:width: 320px

Paint Surface.

Paint is the basic surface type that outputs color and wetness values.
In case of vertex surfaces results are outputted as vertex colors.

Wetmap is a black-and-white output that visualizes paint wetness. White being maximum wetness,
black being completely dry. It is usually used as mask for rendering.
Some "paint effects" affect wet paint only.

Dry
Completely disable drying is useful for indefinitely spreading paint.

Color Dry
It can be used to define wetness level when paint colors start to shift to surface "background".
Lower values can be useful to prevent spreading paint from becoming transparent as it dries,
while higher values give better results in general.

Displace
^^^^^^^^

.. figure:: /images/physics_dynamic-paint_canvas_surface-type_displace.jpg
:width: 320px

Displace Surface.

This type of surface outputs intersection depth from brush objects.

.. tip::

If the displace output seems too rough it usually helps to add
a Smooth Modifier after Dynamic Paint in the modifier stack.

Waves
^^^^^

.. figure:: /images/physics_dynamic-paint_canvas_surface-type_waves.jpg
:width: 320px

Waves Surface.

This surface type produces simulated wave motion. Like displace,
wave surface also uses brush intersection depth to define brush strength.

You can use following settings to adjust the motion:

Open Borders
Allows waves to pass through mesh "edges" instead of reflecting from them.
Timescale
Directly adjusts simulation speed without affecting simulation outcome.
Lower values make simulation go slower and otherwise.
Speed
Affects how fast waves travel on the surface.
This setting is also corresponds to the size of the simulation.
Half the speed equals surface double as large.
Damping
Reduces the wave strength over time. Basically adjusts how fast wave disappears.
Spring
Adjusts the force that pulls water back to "zero level".

.. tip::

In some cases the wave motion gets very unstable around brush.
It usually helps to reduce wave speed, brush "wave factor" or even the resolution of mesh/surface.

Weight
^^^^^^

.. figure:: /images/physics_dynamic-paint_canvas_surface-type_weight.jpg
:width: 320px

Weight Surface.

This is a special surface type only available for vertex format.
It outputs vertex weight groups that can be used by other Blender modifiers and tools.

.. tip::

It is usually preferred to use "proximity" based brushes for
weight surfaces to allow smooth falloff between weight values.

Common Options
--------------

For each surface type there are special settings to adjust.
Most types have the settings *Dissolve* and *Brush* :

Dissolve
Used to make the surface smoothly return to its original state during a defined time period.
Brush Group
Used to define a specific object group to pick brush objects from.
Influence Scale, Radius Scale
For tweaking brush settings individually for each surface.

Output Panel
============

.. figure:: /images/physics_dynamic-paint_canvas_output-panel.png

Canvas output panel.

From Output panel you can adjust how surface outputs its results.

Vertex
------

For *Vertex* format surfaces, you can select a mesh data layer
(color / weight depending on surface type) to generate results to.
You can use the "+"/"-" icons to add/remove a data layers of given name.
If layer with given name is not found, it is shown as red.

Image Sequence
--------------

For *Image Sequence* surfaces,
you can define used UV Maps and output file saving directory, filenames and image format.

Initial Color Panel
===================

ToDo.

Effects Panel
=============

.. figure:: /images/physics_dynamic-paint_canvas_effects-panel.png

Canvas effects panel.

This is a special feature for "Paint" type surface.
It generates animated movement on canvas surface.

Effects
Spread
Paint slowly spreads to surrounding points eventually filling all connected areas.
Drip
Paint moves in specific direction specified by Blender force fields,
gravity and velocity with user defined influences.
Shrink
Painted area slowly shrinks until disappears completely.

For spread and drip effects, only "wet paint" is affected, so as the paint dries,
movement becomes slower until it stops.

Cache Panel
===========

.. figure:: /images/physics_dynamic-paint_canvas_cache-panel.png

Canvas cache panel.

This panel is currently only visible for *Vertex* format surfaces.
You can use it to adjust and bake point cache.
.. _dynamic-paint-index:

################
Dynamic Paint
################

.. toctree::
:maxdepth: 2

introduction.rst
brush.rst
canvas.rst
..    TODO/Review: {{review|text=add more examples of possible effects
(also some vid) and move the how-to-activate explanation in a new page}}.

************
Introduction
************

Dynamic paint is a modifier and physics system that can turn objects into paint canvases
and brushes, creating vertex colors, image sequences or displacement.
This makes many effects possible like, for example footsteps in the snow,
raindrops that make the ground wet, paint that sticks to walls, or objects that gradually freeze.

Activating the modifier
=======================

.. figure:: /images/physics_dynamic-paint_introduction.png

How to activate the Dynamic Paint.

Dynamic Paint can be activated from the "Physics" tab of the "Properties" editor.

Types
=====

Modifier itself has two different types:

:doc:`Canvas &lt;/physics/dynamic_paint/canvas&gt;`
Makes object receive paint from Dynamic Paint brushes.

:doc:`Brush &lt;/physics/dynamic_paint/brush&gt;`
Makes object apply paint on the canvas.

.. note::

You can also enable brush and canvas simultaneously.
In that case same object's "brush" does not influence its "canvas",
but can still interact with other objects in the scene.

.. seealso::

- `A step-by step introduction &lt;https://www.miikahweb.com/en/articles/blender-dynamicpaint-basics&gt;`__
- `A detailed guide that covers every setting with images and examples
&lt;https://www.miikahweb.com/en/articles/dynamic-paint-guide&gt;`__ (Currently not up-to-date)
..    TODO/Review: {{review|text=check see-also and external links}}.

**************
Fluid Appendix
**************

Hints
=====

Some useful hints about fluid simulation in Blender:

- Do not be surprised, but you will get whole bunch of mesh (.bobj.gz) files after a simulation.
One set for preview, and another for final.
Each set has a ``.gz`` file for each frame of the animation.
Each file contains the simulation result -- so you will need them.
- Currently these files will not be automatically deleted, so it is a good idea to e.g.
create a dedicated directory to keep simulation results.
Doing a fluid simulation is similar to clicking the *animation* button.
Currently you have to take care of organizing the fluid surface meshes in some directory by yourself.
If you want to stop using the fluid simulation, you can simply delete all the ``*fluid*.bobj.gz`` files.
- Before running a high resolution simulation that might take hours,
check the overall timing first by doing lower resolution runs.
- Fluid objects must be completely inside the bounding box of the domain object.
If not, baking may not work correctly or at all.
Fluid and obstacle objects can be meshes with complex geometries.
Very thin objects might not appear in the simulation,
if the chosen resolution is too coarse to resolve them (increasing it might solve this problem).
- Do not try to do a complicated scene all at once.
Blender has a powerful compositor that you can use to combine multiple animations.

For example, to produce an animation showing two separate fluid flows while keeping your domain small,
render one ``.avi`` using the one flow. Then move the domain and render another ``.avi``
with the other flow using an alpha channel (in a separate B&amp;W .avi?).
Then, composite both ``.avi``\ 's using the compositor's add function.
A third ``.avi`` is usually the smoke and mist and it is laid on top of everything as well.
Add a rain sheet on top of the mist and spray and you will have quite a storm brewing! And then lightning flashes,
trash blowing around, all as separate animations, compositing the total for a truly spectacular result.

Limitations &amp; Workarounds
=========================

- If the setup seems to go wrong, make sure all the normals are correct (hence,
enter *Edit Mode*, select all, and recalculate normals once in a while).
- Currently there is a problem with zero gravity simulation.
It could be avoided by simply selecting a very small gravity until this is fixed.
- If an object is initialized as *Volume*, it has to be closed and have an inner side
(a plane will not work). To use planes, switch to *Shell*, or extrude the plane.
- Blender freezes after clicking *bake*.
Pressing :kbd:`Esc` makes it work again after a while --
this can happen if the resolution is too high and memory is swapped to a drive,
making everything horribly slow. Reducing the resolution should help in this case.
- Blender crashes after clicking *bake* --
this can happen if the resolution is really high and more than 2GB are allocated, causing Blender to crash.
Reducing the resolution should help in this case.
Many operating systems limit the total amount of memory that can be allocated by a *process*,
such as Blender, even if the *machine* has more memory installed.
- The meshes should be closed, so if some parts of e.g.
a fluid object are not initialized as fluid in the simulation,
check that all parts of connected vertices are closed meshes. Unfortunately,
the Suzanne (monkey) mesh in Blender is not a closed mesh (the eyes are separate).
- If the fluid simulation exits with an error message (stating e.g. that the "init has failed"),
make sure you have valid settings for the domain object, e.g. by resetting them to the defaults.
- Note that first frame may well take only a few hundred MBs of RAM memory,
but latter ones go over one GB, which may be why your bake fails after awhile.
If so, try to bake one frame at the middle or end at full res so you will see if it works.
- Memory used doubles when you set surface subdivision from 1 to 2.
- Using "generate particles" will also add memory requirements, as they increase surface area and complexity.
Ordinary fluid simulations generated particles probably eat less memory.
.. _fluid-baking:

******
Baking
******

.. figure:: /images/physics_fluid_baking.jpg

The fluid simulation options with Domain selected.

Bake Button
===========

Perform the actual fluid simulation. Blender will continue to work normally,
except there will be a progress bar in the header of the Info Editor, next to the render pulldown.
Pressing :kbd:`Esc` or the "x" next to the status bar will abort the simulation.
Afterwards two ``.bobj.gz`` (one for the *Final* quality,
one for the *Preview* quality), plus one ``.bvel.gz``
(for the *Final* quality) will be in the selected output directory for each frame.

Bake directory
==============

Directory and file prefix to store baked surface meshes.

This is similar to the animation output settings, only selecting a file is a bit special:
when you select any of the previously generated surface meshes
(e.g. ``test1_fluidsurface_final_0132.bobj.gz``),
the prefix will be automatically set (``test1_`` in this example).
This way the simulation can be done several times with different settings,
and allows quick changes between the different sets of surface data.

Notes
=====

Unique domain
Because of the possibility of spanning and linking between scenes,
there can only be one domain in an entire blend-file.

Selecting a Baked Domain
After a domain has been baked, it changes to the fluid mesh.
To re-select the domain so that you can bake it again after you have made changes,
go to any frame and select :kbd:`RMB` the fluid mesh.
Then you can click the *bake* button again to recompute the fluid flows inside that domain.

Baking always starts at Frame #1
The fluid simulator disregards the *Start* setting in the *Animation* panel,
it will always bake from frame 1. If you wish the simulation to start later than frame 1,
you must key the fluid objects in your domain to be inactive until the frame you desire to start the simulation.

Baking always ends at the *End* Frame set in the *Animation* panel
If your frame-rate is 25 frames per second,
and ending time is 4.0 seconds, then you should (if your start time is 0)
set your animation to end at frame ``4.0 × 25 = 100``

Freeing the previous baked solutions
Deleting the content of the "Bake" directory is a destructive way to achieve this.
Be careful if more than one simulation uses the same bake directory
(be sure they use different filenames, or they will overwrite one another)!

Reusing Bakes
Manually entering (or searching for) a previously saved (baked)
computational directory and filename mask will switch the fluid
flow and mesh deformation to use that which existed during the old bake.
Thus, you can re-use baked flows by simply pointing to them in this field.

Baking processing time
Baking takes a **lot** of compute power (hence time).
Depending on the scene, it might be preferable to bake overnight.

If the mesh has modifiers, the rendering settings are used for exporting the mesh to the fluid solver.
Depending on the setting, calculation times and memory use might exponentially increase.
For example, when using a moving mesh with *Subdivision Surface* as an obstacle,
it might help to decrease simulation time by switching it off, or to a low subdivision level.
When the setup/rig is correct, you can always increase settings to yield a more realistic result.

.. ===="St"/"Ad"/"Bn"/"Par" Buttons====
Till now, we were in the |Standard buttons.
Clicking another one of these buttons will show other "panels" (groups of controls:
Advanced, ``Bn`` for boundary, and Particle)
of more advanced options, that often are fine set at the defaults.

Standard
The settings in this set are already been described above...

Advanced
Gravity vector
Strength and direction of the gravity acceleration and any lateral (x,y plane) force.
The main component should be along the negative z-axis (in ``m.s&lt;sup&gt;-2&lt;/sup&gt;``).

.. note::

All of the x,y,z values should not be zero, or the fluid will not flow!
Imagine a droplet floating in the nothingness of deep space...
It must be some small number in at least one direction.

.. _fluid-simulation-index:

###################
Fluid Simulation
###################

.. toctree::
:maxdepth: 2

introduction.rst
types/index.rst
baking.rst
appendix.rst

************
Introduction
************

Fluid physics are used to simulate physical properties of liquids especially water.
While creating a scene in Blender, certain objects can be marked to participate in the fluid simulation.
These can include but not limited to, being a fluid or as an obstacle.
For a fluid simulation you have to have a domain to define the space that the simulation takes up.
In the domain settings you will be able to define the global simulation parameters (such as viscosity and gravity).

.. figure:: /images/physics_fluid_introduction_example.jpg

Example of Fluid Simulation.

Workflow
========

In general, you follow these steps:

#. First you want to set the
:doc:`simulation domain &lt;/physics/fluid/types/domain&gt;`,
#. Next set the
:doc:`fluid source(s) &lt;/physics/fluid/types/fluid_object&gt;`, and specify there physical properties.
#. In some cases you may want to set other objects to
:doc:`Control the Flow &lt;/physics/fluid/types/flow&gt;` of the fluid.
#. You can also depending on your scene add other objects related to the fluid, like:
:doc:`Obstacles &lt;/physics/fluid/types/obstacle&gt;`,
:doc:`Particles &lt;/physics/fluid/types/particle&gt;` floating on the fluid.
#. And lastly you must
:doc:`Bake the Simulation &lt;/physics/fluid/types/domain&gt;`.

.. tip:: Baking is done on the Domain object!

When you calculate the fluid simulation, you bake the simulation on the domain object.

For this reason:

- All the baking options are visible only when selecting the Domain Object,
- Baking options are explained in the :ref:`the baking section &lt;fluid-baking&gt;` of the Domain manual page.

.. seealso::

To know more about simulating fluids in Blender you can read the
:doc:`fluids appendix &lt;/physics/fluid/appendix&gt;`.
There you can find the limitations and workarounds, and some additional links.
..    TODO/Review: {{review}}.

*************
Fluid Control
*************

Using the Lattice-boltzman method, the fluid is controlled using particles which define local
force fields and are generated automatically from either a physical simulation or a sequence
of target shapes. At the same time, as much as possible of the natural fluid motion is preserved.

.. only:: builder_html and (not singlehtml)

.. youtube:: WruTNnF6Ztg

.. only:: not builder_html and (singlehtml)

A video can be found at https://www.youtube.com/watch?v=WruTNnF6Ztg

Options
=======

.. figure:: /images/physics_fluid_types_control.jpg

Fluid control options.

Enabled
Controls weather the control object contributes to the fluid system.
This is useful when animating the fluid control object.
Quality
Higher quality result in more control particles for the fluid control object.
Reverse Frames
Reverses the control object's movement.
Time
You specify the time interval (start and end time) during which the fluid control object is active.
Attraction Force
Specifies the force which gets emitted by the fluid control object.

Strength
The strength of the force.
Positive force results in attraction of the fluid, negative force in avoidance.
Velocity Force
If the fluid control object moves, the resulting velocity can also introduce a force to the fluid.

Strength
The strength of the effect.
Radius
The radius of the force.

Examples
========

In these examples,
the Fluid Control is used to control part of the fluid so that it has a certain shape
(the sphere drop or the teapot drop) before it falls in the rest of the fluid:

.. figure:: /images/physics_fluid_types_control_example1.jpg

Falling drop.

.. figure:: /images/physics_fluid_types_control_example2.jpg

"Magic Fluid Control."
..    TODO/Review: {{review|text=todo: review the viscosity table commented text}}.

************
Fluid Domain
************

The Domain Object
=================

The bounding box of the object serves as the boundary of the simulation.
All fluid objects **must** be in the domain. Fluid objects outside the domain will not bake.
No tiny droplets can move outside this domain;
it's as if the fluid is contained within the 3D space by invisible force fields.
There can be only a single fluid simulation domain object in the scene.

The shape of the object does **not** matter because it will *always* be treated like a box
(The lengths of the bounding box sides can be different).
So, usually there will not be any reason to use another shape than a box.
If you need obstacles or other boundaries than a box to interfere with the fluid flow,
you need to insert additional obstacle objects *inside* the domain boundary.

This object will be *replaced* by the fluid during the simulation.

.. tip:: Baking is done on the Domain object

When you calculate the fluid simulation, you bake the simulation on the domain object.
For this reason all the baking options are visible only when selecting the Domain Object.

For baking options, see :doc:`Baking &lt;/physics/fluid/baking&gt;`.

Options
-------

.. figure:: /images/physics_fluid_types_domain.jpg

Fluid Domain Settings.

Bake button
For baking options, see :doc:`Baking &lt;/physics/fluid/baking&gt;`.
Resolution
Render resolution
The granularity at which the actual fluid simulation is performed.
This is probably the most important setting for the simulation as it
determines the amount of details in the fluid, the memory and disk usage as well as computational time.

.. list-table::

* - .. figure:: /images/physics_fluid_types_domain_resolution_low.jpg

10cm mug at Resolution 70.

- .. figure:: /images/physics_fluid_types_domain_resolution_high.jpg

10cm mug at Resolution 200.

.. note::

The amount of required memory quickly increases: a resolution of 32 requires ca. 4MB,
64 requires ca. 30MB, while 128 already needs more than 230MB. Make sure to set the resolution low enough,
depending on how much memory you have, to prevent Blender from crashing or freezing. Remember also that many
operating systems limit the amount of memory that can be allocated by a single *process*, such as Blender,
even if the *machine* contains much more than this. Find out what limitations apply to your machine.

.. note:: Resolution and Real-size of the Domain

Be sure to set the resolution appropriate to the real-world size of the domain
(see the *Real World Size* in the `Fluid World`_).
If the domain is not cubic, the resolution will be taken for the longest side.
The resolutions along the other sides will be reduced according to their lengths
(therefore, a non-cubic domain will need less memory than a cubic one, resolutions being the same).

Preview resolution
This is the resolution at which the preview surface meshes will be generated.
So it does not influence the actual simulation.
Even if "there is nothing to see" in the preview,
there might be a thin fluid surface that cannot be resolved in the preview.

Display quality
How to display a baked simulation in the 3D View (menu *Viewport Display*)
and for rendering (menu *Render Display*):

Geometry
Use the original geometry (before simulation).
Preview
Use the preview mesh.
Final
Use the final high definition mesh.

When no baked data is found, the original mesh will be displayed by default.

After you have baked a domain, it is displayed (usually) in the Blender window as the preview mesh.
To see the size and scope of the original domain box, select *Geometry* in the left selector.

Time
Start
It is the simulation start time (in seconds).

This option makes the simulation computation in Blender start later in the simulation.
The domain deformations and fluid flow prior to the start time are not saved.

For example, if you wanted the fluid to appear to already have been flowing
for 4 seconds before the actual first frame of data, you would enter 4.0 here.
End
It is the simulation ending time (in seconds).

.. tip:: Start and end times have nothing to do with how many frames are baked

If you set *Start* time to 3.0, and *End* time to 4.0, you will simulate 1 second of fluid motion.
That one second of fluid motion will be spread across however-many frames are set in
:menuselection:`Render --&gt; Dimensions`.

This means, for example, that if you have Blender set to make 250 frames at 25 fps, the fluid
will look like it had already been flowing for 3 seconds at the start of the simulation,
*but* will play in slow motion (one-tenth normal speed),
since the 1 second fluid simulation plays out over the course of 10 video seconds.
To correct this, change the end time to 13.0 (3.0 + 10.0) to match the 250 frames at 25 fps.
Now, the simulation will be real-time,
since you set 10 seconds of fluid motion to simulate over 10 seconds of animation.
Having these controls in effect gives you a "speed control" over the simulation.

Generate Speed Vectors
If this button is clicked, no speed vectors will be exported.
So by default, speed vectors are generated and stored on disk.
They can be used to compute image based motion blur with the compositing nodes.
Reverse Frames
The simulation is calculated backward.
Speed
Fluid motion rate. The speed option can be animated to slow down or speed up time.
Offset
Time offset when reading backed cache.
Bake Directory
For baking options see :doc:`Baking &lt;/physics/fluid/baking&gt;`.

Fluid World
===========

.. figure:: /images/physics_fluid_types_domain_world.jpg

The Fluid World panel.

Viscosity Presets
The "thickness" of the fluid and actually the force needed to move an object of a certain surface area through it
at a certain speed.

For manual entry, please note that the normal real-world viscosity (the so-called dynamic viscosity)
is measured in Pascal-seconds (Pa.s), or in Poise units (P, equal to 0.1 Pa.s, pronounced *pwaz*,
from the Frenchman Jean-Louis Poiseuille, who discovered the laws on "the laminar flow of viscous fluids"),
and commonly centiPoise units (cP, equal to 0.001 Pa.s, *sentipwaz*).
Blender, on the other hand, uses the kinematic viscosity
(which is dynamic viscosity in Pa.s, divided by the density in kg.m\ :sup:`-3`\, unit m\ :sup:`2`\.s\ :sup:`-1`\).
The table below gives some examples of fluids together with their dynamic and kinematic viscosities.

.. list-table::
Blender Viscosity Unit Conversion.
:header-rows: 1

* - Fluid
- dynamic viscosity (in cP)
- kinematic viscosity (Blender, in m\ :sup:`2`\.s\ :sup:`-1`\)
* - Water (20- C)
- 1.002×10\ :sup:`0` (1.002)
- 1.002×10\ :sup:`-6` (0.000001002)
* - Oil SAE 50
- 5.0×10\ :sup:`2` (500)
- 5.0×10\ :sup:`-5` (0.00005)
* - Honey (20- C)
- 1.0×10\ :sup:`4` (10,000)
- 2.0×10\ :sup:`-3` (0.002)
* - Chocolate Syrup
- 3.0×10\ :sup:`4` (30,000)
- 3.0×10\ :sup:`-3` (0.003)
* - Ketchup
- 1.0×10\ :sup:`5` (100,000)
- 1.0×10\ :sup:`-1` (0.1)
* - Melting Glass
- 1.0×10\ :sup:`15`
- 1.0×10\ :sup:`0` (1.0)

Manual entries are specified by a floating point number and an exponent.
These floating point and exponent entry fields (scientific notation)
simplify entering very small or large numbers. The viscosity of water at room temperature is 1.002 cP,
ou 0.001002 Pa.s; the density of water is about 1000 kg.m\ :sup:`-3`\, which gives a kinematic viscosity of
0.000001002 m\ :sup:`2`\.s\ :sup:`-1` -- so the entry would be 1.002 times 10 to the minus six
(1.002×10\ :sup:`-6` in scientific notation). Hot Glass and melting iron is a fluid, but very thick;
you should enter something like 1.0×10\ :sup:`0` (= 1.0) as its kinematic viscosity
(indicating a value of 1.0×10\ :sup:`6`\ cP).

Note that the simulator is not suitable for non-fluids, such as materials that do not "flow".
Simply setting the viscosity to very large values will not result in rigid body behavior,
but might cause instabilities.

.. note:: Viscosity varies

The default values in Blender are considered typical for those types of fluids and "look right" when animated.
However, actual viscosity of some fluids,
especially sugar-laden fluids like chocolate syrup and honey, depend highly on temperature and concentration.
Oil viscosity varies by SAE rating.
Glass at room temperature is basically a solid, but glass at 1500 degrees Celsius flows (nearly) like water.

..
There's still some things that are not correct in this table, I think.
Let me put as clear as I can:
*The dynamic viscosity international unit is the Pascal-seconds (Pa.s).
There are also Poise (P = 0.1 Pa.s), and centiPoise (cP = 0.001 Pa.s).
*The kinematic viscosity international unit is in m^2.s^-1.
*The density international unit is in kg.m^-3.
Which implies that a Pascal corresponds to 1 kg.m^-1.s^-2,
or else you cannot divide Pa.s by kg.m^-3 to obtain m^2.s^-1 !
::
So if I take the kinematics values given bellow,
and try to get the corresponding dynamic values, I have:
*water: density: about 1000 (kg.m^-3); kinematic viscosity: 1×10^-6 (m^2.s^-1)
--&gt; dynamic viscosity is 1000 × 1×10^-6 = 1×10^-3 Pa.s, hence 1 cP.
--&gt; COHERENT
*Oil:   density: more or less like water, so about 1000; Kinematic viscosity: 5×10^-5
--&gt; dynamic viscosity is 1000 × 5×10^-5 = 1×10^-2 Pa.s, hence 50 cP, and not 500 cP
--&gt; NOT COHERENT, unless Oil SAE 50 is ten times heavier than water!
*Honey: density: about 1250 (kg.m^-3); kinematic viscosity: 2×10^-3
--&gt; dynamic viscosity is 1250 × 2×10^-3 = 2.5 Pa.s, hence 2500 cP, and not 1×10^4 cP
--&gt; NOT COHERENT, unless honey is five times heavier than water!
*And so on, chocolate syrup density should be of 1×10^4 kg.m^-3 (ten times water density),
ketchup density should be of 1×10^3 kg.m^-3 (same as water density, coherent I think),
melting glass density should be of 1×10^12 kg.m^-3 (a thousand million times water density,
it's more like black hole!)
::
So, either the values in the tables are wrong (one way or the other),
or the law to pass from dynamic viscosity to kinematic viscosity is just a "trick",
an approximation, only working with fluids around water viscosity...
::
Do not know, I am not a physicist, but there definitively something wrong here,
so if someone who knows better about this matter could check and correct it, it would be nice!
--Mont29, 2009/08

Real World Size
Size of the domain object in the real world in meters.
If you want to create a mug of coffee, this might be 10 cm (0.1 meters), while a swimming pool might be 10m.
The size set here is for the longest side of the domain bounding box.

Optimization
Grid Levels
How many adaptive grid levels to be used during simulation.
Setting this to -1 will perform automatic selection.
Compressibility
If you have problems with large standing fluid regions at high resolution,
it might help to reduce this number (note that this will increase computation times).

Fluid Boundary
==============

.. figure:: /images/physics_fluids_types_domain_boundary_panel.jpg
:width: 300px

The Fluid Boundary panel.

This box has all the slip and surface options.

Slip Type
The stickiness of the surface of the obstacle,
to determine the "tacky surface (Surface Adhesion)."
In the real world, and the tackiness and fluid,
the granularity of the object surface, tack, determined by the elasticity.

No Slip
Fluid will stick to snugly (speed 0).
Free Slip
Fluid will move on the object (0 normal direction of speed).
Part Slip
It is a two intermediate. It is almost *No slip*, 1 in the *Free* exactly the same in 0.
Amount
ToDo.
Remove Air Bubbles
Enable the possibility to remove the "air bubble" around submerged collision object.
Surface
Surface Smoothing
Amount of smoothing to be applied to the fluid surface.
1.0 is standard, 0 is off, while larger values increase the amount of smoothing.

Subdivisions
Allows the creation of high-res surface meshes directly during the simulation
(as opposed to doing it afterwards like a Subdivision Surface Modifier).
A value of 1 means no subdivision, and each increase results in one further subdivision of each fluid voxel.
The resulting meshes thus quickly become large, and can require large amounts of disk space.
Be careful in combination with large smoothing values --
this can lead to long computation times due to the surface mesh generation.

Fluid Particles
===============

.. figure:: /images/physics_fluids_types_domain_particles.png

The Fluid Particles panel.

Here you can add particles to the fluid simulated, to enhance the visual effect.

Tracer Particles
Number of tracer particles to be put into the fluid at the beginning of the simulation.
To display them create another object with the *Particle* fluid type,
explained below, that uses the same bake directory as the domain.

Generate Particles
Controls the amount of fluid particles to create (0=off, 1=normal, &gt;1=more).
To use it, you have to have a surface subdivision value of at least 2.

.. figure:: /images/physics_fluid_types_domain_particals.jpg

An example of Particles effects.

Left: Simulated without; Right: With particles and subdivision enabled.

**********************
Fluid Inflow / Outflow
**********************

To control the volume of the fluid simulation,
you can set objects in the scene to add or absorb fluid within the :doc:`Fluid Domain &lt;/physics/fluid/types/domain&gt;`.

Inflow
======

.. figure:: /images/physics_fluid_types_inflow.jpg

Fluid Inflow Settings.

Volume Initialization Type
See :ref:`Volume Initialization Type &lt;fluid-initialization&gt;`

This object will put fluid into the simulation, like a water tap.

Inflow Velocity
Speed of the fluid that is created inside of the object.

Local Coordinates/Enable
Use local coordinates for the inflow.
This is useful if the inflow object is moving or rotating, as the inflow stream will
follow/copy that motion. If disabled, the inflow location and direction do not change.

Animated Mesh/Export
See :ref:`Animated Mesh/Export &lt;fluid-animated-mesh&gt;`

Outflow
=======

.. figure:: /images/physics_fluid_types_outflow.jpg

Fluid Outflow Settings.

Any fluid that enters the region of this object will be deleted (think of a drain or a black hole).
This can be useful in combination with an inflow to prevent the whole domain from filling up.
When enabled, this is like a tornado (waterspout) or "wet vac" vacuum cleaner,
and the part where the fluid disappears will follow the object as it moves around.

Volume Initialization Type
See :ref:`Volume Initialization Type &lt;fluid-initialization&gt;`

Animated Mesh/Export
See :ref:`Animated Mesh/Export &lt;fluid-animated-mesh&gt;`

************
Fluid Object
************

.. figure:: /images/physics_fluid_types_fluid.jpg
:width: 300px

Fluid object settings.

All regions of this object that are inside the domain bounding box will be used as actual
fluid in the simulation. If you place more than one fluid object inside the domain,
they should currently not intersect. Also make sure the surface normals are pointing outwards.
In contrast to domain objects, the actual mesh geometry is used for fluid objects.

Options
=======

Volume Initialization Type
See :ref:`Volume Initialization Type &lt;fluid-initialization&gt;`

Animated Mesh/Export
See :ref:`Animated Mesh/Export &lt;fluid-animated-mesh&gt;`

Initial velocity
Speed of the fluid at the beginning of the simulation, in meters per second.

.. tip:: The direction of Surface Normals makes a big difference!

Blender uses the orientation of the Surface Normals to determine what is "inside of" the Fluid object and what is
"outside". You want all of the normals to face *outside* (in *Edit Mode*, use :kbd:`Ctrl-N` or press
:kbd:`Spacebar` and choose :menuselection:`Edit --&gt; Normals --&gt; Calculate Outside`).
If the normals face the wrong way, you will be rewarded with a "gigantic flood of water" because Blender will think
that the volume of the object is outside of its mesh! This applies regardless of the *Volume init* type
setting.

.. _fluid-simulation-types-index:

##############
Fluid Types
##############

.. toctree::
:maxdepth: 2

introduction.rst
domain.rst
fluid_object.rst
obstacle.rst
flow.rst
particle.rst
control.rst

************
Introduction
************

Common Options
==============

.. _fluid-animated-mesh:

Animated Mesh/Export
--------------------

Click this button if the network is animated (eg . Deformed by an armature, shape keys, or lattice).
It can become very slow and is not necessary if the network's position and rotation are animated.
(i.e. only object transformations).

.. _fluid-initialization:

Volume Initialization Type
--------------------------

A common option among the different fluid types is *Volume Initialization*.

Volume
The inside of the object is initialized as fluid all. This works only if the mesh is closed.
Shell
It is initialized as a thin fluid layer of the surface of the mesh. This can also be used if the mesh is open.
Both
It is a state, such as the sum of the Volume and Shell. This also must be a closed mesh.

.. figure:: /images/physics_fluid_types_introduction_initialization.jpg

Example of different types of initiation of volume.
..    TODO/Review: {{review}}.

**************
Fluid Obstacle
**************

This object will be used as an obstacle in the simulation. As with a fluid object,
obstacle objects currently should not intersect. As for fluid objects,
the actual mesh geometry is used for obstacles. For objects with a volume,
make sure that the normals of the obstacle are calculated correctly,
and radiating properly (use the *Flip Normal* button, in *Edit Mode*,
*Mesh Tools* panel, in the Tool shelf), particularly when using a spinned container.
Applying a :doc:`Subdivision Surface Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`
before baking the simulation could also be a good idea if the mesh is not animated.

Options
=======

Volume Initialization Type
See :ref:`Volume Initialization Type &lt;fluid-initialization&gt;`

Boundary type
Determines the stickiness of the obstacle surface, called "Surface Adhesion".
Surface Adhesion depends in real-world on the fluid and the graininess or
friction/adhesion/absorption qualities of the surface.

No Slip
Causes the fluid to stick to the obstacle (zero velocity).
Free Slip
Allows movement along the obstacle (only zero normal velocity).
Part Slip
Mixes both types, with 0 being mostly no slip, and 1 being identical to free slip.

Note that if the mesh is moving, it will be treated as no slip automatically.

.. figure:: /images/physics_fluid_types_obstacle_bndtcomp.jpg

Example of the different boundary types for a drop falling onto the slanted wall.
From left to right: no-slip, part-slip 0.3, part-slip 0.7 and free-slip.

Animated Mesh/Export
See :ref:`Animated Mesh/Export &lt;fluid-animated-mesh&gt;`

Part Slip Amount
Amount of mixing between no- and free-slip, described above.

Impact Factor
Amount of fluid volume correction for gain/loss from impacting with moving objects.
If this object is not moving, this setting has no effect.
However, if it is and the fluid collides with it, a negative value takes volume away from the Domain,
and a positive number adds to it. Ranges from -2.0 to 10.0.
..    TODO/Review: {{review}}.

**************
Fluid Particle
**************

.. figure:: /images/physics_fluid_types_partical.jpg
:width: 300px

Fluid particle settings.

This type can be used to display particles created during the simulation.
For now only tracers swimming along with the fluid are supported.

Note that the object can have any shape, position or type.
Once the particle button is pressed, a particle system with the fluid
simulation particles will be created for it at the correct position.
When moving the original object, it might be necessary to delete the particle system,
disable the fluidsim particles, and enable them again.
The fluidsim particles are currently also unaffected by any other particle forces or settings.

Options
=======

Influence
Size Influence
The particles can have different sizes, if this value is 0 all are forced to be the same size.

Alpha Influence
If this value is &gt;0, the alpha values of the particles are changed according to their size.

Particle type
Drops
Surface splashes of the fluid result in droplets being strewn about, like fresh water,
with low Surface Tension.

Floats
The surface tension of the fluid is higher and the fluid heavier, like cold seawater and soup.
Breakaways are clumpier and fall back to the surface faster than *Drops*, as with high Surface Tension.

Tracer
Droplets follow the surface of the water where it existed, like a fog suspended above previous fluid levels.
Use this to see where the fluid level has been.

Path (bake directory)
The simulation run from which to load the particles.
This should usually have the same value as the fluid domain object (e.g. copy by :kbd:`Ctrl-C`, :kbd:`Ctrl-V`).
.. _physics-force-fields-index:

###############
Force Fields
###############

.. toctree::
:maxdepth: 2

introduction.rst

Types
=====

.. toctree::
:maxdepth: 1

types/force.rst
types/wind.rst
types/vortex.rst
types/magnetic.rst
types/harmonic.rst
types/charge.rst
types/lennard_jones.rst
types/texture.rst
types/curve_guide.rst
types/boid.rst
types/turbulence.rst
types/drag.rst
types/smoke_flow.rst

************
Introduction
************

Force Fields offer a way to add extra movement to dynamic systems.
:doc:`Particles &lt;/physics/particles/index&gt;`, :doc:`Soft Bodies &lt;/physics/soft_body/index&gt;`,
`Rigid Bodies &lt;/physics/rigid_body/index&gt;`, and :doc:`Cloth objects &lt;/physics/cloth/index&gt;`
can all be affected by forces fields.
Force Fields automatically affect everything.
To remove a simulation or particle system from their influence,
simply turn down the influence of that type of Force Field in its Field Weights panel.

- All types of objects and particles can generate fields,
but only curve object can bear *Curve Guides* fields.
- Force Fields can also be generated from particles.
See :doc:`Particle Physics &lt;/physics/particles/emitter/physics/index&gt;`
- The objects need to share at least one common layer to have effect.

You may limit the effect on particles to a group of objects
(see the :doc:`Particle Physics &lt;/physics/particles/emitter/physics/index&gt;` page).

.. list-table:: Force field types

* - .. figure:: /images/physics_force-field_types_empty.png

- .. figure:: /images/physics_force-field_types_vortex_visualzation.png

* - .. figure:: /images/physics_force-field_types_wind_visualzation.png

- .. figure:: /images/physics_force-field_types_force_visualzation.png

.. Force, Wind, Vortex, Magnetic, Harmonic, Charge, Lennard Jones,
Texture, Curve Guide, Boid, Turbulence, Drag, and Smoke Flow.

Creating a Force Field
======================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Physics --&gt; Fields`

To create a single Force Field,
you can select :menuselection:`Add --&gt; Force Field` and select the desired force field.
This method creates an Empty with the force field attached.

To create a field from an existing object you have to select the object and change to the
*Physics* tab. Select the field type in the *Fields* menu.

The fields have many options in common,
these common options are explained for the *Spherical* field.

.. note::

After changing the fields *Fields* panel or deflection
*Collision* panel settings, you have to recalculate the particle,
softbody or cloth system by *Free Cache*, this is not done automatically. You can
clear the cache for all selected objects with :kbd:`Ctrl-B` :menuselection:`--&gt; Free cache selected`.

Particles react to all kind of *Force Fields*,
Soft Bodies only to *Spherical*, *Wind*, *Vortex*
(they react on *Harmonic* fields but not in a useful way).

Common Field Settings
=====================

Most Fields have the same settings, even though they act very differently.
Settings unique to a field type are described below.
Curve Guide and Texture Fields have very different options.

Shape
The field is either a:

Point
Point with omni-directional influence.
Plane
Constant in the XY-plane, changes only in Z direction.
Surface
ToDo.
Every Point
ToDo.
Strength
The strength of the field effect.
This can be positive or negative to change the direction that the force operates in.
A force field's strength is scaled with the force object's scale,
allowing you to scale up and down scene, keeping the same effects.
Flow
Convert effector force into air flow velocity.
Noise
Adds noise to the strength of the force.
Seed
Changes the seed of the random noise.
Effect Point
You can toggle the field's effect on particle *Location* and *Rotation*.

Collision Absorption
Force gets absorbed by collision objects.

Falloff
-------

Here you can specify the shape of the force field
(if the *Fall-off* Power is greater than 0).

Falloff Type
Sphere
Falloff is uniform in all directions, as in a sphere.
Tube
Fall off results in a tube shaped force field.
The Field's *Radial falloff* can be adjusted,
as well as the *Minimum* and *Maximum* distances of the field.
Cone
Fall off results in a cone shaped force field. Additional options are the same as those of *Tube* options.

Z Direction
*Fall-off* can be set to apply only in the direction of the positive Z Axis, negative Z Axis, or both.
Power (Power)
How the power of the force field changes with the distance from the force field.
If *r* is the distance from the center of the object, the force changes with 1/ *r*\ :sup:`power`\.
A *Fall-off* of 2 changes the force field with 1/ *r*\ :sup:`2`\,
which is the falloff of gravitational pull.

Max Distance
Makes the force field only take effect within a specified maximum radius
(shown by an additional circle around the object).
Min Distance
The distance from the object center, up to where the force field is effective with full strength.
If you have a *Fall-off* of 0 this parameter does nothing,
because the field is effective with full strength up to *Max Distance* (or the infinity).
Shown by an additional circle around the object.

****
Boid
****

.. figure:: /images/physics_force-field_types_empty.png

Boid force field.

Boid probably comes from theoretical works. *Boids* is an artificial life program,
developed by Craig Reynolds in 1986, which simulates the flocking behavior of birds.
His paper on this topic was published in 1987 in the proceedings of the ACM SIGGRAPH conference.
The name refers to a "bird-like object",
but its pronunciation evokes that of "bird" in a stereotypical New York accent.
As with most artificial life simulations, Boids is an example of emergent behavior; that is,
the complexity of Boids arises from the interaction of individual agents (the boids,
in this case) adhering to a set of simple rules.

.. figure:: /images/physics_force-field_types_boid.jpg

UI for a Boid force field.

The rules applied in the simplest Boids world are as follows:

- Separation: steer to avoid crowding local flock mates
- Alignment: steer towards the average heading of local flock mates
- Cohesion: steer to move toward the average position (center of mass) of local flock mates

More complex rules can be added, such as obstacle avoidance and goal seeking.

******
Charge
******

.. figure:: /images/physics_force-field_types_empty.png

Charge force field.

A *Charge* force field is similar to spherical field except it changes behavior (attract/repulse)
based on the effected particles charge field (negative/positive),
like real particles with a charge.
This mean this field has only effect on particles that have also a *Charge* field
(else, they have no "charge", and hence are unaffected)!

.. figure:: /images/physics_force-field_types_charge.jpg

UI for a Charge force field.

.. vimeo:: 182770166

***********
Curve Guide
***********

.. figure:: /images/physics_force-fields_types_curve_example.png

Curve Guide force field.

The *Curve Guide* is used to force particles to follow a certain
path defined by a :doc:`Curve Object &lt;/modeling/curves/index&gt;`.
A typical scenario would be to move a red blood cell inside a vein,
or to animate the particle flow in a motor.
You can also use *Curve Guide* to shape certain hair strands.

.. note::

You can also use the :doc:`Particle Edit Mode &lt;/physics/particles/mode&gt;` to define a path.

Since you can animate curves as Softbody or any other usual way,
you may build very complex animations while keeping great control and keeping the simulation time to a minimum.

The option *Curve Follow* does not work for particles. Instead you have to set *Angular Velocity*
(*Particle system* tab) to *Spin* and leave the rotation constant (i.e. do not turn on *Dynamic*).

*Curve Guide* s affect all particles on the same layer, independently from their distance to the curve.
If you have several guides in a layer,
their fields add up to each other (the way you may have learned it in your physics course).
But you can limit their influence radius by changing there *Minimum Distance* (see below).

.. note::

The Curve Guide does not affect :doc:`Softbodies &lt;/physics/soft_body/index&gt;`.

Options
=======

.. figure:: /images/physics_force-field_types_curve-guide.jpg
:width: 400px

UI for a Curve Guide force field.

Minimum Distance
The distance from the curve, up to where the force field is effective with full strength.
If you have a *Fall-off* of 0 this parameter does nothing,
because the field is effective with full strength up to *Max Distance* (or the infinity).
*Min Distance* is shown with a circle at the endpoints of the curve in the 3D View.

Free
Fraction of particle life time, that is not used for the curve.

Fall-off
This setting governs the strength of the guide between *Min Distance* and *Max Distance*.
A *Fall-off* of 1 means a linear progression.

Path
-----

A particle follows a *Curve Guide* during its lifetime,
the velocity depends on its lifetime and the length of the path.

Additive
If you use *Additive*, the speed of the particles is also evaluated depending on the *Fall-off*.
Weights
Use Curve weights to influence the particle influence along the curve.
Maximum Distance / Use Max
The maximum influence radius. Shown by an additional circle around the curve object.

Clumping
--------

The other settings govern the form of the force field along the curve.

Clumping Amount
The particles come together at the end of the curve (1) or they drift apart (-1).
Shape
Defines the form in which the particles come together.
+0.99: the particles meet at the end of the curve.
0: linear progression along the curve. -0.99: the particles meet at the beginning of the curve.

Kink
----

Changes the shape that the particles can take:

Type
Curl
The radius of the influence depends on the distance of the curve to the emitter.
Radial
A three dimensional, standing wave.
Wave
A two dimensional, standing wave.
Braid
Braid.
Roll
An one dimensional, standing wave.

It is not so easy to describe the resulting shapes, so have a look at the example below.

.. figure:: /images/physics_force-field_types_curve-guide_kink.jpg
:width: 400px

Kink options of a curve guide. From left to right: Radial, Wave, Braid, Roll.
`Animation &lt;https://vimeo.com/1866538&gt;`__.

Axis
ToDo.
Frequency
The frequency of the offset.
Amplitude
The Amplitude of the offset.
Shape
Adjust the offset to the beginning/end.

Example
=======

.. vimeo:: 182780872

****
Drag
****

.. figure:: /images/physics_force-field_types_empty.png

Drag force field.

A *Drag* force field resists particle motion by slowing it down.

Options
=======

.. figure:: /images/physics_force-field_types_drag.jpg

UI for a Drag force field.

Linear
Drag component proportional to velocity.
Quadratic
Drag component proportional to the square of the velocity.

*****
Force
*****

.. figure:: /images/physics_force-field_types_force_visualzation.png

Force force field.

The *Force* field is the simplest of the fields. It gives a constant force towards
(positive strength) or away from (negative strength) the object's center.
Newtonian particles are attracted to a field with negative strength,
and are blown away from a field with positive strength.

.. figure:: /images/physics_force-field_types_force.jpg

UI for a Force force field.

For :doc:`Boids Particles &lt;/physics/particles/emitter/physics/index&gt;`
a field with positive strength can be used as a *Goal*,
a field with negative strength can be used as *Predator*.
Whether *Boids* seek or fly goals/predators depends on the *Physics* settings of the Boids.

.. vimeo:: 173807488

********
Harmonic
********

.. figure:: /images/physics_force-field_types_empty.png

Harmonic force field.

In a *Harmonic* force field,
the source of the force field is the zero point of a harmonic oscillator (spring, pendulum).
If you set the *Damping* parameter to 1,
the movement is stopped in the moment the object is reached.
This force field is really special if you assign it to particles.

Options
=======

.. figure:: /images/physics_force-field_types_harmonic.jpg

UI for a Harmonic force field.

Rest Length
Controls the rest length of the harmonic force.
Multiple Springs
Causes every point to be affected by multiple springs.

Normally every particle of the field system influences every particle of the target system.
Not with *Harmonic* ! Here every target particle is assigned to a field particle.
So particles will move to the place of other particles, thus forming shapes.

Example
=======

Tutorial: `Particles forming Shapes
&lt;https://en.wikibooks.org/wiki/Blender_3D:_Noob_to_Pro/Particles_forming_Shapes&gt;`__.

.. vimeo:: 173822500

*************
Lennard Jones
*************

.. figure:: /images/physics_force-field_types_empty.png

Lennard Jones force field.

The *Lennard Jones* force field is a very short range force with a behavior determined by the sizes of the effector
and effected particle. At a distance smaller than the combined sizes the field is very
repulsive and after that distance it is attractive.
It tries to keep the particles at an equilibrium distance from each other.
Particles need to be at a close proximity to each other to be effected by this field at all.

Particles can have for example both a charge and a Lennard-Jones potential,
which is probably something for the nuclear physicists amongst us.

.. figure:: /images/physics_force-field_types_lennard-jones.jpg

UI for a Lennard Jones force field.

.. vimeo:: 182775330

********
Magnetic
********

.. figure:: /images/physics_force-field_types_empty.png

Magnetic force field.

This field depends on the speed of the particles.
It simulates the force of magnetism on magnetized objects.

.. figure:: /images/physics_force-field_types_harmonic.jpg

UI for a Magnetic force field.

.. vimeo:: 173818957

**********
Smoke Flow
**********

.. figure:: /images/physics_force-field_types_empty.png

Smoke Flow force field.

Will make particles follow the smoke.

.. figure:: /images/physics_force-field_types_smokeflow.jpg

UI for a Smoke Flow force field.

*******
Texture
*******

.. figure:: /images/physics_force-field_types_empty.png

Texture force field.

You can use a *Texture* force field to create an arbitrarily complicated force field,
which force in the three directions is color coded. Red is coding for the X-axis,
green for the Y-axis and blue for the Z-axis
(like the color of the coordinate axes in the 3D View). A value of 0.5 means no force,
a value larger than 0.5 acceleration in negative axis direction (like -Z),
a value smaller than 0.5 acceleration in positive axis direction (like +Z).

Options
=======

.. figure:: /images/physics_force-field_types_texture.jpg

UI for a Texture force field.

Texture mode
This sets the way a force vector is derived from the texture.

RGB
Uses the color components directly as the force vector components in the color encoded directions.
You need an RGB texture for this, e.g. an image or a colorband.
So a *Blend* texture without a colorband would not suffice.
Gradient
Calculates the force vector as the 3D-gradient of the intensity (grayscale) of the texture.
The gradient vector always points to the direction of increasing brightness.
Curl
Calculates the force vector from the curl of the 3D-RGB texture (rotation of RGB vectors).
This also works only with a color texture. It can be used for example to create a nice looking
turbulence force with a color clouds texture with Perlin noise.

Nabla
It is the offset used to calculate the partial derivatives needed
for *Gradient* and *Curl* texture modes.
Use Object Coordinates
Uses the emitter object coordinates (and rotation &amp; scale) as the texture space the particles use.
Allows for moving force fields, that have their coordinates bound to the location coordinates of an object.
Root Texture Coordinates
This is useful for hair as it uses the texture force calculated for
the particle root position for all parts of the hair strand.
2D
The *2D* button disregards the particles z-coordinate
and only uses particles x&amp;y as the texture coordinates.

Remember that only procedural texture are truly 3D.

Examples
========

- A single colored texture (0.5, 0.0, 0.5) creates a force in the direction of the positive Y-axis,
e.g. hair is orientated to the Y-axis.
- A blend texture with colorband can be used to created a force "plane". E.g. on the left side (0.5, 0.5, 0.5),
on the right side (1.0, 0.5, 0.5) you have a force plane perpendicular to XY (i.e. parallel to Z).
If you use an object for the coordinates, you can use the object to push particles around.
- An animated wood texture can be used to create a wave like motion.

.. vimeo:: 182778301

**********
Turbulence
**********

.. figure:: /images/physics_force-field_types_empty.png

Turbulence force field.

A *Turbulence* force field creates a random &amp; chaotic 3D noise effect,
similar to jets of water or geysers under the ocean.

Options
=======

.. figure:: /images/physics_force-field_types_turbulence.jpg

UI for a Turbulence force field.

Size
Indicates the scale of the noise.
Global
Makes the size and strength of the noise relative to the world, instead of the object it is attached to.

Example
=======

.. figure:: /images/physics_force-fields_types_turbulence_example.png

Turbulence force field affecting a particle system.

******
Vortex
******

.. figure:: /images/physics_force-field_types_vortex_visualzation.png

Vortex force field.

The *Vortex* force field gives a spiraling force that twists the direction of points around the force
object's local Z axis. This can be useful for making a swirling sink, or tornado,
or kinks in particle hair.

.. figure:: /images/physics_force-field_types_vortex.jpg

UI for a Vortex force field.

.. vimeo:: 173811208

****
Wind
****

.. figure:: /images/physics_force-field_types_wind_visualzation.png

Wind force field.

The *Wind* force field gives a constant force in a single direction, along the force object's local Z axis.
The strength of the force is visualized by the spacing of the circles shown.

.. figure:: /images/physics_force-field_types_wind.jpg

UI for a Wind force field.

.. vimeo:: 173807567

*******
Gravity
*******

Gravity is a global setting that is applied to all physics systems in a scene.
It can be found in the scene tab.
This value is generally fine left at its default, -9.810 on the Z-Axis,
which is the force of gravity in the real world.
Changing this value would simulate a lower or higher force of gravity.
Gravity denoted g, measurement *m* × *s*\ :sup:`-2`\).

Gravity is applied in the same way to all physics systems.

Gravity is practically the same around the entirety of planet *Earth*.
For rendering scenes from the *Moon*, use a value six times smaller, e.g. 1.622 *m* × *s*\ :sup:`-2`\.
The planet *Mars* has a gravity value of 3.69.

.. note::

The gravity value per physics system can be scaled down in the *Field Weights* tab.
.. _physics-index:

##########
Physics
##########

.. toctree::
:maxdepth: 2

introduction.rst
gravity.rst
baking.rst

Physic Types
============

.. toctree::
:maxdepth: 1

force_fields/index.rst
collision.rst
cloth/index.rst
dynamic_paint/index.rst
soft_body/index.rst
fluid/index.rst
smoke/index.rst
rigid_body/index.rst
particles/index.rst

************
Introduction
************

Blender's physics system allows you to simulate a number of different real world physical phenomena.

Currently, these physics systems are supported:

- :doc:`Particle Systems &lt;/physics/particles/index&gt;`
can be used to simulate many things such as hair, grass, smoke, and flocks.
- :doc:`Hair &lt;/physics/particles/hair/index&gt;`
is a subset of the particle system, and can be used for strand-like objects,
such as hair, fur, grass, quills, etc.
- :doc:`Soft Bodies &lt;/physics/soft_body/index&gt;`
are useful for everything that tends to bend, deform,
in reaction to forces like gravity or wind, or when colliding with other objects.
It can be used for skin, rubber, and even clothes.
- :doc:`Cloth Simulation &lt;/physics/cloth/index&gt;`
is specific for cloth-like objects.
- :doc:`Rigid Bodies &lt;/physics/rigid_body/index&gt;`
can simulate dynamic objects that are fairly rigid.
- :doc:`Fluids &lt;/physics/fluid/index&gt;`
include standard liquids as well as gasses.
- :doc:`Smoke &lt;/physics/smoke/index&gt;`
is a subset of the fluids system, and can be used for simulating volumes such as smoke.
- :doc:`Force Fields &lt;/physics/force_fields/index&gt;` can modify the behavior of simulations.

You can use these systems to create many different effects such as:

- Smoke
- Rain
- Dust
- Cloth
- Water
- Jello
- etc.
..    TODO/Review: {{review|partial=X|text=Some of the information is incorrect | fixes =
[[User:Sascha Uncia/Doc:2.6/Manual/Physics/Particles/Cache And Bake|X]]

*****
Cache
*****

.. figure:: /images/physics_particle_system_cachesettings.png

Particles Cache Settings.

*Emitter* systems use a unified system for caching and baking (together with softbody and cloth).
The results of the simulation are automatically cached to disk when the animation is played,
so that the next time it runs, it can play again quickly by reading in the results from the disk.
If you *Bake* the simulation the cache is protected and you will be asked when you are
trying to change a setting that will make a recalculating necessary.

.. tip:: Beware of the *Start* and *End* Settings

The simulation is only calculated for the positive frames in-between the *Start* and *End*
frames of the *Bake* panel, whether you bake or not.
So if you want a simulation longer than 250 frames you have to change the *End* frame!

Caching
=======

- As animation is played, each physics system writes each frame to disk,
between the simulation start and end frames.
These files are stored in folders with prefix ``blendcache``, next to the blend-file.
Note that for the cache to fill up, one has to start playback before or on the frame that the simulation starts.
- The cache is cleared automatically on changes. But not on all changes,
so it may be necessary to free it manually e.g. if you change a force field.
- If it is impossible to write in the subdirectory there will be no caching.
- The cache can be freed per physics system with a button in the panels,
or with the :kbd:`Ctrl-B` shortcut key to free it for all selected objects.
- If the file path to the cache is longer than what is possible with your operating system
(more than 250 characters for example), strange things might happen.

Baking
======

- The system is protected against changes after baking.
- The *Bake* result is cleared also with
:kbd:`Ctrl-B` for all selected objects or click on *Free Bake* for a singular particle system.
- If the mesh changes the simulation is not calculated anew.
- Sorry: no bake editing for particles like for softbodies and clothes.

Two notes at the end:

- For renderfarms, it is best to bake all the physics systems,
and then copy the blendcache to the renderfarm as well.
- Be careful with the sequence of modifiers in the modifier stack (as always).
You may have a different number of faces in the 3D View and for rendering (e.g. when using subdivision surface),
if so, the rendered result may be very different from what you see in the 3D View.

********
Children
********

*Children* are *Hair* and *Keyed* particles assigned subparticles.
They make it possible to work primarily with a relatively low amount of Parent particles,
for whom the physics are calculated. The children are then aligned to their parents.
Without recalculating the physics the number and visualization of the children can be changed.

Children can be emitted from particles or from faces (with some different options).
Emission from *Faces* has some advantages, especially the distribution is more even on each face
(which makes it better suitable for fur and the like).
However, children from particles follow their parents better, e.g.
if you have a softbody animation and do not want the hair to penetrate the emitting mesh.
But see also our manual page about :doc:`Hair &lt;/physics/particles/hair/index&gt;`.

If you turn on children the parents are no longer rendered
(which makes sense because the shape of the children may be quite different from that of their parents).
If you want to see the parents additionally turn on the *Parents* button in the *Visualization* panel.

Children carry the same material as their parents and are colored according to the exact
place from where they are emitted (so all children may have different color or other attributes).

The possible options depend from the type of particle system,
and if you work with *Children from faces* or *Children from particles*.
We do not show every possible combination,
only the settings for a *Hair* particle system.

Settings
========

Child Type
----------

None
^^^^

No Children are generated.

Simple
^^^^^^

Children are emitted from the parent position.

Size
Only for *Emitter*. A multiplier for children size.
Random
Random variation to the size of child particles.

Interpolated
^^^^^^^^^^^^

Children are emitted between the *Parent* particles on the faces of a mesh.
They interpolate between adjacent parents. This is especially useful for fur,
because you can achieve an even distribution.
Some of the children can become virtual parents, which are influencing other particles nearby.

Seed
Offset the random number table for child particles, to get a different result.
Virtual
Relative amount of virtual parents.
Long Hair
Calculate children that suit long hair well.

Common Options
^^^^^^^^^^^^^^

Display
The number of children in the 3D View.
Render
The number of children to be rendered.

Effects
-------

.. figure:: /images/physics_particles_properties_children_round-clump.png

From left to right: Round: 0.0, Round: 1.0, Clump: 1.0, Clump: -1.0, Shape: -0.99.

Use Clump Curve
Use :ref:`ui-curve-widget` instead of parameters.
Clump
Clumping amount along child strands.
The children may meet at their tip (1.0) or start together at their root (-1.0).
Shape
Form of *Clump*. Either inverse parabolic (0.99) or exponentially (-0.99).
Use Clump Noise
Todo.

Length
Length of child paths.
Threshold
Amount of particles left untouched by child path length.
Radius
The radius in which the children are distributed around their parents.
This is 3D, so children may be emitted higher or lower than their parents.
Roundness
The roundness of the children around their parents. Either in a sphere (1.0) or in-plane (0.0).
Seed
Offset in the random number table for child particles, to get a different randomized result.

Roughness
---------

Use Roughness Curve
Use :ref:`ui-curve-widget` instead of parameters.
Uniform, Size
It is based on children location so it varies the paths in a similar way when the children are near.
Endpoint, Shape
"Rough End" randomizes path ends (a bit like random negative clumping).
Shape may be varied from &lt;1 (parabolic) to 10.0 (hyperbolic).
Random, Size, Threshold
It is based on a random vector so it is not the same for nearby children.
The threshold can be specified to apply this to only a part of children.
This is useful for creating a few stray children that will not do what others do.

Kink
----

.. _fig-particle-child-kink:

.. figure:: /images/physics_particles_properties_children_kink.png

Child particles with Kink.

From left to right: Curl, Radial, Wave, Braid, Spiral.

With *Kink* you can rotate the children around the parent.
See Fig. :ref:`fig-particle-child-kink` above picture for the different types of *Kink*.

Kink
Nothing
Deactivated.
Curl
Children grow in a spiral around the parent hairs.
Radial
Children form around the parent a wave shape that passes through the parent hair.
Wave
Children form a wave, all in the same direction.
Braid
Children braid themselves around the parent hair.
Spiral
Generates a spiral at the end of each hair.

Radius, Resolution
Define the overall size.
Shape
Makes a the spiral grow in- or outward.

.. note:: Alignment Limitations

When hair is pointing straight up (along the chosen spiral axis, default Z), spirals may not show up!
This is a limitation of the projection method used.
Giving a slight tilt or random orientation to hairs fixes this.

Common Options
^^^^^^^^^^^^^^

Amplitude
The amplitude of the offset.
Clump
How much clump effects kink amplitude.
Flatness
How flat the hairs are.

Frequency
The frequency of the offset (1/total length). The higher the frequency the more rotations are done.
Shape
Where the rotation starts (offset of rotation).

*******
Display
*******

The Display Panel controls how particles are displayed in the 3D View.
This does not necessarily determine how they will appear when rendered.

Draw Method
None
The particles are not shown in the 3D View and are not rendered.
The emitter may be rendered though.
Point
Particles are displayed as square points.
Their size is independent of the distance from the camera.
Circle
Particles are displayed as circles that face the view.
Their size is independent of the distance from the camera.
Cross
Particles are displayed as 6-point crosses that align to the rotation of the particles.
Their size is independent of the distance from the camera.
Axis
Particles are displayed as 3-point axes.
This useful if you want to see the orientation and rotation of particles in the view port.
Increase the *Draw Size* until you can clearly distinguish the axis.

Particles visualized like Point, Circle, Cross and Axis do not have any special options,
but can be very useful when you have multiple particle systems at play,
if you do not want to confuse particles of one system from another
(e.g. in simulations using *Boids* physics).

Display
Specifies the percentage of all particles to show in the viewport (all particles are still rendered).
Draw Size
Specifies how large (in pixels) the particles are drawn in the viewport.

Size
Draw the size of the particles with a circle.
Velocity
Draw the velocity of the particles with a line that points in the direction of motion,
and length relative to speed.
Number
Draw the id-numbers of the particles in the order of emission.

Color
=====

The Color Menu allows you to draw particles according to certain particle properties.

None
Particles are black.
Material
Particles are colored according to the material they are given.
Velocity
Color particles according to their speed.
The color is a ramp from blue to green to red, Blue being the slowest,
and Red being velocities approaching the value of *Max* or above.
Increasing *Max* allows for a wider range of particle velocities.
Acceleration
Color particles according to their acceleration.

********
Emission
********

The *Emitter* system works just like its name says: it emits/produces particles for a certain amount of time.
In such a system, particles are emitted from the selected object from the *Start*
frame to the *End* frame and have a certain lifespan.
These particles are rendered default as :doc:`Halos &lt;/render/blender_render/materials/special_effects/halo&gt;`,
but you may also render these kind of particles as objects
(depending on the particle system's render settings,
see :doc:`Visualization &lt;/physics/particles/emitter/render&gt;`).

Options
=======

.. figure:: /images/physics_particle_emission_settings.png

Particle Emission Settings.

The buttons in the *Emission* panel control the way particles are emitted over time:

Number
The maximum amount of parent particles used in the simulation.
Start
The start frame of particle emission. You may set negative values,
which enables you to start the simulation before the actual rendering.
End
The end frame of particle emission.
Lifetime
The lifespan (in frames) of the particles.
Random
A random variation of the lifetime of a given particle.
The shortest possible lifetime is *Lifetime* × (1 - *Rand*).
Values above 1.0 are not allowed.
For example with the default *Lifetime* value of 50 a *Random* setting of 0.5
will give you particles with lives ranging from 50 frames to :math:`50 × (1.0 - 0.5) = 25`
frames, and with a *Random* setting of 0.75 you will get particles with lives ranging
from 50 frames to :math:`50 × (1.0 - 0.75) = 12.5` frames.

Emission Location
-----------------

*Emit From* parameters define how and where the particles are emitted,
giving precise control over their distribution. You may use vertex groups to confine the emission,
that is done in the *Vertex Groups* panel.

Vertices
Emits particles from the vertices of a mesh.
Faces
Emits particles from the surface of a mesh's faces.
Volume
Emits particles from the volume of an enclosed mesh.

Distribution Settings
---------------------

These settings control how the emissions of particles are distributed throughout the emission
locations.

Random
The emitter element indices are gone through in a random order instead of linearly (one after the other).

For Faces and Volume, additional options appear:

Even Distribution
Particle distribution is made even based on surface area of the elements,
i.e. small elements emit less particles than large elements, so that the particle density is even.
Jittered
Particles are placed at jittered intervals on the emitter elements.

Particles/Face
Number of emissions per face (0 = automatic).
Jittering Amount
Amount of jitter applied to the sampling.
Random
Particles are emitted from random locations in the emitter's elements.
Grid
Particles are set in a 3D grid and particles near/in the elements are kept.

Invert Grid
Invert what is considered the object and what is not.
Hexagonal
Uses a hexagonal shaped grid instead of a rectangular one.
Resolution
Resolution of the grid.
Random
Add a random offset to grid locations.

.. tip:: Your mesh must be :term:`manifold` to emit particles from the volume.

Some modifiers like the Edge Split Modifier break up the surface,
in which case volume emission will not work correctly!

Use Modifier Stack
Take any :doc:`Modifiers &lt;/modeling/modifiers/introduction&gt;` above the Particle Modifier in the
:ref:`modifier stack &lt;modifier-stack&gt;` into account when emitting particles, else
it uses the original mesh geometry.

.. note::

Note that particles may differ in the final render if these modifiers
generate different geometry between the viewport and render.

************
Force Fields
************

Field Weights
=============

The Field Weight Panel allows you to control how much influence each type of external force field, or effector,
has on the particle system. Force fields are external forces that give dynamic systems motion.
The force fields types are detailed on the :doc:`Force Field Page &lt;/physics/force_fields/index&gt;`.

Effector Group
Limit effectors to a specified group. Only effectors in this group will have an effect on the current system.
Gravity
Control how much the Global Gravity has an effect on the system.
All
Scale all of the effector weights.

Force Fields Settings
=====================

The Force Field Settings Panel allows you to make each individual act as a force field,
allowing them to affect other dynamic systems, or even, each other.

Self Effect
Causes the particle force fields to have an effect on other particles within the same system.
Amount
Set how many of the particles act as force fields. 0 means all of them are effectors.

You can give particle systems up to two force fields. By default they do not have any.
Choose an effector type from the selector to enable them.
Settings are described on the :doc:`Force Field Page &lt;/physics/force_fields/index&gt;`.

###########
Emitter
###########

.. toctree::
:maxdepth: 2

emission.rst
cache.rst
velocity.rst
rotation.rst
physics/index.rst
render.rst
display.rst
children.rst
force_field.rst
vertex_groups.rst

*****
Boids
*****

.. figure:: /images/physics_particle_physics_boids.jpg

Boid Physics Settings.

Boids particle systems can be set to follow basic rules and behaviors.
They are useful for simulating flocks, swarms, herds and schools of various kind of animals,
insects and fishes. They can react on the presence of other objects and on the members of their own system.
Boids can handle only a certain amount of information,
therefore the sequence of the Behavior settings is very important.
In certain situations only the first three parameter are evaluated.

To view the panel to the right, add a *Particle System* of type
*Emitter* and look in the middle area of the *Particle System* tab.

Physics
=======

Boids try to avoid objects with activated Deflection.
They try to reach objects with positive Spherical fields,
and fly from objects with negative Spherical fields.
The objects have to share one common layer to have effect.
It is not necessary to render this common layer, so you may use invisible influences.

Boids can different physics depending on whether they are in the air,
or on land (on collision object)

Allow Flight
Allow boids to move in the air.
Allow Land
Allow boids to move on land.
Allow Climbing
Allow boids to climb goal objects.

Max Air Speed
Set the Maximum velocity in the air.
Min Air Speed
Set the Minimum velocity in the air.
Max Air Acceleration
Lateral acceleration in air, percent of max velocity (turn). Defines how fast a boid is able to change direction.
Max Air Angular Velocity
Tangential acceleration in air, percent 180 degrees.
Defines how much the boid can suddenly accelerate in order to fulfill a rule.
Air Personal Space
Radius of boids personal space in air. Percentage of particle size.
Landing Smoothness
How smoothly the boids land.

Max Land Speed
Set the Maximum velocity on land.
Jump Speed
Maximum speed for jumping
Max Land Acceleration
Lateral acceleration on land, percent of max velocity (turn). Defines how fast a boid is able to change direction.
Max Land Angular Velocity
Tangential acceleration on land, percent 180 degrees.
Defines how much the boid can suddenly accelerate in order to fulfill a rule.
Land Personal Space
Radius of boids personal space on land. Percentage of particle size.
Land Stick Force
How strong a force must be to start effecting a boid on land.

Banking
Amount of rotation around velocity vector on turns. Banking of 1.0 gives a natural banking effect.
Pitch
Amount of rotation around side vector.
Height
Boid height relative to particle size.

Battle
------

Health
Initial boid health when born.
Strength
Maximum caused damage per second on attack.
Aggression
Boid will fight this times stronger than enemy.
Accuracy
Accuracy of attack.
Range
Maximum distance of which a boid can attack.

Alliance
--------

The relations box allows you to set up other particle systems to react with the boids.
Setting the type to *Enemy* will cause the systems to fight with each other.
*Friend* will make the systems work together.
*Neutral* will not cause them to align or fight with each other.

Deflectors and Effectors
------------------------

As mentioned before, very much like Newtonian particles,
Boids will react to the surrounding deflectors and fields,
according to the needs of the animator:

Deflection:
Boids will try to avoid deflector objects according to the Collision rule's weight.
It works best for convex surfaces (some work needed for concave surfaces).
For boid physics, Spherical fields define the way the objects having the field are seen by others.
So a negative Spherical field (on an object or a particle system)
will be a predator to all other boids particle systems,
and a positive field will be a goal to all other boids particle systems.

When you select an object with a particle system set on,
you have in the Fields tab a little menu stating if the field
should apply to the emitter object or to the particle system.
You have to select the particle system name if you want
prey particles to flew away from predator particles.

Spherical fields: These effectors could be predators (negative Strength)
that boids try to avoid or targets (positive Strength)
that boids try to reach according to the (respectively) Avoid and Goal rules' weights.
Spherical's effective Strength is multiplied by the actual relevant weight (e.g. if either Strength or Goal is null,
then a flock of boids will not track a positive Spherical field).
You can also activate Die on hit (Extras panel) so that a prey particle simply disappears when
"attacked" by a predator particle which reaches it. To make this work,
the predator particles have to have a spherical field with negative force,
it is not sufficient just to set a positive goal for the prey particles
(but you may set the predators force strength to -0.01).
The size of the predators and the prey can be set with the Size button in the Extras panel.

Boid Brain
----------

The Boid Brain panel controls how the boids particles will react with each other.
The boids' behavior is controlled by a list of rules.
Only a certain amount of information in the list can be evaluated.
If the memory capacity is exceeded, the remaining rules are ignored.

The rules are by default parsed from top-list to bottom-list
(thus giving explicit priorities),
and the order can be modified using the little arrows buttons on the right side.

The list of rules available are:

Goal
Seek goal (objects with Spherical fields and positive Strength).

Predict
Predict target's movements.

Avoid
Avoid "predators" (objects with Spherical fields and negative Strength).

Predict
Predict target's movements.
Fear Factor
Avoid object if danger from it is above this threshold.

Avoid Collision
Avoid objects with activated Deflection.

Boids
Avoid collision with other boids.
Deflectors
Avoid collision with deflector objects.
Look Ahead
Time to look ahead in seconds.

Separate
Boids move away from each other.

Flock
Copy movements of neighboring boids, but avoid each other.

Follow Leader
Follows a leader object instead of a boid.

Distance
Distance behind leader to follow.
Line
Follow the leader in a line.

Average Speed
Maintain average velocity.

Speed
Percentage of maximum speed.
Wander
How fast velocity's direction is randomized.
Level
How much velocity's Z component is kept constant.

Fight
Move toward nearby boids.

Fight Distance
Attack boids at a maximum of this distance.
Flee Distance
Flee to this distance.

Rule Evaluation
---------------

There are three ways control how rules are evaluated.

Average
All rules are averaged.
Random
A random rule is selected for each boid.
Fuzzy
Uses fuzzy logic to evaluate rules. Rules are gone through top to bottom.
Only the first rule that effect above fuzziness threshold is evaluated.
The value should be considered how hard the boid will try to respect a given rule
(a value of 1.000 means the Boid will always stick to it, a value of 0.000 means it will never).
If the boid meets more than one conflicting condition at the same time,
it will try to fulfill all the rules according to the respective weight of each.

Please note that a given boid will try as much as it can to comply to each of the rules he is
given, but it is more than likely that some rule will take precedence on other in some cases.
For example, in order to avoid a predator, a boid could probably "forget" about Collision,
Crowd and Center rules, meaning that "while panicked" it could well run into obstacles,
for example, even if instructed not to, most of the time.

As a final note, the Collision algorithm is still not perfect and in research progress,
so you can expect wrong behaviors at some occasion. It is worked on.

*****
Fluid
*****

.. figure:: /images/physics_particles_properties_physics_fluid_panel.png

Fluid Physics Settings.

Fluid simulations are widely used in CG, and a very desired feature of any particle system,
fluid particles are similar to newtonian ones but this time particles are influenced by
internal forces like pressure, surface tension, viscosity, springs, etc.
Blender particle fluids use the SPH techniques to solve the particles fluid equations.

Smoothed-particle hydrodynamics (SPH) is a computational method used for simulating fluid flows.
It has been used in many fields of research, including astrophysics, ballistics, vulcanology,
and oceanography. It is a mesh-free Lagrangian method (where the co-ordinates move with the fluid),
and the resolution of the method can easily be adjusted with respect to variables such as the density.

From liquids to slime, goo to sand and wispy smoke the possibilities are endless.

Settings
========

Fluid physics share options with :doc:`Newtonian Physics &lt;/physics/particles/emitter/physics/newtonian&gt;`.
These are covered on that page.

Fluid Properties
----------------

Stiffness
How incompressible the fluid is.
Viscosity
Linear viscosity. Use lower viscosity for thicker fluids.
Buoyancy
Artificial buoyancy force in negative gravity direction based on pressure differences inside the fluid.

Advanced
--------

Repulsion Factor
How strongly the fluid tries to keep from clustering (factor of stiffness).
Check box sets repulsion as a factor of stiffness.
Stiff Viscosity
Creates viscosity for expanding fluid. Check box sets this to be a factor of normal viscosity.
Interaction Radius
Fluid's interaction radius. Check box sets this to be a factor of 4 × *particle size*.
Rest Density
Density of fluid when at rest. Check box sets this to be a factor of default density.

Springs
-------

Force
Spring force
Rest Length
Rest length of springs. Factor of particle radius. Check box sets this to be a factor of 2 × *particle size*.

Viscoelastic Springs
Use viscoelastic springs instead of Hooke's springs.
Elastic Limit
How much the spring has to be stretched/compressed in order to change its rest length
Plasticity
How much the spring rest length can change after the elastic limit is crossed.
Initial Rest Length
Use initial length as spring rest length instead of 2 × *particle size*.
Frames
Create springs for this number of frames since particle's birth (0 is always).
.. _particle_physics-index:

###########
Physics
###########

.. toctree::
:maxdepth: 2

introduction.rst
newtonian.rst
keyed.rst
boids.rst
fluid.rst

************
Introduction
************

The movement of particles may be controlled in a multitude of ways.
With particles physics: there are five different systems:

None (`No Physics`_)
It does not give the particles any motion, which makes them belong to no physics system.
:doc:`Newtonian &lt;/physics/particles/emitter/physics/newtonian&gt;`
Movement according to physical laws.
:doc:`Keyed &lt;/physics/particles/emitter/physics/keyed&gt;`
Dynamic or static particles where the (animated) targets are other particle systems.
:doc:`Boids &lt;/physics/particles/emitter/physics/boids&gt;`
Particles with limited artificial intelligence, including behavior and rules programming,
ideal for flocks of birds or schools of fishes, or predators vs preys simulations.
:doc:`Fluid &lt;/physics/particles/emitter/physics/fluid&gt;`
Movement according to fluid laws (based on Smoothed Particle Hydrodynamics technique).

Additional ways of moving particles:

- By softbody animation (only for Hair particle systems).
- By forcefields and along curves.
- By lattices.

Here we will discuss only the particle physics in the narrower sense, i.e.
the settings in the Physics panel.

Common Physics Settings
=======================

Size
Sets the size of the particles.
Random Size
Give the particles a random size variation.
Mass
Specify the mass of the particles.
Multiply mass with particle size
Causes larger particles to have larger masses.

No Physics
----------

At first a Physics type that makes the particles do nothing could seem a bit strange,
but it can be very useful at times.
None physics make the particles stick to their emitter their whole life time. The initial
velocities here are for example used to give a velocity to particles that are affected
by a harmonic effector with this physics type when the effect of the effector ends.

Moreover, it can be very convenient to have particles at disposal
(whose both Unborn and Died are visible on render)
to groom vegetation and/or ecosystems using Object, Group or Billboard types of visualization.

*****
Keyed
*****

.. figure:: /images/physics_particle_properties_physics_keyed_panel.png

Keyed Physics Settings.

The particle paths of keyed particles are determined from the emitter to another particle
system's particles. This allows creation of chains of systems with keyed physics to create
long strands or groovy moving particles. Basically the particles have no dynamics but are
interpolated from one system to the next at drawtime.

Setup
=====

To setup Keyed particles you need at least two particle systems.

The first system has keyed physics, and it needs the option First activated.
This will be the system thats is visible.

The second system may be another keyed system but without the option First,
or a normal particle system. This second system is the target of the keyed system.

Loops
Sets the number of times the keys are looped. Disabled if *Use Timing* is enabled.

Keys
====

Key Targets
You have to enter the name of the object which bears the target system and if there are
multiple particle systems the number of the system.

Click the :kbd:`Plus` to add a key, then select the object.

If you use only one keyed system the particles will travel in their lifetime from the emitter
to the target. A shorter lifetime means faster movement.
If you have more than one keyed system in a chain, the lifetime will be split equally.
This may lead to varying particle speeds between the targets.

Timing
======

Use Timing
Timing works together with the Time slider for the other keyed systems in a chain.
The Time slider allows to define a fraction of particle lifetime for particle movement.

An example:
let us assume that you have two keyed systems in a chain and a third system as target.
The particle lifetime of the first system shall be 50 keys.
The particles will travel in 25 frames from the first keyed system to the second,
and in further 25 frames from the second system to the target.
If you use the Timed button for the first system,
the Time slider appears in the second systems panel. Its default value is 0.5,
so the time is equally split between the systems. If you set Time to 1,
the movement from the first system to the second will get all the lifetime
(the particles will die at the second system).

If you set Time to 0 the particles will start at the second system and travel to the target.

*********
Newtonian
*********

These are the "normal" particle physics.
Particles start their life with the specified initial velocities and angular velocities,
and move according to Newtonian forces.
The response to environment and to forces is computed differently,
according to any given integrator chosen by the animator.

.. figure:: /images/physics_particle_properties_physics_newtonian_panel.png

Newtonian Physics Settings.

Forces
======

Brownian
Specify the amount of Brownian motion.
Brownian motion adds random motion to the particles based on a Brownian noise field.
This is nice to simulate small, random wind forces.
Drag
A force that reduces particle velocity in relation to its speed and size
(useful in order to simulate Air-Drag or Water-Drag).
Damp
Reduces particle velocity (deceleration, friction, dampening).

Integration
===========

Integrators are a set of mathematical methods available to calculate the movement of
particles. The following guidelines will help to choose a proper integrator,
according to the behavior aimed at by the animator.

Euler
Also known as "Forward Euler". Simplest integrator.
Very fast but also with less exact results.
If no dampening is used, particles get more and more energy over time.
For example, bouncing particles will bounce higher and higher each time.
Should not be confused with "Backward Euler" (not implemented) which has the opposite feature,
energies decrease over time, even with no dampening.
Use this integrator for short simulations or simulations with a lot of
dampening where speedy calculations is more important than accuracy.
Varlet
Very fast and stable integrator, energy is conserved over time with very little numerical dissipation.
Midpoint
Also known as "2nd order Runge-Kutta". Slower than Euler but much more stable.
If the acceleration is constant (no drag for example), it is energy conservative.
It should be noted that in example of the bouncing particles,
the particles might bounce higher than they started once in a while, but this is not a trend.
This integrator is a generally good integrator for use in most cases.
RK4
Short for "4th order Runge-Kutta". Similar to Midpoint but slower and in most cases more accurate.
It is energy conservative even if the acceleration is not constant.
Only needed in complex simulations where Midpoint is found not to be accurate enough.

Frame Settings
==============

Timestep
The simulation time step per frame.
Subframes
Subframes to simulate for improved stability and finer granularity in simulations.
Use higher values for faster moving particles.

Collision
=========

Size Deflect
Use the particle size in deflections.
Die on Hit
Kill particle when it hits a deflector object.
Collision Group
If set, particles collide with objects from the group, instead of using objects that are on the same layer.

******
Render
******

The Render Panel controls how particles appear when they are rendered.

Material Index
Set which of the object's material is used to shade the particles.
Parent
Use a different object's coordinates to determine the birth of particles.

Emitter
When disabled, the emitter is no longer rendered. Activate the button *Emitter* to also render the mesh.
Parents
Render also parent particles if child particles are used.
Children have a lot of different deformation options,
so the straight parents would stand between their curly children.
So by default *Parents* are not rendered if you activate *Children*..
See :doc:`Children &lt;/physics/particles/emitter/children&gt;`

Unborn
Render particles before they are born.
Died
Render particles after they have died.
This is very useful if particles die in a collision *Die on hit*, so you can cover objects with particles.

Type
====

None
----

When set to *None* particles are not rendered.
This is useful if you are using the particles to duplicate objects.

Halo
----

Halo particles are rendered as :doc:`Halo Type Materials &lt;/render/blender_render/materials/special_effects/halo&gt;`.

Trail Count
Set the number of trail particles. When greater than 1, additional options appear.
Length in Frames
Path timing is in absolute frames.
Length
End time of drawn path.
Random
Give path lengths a random variation.

Line
----

The Line visualization mode creates (more or less thin)
polygon lines with the strand renderer in the direction of particles velocities. The thickness
of the line is set with the parameter *Start* of the *Strands* shader
(*Material* tab, *Links and Pipeline* panel).

Tail
Set the length of the particle's tail.
Head
Set the length of the particle's head.
Speed
Multiply the line length by particles' speed. The faster, the longer the line.

Trail Count
See description in `Halo`_.

Path
----

.. figure:: /images/physics_particle_properties_render_path.png

The Visualization panel for Path visualization.

The *Path* visualization needs a :doc:`Hair &lt;/physics/particles/hair/index&gt;` particle system or
:doc:`Keyed &lt;/physics/particles/emitter/physics/keyed&gt;` particles.

Strand render
[Keypointstrands] Use the strand primitive for rendering. Very fast and effective renderer.
Adaptive render
Tries to remove unnecessary geometry from the paths before rendering particle strands in
order to make the render faster and easier on memory.

Angle
How many degrees path has to curve to produce another render segment
(straight parts of paths need fewer segments).
Pixel
How many pixels path has to cover to produce another render segment
(very short hair or long hair viewed from far away need fewer parts).
(only for Adaptive render).

B-Spline
Interpolate hair using B-Splines.
This may be an option for you if you want to use low *Render* values.
You loose a bit of control but gain smoother paths.
Steps
Set the number of subdivisions of the rendered paths (the value is a power of 2).
You should set this value carefully,
because if you increase the render value by two you need four times more memory to render.
Also the rendering is faster if you use low render values (sometimes drastically).
But how low you can go with this value depends on the waviness of the hair.(the value is a power of 2).
This means 0 steps give 1 subdivision,
1 give 2 subdivisions, 2 --&gt; 4, 3 --&gt; 8, 4 --&gt; 16, ... *n* --&gt; *n*\ :sup:`2`\.

Timing
""""""

Absolute Path Time
Path timing is in absolute frames.
Start
Start time of the drawn path.

.. Ed: option is missing instead: Trail count

End
End time of the drawn path.
Random
Give the path length a random variation.

Please see also the manual page about
:doc:`Strands &lt;/render/blender_render/materials/properties/strands&gt;` for an in depth description.

Object
------

Dupli Object
The specified object is duplicated in place of each particle.

Global
Use object's global coordinates for duplication.
Rotation
Use the rotation of the object.
Scale
Use the size of the object.

Group
-----

Dupli Group
The objects that belong to a group are duplicated sequentially in the place of the particles.

Whole Group
Use the whole group at once, instead of one of its elements, the group being displayed in place of each particle.
Pick Random
The objects in the group are selected in a random order, and only one object is displayed in place of a particle.
Please note that this mechanism fully replaces old Blender particles system using parentage
and DupliVerts to replace particles with actual geometry.
This method is fully deprecated and does not work anymore.
Use Count
Use objects multiple times in the same groups.
Specify the order and number of times to repeat each object with the list box that appears.
You can duplicate an object in the list with the :kbd:`Plus` button,
or remove a duplicate with the :kbd:`Minus` button.

Use Global
Use object's global coordinates for duplication.
Rotation
Use the rotation of the objects.
Scale
Use the size of the objects.

Billboard
---------

.. figure:: /images/physics_particle_properties_render_billboard.png

Billboard visualization for particles.

*Billboards* are aligned square planes. They are aligned to the camera by default,
but you can choose another object that they should be aligned to.

If you move a billboard around its target, it always faces the center of its target.
The size of a billboard is set with the parameter *Size* of the particle
(in Blender Units).
You can use them e.g. for `Sprites &lt;https://en.wikipedia.org/wiki/Sprite_(computer_graphics)&gt;`__,
or to replace *Halo* visualization.
Everything that can be done with a halo can also be done with a billboard.
But billboards are real objects, they are seen by raytracing,
they appear behind transparent objects,
they may have an arbitrary form and receive light and shadows.
They are a bit more difficult to set up and take more render time and resources.

Texturing billboards (including animated textures with alpha) is done by using uv coordinates
that are generated automatically for them so they can take an arbitrary shape.
This works well for animations, because the alignment of the billboards can be dynamic.
The textures can be animated in several ways:

- Depending on the particle lifetime (relative time).
- Depending on the particle starting time.
- Depending on the frame (absolute time).

You can use different sections of an image texture:

- Depending on the lifetime of the billboard.
- Depending on the emission time.
- Depending on align or tilt.

Since you use normal materials for the billboard you have all freedoms in mixing textures to
your liking. The material itself is animated in absolute time.

The main thing to understand is that if the object does not have any *UV maps*,
you need to create at least one in the *Objects Data* tab,
for any of these to work. Moreover,
the texture has to be set to UV coordinates in the *Map Input* panel.
If you want to see examples for some of the animation possibilities, see the
`Billboard Animation Tutorial &lt;https://en.wikibooks.org/wiki/Blender_3D:_Noob_to_Pro/Billboard_Animation&gt;`__.

An interesting alternative to billboards are in certain cases strands,
because you can animate the shape of the strands.
Because this visualization type has so much options it is explained in greater detail below.

Align
You can limit the movement with these options. How the axis is prealigned at emission time.

X, Y , Z
Along the global X/Y/Z-axis respectively.
View
No prealignement, normal orientation to the target.
Velocity
Along the speed vector of the particle.
Lock
Locks the align axis, keeps this orientation, the billboard aligns only along one axis to its target.

Billboard Object
The target object that the billboards are facing. By default, the active camera is used.

Tilt Angle
Rotation angle of the billboards planes. A tilt of 1 rotates by 180 degrees (turns the billboard upside down).
Random
Random variation of tilt.

Offset X
Offset the billboard horizontally in relation to the particle center, this does not move the texture.
Offset Y
Offset the billboard vertically in relation to the particle center.

UV Channels
Billboards are just square polygons.
To texture them in different ways we have to have a way to set what textures we want for the
billboards and how we want them to be mapped to the squares.
These can then be set in the texture mapping buttons to set wanted textures for different coordinates.
You may use three different UV maps and get three different sets of UV coordinates,
which can then be applied to different (or the same) textures.

Billboard Normal UV
Coordinates are the same for every billboard, and just place the image straight on the square.
Billboard Time-Index (X-Y)
Coordinates actually define single points in the texture plane with the x-axis as time and y-axis as the particle
index. For example using a horizontal blend texture mapped to color from white to black will give particles
that start off as white and gradually change to black during their lifetime. On the other hand a vertical blend
texture mapped to color from white to black will make the first particle to be white and the last particle to be
black with the particles in between a shade of gray.

The animation of the UV textures is a bit tricky.
The UV texture is split into rows and columns (N times N). The texture should be square.
You have to use *UV Split* in the UV channel and fill in the name of the UV map.
This generated UV coordinates for this layer.

Split UV's
The amount of rows/columns in the texture to be used.
Coordinates are a single part of the *UV Split* grid, which is a n?n grid over the whole texture. What
the part is used for each particle and at what time is determined by the *Offset* and
*Animate* controls. These can be used to make each billboard unique or to use an "animated" texture for
them by having each frame of the animation in a grid in a big image.
Billboard Split UV
Set the name of the *UV map* to use with billboards
(you can use a different one for each *UV Channel*). By default, it is the active UV map
(check the *Object Data* tab in the Properties editor).

Animate
Select menu, indicating how the split UVs could be animated (changing from particle to particle with time):

None
No animation occurs on the particle itself, the billboard uses one section of the texture in its lifetime.
Age
The sections of the texture are gone through sequentially in particles' lifetimes.
Angle
Change the section based on the angle of rotation around the *Align to* axis,
if *View* is used the change is based on the amount of tilt.
Frame
The section is changes according to the frame.
Offset
Specifies how to choose the first part
(of all the parts in the n×n grid in the texture defined by the *UV Split* number) for all particles.

None
All particles start from the first part.
Linear
First particle will start from the first part and the last particle will start from the last part,
the particles in between will get a part assigned linearly from the first to the last part.
Random
Give a random starting part for every particle.

Trail Count
See the description in `Halo`_.
..(todo) Angular Velocity: Axis changed, added options

********
Rotation
********

.. figure:: /images/physics_particle_rotation.jpg

Particles rotation settings.

These parameters specify how the individual particles are rotated during their travel. To
visualize the rotation of a particle you should choose visualization type Axis in the
Visualization panel and increase the Draw Size.

Initial Rotation
----------------

Orientation Axis
Sets the initial rotation of the particle by aligning the x-axis in the direction of:

None
The global X-axis.
Normal
Orient to the emitter's surface normal, the objects Y axis points outwards.
Normal-Tangent
As with normal, orient the Y axis to the surface normal.
Also orient the X axis to the tangent for control over the objects rotation about the normal.
requires UV coordinates, the UV rotation effects the objects orientation, currently uses the active UV map.
This allow deformation without the objects rotating in relation to their surface.
Velocity
The particle's initial velocity.
Global X, Y, Z
One of the global axes.
Object X, Y, Z
One of the emitter object axes.

Random
Randomizes rotation.

Phase
Initial rotation phase.
Random
Rand allows a random variation of the Phase.

Angular Velocity
----------------

Axis
The selector specifies the axis of angular velocity to be.

None
A zero vector (no rotation).
Spin
The particles velocity vector.
Random
A random vector.

.. hint:: Curve Guide

If you use a Curve Guide and want the particles to follow the curve,
you have to set Angular Velocity to Spin and leave the rotation on Constant (i.e.
do not turn on Dynamic). Curve Follow does not work for particles.
Factor
The magnitude of angular velocity.

Dynamic
-------

If Dynamic is enabled, only initializes particles to the wanted rotation and angular velocity and
let the physics simulation handle the rest.
Particles then change their angular velocity if they collide with other objects
(like in the real world due to friction between the colliding surfaces).
Otherwise the angular velocity is predetermined at all times (i.e. set rotation to dynamic/constant).

********
Velocity
********

The initial velocity of particles can be set through different parameters,
based on the type of the particle system.
If the particle system type is Emitter or Hair,
then the following parameters give the particle an initial velocity in the direction of...

Emitter Geometry
================

Normal
The emitter's surface normals (i.e. let the surface normal give the particle a starting speed).
Tangent
Let the tangent speed give the particle a starting speed.
Rotation
Rotates the surface tangent.

Emitter Object
==============

Align
Give an initial velocity in the X, Y, and Z axes.

X, Y, Z
Object
The emitter objects movement (i.e. let the object give the particle a starting speed).
Random
Gives the starting speed a random variation.
You can use a texture to only change the value, see Controlling Emission, Interaction and Time.
..    TODO/Review: {{review|partial=X}}.

*************
Vertex Groups
*************

The Vertex groups panel allows you to specify vertex groups to use for several child particle settings.
You can also negate the effect of each vertex group with the check boxes.
You can affect the following attributes:

Density
Defines the "density" of the particle distribution.
Length
Defines the "length" of the particle distribution.
Clump
Todo.
Kink
Todo.
Roughness 1
Uniform.
Roughness 2
Random.
Roughness End
Endpoint.

Examples
========

Todo.

********
Children
********

See :doc:`Children &lt;/physics/particles/emitter/children&gt;`.

*******
Display
*******

Rendered
Draw hair as curves.
Path
Draw just the end points if the hairs.

Steps
The number of segments (control points minus 1) of the hair strand.
In between the control points the segments are interpolated. The number of control points is important:

- For the softbody animation, because the control points are animated like vertices,
so more control points mean longer calculation times.
- For the interactive editing, because you can only move the control points
(but you may recalculate the number of control points in *Particle Edit Mode*).

.. hint:: Segments

Ten Segments should be sufficient even for very long hair,
five Segments are enough for shorter hair, and two or three segments should be enough for short fur.
.. _hair-dynamics:

*************
Hair Dynamics
*************

Hair particles can have dynamic properties using physics.
To enable hair physics, click the check box beside *Hair Dynamics*.

Structure
---------

Mass
Value for the mass of the hair.
Stiffness
Controls the bending stiffness of the hair strands.

Random
Random stiffness of hair.

Damping
Damping of bending motion.

Volume
------

Some phenomena of real world hair can be simulated more efficiently using a volumetric model instead
of the basic geometric strand model. This means constructing a regular grid such as those used in
fluid simulations and interpolating hair properties between the grid cells.

Air Drag
Controls how thick the hair is around the hair causing the hair to flow slower.
Internal Friction
Amount of friction between individual hairs.

Density Target
Maximum density if the hair.

Strength
The influence that the *Density Target* has on the simulation.

Voxel Grid Cell Size
Size of the voxel grid cells for interaction effects.

Pinning
-------

Goal Strength
Spring stiffness of the vertex target position.

Quality
-------

Steps
Quality of the simulation in steps per frame. (higher is better quality but slower).
Hair Grid
Show hair simulation grid.

.. warning::

If you use motion blur in your animation,
you will need to bake one extra frame past the last frame which you will be rendering.

********
Emission
********

.. figure:: /images/physics_particle_system_hairsettings.jpg

Hair particle system settings.

Number
Set the amount of hair strands. Use as little particles as possible,
especially if you plan to use softbody animation later.
But you need enough particles to have good control.
For a "normal" haircut I found some thousand (very roughly 2000) particles to give enough control.
You may need a lot more particles if you plan to cover a body with fur.
Volume will be produced later with *Children*.
Hair Length
Controls how long the hair are.

Emit From
Vertices
Emits hair particles from the vertices of a mesh.
When using this the distribution settings (see below) are not available.
Faces
Emits hair particles from the surface of a mesh's faces.
Volume
Emits hair particles from the volume of an enclosed mesh.

Random
Hair particles are emitted in a random order.

Even Distribution
Hair particle distribution is made even based on surface area of the elements,
i.e. small elements emit less particles than large elements, so that the particle density is even.
Distribution
Jittered
Particles are placed at jittered intervals on the emitter elements.

Particles/Face
Number of emissions per face (0 = automatic).
Jittering Amount
Amount of jitter applied to the sampling.

Random
Particles are emitted from random locations in the emitter's elements.

Use Modifier Stack
Take any :doc:`Modifiers &lt;/modeling/modifiers/introduction&gt;` above the Particle Modifier in the
:ref:`modifier stack &lt;modifier-stack&gt;` into account when emitting particles.

.. note::

Note that particles may differ in the final render if these modifiers
generate different geometry between the viewport and render.
.. _particles-hair-index:

#######
Hair
#######

.. toctree::
:maxdepth: 2

introduction.rst
emission.rst
dynamics.rst
render.rst
children
display.rst

************
Introduction
************

When set to hair type, particle system creates only static particles,
which may be used for hair, fur, grass and the like.

.. figure:: /images/physics_particles_hair_example.jpg

Particle hair systems example. Used for the grass and fur.

Growing
=======

The first step is to create the hair, specifying the amount of hair strands and their lengths.

The complete path of the particles is calculated in advance.
So everything a particle does a hair may do also.
A hair is as long as the particle path would be for a particle with a lifetime of 100 frames.
Instead of rendering every frame of the particle animation point by point there are calculated
control points with an interpolation, the segments.

Styling
=======

The next step is to style the hair. You can change the look of base hairs by changing the
:doc:`Physics Settings &lt;/physics/particles/emitter/physics/index&gt;`.

A more advanced way of changing the hair appearance is to use
:doc:`Children &lt;/physics/particles/emitter/children&gt;`.
This adds child hairs to the original ones, and has settings for giving them different types of shapes.

You can also interactively style hairs in :doc:`Particle Edit Mode &lt;/physics/particles/mode&gt;`.
In this mode, the particle settings become disabled, and you can comb, trim, lengthen, etc. the hair curves.

Animating
=========

Hair can now be made dynamic using the cloth solver.
This is covered in the :ref:`Hair Dynamics &lt;hair-dynamics&gt;` page.

Rendering
=========

Blender can render hairs in several different ways. Materials have a Strand section,
which is covered in the materials section in the
:doc:`Strands Page &lt;/render/blender_render/materials/properties/strands&gt;`.

Hair can also be used as a basis for the
:doc:`Particle Instance Modifier &lt;/modeling/modifiers/simulate/particle_instance&gt;`,
which allows you to have a mesh be deformed along the curves,
which is useful for thicker strands, or things like grass, or feathers, which may have a more specific look.

******
Render
******

Hair can be rendered as a Path, Object, or Group.
See :doc:`Particle Visualization &lt;/physics/particles/emitter/display&gt;` for descriptions.

.. seealso::

`Blender Hair Basics &lt;https://www.youtube.com/watch?v=kpLaxqemFU0&gt;`__,
a thorough overview of all of the hair particle settings.
.. _particles-index:

###################
Particles System
###################

.. toctree::
:maxdepth: 2

introduction.rst
particle_system_panel.rst
emitter/index.rst
hair/index.rst
texture_influence.rst
mode.rst

************
Introduction
************

Particles are lots of items emitted from mesh objects, typically in the thousands.
Each particle can be a point of light or a mesh, and be joined or dynamic.
They may react to many different influences and forces, and have the notion of a lifespan.
Dynamic particles can represent fire, smoke, mist,
and other things such as dust or magic spells.

:doc:`Hair &lt;/physics/particles/hair/index&gt;` type particles are a subset of regular particles.
Hair systems form strands that can represent hair, fur, grass and bristles.

You see particles as a Particle Modifier,
but all settings are done in the *Particle tab*.

.. figure:: /images/physics_particle_introduction_fur_example.jpg
:width: 300px

Some fur made from particles.

Particles generally flow out from their mesh into space.
Their movement can be affected by many things, including:

- Initial velocity out from the mesh.
- Movement of the emitter (vertex, face or object) itself.
- Movement according to "gravity" or "air resistance".
- Influence of force fields like wind, vortexes or guided along a curve.
- Interaction with other objects like collisions.
- Partially intelligent members of a flock (herd, school, ...),
that react to other members of their flock, while trying to reach a target or avoid predators.
- Smooth motion with softbody physics (only *Hair* particle systems).
- Or even manual transformation with :doc:`Lattices &lt;/modeling/modifiers/deform/lattice&gt;`.

Particles may be rendered as:

- :doc:`Halos &lt;/render/blender_render/materials/special_effects/halo&gt;`
(for Flames, Smoke, Clouds).
- Meshes which in turn may be animated (e.g. fish, bees, ...).
In these cases, each particle "carries" another object.
- :doc:`Strands &lt;/render/blender_render/materials/properties/strands&gt;`
(for :doc:`Hair, Fur, Grass &lt;/physics/particles/hair/index&gt;`);
the complete way of a particle will be shown as a strand.
These strands can be manipulated in the 3D View (combing, adding, cutting, moving, etc).

Every object may carry many particle systems. Each particle system may contain up to
100.000 particles. Certain particle types (*Hair* and *Keyed*)
may have up to 10.000 children for each particle
(children move and emit more or less like their respective parents).
The size of your memory and your patience are your practical boundaries.

Options
-------

Each system has the same basic sets of controls,
but options within those sets vary based on the system employed. These sets of controls are:

:doc:`Particle System Panel &lt;/physics/particles/particle_system_panel&gt;`
Basic Settings.
:doc:`Emission &lt;/physics/particles/emitter/emission&gt;`
Settings for the initial distribution of particles on the emitter and the way they are born into the scene.
:doc:`Cache &lt;/physics/particles/emitter/cache&gt;`
In order to increase realtime response and avoid unnecessary recalculation of particles,
the particle data can be cached in memory or stored on a drive.
:doc:`Velocity &lt;/physics/particles/emitter/physics/index&gt;`
Initial speed of particles.
:doc:`Rotation &lt;/physics/particles/emitter/physics/index&gt;`
Rotational behavior of particles.
:doc:`Physics &lt;/physics/particles/emitter/physics/index&gt;`
How the movement of the particles behaves.
:doc:`Render &lt;/physics/particles/emitter/render&gt;`
Rendering options.
:doc:`Display &lt;/physics/particles/emitter/display&gt;`
Realtime display in the 3D View.
:doc:`Children &lt;/physics/particles/emitter/children&gt;`
Control the creation of additional child particles.
:doc:`Field Weights &lt;/physics/particles/emitter/physics/index&gt;`
Factors for external forces.
:doc:`Force Field Settings &lt;/physics/particles/emitter/physics/index&gt;`
Makes particles force fields.
:doc:`Vertex Groups &lt;/physics/particles/emitter/vertex_groups&gt;`
Influencing various settings with vertex groups.

******************
Particle Edit Mode
******************

Using *Particle Edit Mode* you can edit the key-points (Keyframes)
and paths of *Baked*
:doc:`Hair &lt;/physics/particles/hair/index&gt;`,
:doc:`Particle &lt;/physics/particles/index&gt;`,
:doc:`Cloth &lt;/physics/cloth/index&gt;`, and
:doc:`Soft Body &lt;/physics/soft_body/index&gt;` simulations.
(You can also edit and style hair before baking).

Since working in Particle Edit Mode is pretty easy and very similar to working with vertices in the
3D View, we will show how to set up a particle system and then give a reference of the
various functions.

Usage
=====

.. tip:: Only Frames Baked to Memory are Editable!

If you cannot edit the particles, check that you are not baking to a
:doc:`Disk Cache &lt;/physics/particles/emitter/cache&gt;`.

Setup for Hair Particles
------------------------

#. Create a *Hair* particle system.
#. Give it an initial velocity in the *Normal* direction.
#. Create a simulation
#. Check the *Hair Dynamics* box.

.. figure:: /images/physics_particle_mode.png

Editing hair strands in Particle Edit Mode.

Setup for Particle, Cloth, and Soft Body Simulations
----------------------------------------------------

#. Use *Emitter* particles, or a cloth/soft-body simulation
#. Create a simulation by setting up objects and or emitters,
set your time range (use a small range if you are just starting out and experimenting),
set up the simulation how you want it, using :kbd:`Alt-A` to preview it.

Bake the Simulation
-------------------

Once you are happy with the general simulation, :doc:`bake &lt;/physics/particles/emitter/cache&gt;`
the simulation from object mode. The simulation must be baked to enable editing.

Edit the Simulation
-------------------

Switch to *Particle Edit* from the *Mode select menu* in the header of the *3D View*
to edit the particle's paths/Keyframes. You may need to press :kbd:`T` from within the 3D View
to see the *Particle Edit* panel. Move to the frame you want to edit and use the various *Particle Edit*
tools to edit your simulation. Work slowly, previewing your changes with :kbd:`Alt-A`,
and save often so that you can go back to the previous version should something happen,
or that you do not like the latest changes you have made.

.. tip:: To be able to clearly see what you are working on:

#. Open the Options panel in the Tool shelf.
#. Select *Point select mode* (see below) in the header of the 3D View.
This will display key points along the particle path.

Selecting
=========

- Single: :kbd:`RMB`.
- All: :kbd:`A`.
- Linked: Move the mouse over a keypoint and press :kbd:`L`.
- Border select: :kbd:`B`.
- First/last: :menuselection:`Specials --&gt; Select First / Select Last`.

You may also use the *Select* Menu.

.. tip:: Selections

Selections are extremely useful for modifying only the particles that you want.
Hover over a particle path and press :kbd:`L` to link-select it,
hover over the next and press :kbd:`L` to add that path to the selection.
To remove a path, hold :kbd:`Shift` and press :kbd:`L`. To Deselect all press :kbd:`A`.

The method to select individual points is the same as in edit mode.
:kbd:`RMB` to select, :kbd:`Shift-RMB` to add/remove a point from the selection.

Select Random
-------------

ToDo.

Select Modes
------------

.. figure:: /images/physics_particles_mode_select-modes.png

Select Modes.

Path
No keypoints are visible, you can select/deselect only all particles.
Point
You see all of the keypoints.
Tip
You can see and edit (including the brushes) only the tip of the particles, i.e. the last keypoint.

Brush
=====

.. admonition:: Reference
:class: refbox

| Mode:     Particle Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Brush`

With the buttons you can select the type of "Comb" utility you want to use.

None
No special tool, just edit the keypoints as "normal" vertices.
Comb
Moves the keypoints (similar to "proportional editing").
Smooth
Parallels visually adjacent segments.
Add
Adds new particles.

Count
The number of new particles per step.
Interpolate
Interpolate the shape of new hairs from existing ones.
Steps
Amount of brush steps
Keys
How many keys to make new particles with.
Length
Scales the segments, so it makes the hair longer with *Grow* or shorter with *Shrink*.
Puff
Rotates the hair around its first keypoint (root).
So it makes the hair stand up with *Add* or lay down with *Sub*.

Puff Volume
Apply puff to unselected end-points, (helps maintain hair volume when puffing root)
Cut
Scales the segments until the last keypoint reaches the brush.

Weight
This is especially useful for softbody animations, because the weight defines the softbody *Goal*.
A keypoint with a weight of 1 will not move at all,
a keypoint with a weight of 0 subjects fully to softbody animation.
This value is scaled by the *GMin* to *GMax* range of softbody goals...

.. Not more true, I think: '''Weight is only drawn for the complete hair (i.e. with the value of the tip),
not for each keypoint, so it's a bit difficult to paint'''

Common Options
--------------

Below the brush types, their settings appear:

Radius :kbd:`F`
Set the radius if the brush.
Strength :kbd:`Shift-F`
Set the strength of the brush effect (not for Add brush).
Add/Sub Grow/Shrink
Sets the brush to add the effect or reverse it.

Options
=======

.. admonition:: Reference
:class: refbox

| Mode:     Particle Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Options`

Deflect Emitter
Hair particles only -- Do not move keypoints through the emitting mesh.

Distance
The distance to keep from the Emitter.
Keep
Length
Keep the length of the segments between the keypoints when combing or smoothing the hair.
This is done by moving all the other keypoints.
Root
Keep first key unmodified, so you cannot transplant hair.
Correct
ToDo.
X Mirror
Enable mirror editing across the local X axis.
Shape Object
A mesh object which boundary is used by the *Shape Cut* tool.

Shape Cut
This grooming tool trims hairs to a shape defined by the *Shape Object*.
This is a quicker way of avoiding protruding hair sections from lengthening than using the cutting tool.
It works especially well for characters with extensive fur,
where working in a single plane with the cutting tool becomes tedious.

.. list-table:: Shape Cut example.

* - .. figure:: /images/physics_particles_mode_shapecut-before.png

Before.

- .. figure:: /images/physics_particles_mode_shapecut-after.png

After.

Draw
----

Path Steps
Drawing steps, sets the smoothness of the drawn path.
Fade Time
Frames
ToDo.
Show Children
Draws the children of the particles too.
This allows to fine tune the particles and see their effects on the result,
but it may slow down your system if you have many children.

Editing
=======

.. warning:: Beware of Undo!

Using *Undo* in *Particle Edit Mode* can have strange results. Remember to save often!

Moving keypoints or particles
-----------------------------

- To move selected keypoints press :kbd:`G`, or use one of the various other methods to grab vertices.
- To move a particle root you have to turn off Keep *Root* in the Tool Shelf.
- You can do many of the things like with vertices, including scaling,
rotating and removing (complete particles or single keys).
- You may not duplicate or extrude keys or particles,
but you can subdivide particles which adds new keypoints
:menuselection:`Specials --&gt; Subdivide` or :kbd:`Numpad2`.
- Alternatively you can rekey a particle
:menuselection:`Specials --&gt; Rekey` or :kbd:`Numpad1` and choose the number of keys.

How smoothly the hair and particle paths are displayed depends on the *Path Steps*
setting in the Tool Shelf. Low settings produce blocky interpolation between points,
while high settings produce a smooth curve.

Mirror
------

.. admonition:: Reference
:class: refbox

| Mode:     Particle Edit Mode
| Menu:     :menuselection:`Particle --&gt; Mirror`

If you want to create an X-Axis symmetrical haircut you have to do following steps:

- Select all particles with :kbd:`A`.
- Mirror the particles with :kbd:`Ctrl-M`, or use the :menuselection:`Particle --&gt; Mirror` menu.
- Turn on *X-Axis Mirror Editing* in the *Particle* menu.

It may happen that after mirroring two particles occupy nearly the same place.
Since this would be a waste of memory and rendertime,
you can *Remove doubles* either from the *Specials* :kbd:`W`
or the *Particle* menu.

Unify Length
------------

.. admonition:: Reference
:class: refbox

| Mode:     Particle Edit Mode
| Menu:     :menuselection:`Particle --&gt; Unify Length`, :menuselection:`Specials --&gt; Unify Length`

This tool is used to make all selected hair uniform length by finding the average length.

Show/Hide
---------

.. admonition:: Reference
:class: refbox

| Mode:     Particle Edit Mode
| Menu:     :menuselection:`Particle --&gt; Show/Hide`

Hiding and unhiding of particles works similar as with vertices in the 3D View.
Select one or more keypoints of the particle you want to hide and press :kbd:`H`.
The particle in fact does not vanish, only the key points.

Hidden particles (i.e. particles whose keypoints are hidden)
do not react on the various brushes. But:

If you use *Mirror Editing* even particles with hidden keypoints may be moved,
if their mirrored counterpart is moved.

To un-hide all hidden particles press :kbd:`Alt-H`.

*********************
Particle System Panel
*********************

.. figure:: /images/physics_particle_system_panel.png

Particle System Panel.

Active Particle System
The :ref:`List View &lt;ui-list-view&gt;` of the objects Particle Modifier(s).

Particle Settings
The :ref:`Data-Block menu &lt;ui-data-block&gt;` for settings.

Type
Main selector of the system type.

Emitter
In such a system particles are :doc:`emitted &lt;/physics/particles/emitter/index&gt;` from the object.
Hair
Use :doc:`Hair &lt;/physics/particles/hair/index&gt;` type, rendered as strands.

Regrow
Regrows the hair for each frame. This is useful when you are animating properties.
Advanced
Enables advanced settings which reflect the same ones as working in Emitter mode.

.. note::

This manual assumes that this option is enabled.

Segments
Controls the number of parts a hair is made of.
Increasing this value will improve the quality of animations.

Seed
This initial value for random properties can be used to create a look, which is slightly different,
even when using the same settings.

Workflow
========

The process for working with standard particles is:

- Create the mesh which will emit the particles.
- Create one or more Particle Systems to emit from the mesh.
Many times, multiple particle systems interact or merge with each other to achieve the overall desired effect.
- Tailor each Particle System's settings to achieve the desired effect.
- Animate the base mesh and other particle meshes involved in the scene.
- Define and shape the path and flow of the particles.
- For :doc:`Hair &lt;/physics/particles/hair/index&gt;` particle systems: Sculpt the emitter's flow
(cut the hair to length and comb it for example).
- Make final render and do physics simulation(s), and tweak as needed.

Creating a Particle System
--------------------------

.. figure:: /images/physics_particle_system_createnew.jpg

Adding a particle system.

To add a new particle system to an object, go to the *Particles* tab of the
Properties editor and click the small ``+`` button.
An object can have many Particle Systems.

Each particle system has separate settings attached to it.
These settings can be shared among different particle systems, so one does not have to copy
every setting manually and can use the same effect on multiple objects.

Types of Particle systems
^^^^^^^^^^^^^^^^^^^^^^^^^

.. _fig-particle-intro-system-type:

.. figure:: /images/physics_particle_system_selecttype.jpg

Particle System Types.

After you have created a particle system,
the Properties editor fills with many panels and buttons.
But do not panic! There are two different types of particle systems,
and you can change between these two with the *Type* selector:
Emitter and Hair.

The settings in the *Particle System* tab are partially different for each system type.
For example, in :ref:`fig-particle-intro-system-type` they are shown for only system type *Emitter*.
.. https://developer.blender.org/T46363
.. leaved out: Mapping Coordinates

*****************
Texture Influence
*****************

.. figure:: /images/physics_particles_texture-influence_panel.png
:align: right

Texture influence settings.

Defines the settings of a Particle system spatial with a texture.

General
=======

Time
Affect the emission time of the particles.
Lifetime
Affect the life time of the particles.
Density
Affect the density of the particles.
Size
Affect the particles size.

Physics
=======

Velocity
Affect the particles initial velocity.
Damp
Affect the particles velocity damping.
Gravity
Affect the particles gravity.
Force Fields
Affect the particles force fields.

Hair
====

Length
Affect the child hair length.
Clump
Affect the child clumping.
Kink
Affect the child kink.
Rough
Affect the child roughness.
.. _rigid-body-constraints-index:

#########################
Rigid Body Constraints
#########################

.. toctree::
:maxdepth: 2

introduction.rst
types/index.rst

************
Introduction
************

:term:`Constraints &lt;Constraint&gt;` (also known as joints) for rigid bodies connect two rigid bodies.

The physics constraints available in the non-game modes are meant to be attached to an :term:`Empty` object.
The constraint then has fields which can be pointed at the two physics-enabled object which will be bound by the
constraint. The *Empty* object provides a location and axis for the constraint distinct from the two constrained
objects. The location of the entity hosting the physics constraint marks a location and set of axes on each of the two
constrained objects. These two anchor points are calculated at the beginning of the animation and their position and
orientation remain fixed in the *local* coordinate system of the object for the duration of the animation. The
objects can move far from the constraint object, but the constraint anchor moves with the object. If this feature
seems limiting, consider using multiple objects with a non-physics *Child-of* constraint and animate
the relative location of the child.

Connect
=======

The quickest way to constrain two objects is to select both and click the *Connect* button in the *Physics* tab of the
*Tool Shelf*. This creates a new *Empty* object (named "Constraint") with a physics constraint already attached and
pointing at the two selected objects.

Physics Tab
===========

Also you can create *Rigid Body Constraint* on of the two constrained objects with
*Rigid Body Constraint* button of the *Physics* tab in the Properties editor.
This constraint is dependent on the object location and rotation on which it was created.
This way, there are no *Empty* object created for the constraint.
The role of the *Empty* object is put on this object.
The constrained object can be then set as *Passive* type for better driving the constrain.

Additional parameters appear in the *Rigid Body Constraint* panel of the *Physics* tab in the Properties editor
for the selected *Empty* object or the one of the two constrained objects with the created constraint.

Common Options
==============

Rigid Body Constraint panel.

Enabled
Specifies whether the constraint is active during the simulation.
Disable Collisions
Allows constrained objects to pass through one another.
Object 1
First object to be constrained.
Object 2
Second object to be constrained.
Breakable
Allows constraint to break during simulation. Disabled for the *Motor* constraint.
This can be used to simulate destruction.

Threshold
Impulse strength that needs to be reached before constraint breaks.

Override Iterations
Allows to make constraints stronger (more iterations) or weaker (less iterations)
than specified in the rigid body world.

Iterations
Number of constraint solver iterations made per simulation step for this constraint.

Limits
By using limits you can constrain objects even more by specifying a translation/rotation range on/around
respectively axis (see below for each one individually). To lock one axis, set both limits to 0.

*****
Fixed
*****

.. figure:: /images/physics_rigid-body_constraints_fixed.png
:width: 500px

Options available to a *Fixed* constraint.

This constraint cause the two objects to move as one.
Since the physics system does have a tiny bit of slop in it,
the objects do not move as rigidly as they would if they were part of the same mesh.

*******
Generic
*******

The generic constraint has a lot of available parameters.

The X, Y, and Z axis constraints can be used to limit the amount of translation between the objects.
Clamping the min/max to zero has the same effect as the Point constraint.

Clamping the relative rotation to zero keeps the objects in alignment.
Combining an absolute rotation and translation clamp would behave much like the Fixed constraint.

Using a non-zero spread on any parameter allows it to rattle
around in that range throughout the course of the simulation.

Options
=======

Limits
X Axis/Y Axis/Z axis
Enables/disables limit translation on X, Y or Z axis respectively.

Lower
Lower limit of translation for X, Y or Z axis respectively.
Upper
Upper limit of translation for X, Y or Z axis respectively.
X Angle/Y Angle/Z Angle
Enables/disables limit rotation around X, Y or Z axis respectively.

Lower
Lower limit of rotation for X, Y or Z axis respectively.
Upper
Upper limit of rotation for X, Y or Z axis respectively.
.. (todo) wrong images

**************
Generic Spring
**************

.. figure:: /images/physics_rigid-body_constraints_hinge.png
:width: 500px

Options available to a *Generic Spring* constraint.

The generic spring constraint adds some spring parameters for the X/Y/Z axes to all the options available on the
Generic constraint. Using the spring alone allows the objects to bounce around as if attached with a spring anchored
at the constraint object. This is usually a little too much freedom, so most applications will benefit from enabling
translation or rotation constraints.

If the damping on the springs is set to 1, then the spring forces are prevented from realigning the anchor points,
leading to strange behavior. If your springs are acting weird, check the damping.

Options
=======

Limits
X Axis/Y Axis/Z axis
Enables/disables limit translation on X, Y or Z axis respectively.

Lower
Lower limit of translation for X, Y or Z axis respectively.
Upper
Upper limit of translation for X, Y or Z axis respectively.
X Angle/Y Angle/Z Angle
Enables/disables limit rotation around X, Y or Z axis respectively.

Lower
Lower limit of rotation for X, Y or Z axis respectively.
Upper
Upper limit of rotation for X, Y or Z axis respectively.

Springs
X/Y/Z
Enables/disables springs on X, Y or Z axis respectively.

Stiffness
Spring Stiffness on X, Y or Z axis respectively. Specifies how "bendy" the spring is.
Damping
Spring Damping on X, Y or Z axis respectively. Amount of damping the spring has.

*****
Hinge
*****

.. figure:: /images/physics_rigid-body_constraints_hinge.png
:width: 500px

Options available to a *Hinge* constraint.

The hinge permits 1 degree of freedom between two objects. Translation is completely constrained.
Rotation is permitted about the Z axis of the object hosting the Physics constraint
(usually an :term:`Empty`, distinct from the two objects that are being linked).
Adjusting the position and rotation of the object hosting the constraint allows you to
control the anchor and axis of the hinge.

The Hinge is the only 1-axis rotational constraint that uses the Z axis instead of the X axis.
If something is wrong with your hinge, check your other constraints to see if this might be the problem.

Options
=======

Limits
Z Angle
Enables/disables limit rotation around Z axis.

Lower
Lower limit of Z axis rotation.
Upper
Upper limit of Z axis rotation.
.. _rigid-body-constraints-types-index:

########
Types
########

.. toctree::
:maxdepth: 2

fixed.rst
point.rst
hidge.rst
slider.rst
piston.rst
generic.rst
generic_spring.rst
motor.rst

*****
Motor
*****

.. figure:: /images/physics_rigid-body_constraints_motor.png
:width: 500px

Options available to a *Motor* constraint.

The motor constraint causes translation and/or rotation between two entities.
It can drive two objects apart or together.
It can drive simple rotation, or rotation and translation
(although it will not be constrained like a screw since the translation
can be blocked by other physics without preventing rotation).

The rotation axis is the X axis of the object hosting the constraint.
This is in contrast with the Hinge which uses the Z axis.
Since the Motor is vulnerable to confusing perturbations without a matching Hinge constraint,
special care must be taken to align the axes.
Without proper alignment, the motor will appear to have no effect
(because the hinge is preventing the motion of the motor).

Options
=======

Linear motor/Angular motor
Enable
Enable linear or angular motor respectively.

Target Velocity
Target linear or angular motor velocity respectively.
Max Impulse
Maximum linear or angular motor impulse respectively.

******
Piston
******

A piston permits translation along the X axis of the constraint object.
It also allows rotation around the X axis of the constraint object.
It is like a combination of the freedoms of a slider with the freedoms of a hinge
(neither of which is very free alone).

Options
=======

Limits
X Axis
Enables/disables limit translation around X axis.

Lower
Lower limit of X axis translation.
Upper
Upper limit of X axis translation.
X Angle
Enables/disables limit rotation around X axis.

Lower
Lower limit of X axis rotation.
Upper
Upper limit of X axis rotation.

*****
Point
*****

.. figure:: /images/physics_rigid-body_constraints_point.png
:width: 500px

Options available to a *Point* constraint.

The objects are linked by a point bearing allowing any kind of rotation around the location of the constraint object,
but no relative translation is permitted. The physics engine will do its best to make sure that the two points
designated by the constraint object on the two constrained objects are coincident.

******
Slider
******

The Slider constraint allows relative translation along the X axis of the constraint object,
but permits no relative rotation, or relative translation along other axes.

Options
=======

Limits
X Axis
Enables/disables limit translation around X axis.

Lower
Lower limit of X axis translation.
Upper
Upper limit of X axis translation.
.. _rigid-body-index:

#############
Rigid Body
#############

.. toctree::
:maxdepth: 2

introduction.rst
properties.rst
world.rst
constraints/index.rst
tips.rst

************
Introduction
************

The rigid body simulation can be used to simulate the motion of solid objects.
It affects the position and orientation of objects and does not deform them.

Unlike the other simulations in Blender, the rigid body simulation works closer with the animation system.
This means that rigid bodies can be used like regular objects and be part of parent-child relationships,
animation constraints and drivers.

Creating a Rigid Body
=====================

Right now only mesh objects can participate in the rigid body simulation.
To create rigid bodies, either click on *Rigid Body* button in the *Physics* tab of the
Properties editor or use the *Add Active*/*Add Passive* buttons in the *Physics* tab of the *Tool Shelf*.

There are two types of rigid body: active and passive. *Active* bodies are dynamically simulated, while *passive*
bodies remain static. Both types can be driven by the animation system when using the *Animated* option.

During the simulation, the rigid body system will override the position and orientation of dynamic rigid body objects.
Note however, that the location and rotation of the objects is not changed,
so the rigid body simulation acts similar to a constraint.
To apply the rigid body transformations you can use the
*Apply Transformation* button in the *Physics* tab of the *Tool Shelf*.

The scale of the rigid body object also influences the simulation, but is always controlled by the animation system.

Rigid Body physics on the object can be *removed* with the *Rigid Body* button in the *Physics* tab or *Remove*
button in the *Physics* tab of the *Tool Shelf*.

*********************
Rigid Body Properties
*********************

.. figure:: /images/physics_rigid-body_properties_panel.jpg
:width: 400px

Default rigid body panel.

Rigid Body
==========

Type
Role of the rigid body in the simulation.
Active objects can be simulated dynamically, passive object remain static.

Active
Object is directly controlled by simulation results.
The possibility to select this type also available with *Add Active*
button in the Physics tab of the Tool Shelf.
Passive
Object is directly controlled by animation system.
Thus, this type is not available for `Rigid Body Dynamics`_.
The possibility to select this type also available with *Add Passive* button
in the Physics tab of the Tool Shelf.

Dynamic
Enables/disables rigid body simulation for object.
Animated
Allows the rigid body additionally to be controlled by the animation system.
Mass
Specifies how heavy the object is and "weights" irrespective of gravity.
There are predefined mass preset available with the *Calculate Mass* button
in the Physics tab of the Tool Shelf.

Calculate Mass
Automatically calculate mass values for Rigid Body Objects based on volume.
There are many useful presets available from the menu, patching real-world objects.

.. note::

Also you can have *Custom* mass material type,
which is achieved by setting a custom density value (kg/m\ :sup:`3`\).

Rigid Body Collisions
=====================

Rigid Body Collisions panel.

Collision Shapes
----------------

The Shape option determines the collision shape of the object.
The changing collision shape is available also with *Change Shape* button in the Physics tab of the Tool Shelf.

.. rubric:: Primitive Shapes

These are best in terms of memory/performance but do not
necessarily reflect the actual shape of the object.
They are calculated based on the object's bounding box.
The center of gravity is always in the middle for now.
Primitive shapes can be shown in the viewport by
enabling *Bounds* in the :menuselection:`Object --&gt; Display` panel.

Box
Box-like shapes (e.g cubes), including planes (e.g. ground planes).
The size per axis is calculated from the bounding box.
Sphere
Sphere-like shapes. The radius is the largest axis of the bounding box.
Capsule
This points up the Z-Axis.
Cylinder
This points up the Z-Axis.
The height is taken from the z-axis, while the radius is the larger of the x/y-axes.
Cone
This points up the Z-Axis.
The height is taken from the z-axis, while the radius is the larger of the x/y-axes.

.. rubric:: Mesh based shapes

These are calculated based on the geometry of the object so they are a better representation of the object.
The center of gravity for these shapes is the object origin.

Convex Hull
A mesh-like surface encompassing (e.g. shrink wrap over) all vertices (best results with fewer vertices).
Convex approximation of the object, has good performance and stability.
Mesh
:term:`Mesh` consisting of triangles only, allowing for more detailed interactions than convex hulls.
Allows to simulate concave objects, but is rather slow and unstable.

Mesh Source
-----------

Users can now specify the mesh *Source* for *Mesh* bases collision shapes:

Base
The base mesh of the object.
Deform
Includes any deformations added to the mesh (shape keys, deform modifiers).

Deforming
Mesh shapes can deform during simulation.
Final
Includes all deformations and modifiers.

General Settings
----------------

Surface Response
Friction
Resistance of object to movement. Specifies how much velocity is lost when objects collide with each other.
Bounciness
Tendency of object to bounce after colliding with another (0 to 1) (rigid to perfectly elastic).
Specifies how much objects can bounce after collisions.

Collision Groups
Allows rigid body collisions allocate on different groups (maximum 20).

Collision Margin
----------------

Margin
Threshold of distance near surface where collisions are still considered (best results when non-zero).

The collision margin is used to improve performance and stability of rigid bodies. Depending on the shape, it behaves
differently: some shapes embed it, while others have a visible gap around them.

The margin is *embedded* for these shapes:

- Sphere
- Box
- Capsule
- Cylinder
- Convex Hull: Only allows for uniform scale when embedded.

The margin is *not embedded* for these shapes:

- Cone
- Active Triangle Mesh
- Passive Triangle Mesh: Can be set to 0 most of the time.

Rigid Body Dynamics
===================

Used to control the physics of the rigid body simulation.
This panel is available only for *Active* type of rigid bodies.

Deactivation
Enable Deactivation
Enable deactivation of resting rigid bodies. Allows object to be deactivated during the simulation
(improves performance and stability, but can cause glitches).
Start Deactivated
Starts objects deactivated. They are activated on collision with other objects.
Linear Velocity
Specifies the linear deactivation velocity below which the rigid body is deactivated and simulation stops
simulating object.
Angular Velocity
Specifies the angular deactivation velocity below which the rigid body is deactivated and simulation stops
simulating object.

Damping
Translation
Amount of linear velocity that is lost over time.
Rotation
Amount of angular velocity that is lost over time.

****
Tips
****

As with all physics-enabled objects, pay close attention to the *Animated* check box in the *Rigid Body* panel of the
*Physics* tab in the Properties editor. A common mistake is to use keyframe animation on a *Passive* physics
object without checking the *Animated* box. The object will move, but the physics engine will behave as if the
*Passive* is still in its starting place, leading to disappointment.

Animation
=========

The most common trick is to :term:`keyframe` animate the location or rotation of an *Active* physics object as well as
the *Animated* checkbox. When the curve on the *Animated* property switches to disabled, the physics engine takes over
using the object's last known location, rotation and velocities.

Animating the strengths of various other parameters
(a :doc:`Motor's &lt;/physics/rigid_body/constraints/types/motor&gt;` Target Velocity,
a :doc:`Hinge's &lt;/physics/rigid_body/constraints/types/hidge&gt;` limits, etc)
can be used to accomplish a wide variety of interesting results.

Enabling a constraint during the physics simulation often has dramatic results as the physics engine tries to bring
into alignment two objects which are often dramatically out of alignment. It is very common for the affected objects
to build up enough kinetic energy to bounce themselves out of camera (and into orbit, although the physics engine is
not yet capable of simulating a planet's gravity well, so scratch that).

Rigid Body dynamics can be baking to normal keyframes with *Bake To Keyframes* button in the *Physics* tab of
the *Tool Shelf*.

Simulation Stability
====================

The simplest way of improving simulation stability is to increase the steps per second. However, care has to be taken
since making too many steps can cause problems and make the simulation even less stable (if you need more than 1000
steps, you should look at other ways to improve stability).

Increasing the number of solver iterations helps making constraints stronger and also improves object stacking
stability.

It is best to avoid small objects, as they are currently unstable.
Ideally, objects should be at least 20 cm in diameter.
If it is still necessary, setting the collision margin to 0,
while generally not recommended, can help making small object behave more naturally.

When objects are small and/or move very fast, they can pass through each other. Besides what is mentioned above it's
also good to avoid using mesh shapes in this case. Mesh shapes consist of individual triangles and therefore do not
really have any thickness, so objects can pass through more easily. You can give them some thickness by increasing the
collision margin.

Combining Rigid Bodies with Other Simulations
=============================================

Since the rigid body simulation is part of the animation system, it can influence other simulations just like the
animation system can.

In order for this to work, the rigid body object needs to have a Collision Modifier.
Simply click on *Collision* in the *Physics* tab.

Scaling Rigid Bodies
====================

Rigid body objects can be scaled, also during the simulation.
This work well in most cases, but can sometimes cause problems.

If dynamic scaling is not needed, rigid body objects should have the scale applied by
using the *Apply Scale* tool :kbd:`Ctrl-A`.

****************
Rigid Body World
****************

The *Rigid Body World* is a group of Rigid Body objects,
which holds settings that apply to all rigid bodies in this simulation.
These setting can be found in :menuselection:`Properties Editor --&gt; Scene --&gt; Rigid Body World`.

When you add Rigid Body physics on an object,
primary there is created a group of objects with default "RigidBodyWorld" name.
Rigid body objects automatically are added to this group when you add Rigid Body physics for them.

You can be create several Rigid Body World groups and allocate
there yours Rigid Body objects with *Groups* panel in *Object* tab.

Rigid body objects and constraints are only taken into account by the simulation if they are in the groups specified
in *Group* field of the *Rigid Body World* panel in the *Scene* tab.

Settings
========

Rigid Body World
Enable/disable evaluation of the Rigid Body simulation based on the rigid body objects
participating in the specified group of Rigid Body World.
Remove Rigid Body World
Remove Rigid Body simulation from the current scene.
Group
Containing rigid body objects participating in this simulation.
Constraints
Containing rigid body object constraints participating in the simulation.

Simulation quality and timing settings:

Speed
Can be used to speed up/slow down the simulation.
Split Impulse
Enable/disable reducing extra velocity that can build up when objects collide
(lowers simulation stability a little so use only when necessary).
Limits the force with which objects are separated on collision, generally produces nicer
results, but makes the simulation less stable (especially when stacking many objects).
Steps Per Second
Number of simulation steps made per second (higher values are more accurate but slower).
This only influences the accuracy and not the speed of the simulation.
Solver Iterations
Amount of constraint solver iterations made per simulation step (higher values are more accurate but slower).
Increasing this makes constraints and object stacking more stable.

Rigid Body Cache
================

The *Rigid Body Cache* panel specifies the frame range in which the simulation is active.
Can be used to bake the simulation.

Start/End
First and last frame of the simulation.
Bake
Calculates the simulation and protects the cache. You need to be in *Object Mode* to bake.

Free Bake
Active after the baking of simulation. Clears the baked cache.

Calculate to Frame
Bake physics to current frame.
Current Cache to Bake
Bake from Cache.
Bake All Dynamics
Bake all physics.
Free All Bakes
Free all baked caches of all objects in the current scene.
Update All To Frame
Update cache to current frame.

If you have not saved the blend-file, the cache is created in memory,
so save your file first or the cache may be lost.

Rigid Body Field Weights
========================

As other physics dynamics systems, Rigid Body simulation are also influenced by external force effectors.

************************
Baking Smoke Simulations
************************

.. figure:: /images/physics_smoke_baking_interface.png
:align: right

*Smoke Cache* options.

:term:`Baking` is used to store the outcome of a simulation so it does not need to be recalculated.

Smoke baking settings are in :menuselection:`Properties --&gt; Physics --&gt; Smoke --&gt; Smoke Cache`.
Unlike most physics simulations smoke physics has some settings that are specific to smoke.

File Format
===========

File format that the cache data is to be stored.

Point Cache
-----------

Blender's own caching format.

OpenVDB
-------

Advanced and efficient storage method developed by
`DreamWorks Animation &lt;http://www.dreamworksanimation.com/&gt;`__.

The simulation fields can be found in the ``.vdb`` files under the following names:

- "color"
- "density"
- "heat"
- "heat old" (the temperate at the previous fame)
- "flame"
- "fuel"
- "react" (reaction coordinates, used for fire)
- "velocity"
- "shadow" (the shadows of the volume computed for viewport rendering)
- "texture coordinates" (used for turbulence)

Compression
Method of data compression.

Zip
Efficient but slower compression method.
Blosc
Multi-threaded compression with about the same quality and size as ``Zip``.
None
Do not compress the data.

Data Depth
Bit depth for writing all scalar (including vectors), lower values reduce the file size of the cache.

Float (Half)
Half float (16 bit data). Gives less data with the benefit of smaller file sizes.
Float (Full)
Full float (32 bit data). Gives more data at the cost of larger file sizes.

.. seealso::

For other options see the :doc:`General Baking &lt;/physics/baking&gt;` docs for more information.

.. note::

Baking can only been done once your blend-file is saved.
If your blend-file has not been saved, the *Smoke Cache* panel will be disabled.
.. _smoke-index:

###################
Smoke Simulation
###################

.. toctree::
:maxdepth: 2

introduction.rst
types/index.rst
material.rst
baking.rst
..    TODO/Review: {{review}}.

************
Introduction
************

Smoke simulation is used to simulate the fluid movement of air and generate animated :term:`voxel`
textures representing the density, heat, and velocity of other fluids or suspended particles
(i.e. smoke) which can be used for rendering.

.. figure:: /images/physics_smoke_type_domain_note-on-resolution.jpg

Example of smoke simulation.

Smoke and fire are emitted into a :doc:`Domain &lt;/physics/smoke/types/domain&gt;`
from a mesh object or particle system. Smoke movement is controlled by airflow inside the domain,
which can be influenced by :doc:`smoke collision objects &lt;/physics/smoke/types/collisions&gt;`.
Smoke will also be affected by scene gravity and :doc:`force fields &lt;/physics/force_fields/index&gt;`.
Airflow inside the domain can affect other physics simulations via the smoke flow force field.

Workflow
========

At least a :doc:`Domain Object &lt;/physics/smoke/types/domain&gt;` object and
one :doc:`Flow object &lt;/physics/smoke/types/flow_object&gt;` are required to create a smoke simulation.
A basic workflow looks like this:

#. Create a :doc:`Domain Object &lt;/physics/smoke/types/domain&gt;`
that defines the bounds of the simulation volume.
#. Define a :doc:`Flow object &lt;/physics/smoke/types/flow_object&gt;`
or objects which will emit smoke and fire.
#. Set :doc:`Collision objects &lt;/physics/smoke/types/collisions&gt;`
to make the smoke interact with objects in the scene.
#. Assign a :doc:`Volumetric material &lt;/physics/smoke/material&gt;`
to the domain object.
#. Save the blend-file.
#. :doc:`Bake &lt;/physics/smoke/baking&gt;`
the simulation.

.. note::

There is a *Quick Smoke* operator which will automatically create a domain object with a basic smoke/fire material.
It can be found in :menuselection:`3D View --&gt; Object --&gt; Quick Effects --&gt; Quick Smoke`,
or in the :kbd:`Spacebar` search box.

.. note::

Blender's smoke simulation is based on the paper
`Wavelet Turbulence for Fluid Simulation &lt;https://www.cs.cornell.edu/~tedkim/wturb/&gt;`__
and associated sample code.

**************
Smoke Material
**************

Blender has multiple render engines each with its own method of rendering smoke-data:

- :doc:`Blender Internal &lt;/render/blender_render/materials/special_effects/volume&gt;`
- :doc:`Cycles Render &lt;/render/cycles/materials/volume&gt;`

**********
Collisions
**********

*Smoke Collision* objects are used to deflect smoke and influence airflow.

To define any mesh object as a *Smoke Collision* object,
add smoke physics by clicking *Smoke* in :menuselection:`Properties --&gt; Physics`.
Then select *Collision* as the *Smoke Type*.

Options
=======

.. figure:: /images/physics_smoke_type_collisions_settings.png
:align: right

*Smoke Collision* settings.

.. TODO, cannot figure out what the differences between the collision types are :/
.. Wild speculation on SE: https://blender.stackexchange.com/q/1723/599

.. Lukas Toenne investigated this (https://developer.blender.org/T45842#329325) and it appears that rigid and static
are the same.

Collision type
Static
Simple collision model which can be calculated quickly, but may be inaccurate for moving objects.

Animated
More complex collision model which takes into account impulse imparted to smoke when the collider is moving.
Calculations are slower, but more accurate for moving objects.

Rigid
Identical to *Static* (unfinished code).

Forces
======

:doc:`Force Fields &lt;/physics/force_fields/index&gt;` (such as wind or vortex) are supported, like most physics systems.
The influence individual force types have :ref:`can be controlled per domain object &lt;smoke-field-weights&gt;`.

************
Smoke Domain
************

The domain object contains the entire simulation. Smoke and fire cannot leave the domain,
it will either collide with the edge or disappear, depending on the domain's settings.

Keep in mind that large domains require higher resolutions and longer bake times.
You will want to make it just large enough that the simulation will fit inside it,
but not so large that it takes too long to compute the simulation.

To create a domain, add a cube :menuselection:`Add --&gt; Mesh --&gt; Cube`, :kbd:`Shift-A`
and transform it until it encloses the area where you want smoke. Translation, rotation,
and scaling are all allowed. To turn it into a smoke domain, click *Smoke*
in :menuselection:`Properties --&gt; Physics`, then select *Domain* as the *Smoke Type*.

.. note::

You *can* use other shapes of mesh objects as domain objects,
but the smoke simulator will use the shape's :term:`bounding box`
as the domain bounds. In other words, the actual shape of the domain will still be rectangular.

.. figure:: /images/physics_smoke_type_domain_settings.png
:align: right

*Smoke Domain* settings.

Settings
========

.. _smoke-resolution:

Resolution
The smoke domain is subdivided into many "cells" called voxels (see :term:`voxel`)
which make up "pixels" of smoke. This setting controls the number of subdivisions in the domain.
Higher numbers of subdivisions are one way of creating higher resolution smoke (See `Smoke High Resolution`_)

Since the resolution is defined in terms of *subdivisions*,
larger domains will need more divisions to get an equivalent resolution to a small domain.

Also see `Note on Divisions and High Resolution`_.

Time Scale
Controls the speed of the simulation. Low values result in a "slow motion" simulation,
while higher values can be used to advance the simulation faster
(useful for generating smoke for use in still renders).

Border Collisions
Controls which sides of the domain will allow smoke "through" the domain,
making it disappear without influencing the rest of the simulation,
and which sides will deflect smoke as if colliding with a
:doc:`Collision Object &lt;/physics/smoke/types/collisions&gt;`.

Vertically Open
Smoke disappears when it hits the top or bottom of the domain, but collides with the walls.
Open
Smoke disappears when it hits any side of the domain.
Collide All
Smoke collides with all sides of the domain.
Density
Controls how much smoke is affected by density.

- Values above 0 will cause the smoke to rise (simulating smoke which is lighter than ambient air).
- Values below 0 will cause smoke to sink (simulating smoke which is heavier than ambient air).

.. _smoke-domain-temp-diff:

Temperature Difference
The *Temperature Difference* setting controls how much smoke is affected by temperature.

The effect this setting has on smoke depends on the
per flow object :ref:` Temperature Difference &lt;smoke-flow-temp-diff&gt;`:

- Values above 0 will result in the smoke rising when the flow object *Temperature Difference* is
set to a positive value, and smoke sinking when the flow object *Temperature Difference* is
set to a negative value.
- Values below 0 will result in the opposite of positive values, i.e.
smoke emitted from flow objects with a positive *Temperature Difference* will sink,
and smoke from flow objects with a negative *Temperature Difference* will rise.

Note that smoke from multiple flow objects with different temperatures
will mix and warm up/cool down until an equilibrium is reached.

Vorticity
Controls the amount of turbulence in the smoke. Higher values will make lots of small swirls,
while lower values make smoother shapes.

.. figure:: /images/physics_smoke_type_domain_vorticity.jpg
:width: 400px

Comparison of different amounts of vorticity. The domain on the left has a vorticity of 3,
while the domain on the right has a vorticity of 0.01.

Dissolve
Allow smoke to dissipate over time.
Time
Speed of smoke's dissipation in frames.
Slow
Dissolve smoke in a logarithmic fashion. Dissolves quickly at first, but lingers longer.

Smoke Flames
============

Speed
How fast fuel burns. Larger values result in smaller flames (fuel burns before it can go very far),
smaller values result in larger flames (fuel has time to flow farther before being fully consumed).
Smoke
Amount of extra smoke created automatically to simulate burnt fuel.
Vorticity
Additional vorticity for flames.
Ignition
Minimum temperature of flames.
Maximum
Maximum temperature of flames.
Smoke Color
Color of smoke created by burnt fuel.

Smoke Adaptive Domain
=====================

When enabled, the domain will adaptively shrink to best fit the smoke,
saving computation time by leaving voxels without smoke out of the simulation.
Unless the *Additional* option is used, the adaptive domain will not exceed the bounds of the original domain.

Additional
Number of voxels to add around the outside of the domain.
Margin
Amount of extra space to leave around smoke, measured in voxels.
With very fast moving smoke larger margins may be required to prevent the smoke from being cut off
by the adaptive boundary, but note this will increase the number of voxels which need to be computed.
Threshold
Smallest amount of smoke a voxel can contain before it is considered empty
and the adaptive domain is allowed to cut it out of the simulation.

.. _smoke-high-resolution:

Smoke High Resolution
=====================

The High Resolution option lets you simulate at low resolution and then uses noise techniques
to enhance the resolution without actually computing it. This allows animators to set up a low
resolution simulation quickly and later add details without changing the overall fluid motion.
Also see `Note on Divisions and High Resolution`_.

Resolution: Divisions
Factor by which to enhance the resolution of smoke using the specified noise method.
Show High Resolution
Show high resolution in the viewport (may cause viewport responsiveness to suffer).

Noise Method
The two options, *Wavelet* and *FFT*, are very similar.

.. figure:: /images/physics_smoke_type_domain_high-resolution-method.jpg
:width: 400px

Comparison of noise methods. *Wavelet* on the left, *FFT* on the right.

.. note::

*Wavelet* is an implementation of `Turbulence for Fluid Simulation
&lt;http://graphics.ethz.ch/research/physics_animation_fabrication/simulation/turb.php&gt;`__.

Strength
Strength of noise.

.. figure:: /images/physics_smoke_type_domain_high-resolution-strength.jpg
:width: 400px

From left to right, the domains' high resolution strengths are set to 0, 2, and 6.

Smoke Groups
============

Flow Group
If set, only objects in the specified :doc:`Group &lt;/editors/3dview/object/properties/relations/groups&gt;`
will be allowed to act as flow objects in this domain.
Collision Group
If set, only objects in the specified :doc:`Group &lt;/editors/3dview/object/properties/relations/groups&gt;`
will be allowed to act as collision objects in this domain.

Smoke Cache
===========

See :doc:`Baking &lt;/physics/smoke/baking&gt;`.

.. _smoke-field-weights:

Smoke Field Weights
===================

These settings determine how much gravity and :doc:`Force Fields &lt;/physics/force_fields/index&gt;` affect the smoke.

Effector Group
When set, smoke can only be influenced by force fields in the specified group.
Gravity
How much the smoke is affected by Gravity.
All
Overall influence of all force fields.

The other settings determine how much influence individual force field types have.

.. figure:: /images/physics_smoke_type_domain_force-field-demo.jpg
:width: 500px

Smoke with a wind force field.

Note on Divisions and High Resolution
=====================================

:ref:`High Resolution Divisions &lt;smoke-high-resolution&gt;`
and :ref:`Domain Subdivisions &lt;smoke-resolution&gt;` are not equivalent.
By using different combinations of these resolution settings you can obtain a variety of different styles of smoke.

.. figure:: /images/physics_smoke_type_domain_high-resolution-comparison.jpg
:align: center

Comparison between a domain with 24 divisions and 4 *High Resolution* divisions (left),
and a domain with 100 divisions and 1 *High Resolution* division (right).

Low division simulations with lots of *High Resolution*
divisions generally appear smaller in real-world scale
(larger flames etc.) and can be used to achieve pyroclastic plumes such as this:

.. figure:: /images/physics_smoke_type_domain_note-on-resolution.jpg
:align: center
:width: 550px

High *Domain Division* simulations tend to appear larger in real-world scale, with many smaller details.

*****************
Smoke Flow Object
*****************

*Smoke Flow* objects are used to add or remove smoke and fire
to a :doc:`Smoke Domain &lt;/physics/smoke/types/domain&gt;` object.

To define any mesh object as a *Smoke Flow* object, add smoke physics by clicking *Smoke*
in :menuselection:`Properties --&gt; Physics`. Then select *Flow* as the *Smoke Type*.
Now you should have a default smoke flow source object. You can test this by playing the animation
:kbd:`Alt-A` from the first frame. If your source object is inside your domain, you should see smoke.

Settings
========

.. figure:: /images/physics_smoke_type_flow-object_settings.png
:align: right

Smoke Flow settings.

Flow Type
---------

Fire
Emit only fire. Note that the domain will automatically create some smoke to simulate smoke left by burnt fuel.
Smoke
Emit only smoke.
Fire + Smoke
Emit both fire and smoke.
Outflow
Remove smoke and fire. Note that the shape of the outflow will use the object's :term:`bounding box`.

Flow Source
-----------

Source
This setting defines the method used to emit smoke and fire.

Mesh
Create smoke/fire directly from the object's mesh.
With this option selected there two additional settings, *Surface* and *Volume*.

.. _smoke-flow-surface:

Surface
Maximum distance in voxels from the surface of the mesh in which smoke is created (see :term:`voxel`).
Since this setting uses voxels to determine distance,
results will vary depending on the domain's resolution.

Volume
Amount of smoke to emit inside the emitter mesh, where 0 is none and 1 is
Note that emitting smoke based on volume may have unpredictable results
if your mesh is :term:`non-manifold`.

Particle System
Create smoke/fire from a particle system on the flow object. Note that only *Emitter* type particle systems
can add smoke.
See :doc:`Particles &lt;/physics/particles/introduction&gt;` for information on how to create a particle system.

With this option selected there is a box to select a particle system and one addition setting, *Set Size*.

Set Size
When this setting is enabled it allows the *Size* setting to define
the maximum distance in voxels at which particles can emit smoke,
similar to the :ref:`*Surface* &lt;smoke-flow-surface&gt;` setting for mesh sources.

When disabled, particles will fill the nearest :term:`voxel` with smoke.

Initial Velocity
When enabled, smoke will inherit the momentum of the flow source.

Source
Multiplier for inherited velocity. A value of 1 will emit smoke moving at the same speed as the source.
Normal
When using a mesh source,
this option controls how much velocity smoke is given along the source's :term:`normal`.

Initial Values
--------------

Absolute Density
Maximum density of smoke allowed within range of the source.
Density
Amount of smoke to emit at once.

.. _smoke-flow-temp-diff:

Temperature Difference
Difference between the temperature of emitted smoke and the domain's ambient temperature.
This setting's effect on smoke depends on the domain's :ref:`Temperature Difference &lt;smoke-domain-temp-diff&gt;`.
Smoke Color
Color of emitted smoke. When smoke of different colors are mixed they will blend together,
eventually settling into a new combined color.

.. figure:: /images/physics_smoke_type_flow-object_color_blending.jpg

Flame Rate
Amount of "fuel" being burned per second. Larger values result in larger flames,
smaller values result in smaller flames:

.. figure:: /images/physics_smoke_type_flow-object_flame_rate.jpg

Example showing two fire sources.
The object on the left has a *Flame Rate* of 5, while the one on the right has 0.3.

Sampling: Subframes
Number of sub-frames used to reduce gaps in emission of smoke from fast-moving sources.

.. figure:: /images/physics_smoke_type_flow-object_subframes.jpg

Example showing two fast moving sources.
The object on the left uses 0 subframes, while the one on the right uses 6.

Smoke Flow Advanced
===================

.. figure:: /images/physics_smoke_type_flow-object_advanced.png
:align: right

When using a mesh as the *Flow Source*, you can use these settings to control where on the
mesh smoke can be emitted from. These settings have no effect on outflow objects.

Use Texture
When enabled, use the specified texture to control where smoke is emitted.

Vertex Group
When set, use the specified :doc:`Vertex Group &lt;/modeling/meshes/properties/vertex_groups/vertex_groups&gt;`
to control where smoke is emitted.

.. container:: lead

.. clear

Example
=======

These settings are useful for effects like this:

.. figure:: /images/physics_smoke_type_flow-object_texture_usecase.jpg
:align: center
:width: 500px

.. _smoke-types-index:

##############
Smoke Types
##############

.. toctree::
:maxdepth: 2

domain.rst
flow_object.rst
collisions.rst
..    TODO/Review: {{review|copy=X|text=partialy}}.

**********
Collisions
**********

There are two different collision types that you may use:
collision between different objects and internal collision.
We should set one thing straight from the start:
the primary targets of the collision calculation are the vertices of a Soft Body.
So if you have too few vertices too few collision takes place. Secondarily,
you can use edges and faces to improve the collision calculation.

Collisions with other objects
=============================

For a *Soft Body* to collide with another object there are a few prerequisites:

- If *Collision Group* is set, the object must belong to the group.
Otherwise, both objects have to share a layer, but the layer does not necessarily have to be visible.
- The collision object has to be a mesh object.
- You have to activate the option *Collision* in the *Collision* panel of the *Physics* tab
for the collision object. The collision object may also be a Soft Body.
- If you use modifiers such as *Array* and *Mirror* you have to activate *EV.M.Stack* to ensure
that collision calculation is based on the modified object. The sequence of *Modifiers* is not important.

Examples
--------

A cube colliding with a plane works pretty well Fig. :ref:`fig-softbody-collision-plane1`,
but a plane falls right through a cube that it is supposed to collide with
Fig. :ref:`fig-softbody-collision-plane2`. Why is that?
Because the default method of calculation only checks to see if the four vertices of
the plane collides with the cube as the plane is pulled down by gravity. You can activate
*CFace* to enable collision between the face of the plane and the object instead
Fig. :ref:`fig-softbody-collision-plane3`, but this type of calculation takes much longer.

Let us have a closer look at the collision calculation, so you can get an idea of how we might optimize it.

.. only:: builder_html

.. list-table::

* - .. _fig-softbody-collision-plane1:

.. figure:: /images/physics_soft-body_collision_cubeplane1.gif

A Soft Body cube colliding with a plane.

- .. _fig-softbody-collision-plane2:

.. figure:: /images/physics_soft-body_collision_cubeplane2.gif

A Soft Body plane colliding with a cube, so no interaction at all.

- .. _fig-softbody-collision-plane3:

.. figure:: /images/physics_soft-body_collision_cubeplane-cface.gif

Collision with Face activated.

.. only:: latex or epub

An example image can be found at:
https://docs.blender.org/manual/en/dev/physics/soft_body/collisions.html#examples

Calculating Collisions
----------------------

.. only:: builder_html

.. list-table::

* - .. _fig-softbody-collision-vertex:

.. figure:: /images/physics_soft-body_collision_vertex-plane1.gif

Visualization of the collision of a Soft Body vertex with a plane.

- .. _fig-softbody-collision-vertex2:

.. figure:: /images/physics_soft-body_collision_vertex-plane2.gif

Six Soft Body vertices with different speed.

`Blend file &lt;https://wiki.blender.org/index.php/Media:CollidingVertices.blend&gt;`__.

.. only:: latex or epub

An example image can be found at:
https://docs.blender.org/manual/en/dev/physics/soft_body/collisions.html#calculating-collisions

Soft Body simulation is by default done on a per vertex basis. If the vertices of the Soft Body
do not collide with the collision object, there will be no interaction between the two objects.

In Fig. :ref:`fig-softbody-collision-vertex` you can see a vertex colliding with a plane.
If a vertex penetrates the zone between *Outer* and *Inner*, it is repulsed by a force in
the direction of the face normal. The position that a vertex finally ends up in is dependent
on the forces that act upon it. In the example gravity and the repulsion force of the face balance out.
The speed at which the vertex is pulled out of the collision zone is influenced by the *Choke* parameter
Fig. :ref:`fig-softbody-collision-parameter`.

Now lets see what happens if we make vertices heavier and let them travel at a faster speed.
In Fig. :ref:`fig-softbody-collision-vertex2` you can see vertices traveling at different speeds.
The two on the far right (5 and 6) are traveling so fast that they pass right through the collision zone
(this is because of the default solver precision, which we can fix later). You will notice
that the fourth vertex also travels quite fast and because it is heavier it breaches the inner
zone. The first three vertices collide correctly.

.. _fig-softbody-collision-vertex3:

.. figure:: /images/physics_soft-body_collision_edges.png

Also Edges and Faces can be used for the collision calculation.

You can set up your collision so that edges and even faces are included in the collision calculation Fig.
:ref:`fig-softbody-collision-vertex3`. The collision is then calculated differently. It is checked whether
the edge or face intersects with the collision object, the collision zones are not used.

Good collisions
---------------

.. _fig-softbody-collision-parameter:

.. figure:: /images/physics_soft-body_collision_solver-parameters.png

Parameters for Soft Body calculation.

If the collision you have set up is not behaving properly, you can try the following:

.. tip:: The best way

Add *Loop Cuts* to your Soft Body object in strategic areas that you know are most likely to
be involved in a collision.

- The Soft Body object must have more subdivisions than the collision object.
- Check the direction of the face normals.
- If the collision object has sharp spikes they might penetrate the Soft Body.
- The resolution of the solver must match the speed at which Soft Body vertices are traveling.
Lower the parameter *Error Lim* and carefully increase *Min S*.
- *Outer* and *Inner* should be large enough, but zones of opposite faces should not overlap,
or you have forces in opposite directions.
- If you use strong forces you should use large zones.
- Set *Choke* to a high enough value (all the way up if necessary) if you have difficulties with repelled vertices.
- Colliding faces are difficult to control and need long calculation times. Try not to use them.

Often it is better to create a simplified mesh to use as your collision object,
however, this may be difficult if you are using an animated mesh.

Self Collision
==============

*Self Collision* is working only if you have activated *Use Edges*.

When enabled,
allows you to control how Blender will prevent the Soft Body from intersecting with itself.
Every vertex is surrounded with an elastic virtual ball.
Vertices may not penetrate the balls of other vertices.
If you want a good result you may have to adjust the size of these balls.
Normally it works pretty well with the default options.

Ball Size Calculation
Man ("manual")
The *Ball Size* directly sets the ball size (in BU).
Av ("average")
The average length of all edges attached to the vertex is calculated and then multiplied
with the *Ball Size* setting. Works well with evenly distributed vertices.
Min / Max
The ball size is as large as the smallest/largest spring length of the vertex multiplied with the *Ball Size*.
AvMiMax ("average min/max")
Size = ((Min + Max)/2) × *Ball Size*.

Ball Size
Default 0.49 BU or fraction of the length of attached edges.
The edge length is computed based on the algorithm you choose. You know how when someone stands too close to you,
and feel uncomfortable? We call that our "personal space",
and this setting is the factor that is multiplied by the spring length. It is a spherical distance (radius)
within which, if another vertex of the same mesh enters,
the vertex starts to deflect in order to avoid a self-collision.

Set this value to the fractional distance between vertices that you want them to have their own "space".
Too high of a value will include too many vertices all the time and slow down the calculation.
Too low of a level will let other vertices get too close and thus possibly intersect
because there will not be enough time to slow them down.

Stiffness
Default 1.0. How elastic that ball of personal space is.

Damping
Default 0.5. How the vertex reacts.
A low value just slows down the vertex as it gets too close. A high value repulses it.

Collisions with other objects are set in the (other) :doc:`Collision panel &lt;/physics/collision&gt;`.
To collide with another object they have to share at least one common layer.

********
Examples
********

Here are some simple examples showing the power of softbody physics.

A Bouncing Cube
===============

The Process
-----------

First, change your start and end frames to 1 and 150.

.. figure:: /images/physics_soft-body_examples_timeline.png
:width: 600px

The timeline.

Then, add a plane, and scale it five times. Next, go to the physics tab, and add a collision.
The default settings are fine for this example.

Now add a cube, or use the default cube, then enter *Edit Mode* to subdivide it three times.
Add a Bevel Modifier to it to smoothen the edges and then to add a little more,
press :kbd:`R` twice, and move your cursor a bit.

When finished, your scene should look like this:

.. figure:: /images/physics_soft-body_examples_scene-ready.png
:width: 400px

The scene, ready for softbody physics.

Everything is ready to add the softbody physics.
Go to :menuselection:`Properties --&gt; Physics` and choose *Softbody*.
Uncheck the soft body goal, and check softbody self collision.
Also, under soft body edges,increase the bending to 10.

Playing tha animation with :kbd:`Alt-A` will now give a slow animation of a bouncing cube.
To speed things up, we need to bake the softbody physics.

Under *Soft Body Cache* change the start and end values to your start and end frames. In this case 1 and 150.
Now, to test if everything is working, you can take a cache step of 5 or 10,
but for the final animation it is better to reduce it to 1, to cache everything.

When finished, your physics panel should look like this:

.. figure:: /images/physics_soft-body_examples_physics-settings.jpg
:width: 500px

The physics settings.

You can now bake the simulation, give the cube materials and textures and render the animation.

The Result
----------

The rendered bouncing cube:

.. only:: builder_html and (not singlehtml)

.. youtube:: 3PzgB9jw9iA

.. only:: not builder_html and (singlehtml)

A video can be found at https://www.youtube.com/watch?v=3PzgB9jw9iA

********
Exterior
********

Exterior forces are applied to the vertices (and nearly exclusively to the vertices)
of Soft Body objects. This is done using Newtons Laws of Physics:

- If there is no force on a vertex, it stays either unmoved or moves with constant speed in a straight line.
- The acceleration of a vertex depends on its mass and the force.
The heavier the mass of a vertex the slower the acceleration. The larger the force the greater the acceleration.
- For every action there is an equal and opposite reaction.

Well, this is done only in the range of computing accurateness,
there is always a little damping to avoid overshoot of the calculation.

Example
=======

We will begin with a very simple example: the default cube.

- To judge the effect of the external forces you should at first turn off the *Goal*,
so that the vertices are not retracted to their original position.
- Press :kbd:`Alt-A`.

What happens? The cube moves in negative Z-direction.
Each of its eight vertices is affected by a global, constant force -- the gravitation.
Gravitation without friction is independent from the weight of an object,
so each object you would use as a Soft Body here would fall with the same acceleration.
The object does not deform,
because every vertex moves with the same speed in the same direction.

Settings
========

Soft Body Panel
---------------

Friction
The friction of the surrounding medium.
The larger the friction, the more viscous is the medium.
Friction always appears when a vertex moves relative to its surround medium.

Mass
Mass value for vertices.
Larger mass slows down acceleration, except for gravity where the motion is constant regardless of mass.
Larger mass means larger inertia, so also braking a Soft Body is more difficult.

Mass Vertex Group
You can paint weight values for an mesh's mass, and select that vertex group here.

Speed
You can control the internal timing of the softbody system with this value.
It sets the correlation between frame rate and tempo of the simulation.
A free falling body should cover a distance of about five meters after one second.
You can adjust the scale of your scene and your simulation with this correlation. If you
render with 25 frames per second and 1 meter shall be 1 BU, you have to set *Speed* to 1.3.

Force Fields
------------

To create other forces you have to use another object,
often *Empty* objects are used for that.
You can use some of the forces on Soft Body vertices as on *Particles*.
Soft Bodies react only to:

- Spherical
- Wind
- Vortex

Soft bodies do react on *Harmonic* fields, but not in a useful way.
So if you use a *Harmonic* field for particles move the Soft body to another layer.

See the section :doc:`Force Fields &lt;/physics/force_fields/index&gt;` for details.
The force fields are quite strong,
a *Spherical* field with a strength of -1.0 has the same effect that gravity has --
approximately -- a force of 10 Newton.

Aerodynamics
------------

This special exterior force is not applied to the vertices but to the connecting edges.
Technically, a force perpendicular to the edge is applied.
The force scales with the projection of the relative speed on the edge (dot product). Note
that the force is the same if wind is blowing or if you drag the edge through the air with the
same speed. That means that an edge moving in its own direction feels no force,
and an edge moving perpendicular to its own direction feels maximum force.

Simple
Edges receive a drag force from surrounding media
Lift Force
Edges receive a lift force when passing through surrounding media.
Factor
How much aerodynamic force to use. Try a value of 30 at first.

Using a Goal
------------

A goal is a shape that a soft body object tries to conform to.

You have to confine the movement of vertices in certain parts of the mesh, e.g.
to attach a Soft Body object at other objects. This is done with the *Vertex Group*
(target). The target position is the original position of the vertex, like it would result
from the "normal" animation of an object including *Shape Keys*,
*Hooks* and *Armatures*.
The vertex tries to reach its target position with a certain, adjustable intensity.

.. _fig-softbody-force-exterior-shock:

.. figure:: /images/physics_soft-body_forces_exterior_shockabs.png
:width: 320px

Shock absorber description.

Imagine the vertex is connected with its target through a spring Fig. :ref:`fig-softbody-force-exterior-shock`.

Default
This parameter defines how strong the influence of this spring is. A strength of 1 means,
that the vertex will not move as Soft Body at all, instead keep its original position. 0 *Goal*
(or no *Goal*) means, that the vertex moves only according to Soft Body simulation.
If no vertex group is used/assigned, this number button is the default goal weight for all vertices.
If a vertex group is present and assigned,
this button instead shows an list field, that allows you to choose the name of the goal vertex group.
If you use a vertex group the weight of a vertex defines its goal.

Often :ref:`painting-weight-index` is used to adjust the weight comfortably.
For non-mesh objects the *Weight* parameter of their vertices/control points is used instead
(:kbd:`W` in *Edit Mode*) or use the *Transform* panel.
The weight of *Hair* particles can also be painted in :doc:`Particle Edit Mode &lt;/physics/particles/mode&gt;`.

Minimum / Maximum
When you paint the values in vertex-groups (using *WeightPaint Mode*),
you can use the *G Min* and *G Max* to fine-tune (clamp) the weight values.
The lowest vertex-weight (blue) will become *G Min*, the highest value
(red) becomes *G Max* (please note that the blue-red color scale may be altered by User Preferences).

.. tip:: For now all is applied to single vertices

For now we have discussed vertex movement independent of each other, similar to particles.
Every object without *Goal* would collapse completely if a non uniform force is applied.
Now we will move to the next step,
the forces that keep the structure of the object and make the Soft Body to a real Body.

Stiffness
The spring stiffness for Goal. A low value creates very weak springs
(more flexible "attachment" to the goal), a high value creates a strong spring
(a stiffer "attachment" to the goal).

Damping
The friction of the spring. With a high value the movement will soon come to an end (little jiggle).

#########
Forces
#########

.. toctree::
:maxdepth: 2

exterior.rst
interior.rst

********
Interior
********

.. _fig-softbody-force-interior-connection:

.. figure:: /images/physics_soft-body_forces_interior_theory-1.png
:width: 200px

Vertices and forces along their connection edges.

To create a connection between the vertices of a Soft Body object there have to be forces that
hold the vertices together. These forces are effective along the edges in a mesh,
the connections between the vertices. The forces act like a spring. Fig. :ref:`fig-softbody-force-interior-connection`
illustrates how a 3×3 grid of vertices (a mesh plane in Blender)
are connected in a Soft Body simulation.

But two vertices could freely rotate if you do not create additional edges between them.
Have you ever tried building a storage shelf out of four planks alone? Well, do not do it,
it will not be stable. The logical method to keep a body from collapsing would be to create
additional edges between the vertices. This works pretty well,
but would change your mesh topology drastically.

.. _fig-softbody-force-interior-stiff:

.. figure:: /images/physics_soft-body_forces_interior_theory-2.png
:width: 200px

Additional forces with Stiff Quads enabled.

Luckily, Blender allows to define additional *virtual* connections.
On one hand we can define virtual connections between the diagonal edges of a quad face
(*Stiff Quads* Fig. :ref:`fig-softbody-force-interior-stiff`), on the other hand we can define virtual connections
between a vertex and any vertices connected to its neighbors
*Bending Stiffness*. In other words, the amount of bend that is allowed between a
vertex and any other vertex that is separated by two edge connections.

Edges Settings
==============

The characteristics of edges are set with the *Soft Body Edge* properties.

Use Edges
Allow the edges in a Mesh Object to act like springs.

Pull
The spring stiffness for edges (how much the edges are allowed to stretch). A low value means very weak springs
(a very elastic material), a high value is a strong spring (a stiffer material) that resists being pulled apart.
0.5 is latex, 0.9 is like a sweater, 0.999 is a highly-starched napkin or leather.
The Soft Body simulation tends to get unstable if you use a value of 0.999,
so you should lower this value a bit if that happens.
Push
How much the softbody resist being scrunched together,
like a compression spring. Low values for fabric, high values for inflated objects and stiff material.
Damp
The friction for edge springs. High values (max of 50) dampen the *Push* / *Pull* effect and calm down the cloth.
Plastic
Permanent deformation of the object after a collision.
The vertices take a new position without applying the modifier.
Bending
This option creates virtual connections between a vertex and the vertices connected to its neighbors.
This includes diagonal edges. Damping also applies to these connections.
Length
The edges can shrink or been blown up. This value is given in percent,
0 disables this function. 100% means no change, the body keeps 100% of his size.

Stiff Quads
For quad faces, the diagonal edges are used as springs.
This stops quad faces to collapse completely on collisions (what they would do otherwise).
Shear
Stiffness of the virtual springs created for quad faces.

Preventing Collapse
-------------------

To show the effect of the different edge settings we will use two cubes
(blue: only quads, red: only tris) and let them fall without any goal onto a plane
(how to set up collision is shown on the page :doc:`Collisions &lt;/physics/soft_body/collisions&gt;`).

.. _fig-softbody-force-interior-without:

.. list-table:: Without Stiff Quads.

* - .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-001.png
:width: 200px

Frame 1.

- .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-036.png
:width: 200px

Frame 36.

- .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-401.png
:width: 200px

Frame 401.

In Fig. :ref:`fig-softbody-force-interior-without`, the default settings are used (without *Stiff Quads*).
The "quad only" cube will collapse completely, the cube composed of tris keeps its shape,
though it will deform temporarily because of the forces created during collision.

.. _fig-softbody-force-interior-with:

.. list-table:: With Stiff Quads.

* - .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-001.png
:width: 200px

Frame 1.

- .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-sq-036.png
:width: 200px

Frame 36.

- .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-sq-401.png
:width: 200px

Frame 401.

In Fig. :ref:`fig-softbody-force-interior-with`, *Stiff Quads* is activated (for both cubes).
Both cubes keep their shape, there is no difference for the red cube,
because it has no quads anyway.

.. _fig-softbody-force-interior-bending:

.. list-table:: Bending Stiffness.
`Blend file &lt;https://wiki.blender.org/index.php/Media:Blender3D Quads-BE-Stiffness.blend&gt;`__.

* - .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-001.png
:width: 200px

Frame 1.

- .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-bs-036.png
:width: 200px

Frame 36.

- .. figure:: /images/physics_soft-body_forces_interior_quadvstri-sb-bs-401.png
:width: 200px

Frame 401.

The second method to stop an object from collapsing is to change its *Bending Stiffness*.
This includes the diagonal edges (Damping also applies to these connections).

In Fig. :ref:`fig-softbody-force-interior-bending`, *Be* is activated with a strength setting of 1.
Now both cubes are more rigid.

.. list-table::

* - .. figure:: /images/physics_soft-body_forces_interior_quadvstri-bending-001.png
:width: 200px

Two planes going to collide.

- .. _fig-softbody-force-interior-no-bending:

.. figure:: /images/physics_soft-body_forces_interior_quadvstri-bending-101.png
:width: 200px

No bending stiffness, Frame 101.

- .. figure:: /images/physics_soft-body_forces_interior_quadvstri-bending-high-101.png
:width: 200px

High bending stiffness (10), Frame 101.

Bending stiffness can also be used if you want to make a subdivided plane more plank like.
Without *Be* the faces can freely rotate against each other like hinges
Fig. :ref:`fig-softbody-force-interior-no-bending`.
There would be no change in the simulation if you activated *Stiff Quads*,
because the faces are not deformed at all in this example.

Bending stiffness is the strength needed for the plane to be deformed.
.. _soft-body-index:

############
Soft Body
############

.. toctree::
:maxdepth: 2

introduction.rst
settings.rst
forces/index.rst
collisions.rst
examples.rst

************
Introduction
************

.. _fig-softbody-intro-cloth:

.. figure:: /images/physics_softbody_introduction_hidden-text.jpg
:width: 600px

A softbody cloth uncovering a text.

`Animation video &lt;https://vimeo.com/1865528&gt;`__ and
`Blend file &lt;https://wiki.blender.org/index.php/Media:HiddenTextExample.blend&gt;`__.

A Soft Body in general, is a simulation of a soft or rigid deformable object.
In Blender, this system is best for simple cloth objects and closed meshes.
There is dedicated :doc:`Cloth Simulation &lt;/physics/cloth/index&gt;` physics that use a different solver,
and is better for cloth.

This simulation is done by applying forces to the vertices or control points of the object.
There are exterior forces like gravity or forcefields and interior forces that hold the
vertices together.
This way you can simulate the shapes that an object would take on in reality if it had volume,
was filled with something, and was acted on by real forces.

Soft Bodies can interact with other objects trough *Collision*. They can interact with themselves
trough *Self Collision*.

The result of the Soft Body simulation can be converted to a static object.
You can also *bake edit* the simulation, i.e.
edit intermediate results and run the simulation from there.

Typical scenarios for using Soft Bodies
=======================================

.. _fig-softbody-intro-cone:

.. figure:: /images/physics_softbody_introduction_windcone.jpg
:width: 300px

A wind cone. The cone is a Soft Body, as the suspension.

`Animation &lt;https://vimeo.com/1865817&gt;`__ - `Blend file
&lt;https://wiki.blender.org/index.php/Media:WindConeExample.blend&gt;`__

Soft Bodies are well suited for:

- Elastic objects with or without collision.
- Flags, fabric reacting to forces.
- Certain modeling tasks, like a cushion or a table cloth over an object.
- Blender has another simulation system for clothing (see :doc:`Clothes &lt;/physics/cloth/index&gt;`).
But you can sometimes use Soft Bodies for certain parts of clothing, like wide sleeves.
- Hair (as long as you minimize collision).
- Animation of swinging ropes, chains and the like.

The following videos may give you some more ideas:

- https://www.youtube.com/watch?v=qdusMZlBbQ4
- https://www.youtube.com/watch?v=3du8ksOm9Fo&amp;hl

Creating a Soft Body
====================

Soft Body simulation works for all objects that have vertices or control points:

- Meshes.
- Curves.
- Surfaces.
- Lattices.

To activate the Soft Body simulation for an object:

- In the Properties editor, go to the *Physics* tab
(it is all the way on the right, and looks like a bouncing ball).
- Activate the *Soft Body* button.

A lot of options appear.
For a reference of all the settings see :doc:`this page &lt;/physics/soft_body/settings&gt;`.

- You start a Soft Body simulation with :kbd:`Alt-A`.
- You pause the simulation with :kbd:`Spacebar`, continue with :kbd:`Alt-A`.
- You stop the simulation with :kbd:`Esc`.

Simulation Quality
==================

The settings in the *Soft Body Solver* panel determine the accuracy of the
simulation.

Min Step
Minimum simulation steps per frame. Increase this value, if the Soft Body misses fast moving collision objects.
Max Step
Maximum simulation steps per frame.
Normally the number of simulation steps is set dynamically
(with the *Error Limit*) but you have probably a good reason to change it.
Auto-Step
Use Velocities for automatic step sizes.

Error Limit
Rules the overall quality of the solution delivered. Default 0.1.
The most critical setting that says how precise the solver should check for collisions.
Start with a value that is 1/2 the average edge length. If there are visible errors, jitter,
or over-exaggerated responses, decrease the value. The solver keeps track of how "bad" it is doing and the
*Error Limit* causes the solver to do some "adaptive step sizing".

Fuzzy
Simulation is faster, but less accurate.
Choke
Calms down (reduces the exit velocity of) a vertex or edge once it penetrates a collision mesh.

Diagnostics
-----------

Print Performance to Console
Prints on the console how the solver is doing.
Estimate Matrix
Estimate matrix. Split to ``COM``, ``ROT``, ``SCALE``

Cache and Bake
==============

Soft Bodies and other physic simulations use a unified system for caching and baking.
See :doc:`Particle Cache &lt;/physics/particles/emitter/cache&gt;` for reference.

The results of the simulation are automatically cached to disk when the animation is played,
so that the next time it runs,
it can play again quickly by reading in the results from the disk. If you *Bake* the
simulation the cache is protected and you will be asked when you are trying to change a setting
that will make a recalculating necessary.

.. tip:: Beware of the *Start* and *End* settings

The simulation is only calculated for the frames in-between the *Start* and *End* frames
(*Bake* panel), even if you do not actually bake the simulation!
So if you want a simulation longer than the default setting of 250 frames you have the change the *End* frame.

.. rubric:: Caching

- As animation is played, each physics system writes each frame to disk,
between the simulation start and end frames.
These files are stored in folders with prefix ``blendcache``, next to the blend-file.
- The cache is cleared automatically on changes. But not on all changes,
so it may be necessary to free it manually, e.g. if you change a force field.
Note that for the cache to fill up, one has to start playback before or on the frame that the simulation starts.
- If you are not allowed to write to the required sub-directory caching will not take place.
- The cache can be freed per physics system with a button in the panels,
or with the :kbd:`Ctrl-B` shortcut key to free it for all selected objects.
- You may run into trouble if your blend-file path is very long and your operating system
has a limit on the path length that is supported.

.. rubric:: Baking

- The system is protected against changes after baking.
- The *Bake* result is cleared also with
:kbd:`Ctrl-B` for all selected objects or click on *Free Bake* for the current Soft Body system.
- If the mesh changes the simulation is not calculated anew.

For renderfarms, it is best to bake all the physics systems,
and then copy the blendcache to the renderfarm as well.

Interaction in real time
========================

To work with a Soft Body simulation you will find it handy to use the Timeline editor.
You can change between frames and the simulation will always be shown in the actual state.
The option *Continue Physics* in the *Playback* menu
of the *Timeline* editor lets you interact in real time with the simulation,
e.g. by moving collision objects or shake a Soft Body object.

.. tip:: *Continue Physics* does not work while playing the animation with :kbd:`Alt-A`

Right. This works only if you start the animation with the *Play* button of the Timeline editor.

You can than select the Soft Body object while running the simulation and *Apply*
the modifier in the *Modifiers* tab of the Properties editor.
This makes the deformation permanent.

Tips
====

- Soft Bodies work especially well if the objects have an even vertex distribution.
You need enough vertices for good collisions. You change the deformation
(the stiffness) if you add more vertices in a certain region
(see the animation of Fig. :ref:`fig-softbody-intro-cone`).
- The calculation of collisions may take a long time. If something is not visible, why calculate it?
- To speed up the collision calculation it is often useful to collide with an additional,
simpler, invisible, somewhat larger object (see the example to Fig. :ref:`fig-softbody-intro-cloth`).
- Use Soft Bodies only where it makes sense.
If you try to cover a body mesh with a tight piece of cloth and animate solely with Soft Body,
you will have no success. Self collision of Soft Body hair may be activated,
but that is a path that you have to wander alone. We will deal with
:doc:`Collisions &lt;/physics/soft_body/collisions&gt;` in detail later.
- Try and use a *Lattice* or a *Curve Guide* Soft Body instead of the object itself. This may be magnitudes faster.
..    TODO/Review: {{review|im=add}}.

********
Settings
********

Soft Body
This creates the Soft Body Modifier on the selected object.
Render
Enable soft body during render.
Display
Display soft body in real time.

Soft Body
=========

Friction
The friction of the surrounding medium. Generally friction dampens a movement.
Mass
Mass value for vertices.
Larger mass slows down acceleration, except for gravity where the motion is constant regardless of mass.
Larger mass means larger inertia, so also braking a Soft Body is more difficult.
Vertex Group Mass
Use a specified vertex group for mass values.
Speed
You can control the internal timing of the Softbody system with this value.
Collision Group
If set, Soft Body collides with objects from the group, instead of using objects that are on the same layer.

Soft Body Cache
===============

.. note::

Caching and cache options are documented :doc:`Here &lt;/physics/baking&gt;`.

Soft Body Goal
==============

Use Goal
Soft Body Goal acts like a pin on a chosen set of vertices;
controlling how much of an effect soft body has on them.
Enabling this tells Blender to use the position / animated position of a vertex in the simulation.
Animating the vertices can be done in all the usual ways before the Soft Body simulation is applied.
The *goal* is the desired end-position for vertices.
How a softbody tries to achieve this goal can be defined using stiffness forces and damping.

Default
A *Goal* value of 1.0 means no Soft Body simulation, the vertex stays at its original (animated)
position. When setting *Goal* to 0.0, the object is only influenced by physical laws.
By setting goal values between 0.0 and 1.0,
you can blend between having the object affected only by the animation system,
and having the object affected only by the soft body effect.

Minimum / Maximum
When you paint the values in vertex-groups (using *Weight Paint Mode*),
you can use the *G Min* and *G Max* to fine-tune (clamp) the weight values.
The lowest vertex-weight (blue) will become *G Min*, the highest value (red) becomes *G Max*
(please note that the blue-red color scale may be altered by User Preferences).

Stiffness
The spring stiffness for *Goal*. A low value creates very weak springs
(more flexible "attachment" to the goal), a high value creates a strong spring
(a stiffer "attachment" to the goal).

Damping
The friction for *Goal*. Higher values dampen the effect of the goal on the soft body.

Vertex Group
Use a vertex group to allow per-vertex goal weights
(multiplied by the *Default* goal).

Soft Body Edges
===============

Use Edges
The edges in a Mesh Object can act as springs as well, like threads in fabric.

Pull
The spring stiffness for edges (how much the edges are stretched). A low value means very weak springs
(a very elastic material), a high value is a strong spring (a stiffer material) that resists being pulled apart.
0.5 is latex, 0.9 is like a sweater, 0.999 is a highly-starched napkin or leather.
Push
How much the softbody resist being scrunched together, like a compression spring. Low values for fabric,
high values for inflated objects and stiff material.
Damp
The friction for edge springs. High values (max of 50) dampen the edge stiffness effect and calm down the cloth.
Plastic
Plasticity, permanent deformation of the object.
Bending
This option creates virtual connections between a vertex and the one after the next. This includes diagonal edges.
Damping applies also to these connections.
Length
The edges can shrink or been blown up. This value is given in percent, 0 disables this function.
100% means no change, the body keeps 100% of his size.

Stiff Quads
For quad faces, the diagonal edges are used as springs.
This stops quad faces to collapse completely on collisions (what they would do otherwise).
Shear
Stiffness of the virtual springs for quad faces.

Aerodynamics
Simple
If you turn on *Aero* the force is not confined to the vertices, but has an effect also on the edges.
The angle and the relative speed between medium and edge is used to calculate the force on the edge.
This force results that vertices with little connecting edges (front of a plane)
fall faster than vertices with more connecting edges (middle of a plane).
If all vertices have the same amount of edges in a direction they fall with equal speed.
An edge moving in its own direction feels no force,
and an edge moving perpendicular to its own direction feels maximum force
(think of a straw moving through air). Try it with an *Factor* of 30 at first.

Lift Force
Use an aerodynamic model that is closer to physical laws and looks more interesting.
Disable for a more muted simulation.
Factor
How much aerodynamic effect to use

Edge
Checks for edges of the softbody mesh colliding.

Face
Checks for any portion of the face of the softbody mesh colliding (compute intensive!).
While *CFace* enabled is great, and solves lots of collision errors,
there does not seem to be any dampening settings for it,
so parts of the softbody object near a collision mesh tend to "jitter" as they bounce off and fall back,
even when there is no motion of any meshes. Edge collision has dampening, so that can be controlled,
but Deflection dampening value on a collision object does not seem to affect the face collision.

Soft Body Self Collision
========================

.. note::

*Self Collision* is working only if you have activated *Use Edges*.

Self Collision
When enabled, allows you to control how Blender will prevent the Soft Body from intersecting with itself.
Every vertex is surrounded with an elastic virtual ball.
Vertices may not penetrate the balls of other vertices.
If you want a good result you may have to adjust the size of these balls.
Normally it works pretty well with the default options.

Manual
The *Ball Size* directly sets the ball size (in BU).
Average
The average length of all edges attached to the vertex is calculated and then multiplied
with the *Ball Size* setting. Works well with evenly distributed vertices.
Minimal / Maximal
The ball size is as large as the smallest/largest spring length of the vertex multiplied with the *Ball Size*.
Average Min Max
Size = ((Min + Max)/2) × *Ball Size*.

Size
Default 0.49 BU or fraction of the length of attached edges.
The edge length is computed based on the algorithm you choose.
You know how when someone stands too close to you, and feel uncomfortable?
We call that our "personal space", and this setting is the factor that is multiplied by the spring length.
It is a spherical distance (radius) within which, if another vertex of the same mesh enters,
the vertex starts to deflect in order to avoid a self-collision.
Set this value to the fractional distance between vertices that you want them to have their own "space".
Too high of a value will include too many vertices all the time and slow down the calculation.
Too low of a level will let other vertices get too close and thus possibly intersect because
there will not be enough time to slow them down.

Stiffness
Default 1.0. How elastic that ball of personal space is.

Dampening
Default 0.5. How the vertex reacts.
A low value just slows down the vertex as it gets too close. A high value repulses it.

Collisions with other objects are set in the (other) :doc:`Collision panel &lt;/physics/collision&gt;`.
To collide with another object they have to share at least one common layer.

Soft Body Solver
================

These settings determine the accurateness of the simulation.

Min Step
Minimum simulation steps per frame. Increase this value, if the Soft Body misses fast moving collision objects.

Max Step
Maximum simulation steps per frame.
Normally the number of simulation steps is set dynamically
(with the *Error Limit*) but you have probably a good reason to change it.

Auto-Step
helps the Solver figure out how much work it needs to do based on how fast things are moving.

Error Limit
Rules the overall quality of the solution delivered. Default 0.1.
The most critical setting that says how precise the solver should check for collisions.
Start with a value that is 1/2 the average edge length.
If there are visible errors, jitter, or over-exaggerated responses, decrease the value.
The solver keeps track of how "bad" it is doing and the *Error Limit* causes the solver to
do some "adaptive step sizing".

Fuzzy
Fuzziness while on collision, high values make collision handling faster but less stable.

Choke
Calms down (reduces the exit velocity of) a vertex or edge once it penetrates a collision mesh.

Print Performance to Console
Prints on the console how the solver is doing.
Estimate Matrix
Estimate matrix... split to COM, ROT, SCALE
.. _pipeline-index:

##########
Pipeline
##########

This section of the manual focuses on the integration of Blender into a production pipeline.
This is a vast topic that covers many areas of the software,
but here we will focus on file/asset management and data I/O.

.. note::

The tools and workflows documented here require familiarity with working
with a command line interface and are mostly aimed at TDs and technical users.

BAM Asset Manager
=================

Refactoring linked .blend files is a common practice in a production environment.
While some basic operations can be accomplished within Blender,
sometimes it is more practical to perform them on the command line or via a script.
During the production of Cosmos Laundromat (Gooseberry Open Movie Project)
the *BAM Asset Manager* (BAM) was developed. The original scope of BAM included
client-server asset management tools going beyond Blender,
but it was later refocused on core utilities to perform two operations:

- Blend-file packing
- Automatic dependencies remapping

The following section of the manual focuses on how to use BAM.

.. figure:: /images/pipeline_tools_bam.png

Installing BAM
--------------

BAM is a standalone Python package, that can be run on any system without any particular configuration.
The only requirement is Python 3 (and pip, the Python package manager, to easily install BAM).

Windows, Linux and macOS provide different ways to install Python 3 and pip.
Check out the online docs to learn more about a specific platform.

Once Python 3 and pip are available, BAM can be installed via command line by typing:

.. code-block:: bash

pip3 install blender-bam

After a successful installation, the `bam` command will be available.
By typing it and pressing the Enter key, all the available subcommands will be displayed.

bam pack
--------

This command is used for packing a ``.blend`` file and *all*
its dependencies into a ``.zip`` file for redistribution. ::

usage: bam pack [-h] [-o FILE] [-m MODE] [-e PATTERNS] [-a] [-q] [-c LEVEL]
paths [paths ...]

You can simply pack a blend file like this to create a zip-file of the same name.

.. code-block:: sh

bam pack /path/to/scene.blend

You may also want to give an explicit output directory.
The example shows how to pack a blend with maximum compression for online downloads

.. code-block:: sh

bam pack /path/to/scene.blend --output my_scene.zip --compress=best

The command provides several options to adapt to different workflows
(final distribution, partial extraction, rendering).

``-o``, ``--output`` ``&lt;FILE&gt;``
Output file or a directory when multiple inputs are passed.
``-m``, ``--mode`` ``&lt;MODE&gt;``
Output file or a directory when multiple inputs are passed. Possible choices: ``ZIP``, ``FILE``.
``-e``, ``--exclude`` ``&lt;PATTERN(S)&gt;``
Optionally exclude files from the pack.

``--exclude="*.png"``
Using Unix shell-style wildcards *(case insensitive)*.
``--exclude="*.txt;*.avi;*.wav"``
Multiple patterns can be passed using the ``;`` separator.
``-a``, ``--all-deps``
Follow all dependencies (unused indirect dependencies too).
``-q``, ``--quiet``
Suppress status output.
``-c``, ``--compress`` ``&lt;LEVEL&gt;``
Compression level for resulting archive.
Possible choices: ``default``, ``fast``, ``best``, ``store``.
``--repo`` ``&lt;DIR PATH&gt;``
Specify a "root" path from where to pack the selected file.
This allows for the creation of a sparse copy of the production tree, without any remapping.
``--warn-external``
Report external libraries errors (missing paths).

Examples
^^^^^^^^

Consider the following directory layout,
and in particular the file *01_01_A.lighting.blend* with its linked libraries.

.. code-block:: none

~/agent327/
└─ lib/
├─ chars/
|  ├─ agent.blend  -------------&gt;|
|  ├─ boris.blend  -------------&gt;|
|  └─ barber.blend               |
└─ scenes/                       |
├─ 01-opening                 |
├─ 01_01_A.lighting.blend  &lt;--|  &lt; BAM pack this file
└─ 01_01_A.anim.blend  ------&gt;|

Once we run ``bam pack /scenes/01-opening/01_01_A.lighting.blend``
we obtain a *01_01_A.lighting.zip* inside of which we find the following structure.

.. code-block:: none

~/01_01_A.lighting
├─ 01_01_A.lighting.blend
└─ __/
├─ 01_01_A.anim.blend
└─ __/
└─ lib/
└─ chars/
├─ agent.blend
└─ boris.blend

Note how all paths have been remapped relative to the placement
of *01_01_A.lighting.blend* in the root of the output.
If we run ``bam pack /scenes/01-opening/01_01_A.lighting.blend --repo ~/agent327``,
the output will be different.

.. code-block:: none

~/01_01_A.lighting
├─ lib/
|  └─ chars/
|     ├─ agent.blend
|     └─ boris.blend
└─ scenes
└─ 01-opening/
├─ 01_01_A.lighting.blend  &lt; The BAM packed file
└─ 01_01_A.anim.blend

In this case no path is remapped, and we simply strip out any file
that is not referenced as a direct or indirect dependency of *01_01_A.lighting.blend*.
This is effectively a sparse copy of the original production tree.

bam remap
---------

Remap blend file paths::

usage: bam remap [-h] {start,finish,reset} ...

This command is a three step process:

#. First run ``bam remap start .`` which stores the current state of your project (recursively).
#. Then re-arrange the files on the filesystem (rename, relocate).
#. Finally run ``bam remap finish`` to apply the changes, updating the ``.blend`` files internal paths.

.. code-block:: sh

cd /my/project

bam remap start .
mv photos textures
mv barbershop_v14_library.blend barberhop_libraray.blend
bam remap finish

.. note::

Remapping creates a file called ``bam_remap.data`` in the current directory.
You can relocate the entire project to a new location but on executing ``finish``,
this file must be accessible from the current directory.

.. note::

This command depends on files unique contents,
take care not to modify the files once remap is started.

Subcommands
^^^^^^^^^^^

remap start
"""""""""""

Start remapping the blend files::

usage: bam remap start [-h] [-j] [paths [paths ...]]

``-j``, ``--json``
Generate JSON output.

remap finish
""""""""""""

Finish remapping the blend files::

usage: bam remap finish [-h] [-r] [-d] [-j] [paths [paths ...]]

``-r``, ``--force-relative``
Make all remapped paths relative (even if they were originally absolute).
``-d``, ``--dry-run``
Just print output as if the paths are being run.
``-j``, ``--json``
Generate JSON output.

remap reset
"""""""""""

Cancel path remapping::

usage: bam remap reset [-h] [-j]

``-j``, ``--json``
Generate JSON output.

*******
Add-ons
*******

The Add-ons tab lets you manage secondary scripts, called "Add-ons" that extends Blender's functionality.
In this tab you can search, install, enable and disable Add-ons.

.. figure:: /images/preferences_addons_tab.png

Add-ons tab in the User Preferences.

Searching
=========

Blender comes with some useful Add-ons already, ready to be enabled. But you can also add your own,
or any interesting ones you find on the web.

Filtering
---------

Supported Level
Blender's add-ons are split into two groups depending on who writes/supports them:

- Official: Add-ons that are written by Blender developers.
- Community: Add-ons that are written by people in the Blender community.

Categories
Add-ons are divided into categories by what areas of Blender they affect.

Enabling and Disabling
======================

Enable and disable an add-on by checking or unchecking the box on the right of the add-on you chose,
as shown in the figure.

.. figure:: /images/preferences_addons-enable.png

Enabling an Add-on.

The add-on functionality should be immediately available.
If the Add-on does not activate when enabled,
check the :doc:`Console window &lt;/advanced/command_line/introduction&gt;`
for any errors, that may have occurred.

.. This could use a better title

Add-on Information
==================

You can click the arrow at the left of the add-on box to see more information, such as
its location, a description and a link to the documentation.
Here you can also find a button to report a bug specific of this add-on.

.. tip:: Saving Add-on Preferences

If you want an Add-on to be enabled every time you start Blender,
you will need to *Save User Settings*.

.. _user-prefs-addons-prefs:

Add-on Preferences
------------------

Individual Activation
^^^^^^^^^^^^^^^^^^^^^

Add-ons that activate or change multiple hotkeys now have a special system of activation.
For example, with the "UI: Pie Menu Official" add-on
for each menu there's a selection box to activate the menu and its hotkey.

With Pie menus, First you activate the add-on. This activates the "Add-ons Preferences Submodule Activation".
You then need to expand the Add-ons Preferences, then you will see the list of Pie Menu types you can choose from.
From here you can individually activate the menus you like to use.
If the menu conflicts with another favorite, there's no need to activate it.
You can activate any combination &amp; save as user settings
so your activations are available next time you start Blender.

Header
======

Install from File
For add-ons that you found on the web or your own to show on the list, you have to install them first
by clicking *Install from File...* and providing a ``.zip`` or ``.py`` file.

Now the add-on will be installed, not automatically enabled.
The search field will be set to the add-on's name (to avoid having to look for it).
Enable the add-on by turning on the check-box.

Refresh
Scans the :doc:`Add-on Directory &lt;/getting_started/installing/configuration/directories&gt;` for new add-ons.

Online Resources
This menu contains a list of helpful links for both users
and people who are interested in writing their own add-on.

`Scripts Catalog &lt;https://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts&gt;`__
Provides an index of Add-ons that are included with Blender as well as listing a number of external Add-ons.

`How to share your add-on &lt;https://wiki.blender.org/index.php/Dev:Doc/Process/Addons&gt;`__
Information on how to get your add-on into Blender.
`Add-ons development guidelines &lt;https://wiki.blender.org/index.php/Dev:Py/Scripts/Guidelines/Addons&gt;`__
Guidelines on writing new add-on that you might want to get into Blender.
`API Concepts &lt;https://www.blender.org/api/blender_python_api_current/info_quickstart.html&gt;`__
A quick introduction to Blender's API.
`Add-on Tutorial &lt;https://www.blender.org/api/blender_python_api_current/info_tutorial_addon.html&gt;`__
A quick tutorial on the essentials of writing an add-on.

.. tip:: User Defined Add-on Path

You can also create a personal directory containing new add-ons and configure your files path in
the *File* tab of the *User Preferences*. To create a personal script directory:

#. Create an empty directory in a location of your choice (e.g. ``my_scripts``).
#. Add a subdirectory under ``my_scripts`` called ``addons``
(it *must* have this name for Blender to recognize it).
#. Open the *File* tab of the *User Preferences*.
#. Set the *Scripts* in the User Preferences to point to your script directory (e.g. ``my_scripts``).
#. Save the User Preferences and restart Blender for it to recognize the new add-ons location.

Now when you install add-ons you can select the *Target Path* option to *User Pref*
(from the *File* tab).

Blender will copy newly installed add-ons under the directory selected in your User Preferences.

*******
Editing
*******

These preferences control how several tools will interact with your input.

.. figure:: /images/preferences_editing_tab.png

Link Materials To
=================

.. figure:: /images/preferences_editing_data-blocks-hierarchy.png

Example for a Mesh.

To understand this option properly, you need to understand how Blender works with Objects.
Almost everything in Blender is organized in a hierarchy of data-blocks.
A data-block can be thought of as containers for certain pieces of information. For example,
the Object data-block contains information about the Object's location while the Object Data
"ObData" data-block contains information about the mesh.

A material may be linked in two different ways:

.. figure:: /images/preferences_editing_data-blocks-link.png

A material linked to Object Data (left) and Object (right).

Object Data
Any created material will be created as part of the Object Data data-block.
Object
Any created material will be created as part of the Object data-block.

:doc:`Read more about Blender's Data System &lt;/data_system/index&gt;`

New Objects
===========

Enter Edit Mode
If selected, Edit Mode is automatically activated when you create a new object.
Align To
World
New objects align with world coordinates.
View
New object align with view coordinates.

Undo
====

Global Undo
This enables Blender to save actions done when you are **not** in *Edit Mode*.
For example, duplicating Objects, changing panel settings or switching between modes.

.. warning::

While disabling this option does save memory, it stops the :ref:`Redo Panel &lt;ui-redo-last&gt;`
from functioning, also preventing tool options from being changed in some cases.

For typical usage, its best to keep this enabled.
Steps
Number of Undo steps available.
Memory Limit
Maximum memory usage in Mb (0 is unlimited).

:doc:`Read more about Undo and Redo options &lt;/interface/undo_and_redo&gt;`

Grease Pencil
=============

Eraser Radius
The size of the eraser used with the grease pencil.

Manhattan Distance
The minimum number of pixels the mouse should have moved either
horizontally or vertically before the movement is recorded.
Decreasing this should work better for curvy lines.
Euclidian Distance
The minimum distance that mouse has to travel before movement is recorded.

Simplify Stroke
This turns on the post-processing step of simplifying the stroke to remove about half of current points in it.
It is only relevant when not drawing straight lines.

Default Color
The default color for new Grease Pencil layers.

:doc:`Read more about Grease Pencil &lt;/interface/grease_pencil/index&gt;`

Playback
========

Allow Negative Frame
Time Cursor can be set to negative frames with mouse or keyboard.
When using *Use Preview Range*, this also allows playback.

Node Editor
===========

Auto-offset Margin
Margin to use for :ref:`offsetting nodes &lt;editors-nodes-usage-auto-offset&gt;`.

Animation Editors
=================

F-Curve Visibility
Opacity that un-selected :doc:`F-Curves &lt;/editors/graph_editor/fcurves/index&gt;`
stand out from the *Graph Editor*.

Keyframing
==========

In many situations, animation is controlled by keyframes. The state of a value (e.g. location)
is recorded in a keyframe and the animation between two keyframes is interpolated by Blender.

Visual Keying
When an object is using constraints, the object property value does not actually change.
*Visual Keying* will add keyframes to the object property,
with a value based on the visual transformation from the constraint.
Only Insert Needed
This will only insert keyframes if the value of the property is different.
Auto Keyframing
Enables *Auto Keyframe* by default for new scenes.
Show Auto Keying Warning
Displays a warning at the top right of the *3D View*, when moving objects, if *Auto Keyframe* is on.
Only Insert Available
This will only add keyframes to channel F-Curves that already exist.

New F-Curve Defaults
====================

Interpolation
Controls the default :ref:`Interpolation &lt;editors-graph-fcurves-settings-interpolation&gt;`
for newly created keyframes.
Handles
Controls the default :ref:`Handle &lt;editors-graph-fcurves-settings-handles&gt;` for newly created F-Curves.
XYZ to RGB
Color for X, Y or Z animation curves (location, scale or rotation)
is the same as the color for the X, Y and Z axis.

Transform
=========

Release confirms
Dragging :kbd:`LMB` on an object will move it.
To confirm this (and other) transforms, a :kbd:`LMB` is necessary by default.
When this option is activated, the release of :kbd:`LMB` acts as confirmation of the transform.

Sculpt Overlay Color
====================

This color button allows the user to define a color to be used in the inner part of the
brushes circle when in sculpt mode, and it is placed as an overlay to the brush,
representing the focal point of the brush influence.
The overlay color is visible only when the overlay visibility is selected
(clicking at the *eye* to set its visibility), and the transparency of the overlay is
controlled by the alpha slider located at the :menuselection:`Option tab --&gt; Overlay panel`
in the tool shelf.

.. _prefs-editing-duplicate-data:

Duplicate Data
==============

The *Duplicate Data* check-boxes define what data is copied with a duplicated Object and what
data remains linked. Any boxes that are checked will have their data copied along with the
duplication of the Object. Any boxes that are not checked will instead have their data linked
from the source Object that was duplicated.

For example, if you have Mesh checked,
then a full copy of the mesh data is created with the new Object,
and each mesh will behave independently of the duplicate.
If you leave the mesh box unchecked then when you change the mesh of one object,
the change will be mirrored in the duplicate Object.

The same rules apply to each of the check-boxes in the 'Duplicate Data' list.

****
File
****

The *File* tab in *User Preferences* allows you to configure auto-save preferences and set default file paths for
blend-files, rendered images, and more.

.. figure:: /images/preferences_file_tab.png

.. _prefs-file-paths:

File Paths
==========

Locations for various external files can be set for the following options:

Fonts
Default location when searching for font files.
Textures
Default location when searching for image textures.
Render Output
Where rendered images/videos are saved.
Scripts
An additional location to search for Python scripts. See `Scripts Path`_ below.
Sounds
Default location when searching for sound files.
Temp
The location where temporary files are stored.
Render Cache
The location where cached render images are stored.
I18n Branches
The path to the ``/branches`` directory of your local svn-translation copy, to allow translating from the UI.
Image Editor
The path to an external program to use for image editing.
Animation Player
The path to an external program to use for playback of rendered animations.

.. note:: If these folders do not exist, they will *not* be created automatically.

Scripts Path
------------

By default Blender looks in several directories (OS dependant) for scripts.
By setting a user script path in the preferences an additional directory is looked in. This
can be used to store certain scripts/templates/presets independently of the currently used
Blender Version.

Inside the specified folder, specific subfolders have to be created to tell Blender what to look
for where. This folder structure has to mirror the structure of the scripts folder found in
the installation directory of Blender:

- scripts
- add-ons
- modules
- presets
- camera
- cloth
- interface_theme
- operator
- render
- ...
- startup
- templates
Not all of the folders have to be present.

.. warning::

Be sure that you have the right privileges for running the executable accessing the path defined.
On MS-Windows for instance, if the option "Run this program as an administrator" is enabled for the executable,
it will lead to a failure to open the editor due to a limitation within the OS User Account Control.
Running a program with elevated privileges is potentially dangerous!

.. _prefs-auto-execution:

Auto Execution
==============

Python scripts (including driver expressions) are not executed by default for security reasons.

Auto Run Python Scripts
You may choose to ignore these security issues and allow scripts to be executed automatically.
Excluded Paths
Blend files in these folders will *not* automatically run Python scripts.
This can be used to define where blend-files from untrusted sources are kept.

.. seealso::

:doc:`Python Security &lt;/advanced/scripting/security&gt;`

.. _prefs-save-load:

Save &amp; Load
===========

Relative Paths
By default, external files use a :doc:`relative path &lt;/data_system/files/relative_paths&gt;`.
Compress File
Compress blend-file when saving.

This option will compact your files whenever Blender is saving them.
Dense meshes, large packed textures or lots of elements in your scene
will result in a large blend being created.

This option may slow down Blender when you quit,
or under normal operation when Blender is saving your backup files.
Using this option traces processor time for file-size.
Load UI
Default setting is to load the Window layout
(the :doc:`Screens &lt;/interface/window_system/screens&gt;`) of the saved file.
This can be changed individually when loading a file from the
*Open blend-file* panel of the :doc:`File Browser &lt;/editors/file_browser/index&gt;`.
Filter File Extensions
By activating this, the file region in the File Browser will only show appropriate files
(i.e. blend-files when loading a complete Blender setting).
The selection of file types may be changed in the file region.

.. figure:: /images/preferences_file-filefilter.png

File extension filter.

Hide Dot File/Data-blocks
Hide file which start with ``.`` on file browsers (in Linux and Apple systems, ``.`` files are hidden).
Hide Recent Locations
Hide the *Recent* panel of the :doc:`File Browser &lt;/editors/file_browser/index&gt;`
which displays recently accessed folders.
Hide System Bookmarks
Hide System Bookmarks in the *File Browser*.
Show Thumbnails
Display a thumbnail of images and movies when using the :doc:`File Browser &lt;/editors/file_browser/index&gt;`.

Save Versions
Number of versions created for the same file (for backup).

This option tells Blender to keep the indicated number of saved versions of your file in your current working
directory when you manually save a file.
These files will have the extension: ``.blend1``, ``.blend2``, etc.,
with the number increasing to the number of versions you specify. Older files will be named with a higher number.
e.g. With the default setting of 2, you will have three versions of your file: ``*.blend`` (your last save),
``*.blend1`` (your second last save) and ``*.blend2`` (your third last save).
Recent Files
Number of files displayed in :menuselection:`File --&gt; Open Recent`.
Save Preview Images
Previews of images and materials in the :doc:`File Browser &lt;/editors/file_browser/index&gt;`
are created on demand. To save these previews into your blend-file,
enable this option (at the cost of increasing the size of your blend-file).

.. _prefs-auto-save:

Auto Save
=========

Keep Session
Always saves the blend-file after quiting Blender and reloads it after re-starting Blender.

Auto Save Temporary Files
Enable Auto Save (create a temporary file).

Checking this box tells Blender to *automatically* save a backup copy of your work-in-progress to the Temp
directory (refer to the *File* tab in the *User Preferences* for its location).

The Auto Saved files are named using a random number and have a blend extension.
Timer
Time to wait between automatic saves.

This specifies the number of minutes between each Auto Save.
The default value of the Blender installation is 5 (5 minutes).
The minimum is 1, and the Maximum is 60 (Save at every one hour).

:doc:`Read more about Auto Save options &lt;/troubleshooting/recover&gt;`.

Text Editor
===========

Tabs as Spaces
When hitting :kbd:`Tab` the tabs get written as keyboard spaces.
Author
Name that will be used in exported files when the format supports such feature.
.. _prefs-index:

###################
User Preferences
###################

.. toctree::
:maxdepth: 2

introduction.rst

Tabs
====

.. toctree::
:maxdepth: 1

interface.rst
editing.rst
input.rst
addons.rst
themes.rst
file.rst
system.rst

*****
Input
*****

In the Input preferences, you can customize how Blender reacts to the mouse and keyboard as
well as define your own keymap.

.. figure:: /images/preferences_input_tab.png

Interaction
===========

Interaction Presets
Presets that allow Blender to act like other software on your personal preference.

Mouse
-----

Emulate 3 Button Mouse
Blender can be configured to work with pointing devices which do not have a :kbd:`MMB`
(such as a two-button mouse, Apple's single-button mouse, or laptop touch-pad).
The functionality of the three mouse buttons will then be emulated with
key/mouse button combinations as shown in the table below.

.. list-table:: Shortcuts for supported mouse hardware
:header-rows: 1
:class: valign
:widths: 25 25 50

* - 3-button Mouse
- 2-button Mouse
- Apple Mouse
* - :kbd:`LMB`
- :kbd:`LMB`
- :kbd:`LMB` (mouse button)
* - :kbd:`MMB`
- :kbd:`Alt-LMB`
- :kbd:`Alt-LMB` (Option/Alt key + mouse button)
* - :kbd:`RMB`
- :kbd:`RMB`
- :kbd:`Cmd-LMB` (Command/Apple key + mouse button)

Mouse/Keyboard combinations referenced in this manual
can be expressed with the combinations shown in the table. For example:

- :kbd:`MMB` drag becomes :kbd:`Alt-LMB` drag.
- :kbd:`Shift-Alt-RMB` becomes :kbd:`Shift-Alt-Cmd-LMB` on a single-button mouse.

.. _prefs-input-continuous-grab:

Continuous Grab
This feature is used to prevent the problem where an action such as grabbing or panning a view,
is limited by your screen bounds.

This is done by warping the mouse within the view.

.. note::

Cursor warping is only supported by *relative* input devices (mouse, trackball, trackpad).

Graphics tablets, however, typically use *absolute* positioning,
this feature is disabled when a tablet is being used.

This is detected for each action,
so the presence of a tablet will not disable *Continuous Grab* for mouse cursor input.

Drag Threshold
The number of pixels that a User Interface element has to be moved before it is recognized by Blender.
Select With
You can choose which button is used for selection (the other one is used to place the 3D cursor).
Double Click
The time in ms for a double click to be recognized.

.. note::

The Mouse emulate option is only available if *Select With* is set to *Right*.

Numpad Emulation
----------------

The Numpad keys are used quite often in Blender and are not the same keys as the regular
number keys. If you have a keyboard without a Numpad (e.g. on a laptop),
you can tell Blender to treat the standard number keys as Numpad keys.
Just check *Emulate Numpad*.

View Manipulation
-----------------

.. _prefs-input-orbit-style:

Orbit Style
Select how Blender works when you rotate the 3D View by default when holding :kbd:`MMB`.

Turntable
Rotates the view keeping the horizon horizontal.

This behaves like a potter's wheel or record player where you have two axes of rotation available,
and the world seems to have a better definition of what is "Up" and "Down" in it.

The drawback to using the *Turntable* style is that you lose some flexibility when working with your objects.
However, you gain the sense of "Up" and "Down" which can help if you are feeling disoriented.
Trackball
Is less restrictive, allowing any orientation.
Zoom Style
Choose your preferred style of zooming in and out with :kbd:`Ctrl-MMB`

Scale
*Scale* zooming depends on where you first click in the view.
To zoom out, hold :kbd:`Ctrl-MMB` while dragging from the edge of the screen towards the center.
To zoom in, hold :kbd:`Ctrl-MMB` while dragging from the center of the screen towards the edge.
Continue
The *Continue* zooming option allows you to control the speed
(and not the value) of zooming by moving away from the initial click point with :kbd:`Ctrl-MMB`.
Moving up from the initial click-point or to the right will zoom out,
moving down or to the left will zoom in. The further away you move,
the faster the zoom movement will be.
The directions can be altered by the *Vertical* and *Horizontal* radio buttons and the
*Invert Zoom Direction* option.
Dolly
*Dolly* zooming works similarly to *Continue* zooming except that zoom speed is constant.
Zoom Axis
The axis of the :kbd:`MMB` to use for zooming.

Vertical
Moving up zooms out and moving down zooms in.
Horizontal
Moving left zooms in and moving right zooms out.
Invert Zoom Direction
Inverts the Zoom direction for *Dolly* and *Continue* zooming.
Invert Wheel Zoom Direction
Inverts the direction of the mouse wheel zoom.

View Navigation
---------------

Navigation Mode
The default navigation mode for :kbd:`Shift-F` in the 3D View.

Walk
^^^^

Reverse Mouse
Inverts the mouse's Y movement.

Mouse Sensitivity
Speed factor for when looking around, high values mean faster mouse movement.

Teleport Duration
Interval of time warp when teleporting in navigation mode.

Walk Speed
Base speed for walking and flying.
Speed Factor
The multiplication factor for the speed boost.

Gravity
Simulates the effect of gravity when walking.

View Height
The distance from the ground floor to the camera when walking.
Jump Height
The maximum height of a jump.

Fly
^^^

There are no additional options for fly mode.

NDOF Device
-----------

Pan Sensitivity
The overall sensitivity for panning in the 3D View.
Orbit Sensitivity
The overall sensitivity for orbiting in the 3D View.
Deadzone
The threshold for the amount of movement needed from
the device's rest position for Blender to interrupt that movement.

Navigate Method
Navigation style for the viewport.

Free
Uses the full 6-degrees of freedom.
Orbit
Orbit about the view center.

Rotate Method
Rotation style for the viewport.

Turntable
Rotates the view keeping the horizon horizontal.
Trackball
Is less restrictive, allowing any orientation.

.. _prefs-input-keymap-editor:

Keymap Editor
=============

The Keymap editor lets you change the default Hotkeys. You can change keymaps for each of Blender's editors.

.. figure:: /images/preferences_input_keymap-editor.png

Keymap Editor.

Keymap Presets
A list of predefined keymaps.

#. Select the keymap you want to change and click on the white arrows to open up the keymap tree.
#. Select which Input will control the function.

- Keyboard: Only hotkey or combo hotkey :kbd:`E`, :kbd:`Shift-E`.
- Mouse: Left/middle/right click. Can be combined with :kbd:`Alt`, :kbd:`Shift`, :kbd:`Ctrl`, :kbd:`Cmd`.
- NDOF: ToDo.
- Tweak: Click and drag. Can also be combined with the four previous keys.
- Text input: Use this function by entering a text.
- Timer: Used to control actions based on a time period.
e.g. By default, *Animation Step* uses "Timer 0", *Smooth View* uses "Timer 1".

#. Change hotkeys as you want. Just click on the shortcut input and enter the new shortcut.

If you want to restore the default settings for a keymap,
just click on the *Restore* button at the top right of this keymap.

.. tip::

Instead of deleting the default keymap to create yours,
you can just add a new *Preset* for both the mouse and keyboard.

Export/Import Key Configuration
===============================

In some cases, you may need to save your configuration in an external file (e.g.
if you need to install a new system or share your keymap configuration with the community).
To do this, simply press the *Export Key Configuration* button found in the header.
After doing so a the file browser will open to choose where to store the configuration.
The *Import Key Configuration* button installs a keymap configuration that is on
your computer but not in Blender.

The exported keymap will only contain keymaps and categories that have been modified by the user.
In addition, add-ons may register keymaps to their respective functions,
however, these keymaps are not exported unless changed by the user.
This exported file may be thought of as a *"keymap delta"* instead of a full keymap export.

*********
Interface
*********

Interface configuration lets you change how UI elements are displayed and how they react.

.. figure:: /images/preferences_interface_tab.png

Display
=======

Tooltips
When enabled, a tooltip will appear when your mouse pointer is over a control.
This tip explains the function of what is under the pointer,
gives the associated hotkey (if any) and the Python function that refers to it.
Python Tooltips
Displays a property's Python information below the tooltip.
Object Info
Display the active Object name and frame number at the bottom left of the 3D View.
Large Cursors
Use large mouse cursors when available.
View Name
Display the name and type of the current view in the top left corner of the 3D View.
For example: *User Persp* or *Top Ortho*.
Playback FPS
Show the frames per second screen refresh rate while an animation is played back.
It appears in the viewport corner, displaying red if the frame rate set cannot be reached.
Global Scene
Forces the current scene to be displayed in all screens (a project can consist of more than one scene).
Object Origin Size
Diameter of 3D Object centers in the view port (value in pixels from 4 to 10).

Display Mini Axis
Show the mini axis at the bottom left of the viewport.
Size
Size of the mini axis.
Brightness
Adjust brightness of the mini axis.

Warnings
========

Prompt Quit
When exiting Blender, a pop-up will ask you weather or not you really want to quit
(currently only available on MS-Windows).

View Manipulation
=================

Cursor Depth
Use the depth under the mouse when placing the cursor.

.. _prefs-auto-depth:

Auto Depth
Use the depth under the mouse to improve view pan, rotate, zoom functionality.
Useful in combination with *Zoom To Mouse Position*.

.. _prefs-zoom-mouse-pos:

Zoom to Mouse Position
When enabled, the mouse pointer position becomes the focus point of zooming instead of the 2D window center.
Helpful to avoid panning if you are frequently zooming in and out.
Rotate Around Selection
The selected object (bounding box center) becomes the rotation center of the viewport.
When there is no selection the last selection will be used.

.. hint::

This may seem ideal behavior.
However, it can become problematic with larger objects such as a terrain-mesh,
where the center is not necessarily your point of interest.

Global Pivot
Lock the same rotation/scaling pivot in all 3D Views.
Camera Parent Lock
When the camera is locked to the view and in fly mode, transform the parent rather than the camera.

.. _prefs-interface-auto-perspective:

Auto Perspective
Automatically to perspective Top/Side/Front view after using User Orthographic.
When disabled, Top/Side/Front views will retain Orthographic or Perspective view
(whichever was active at the time of switching to that view).
Smooth View
Length of time the animation takes when changing the view with the numpad
(Top/Side/Front/Camera...). Reduce to zero to remove the animation.
Rotation Angle
Rotation step size in degrees, when :kbd:`Numpad4`, :kbd:`Numpad6`, :kbd:`Numpad8`,
or :kbd:`Numpad2` are used to rotate the 3D View.

2D Viewports
============

Minimum Grid Spacing
The minimum number of pixels between grid lines in a 2D (i.e. top orthographic) viewport.
Time Code Style
Format of Time Codes displayed when not displaying timing in terms of frames.
The format uses '+' as separator for sub-second frame numbers,
with left and right truncation of the timecode as necessary.
Zoom To Frame Type
How zooming to frame focuses around current frame.

:Keep Range: Todo.
:Seconds: Todo.
:Keyframes: Todo.

.. _prefs-interface-manipulator:

Manipulator
Turns manipulators on and off.
Size
Diameter of the manipulator.
Handle Size
Size of manipulator handles, as a percentage of the manipulator radius (*size*/ 2).
Hotspot
Hotspot size (in pixels) for clicking the manipulator handles.

Menus
=====

Open on Mouse Over
Select this to have the menu open by placing the mouse pointer over the entry instead of clicking on it.
Menu Open Delay
Time for the menu to open.
Top Level
Time delay in 1/10 second before a menu opens (*Open on Mouse Over* needs to be enabled).
Sub Level
Same as above for sub menus (for example: :menuselection:`File --&gt; Open Recent`).

.. _prefs-pie-menu:

Pie Menus
=========

Animation Timeout
Length of animation when opening Pie Menus.
Recenter Timeout
The window system tries to keep the pie menu within the window borders.
Pie menus will use the initial mouse position as center for this amount of time, measured in 1/100ths of a second.
This allows for fast dragged selections.
Radius
The size of the Pie Menu set with the distance (in pixels) of the menu items from the center of the pie menu.
Threshold
Distance from center before a selection can be made.
Confirm Threshold
Distance threshold after which selection is made (zero disables).

Splash
======

Show Splash
Display the :ref:`splash` when starting Blender.

************
Introduction
************

This chapter explains how to change Blender's default configuration with the *User Preferences* editor.

The Blender *User Preferences* editor contains settings to control how Blender behaves.

Open User Preferences
=====================

To open the *User Preferences* editor go to :menuselection:`File --&gt; User Preferences`.

.. figure:: /images/preferences_interface_tab.png

Configure
=========

Now that you have opened the User Preferences editor, you can configure Blender to your liking.
At the top of the editor, the available options are grouped into seven tabs:

:doc:`Interface &lt;/preferences/interface&gt;`
Change how UI elements are displayed and how they react.
:doc:`Editing &lt;/preferences/editing&gt;`
Control how several tools will interact with your input.
:doc:`Input &lt;/preferences/input&gt;`
Customize how Blender reacts to the mouse and keyboard as well as define your own keymap.
:doc:`Add-ons &lt;/preferences/addons&gt;`
Manage Blender's *Add-ons*, allowing you to access features
not built-in as well as install new features.
:doc:`Themes &lt;/preferences/themes&gt;`
Customize interface appearance and colors.
:doc:`File &lt;/preferences/file&gt;`
Configure auto-save preferences and set default file paths for blend-files, rendered images, and more.
:doc:`System &lt;/preferences/system&gt;`
Set resolution, scripting console preferences, sound, graphics cards, and internationalization.

Save User Settings
==================

Once you have set your preferences, you will need to manually save them,
otherwise the new configuration will be lost after a restart.
Blender saves its preferences to *userpref.blend* in your user folder
(see next section, "Load Factory Settings", for details).

In the *User Preferences* editor, click on the *Save User Settings* button in the bottom left.
This will save all of the new preferences.

.. _factory-settings:

Load Factory Settings
=====================

Go to :menuselection:`File --&gt; Load Factory Settings`
then save the preferences via the *User Preferences* editor.

.. hint::

It can be valuable to make a backup of your preferences in the event that you lose your configuration.

See the :doc:`directory layout &lt;/getting_started/installing/configuration/directories&gt;`
section to see where your preferences are stored.

******
System
******

The *System* tab allows you to set resolution, scripting console preferences,
sound, graphics cards, and internationalization.

If your hardware does not support some of the options described on this page,
then they will either not show up or get corrected on startup.
If this happens do not worry, you can either consult your computer manual
to find a supported value or just let Blender correct it.

.. figure:: /images/preferences_system.png

User Preferences System tab.

General
=======

DPI
Value of the screen resolution which controls the size of Blender's interface fonts and internal icons shown.
Useful for taking screen shots for book printing and use of high resolution monitors.
During typical usage, you may prefer to use zoom which is an available in many parts of Blender interface.
Virtual Pixel Mode
Allows you to select global scaling. While the DPI only scales the interface,
this will scale line width, vertex-size. This is intended for HiDPI monitors
and is auto-detected on macOS.

Native
The normal pixel size.
Double
Double of the native pixel size.

Frame Server Port
TCP/IP port used in conjunction with the IP Address of the machine for frameserver rendering.
Used when working with distributed rendering.
Avoid changing this port value unless it is conflicting with already
existing service ports used by your Operating System and/or other software.
Always consult your operating system documentation and services or
consult your system administrator before changing this value.
Console Scrollback
The number of lines, buffered in memory of the console window.
Useful for debugging purposes and command line rendering.

.. _prefs-system-sound:

Sound
=====

Audio Device
Sets the audio engine to use to process and output audio.

None
No Audio support (audio strips can still be loaded normally).
SDL
Uses Simple Direct Media Layer API from `libsdl.org &lt;https://www.libsdl.org&gt;`__
to render sounds directly to the sound device output. Very useful for sequencer strips editing.
OpenAL
Provides buffered sound rendering with 3D/spatial support.
Used for 3D source support by *Speaker Objects* and the *Game Engine*.

Sound options
-------------

These settings are specific to *SDL* or *OpenAL* enabled.

Channels
Sets the audio channel count. Available options are: *Stereo*, *4 Channels* , *5.1 Surround* , *7.1 Surround*.
Mixing Buffer
Sets the number of samples used by the audio mixing buffer. Available options are:
*512* , *1024* , *2048*, *4096* , *8192*, *16384*, and *32768*.
Sample Rate
Sets the audio sample rate. Available options are: *44.1 Khz*, *48 Khz*, *96 Khz* and *192 Khz*.
Sample Format
Sets the audio sample format. Available options are:
*32 bit float*, *8 bit Unsigned*, *16 Bits Signed*, *24 Bits Signed*,
*32 Bits Signed*, *32 Bits Float*, and *64 Bits Float*.

.. _prefs-system-screencast:

Screencast
==========

These settings are used to control the frame-rate for recording a :ref:`Screencast &lt;info-screencast&gt;`.

FPS
The frame-rate for screencast playback.
Wait Timer
Time in milliseconds between each frame recorded for screencast.

Compute Device
==============

The Options here will set the compute device used by the Cycles render engine.

None
When set to *None* or the only option is *None*:
your CPU will be used as a computing device for Cycles Render Engine.
CUDA
If the system has a compatible Nvidia CUDA enabled graphics card you will be able
to use it to render with the :doc:`Cycles &lt;/render/cycles/features&gt;` render engine.
OpenCL
If the system has a compatible OpenCL device, it will show up an option for rendering with Cycles.

.. note::

That currently has limited support. See:
:doc:`Cycles Features &lt;/render/cycles/features&gt;` page for more information.

.. _prefs-system-opensubdiv:

OpenSubdiv Compute
==================

The options here will set the compute device used by OpenSubdiv for the
:doc:`Subdivision Surface Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`.

None
Disables any OpenSubdiv compute devices, makes sure legacy subdivision method is used.
Use this option when OpenSubdiv causes any bugs or regressions.
CPU
Single threaded CPU implementation.
It is mainly useful in cases when GPU compute is possible and threaded CPU option causes artifacts
(it is unlikely to happen, but still possible).
OpenMP
Multi-threaded CPU implementation. Use it for maximum performance in cases when GPU compute is not available.
GLSL Transform Feedback
Uses GPU to perform calculations, has minimal requirements to video card and driver.
GLSL Compute
Uses GPU to perform calculations, supposed to be more efficient than *Transform Feedback*
but also has higher requirements to video card and driver.

OpenGL
======

Clip Alpha
Clip alpha below this threshold in the 3D View.
Note that the default is set to a low value to prevent issues on some GPU's.
Mipmaps
Scale textures for 3D View using :term:`Mipmap` filtering. This increases display quality, but uses more memory.
GPU Mipmap Generation
Generate Mipmaps on the GPU instead of the CPU.
16 Bit Float Textures
Enables the use of 16 Bit per component Texture Images (Floating point Images).
Selection
Selection method to use for selecting.

Automatic
Automatically chooses the best setting depending on your OS, GPU, and drivers.
OpenGL Select
Legacy OpenGL selection method for legacy hardware.
OpenGL Occlusion Queries
More optimized OpenGL selection method.
Use this method if you are using an `OpenSubdiv Compute`_ compute device.

OpenGL Depth Picking
This option uses an alternate method of picking which uses depth information to select the front-most elements.
It is only used for selecting with the cursor (not border select, lasso, circle select etc.

Performance varies depending on your OpenGL hardware &amp; drivers.
Anisotropic Filtering
Sets the level of anisotropic filtering.
This improves the quality of how textures are drawn at the cost of performance.
Available Options are: *Off* (No Filtering), *2x*, *4x*, *8x*, and *16x*.

.. _prefs-system-window-draw:

Window Draw Method
==================

Window Draw Method
Specifies the Window Draw Method used to display Blender Window(s).

Automatic
Automatically set based on graphics card and driver.
Triple Buffer
Use a third buffer for minimal redraws at the cost of more memory.
If you have a capable GPU, this is the best and faster method of redraw.
Overlap
Redraw all overlapping regions. Minimal memory usage, but more redraws.
Recommended for some graphics cards and drivers combinations.
Overlap Flip
Redraw all overlapping regions. Minimal memory usage, but more redraws (for graphics drivers that do flipping).
Recommended for some graphic cards and drivers combinations.
Full
Do a full redraw each time. Only use for reference, or when all else fails.
Useful for certain cards with bad to no OpenGL acceleration at all.

.. _prefs-system-multi-sampling:

Multi-Sampling
This enables :term:`FSAA` for smoother drawing, at the expense of some performance.

.. note::

This is known to cause selection issues on some configurations,
see: :ref:`troubleshooting-3dview-invalid-selection`.

Region Overlap
This checkbox will enable Blender to draw regions overlapping the 3D View.
It means that the *Tool Shelf* and *Properties regions*,
will be drawn overlapping the 3D View editor.

If you have a capable graphics card and drivers with *Triple Buffer* support,
clicking the checkbox will enable the overlapping regions to be drawn using the *Triple Buffer* method,
which will also enable them to be drawn using Alpha, showing the 3D View contents through the regions.

Text Draw Options
Enable interface text anti-aliasing.
When disabled, texts are drawn using text straight render (Filling only absolute Pixels).

Textures
========

Limit Size
Limit the maximum resolution for pictures used in textured display to save memory.
The limit options are specified in a square of pixels
(e.g.: the option 256 means a texture of 256×256 pixels). This is useful for game engineers,
whereas the texture limit matches paging blocks of the textures in the target graphic card memory.
Available Options are: *Off* (No limit), *128*, *256*, *512*, *1024*, *2048*, *4096*, and *8192*.
Time Out
Time since last access of a GL texture in seconds, after which it is freed. Set to 0 to keep textures allocated.
Minimum: *0*, Maximum: *3600*.
Collection Rate
Number of seconds between each run of the GL texture garbage collector.
Minimum: *0*, Maximum: *3600*.

Image Draw Method
Method to draw images as the following options are supported:

2D Texture
Uses CPU for display transform and draws images as a 2D texture.
GLSL
Fastest method using GLSL for display transform and draws images as a 2D texture.
Draw Pixels
Uses CPU for display transform and draws images as a 2D texture.

Sequencer/Clip Editor
=====================

Memory Cache Limit
Upper limit of the sequencer's memory cache (megabytes).
For optimum clip editor and sequencer performance, high values are recommended.

Solid OpenGL lights
===================

*Solid OpenGL Lights* are used to light the 3D View,
mostly during *Solid view*. Lighting is constant and position "world" based.
There are three virtual light sources, also called OpenGL auxiliary lamps,
used to illuminate 3D View scenes, which will not display in renders.

The Lamp icons allow the user to enable or disable OpenGL lamps.
At least one of the three auxiliary OpenGL Lamps must remain enabled for the 3D View.
The lamps are equal, their difference is their positioning and colors.
You can control the direction of the lamps, as well as their diffuse and specular colors.

Use
Toggles the specific lamp.
Diffuse
This is the constant color of the lamp.
Specular
This is the highlight color of the lamp.
Direction
Clicking with :kbd:`LMB` in the sphere and dragging the mouse cursor
let us the user change the direction of the lamp by rotating the sphere.
The direction of the lamp will be the same as shown at the sphere surface.

Color Picker Type
=================

Choose which type of :term:`color space` you prefer. It will show when clicking :kbd:`LMB` on any color button.

See the different color picker types at the :doc:`Color picker &lt;/interface/controls/templates/color_picker&gt;` page.

.. _prefs-system-weight:

Custom Weight Paint Range
=========================

*Mesh skin weighting* is used to control how much a bone deforms the mesh of a character.
To visualize and paint these weights, Blender uses a color ramp (from blue to green, and from yellow to red).
Enabling the checkbox will enable an alternate map using a ramp starting with an empty range.
Now you can create your custom map using the common color ramp options.
For detailed information see the :doc:`Color ramps &lt;/interface/controls/templates/color_ramp&gt;` page.

Fonts
=====

Interface Font
--------------

Interface Font
Replacement for the default user interface font.
Mono-space Font
Same as above for the mono-space font.

.. _prefs-system-international:

Internationalization
--------------------

Blender supports a wide range of languages,
enabling this check box will enable Blender to support International Fonts.
International fonts can be loaded for the User Interface and used instead of Blender default bundled font.

This will also enable options for translating the User Interface
through a list of languages and Tips for Blender tools which appear
whenever the user hovers a mouse over Blender tools.

Blender supports I18N for internationalization.
For more Information on how to load International fonts,
see: :doc:`Editing Texts &lt;/modeling/texts/editing&gt;` page.

******
Themes
******

The *Themes* tab allows you to customize interface appearance and colors.

.. figure:: /images/preferences_themes_tab.png

The colors for each editor can be set separately by simply selecting the editor you wish to
change in the multi-choice list at the left, and adjusting colors as required.
Notice that changes appear in real-time on your screen. In addition, details such as the dot
size in the *3D View* or the *Graph Editor* can also be changed.

Themes use Blender's preset system to save a theme.
This will save the theme to an XML file in the ``./scripts/presets/interface_theme/`` subdirectory of one of the
:doc:`configuration directories &lt;/getting_started/installing/configuration/directories&gt;`.

.. figure:: /images/preferences_theme_example.png

Blender comes bundled with a small selection of themes.

This is an example of the theme *Elsyiun*.

###################
Audio Rendering
###################

.. toctree::
:maxdepth: 2

introduction.rst
speaker.rst

************
Introduction
************

Audio can be rendered from the :menuselection:`Properties Editor --&gt; Render tab --&gt; Render --&gt; Audio`.

.. figure:: /images/render_output_render-panel.png

Render panel.

Options
=======

Relative Path
Select the file relative to the blend-file.

Accuracy
Sample accuracy, important for animation data (the lower the value, the more accurate).

Audio Containers
See :doc:`here &lt;/data_system/files/media/video_formats&gt;`.

Codec
Some *Audio Containers* also have option to choose a codec.
For more information see :doc:`here &lt;/data_system/files/media/video_formats&gt;`.

Split Channels
Each audio channel will be rendered into a separate file.

.. seealso::

- See :ref:`Scene Audio &lt;data-scenes-audio&gt;` settings.
- See :ref:`Audio Output Settings &lt;render-output-video-encoding-audio&gt;` settings.
- See :ref:`Audio Preferences &lt;prefs-system-sound&gt;`.

*******
Speaker
*******

.. figure:: /images/render_audio_speaker_objects.png
:align: right

Speaker Objects.

The speaker object is used to give sound in the 3D View.
After adding the object the various settings can be changed in the properties editor.

Options
=======

.. These descriptions are the same as the tool tips

Sound
-----

Mute
Toggles whether or not the sound can be heard.
Volume
Adjust the loudness of the sound.
Pitch
Can be used to bend the pitch of the sound to be either deeper or higher.

Distance
--------

.. figure:: /images/render_audio_speaker_properties.png
:align: right

.. rubric:: Volume

Minimum
Minimum volume, no matter how far the object is.
Maximum
Maximum volume, no matter how far the object is.
Attenuation
How strong the distance affects the volume.

.. rubric:: Distance

Maximum
Maximum distance for volume calculation.
Reference
Reference distance at which volume is 100%.

Cone
----

.. rubric:: Angle

Outer
Angle of the outer cone in degrees. Outside this cone the volume is the outer cone volume (see below).
Between the inner and outer cone the volume is interpolated.
Inner
Angle of the inner cone in degrees. Inside the cone the volume is 100%.

.. rubric:: Volume

Outer
Volume outside the outer cone.

*************
Render Baking
*************

Baking, in general, is the act of pre-computing something in order to speed up some other
process later down the line.
Rendering from scratch takes a lot of time depending on the options you choose.
Therefore, Blender allows you to "bake" some parts of the render ahead of time, for select objects.
Then, when you press Render, the entire scene is rendered much faster,
since the colors of those objects do not have to be recomputed.

Render baking creates 2D bitmap images of a mesh object's rendered surface.
These images can be re-mapped onto the object using the object's UV coordinates.
Baking is done for each individual mesh, and can only be done if that mesh has been UV-unwrapped.
While it takes time to set up and perform, it saves render time. If you are rendering a long animation,
the time spent baking can be much less than time spent rendering out each frame of a long animation.

Use Render Bake in intensive light/shadow solutions,
such as AO or soft shadows from area lights. If you bake AO for the main objects,
you will not have to enable it for the full render, saving render time.

Use *Full Render* or *Textures* to create an image texture;
baked procedural textures can be used as a starting point for further texture painting.
Use *Normals* to make a low-resolution mesh look like a high-resolution mesh.
To do that, UV-unwrap a high-resolution, finely sculpted mesh and bake its normals.
Save that normal map, and *Mapping* (texture settings)
the UV of a similarly unwrapped low-resolution mesh.
The low-resolution mesh will look just like the high-resolution,
but will have much fewer faces/polygons.

.. rubric:: Advantages

- Can significantly reduce render times.
- Texture painting made easier.
- Reduced polygon count.
- Repeated renders are made faster, multiplying the time savings.

.. rubric:: Disadvantages

- Object must be UV-unwrapped.
- If shadows are baked, lights and object cannot move with respect to each other.
- Large textures (e.g. 4096×4096) can be memory intensive, and be just as slow as the rendered solution.
- Human (labor) time must be spent unwrapping and baking and saving files and applying the textures to a channel.

Options
=======

Bake Mode
---------

Full Render
^^^^^^^^^^^

Bakes all materials, textures, and lighting except specularity and SSS.

Ambient Occlusion
^^^^^^^^^^^^^^^^^

Bakes ambient occlusion as specified in the World panels. Ignores all lights in the scene.

.. figure:: /images/render_blender-render_bake_ao.jpg

Ambient Occlusion.

Normalized
Normalize without using material's settings.

Shadow
^^^^^^

Bakes shadows and lighting.

Normals
^^^^^^^

Bakes tangent and camera-space normals (amongst many others) to an RGB image.

.. figure:: /images/render_blender-render_bake_norm.jpg

Normals.

.. figure:: /images/render_blender-render_bake_normspace.jpg
:align: right

Normal Space.

Normal Space
Normals can be baked in different spaces:

Camera space
Default method.
World space
Normals in world coordinates, dependent on object transformation and deformation.
Object space
Normals in object coordinates, independent of object transformation, but dependent on deformation.
Tangent space
Normals in tangent space coordinates, independent of object transformation and deformation.
This is the new default, and the right choice in most cases,
since then the normal map can be used for animated objects too.

For materials the same spaces can be chosen as well, in the image texture options,
next to the existing *Normal Map* setting. For correct results,
the setting here should match the setting used for baking.

Textures
^^^^^^^^

Bakes colors of materials and textures only, without shading.

Displacement
^^^^^^^^^^^^

Similar to baking normal maps,
displacement maps can also be baked from a high-res object to an unwrapped low-res object,
using the *Selected to Active* option.

.. figure:: /images/render_blender-render_bake_disp.jpg

Displacement.

Normalized
Normalize to the distance.

When using this in conjunction with a Subdivision Surface and Displacement modifiers within Blender, it is
necessary to temporarily add a heavy Subdivision Surface Modifier to the 'low res' model before baking.
This means that if you then use a Displacement Modifier on top of the Subdivision Surface,
the displacement will be correct, since it is stored as a relative difference to the subdivided geometry,
rather than the original base mesh (which can get distorted significantly by a Subdivision Surface).
The higher the render subdivision level while baking, the more accurate the displacements will be.
This technique may also be useful when saving the displacement map out for use in external renderers.

Emission
^^^^^^^^

Bakes Emit, or the Glow color of a material.

Alpha
^^^^^

Bakes Alpha values, or transparency of a material.

Mirror Color and Intensity
^^^^^^^^^^^^^^^^^^^^^^^^^^

Bakes Mirror color or intensity values.

Specular Color and Intensity
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Bakes specular color or specular intensity values.

.. figure:: /images/render_blender-render_bake_fullrender.jpg

Full Render.

Additional Options
------------------

Clear
If selected, clears the image to selected background color (default is black) before baking render.
Margin
Baked result is extended this many pixels beyond the border of each UV "island," to soften seams in the texture.

Split
Fixed
Slit quads predictably (0, 1, 2) (0, 2, 3).
Fixed alternate
Slit quads predictably (1, 2, 3) (1, 3, 0).
Automatic
Split quads to give the least distortion while baking.

Select to Active
Enable information from other objects to be baked onto the active object.

Distance
Controls how far a point on another object can be away from the point on the active object.
Only needed for *Selected to Active*.
A typical use case is to make a detailed, high poly object,
and then bake its normals onto an object with a low polygon count.
The resulting normal map can then be applied to make the low poly object look more detailed.
Bias
Bias towards further away from the object (in Blender units)

.. note:: Mesh Must be Visible in Render

If a mesh is not visible in regular render,
for example because it is disabled for rendering in the Outliner or has the DupliVerts setting enabled,
it cannot be baked to.

Workflow
========

#. In a 3D View editor, select a mesh and enter UV/Face Select mode
#. :ref:`Unwrap the mesh object &lt;editors-uv-image-index&gt;`
#. In a UV/Image Editor, either create a new image or open an existing one.
If your 3D View is in textured display mode, you should now see the image mapped to your mesh.
Ensure that all faces are selected.
#. In the Bake panel at the bottom of the *Render menu*, bake your desired type of image
(*Full Render* etcetera.)
#. When rendering is complete, Blender replaces the image with the Baked image.
#. Save the image.
#. Apply the image to the mesh as a UV texture. For displacement and normal maps,
refer to :doc:`Bump and Normal Maps &lt;/render/blender_render/textures/properties/influence/bump_and_normal&gt;`.
For full and texture bakes, refer to :doc:`Textures &lt;/render/blender_render/textures/index&gt;`.
#. Refine the image using the process described below,
or embellish with :ref:`painting-texture-index`
or an external image editor.

#########
Camera
#########

.. toctree::
:maxdepth: 2

introduction.rst
object_data.rst
..    TODO/Review: {{review|text=Options reviewed for v2.70; Video is for old version}}.

************
Introduction
************

A *Camera* is an object that provides a means of rendering images from Blender.
It defines which portion of a scene is visible in the rendered image.
By default a scene contains one camera. However, a scene can contain more than one camera,
but only one of them will be used at a time.
So you will only need to add a new camera if you are making cuts between them.
See :ref:`Animating Cameras &lt;marker-bind-camera&gt;`.

Changing the Active Camera
==========================

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Hotkey:   :kbd:`Ctrl-Numpad0`

.. figure:: /images/render_blender-render_camera_introduction_cameras.png

Active camera (left one).

The *active* camera is the camera that is currently being used for rendering and camera view
:kbd:`Numpad0`.

Select the camera you would like to make active and press :kbd:`Ctrl-Numpad0`
(by doing so, you also switch the view to camera view). In order to render,
each scene **must** have an active camera.

The active camera can also be set in the *Scene* tab of the *Properties Editor*.

The camera with the solid triangle on top is the active camera.
Limit and mist indicators of cameras are drawn darker if the camera is not the active camera for the current scene.

.. note::

The active camera, as well as the layers, can be specific to a given view,
or global (locked) to the whole scene.
See :doc:`Local Camera &lt;/editors/3dview/properties/panels&gt;`.

Render Border
=============

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Menu:     :menuselection:`View --&gt; Render Border`
| Hotkey:   :kbd:`Ctrl-B`

.. figure:: /images/render_blender-render_camera_introduction_border.png
:align: right

Render Border toggle.

While in camera view, you can define a subregion to render by drawing out a rectangle within the camera's frame.
Your renders will now be limited to the part of scene visible within the render border.
This can be very useful for reducing render times for quick previews on an area of interest.

The border can be disabled by disabling the *Border* option in the *Dimensions* panel
in the *Render* tab or by activating the option again.

.. container:: lead

.. clear

.. note::

When Render Border is activated, :doc:`Sampled Motion Blur &lt;/render/blender_render/settings/motion_blur&gt;`
will become available to view in the 3D View.

.. list-table:: Render border and associated render.
:widths: 60 40

* - .. figure:: /images/render_blender-render_camera_introduction_render-border-1.png

- .. figure:: /images/render_blender-render_camera_introduction_render-border-2.png
.. _camera-settings:

***********
Object Data
***********

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Editor:   :menuselection:`Properties --&gt;  Camera`

Cameras are invisible in renders, so they do not have any material or texture settings.
However, they do have *Object* and *Editing* setting panels available
which are displayed when a camera is the selected (active!) object.

Lens
====

.. figure:: /images/render_blender-render_camera_object-data_lens-panel.png

Camera Lens panel.

The camera lens options control the way 3D objects are represented in a 2D image.

.. _camera-lens-type:

Lens Type
---------

There are three different lens types:

- `Perspective`_
- `Orthographic`_
- `Panoramic`_

Perspective
^^^^^^^^^^^

This matches how you view things in the real-world.
Objects in the distance will appear smaller than objects in the foreground,
and parallel lines (such as the rails on a railroad) will appear to converge as they get farther away.

.. figure:: /images/perspective_perspective_traintracks.jpg

Render of a train track scene with a *Perspective* camera.

Settings which adjust this projection include:

- Focal length
- `Shift`_
- :ref:`Sensor size &lt;render-camera-sensor-size&gt;`

Focal length
The :term:`focal length` setting controls the amount of zoom, i.e.
the amount of the scene which is visible all at once.
Longer focal lengths result in a smaller :abbr:`FOV (Field of View)` (more zoom),
while short focal lengths allow you to see more of the scene at once
(larger :abbr:`FOV (Field of View)`, less zoom).

.. figure:: /images/perspective_perspective_traintracks_telephoto.jpg

Render of the same scene as above, but with a focal length of 210mm instead of 35mm.

Lens Unit
The focal length can be set either in terms of millimeters or the actual :term:`Field of View` as an angle.

Orthographic
^^^^^^^^^^^^

With *Orthographic* perspective objects always appear at their actual size, regardless of distance.
This means that parallel lines appear parallel, and do not converge like they do with *Perspective*.

.. figure:: /images/perspective_orthographic_ortho_example.jpg

Render from the same camera angle as the previous examples, but with orthographic perspective.

Orthographic Scale
This controls the apparent size of objects in the camera.

Note that this is effectively the only setting which applies to orthographic perspective.
Since parallel lines do not converge in orthographic mode (no vanishing points),
the lens shift settings are equivalent to translating the camera in the 3D View.

Panoramic
^^^^^^^^^

Panoramic cameras are only supported in the Cycles render engine.
See :ref:`the Cycles documentation &lt;cycles-panoramic-camera&gt;`.

Shift
-----

The *Shift* setting allows for the adjustment of *vanishing points*.
*Vanishing points* refer to the positions to which parallel lines converge.
In this example, the most obvious vanishing point is at the end of the railroad.

To see how this works, take the following examples:

.. figure:: /images/perspective_perspective_traintracks_lens_shift.jpg

Render of a train track scene with a horizontal lens shift of 0.330.

.. figure:: /images/perspective_perspective_traintracks_camera_rotate.jpg

Render of a train track scene with a rotation of the camera object instead of a lens shift.

Notice how the horizontal lines remain perfectly horizontal when using the lens shift,
but do get skewed when rotating the camera object.

Using lens shift is equivalent to rendering an image with a larger
:abbr:`FOV (Field of View)` and cropping it off-center.

.. _camera-clipping:

Clipping
--------

Clip Start and End
The interval in which objects are directly visible;
Only objects within the limits are rendered.

For OpenGL display, setting clipping distances to limited values
is important to ensure sufficient rasterization precision.
Ray tracing renders do not suffer from this issue so much,
and as such more extreme values can safely be set.

When *Limits* in the *Display* panel is enabled,
the clip bounds will be visible as two yellow connected dots on the camera line of sight.

.. tip::

Changing the clipping value can have a serious impact on render performance.
It is important to always set the *Start* and *End* values to a safe distance that is both not too extreme,
nor too small to have the best possible render times.

.. seealso::

- :ref:`Blender Render Camera Clipping &lt;camera-clipping&gt;`.
- :doc:`3D View clipping &lt;/editors/3dview/properties/panels&gt;`.

Camera
======

.. figure:: /images/render_blender-render_camera_object-data_camera-panel.png

Camera Presets panel.

Camera Presets
:ref:`Presets &lt;ui-presets&gt;` to match real cameras.

.. _render-camera-sensor-size:

Sensor size
This setting is an alternative way to control the focal-length,
it is useful to match the camera in Blender to a physical camera &amp; lens combination,
e.g. for :doc:`motion tracking &lt;/editors/movie_clip_editor/index&gt;`.
Sensor Fit
Option to control which dimension (vertical or horizontal) along which field of view angle fits.

.. _render-camera-dof:

Depth of Field
==============

.. figure:: /images/render_blender-render_camera_object-data_depth-of-field-panel.png

Camera Depth of Field Panel.

Real world cameras transmit light through a lens that bends and focuses it onto the sensor.
Because of this, objects that are a certain distance away are in focus,
but objects in front and behind that are blurred.

The area in focus is called the *focal point* and can be set using either an exact value,
or by using the distance between the camera and a chosen object:

Focus Object
Choose an object which will determine the focal point. Linking an object will deactivate the distance parameter.
Typically this is used to give precise control over the position of the focal point,
and also allows it to be animated or constrained to another object.
Distance
Sets the distance to the focal point when no *Focus Object* is specified.
If *Limits* are enabled, a yellow cross is shown on the camera line of sight at this distance.

.. hint::

Hover the mouse over the *Distance* property and press :kbd:`E` to use a special *Depth Picker*.
Then click on a point in the 3D View to sample the distance from that point to the camera.

High Quality
In order for the viewport to offer an accurate representation of depth of field (blur radius calculation),
like a render, you must enable High Quality. Without it, you may notice a
difference in shading. (Grayed out if not supported by the GPU).
Viewport F-stop
Controls the real-time focal blur effect used during sequencer or OpenGL rendering and,
when enabled, camera views in the 3D View.
The amount of blur depends on this setting, along with Focal Length and Sensor Size.
Smaller Viewport F-stop values result in more blur.
Blades
Add a number of polygonal *blades* to the blur effect, in order to achieve a
a *bokeh effect* in the viewport. To enable this feature, the blades must be
set to at least 3 (3 sides, triangle)

.. figure:: /images/render_blender-render_camera_object-data_depth-of-field-bokeh.png

The viewport bokeh effect with the blades set to 3.

Display
=======

.. figure:: /images/render_blender-render_camera_object-data_display-panel.png

Camera Display Panel.

Limits
Shows a line which indicates *Start* and *End Clipping* values.
Mist
Toggles viewing of the mist limits on and off.
The limits are shown as two connected white dots on the camera line of sight.
The mist limits and other options are set in the *World* panel,
in the :doc:`Mist section &lt;/render/blender_render/world/mist&gt;`.

.. figure:: /images/render_blender-render_camera_object-data_display-view.png

Camera view displaying safe areas, sensor and name.

Sensor
Displays a dotted frame in camera view.
Name
Toggle name display on and off in camera view.
Size
Size of the camera icon in the 3D View. This setting has no effect on the render output of a camera,
and is only a cosmetic setting.
The camera icon can also be scaled using the standard Scale :kbd:`S` transform key.
Passepartout
This option darkens the area outside of the camera's field of view.

Alpha
Controls the transparency of the passepartout mask.

Composition Guides
------------------

*Composition Guides* are available from the menu, which can help when framing a shot.
There are eight types of guides available:

Center
Adds lines dividing the frame in half vertically and horizontally.
Center Diagonal
Adds lines connecting opposite corners.
Thirds
Adds lines dividing the frame in thirds vertically and horizontally.
Golden
Divides the width and height into Golden proportions (About 0.618 of the size from all sides of the frame).
Golden Triangle A
Draws a diagonal line from the lower-left to upper-right corners,
then adds perpendicular lines that pass through the top left and bottom right corners.
Golden Triangle B
Same as A, but with the opposite corners.
Harmonious Triangle A
Draws a diagonal line from the lower-left to upper-right corners,
then lines from the top left and bottom right corners to 0.618 the lengths of the opposite side.
Harmonious Triangle B
Same as A, but with the opposite corners.

.. _camera-safe-areas:

Safe Areas
==========

Safe areas are guides used to position elements to ensure that the most important
parts of the content can be seen across all screens.

Different screens have varying amounts of :term:`overscan`.
(specially older TV sets).
That means that not all content will be visible to all viewers,
since parts of the image surrounding the edges are not shown.
To work around this problem TV producers defined two areas where content is guaranteed to be shown:
action safe and title safe.

Modern LCD/plasma screens with purely digital signals have no :term:`overscan`,
yet safe areas are still considered best practice and may be legally required for broadcast.

In Blender, safe areas can be set from the Camera and Sequencer views.

.. figure:: /images/render_blender-render_camera_object-data_safe-areas-panel.png

The Safe areas panel found in the camera properties,
and the view mode of the sequencer.

The Safe Areas can be customized by their outer margin,
which is a percentage scale of the area between the center and the render size.
Values are shared between the Video Sequence editor and camera view.

Main Safe Areas
---------------

.. figure:: /images/render_blender-render_camera_object-data_safe-areas-main.png

Red line: Action safe. Green line: Title safe.

Title Safe
Also known as *Graphics Safe*.
Place all important information (graphics or text) inside this area to
ensure it can be seen by the majority of viewers.
Action Safe
Make sure any significant action or characters in the shot are inside this area.
This zone also doubles as a sort of "margin" for the screen which can be used
to keep elements from piling up against the edges.

.. tip:: Legal Standards

Each country sets a legal standard for broadcasting.
These include, among other things, specific values for safe areas.
Blender defaults for safe areas follow the EBU (European Union) standard.
Make sure you are using the correct values when working for broadcast to avoid any trouble.

Center-Cuts
-----------

.. figure:: /images/render_blender-render_camera_object-data_safe-areas-cuts.png

Cyan line: action center safe. Blue line: title center safe.

Center-cuts are a second set of safe areas to ensure content
is seen correctly on screens with a different aspect ratio.
Old TV sets receiving ``16:9`` or ``21:9`` video will cut off the sides.
Position content inside the center-cut areas to make sure the most important elements
of your composition can still be visible in these screens.

Blender defaults show a ``4:3`` (square) ratio inside ``16:9`` (wide-screen).
.. _blender-render-index:

########################
Blender Render Engine
########################

.. toctree::
:maxdepth: 2

introduction.rst
materials/index.rst
textures/index.rst
lighting/index.rst
world/index.rst
camera/index.rst
settings/index.rst
bake.rst
post_processing/index.rst
optimizations/index.rst
.. expand text (todo)

************
Introduction
************

The Blender Internal Render is Blender's non photo-real render engine.
.. _lighting-index:

###########
Lighting
###########

.. toctree::
:maxdepth: 2

introduction.rst
lights/index.rst
shadows/index.rst
volumetric_lights.rst
lamps/index.rst
lighting_rigs.rst

************
Introduction
************

Lighting is a very important topic in rendering, standing equal to modeling,
materials and textures. The most accurately modeled and textured scene will yield poor results
without a proper lighting scheme,
while a simple model can become very realistic if skillfully lit.

Viewing Restrictions
====================

The color of an object and the lighting of your scene is affected by:

- Your ability to see different colors (partial color blindness is common).
- The medium in which you are viewing the image (e.g. an LCD panel versus printed glossy paper).
- The quality of the image (e.g. a ``jpeg`` at 0.4 compression versus 1.0).
- The environment in which you are viewing the image
(e.g. a CRT monitor with glare versus in a dark room, or in a sunshiny blue room).
- Your brain's perception of the color and intensity
relative to those objects around it and the world background color,
which can be changed using color manipulation techniques using Blender
:doc:`Composite Nodes &lt;/compositing/introduction&gt;`.

Global Influences
=================

In Blender, the elements under your control which affect lighting are:

- The color of the world :doc:`ambient light &lt;/render/blender_render/world/ambient_light&gt;`.
- The use of :doc:`Ambient Occlusion &lt;/render/blender_render/world/ambient_occlusion&gt;`
as a way to cast that ambient light onto the object.
- The degree to which the ambient light colors the
:doc:`material &lt;/render/blender_render/materials/index&gt;` of the object.
- The use of :doc:`Indirect lighting &lt;/render/blender_render/world/indirect_lighting&gt;`,
where the color of one object radiates onto another.
- The :doc:`lamps &lt;/render/blender_render/lighting/lamps/introduction&gt;` in your scene.

The physics of light bouncing around in the real world is simulated by Ambient Occlusion (a world setting),
buffer shadows (which approximate shadows being cast by objects), ray tracing
(which traces the path of photons from a light source). Also,
within Blender you can use :doc:`Indirect lighting &lt;/render/blender_render/world/indirect_lighting&gt;`.
Ray tracing, ambient occlusion, and indirect lighting are computer-intensive processes.
Blender can perform much faster rendering with its internal scan line renderer,
which is a very good scan line renderer indeed.
This kind of rendering engine is much faster since it does not try to simulate the real behavior of light,
assuming many simplifying hypotheses.

Lighting Settings
=================

Only after the above global influences have been considered,
do you start adding light from lamps in your scene.
The main things under your control are the:

- Type of light used (*Sun*, *Spot*, *Lamp*, *Hemi*, etc.).
- Color of the light.
- Position of the light and its direction.
- Settings for the light, including energy and falloff.

Then you are back to how that material's
:doc:`shader &lt;/render/blender_render/materials/properties/diffuse_shaders&gt;` reacts to the light.

This chapter attempts to address the above,
including how lights can work together in rigs to light your scene.
In this chapter we will analyze the different types of light in Blender and their behavior;
we will discuss their strong and weak points. We will also describe many lighting rigs,
including the ever-popular three-point light method.

Lighting in the Workflow
========================

In this user manual we have placed Lighting before Materials;
you should set up your lighting before assigning materials to your meshes.
Since the material shaders react to light, without proper lighting,
the material shaders will not look right, and you will end up fighting the shaders,
when it is really the bad lighting that is causing you grief.
All of the example images in this section do not use any material setting at all on the ball,
cube or background.

Overriding Materials to Reset Lighting
======================================

.. figure:: /images/render_blender-render_lighting_introduction_material-field.png

Material field in the Render Layers panel.

If you have started down the road of assigning materials,
and are now fiddling with the lighting, we suggest that you create a default,
generic gray material -- no *Vertex Color*, no *Face Texture*,
no *Shadeless*, just plain old middle gray with RGB(0.8, 0.8, 0.8).
Name this "Gray".

Next go to the *Render Layer* tab. In the *Layer* panel,
select your new "Gray" material in the *Material* field.
This will override any materials you may have set, and render everything with this color.
Using this material, you can now go about adjusting the lighting.
Just empty this field to get back to your original materials.

########
Area
########

.. toctree::
:maxdepth: 2

introduction.rst
raytraced_shadows.rst
..    TODO/Review: {{review|im=examples}}.

************
Introduction
************

The *Area* lamp simulates light originating from a surface (or surface-like)
emitter. For example, a TV screen, your supermarket's neon lamps, a window,
or a cloudy sky are just a few types of area lamp. The area lamp produces shadows with soft
borders by sampling a lamp along a grid the size of which is defined by the user.
This is in direct contrast to point-like artificial lights which produce sharp borders.

.. figure:: /images/lighting-lamps-area-com_options.png
:width: 308px

Commons Options.

Lamp options
============

Distance, Energy and Color
These settings are common to most types of lamps,
and are described in :doc:`Light Properties &lt;/render/blender_render/lighting/lights/lamp_panel&gt;`.

Note that the *Distance* setting is much more sensitive and important for *Area* lamps than for others;
usually any objects within the range of *Distance* will be blown out and overexposed.
For best results, set the *Distance* to just below the distance to the object that you want to illuminate.
Gamma
Amount to gamma correct the brightness of illumination. Higher values give more contrast and shorter falloff.

The *Area* lamp does not have light falloff settings. It uses an "inverse quadratic" attenuation law.
The only way to control its falloff is to use the *Distance* and/or *Gamma* settings.
This Layer Only, Negative, Specular and Diffuse
These settings control what the lamp affects,
as described in :ref:`What Light Affects &lt;bi-lamp-influence&gt;`.

Shadows
=======

Area light ray-traced shadows are described here:
:doc:`Raytraced Shadows &lt;/render/blender_render/lighting/lamps/area/raytraced_shadows&gt;`.

When an *Area* light source is selected,
the *Shadow* panel has the following default layout:

.. list-table::
The *Shadow* panel when *Area* light source is selected.

* - .. figure:: /images/lighting-lamps-area-adap_qmc.jpg
:width: 320px

Adaptive QMC settings.

- .. figure:: /images/lighting-lamps-area-cont_jitt.png
:width: 320px

Constant Jittered settings.

Area Shape
==========

The shape of the area light can be set to *Square* or *Rectangle*.

.. list-table::

* - .. figure:: /images/lighting-lamps-area-square.png
:width: 308px

Square options.

- .. figure:: /images/lighting-lamps-area-rect.png
:width: 308px

Rectangle options.

Square / Rectangular
Emit light from either a square or a rectangular area
Size / Size X / Size Y
Dimensions for the *Square* or *Rectangle*

.. note:: Shape Tips

Choosing the appropriate shape for your *Area* light will enhance the believability of your scene.
For example, you may have an indoor scene and would like to simulate light entering through a window.
You could place a *Rectangular* area lamp in a window (vertical) or from neons (horizontal)
with proper ratios for *Size X* and *Size Y*. For the simulation of the light emitted by a
TV screen a vertical *Square* area lamp would be better in most cases.
..    TODO/Review: {{review|}}.

**********************
Area Raytraced Shadows
**********************

.. figure:: /images/lighting-lamps-area-adap_qmc.jpg
:width: 300px

Adaptive QMC settings.

The *Area* light source can only cast ray-traced shadows.
The ray-traced shadows settings of this lamp are mostly shared with other lamps,
as described in :doc:`Raytraced Properties &lt;/render/blender_render/lighting/shadows/raytraced_properties&gt;`.
However, there are some specifics with this lamp, which are detailed below:

Shadow Samples
==============

Samples
This have the same role as with other lamps, but when using a *Rectangle* Area lamp,
you have two samples settings: *Samples X* and *Samples Y*, for the two axes of the area plane.
Note also that when using the *Constant Jittered* sample generator method,
this is more or less equivalent to the number of virtual lamps in the area.
With QMC sample generator methods, it behaves similarly to with *Lamp* or *Spot* lamps.

Sample Generator Types
======================

Adaptive QMC / Constant QMC
These common setting are described in
:doc:`/render/blender_render/lighting/shadows/shadow_panel`.

Constant Jittered
The *Area* lamp has a third sample generator method, *Constant Jittered*,
which is more like simulating an array of lights.
It has the same options as the old one: *Umbra*, *Dither* and *Jitter*.

.. figure:: /images/lighting-lamps-area-cont_jitt.png
:width: 300px

Constant Jittered settings.

The following three parameters are only available when using the *Constant Jittered* sample generator method,
and are intended to artificially boost the "soft" shadow effect, with possible loss in quality:

Umbra
Emphasizes the intensity of shadows in the area fully within the shadow rays.
The light transition between fully shadowed areas and fully lit areas changes more quickly (i.e.
a sharp shadow gradient).
You need *Samples* values equal to or greater than 2 to see any influence of this button.

Dither
Applies a sampling over the borders of the shadows,
similar to the way anti-aliasing is applied by the *OSA* button on the borders of an object.
It artificially softens the borders of shadows; when *Samples* is set very low,
you can expect poor results, so *Dither* is better used with medium *Samples* values.
It is not useful at all with high *Samples* values, as the borders will already appear soft.

Jitter
Adds noise to break up the edges of solid shadow samples,
offsetting them from each other in a pseudo-random way.
Once again, this option is not very useful when you use high *Samples* values where the
drawback is that noise generates quite visible graininess.

Technical Details
=================

.. _fig-bi-light-rayshadow-area:

.. figure:: /images/lighting-lamps-area_concept.png
:width: 250px

Principles behind the Area light.

The Fig. :ref:`fig-bi-light-rayshadow-area`
picture helps to understand how the soft shadows are simulated.

"(a)" is the *Area* light as defined in Blender. If its shape is *Square*,
then the softness of the shadow is defined by the number of light *Samples* in each direction of the shape.
For example, "(b)" illustrates the equivalent case of an *Area* light
(*Square* shape), with *Samples* set at 3 on the *Shadow and Spot* panel.

The *Area* lamp is then considered as a grid with a resolution of three in each
direction, and with a light "dupliverted" at each node for a total of nine lights.

In case "(a)", the energy *E* is *E*/1, and in case "(b)",
the energy of each individual pseudo-light is equal to
*E*/ (nbr. of lights). Each pseudo-light produces a faint shadow
(proportional to its energy), and the overlay of the shadows produces the soft shadow
(it is darker where the individual shadows overlap, and lighter everywhere else).

Hints
=====

You will note that changing the *Size* parameter of your area lamp does not affect
the lighting intensity of your scene. On the other hand, rescaling the lamp using the
:kbd:`S` in the 3D View could dramatically increase or decrease the lighting intensity
of the scene. This behavior has been coded this way so that you can fine tune all your light
settings and then decide to scale up (or down)
the whole scene without suffering from a drastic change in the lighting intensity.
If you only want to change the dimensions of your *Area* lamp,
without messing with its lighting intensity,
you are strongly encouraged to use the *Size* button(s) instead.

If your computer is not very fast,
when using the *Constant Jittered* sample generator method,
you could find it useful to set a low *Samples* value (like 2)
and activate *Umbra*, *Dither*,
and/or *Jitter* in order to simulate slightly softer shadows. However,
these results will never be better than the same lighting with high *Samples* values.

*********
Hemi Lamp
*********

.. figure:: /images/render_blender-render_lighting_lamps_hemi_scheme.svg

Hemi light conceptual scheme.

The *Hemi* lamp provides light from the direction of a 180- hemisphere,

designed to simulate the light coming from a heavily clouded or otherwise uniform sky.
In other words, it is a light which is shed, uniformly,
by a glowing dome surrounding the scene.

Similar to the *Sun* lamp, the *Hemi* 's location is unimportant,
while its orientation is key.

The *Hemi* lamp is represented with four arcs,
visualizing the orientation of the hemispherical dome,
and a dashed line representing the direction in which the maximum energy is radiated,
the inside of the hemisphere.

Options
=======

.. figure:: /images/lighting-lamps-hemi.png
:width: 307px

Hemi lamp's panel.

Energy and Color
These settings are common to most types of lamps, and are described in
:doc:`Light Properties &lt;/render/blender_render/lighting/lights/lamp_panel&gt;`.
Layer, Negative, Specular, and Diffuse
These settings control what the lamp affects, as described in
:ref:`What Light Affects &lt;bi-lamp-influence&gt;`.

The *Hemi* lamp has no light falloff settings: it always uses a constant attenuation
(i.e. no attenuation).

Since this lamp is the only lamp which cannot cast any shadow, the *Shadow* panel is absent.

##############
Lamp Types
##############

.. toctree::
:maxdepth: 2

introduction.rst
point.rst
sun/index.rst
spot/index.rst
hemi.rst
area/index.rst

************
Introduction
************

Blender comes equipped with five different lamp types,
each with its own unique strengths and limitations. Here are the available lamps:

- :doc:`Point &lt;/render/blender_render/lighting/lamps/point&gt;`
is an omni-directional point light source, similar to a light bulb.
- :doc:`Spot &lt;/render/blender_render/lighting/lamps/spot/introduction&gt;`
is a directional point light source, similar to ... a spot.
- :doc:`Area &lt;/render/blender_render/lighting/lamps/area/introduction&gt;`
is a source simulating an area which is producing light,
as windows, neons, TV screens.
- :doc:`Hemi &lt;/render/blender_render/lighting/lamps/hemi&gt;`
simulates a very wide and far away light source, like the sky.
- :doc:`Sun &lt;/render/blender_render/lighting/lamps/sun/introduction&gt;`
simulates a very far away and punctual light source, like the sun.

.. figure:: /images/render_blender-render_lighting_lamps_introduction_visual.png

Visual height and shadow markers of two points lamps. Ray Shadow is enabled on the left lamp.

You can add new lamps to a scene using the *Add* menu in the top header, or with
:menuselection:`Add --&gt; Lamp`, :kbd:`Shift-A`.

Once added, a lamp's position is indicated in the 3D View by a solid dot in a circle, but most
types also feature dashed wire-frames that help describe their orientation and properties.
While each type is represented differently,
there are some visual indicators common to all of them:

Shadows
If shadows are enabled, an additional dashed circle is drawn around the solid circle.
This makes it easier to quickly determine if a lamp has shadows enabled.
Vertical Height Marker
This is a dim gray line, which helps locate the lamp's position relative to the global XY plane.
..    TODO/Review: {{review|im=examples}}.

*****
Point
*****

.. figure:: /images/lighting-lamps-point.png
:width: 200px

Point lamp.

The *Point* lamp is an omni-directional point of light, that is,
a point radiating the same amount of light in all directions. It's visualized by a plain,
circled dot. Being a point light source, the direction of the light hitting an object's
surface is determined by the line joining the lamp and the point on the surface of the object
itself.

Light intensity/energy decays based on (among other variables)
distance from the *Point* lamp to the object. In other words,
surfaces that are further away are rendered darker.

Lamp Options
============

Distance, Energy and Color
These settings are common to most types of lamps, and are described in
:doc:`Light Properties &lt;/render/blender_render/lighting/lights/lamp_panel&gt;`.

Negative, This Layer Only, Specular, and Diffuse
These settings control what the lamp affects, as described in
:ref:`What Light Affects &lt;bi-lamp-influence&gt;`.

Falloff and Sphere
These settings control how the light of the *Lamp* decays with distance.
See :doc:`Light Attenuation &lt;/render/blender_render/lighting/lights/light_attenuation&gt;` for details.

Shadows
=======

.. figure:: /images/lighting-lamps-point_panel-noshad.png
:width: 307px

Without ray shadows.

.. figure:: /images/lighting-lamps-point_panel-rayshad.png
:width: 307px

Point lamp with ray shadows and Adaptive QMC sample generator enabled.

The *Point* light source can only cast ray-traced shadows.
It shares with other lamp types the common shadow options described in
:doc:`/render/blender_render/lighting/shadows/shadow_panel`.

The ray-traced shadows settings of this lamp are shared with other lamps,
and are described :doc:`Raytraced Properties &lt;/render/blender_render/lighting/shadows/raytraced_properties&gt;`.
..    TODO/Review: {{review|text=simplify?}}.

*********************
Spot Buffered Shadows
*********************

.. figure:: /images/lighting-shadow-spot_buf_shad.png
:width: 310px

Buffer Shadow enabled for a Spot lamp.

Spotlights can use either
:doc:`Raytraced Shadows &lt;/render/blender_render/lighting/shadows/raytraced_properties&gt;`
or buffered shadows. Either of the two can provide various extra options.

Raytraced shadows are generally more accurate,
with extra capabilities such as transparent shadows, although they are quite slower to render.

Buffered shadows are more complex to set up and involve more faking,
but the speed of rendering is a definite advantage.
Nevertheless, it shares with other lamp types common shadows options described in
:doc:`/render/blender_render/lighting/shadows/shadow_panel`.

Shadow Buffer Types
===================

When the *Buffer Shadow* button is activated,
the currently selected *Spot* light generates shadows,
using a "shadow buffer" rather than using raytracing,
and various extra options and buttons appear in the *Shadow* panel.

Buffer Type
There more than one way to generate buffered shadows.
The shadow buffer generation type controls which generator to use.
There are four shadow generation types, those being:
- Classical
- Classic-Halfway
- Irregular
- Deep

For more information on the different shadow generation methods see these links:

- `Development Release Logs 2.43: Irregular Shadow Buffer
&lt;https://www.blender.org/development/release-logs/blender-243/irregular-shadow-buffer/&gt;`__.
- `Blender Nation: Blender Gets Irregular Shadow Buffers
&lt;http://www.blendernation.com/2006/10/15/blender-gets-irregular-shadow-buffers/&gt;`__.
- `Development Release Logs 2.43: Shadow Buffer Halfway Average
&lt;https://www.blender.org/development/release-logs/blender-243/shadow-buffer-halfway-average/&gt;`__.

"Classical" and "Classic-Halfway"
---------------------------------

.. figure:: /images/lighting-shadow-spot_buf_shad.png
:width: 310px

Buffer Shadowset to Classic-Halfway.

Classical
A shadow generation which used to be the Blender default and unique method for generation of buffered shadows.
It used an older way of generating buffered shadows,
but it could have some problems with accuracy of the generated shadows and can be very
sensitive to the resolution of the shadow buffer :menuselection:`Shadow Buffer --&gt; Size`,
different *Bias* values, and all the self-shadowing issues that brings up.

The *Classical* method of generating shadows is obsolete and is really only still present to
allow for backward compatibility with older versions of Blender.
In most other cases you will want to use *Classic-Halfway* instead.

Classic-Halfway
This shadow buffer type is an improved shadow buffering method and is the default option selected in Blender.
It works by taking an averaged reading of the first and second nearest Z depth values
allowing the *Bias* value to be lowered and yet not suffer as much from self-shadowing issues.

Not having to increase *Bias* values helps with shadow accuracy,
because large *Bias* values can mean small faces can lose their shadows,
as well as preventing shadows being overly offset from the larger *Bias* value.

*Classic-Halfway* does not work very well when faces overlap, and biasing problems can happen.

Here are now the options specific to these generation methods:

Size
The *Size* number button can have a value from (512 to 10240).
*Size* represents the resolution used to create a shadow map.
This shadow map is then used to determine where shadows lay within a scene.

As an example, if you have a *Size* with a value of 1024,
you are indicating that the shadow data will be written to a buffer which will have a *square*
resolution of 1024×1024 pixels/samples from the selected spotlight.

The higher the value of *Size*, the higher resolution and accuracy of the resultant shadows,
assuming all other properties of the light and scene are the same,
although more memory and processing time would be used.
The reverse is also true -- if the *Size* value is lowered,
the resultant shadows can be of lower quality,
but would use less memory and take less processing time to calculate.

As well as the *Size* value affecting the quality of generated shadows,
another property of *Spot* lamps that affects the quality of their buffered shadows is the
angle of the spotlights lighted area (given in the *Spot Shape* panel's *Size* field).

As the spot shape *Size* value is increased, the quality of the cast shadows degrades.
This happens because when the *Spot* lighted area is made larger (by increasing spot shape *Size*),
the shadow buffer area has to be stretched and scaled to fit the size of the new lighted area.

The *Size* resolution is not altered to compensate for the change in size of the spotlight,
so the quality of the shadows degrades. If you want to keep the generated shadows the same quality,
as you increase the spot shape *Size* value, you also need to increase the buffer *Size* value.

.. note:: The above basically boils down to

If you have a spotlight that is large you will need to have a larger buffer *Size* to keep
the shadows good quality.
The reverse is true also -- the quality of the generated shadows will usually improve
(up to a point) as the *Spot* lamp covers a smaller area.

Filter Type
The *Box*, *Tent*, and *Gauss* filter types control what filtering algorithm to use to
anti-alias the buffered shadows.

They are closely related to the *Samples* number button,
as when this setting is set to 1, shadow filtering is disabled,
so none of these buttons will have any effect what soever.

Box
The buffered shadows will be anti-aliased using the "box" filtering method.
This is the original filter used in Blender.
It is relatively low quality and is used for low resolution renders, as it produces very sharp anti-aliasing.
When this filter is used,
it only takes into account oversampling data which falls within a single pixel,
and does not take into account surrounding pixel samples.
It is often useful for images which have sharply angled elements and horizontal/vertical lines.

Tent
The buffered shadows will be anti-aliased using the "tent" filtering method.
It is a simple filter that gives sharp results, an excellent general purpose filtering method.
This filter also takes into account the sample values of neighboring pixels when
calculating its final filtering value.

Gauss
The buffered shadows will be anti-aliased using the "Gaussian" filtering method.
It produces a very soft/blurry anti-aliasing. As result, this filter is excellent with high resolution renders.

The :doc:`Anti-Aliasing page &lt;/render/blender_render/settings/antialiasing&gt;` in the Render chapter will give
more information on the various filtering/distribution methods and their uses.

Samples
The *Samples* number button can have a value between (1 and 16).
It controls the number of samples taken per pixel when calculating shadow maps.

The higher this value, the more filtered,
smoothed and anti-aliased the shadows cast by the current lamp will be,
but the longer they will take to calculate and the more memory they will use.
The anti-aliasing method used is determined by having one of the *Box*,
*Tent* or *Gauss* buttons activated (see above).

Having a *Samples* value of 1 is similar to turning off anti-aliasing for buffered shadows.

Soft
The *Soft* number button can have a value between (1.0 to 100.0).
It indicates how wide an area is sampled when doing anti-aliasing on buffered shadows.
The larger the *Soft* value,
the more graduated/soft the area that is anti-aliased/softened on the edge of generated shadows.

Sample Buffers
The *Sample Buffers* setting can be set to values (1, 4 or 9),
and represents the number of shadow buffers that will be used when doing anti-aliasing on buffered shadows.

This option is used in special cases,
like very small objects which move and need to generate really small shadows (such as strands).
It appears that normally, pixel width shadows do not anti-alias properly,
and that increasing *Buffer Size* does not help much.

So this option allows you to have a sort of extra sample pass, done above the regular one
(the one controlled by the *Box* / *Tent* / *Gauss*, *Samples* and *Soft* settings).

The default 1 value will disable this option.

Higher values will produce a smoother anti-aliasing --
but be careful: using a *Sample Buffers* of 4 will require four times as much memory and process time,
and so on, as Blender will have to compute that number of sample buffers.

"Irregular"
-----------

.. figure:: /images/lighting-lamps-spot-buf-irregular.jpg
:width: 313px

Buffer Shadow set to Irregular.

Irregular shadow method is used to generate sharp/hard shadows that are placed as accurately as raytraced shadows.
This method offers very good performance because it can be done as a multi-threaded process.

This method supports transparent shadows.
To do so, you will first need to setup the shadow setting for the object which will receive the transparent shadow
:menuselection:`Material --&gt; Shadow --&gt; Cat Buffer Shadows and Buffer Bias`.

Deep generation method
----------------------

.. figure:: /images/lighting-lamps-spot-buf-deep.jpg
:width: 313px

Buffer Shadow set to Deep.

Deep Shadow buffer supports transparency and better filtering,
at the cost of more memory usage and processing time.

Compress
Deep shadow map compression threshold.

Common options
==============

The following settings are common to all buffered shadow generation method.

Bias
The *Bias* number button can have a value between (0.001 to 5.0).
*Bias* is used to add a slight offset distance between an object and the shadows cast by it.
This is sometimes required because of inaccuracies in the calculation which determines
weather an area of an object is in shadow or not.

Making the *Bias* value smaller results in the distance between the object and its shadow being smaller.
If the *Bias* value is too small, an object can get artifacts,
which can appear as lines and interference patterns on objects.
This problem is usually called "self shadowing",
and can usually be fixed by increasing the *Bias* value, which exists for that purpose!

Other methods for correcting self shadowing include increasing the size of the *Shadow
Buffer Size* or using a different buffer shadow calculation method such as *Classic-Halfway* or *Irregular*.

Self shadowing interference tends to affect curved surfaces more than flat ones,
meaning that if your scene has a lot of curved surfaces it may be necessary to increase the
*Bias* value or *Shadow Buffer Size* value.

Having overly large *Bias* values not only places shadows further away from their casting objects,
but can also cause objects that are very small to not cast any shadow at all.
At that point altering *Bias*, *Shadow Buffer Size* or *Spot Size* values,
among other things, may be required to fix the problem.

.. note:: Finer Bias tuning

You can now refine the *Bias* value independently for each
:doc:`Material &lt;/render/blender_render/materials/index&gt;`,
using the *Bias* slider (*Material* menu, *Shadow* panel).
This value is a factor by which the *Bias* value of each *Spot* buffered shadows lamp is multiplied,
each time its light hits an object using this material.
The (0.0 and 1.0) values are equivalent. They do not alter the lamp's *Bias* original value.

Clip Start &amp; Clip End
When a *Spot* light with buffered shadows is added to a scene,
an extra line appears on the *Spot* 3D View representation.

The start point of the line represents *Clip Start* 's value and the end of the line
represents *Clip End* 's value.
*Clip Start* can have a value between (0.1 to 1000.0), and *Clip End*,
between (1.0 to 5000.0). Both values are represented in Blender Units.

*Clip Start* indicates the point after which buffered shadows can be present within the *Spot* light area.
Any shadow which could be present before this point is ignored and no shadow will be generated.

*Clip End* indicates the point after which buffered shadows will not be generated within the *Spot* light area.
Any shadow which could be present after this point is ignored and no shadow will be generated.

The area between *Clip Start* and *Clip End* will be capable of having buffered shadows generated.

Altering the *Clip Start* and *Clip End* values helps in controlling where shadows can be generated.
Altering the range between *Clip Start* and *Clip End* can help speed up rendering,
save memory and make the resultant shadows more accurate.

When using a *Spot* lamp with buffered shadows,
to maintain or increase quality of generated shadows,
it is helpful to adjust the *Clip Start* and *Clip End* such that their values closely bound
around the areas which they want to have shadows generated at.
Minimizing the range between *Clip Start* and *Clip End*,
minimizes the area shadows are computed in and therefore helps increase shadow quality in
the more restricted area.

Autoclip Start &amp; Autoclip End
As well as manually setting *Clip Start* and *Clip End* fields to control when buffered shadows start and end,
it is also possible to have Blender pick the best value independently for each *Clip Start* and *Clip End* field.

Blender does this by looking at where the visible vertices are when viewed from the *Spot* lamp position.

Hints
=====

Any object in Blender can act as a camera in the 3D View. Hence you can select the
*Spot* light and switch to a view from its perspective by pressing :kbd:`Ctrl-Numpad0`.
..    TODO/Review: {{review|}}.

***********************
Spot Volumetric Effects
***********************

.. figure:: /images/lighting-lamps-spot-halo_options.png
:width: 310px

Spot lamps's Halo options.

*Spot* lights also can produce "volumetric" effects.
See :doc:`Volumetric Light &lt;/render/blender_render/lighting/volumetric_lights&gt;`
for more information about what it means.

Halo
The *Halo* button allows a *Spot* lamp to have a volumetric effect applied to it.
This button must be active if the volumetric effect is to be visible.
Note that if you are using buffered shadows, you have extra options described in the
:doc:`Spot Buffered Shadows &lt;/render/blender_render/lighting/lamps/spot/buffered_shadows&gt;` page.

Intensity
The *Intensity* slider controls how intense/dense the volumetric effect is that is generated
from the light source. The lower the value of the *Intensity* slider,
the less visible the volumetric effect is,
while higher *Intensity* values give a much more noticeable and dense volumetric effect.
Step
This field can have a value between (0 to 12).
It is used to determine whether this *Spot* will cast volumetric shadows,
and what quality those volumetric shadows will have.
If *Step* is set to a value of 0, then no volumetric shadow will be generated.
Unlike most other controls, as the *Step* value increases,
the quality of volumetric shadows decreases (but take less time to render), and *vice versa*.

.. tip:: Step values

A value of 8 for *Halo Step* is usually a good compromise between speed and accuracy.

Blender only simulates volumetric lighting in *Spot* lamps when using its internal renderer.
This can lead to some strange results for certain combinations of settings for the light's
*Energy* and the halo's *Intensity*.
For example, having a *Spot* light with null or very low light *Energy* settings but a very
high halo *Intensity* setting can result in a dark/black halo, which would not happen in the real world.
Just be aware of this possibility when using halos with the internal renderer.

.. note::

The halo effect can be greatly enhanced when using buffered shadows: when the halo's *Step* is not null,
they can create "volumetric shadows".
See the page about *Spot*
:doc:`Buffered Shadows &lt;/render/blender_render/lighting/lamps/spot/buffered_shadows&gt;` for more information.

.. seealso::

- :doc:`Shadows &lt;/render/blender_render/lighting/shadows/introduction&gt;`
- :doc:`Spot Lamp &lt;/render/blender_render/lighting/lamps/spot/introduction&gt;`
- :doc:`Spot Buffered Shadows &lt;/render/blender_render/lighting/lamps/spot/buffered_shadows&gt;`

#######
Spot
#######

.. toctree::
:maxdepth: 2

introduction.rst
buffered_shadows.rst
halos.rst
..    TODO/Review: {{review|text=like 2.4?}}.

************
Introduction
************

A *Spot* lamp emits a cone-shaped beam of light from the tip of the cone,
in a given direction.

The *Spot* light is the most complex of the light objects and indeed,
for a long time,
among the most used thanks to the fact that it was the only one able to cast shadows.
Nowadays, with a ray tracer integrated into Blender's internal render engine,
all lamps can cast shadows (except *Hemi*). Even so,
*Spot* lamps' shadow buffers are much faster to render than ray-traced shadows,
especially when blurred/softened,
and spot lamps also provide other functionality such as "volumetric" halos.

Lamp options
============

.. figure:: /images/lighting-lamps-spot-lamp_options.jpg
:width: 307px

Common Lamp options of a Spot.

Distance, Energy and Color
These settings are common to most types of lamps, and are described in
:doc:`Light Properties &lt;/render/blender_render/lighting/lights/lamp_panel&gt;`.
This Layer Only, Negative, Diffuse and Specular
These settings control what the lamp affects, as described in
:ref:`What Light Affects &lt;bi-lamp-influence&gt;`.
Light Falloff and Sphere
These settings control how the light of the *Spot* decays with distance.
See :doc:`Light Attenuation &lt;/render/blender_render/lighting/lights/light_attenuation&gt;` for details.

.. figure:: /images/lighting-lamps-spot-terms.png
:width: 610px

Changing the Spot options also changes the appearance of the spotlight as displayed in the 3D View.

Shadows
=======

.. figure:: /images/lighting-lamps-spot-ray_panel.png
:width: 306px

Shadow panel set to Ray Shadow.

Spotlights can use either ray-traced shadows or buffered shadows.
Either of the two can provide various extra options.
Ray-traced shadows are generally more accurate,
with extra capabilities such as transparent shadows, although they are quite slower to render.

No Shadow
Choose this to turn shadows off for this spot lamp.
This can be useful to add some discreet directed light to a scene.
Buffer Shadow
*Buffered Shadows* are also known as depth map shadows.
Shadows are created by calculating differences in the distance from the light to scene objects.
See :doc:`Buffered Shadows &lt;/render/blender_render/lighting/lamps/spot/buffered_shadows&gt;`
for full details on using this feature.
Buffered shadows are more complex to set up and involve more faking,
but the speed of rendering is a definite advantage.
Nevertheless, it shares with other lamp types common shadow options
described in :doc:`/render/blender_render/lighting/shadows/shadow_panel`.
Ray Shadow
The ray-traced shadows settings of this lamp are shared with other lamps,
and are described in :doc:`Raytraced Properties &lt;/render/blender_render/lighting/shadows/raytraced_properties&gt;`.

Spot Shape
==========

Size
The size of the outer cone of a *Spot*,
which largely controls the circular area a *Spot* light covers.
This slider in fact controls the angle at the top of the lighting cone,
and can be between (1.0 to 180.0).

.. list-table::
Changing the spot *Size* option.

* - .. figure:: /images/lighting-lamps-spot-size_45.png
:width: 320px

- .. figure:: /images/lighting-lamps-spot-size_60.png
:width: 320px

Blend
The *Blend* slider controls the inner cone of the *Spot*.
The *Blend* value can be between (0.0 to 1.0).
The value is proportional and represents that amount of space that the inner cone should
occupy inside the outer cone *Size*.

The inner cone boundary line indicates the point at which light from the *Spot* will start to blur/soften;
before this point its light will mostly be full strength.
The larger the value of *Blend* the more blurred/soft the edges of the spotlight will be,
and the smaller the inner cone's circular area will be (as it starts to blur/soften earlier).

To make the *Spot* have a sharper falloff rate and therefore less blurred/soft edges,
decrease the value of *Blend*.
Setting *Blend* to 0.0 results in very sharp spotlight edges, without any transition between light and shadow.

The falloff rate of the *Spot* lamp light is a ratio between the *Blend* and *Size* values;
the larger the circular gap between the two, the more gradual the light fades between *Blend* and *Size*.

*Blend* and *Size* only control the *Spot* light cone's aperture and softness
("radial" falloff); they do not control the shadow's softness as shown below.

.. figure:: /images/render_blender-render_lighting_lamps_spot_introduction_shadow-spotlight.png
:width: 400px

Render showing the soft edge spotlighted area and the sharp/hard object shadow.

Notice in the picture above that the object's shadow is sharp as a result of the ray tracing,
whereas the spotlight edges are soft.
If you want other items to cast soft shadows within the *Spot* area, you will need to alter other shadow settings.

Square
The *Square* button makes a *Spot* light cast a square light area, rather than the default circular one.
Show Cone
Draw a transparent cone in 3D View to visualize which objects are contained in it.
Halo
Adds a volumetric effects to the spot lamp.
See :doc:`Spot Halos &lt;/render/blender_render/lighting/lamps/spot/halos&gt;`.

######
Sun
######

.. toctree::
:maxdepth: 2

introduction.rst
sky_and_atmosphere.rst
..    TODO/Review: {{review|im= examples}}.

************
Introduction
************

A *Sun* lamp provides light of constant intensity emitted in a single direction.
A *Sun* lamp can be very handy for a uniform clear daylight open-space illumination.
In the 3D View,
the *Sun* light is represented by an encircled black dot with rays emitting from it,
plus a dashed line indicating the direction of the light.

This direction can be changed by rotating the *Sun* lamp, like any other object,
but because the light is emitted in a constant direction,
the location of a *Sun* lamp does not affect the rendered result (unless you use the
:doc:`"sky &amp; atmosphere" option &lt;/render/blender_render/lighting/lamps/sun/sky_and_atmosphere&gt;`).

.. figure:: /images/lighting-lamps-sun-lamp_panel.jpg
:width: 304px

Sun lamp panel.

Lamp options
============

Energy and Color
These settings are common to most types of lamps, and are described in
:doc:`Light Properties &lt;/render/blender_render/lighting/lights/lamp_panel&gt;`.
Negative, This Layer Only, Specular, and Diffuse
These settings control what the lamp affects, as described in
:ref:`What Light Affects &lt;bi-lamp-influence&gt;`.

The *Sun* lamp has no light falloff settings: it always uses a constant attenuation
(i.e. no attenuation!).

Sky &amp; Atmosphere
================

.. figure:: /images/render_blender-render_lighting_lamps_sun_sky-atmosphere_panel.png

Sky &amp; Atmosphere panel.

Various settings for the appearance of the sun in the sky,
and the atmosphere through which it shines, are available. For details, see
:doc:`Sky and Atmosphere &lt;/render/blender_render/lighting/lamps/sun/sky_and_atmosphere&gt;`.

Shadow
======

.. figure:: /images/lighting-lamps-sun-shade_panel.jpg
:width: 304px

Shadow panel.

The *Sun* light source can only cast ray-traced shadows.
It shares with other lamp types the same common shadowing options,
described in :doc:`/render/blender_render/lighting/shadows/shadow_panel`.

The ray-traced shadows settings of this lamp are shared with other lamps,
and are described in :doc:`Raytraced Properties &lt;/render/blender_render/lighting/shadows/raytraced_properties&gt;`.
..    TODO/Review: {{review}}.

****************
Sky &amp; Atmosphere
****************

.. figure:: /images/render_blender-render_lighting_lamps_sun_sky-atmosphere_panel.png

Sky &amp; Atmosphere panel.

This panel allows you to enable an effect that simulates various properties of real sky and
atmosphere: the scattering of sunlight as it crosses the kilometers of air overhead.
For example, when the Sun is high, the sky is blue (and the horizon, somewhat whitish).
When the Sun is near the horizon, the sky is dark blue/purple, and the horizon turns orange.
The dispersion of the atmosphere is also more visible when it is a bit foggy:
the farther away an object is, the more "faded" in light gray it is...
Go out into the countryside on a nice hot day, and you will see.

To enable this effect, you have to use a *Sun* light source. If, as usual,
the *position* of the lamp has no importance, its *rotation* is crucial:
it determines which hour it is. As a starting point,
you should reset rotation of your *Sun* (with :kbd:`Alt-R`, or typing :kbd:`0`
in each of the three *Rotation* fields X, Y, Z in
the *Transform* panel). This way,
you will have a nice mid-day sun (in the tropics).

Now, there are two important angles for the *Sky/Atmosphere* effect:
the "incidence" angle (between the light direction and the X-Y plane),
which determines the "hour" of the day (as you might expect,
the default rotation -- straight down -- is "mid-day",
a light pointing straight up is "midnight", and so on...).
And the rotation around the Z axis determines the position of the sun around the camera.

.. figure:: /images/render_blender-render_lighting_lamps_sun_sky-atmosphere_position.png
:width: 700px

The dashed "light line" of the Sun lamp crossing the camera focal point.

In fact, to have a good idea of where the sun is in your world,
relative to the camera in your 3D View, you should always try to have the dashed "light line"
of the lamp crossing the center of the camera (its "focal" point), as shown in
(The dashed "light line" of the *Sun lamp* crossing the camera focal point).
This way, in camera view (:kbd:`Numpad0`, center area in the example picture),
you will see where the "virtual" sun created by this effect will be.

It is important to understand that the *position* of the sun has no importance for the
effect: only its *orientation* is relevant.
The position just might help you in your scene design.

Options
=======

Sun &amp; Sky Presets
- Classic
- Desert
- Mountain

Sky
---

Sky
This button enables the sky settings: it will create a "sky", with a "sun" if visible,
and mix it with the background as defined in *World* settings.

Turbidity
This is a general parameter that affects sun view, sky and atmosphere;
it is an atmosphere parameter where low values describe clear sky, and high values shows more foggy sky.
In general, low values give a clear, deep blue sky, with "little" sun; high values give a more reddish sky,
with a big halo around the sun.
Note that this parameter is one which can really modify the "intensity" of the sun lighting. See examples below.

Here are its specific controls:

Blending
The select menu shows various mix methods.
The one selected will be used to blend the sky and sun with the background defined in the *World* settings.
The mixing methods are the same as described e.g.
in the :doc:`Mix Compositing Node &lt;/compositing/types/color/mix&gt;` page.

Factor
Controls how much the sky and sun effect is applied to the World background.

Color space
These buttons allows you to select which color space the effect uses, with the following choices:

- CIE
- REC709
- SMPTE
- Exposure

This number button allows you to modify the exposure of the rendered Sky and Sun (0.0 for no correction).

Horizon
Brightness
Controls brightness of colors at the horizon. Its value should be in the range (0.0 to 10.0);
values near zero means no horizontal brightness,
and large values for this parameter increase horizon brightness.
See examples below.
Spread
Controls spread of light at the horizon. Its value should be in the range (0.0 to 10.0);
values low in the range result in less spread of light at horizon,
and values high in the range result in horizon light spread in through all the sky.

Sun
Brightness
Controls the sun brightness. Its value should be in the range (0.0 to 10.0);
with low values the sky has no sun and with high values the sky only has sun.
Size
Controls the size of sun. Its values should be in the range (0.0 to 10.0),
but note that low values result in large sun size, and high values result in small sun size.
Note that the overall brightness of the sun remains constant (set by *Brightness*),
so the larger the sun (the smaller *Size*), the more it "vanishes" in the sky, and *vice versa*.
Back Light
For "Back Scatter Light", result on sun's color, high values result in more light around the sun.
Its values range is (-1.0 to 1.0). Negative values result in less light around sun.

Atmosphere
----------

Atmosphere
This button enables the atmosphere settings.
It will not modify the background, but it tries to simulate the effects of an atmosphere:
scattering of the sunlight in the atmosphere, its attenuation, ...
Intensity
Sun
Sets sun intensity. Its values are in range (0.0 to 10.0).
High values result in bluer light on far objects.
Distance
This factor is used to convert Blender units into an understandable unit for atmosphere effect,
it starts from 0 and high values result in more yellow light in the scene.
Scattering
Inscattering
This factor can be used to decrease the effect of light inscattered
into atmosphere between the camera and objects in the scene.
This value should be 1.0 but can be changed to create some nice, but not realistic, images.
Extinction
This factor can be use to decrease the effect of extinction light from objects in the scene.
Like *Inscattering* factor, this parameter should be 1.0 but you can change it;
low values result in less light extinction. Its value is in the range (0.0 to 1.0).

Examples
========

First, let us see what happens when we modify the orientation of the sun:

.. list-table::
Variations in Sun orientation, Sun Size to 5.0, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-midday.jpg
:width: 200px

With sun right overhead (mid-day).

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-midnight.png
:width: 200px

With sun deep "under the Earth" (midnight).

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-early_twilight.jpg
:width: 200px

Sun slightly above the horizon (start of twilight).

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-latetwilight.jpg
:width: 200px

Sun slightly below the horizon (end of twilight).

`The 2.4 blend-file of these examples
&lt;https://wiki.blender.org/index.php/Media:Manual-Lighting-Lamps-Sun-SkyAtmosphere-Examples-SunOrientation.blend&gt;`__.

And now, the effects of various settings (examples created with
`this 2.4 blend-file
&lt;https://wiki.blender.org/index.php/Media:Manual-Lighting-Lamps-Sun-SkyAtmosphere-Examples-Settings.blend&gt;`__):

.. list-table::
Variations in Turbidity parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight1_0.jpg
:width: 200px

Turbidity: 2.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-turbidity2_3.jpg
:width: 200px

Turbidity: 2.3.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-turbidity5_0.jpg
:width: 200px

Turbidity: 5.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-turbidity10_0.jpg
:width: 200px

Turbidity: 10.0.

Sky
---

.. list-table::
Variations in Horizon Brightness parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-hor_bright0_0.jpg
:width: 200px

Horizon Brightness: 0.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-hor_bright0_85.jpg
:width: 200px

Horizon Brightness: 0.85.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-hor_bright1_04.jpg
:width: 200px

Horizon Brightness: 1.04.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-hor_bright1_13.jpg
:width: 200px

Horizon Brightness: 1.13.

.. list-table::
Variations in Horizon Spread parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-hor_spread0_7.jpg
:width: 200px

Horizon Spread: 0.7.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-hor_spread1_2.jpg
:width: 200px

Horizon Spread: 1.2.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-hor_spread2_2.jpg
:width: 200px

Horizon Spread: 2.2.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-hor_spread5_0.jpg
:width: 200px

Horizon Spread: 5.0.

.. list-table::
Variations in Sun Brightness parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_bright0_2.jpg
:width: 200px

Sun Brightness: 0.2.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_bright0_5.jpg
:width: 200px

Sun Brightness: 0.5.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_bright0_75.jpg
:width: 200px

Sun Brightness: 0.75.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight1_0.jpg
:width: 200px

Sun Brightness: 1.0.

.. list-table::
Variations in Sun Size parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_size2_0.jpg
:width: 200px

Sun Size: 2.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_size4_0.jpg
:width: 200px

Sun Size: 4.0.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_size7_0.jpg
:width: 200px

Sun Size: 7.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_size10_0.jpg
:width: 200px

Sun Size: 10.0.

.. list-table::
Variations in Back Light parameter, Sun Bright to 2.5, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight-1_0.jpg
:width: 200px

Back Light: -1.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight-0_33.jpg
:width: 200px

Back Light: -0.33.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight0_33.jpg
:width: 200px

Back Light: 0.33.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight1_0.jpg
:width: 200px

Back Light: 1.0.

Atmosphere
----------

For all renders below, *Hor.Bright* is set to 0.2, and *Sun Bright* to 2.0.

.. list-table::
Variations in Sun Intensity parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-inscattering0_1.jpg
:width: 200px

Sun Intensity: 1.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_intensity3_33.jpg
:width: 200px

Sun Intensity: 3.33.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-sun_intensity6_66.jpg
:width: 200px

Sun Intensity: 6.66.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight1_0.jpg
:width: 200px

Sun Intensity: 10.0.

.. list-table::
Variations in Inscattering parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-inscattering0_1.jpg
:width: 200px

Inscattering: 0.1.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-inscattering0_33.jpg
:width: 200px

Inscattering: 0.33.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-inscattering0_66.jpg
:width: 200px

Inscattering: 0.66.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight1_0.jpg
:width: 200px

Inscattering: 1.0.

.. list-table::
Variations in Extinction parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-extinction0_0.jpg
:width: 200px

Extinction: 0.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-extinction0_33.jpg
:width: 200px

Extinction: 0.33.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-extinction0_66.jpg
:width: 200px

Extinction: 0.66.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-backlight1_0.jpg
:width: 200px

Extinction: 1.0.

.. list-table::
Variations in Distance parameter, all other settings to default.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-distance1_0.jpg
:width: 200px

Distance: 1.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-distance2_0.jpg
:width: 200px

Distance: 2.0.

* - .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-distance3_0.jpg
:width: 200px

Distance: 3.0.

- .. figure:: /images/lighting-lamps-sun-sky_atmosphere-sky-distance4_0.jpg
:width: 200px

Distance: 4.0.

Hints and limitations
=====================

To always have the *Sun* pointing at the camera center,
you can use a :doc:`Track To constraint &lt;/rigging/constraints/tracking/track_to&gt;` on the sun object,
with the camera as target, and -Z as the "To" axis (use either X or Y as "Up" axis).
This way, to modify height/position of the sun in the rendered picture,
you just have to move it; orientation is automatically handled by the constraint.
Of course, if your camera itself is moving, you should also add e.g.
a :doc:`Copy Location constraint &lt;/rigging/constraints/transform/copy_location&gt;`
to your *Sun* lamp, with the camera as target and the *Offset* option activated...
This way, the sun light will not change as the camera moves around.

If you use the default *Add* mixing type,
you should use a very dark-blue world color, to get correct "nights"...

This effect works quite well with a *Hemi* lamp,
or some ambient occlusion, to fill in the *Sun* shadows.

Atmosphere shading currently works incorrectly in reflections and refractions and is only
supported for solid shaded surfaces. This will be addressed in a later release.

*************
Lighting Rigs
*************

A rig is a standard setup and combination of objects; there can be lighting rigs,
or armature rigs, etc.
A rig provides a basic setup and allows you to start from a known point and go from there.
Different rigs are used for different purposes and emulate different conditions;
the rig you start with depends on what you want to convey in your scene.
Lighting can be very confusing, and the defaults do not give good results. Further,
very small changes can have a dramatic effect on the mood and colors.

In all the lighting rigs,
the default camera is always positioned nearly 15 degrees off dead-on, about 25 BU
(Blender Units) back and 9 BU to the side of the subject, at eye level,
and uses a long lens of 80 mm. Up close, a 35 mm lens will distort the image.
A long lens takes in more of the scene.
A dead-on camera angle is too dramatic and frames too wide a scene to take in.
So now you know; next time you go to a play, sit off-center and you will not miss the action
happening on the sidelines and will have a greater appreciation for the depth of the set.
Anyway, enough about camera angles; this is about lighting.

Environment or Ambient Only
===========================

.. figure:: /images/lighting-rigs-el.png
:width: 320px

Environment (Ambient) lighting only.

In the *World* tab, there is a panel *Environment Lighting*,
where you enable environment or ambient lighting of your scene. Ambient light is the scattered
light that comes from sunlight being reflected off every surface it hits, hitting your object,
and traveling to camera.

.. figure:: /images/lighting-rigs-ao.jpg
:width: 256px

Ambient occlusion.

Ambient light illuminates, in a perfectly balanced, shadeless way, without casting shadows.
You can vary the intensity of the ambient light across your scene via
:doc:`ambient occlusion &lt;/render/blender_render/world/ambient_occlusion&gt;`. The ambient color is a sunny white.

Single Rig
==========

.. figure:: /images/lighting-rigs-01.png
:width: 300px

Standard Spot light rig.

The sole, or key, spot light rig provides a dramatic, showy,
yet effective illumination of one object or a few objects close together.
It is a single *Spot* light, usually with a hard edge.
Halos are enabled in this render to remind you of a smoky nightclub scene.
It is placed above and directly in front of the subject;
in this case 10 BU in front and 10 BU high, just like a stage,
it shines down at about a 40 degrees angle. We use quadratic attenuation.

You can make the spot wider by increasing *Size Spot Shape* and softening the edge
by increasing *Blend Spot Shape*, and parent it to the main actor,
so that the spot follows him as he moves around. Objects close to the main actor will
naturally be more lit and your viewer will pay attention to them.

Moving this spot directly overhead and pointing down gives the interrogation effect.
At the opposite end of the show-off emotional spectrum is one soft candlelight
(*Point* lamp, short falloff *Distance*, yellow light)
placed really up close to the subject, dramatizing the fearful "lost in the darkness" effect.

Somewhere in the macabre spectrum is a hard spot on the floor shining upward. For fun,
grab a flashlight, head into the bathroom and close the door.
Turn out the light and hold the flashlight under your chin, pointing up.
Look in the mirror and turn it on. From this you can see that lighting,
*even* with a single light, varying the intensity,
location and direction, changes *everything* in a scene.

Use this rig, with *Environment Lighting* light
(and props receiving and being lit by ambient light in their material settings)
for scenes that feature one main actor or a product being spotlighted.
Do not use this rig for big open spaces or to show all aspects of a model.

Two-Point Rig
=============

.. figure:: /images/lighting-rigs-02.png
:width: 300px

Standard two-point light rig.

The two-point lighting rig provides a balanced illumination of an object.
Shown to the right are the views of the standard two-point lighting rig.
It is called the two-point because there are two points of light. The standard two-point
lighting rig provides a balanced illumination of untextured objects hanging out there in 3D
space. This rig is used in real studios for lighting a product, especially a glossy one.

Both lights are almost the same but do different things. Both emulate very wide,
soft light by being *Hemi*. In real life,
these lights bounce light off the inside of a silver umbrella.

Notice how we use low *Energy* to bring out the dimensionality of the sphere;
I cannot stress that enough. Hard, bright lights actually flatten it and make you squint.
Soft lights allow your eye to focus. We disable specular for right *Hemi*,
so we do not get that shiny forehead or nose.

The lamp on the left however, lets it be known that it is there by enabling specular;
specular flare is that bright spot that is off center above midline on the sphere.

Use this rig to give even illumination of a scene, where there is no main focus.
The *Hemi* 's will light up background objects and props,
so *Environment Lighting* is not that important.
At the opposite end of the lighting spectrum, two narrow *Spot* lights at higher
power with a hard edge gives a "This is the Police, come out with your hands up" kind of look,
as if the subject is caught in the crossfire.

Three-Point Rigs
================

The standard three-point lighting rig is the most common illumination of objects and scenes
bar none. If you want to show off your model, use this rig. As you can see,
the untextured unmaterialized sphere seems to come out at you.
There are multiple thesis on this rig, and you will use one of two:

- Studio: Used in a real studio to film in front of a green screen or backdrop.
Use this rig when you are rendering your CG objects to alpha into the scene so that the
lighting on the actors *and* your CG objects is the same.
- Standard: Used in real life to light actors on a set,
and gives some backlighting to highlight the sides of actors, making them stand out more and giving them depth.

Studio rig
----------

.. figure:: /images/lighting-rigs-03a-studio.png
:width: 300px

Studio three-point light rig.

Shown to the right are the "Studio" top, front,
and side views of the standard three-point lighting rig. It changes the dynamics of the scene,
by making a brighter "key" light give some highlights to the object,
while two side "fill" lights soften the shadows created by the key light.

In the studio, use this rig to film a talking head (actor) in front of a green screen,
or with multiple people, keeping the key light on the main actor.
This rig is also used to light products from all angles,
and the side fill lights light up the props.

The key light is the *Area* light placed slightly above and to the left of the
camera. It allows the specular to come out. It is about 30 BU back from the subject,
and travels with the camera. A little specular shine lets you know there is a light there,
and that you are not looking at a ghost. In real life, it is a spot with baffles, or blinders,
that limit the area of the light.

The two sidelights are reduced to only fill; each of them are *Hemi* lights placed
20 BU to the side and 5 BU in front of the subject, at ground level.
They do not cause a spotshine on the surface by disabling specular, and at ground level,
light under the chin or any horizontal surfaces,
countering the shadows caused by the key light.

Use this rig to give balanced soft lighting that also highlights your main actor or object.
It combines the best of both the single rig and the two-point rig,
providing balanced illumination and frontal highlights. For a wide scene,
you may have to pull the sidelights back to be more positioned like the two-point rig.

Standard Rig
------------

.. figure:: /images/lighting-rigs-03b-standart.png
:width: 300px

Standard three-point light rig.

Without a curtain in back of your main subject, you have depth to work with.
The left fill light has been moved behind the subject (so it is now called a backlight)
and is just off-camera, while the right side fill light remains the same. The keylight gives
you specular reflection so you can play with specularity and hardness in your object's
material settings. The key light gives that "in-the-spotlight" feel, highlighting the subject,
while the backlight gives a crisp edge to the subject against the background.
This helps them stand out.

In this rig, the key light is a fairly bright spot light.
Use a slighter tinge of yellow because the light is so bright;
it is the only light for that side.
The other sidelight has been moved in back and raised to eye (camera) level.
You need to cut the energy of the backlight in half,
or when it is added to the remaining sidelight,
it will light up the side too much and call too much attention to itself.
You can vary the angle and height of the backlight to mimic a sun lighting up the objects.

Use this rig in normal 3D animations to light the main actor.
Use this rig especially if you have transparent objects (like glass)
so that there is plenty of light to shine through them to the camera. The tricky part here is
balancing the intensities of the lights so that no one light competes with or overpowers the
others, while making sure all three work together as a team.

Four-point Rig
==============

.. figure:: /images/lighting-rigs-04.png
:width: 300px

Four-point light rig.

The four-point lighting rig provides a better simulation of outside lighting,
by adding a *Sun* lamp 30 Blender Units above, 10 to the side,
and 15 BU behind the subject.
This sunlight provides backlighting and fills the top of the subject;
even producing an intentional glare on the top of their head,
telling you there is a sun up there. Notice it is colored yellow,
which balances out the blue sidelights.

Changing the key light to a *Spot*, select *Inverse Square*, disable
*Specular* and pure white light combines with and softens the top sun flare while
illuminating the face, resulting in a bright sunshine effect.
Two lights above means sharper shadows as well,
so you might want to adjust the side fill lights. In this picture,
they are still *Hemi*, disable *Specular*.

Use this rig when the camera will be filming from behind the characters,
looking over their shoulder or whatnot, because the sun provides the backlight there.
Also use this rig when you have transparent objects,
so there is light to come through the objects to the camera.

Another spot for the fill light is shining up onto the main actor's face,
illuminating the underside of his chin and neck.
This gets rid of a sometimes ugly shadow under the chin, which if not corrected,
can make the actor look fat or like they have a double chin; otherwise distracting.
It evens out the lighting of the face.

Troubleshooting
===============

If you run into a problem with your render, where there are really bright areas,
or really dark ones, or strange shadows, or lines on your objects,
here are some good steps to debugging what is wring:

#. First, try deactivating all materials
(create a default, gray one, and enter its name in the *Mat* field, *Layer* panel,
the *Render Layer* tab to get back all your normal materials, just erase this text field!).
See if you get those problems with just grayness objects. If you do not have the problem anymore,
that should tell you that you have got a materials-interacting-with-light problem.
Check the material settings, especially ambient,
reflection and all those little buttons and sliders in the *Material* tab.
You can set some lights to affect only certain materials,
so if there is an issue with only a few objects being really bright, start with those.
#. Then start "killing" lights (e.g. moving them to an unused layer);
regress all the way back to one light, make sure it is smooth,
then add them in one by one. As they add together, reduce power in the tested ones so they merge cleanly,
or consider not adding it at all, or, especially, reduce the energy of the lamp you just introduced.
#. You can also set lights to only light objects on a layer, so again, if some of the gray spheres have weirdness,
check for that as well. Again, you may have done some of this accidentally,
so sometimes deleting the light and re-adding it with defaults helps you reset to a known-good situation.
#. Negative lights can be very tricky, and make your model blotchy,
so pay special attention to your use of those special lights.
Shadow-only lights can throw off the look of the scene as well.
Overly textured lights can make your scene have random weird colors.
Do not go too far off a slight tinge of blue or yellow or shades of white,
or your material may show blue in the *Material* tab but render green, and you will be very confused.
#. Look at your environment settings *World* tab: *Horizon*, *Zenith*, and *Environment Lighting*.

#########
Lights
#########

.. toctree::
:maxdepth: 2

lamp_panel.rst
light_attenuation.rst
textures.rst
lights_in_other_contexts.rst

**********
Lamp Panel
**********

.. figure:: /images/render_blender-render_lighting_lights_lamp-panel.png

Lamp tab.

Lamp
A :ref:`ui-data-block`. Its list shows all light settings used in the current scene.
Texture Count
Shows the count of textures in the lamp texture stack.

Preview
=======

A quick preview of the light settings.

Lamp
=====

Type
:doc:`Types of lamps &lt;/render/blender_render/lighting/lamps/index&gt;` available in Blender Internal.
They share all or some of the options listed here:
Color
The color of the light source's illumination.
Energy
The intensity of the light source's illumination from (0.0 to 10.0).
Falloff
See :doc:`Light Attenuation &lt;/render/blender_render/lighting/lights/light_attenuation&gt;`.
Distance
The *Distance* number button indicates the number of Blender Units (BU)
at which the intensity of the current light source will be half of its intensity.
Objects less than the number of BU away from the lamp will get more light,
while objects further away will receive less light.
Certain settings and lamp falloff types affect how the *Distance* is interpreted,
meaning that it will not always react the same;
see the page about :doc:`light falloff &lt;/render/blender_render/lighting/lights/light_attenuation&gt;`.

The *Sun* and *Hemi* Lamps are another class of Lamps which uses a constant falloff.
Those lamps do not have a *Distance* parameter, and are often called "Base Lighting Lamps".

.. _bi-lamp-influence:

Influence
---------

Every lamp has a set of switches that control which objects receive its light,
and how it interacts with materials.

Negative
Let the lamp cast negative light.
The light produced by the lamp is *subtracted* from the irradiance on the surfaces it hits,
which darkens these surfaces instead of brightening them.
This Layer Only
The Lamp only illuminates objects on the same layer the lamp is on.
Causes the lamp to only light objects on the same layer.
Specular
The Lamp creates specular highlights.
Diffuse
The Lamp affects diffuse shading.

**********************
Lamps Related Settings
**********************

Here are some options closely related to light sources, without being lamps settings.

Lighting Groups
===============

Materials
---------

.. figure:: /images/render_blender-render_lighting_lights_in-other-contexts_materials.png

Light Group options for Materials.

By default, materials are lit by all lamps in all visible layers, but a material
(and thus all objects using that material) can be limited to a single group of lamps.
This sort of control can be incredibly useful, especially in scenes with complex lighting setups.
To enable this, navigate to the *Material* menu's *Options*
panel and select a group of lamps in the *Light Group* field.
Note that a :doc:`light group &lt;/editors/3dview/object/properties/relations/groups&gt;` must be created first.

If the *Exclusive* button is enabled,
lights in the specified group will *only* affect objects with this material.

Render Layers
-------------

.. figure:: /images/render_blender-render_lighting_lights_in-other-contexts_render-layers.png

Light Group options for Render Layers.

There is a similar control located in the *Layer panel* of the
:doc:`Render Layers &lt;/render/post_process/layers&gt;` tab.
If a light group name is selected in this *Light* field,
the scene will be lit exclusively by lamps in the specified group.

.. seealso::

- :doc:`Lamps Introduction &lt;/render/blender_render/lighting/lamps/introduction&gt;`
- :doc:`Shadows &lt;/render/blender_render/lighting/shadows/introduction&gt;`
- :doc:`Materials Introduction &lt;/render/blender_render/materials/index&gt;`

*****************
Light Attenuation
*****************

.. figure:: /images/render_blender-render_lighting_lights_attenuation_falloff-options.png

Lamp panel, falloff options highlighted.

There are two main controls for light falloff for *Point* and *Spot* lamps:

- The lamp *Falloff* type selector.
- And the *Sphere* checkbox.

Falloff types
=============

Lin/Quad Weighted
-----------------

.. figure:: /images/render_blender-render_lighting_lights_attenuation_linear-quadratic.png

Lamp panel with Lin/Quad Weighted Falloff options highlighted.

When this setting is chosen, two sliders are shown,
*Linear* and *Quadratic*,
which control respectively the "linearness" and "quadraticness" of the falloff curve.

This lamp falloff type is in effect allowing the mixing of the two light attenuation profiles
(linear and quadratic attenuation types).

Linear
^^^^^^

This slider input field can have a value between (0.0 to 1.0).
A value of 1.0 in the *Linear* field and 0.0 in the
*Quadratic* field in effect means that the light from this source is completely
linear. This means that at the number of Blender Units distance specified in the
*Distance* field,
this light source's intensity will be half the value it was originally.

When the *Quadratic* slider is set to 0.0, the formula for working out the
attenuation at a particular range for full linear attenuation is:

:math:`I = E × (D / (D + L × r))`

Where:

- *I* is the calculated Intensity of light.
- *E* is the current *Energy* slider setting.
- *D* is the current setting of the *Distance* field.
- *L* is the current setting of the *Linear* slider.
- *r* is the distance from the lamp where the light intensity gets measured.

Quadratic
^^^^^^^^^

.. _fig-bi-light-lin-default:

.. figure:: /images/light-example-default_lin-quad_weighted.jpg
:width: 250px

Lamp with Lin/Quad Weighted falloff default settings.

This slider input field can have a value between (0.0 to 1.0). A value of 1.0
in the *Quadratic* field and 0.0 in the *Linear* field means that
the light from this source is completely quadratic.

Quadratic attenuation type lighting is considered a more accurate representation of how light
attenuates (in the real world). In fact, fully quadratic attenuation is selected by default.
For *Lin/Quad Weighted* lamp fallout see Fig. :ref:`fig-bi-light-lin-default`.

Here again,
the light intensity is half when it reaches the *Distance* value from the lamp.
Comparing the quadratic falloff to the linear falloff,
the intensity decays much slower at distances lower than the set *Distance*,
but it attenuates much quicker after *Distance* is reached.

When the *Linear* slider is set to 0.0, the formula for working out the
attenuation at a particular range for full quadratic attenuation is:

:math:`I = E × (D^2 / (D^2 + Q × r^2))`

Where:

- *I* is the calculated Intensity of light.
- *E* is the current *Energy* slider setting.
- *D* is the current setting of the *Distance* field.
- *Q* is the current setting of the *Quad* slider.
- *r* is the distance from the lamp where the light intensity gets measured.

Mixing "Linear" and "Quad"
^^^^^^^^^^^^^^^^^^^^^^^^^^

If both the *Linear* and *Quad* slider fields have values greater than
0.0, then the formula used to calculate the light attenuation profile changes to this:

:math:`I = E × (D / (D + L × r)) × (D^2 / (D^2 + Q × r^2))`

Where:

- *I* is the calculated Intensity of light.
- *E* is the current *Energy* slider setting.
- *D* is the current setting of the *Distance* field.
- *L* is the current setting of the *Linear* slider.
- *Q* is the current setting of the *Quad* slider.
- *r* is the distance from the lamp where the light intensity gets measured.

Zeroing both "Linear" and "Quad"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If both the *Linear* and *Quadratic* sliders have 0.0 as their
values, the light intensity will not attenuate with distance.
This does not mean that the light will not get darker, rather it will,
but only because the energy the light has is spread out over a wider and wider distance.
The total amount of energy in the spread-out light will remain the same, though.
The light angle also affects the amount of light you see.
It is in fact the behavior of light in the deep space vacuum.

If what you want is a light source that does not attenuate and gives the same amount of light
intensity to each area it hits,
you need a light with properties like the *Constant* lamp *Falloff* type.

Also, when the *Linear* and *Quad* sliders are both 0.0 values the
*Distance* field ceases to have any influence on the light attenuation,
as shown by the equation above.

Graphical Summary
^^^^^^^^^^^^^^^^^

Below is a graph summarizing the lin/quad attenuation type,
showing attenuation with or without the *Sphere* option (described later).

.. figure:: /images/render_blender-render_lighting_lights_attenuation_linear-quad-graph.png

Light Attenuation:

a) Linear (Linear=1.0, Quad=0.0);
b) Quadratic (Linear=0.0, Quad=1.0);
c) Linear and quadratic (Linear=Quad=0.5);
d) Null (Linear=Quad=0.0);

Also shown in the graph the "same" curves, in the same colors,
but with the Sphere button turned on.

Custom Curve
------------

The *Custom Curve* lamp *Falloff* type is very flexible.

Most other lamp falloff types work by having their light intensity start at its maximum
(when nearest to the light source) and then with some predetermined pattern decrease their
light intensity when the distance from the light source increases.

When using the *Custom Curve* Lamp Falloff type,
a new panel is created called *Falloff Curve*. This *Falloff Curve*
profile graph allows the user to alter how intense light is at a particular point along a
light's attenuation profile (i.e. at a specific distance from the light source).

The *Falloff Curve* profile graph has two axes,
the Distance-axis and the Intensity-axis.

Distance axis
It represents the position at a particular point along a light source's attenuation path.
The far left is at the position of the light source and the far right is the place where the
light source's influence would normally be completely attenuated.
Intensity axis
It represents the intensity at a particular point along a light source's attenuation path.
Higher intensity is represented by being higher up the intensity axis,
while lower intensity light is represented by being lower down on the intensity axis.

Altering the *Falloff Curve* profile graph is easy. Just :kbd:`LMB` click on a
part of the graph you want to alter and drag it where you want it to be.
If when you click you are over or near one of the tiny black square handles,
it will turn white, indicating that this handle is now selected,
and you will be able to drag it to a new position.
If when you click on the graph you are not near a handle,
one will be created at the point that you clicked, which you can then drag where you wish.
You can also create handles at specific parts of the graph,
clicking with :kbd:`LMB` while holding :kbd:`Ctrl`;
it will create a new handle at the point you have clicked.

In the example below (the default for the *Falloff Curve* Profile Graph),
the graph shows that the intensity of the light starts off at its maximum
(when near the light), and linearly attenuates as it moves to the right
(further away from the light source).

.. list-table::

* - .. figure:: /images/lighting-falloff-custom_default.png
:width: 306px

Default Falloff Curve panel graph.

- .. figure:: /images/light-example-default_custom_curve.jpg
:width: 250px

Render showing the Custom Curve lamp falloff type effect with default settings.

If you want to have a light attenuation profile that gets more intense as it moves away from
the light source, you could alter the graph as below:

.. list-table::

* - .. figure:: /images/lighting-falloff-custom_reversed.png
:width: 310px

Falloff Curve for reversed attenuation.

- .. figure:: /images/lights-lamps-falloff_curve_reverse_render.jpg
:width: 250px

Falloff Curve for reversed attenuation rendered.

You are obviously not just limited to simple changes such as reversing the attenuation
profile, you can have almost any profile you desire.

Here is another example of a different *Falloff Curve* profile graph,
along with its resultant render output:

.. list-table::

* - .. figure:: /images/lighting-falloff-custom_oscill.png
:width: 310px

Oscillating attenuation profile.

- .. figure:: /images/lights-lamps-falloff_curve_render.jpg
:width: 250px

Render showing the effects of a "wavelet" profile graph on the light attenuation.

Inverse Square
--------------

.. figure:: /images/light-example-inverse_square.jpg
:width: 300px

Render showing the Inverse Square lamp falloff type effect with default settings.

This lamp falloff type attenuates its intensity according to inverse square law,
scaled by the *Distance* value. Inverse square is a sharper, realistic decay,
useful for lighting such as desk lamps and street lights.
This is similar to the old *Quad* option (and consequently, to the new
*Lin/Quad Weighted* option with *Linear* to 0.0 and *Quad*
to 1.0), with slight changes.

Inverse Linear
--------------

.. figure:: /images/light-example-inverse_linear.jpg
:width: 300px

Render showing the Inverse Linear lamp falloff type effect with default settings.

This lamp falloff type attenuates its intensity linearly,
scaled by the *Distance* value. This is the default setting, behaving the same as the
default in previous Blender versions without *Quad* switched on, and consequently,
like the new *Lin/Quad Weighted* option with *Linear* to 1.0 and
*Quad* to 0.0. This is not physically accurate,
but can be easier to light with.

Constant
--------

.. figure:: /images/light-example-constant.jpg
:width: 300px

Render showing the Constant lamp falloff type effect with default settings.

This lamp falloff type does not attenuate its intensity with distance.
This is useful for distant light sources like the sun or sky,
which are so far away that their falloff is not noticeable.
*Sun* and *Hemi* lamps always have constant falloff.

Inverse Coefficients
--------------------

This lamp falloff type combines the *Inverse Square*, *Inverse Linear* and *Constant*
modes into a single inverse-quadratic formula:

:math:`I = E × (1.0 / (Q × r^2 + L × r + C))`

Where:

- *I* is the calculated Intensity of light.
- *E* is the current *Energy* slider setting.
- *C* is the current setting of the *Constant* slider setting.
- *L* is the current setting of the *Linear* slider setting.
- *Q* is the current setting of the *Quadratic* slider setting.
- *r* is the distance from the lamp where the light intensity gets measured.

Such a falloff model is commonly used in real-time rendering applications via a shading
language like GLSL.

Sphere
======

.. figure:: /images/render_blender-render_lighting_lights_attenuation_sphere-clipping-circle.png
:width: 340px

Screenshot of the 3D View editor, showing the Sphere light clipping circle.

The *Sphere* option restricts the light illumination range of a *Lamp* or
*Spot* lamp, so that it will completely stop illuminating an area once it reaches
the number of Blender Units away from the Lamp, as specified in the *Distance* field.

When the *Sphere* option is active,
a dotted sphere will appear around the light source,
indicating the demarcation point at which this light intensity will be null.

The *Sphere* option adds a term to the chosen attenuation law, whatever it is:

:math:`I' = I × (D - r) / D` if :math:`r &lt; D`;

:math:`I' = 0` otherwise;

Where:

- *I'* is the required Intensity of light (with the *Sphere* option activated).
- *I* is the intensity of light calculated by the chosen attenuation law (without the *Sphere* option).
- *D* is the current setting of the *Distance* field.
- *r* is the distance from the lamp where the light intensity gets measured.

See the graphic at the end of the description of the *Lin/Quad Weighted* attenuation option.

.. list-table::

* - .. figure:: /images/light-constant_falloff-sphere_active-lighted_plane.png
:width: 320px

Render showing the light attenuation of a Constant falloff light type with the Sphere option active.

- .. figure:: /images/light-constant_falloff-sphere_deactivated-lighted_plane.png
:width: 320px

Render showing the light attenuation of a Constant falloff light type with the Sphere option deactivated.

Examples
========

Distance Example
----------------

In this example, the *Lamp* has been set pretty close to the group of planes.
This causes the light to affect the front, middle and rear planes more dramatically.
Looking at the figure below, you can see that as the Distance is increased,
more and more objects become progressively brighter.

.. list-table:: Various Distance settings (shadows disabled).

* - .. figure:: /images/render_blender-render_lighting_lights_attenuation_distance10.jpg

Distance: 10.

- .. _fig-bi-light-attenuation-distance100:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_distance100.jpg

Distance: 100.

- .. _fig-bi-light-attenuation-distance1000:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_distance1000.jpg

Distance: 1000.

The *Distance* parameter is controlling where the light is falling -- at a linear
rate by default -- to half its original value from the light's origin.
As you increase or decrease this value, you are changing where this half falloff occurs. You
could think of *Distance* as the surface of a sphere and the surface is where the
light's intensity has fallen to half its strength in all directions.
Note that the light's intensity continues to fall even after *Distance*.
*Distance* just specifies the distance where half of the light's energy has weakened.

Notice in Fig. :ref:`fig-bi-light-attenuation-distance1000`, that the farthest objects are very bright.
This is because the falloff has been extended far into the distance,
which means the light is very strong when it hits the last few objects. It is not until
1000 units that the light's intensity has fallen to half of its original intensity.

Contrast this with Fig. :ref:`fig-bi-light-attenuation-distance100`,
where the falloff occurs so soon that the farther objects are barely lit.
The light's intensity has fallen by a half by time it even reaches the tenth object.

You may be wondering why the first few planes appear to be dimmer? This is because the surface
angle between the light and the object's surface normal is getting close to oblique.
That is the nature of a *Lamp* light object. By moving the light infinitely far away
you would begin to approach the characteristics of the *Sun* lamp type.

Inverse Square Example
----------------------

*Inverse Square* makes the light's intensity falloff with a non-linear rate, or specifically, a quadratic rate.
The characteristic feature of using *Inverse Square* is that the light's intensity begins to
fall off very slowly but then starts falling off very rapidly.
We can see this in the Fig. :ref:`fig-bi-light-attenuation-inverse-square` images.

.. _fig-bi-light-attenuation-inverse-square:

.. list-table::
Inverse Square selected. (with the specified distances).

* - .. _fig-bi-light-attenuation-inverse-square10:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_quad10.jpg

Inverse Square with 10.

- .. _fig-bi-light-attenuation-inverse-square100:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_quad100.jpg

Inverse Square with 100.

- .. _fig-bi-light-attenuation-inverse-square1000:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_quad1000.jpg

Inverse Square with 1000.

With *Inverse Square* selected, the *Distance* field specifies where the light begins to fall off faster,
roughly speaking; see the light attenuation description in `Falloff types`_ for more info.

In Fig. :ref:`fig-bi-light-attenuation-inverse-square10`,
the light's intensity has fallen so quickly that the last few objects are not even lit.

Both Fig. :ref:`fig-bi-light-attenuation-inverse-square100` and
Fig. :ref:`fig-bi-light-attenuation-inverse-square1000` appear to be almost identical and that is
because the *Distance* is set beyond the farthest object's distance which is at
about 40 BU out. Hence, all the objects get almost the full intensity of the light.

As above, the first few objects are dimmer than farther objects because they are very close to
the light. Remember, the brightness of an object's surface is also based on the angle between
the surface normal of an object and the ray of light coming from the lamp.

This means there are at least two things that are controlling the surface's brightness:
intensity and the angle between the light source and the surface's normal.

Sphere Example
--------------

.. _fig-bi-light-attenuation-clip:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_example-sphere-scene.png

Clipping Sphere.

*Sphere* indicates that the light's intensity is null at the *Distance* distance and beyond,
regardless of the chosen light's falloff.
In Fig. :ref:`fig-bi-light-attenuation-clip` you can see a side view example of the setup
with *Sphere* enabled and a distance of 10.

Any objects beyond the sphere receive no light from the lamp.

The *Distance* field is now specifying both where the light's rays become null,
and the intensity's ratio falloff setting.
Note that there is no abrupt transition at the sphere:
the light attenuation is progressive
(for more details, see the descriptions of the `Sphere`_ and `Falloff types`_ above).

.. list-table::
Sphere enabled with the specified distances, Inverse Linear light falloff.

* - .. _fig-bi-light-attenuation-sphere10:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_sphere10.jpg

Sphere with 10.

- .. _fig-bi-light-attenuation-sphere20:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_sphere20.jpg

Sphere with 20.

- .. _fig-bi-light-attenuation-sphere40:

.. figure:: /images/render_blender-render_lighting_lights_attenuation_sphere40.jpg

Sphere with 40.

In Fig. :ref:`fig-bi-light-attenuation-sphere10`, the clipping sphere's radius is 10 units,
which means the light's intensity is also being controlled by 10 units of distance.
With a linear attenuation,
the light's intensity has fallen very low even before it gets to the first object.

In Fig. :ref:`fig-bi-light-attenuation-sphere20`,
the clipping sphere's radius is now 20 BU and some light is reaching the middle objects.

In Fig. :ref:`fig-bi-light-attenuation-sphere40`, the clipping sphere's radius is now 40 units,
which is beyond the last object. However, the light does not make it to the last few objects
because the intensity has fallen to nearly 0.

.. hint::

If a *Lamp* light is set to not cast shadows,
it illuminates through walls and the like.
If you want to achieve some nice effects like a fire,
or a candle-lit room interior seen from outside a window,
the *Sphere* option is a must. By carefully working on the *Distance*
value you can make your warm firelight shed only within the room,
while illuminating outside with a cool moonlight,
the latter achieved with a *Sun* or *Hemi* light or both.

**************
Lamps Textures
**************

.. figure:: /images/render_blender-render_lighting_lights_textures.png

Lamp Texture panels.

When a new lamp is added, it produces light in a uniform, flat color.
While this might be sufficient in simple renderings,
more sophisticated effects can be accomplished through the use of
:doc:`textures &lt;/render/blender_render/textures/index&gt;`.
Subtle textures can add visual nuance to a lamp, while hard textures can be used to simulate more pronounced effects,
such as a disco ball, dappled sunlight breaking through treetops, or even a projector.
These textures are assigned to one of ten channels, and behave exactly like material textures,
except that they affect a lamp's color and intensity, rather than a material's surface characteristics.

Options
=======

The lamp textures settings are grouped into two panels.
Here we will only talk about the few things that differ from object material textures;
see the :doc:`Materials &lt;/render/blender_render/materials/index&gt;` and
:doc:`Textures &lt;/render/blender_render/textures/index&gt;` chapters for details about the standard options.

The texture-specific and the *Mapping* panels remain the same. However, you will note
there are much fewer *Mapping* options. You can only choose between
*Global*, *View* or another *Object* 's texture *coordinates*
(since a lamp has no texture coordinates by itself), and you can scale or offset the texture.

The *Mapping* panel is also a subset of its regular material's counterpart.
You can only map a lamp texture to its regular,
basic *Color* and/or to its *Shadow* color. As you can only affect colors,
and a lamp has no texture coordinates on its own, the *Diffuse*,
*Specular*, *Shading*, and *Geometry* options have disappeared.

##########
Shadows
##########

.. toctree::
:maxdepth: 2

introduction.rst
shadow_panel.rst
raytraced_properties.rst

************
Introduction
************

Light would not even exist without its counterpart: shadows. Shadows are a darkening of a
portion of an object because light is being partially or totally blocked from illuminating the
object. They add contrast and volume to a scene;
there is nearly no place in the real world without shadows, so to get realistic renders,
you will need them. Blender supports the following kinds of shadows:

- `Lamps: Ray-traced Shadows`_
- `Lamps: Buffered Shadows`_
- :doc:`Ambient occlusion &lt;/render/blender_render/world/ambient_occlusion&gt;`
- :doc:`Indirect lighting &lt;/render/blender_render/world/indirect_lighting&gt;`

Ambient occlusion really is not a shadow based on light *per se*, but based on geometry.
However, it does mimic an effect where light is prevented from fully and uniformly
illuminating an object, so it is mentioned here. Also,
it is important to mention ambient lighting,
since increasing *Ambient* decreases the effect of a shadow.

You can use a combination of ray-traced and buffer shadows to achieve different results.
Even within ray-traced shadows,
different lamps cast different patterns and intensities of shadow.
Depending on how you arrange your lamps,
one lamp may wipe out or override the shadow cast by another lamp.

Shadows is one of those trifectas in Blender,
where multiple things have to be set up in different areas to get results:

- The lamp has to cast shadows (ability and direction).
- An opaque object has to block light on its way (position and layer).
- Another object's material has to receive shadows (*Shadow* and *Receive Transparent* enabled).
- The render engine has to calculate shadows (*Shadow* for buffered shadows,
*Shadow* and *Ray* for ray-traced shadows).

For example, the simple *Lamp*, *Area*,
and *Sun* light has the ability to cast ray shadows, but not buffer shadows.
The *Spot* light can cast both, whereas the *Hemi* light does not cast any.
If a *Sun* lamp is pointing sideways, it will not cast a shadow from a sphere above a plane onto the plane,
since the light is not traveling that way. All lamps able to cast shadows share some common options,
described in the :doc:`/render/blender_render/lighting/shadows/shadow_panel`.

Just to give you more shadow options (and further confuse the issue),
lamps and materials can be set to respectively **only** cast and receive shadows,
and not light the diffuse/specular aspects of the object. Also,
render layers can turn on/off the shadow pass,
and their output may or may not contain shadow information...

Lamps: Ray-traced Shadows
=========================

.. figure:: /images/lighting-shadow-ray.png
:width: 310px

Ray Shadow enabled for a lamp.

Ray-traced shadows produce very precise shadows with very low memory use,
but at the cost of processing time.
This type of shadowing is available to all lamp types except *Hemi*.

As opposed to buffered shadows (`Lamps: Buffered Shadows`_),
ray-traced shadows are obtained by casting rays from a regular light source, uniformly and in all directions.
The ray-tracer then records which pixel of the final image is hit by a ray light, and which is not.
Those that are not are obviously obscured by a shadow.

Each light casts rays in a different way. For example,
a *Spot* light casts rays uniformly in all directions within a cone.
The *Sun* light casts rays from an infinitely distant point,
with all rays parallel to the direction of the *Sun* light.

For each additional light added to the scene, with ray-tracing enabled,
the rendering time increases. Ray-traced shadows require more computation than buffered
shadows but produce sharp shadow borders with very little memory resource usage.

To enable ray-traced shadows, three actions are required:

- Enable *Shadows* globally in the *Render* menu's *Shading* panel.
- Enable *Ray tracing* globally from the same panel.
- Enable ray-traced shadows for the light using the *Ray Shadow* button in the *Light* menu's *Shadow* panel.
This panel varies depending on the type of light.

All lamps able to cast ray-traced shadows share some common options,
described in :doc:`Ray-traced Properties &lt;/render/blender_render/lighting/shadows/raytraced_properties&gt;`.

Ray-traced shadows can be cast by the following types of lamp:

- :doc:`Point lamp &lt;/render/blender_render/lighting/lamps/point&gt;`
- :doc:`Spot lamp &lt;/render/blender_render/lighting/lamps/spot/introduction&gt;`
- :doc:`Area lamp &lt;/render/blender_render/lighting/lamps/area/introduction&gt;`
- :doc:`Sun lamp &lt;/render/blender_render/lighting/lamps/sun/introduction&gt;`

Lamps: Buffered Shadows
=======================

.. figure:: /images/lighting-shadow-spot_buf_shad.png
:width: 310px

Buffer Shadow enabled for a Spot lamp.

.. figure:: /images/lighting-shadow-mat_buf_shad.jpg
:width: 310px

Cast Buffer Shadows enabled for a material.

*Buffered* shadows provide fast-rendered shadows at the expense of precision and/or quality.
Buffered shadows also require more memory resources as compared to ray tracing.
Using buffered shadows depends on your requirements.
If you are rendering animations or cannot wait hours to render a complex scene with soft shadows,
buffer shadows are a good choice.

For a scanline renderer -- and Blender's built-in engine *is*, among other things,
a scanline renderer -- shadows can be computed using a *shadow buffer*.
This implies that an "image", as seen from the spot lamp's point of view, is "rendered" and
that the distance -- in the image -- for each point from the spot light is saved. Any point in
the "rendered" image that is farther away than any of those points in the spot light's image
is then considered to be in shadow. The shadow buffer stores this image data.

To enable buffered shadows these actions are required:

- Enable shadows globally from the *Scene* menu's *Gather* panel by selecting *Approximate*.
- Enable shadows for the light using the *Buffer Shadow* button in the *Lamp* menu's *Shadow* panel.
- Make sure the *Cast Buffer Shadows* options is enabled in each *Material* 's *Shadow* panel.

- The :doc:`Spot lamp &lt;/render/blender_render/lighting/lamps/spot/buffered_shadows&gt;`
is the only lamp able to cast buffered shadows.

*****************
Raytraced Shadows
*****************

.. figure:: /images/lighting-shadow-ray.png
:width: 310px

Ray shadowing options for lamps.

Most lamp types (:doc:`Lamp &lt;/render/blender_render/lighting/lamps/point&gt;`,
:doc:`Spot &lt;/render/blender_render/lighting/lamps/spot/introduction&gt;` and
:doc:`Sun &lt;/render/blender_render/lighting/lamps/sun/introduction&gt;`)
share the same options for the ray-traced shadows generation,
which are described below. Note that the :doc:`Area &lt;/render/blender_render/lighting/lamps/area/introduction&gt;` lamp,
even though using most of these options, have some specifics described in its
:doc:`own ray-traced shadows page &lt;/render/blender_render/lighting/lamps/area/raytraced_shadows&gt;`.

Ray Shadow
The *Ray Shadow* button enables the light source to generate ray-traced shadows.
When the *Ray Shadow* button is selected, another set of options is made available, those options being:
Shadow sample generator type
Method for generating shadow samples: Adaptive QMC is fastest, Constant QMC is less noisy but slower.
This allows you to choose which algorithm is to be used to generate the samples that will
serve to compute the ray-traced shadows (for now, mainly two variants of Quasi-Monte Carlo, see
`Quasi-Monte Carlo method`_):

Constant QMC
The *Constant QMC* method is used to calculate shadow values in a very uniform, evenly distributed way.
This method results in very good calculation of shadow value but it is not as fast as
using the *Adaptive QMC* method; however, *Constant QMC* is more accurate.
Adaptive QMC
The *Adaptive QMC* method is used to calculate shadow values in a slightly less uniform and distributed way.
This method results in good calculation of shadow value but not as good as *Constant QMC*.
The advantage of using *Adaptive QMC* is that it is in general much quicker while being
not much worse than *Constant QMC* in terms of overall results.

Samples
Number of extra samples taken (samples x samples).
This slider sets the maximum number of samples that both *Constant QMC* and *Adaptive QMC*
will use to do their shadow calculations.
The maximum value is 16: the real number of samples is actually the square of it,
so setting a sample value of 3 really means 3\ :sup:`2` = 9 samples will be taken.
Soft Size
Light size for ray shadow sampling.
This slider determines the size of the fuzzy/diffuse/penumbra area around the edge of a shadow.
*Soft Size* only determines the width of the soft shadow size, not how graded and smooth the shadow is.
If you want a wide shadow which is also soft and finely graded,
you must also set the number of samples in the *Samples* field higher than 1;
otherwise this field has no visible effect and the shadows generated will not have a soft edge.
The maximum value for *Soft Size* is 100.0.

Below is a table of renders with different *Soft Size* and *Samples* settings showing the
effect of various values on the softness of shadow edges:

.. list-table::

* - .. figure:: /images/light-ray_shadow-soft_size_1-samples_2-cube.jpg
:width: 190px

Soft Size: 1.0, Samples: 2.

- .. figure:: /images/light-ray_shadow-soft_size_1-samples_4-cube.jpg
:width: 190px

Soft Size: 1.0, Samples: 4.

- .. figure:: /images/light-ray_shadow-soft_size_1-samples_6-cube.jpg
:width: 190px

Soft Size: 1.0, Samples: 6.

* - .. figure:: /images/light-ray_shadow-soft_size_2-samples_2-cube.jpg
:width: 190px

Soft Size: 2.0, Samples: 2.

- .. figure:: /images/light-ray_shadow-soft_size_2-samples_4-cube.jpg
:width: 190px

Soft Size: 2.0, Samples: 4.

- .. figure:: /images/light-ray_shadow-soft_size_2-samples_6-cube.jpg
:width: 190px

Soft Size: 2.0, Samples: 6.

* - .. figure:: /images/light-ray_shadow-soft_size_3-samples_2-cube.jpg
:width: 190px

Soft Size: 3.0, Samples: 2.

- .. figure:: /images/light-ray_shadow-soft_size_3-samples_4-cube.jpg
:width: 190px

Soft Size: 3.0, Samples: 4.

- .. figure:: /images/light-ray_shadow-soft_size_3-samples_6-cube.jpg
:width: 190px

Soft Size: 3.0, Samples: 6.

Threshold
Threshold for Adaptive Sampling.
This field is used with the *Adaptive QMC* shadow calculation method.
The value is used to determine if the *Adaptive QMC* shadow sample
calculation can be skipped based on a threshold of how shadowed an area is already.
The maximum *Threshold* value is 1.0.

.. _render-blender-internal-quasi-monte-carlo:

Quasi-Monte Carlo method
========================

The Monte Carlo method is a method of taking a series of samples/readings of values
(any kind of values, such as light values, color values, reflective states)
in or around an area at random, so as to determine the correct actions to take in certain
calculations which usually require multiple sample values to determine overall accuracy of
those calculations. The Monte Carlo method tries to be as random as possible;
this can often cause areas that are being sampled to have large irregular gaps in them
(places that are not sampled/read). This in turn can cause problems for certain calculations
(such as shadow calculation).

The solution to this was the Quasi-Monte Carlo method.

The Quasi-Monte Carlo method is also random,
but tries to make sure that the samples/readings it takes are also better distributed
(leaving less irregular gaps in its sample areas) and more evenly spread across an area. This
has the advantage of sometimes leading to more accurate calculations based on samples/reading.

.. seealso::

- :doc:`Lamp Light Raytraced Shadows &lt;/render/blender_render/lighting/lamps/point&gt;`
- :doc:`Spot Light Raytraced Shadows &lt;/render/blender_render/lighting/lamps/spot/introduction&gt;`
- :doc:`Area Light Raytraced Shadows &lt;/render/blender_render/lighting/lamps/area/introduction&gt;`
- :doc:`Sun Light Raytraced Shadows &lt;/render/blender_render/lighting/lamps/sun/introduction&gt;`

************
Shadow Panel
************

.. figure:: /images/lighting-shadow-common-properties.png
:width: 310px

Common shadowing options for lamps.

All lamps able to cast shadows. Share some options, described below:

Shadow Method
No Shadow
The lamp casts no shadow.
Buffered Shadow
The :doc:`Spot lamp &lt;/render/blender_render/lighting/lamps/spot/buffered_shadows&gt;`
is the only lamp able to cast buffered shadows.
Raytraced Shadows
:doc:`Ray-traced Properties &lt;/render/blender_render/lighting/shadows/raytraced_properties&gt;`.
This Layer Only
When this option is enabled, only the objects on the same layer as the light source will cast shadows.
Only Shadow
The light source will not illuminate an object but will generate the shadows that would normally appear.
This feature is often used to control how and where shadows fall by having a light which
illuminates but has no shadow,
combined with a second light which does not illuminate but has *Only Shadow* enabled,
allowing the user to control shadow placement by moving the "Shadow Only" light around.

Shadow color
This color picker control allows you to choose the color of your cast shadows (black by default).
The images below were all rendered with a white light and the shadow color was selected independently.

.. list-table::

* - .. figure:: /images/render_blender-render_lighting_shadow_spot-red_buffer_shadow.jpg
:width: 190px

Red colored shadow example.

- .. figure:: /images/render_blender-render_lighting_shadow_spot-green_buffer_shadow.jpg
:width: 190px

Green colored shadow example.

- .. figure:: /images/render_blender-render_lighting_shadow_spot-blue_buffer_shadow.jpg
:width: 190px

Blue colored shadow example.

Although you can select a pure white color for a shadow color, it appears to make a shadow disappear.
..    TODO/Review: {{review|partial=X}}.

*******************
Volumetric Lighting
*******************

"Volumetric lighting is a technique used in 3D computer graphics to add lighting effects to a rendered scene.
It allows the viewer to see beams of light shining through the environment;
seeing sunbeams streaming through an open window is an example of volumetric lighting, also known as God rays.
The term seems to have been introduced from cinematography and is now widely applied to 3D
modeling and rendering especially in the field of 3D gaming. In volumetric lighting,
the light cone emitted by a light source is modeled as a transparent object and considered
as a container of a "volume": as a result,
light has the capability to give the effect of passing through an actual three dimensional medium
(such as fog, dust, smoke, or steam) that is inside its volume, just like in the real world."

-- According to Wikipedia, `volumetric lighting &lt;https://en.wikipedia.org/wiki/Volumetric_lighting&gt;`__.

A classic example is the search light with a visible halo/shaft of light being emitted from it
as the search light sweeps around.

By default Blender does not model this aspect of light.
For example when Blender lights something with a *Spot* light, you see the objects
and area on the floor lit but not the shaft/halo of light coming from the spotlight as it
progresses to its target and would get scattered on the way.

The halo/shaft of light is caused in the real world by light being scattered by particles in
the air,
some of which get diverted into your eye and that you perceive as a halo/shaft of light.
The scattering of light from a source can be simulated in Blender using various options,
but by default is not activated.

The only lamp able to create volumetric effects is the
:doc:`Spot lamp &lt;/render/blender_render/lighting/lamps/spot/halos&gt;`
(even thought you might consider some of the :doc:`"Sky &amp; Atmosphere" effects
&lt;/render/blender_render/lighting/lamps/sun/sky_and_atmosphere&gt;`
of the *Sun* lamp as volumetric as well).

.. seealso::

- :doc:`Mist &lt;/render/blender_render/world/mist&gt;`
- :doc:`Smoke &lt;/physics/smoke/index&gt;`
- :doc:`Volumetric Materials &lt;/render/blender_render/materials/special_effects/volume&gt;`
.. |material-icon| image:: /images/icons_material.png
:width: 1.1em

********************
Assigning a Material
********************

Materials available in the currently-open blend-file can be investigated by clicking
on the Materials icon |material-icon| in the Properties editor Header.
In this section we look at how to assign or remove a material to/from the Active Object in Blender, either by:

- Creating a new material,
- re-using an existing material, or
- deleting a material.

We also give hints about practical material usage.

Creating a new Material
=======================

Every time a new Object is created it has no material linked to it.
You can create a new material for the object by:

- Selecting the object.
- In the Properties editor, click on the object button.
- Click on the Materials button in the Properties editor header (1).

The Shading panel then appears. This contains the following elements:

.. figure:: /images/materials_creating.jpg

Add new material.

- Context: The currently-selected scene and object
- Object Material Slots (3): this panel shows the "slots"
for the material (or materials) that this object data contains.
- Active Material (2): Initially empty, asking for "New".

To add a new material, click "+" in the Active Material box.
This action has a series of effects:

.. figure:: /images/render_blender-render_materials_assigning_material-panel-object-mode.png

Materials Panel with New Entry.

#. Opens the new material in the Active Material box.
#. Brings up additional buttons in the immediate panel.
#. Adds the new material to the Available Materials list.
#. Adds the new material to the Object Material Slots list for the active object (or its object data -- see below).
#. Brings up a :doc:`preview &lt;/render/blender_render/materials/properties/preview&gt;` of the new material.
#. Provides you with a range of panels allowing you to select the
:doc:`properties &lt;/render/blender_render/materials/properties/introduction&gt;` of the new material.

New Material Panel Buttons
--------------------------

Details of the additional buttons which appear in the Material panel for a new Active
Material are as follows:

Active Material
List View.
Material
The Material :ref:`Data-Block Menu &lt;ui-data-block&gt;` for the selected Material slot.

.. tip:: Naming materials

It is a very good idea to give your materials clear names so you can keep track of them,
especially when they are linked to multiple objects.
Try to make your names descriptive of the material,
not its function (e.g. "Yellow Painted" rather than "Kitchen Table Color").

Node
Use Nodes.
Data
Specifies whether the material is to be linked to the Object or to the Object Data.
Material type
This menu has four options which define how the object is to be rendered.

Reusing Existing Materials
==========================

Blender is built to allow you to reuse *anything*, including material settings,
between many objects. Instead of creating duplicate materials,
you can simply re-use an existing material.
There are several ways to do this using the Materials data-block menu:

*Single Object* -- With the object selected, click the sphere located to the left of the Material name.
A pop-up appears showing all the materials available in the current blend-file.
To use one, just click on it.

.. figure:: /images/material-matmenu-addfirst-select_exist_button.png

Select an existing material.

.. figure:: /images/material-matmenu-searchlist.png

List of available materials.

.. tip:: Searching for Materials

The search field at the bottom of the material list allows you to search the names in the list.
For example, by entering "wood" all existent materials are filtered so that
only materials containing "wood" are displayed in the list.

*Multiple Objects* -- In the 3D View, with :kbd:`Ctrl-L`
you can quickly link all selected objects to the material (and other aspects)
of the :ref:`active object &lt;object-active&gt;`.
Very useful if you need to set a large number of objects to the same material;
just select all of them,
then the object that has the desired material, and :kbd:`Ctrl-L` link them to that "parent".
(See Tip on Linking Data in Creating about data linking.)

Deleting a Material
===================

To delete a material, select the material and click X in the Available Materials List entry.

Although the material will seem to disappear immediately,
the Delete action can depend on how the material is used elsewhere.

If the material is linked to the Object and there are other objects which use this material,
then the material will be removed from that object (but remain on all its other objects).

If the "Fake User" button (F) has been lit in the Available Materials list,
then the material will be retained when the file is saved, even if it has no users.

Only if it has 0 "real" users, and no "Fake" user, will the material be permanently deleted.
Note that it will still remain in the Materials list until the blend-file is saved,
but will have disappeared when the file is reloaded.

.. _bi-multiple-materials:

Multiple Materials
==================

Normally,
different colors or patterns on an object are achieved by adding textures to your materials.
However, in some applications you can obtain multiple colors on an object by assigning
different materials to the individual faces of the object.

.. figure:: /images/materials_creating.jpg

Add new material.

To apply several materials to different faces of the same object,
you use the Material Slots options (3) in the Materials header panel.

.. figure:: /images/render_blender-render_materials_assigning_material-panel-edit-mode.png

Material menu in edit mode.

The workflow for applying a second material to some faces of an object covered by a base
material is as follows:

#. In Object Mode, apply the base material to the whole object
(as shown in :doc:`Assigning a material &lt;/render/blender_render/materials/assigning_a_material&gt;`)
#. Create/select the second material (the whole object will change to this new material).
#. In the Active Material box (2), re-select the base material.
#. Go to Edit Mode and Face Select (a new box appears above the Active Material box with Assign/Select/Deselect).
#. Select the face/faces to be colored with the second material.
#. In the Object Material Slots box (3), click the :kbd:`Plus` to create a new slot, and while this is still active,
click on the second material in the Available Materials list.
#. Click the Assign button, and the second material will appear on the selected object faces.

You can also make this new material a copy of an existing material by adding the data-block:

Select the object, get the material, (R Click) and Copy data to clipboard.
When you have renamed the material, click "Link: Data" to link to the existing material.
Proceed to assign faces as required.
NB: If you change the material on the original object, the new object color changes too.

############
Materials
############

.. toctree::
:maxdepth: 2

introduction.rst
material_panel.rst
assigning_a_material.rst
properties/index.rst
nodes/index.rst
special_effects/index.rst

************
Introduction
************

A material defines the artistic qualities of the substance that an object is made of.
In its simplest form, you can use materials to show the substance an object is made of,
or to "paint" the object with different colors. Usually,
the substance is represented by its surface qualities (color, shininess, reflectance, etc.)
but it can also exhibit more complicated effects such as transparency,
diffraction and sub-surface scattering. Typical materials might be brass, skin, glass, or linen.

.. figure:: /images/materials_demo.jpg
:width: 320px

Various basic materials (single, multiple material, transparency, vertex paint).

The basic (un-textured) Blender material is uniform across each face of an object
(although the various pixels of each face of the object may appear differently because of lighting effects).
However, different faces of the object may use different materials (see :ref:`bi-multiple-materials`).

In Blender, materials can (optionally) have associated textures.
Textures *describe* the substance: e.g. *polished* brass,
*dirty* glass or *embroidered* linen. The :doc:`Textures &lt;/render/blender_render/textures/index&gt;`
chapter describes how to add textures to materials.

How Materials Work
==================

Before you can understand how to design effectively with materials, you must understand how
simulated light and surfaces interact in Blender's rendering engine and how material settings
control those interactions.
A deep understanding of the engine will help you to get the most from it.

The rendered image you create with Blender is a projection of the scene onto an imaginary
surface called the *viewing plane*.
The viewing plane is analogous to the film in a traditional camera,
or the rods and cones in the human eye, except that it receives simulated light,
not real light.

To render an image of a scene we must first determine what light from the scene is arriving at
each point on the viewing plane.
The best way to answer this question is to follow a straight line (the simulated light ray)
backwards through that point on the viewing plane and the focal point
(the location of the camera) until it hits a renderable surface in the scene,
at which point we can determine what light would strike that point.

The surface properties and incident light angle tells how much of that light would be
reflected back along the incident viewing angle *(Rendering engine basic principle)*.

.. figure:: /images/matgen01.jpg

Rendering engine basic principle.

Two basic types of phenomena take place at any point on a surface when a light ray strikes it:
diffusion and specular reflection. Diffusion and specular reflection are distinguished from
each other mainly by the relationship between the incident light angle and the reflected light
angle.

The shading (or coloring) of the object during render will then take into account the base color
(as modified by the diffusion and specular reflection phenomenon) and the light intensity.

Using the internal ray tracer, other (more advanced) phenomena could occur.
In ray-traced reflections, the point of a surface struck by a light ray will return the color
of its surrounding environment, according to the rate of reflection of the material
(mixing the base color and the surrounding environment's) and the viewing angle.

On the other hand, in ray-traced refractions, the point of a surface struck by a light ray
will return the color of its background environment, according to the rate of transparency
(mixing the base color and the background environment's along with its optional filtering
value) of the material and the optional index of refraction of the material,
which will distort the viewing angle.

Of course, shading of the object hit by a light ray will be about mixing all these phenomena
at the same time during the rendering. The appearance of the object, when rendered,
depends on many inter-related settings:

- World (Ambient color, Radiosity, Ambient Occlusion)
- Lights
- Material settings (including ambient, emission, and every other setting on every panel in that tab)
- Texture(s) and how they are mixed
- Material Nodes
- Camera
- Viewing angle
- Obstructions and transparent occlusions
- Shadows from other opaque/transparent objects
- Render settings
- Object dimensions (SS settings are relevant to dimensions)
- Object shape (refractions, Fresnel effects)

Using Materials
===============

.. tip:: Check your Render

When designing materials (and textures and lighting), frequently check the rendered appearance of your scene,
using your chosen render engine/shader settings.
The appearance might be quite different from that shown in the texture display in the 3D panel.

As stated above, the material settings usually determine the surface properties of the object.
There are several ways in which materials can be set up in Blender.
Generally speaking, these are not compatible.
You must choose which method you are going to use for each particular object in your scene:

#. First, you can set the :doc:`Properties &lt;/render/blender_render/materials/properties/introduction&gt;`
in the various Material panels.
#. Second, you can use :doc:`Nodes &lt;/render/blender_render/materials/nodes/index&gt;`;
a graphical nodes editor is available.
#. Last, you can directly set the color of object surfaces using various special effects. Strictly speaking,
these are not materials at all, but they are included here because they affect the appearance of your objects.
These include :ref:`Vertex Painting &lt;painting-vertex-index&gt;`,
:doc:`Wire Rendering &lt;/render/blender_render/materials/special_effects/wire&gt;`,
:doc:`Volume Rendering &lt;/render/blender_render/materials/special_effects/volume&gt;`,
and :doc:`Halo Rendering &lt;/render/blender_render/materials/special_effects/halo&gt;`.

The exact effect of Material settings can be affected by a number of system settings.
First and foremost is the Render Engine used:
Cycles and the Blender Render Engine (aka Blender Internal or BI)
require quite different illumination levels to achieve similar results,
and even then the appearance of objects can be quite different. Also,
the material properties settings can be affected by the texture method used (Single Texture,
Multitexture or GLSL). So it is recommended to always select the appropriate system settings
before starting the design of materials.
.. |node-icon| image:: /images/render_blender-render_materials_material-panel_node-icon.png

**************
Material Panel
**************

Materials can be linked to objects and Object's data in the :menuselection:`materials tab --&gt; materials panel`.
Here is where you can manage how materials are linked to objects, meshes, etc.
and activate a material for editing in the rest of the panels.

.. figure:: /images/render_blender-render_materials_assigning_material-panel-object-mode.png

Material panel.

Material slots
--------------

Active Material
The object's material slots displayed in a :ref:`List View &lt;ui-list-view&gt;`.

Specials
Copy and paste the selected material slot.

Multiple materials
------------------

Meshes can handle having more than one material.
Materials can be mapped on a per-face basis,
as detailed on the :ref:`bi-multiple-materials` page.
In edit mode, the following tools appear:

Assign
Assign the material in the selected material slot to selected vertices.
Select
Select vertices assigned to the selected material slot.
Deselect
Deselect vertices assigned to the selected material slot.

Material naming and linking
---------------------------

Material
The Material :ref:`Data-Block Menu &lt;ui-data-block&gt;` for the selected material slot.
Nodes
Toogle |node-icon| that designates this material to be a material node setup,
and not from the Material/Ramps/Shaders settings.
Data-block Links
Specifies whether the material is to be linked to the Object or to the Object Data.

The Link selector has two choices, Data and Object.
These two menu choices determine whether the material is linked to the object or to the data,
(e.g. a mesh or curve). The Data menu item determines that this material will be linked to the mesh's
data-block which is linked to the object's data-block.
The Object menu item determines that the material will be linked to the object's data-block directly.

This has consequences of course. For example, different objects may share the same mesh data-block.
Since this data-block defines the shape of the object any change in edit mode
will be reflected on all of those objects.
Moreover, anything linked to that mesh data-block will be shared by every object that shares that mesh.
So, if the material is linked to the mesh, every object will share it.

On the other hand, if the material is linked directly to the object data-block, the objects can have
different materials and still share the same mesh.

Short explanation: If connected to the object, you can have several instances of the same Object Data using
different materials. If linked to mesh data, you cannot.
See :doc:`Data System &lt;/data_system/introduction&gt;` for more information.

Material type
-------------

Material added in edit mode. These toggles tell Blender where this material fits into the Render Pipeline,
and what aspects of the material are to be rendered.

Surface
Render object as a surface.
Wire
Render the edges of faces as wires (not supported in ray tracing).
Volume
Render object as a volume.
See :doc:`Volume &lt;/render/blender_render/materials/special_effects/volume&gt;`.
Halo
Render object as halo particles.
See :doc:`Halo &lt;/render/blender_render/materials/special_effects/halo&gt;`.

.. list-table::

* - .. figure:: /images/materials_render_surface.jpg

Surface.

- .. figure:: /images/materials_render_wire.jpg

Wire.

* - .. figure:: /images/materials_render_volume.jpg

Volume.

- .. figure:: /images/materials_render_halo.jpg

Halo.

##################
Material Nodes
##################

.. toctree::
:maxdepth: 2

introduction.rst

Node Types
==========

.. toctree::
:maxdepth: 1

types/color/index.rst
types/converter/index.rst
types/input/index.rst
types/output/output.rst
types/vector/index.rst

*********************
Introduction to Nodes
*********************

In addition to creating materials as just described using all the settings on all the
materials panels,
Blender allows you to create a material by routing basic materials through a set of nodes.
Each node performs some operation on the material,
changing how it will appear when applied to the mesh, and passes it on to the next node.
In this way, very complex material appearances can be achieved.

You should already be familiar with general material concepts and how to create
materials/textures using the material menu. You should also have a general understanding of
the texture coordinate systems available in Blender (e.g. Generated, UV, etc.). Also, many
aspects of a node will be skipped here because in later sections you will see the function
expanded upon. Each section builds off the previous.

To start, the node system does not make the material menu obsolete.
Many features and material settings are still only accessible through the material panel (e.g.
Ray Mirror). However, with the advent of nodes,
more complex and fantastic materials can be created since we now have greater control.

Just in case you are not (yet) familiar with the concepts: when you create a system of nodes,
you are describing a data-processing pipeline of sorts,
where data "flows from" nodes which describe various *sources,*
"flows through" nodes which represent various processing and filtering stages,
and finally "flows into" nodes which represent outputs or destinations.
You can connect the nodes to one another in many different ways, and you can adjust "knobs,
" or parameters, that control the behavior of each node.
This gives you a tremendous amount of creative control. And,
it will very quickly become intuitive.

Having said all that, let us begin with a normal material.

Here we have the standard material we have added to a cube mesh. We could,
as we have in the past,
add color and other settings to this material and it would certainly look nice. But let us say
we are just not getting what we are looking for? What if we want to control the creation more
tightly or add more complexity? Here is where nodes come in.

Making this node map is accomplished by working in a
:doc:`Node Editor &lt;/editors/node_editor/index&gt;`.
This section covers:

- Enabling Material Nodes.
- The Node Editor, its basic controls, and working with nodes.
- The specific types of nodes available for materials.

Accessing The Node Editor
=========================

First lets enter the :doc:`Node editor &lt;/editors/node_editor/index&gt;`
and make sure that the Node editor has the material node button (the sphere icon) pressed,
not the composite or texture node buttons.

Enabling Node Materials in the Material Buttons
-----------------------------------------------

Let us take the base material and hit the Nodes button next to the material name in the
material panel or the Node editor. You will see a change in the material panel.

.. figure:: /images/render_blender-render_materials_nodes_introduction_use-nodes-button.png

Use material nodes button.

What you have just done is told Blender to make the material you were on to become the node
tree. Most of the panels we normally find in the material menu are now gone.

If you switch to the *Compositing* :doc:`screen &lt;/interface/window_system/screens&gt;`
with :kbd:`Ctrl-Left`, if you are on the default screen,
you will find a *Node Editor* on the top half of the screen.
When you enabled material nodes,
a material node and an output node were automatically added to the Node editor.

.. figure:: /images/render_blender-render_materials_nodes_introduction_nodes-default.png

Default nodes.

You can also split the 3D View in the default screen in two and change one into a
*Node Editor*.

It is important to note that you can add a new material
(which you can edit and change like any other material in the material panel),
add an already created material or append a material from another blend-file,
and also use the material that you used to create the node tree.

.. figure:: /images/render_blender-render_materials_nodes_introduction_nodes-material.png

A first material added to the node setup.

Here, we added a new material in the *Node editor* "Material.001",
and as we did, we can access the properties of this material in the material's menu.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/gamma.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/hue_saturation.rst

###############
Color Nodes
###############

.. toctree::
:maxdepth: 1

gamma.rst
hue_saturation.rst
invert.rst
mix_rgb.rst
rgb_curves.rst

.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/invert.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/mix.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/rgb_curves.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/converter/color_ramp.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/converter/combine_separate.rst

###################
Converter Nodes
###################

As the name implies, these nodes convert the colors in the material in some way.

.. toctree::
:maxdepth: 1

color_ramp.rst
combine_separate.rst
math.rst
rgb_to_bw.rst
sqeeze_value.rst
vector_math.rst

.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/converter/math.rst
:end-before: Examples
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/converter/rgb_to_bw.rst

******************
Squeeze Value Node
******************

.. figure:: /images/render_blender-render_materials_nodes_converter_sqeeze-value.png
:align: right

Squeeze Value node.

This node is used primarily in conjunction with the Camera Data node used.
The camera data generate large output values,
both in terms of the depth information as well as the extent in the width.
With the squeeze Node high output values to an acceptable material for the node degree,
i.e. to values between 0.0 - 1.0 scaled down.

Inputs
======

Value
Any numeric value. The value can be provided by another node or set manually.
Width
Determines the curve between sharp S-shaped at a width of 1 and stretched at a width of 0.1.
Negative values reverse the course. The value can be provided by another node or set manually.
Center
The center of the output value range.
This input value is replaced by the output value of 0.5.
The value can be provided by another node or set manually.

Properties
==========

This node has no properties.

Outputs
=======

Value
A value in the range between 0 and 1.

****************
Vector Math Node
****************

.. figure:: /images/render_blender-render_materials_nodes_converter_vector-math.png
:align: right

Vector Math node.

This node performs vector math operation.

Inputs
======

Vector
First vector input.
Vector
Second vector input.

Properties
==========

Operation
Selector of the math function.

Add
Adding input 1 and 2.
Subtract
Subtracting input 1 and 2.
Average
Averaging input 1 and 2.
Dot Product
Algebraic operation that takes two equal-length sequences of input vectors.
The result is a scalar value.
Cross Product
Geometric binary operation on the two vectors inputs in three-dimensional space.
It results in a vector which is perpendicular to both and therefore normal to the plane containing them.
Normalize
Normalizing input 1 and 2.

Outputs
=======

Vector
Standard vector output.
Value
Standard value output.

****************
Camera Data Node
****************

.. figure:: /images/render_blender-render_materials_nodes_input_camera-data.png
:align: right

Camera Data node.

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

View Vector
A Camera space vector from the camera to the shading point.
View Z Depth
How far away each pixel is from the camera
View Distance
Distance from the camera to the shading point.

**********************
Extended Material Node
**********************

.. figure:: /images/render_blender-render_materials_nodes_input_extendend-material.png
:align: right

Extended Material node.

Adds additional input and output sockets
to the :doc:`/render/blender_render/materials/nodes/types/input/material`.
Only the additional sockets are listed.

Inputs
======

Mirror
Color of mirrored reflection.
Ambient
Amount of global ambient color the material receives.
Emit
The emissivity, which is the amount of light to emit.
Specular Transparency
Is the alpha for the specular color.
Reflectivity
The degree to which the material reflects light.
Alpha
Transparency of the material by setting all pixels in the alpha channel to the given value.
Translucency
Amount of diffuse shading on the back side.

Properties
==========

This node has no additional properties.

Outputs
=======

Diffuse
Value of the diffuse color.
Specular
Value of the specular color.
AO
Value of the Ambient Occlusion.

*************
Geometry Node
*************

.. figure:: /images/render_blender-render_materials_nodes_input_geometry.png
:align: right

Geometry node.

The geometry node is used to specify how light reflects off the surface.
This node is used to change a material's Normal response to lighting conditions.

Use this node to feed the Normal vector input on the Material node,
to see how the material will look (e.g. shine, or reflect light)
under different lighting conditions. Your choices are:

Inputs
======

This node has no inputs.

Properties
==========

UV Map
To select a listed UV map.
Color Layer
To select a listed vertex color data (Vertex Paint, Weight Paint).

Outputs
=======

Global
Global position of the surface.
Local
Local position of the surface.
View
Viewed position of the surface.
Orco
Using the Original Coordinates of the mesh.
UV
Using the UV coordinates of the mesh, selected in the field in bottom node.
Normal
Surface Normal; On a flat plane with one light above and to the right reflecting off the surface.
Vertex Color
Allows for output value of group vertex colors, selected in the field in bottom node.
Vertex Alpha
Allows for output alpha value of vertex.
Front/Back
Allows for output to take into account front or back of surface is light relative the camera.

.. note::

These are exactly the same settings as in the
:doc:`Mapping &lt;/render/blender_render/textures/properties/mapping&gt;` panel for
:doc:`Textures &lt;/render/blender_render/textures/index&gt;`,
though a few settings, like *Stress* or *Tangent*, are missing here.
Normally you would use this node as input for a
:doc:`Texture Node &lt;/render/blender_render/materials/nodes/types/input/texture&gt;`.

Geometry Node Example using a UV image
======================================

.. figure:: /images/render_blender-render_materials_nodes_input_geometry_example.png

Setup to render a UV-Mapped Image Texture.

E.g.: To render a UV-mapped image,
you would use the *UV* output and plug it into the *Vector* Input of a texture node.
Then you plug the color output of the texture node into the color input of the material node,
which corresponds to the setting on the *Map To* panel.

###############
Input Nodes
###############

.. toctree::
:maxdepth: 1

camera_data.rst
extendend_material.rst
geometry.rst
lamp_data.rst
material.rst
particle_info.rst
rgb.rst
texture.rst
value.rst

**************
Lamp Data Node
**************

.. figure:: /images/render_blender-render_materials_nodes_input_lamp-data.png
:align: right

Lamp Data node.

The Lamp Data node is used to obtain information related to a specified lamp object.

Inputs
======

This node has no inputs.

Properties
==========

Lamp field
To select a listed lamp object.

Outputs
=======

The light textures and the shadow textures affect the Color and Shadow outputs, respectively.

Color
Lamp color multiplied by the lamp energy.
Light Vector
A unit vector in the direction from the lamp to the shading point.
Distance
Distance from the shading point to the lamp.
Shadow
Shadow color that the other objects cast on the shading point.
Visibility Factor
Light falloff ratio at the shading point.

.. note:: Portability to Various Scenes

If multiple materials use a Lamp Data node linking to the same lamp object,
including the Lamp Data node into a node group is recommended.
Otherwise, when the mesh objects are imported to the other scene, all the materials may need to be modified.

*************
Material Node
*************

.. figure:: /images/render_blender-render_materials_nodes_input_material.png
:align: right

Material node.

The Material node is used for shading.

Inputs
======

Color
The diffuse color or texture.
Specular
The specular color or texture that is reflected as the point of view get perpendicular
to the light source reflecting off the surface.
Diffuse Intensity
Amount of diffuse scattering.
Can also be set by a texture.
Normal
Standard normal input. Used for normal mapping.

.. note:: Normal Override

The normal input socket does not blend the source normal
with the underlying geometry but completely overrides the normals.

Properties
==========

Material field
Can be used to browse and select materials.
Diffuse
De/activate diffuse shading.
Specular
De/activate specular shading.
Invert Normal
Inverts the material input normal when activated.
(which, is a combination of the 3D normal given to it by the 3D object plus the normal input point).

Outputs
=======

Color
Shaded color value.
Alpha
Alpha transparency value.
Normal
Direction of the normal.

Examples
========

Using the Material Node with Specularity
----------------------------------------

.. figure:: /images/render_blender-render_materials_nodes_input_material_example.png

Material Node using Specularity.

To make a material node actually generate a color, at least
a basic input color have to be specified, and optionally a specularity color.
The specularity color is the color that shines under intense light.

For example, consider the mini-map to the right. The base color, a dark blue,
is connected from an RGB color generator node to the *Color* input socket.
The specular color, yellow, is connected to the *Spec* input.
Under *Normal* lighting conditions on a flat surface,
this material will produce a deep blue color and,
as the point of view approaches a spot perpendicular to the light,
the yellow specular color mix in becomes visible.

.. note:: Enable Spec

To see specularity, the specular toggle has to be enabled,
which is located just below the material color button in the node.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../cycles/nodes/types/input/particle_info.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/input/rgb.rst

************
Texture Node
************

.. figure:: /images/render_blender-render_materials_nodes_input_texture.png
:align: right

Texture node.

Can be used to input image or procedural textures.

Inputs
======

Vector
Uses for map the texture to a specific geometric space.

Properties
==========

Texture
The texture could be selected from a list of textures available in the current blend-file or link in textures.
The textures themselves could not be edited in this note, but in the Texture panel.

Outputs
=======

Value
Straight black-and-white value of the texture.
Color
Texture color output.
Normal
The of normal map.

Example
=======

.. figure:: /images/render_blender-render_materials_nodes_input_texture_example.png

Example of the applying Texture node.

In the example to the right, a cloud texture, as it would appear to a viewer,
is added to a base purple material, giving a velvet effect.

.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/input/value.rst

***********
Output Node
***********

.. figure:: /images/render_blender-render_materials_nodes_output.png
:align: right

Output material node.

The preview could also be used for a non shader color input.

Inputs
======

Color
Color applied to the geometry.
Alpha
Alpha transparency.

Properties
==========

This node has no properties.

Outputs
=======

This node has no outputs.

.. note:: Effective Output Node

The only Output node that is used for the Material in the end
is the last selected, indicated by the darker background.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/vector/vector_curves.rst

################
Vector Nodes
################

Vector nodes manipulate information about how light interacts with the material,
multiplying vector sets, and other wonderful things which can become quite advanced.
Even if you do not have experience with vector maths, you will find these nodes to be very useful.

Vectors, in general, are two or three element values, for example,
surface normals are vectors. Vectors are also important for calculating shading.

.. toctree::
:maxdepth: 1

curves.rst
mapping.rst
normal.rst
transform.rst

************
Mapping Node
************

.. figure:: /images/render_blender-render_materials_nodes_vector_mapping.png

Mapping node.

Essentially mapping node allows the user to modify a mapping of system of 3D-coordinates.
Mapping can be rotated and clamped if desired.

Typically used for modifying texture coordinates.

Inputs
======

Vector
Standard vector input.

Properties
==========

The controls of the node have been ordered in X, Y, Z order.
Clamping can be enabled by Min and Max.

Vector type
Type of vector that the mapping transforms.

Texture
Transform a texture by inverse mapping the texture coordinates.
Point
Transform a point.
Vector
Transform a direction vector.
Normal
Transform a normal vector with unit length.

Location
Transform position vector.
Rotation
Transform rotation vector.
Scale
Transform scale vector.

Min
Minimum clipping value.
Max
Maximum clipping value.

Outputs
=======

Vector
Standard vector output.

.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/vector/normal.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../cycles/nodes/types/vector/transform.rst

***************
Diffuse Shaders
***************

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Shading/Material --&gt; Diffuse`

A diffuse shader determines, simply speaking,
the general color of a material when light shines on it.
Most shaders that are designed to mimic reality give a smooth falloff
from bright to dark from the point of the strongest illumination
to the shadowed areas, but Blender also has other shaders for various special effects.

Common Options
==============

All diffuse shaders have the following options:

Color
Select the base *diffuse color* of the material.
Intensity
The shader's brightness, or more accurately,
the amount of incident light energy that is actually diffusely reflected towards the camera.
Ramp
Allows you to set a range of colors for the *Material*, and define how the range will vary over a surface.
See :doc:`Color Ramps &lt;/render/blender_render/materials/properties/ramps&gt;` for details.

Technical Details
=================

Light striking a surface and then re-irradiated via a Diffusion phenomenon will be scattered,
i.e., re-irradiated in all directions isotropically.
This means that the camera will see the same amount of light from that
surface point no matter what the *incident viewing angle* is.
It is this quality that makes diffuse light *viewpoint independent*. Of course,
the amount of light that strikes the surface depends on the incident light angle.
If most of the light striking a surface is reflected diffusely, the surface will have a matte appearance
(Light re-irradiated in the diffusion phenomenon).

.. figure:: /images/matgen02.jpg

Light re-irradiated in the diffusion phenomenon.

.. tip:: Shader Names

Some shaders are -- traditionally -- named after the people,
who first introduced the models on which they are based.

Lambert
=======

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Shading/Material --&gt; Shaders`

.. figure:: /images/material-shader-lambert.jpg
:width: 320px

Lambert Shader.

This is Blender's default diffuse shader, and is a good general all-around workhorse for
materials showing low levels of specular reflection.

`Johann Heinrich Lambert &lt;https://en.wikipedia.org/wiki/Johann_Heinrich_Lambert&gt;`__ (1728-1777)
was a Swiss mathematician, physicist and astronomer who published works on the reflection of light,
most notably the `Beer-Lambert Law &lt;https://en.wikipedia.org/wiki/Beer%E2%80%93Lambert_law&gt;`__
which formulates the law of light absorption.

This shader has only the default option, determining how much of available light is reflected.
Default is 0.8, to allow other objects to be brighter.

.. figure:: /images/material-shader-lambert-settings.png
:width: 220px

The Lambert diffuse shader settings.

Oren-Nayar
==========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Shading/Material --&gt; Shaders`

.. figure:: /images/material-shader-oren-nayar.jpg
:width: 320px

Oren-Nayar Shader.

Oren-Nayar takes a somewhat more 'physical' approach to the diffusion phenomena as it takes
into account the amount of microscopic roughness of the surface.
`Michael Oren &lt;http://dblp.uni-trier.de/pers/hd/o/Oren:Michael.html&gt;`__
and `Shree K. Nayar &lt;https://en.wikipedia.org/wiki/Shree_K._Nayar&gt;`__
Their `reflectance model &lt;https://en.wikipedia.org/wiki/Oren%E2%80%93Nayar_reflectance_model&gt;`__,
developed in the early 1990s, is a generalization of Lambert's law now widely used in computer graphics.

Options
-------

Roughness
The roughness of the surface, and hence, the amount of diffuse scattering.

.. figure:: /images/material-shader-oren-nayar-settings.jpg
:width: 200px

The Oren-Nayar diffuse shader settings.

Toon
====

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Shading/Material --&gt; Shaders`

.. list-table::

* - .. figure:: /images/material-shader-toon.jpg

Toon Shader, Different Spec.

- .. figure:: /images/material-shader-toon-vary.jpg

Toon Shader Variations.

The Toon shader is a very 'un-physical' shader in that it is not meant to fake reality,
but to produce cartoon cel styled rendering,
with clear boundaries between light and shadow and uniformly lit/shadowed regions.

Options
-------

Size
The size of the lit area.
Smooth
The softness of the boundary between lit and shadowed areas.

.. figure:: /images/material-shader-toon-settings.jpg
:width: 200px

The Toon diffuse shader settings.

Minnaert
========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Shading/Material --&gt; Shaders`

.. figure:: /images/material-shader-lambert.jpg
:width: 320px

Minnaert Shader.

Minnaert works by darkening parts of the standard Lambertian shader,
so if *Dark* is 1 you get exactly the Lambertian result.
Higher darkness values will darken the center of an object (where it points towards the viewer).
Lower darkness values will lighten the edges of the object, making it look somewhat velvet.
`Marcel Minnaert &lt;https://en.wikipedia.org/wiki/Marcel_Minnaert&gt;`__ (1893-1970)
was a Belgian astronomer interested in the effects of the atmosphere on light and
images who in 1954 published a book entitled "The Nature of Light and Color in the Open Air".

Options
-------

Dark
The darkness of the 'lit' areas (higher) or the darkness of the edges pointing away from the light source (lower).

.. figure:: /images/material-shader-minnaert-settings.jpg
:width: 200px

The Minnaert diffuse shader settings.

Fresnel
=======

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Shading/Material --&gt; Shaders`

.. list-table::

* - .. figure:: /images/material-shader-fresnel-vary.jpg

Various settings for the Fresnel shader,
Cook-Torr Specular shader kept at Intensity 0.5, Hardness: 50.

- .. figure:: /images/material-shader-fresnel.jpg

Fresnel Shader, Different Spec.

With a Fresnel shader the amount of diffuse reflected light depends on the incidence angle,
i.e. from the direction of the light source.
Areas pointing directly towards the light source appear darker;
areas perpendicular to the incoming light become brighter.
`Augustin-Jean Fresnel &lt;https://en.wikipedia.org/wiki/Augustin-Jean_Fresnel&gt;`__ (1788-1827)
was a French physicist who contributed significantly to the establishment of the theory of wave optics.

Options
-------

Fresnel
Power of the Fresnel effect, 5.0 is max.
Factor
Blending factor of the Fresnel factor to blend in, 5.0 is max.

.. figure:: /images/material-shader-fresnel-settings.jpg
:width: 200px

The Fresnel diffuse shader settings.

Emit
Amount of light to emit
Ambient
Amount of global ambient color the material receives
Translucency
Amount of diffuse shading on the back side
Shadeless
Make this material insensitive to light or shadow
Tangent Shading
Use the material's tangent vector instead of the normal for shading --
for anisotropic shading effects (e.g. soft hair and brushed metal).

.. seealso::

Settings for strand rendering in the menu further down and in the Particle System menu.

Cubic Interpolation
Use cubic interpolation for diffuse values, for smoother transitions between light areas and dark areas.

######################
Material Properties
######################

.. toctree::
:maxdepth: 2

introduction.rst
preview.rst
diffuse_shaders.rst
specular_shaders.rst
ramps.rst
shading.rst
transparency.rst
mirror.rst
subsurface_scattering.rst
strands.rst
options.rst
shadows.rst

************
Introduction
************

Materials can have a wide array of properties.
It is the combination of all of these things that define the way a material looks,
and how objects using that material will appear when rendered.
These properties are set using the various panels in the material tab.

Remember that the appearance of your materials are affected by the way that they are rendered
(surface, wire, volume or halo), and by the rendering engine (Blender, Cycles, or Game) used.
Most properties for images rendered using Cycles can only be controlled using the Node system.

The list below sets out the various panels available in Blender Render and Game Engine,
and brief details of their scope. Details of their controls and settings are given on the relevant pages.

:doc:`Preview &lt;/render/blender_render/materials/properties/preview&gt;`
A preview of the current material mapped on to one of several basic objects.
:doc:`Diffuse Shaders &lt;/render/blender_render/materials/properties/diffuse_shaders&gt;`
The basic color of the material, together with different models for dispersion.
:doc:`Specular Shaders &lt;/render/blender_render/materials/properties/specular_shaders&gt;`
The reflected highlights: color, strength and different models for dispersion.
:doc:`Color Ramps &lt;/render/blender_render/materials/properties/ramps&gt;`
How to vary the base color over a surface in both Diffuse ans Specular shaders.
:doc:`Shading &lt;/render/blender_render/materials/properties/shading&gt;`
Properties of various characteristics of the shading model for the material.
:doc:`Transparency &lt;/render/blender_render/materials/properties/transparency&gt;`
Sets options for objects in which light can pass through.
:doc:`Mirror &lt;/render/blender_render/materials/properties/mirror&gt;`
(Only Blender Render): Reflective properties of the material.
:doc:`Subsurface Scattering &lt;/render/blender_render/materials/properties/subsurface_scattering&gt;`
(Only Blender Render): Simulates semi-translucent objects in which light enters,
bounces around, then exits in a different place.
:doc:`Strand &lt;/render/blender_render/materials/properties/strands&gt;`
(Only Blender Render): For use when surfaces are covered with hair, fur, etc.
:doc:`Options &lt;/render/blender_render/materials/properties/options&gt;`
Various options for shading and coloring the object.
:doc:`Shadow &lt;/render/blender_render/materials/properties/shadows&gt;`
Controls how objects using this material cast and receive shadows.
:doc:`Game Settings &lt;/game_engine/materials&gt;`
(Only Blender Render): Controls settings for real-time rendering of Game Engine objects.

******************
Mirror Reflections
******************

Mirror reflections are computed in the Blender Render and Cycles render engines using ray
tracing. (NB: Reflections are not available in the Game Engine.)
Ray tracing can be used to make a material reflect its surroundings, like a mirror.
The principle of ray-traced reflections is very simple:
a ray is fired from the camera and travels through the scene until it encounters an object.
If the first object hit by the ray is not reflective,
then the ray takes the color of the object. If the object is reflective,
then the ray bounces from its current location and travels up to another object, and so on,
until a non-reflective object is finally met and gives the whole chain of rays its color.

Eventually, the first reflective object inherits the colors of its environment,
proportional to its *Reflectivity* value.
Obviously, if there are only reflective objects in the scene, then the render could last forever.
This is why a mechanism for limiting the travel of a single ray is set through the *Depth* value:
this parameter sets the maximum number of bounces allowed for a single ray.

.. note::

You need to enable ray tracing in your scene settings if you want to use ray-traced
reflections. This is done in the :menuselection:`Render --&gt; Shading` panel.

The *Mirror Color* in the mirror panel is the color of the light reflected back. Usually,
for normal mirrors, use white. However, some mirrors color the reflection (e.g. metals),
so you can change the color by clicking on the color button.
The amount of mirrored reflection is determined by the *Reflectivity* value.
If set to something greater than 0, mirrored reflectivity will be activated and the reflection
will be tinted the color set in Mirror Color.

Options
-------

.. figure:: /images/material-mirrorpanel.jpg

The Mirror Panel.

Enable ray-traced reflections
Enable or disable ray-traced reflections
Reflectivity
Sets the amount of reflectiveness of the object.
Use a value of 1.0 if you need a perfect mirror, or set it to 0.0 if you do not want any reflection.

.. figure:: /images/material-mirrorcolor.jpg

Picking a mirror color.

Mirror Color
Color of mirrored reflection
By default, an almost perfectly reflective material like chrome, or a mirror object,
will reflect the exact colors of its surrounding.
But some other equally reflective materials tint the reflections with their own color.
This is the case for well-polished copper and gold, for example. In order to replicate this within Blender,
you have to set the Mirror Color accordingly. To set a mirror color,
simply click the color button in the mirror panel and select a color.
Fresnel
Sets the power of the Fresnel effect. The Fresnel effect controls how reflective the material is,
depending on the angle between the surface normal and the viewing direction. Typically, the larger the angle,
the more reflective a material becomes (this generally occurs on the outline of objects).
Blend
A controlling factor to adjust how the blending happens between the reflective and non-reflective areas.
Depth
Maximum allowed number of light inter-reflections.
If your scene contains many reflective objects and/or if the camera zooms in on such a reflective object,
you will need to increase this value if you want to see surrounding
reflections in the reflection of the reflected object (!).
In this case, a Depth of 4 or 5 is typically a good value.
Max Distance
Maximum distance of reflected rays away from camera (Z-Depth) in Blender units.
Reflections further than this range fade out to reduce compute time.

Fade to
The color that rays with no intersection within the *Max Distance* take.
*Material* color can be best for indoor scenes, *Sky* color (World settings)
for outdoor scenes.

.. figure:: /images/material-raymirror-example.jpg

Suzanne in the Fun House
(`blend-file &lt;https://wiki.blender.org/index.php/:File:Manual-2.5-Material-MonkeyMirror.blend&gt;`__)

Gloss
In paint, a high-gloss finish is very smooth and shiny. A flat, or low gloss,
finish disperses the light and gives a very blurry reflection. Also, uneven or waxed-but-grainy surfaces
(such as car paint) are not perfect and therefore slightly need a Gloss greater than 1.0.
In the example to the right,
the left mirror has a Gloss of 0.98, the middle is Gloss = 1.0, and the right one has Gloss of 0.90.
Use this setting to make a realistic reflection, all the way up to a completely foggy mirror.
You can also use this value to mimic depth of field in mirrors.

Amount
The shininess of the reflection.
Values &lt; 1.0 give diffuse, blurry reflections and activate the settings below.
Threshold
Threshold for adaptive sampling.
If a sampling contributes less than this amount (as percentage), sampling is stopped.
Raising the threshold will make the adaptive sampler skip more often,
however, the reflections could become noisier.
Samples
Number of cone samples averaged for blurry reflection.
More samples will give a smoother result, but will also increase render time.

.. figure:: /images/material-raymirror-anisotropicexample.jpg

Anisotropic tangent reflecting spheres with anisotropic set to 0.0, 0.75, 1.0.
(`.blend &lt;https://wiki.blender.org/index.php/:File:Manual-2.5-Material-Mirror-anisotropic-example.blend&gt;`__)

Anisotropic
The shape of the reflection, from 0.0 (circular) to 1.0 (fully stretched along the tangent).
If the *Tangent Shading* is on,
Blender automatically renders blurry reflections as anisotropic reflections.
When Tangent is switched on, the *Anisotropic* slider controls the strength of this anisotropic reflection,
with a range of 1.0 (default) being fully anisotropic and 0.0 being fully circular,
as is when tangent shading on the material is switched off.
Anisotropic ray-traced reflection uses the same tangent vectors as for tangent shading,
so you can modify the angle and layout the same way, with the auto-generated tangents,
or based on the mesh's UV co-ordinates.

Examples
--------

Fresnel
^^^^^^^

.. figure:: /images/material-mirrorfresnel-example.jpg

Demonstration of Fresnel effect with values equal to (from top to bottom) 0.0, 2.5 and 5.0.

Let us undertake a small experiment in order to understand what Fresnel is really about.
After a rainy day, go out and stand over a puddle of water.
You can see the ground through the puddle. If you kneel just in front of the puddle,
your face close to the ground, and look again at a distant point on the puddle of water,
the liquid surface part which is closer to you lets you see the ground,
but if you move your gaze towards the other end of the puddle,
then the ground is gradually masked until all you see is the reflection of the sky.
This is the Fresnel effect: having a surface sharing reflective and non-reflective properties
according to the viewing angle and the surface normal.

In *Demonstration of Fresnel effect with values equal to (from top to bottom) 0.0,
2.5 and 5.0*, this behavior is demonstrated for a perfectly reflective Material
(Mirror Reflectivity 1.0).

Fresnel 0.0 stands for a perfect mirror Material, while Fresnel 5.
0 could stand for a glossy Material. It is barely noticeable but in the lower picture,
the Material is perfectly reflective around the edges.

The smoothness of the Fresnel limit can be further controlled using the *Blend* slider.

*******
Options
*******

.. figure:: /images/render_blender-render_materials_properties_options.png

Material Options panel.

This panel provides a series of control options concerning how objects using this material
will appear in the rendered image. All controls are default "Off" unless otherwise stated.

Traceable
Include this material and the geometry that uses it in ray-tracing calculations.
See :doc:`Transparency &lt;/render/blender_render/materials/properties/transparency&gt;` for details of ray-tracing.
Full Oversampling
Force this material to render full shading and textures for all
:doc:`anti-aliasing &lt;/render/blender_render/settings/antialiasing&gt;` samples.
Sky
Render this material with zero alpha, but with
:doc:`sky background &lt;/render/blender_render/lighting/lamps/sun/sky_and_atmosphere&gt;` in place (scanline only)
Use Mist
Use :doc:`mist &lt;/render/blender_render/world/mist&gt;` on this material (see "World Settings" for more details)
Invert Z depth
Render material's faces with an inverted Z buffer (scanline only)
Z Offset
Give faces an artificial Z offset for Z transparency.
Light Group
Limit lighting to lamps in this
:doc:`light group &lt;/render/blender_render/lighting/lights/lights_in_other_contexts&gt;`.
Exclusive
Uses the :doc:`light group &lt;/render/blender_render/lighting/lights/lights_in_other_contexts&gt;` exclusively.
These lamps will be excluded from other scene lighting.
Local
When linked in, uses local
:doc:`light group &lt;/render/blender_render/lighting/lights/lights_in_other_contexts&gt;` with the same name.
Face Textures
Replace object's base color with color from
:ref:`UV map &lt;editors-uv-image-index&gt;` image textures.
Face Textures Alpha
Replace object's base alpha with alpha from
:ref:`UV map &lt;editors-uv-image-index&gt;` image textures.
Vertex Color Paint
Replace object's base color with
:ref:`vertex paint &lt;painting-vertex-index&gt;`
colors (multiply with 'texture face' face assigned textures)
Vertex Color Light
Add :ref:`vertex paint &lt;painting-vertex-index&gt;`
colors as additional lighting.
(This can be used to produce good incandescence effects).
Object Color
Modulate the result with a per object color.
See :doc:`Object Display panel &lt;/editors/3dview/object/properties/display&gt;`.
UV Project
Use to ensure UV interpolation is correct for camera projections (use with
:doc:`UV Project Modifier &lt;/modeling/modifiers/modify/uv_project&gt;`).
Pass Index
Index number for the Material Index render pass.

*******
Preview
*******

The Preview panel gives a quick visualization of the active material and its properties.
Including its *Shaders*, *Ramps*, *Mirror Transp* properties and *Textures*.
It provides several shapes that are very useful for designing new shaders:
For some shaders (like those based on *Ramp* colors, or a Diffuse shader like *Minnaert*),
one needs fairly complex or specific previewing shapes to decide if the shader being designed achieves its goal.

Options
-------

Flat XY plane
Useful for previewing textures and materials of flat objects, like walls, paper and such.
Sphere
Useful for previewing textures and materials of sphere-like objects,
but also to design metals and other reflective/transparent materials, thanks to the checkered background.
Cube
Useful for previewing textures and materials of cube-like objects, but also to design procedural textures.
Features a checkered background.
Monkey
Useful for previewing textures and materials of organic or complex non-primitive shapes.
Features a checkered background.
Hair strands
Useful for previewing textures and materials of strand-like objects, like grass, fur, feathers and hair.
Features a checkered background.
Large Sphere with Sky
Useful for previewing textures and materials of sphere-like objects,
but also to design metals and other reflective materials, thanks to the gradient Sky background.

Examples
--------

.. list-table::

* - .. figure:: /images/render_blender-render_materials_properties_preview_flat.png

Plane preview.

- .. figure:: /images/render_blender-render_materials_properties_preview_sphere.png

Sphere preview.

- .. figure:: /images/render_blender-render_materials_properties_preview_cube.png

Cube preview.

* - .. figure:: /images/render_blender-render_materials_properties_preview_monkey.png

Monkey preview.

- .. figure:: /images/render_blender-render_materials_properties_preview_hair.png

Hair Strands preview.

- .. figure:: /images/render_blender-render_materials_properties_preview_sky.png

Sky Sphere preview.

***********
Color Ramps
***********

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Material --&gt; Ramps`

In many real life situations, like skin or metals,
the color of diffuse and specular reflections can differ slightly,
based on the amount of energy a surface receives or on the light angle of incidence. The
*Ramp Shader* options in Blender allow you to set a range of colors for a
*Material*, and define how the range will vary over a surface,
and how it blends with the 'actual color'
(typically from a material or as output of a texture).

Ramps allow you to precisely control the color gradient across a material,
rather than just a simple blend from a brightened color to a darkened color,
from the most strongly lit area to the darkest lit area.
As well as several options for controlling the gradient from lit to shadowed,
ramps also provide 'normal' input,
to define a gradient from surfaces facing the camera to surfaces facing away from the camera.
This is often used for materials like some types of metallic car paint that change color based
on viewing angle.

Since texture calculations in Blender happen before shading,
the *Ramp Shader* can completely replace texture or material color. But by use of
the mixing options and Alpha values it is possible to create an additional layer of shading in
Blender materials.

Options
=======

.. figure:: /images/material-rampspanel.png

Ramps Panel.

For the first part of the color ramp option see :ref:`ui-color-ramp-widget`.

Input
The input menu contains the following options for defining the gradient:

Shader
The value as delivered by the material's shader (*Lambert*, *Cook Torrance*) defines the color.
Here the amount of light does not matter for color, only the direction of the light.
Energy
As *Shader*, now also lamp energy, color, and distance are taken into account.
This makes the material change color when more light shines on it.
Normal
The surface normal, relative to the camera, is used for the *Ramp Shader*.
This is possible with a texture as well, but added for convenience.
Result
While all three previous options work per lamp, this option only works after shading calculations.
This allows full control over the entire shading, including 'Toon' style results.
Using alpha values here is most useful for tweaking a finishing touch to a material.
Blend
A list of the various :term:`Color Blend Modes` are
available for blending the ramp shader with the color from *Input*.
Factor
This slider denotes the overall factor of the ramp shader with the color from *Input*.

*******
Shading
*******

In the separate *Shading* panel six more options are available:

.. figure:: /images/material-shadingmenu.png

Shading menu, default settings.

Emit
Amount of light to emit.
Ambient
Amount of global ambient color the material receives.
Each material has an *Ambient* slider that lets you choose how much ambient light that object receives.
Set to 1.0 by default.

You should set this slider depending on the amount of ambient light you think the object will receive.
Something deep in the cave will not get any ambient light, whereas something close to the entrance will get more.
Note that you can animate this effect, to change it as the object comes out of the shadows and into the light.

.. seealso::

Settings for Ambient Occlusion and Environment Lighting can be found
in the World tab, with parameters affecting both these lighting components found
in the :menuselection:`World --&gt; Gather` panel.

Translucency
Amount of light from the back side that shows through.
Shadeless
Disables the calculation of any shading. This makes material insensitive to light or shadow,
resulting in a solid, uniform color for the whole object.
Tangent Shading
Use the material's tangent vector instead of the normal for shading, i.e. for anisotropic shading effects
(like soft hair and brushed metal).
This shading was
`introduced in 2.42 &lt;https://www.blender.org/development/release-logs/blender-242/material-features/&gt;`__,
see also settings for strand rendering in the menu further down and in the Particle System menu.
Cubic Interpolation
Use cubic interpolation for diffuse values, for smoother transitions between light areas and shadowed areas.
Enhances the perceived contrast.

.. list-table::

* - .. figure:: /images/light-lamps-sphere_non-cubic_shadow.jpg
:width: 200px

Without Cubic enabled.

- .. figure:: /images/light-lamps-sphere_cubic_shadow.jpg
:width: 200px

With Cubic enabled.

*******
Shadows
*******

The shadows that appear in a scene are affected by a combination of the layout of objects,
the shape of the objects, the materials of the objects, and the lighting.
In Blender, the Display Mode (Single Texture, Multitexture, or GLSL) also affects the appearance of shadows.
See :doc:`Shadows &lt;/render/blender_render/lighting/shadows/index&gt;` for a more complete description of this subject.

.. tip:: Shadows in 3D mode

To see shadows in 3D (textured) mode, you must have switched to GLSL mode before making any materials.
In MultiTexture mode, shadows only appear in the rendered image: none of these can be seen in the preview image.

.. _fig-bi-material-shadow-panel:

.. figure:: /images/render_blender-render_materials_properties_shadows_panel.png

Shadow Panel.

The Shadow panel in the Materials Properties editor (see Fig. :ref:`fig-bi-material-shadow-panel`)
controls the effects that the material can have on the shadows that appear in the scene.
The various properties are described in the sections below.

.. _fig-bi-material-shadow-scene:

.. figure:: /images/materials_properties_shadow2.png

Scene with all shadow properties off.

Options
=======

The following properties can be set for each individual material with which objects in the
scene are shaded. The effects are illustrated with rendered images for a simple scene
(Fig. :ref:`fig-bi-material-shadow-scene`) consisting of two "posts", one with
a red (totally non-transparent) material; one green (partially transparent) material,
set up on a light blue plane to receive the shadows.
The illustrations were all taken in Blender Render engine, with Multitexture mode.

Shadow Receiving Object Material
--------------------------------

The following options affect the material that receives shadows:

Receive
Allows this material to receive full-intensity shadows (Fig. :ref:`fig-bi-material-shadow-receive`).
Receive Transparent
Allows this material to receive shadows whose intensity is modified by the transparency
and color of the shadow-casting object (Fig. :ref:`fig-bi-material-shadow-receive-trans`).

.. list-table::

* - .. _fig-bi-material-shadow-receive:

.. figure:: /images/materials_properties_shadow3.png

Plane with Receive.

- .. _fig-bi-material-shadow-receive-trans:

.. figure:: /images/materials_properties_shadow4.png

Plane with Receive and Receive Transparency.

Shadow Casting Object Material
------------------------------

The following options affect the material that casts shadows:

Cast Only
Causes objects with the material to only cast a shadow, and not appear in renders.
(Fig. :ref:`fig-bi-material-shadow-cast`).
Casting Alpha
Sets the Alpha of shadow casting. Used for irregular and deep shadow buffering.
Shadows Only
Renders shadows as materials alpha value, making materials transparent,
except for areas where it receives shadows from other objects,
and also it retains its own transparency (Fig. :ref:`fig-bi-material-shadow-only`).
Note the faint image of the partly-transparent post.

Shadow Only Type
Set the type of shadows used when Shadows Only is enabled.

- Shadow and Distance
- Shadow Only
- Shadows and Shading

.. list-table::

* - .. _fig-bi-material-shadow-cast:

.. figure:: /images/materials_properties_shadow5.png

Posts with Cast Only.

- .. _fig-bi-material-shadow-only:

.. figure:: /images/materials_properties_shadow6.png

Posts with Shadows Only.

Buffered Shadow Options
-----------------------

In addition to the shadow options described above,
there are further material properties which control buffered shadow features.
See section on :doc:`Spot Buffered Shadows &lt;/render/blender_render/lighting/lamps/spot/buffered_shadows&gt;`
for further discussion of these techniques.

Cast Buffer Shadow
Casts shadows from shadow buffer lamps.
Buffer Bias
Multiplication factor for Buffer shadows (0 = ignore).
Auto Ray Bias
Prevent raytraced shadow errors on surfaces with smooth shaded normals.
Ray Bias
Shadow raytracing bias value to prevent terminator artifacts on shadow boundary.
Cast Approximate
Allow this material to cast shadows when using approximate ambient occlusion.

****************
Specular Shaders
****************

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Material --&gt; Specular`

Specular shaders create the bright highlights that one would see on a glossy surface,
mimicking the reflection of light sources.
Unlike :doc:`diffuse shading &lt;/render/blender_render/materials/properties/diffuse_shaders&gt;`,
specular reflection is *viewpoint dependent*.
According to Snell's Law, light striking a specular surface will be reflected at an angle which mirrors the
incident light angle (with regard to the surface's normal), which makes the viewing angle very important.

.. tip:: Not a Mirror!

It is important to stress that the *specular reflection*
phenomenon discussed here is not the reflection we would see in a mirror,
but rather the light highlights we would see on a glossy surface.
To obtain true mirror-like reflections you would need to use the internal raytracer.
Please refer to section :doc:`rendering &lt;/render/index&gt;` of this manual.

Common Options
==============

Each specular shader share the following common options:

Specular Color
The color of the specular highlight
Intensity
The intensity, or brightness of the specular highlight. This has a range of [0-1].
Ramp
Allows you to set a range of specular colors for *Material*,
and define how the range will vary over a surface.
See :doc:`Ramps &lt;/render/blender_render/materials/properties/ramps&gt;` for details.

As a result, a material has at least two different colors, a diffuse, and a specular one.
The specular color is normally set to pure white
(the same "pure white" as the reflected light source),
but it can be set to different values for various effects (e.g.
metals tend to have colored highlights).

Technical Details
-----------------

.. figure:: /images/matgen03.jpg

Specular Reflection.

In reality, the quality of Diffuse and Specular reflection are generated during the same
process of light scattering, but are not the same.
Diffusion is actually subsurface scattering at a very small scale.

Imagine that a surface is made up of extremely microscopic semi-transparent,
reflective facets. The sharpness of Specular reflection is determined by the distribution of
the angle of these microfacets on the surface of an object.
The more deep and jagged these facets are,
the more the light spreads when it hits the surface.
When these facets are flatter against the "macrosurface",
the surface will have a tighter reflection, closer to a mirror.
This is a condensed explanation of the generally accepted microfacet theory of reflectance,
which is the basis of all modern BRDFs (Bi-directional Reflectance Distribution Functions),
or shading models.

Because these microfacets are transparent,
some light that hits them travels into the surface and diffuses.
The light that makes it back out is roughly Lambertian most of the time,
meaning that it spreads evenly in all directions.
It is also attenuated by the pigmentation in the surface,
hence creating what we perceive as diffuse, and the color of an object.

Note that at glancing angles, the reflectivity of a surface will always go to 1.

If it is difficult for you to understand this relationship, try to imagine a ball (say,
of centimeter scale): if you throw it against a wall of raw stones
(with a scale of roughness of a decimeter), it will bounce in a different direction each time,
and you will likely quickly lose it! On the other hand,
if you throw it against a smooth concrete wall (with a roughness of, say, a millimeter scale),
you can quite easily anticipate its bounce, which follow (more or less!)
the same law as the light reflection.

Cook-Torrance
=============

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Material --&gt; Shaders`

.. figure:: /images/material-shader-cooktorr.jpg
:width: 320px

Cook-Torrance Shader (Lambert 0.8).

Cook-Torrance
is a basic specular shader that is most useful for creating shiny plastic surfaces.
It is a slightly optimized version of Phong.
Robert L. Cook (LucasFilm) and Kenneth E. Torrance (Cornell University) In their 1982 paper
`A Reflectance Model for Computer Graphics
&lt;https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.7263&amp;rep=rep1&amp;type=pdf&gt;`__
(PDF),
they described "a new reflectance model for rendering computer synthesized images"
and applied it to the simulation of metal and plastic.

Options
-------

Hardness
Size of the specular highlight

Phong
=====

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Material --&gt; Shaders`

.. figure:: /images/material-shader-phong.jpg
:width: 320px

Phong Shader (Lambert 0.8).

Phong is a basic shader that is very similar to CookTorr,
but is better for skin and organic surfaces.
`Bui Tuong Phong &lt;https://en.wikipedia.org/wiki/Bui_Tuong_Phong&gt;`__ (1942-1975)
was a Vietnamese-born computer graphics pioneer that developed the first algorithm for
simulating specular phenomenon.
`His model &lt;https://en.wikipedia.org/wiki/Phong_reflection_model&gt;`__
included components not only for specular lighting, but also diffuse and ambient lighting.

Options
-------

Hardness
Size of the specular highlight.

.. tip:: Planet Atmosphere

Because of its fuzziness, this shader is good for atmosphere around a planet.
Add a sphere around the planet, slightly larger than the planet.
For its material, use a phong specular shader.
Set it to a very low alpha (.05), zero diffuse, low hardness (5) but high specularity (1).

Blinn
=====

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Material --&gt; Shaders`

.. figure:: /images/material-shader-blinn.jpg
:width: 320px

Blinn Shader (Oren-Nayar Int 0.8, Rough 0.5).

Blinn is a more 'physical' specular shader, often used with the Oren-Nayar diffuse shader.
It can be more controllable because it adds a fourth option, an :term:`index of refraction`,
to the aforementioned three.
`James F. Blinn &lt;https://en.wikipedia.org/wiki/Jim_Blinn&gt;`__
worked at NASA's Jet Propulsion Laboratory and became widely known for his work
on Carl Sagan's TV documentary *Cosmos*. The model he described in his 1977 paper
`Models of Light Reflection for Computer Synthesized Pictures
&lt;https://www.microsoft.com/en-us/research/publication/models-of-light-reflection-for-computer-synthesized-pictures/&gt;`__
(PDF) included changes in specular intensity with light
direction and more accurately positioned highlights on a surface.

Options
-------

Hardness
Size of the specular highlight.
The Blinn shader is capable of much tighter specular highlights than Phong or CookTorr.
IOR
'Index of Refraction'.
This parameter is not actually used to compute refraction of light rays through the material
(a ray tracer is needed for that),
but to correctly compute specular reflection intensity and extension via Snell's Law.

Toon
----

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Material --&gt; Shaders`

.. figure:: /images/material-shader-toonspec.jpg
:width: 320px

Toon Specular Shader (Toon Diffuse, Int 0.8, Size &amp; Smooth match).

The Toon specular shader matches the Toon diffuse shader. It is designed to produce the sharp,
uniform highlights of cartoon cels.

Options
-------

Size
Size of the specular highlight.
Smooth
Softness of the highlight's edge.

.. tip:: Alternative Method

The Toon shader effect can also be accomplished in a more controllable way using color ramps.

Ward Isotropic
==============

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Material --&gt; Shaders`

.. figure:: /images/material-shader-wardiso.jpg
:width: 320px

Ward isotropic Shader.

Ward isotropic is a flexible specular shader that can be useful for metal or plastic.

Gregory J. Ward
developed a relatively simple model that obeyed the most basic laws of physics. In his 1992 paper,
"Measuring and modeling anisotropic reaction", Ward introduced a Bidirectional Reflectance Distribution Function
(BRDF) since then widely used in computer graphics because the few parameters it uses are simple to control.
His model could represent both isotropic surfaces (independent of light direction) and anisotropic surfaces
(direction dependent). In Blender,
the Ward specular shader is still called "Ward Isotropic" but is actually anisotropic.
(`PDF &lt;https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.6812&amp;rep=rep1&amp;type=pdf&gt;`__)

Options
-------

Slope
Standard deviation for of surface slope.
Previously known as the `root-mean-square &lt;https://en.wikipedia.org/wiki/Root_mean_square&gt;`__ or rms value,
this parameter in effect controls the size of the specular highlight,
though using a different method to that of the other specular shaders.
It is capable of extremely sharp highlights.

*******
Strands
*******

The Strand section of the Material tab is specific to the rendering of Hair particles.
There are two different strand methods available:

Polygon strands
This is the default (old) method.
The strands are rendered as flat polygons.
The number of polygons depend on the *Steps* settings in the *Particles system* tab.
Strand Primitive
You activate Strand Primitive with the button *Strand render* in the *Render* panel of the particle system.
The hair curves are not stored as polygons; only the key points are stored,
which are then converted to polygons on the fly.
A second difference is the way transparency works.
Rather than rendering using the existing system,
all strand segments in a part are sorted front to back and rendered in that order.

.. rubric:: Strand Primitives

- Are more memory efficient and faster, to make rendering of large amounts of fur and grass possible.
For good performance,
the render steps button should be lowered (e.g. 2 should be good enough fur),
since the result will be a smoothed curve anyway.
You need 1 to 2 render steps less than steps in the 3D View.
Also, using more render parts helps to reduce memory usage.
- Have a distance of vision reduction
(in the *Render* panel under *Child Simplification*) for children from faces.
- May be faded out towards the tip without an additional texture.
- Are not ray traced.
So they are not visible through ray-transparent materials or in a ray mirror
(you can use *Environment Mapping* for that).
- Have shape problems if they are rendered with a greater width.
- Cannot carry a UV-Texture along the strand.

.. rubric:: Polygon strands

- Work well with greater width, so you can use them as an alternative
to billboards because the strands may have an animated shape.
- Can be textured with a UV-Texture along the strands.
- Are seen by ray tracing.

Strands Shading
===============

.. figure:: /images/materials_properties_strands.png
:align: right

Strands Panel.

Strands are rendered with the material of the underlying face/vertex,
including shading with a UV-Texture. Since you can assign more than one material to each face,
each particle system may have its own material and the material of the underlying face can be
different from the material of the strands.

Additionally strands can be shaded along the strand (from root to tip)
with a mono-dimensional texture; only polygon strands can carry a two-dimensional UV-Texture.

The options for strand shading are in the *Strands* section of the *Material* tab.

Root
Width of the hair at the root.
Tip
Width of the hair at the tip.

Minimum
This is the minimum thickness (in pixels) of the strands.
Strands below that size are not rendered smaller,
but are faded to alpha (well, the fading works only for strand primitives).
This gives a much better rendering result for thin hair.
Blender Units
Normally strands are quite thin; the thickness is given in screenpixels.
If you use Blender units (BU) you may set the root value up to 2 BU, and the tip value up to 1 BU.
You have to consider the overall object size, because the smallest possible size is 0.001 BU.
So if you use 1 BU for 1 meter the smallest possible size would be 1 mm (too thick for thin hair).
Use Tangent Shading
Calculates the light as if the strands were very thin and round.
This makes the hair appear brighter and shinier.
Disabling the "Tangent Shading" option will still render nicely,
but resembles more solid strands, as though made of metal or wood.
Shape
This slider allows you to control the interpolation.
Default (0.0) is a linear interpolation between *Root* and *Tip*.
A negative value will make the strand narrower (spiky), a positive value will make it fatter.

.. _fig-bi-material-shadow-shapes:

.. figure:: /images/render_blender-render_materials_strand_shapes.png

Various Shape settings.

From left to right,
\0 (root and tip are equal in the first), 0, -0.4, -0.9, 0.4, 0.9.

Width Fade
To fade out along the width of the strand.
This works only for Strand Primitives. 0.0 is no fading at all, 1.0 linear fading out.
UV Map
You can texture polygon strands with a UV-Texture.
Fill in the name of the UV-Set (not the texture) here.
You also have to load the texture in the *Texture* tab and *Material* tab
(*Mapping*: *UV*; you may use every *Influence* setting you like --
especially the alpha value; see Fig. :ref:`fig-bi-material-shadow-shapes`).
Surface Diffuse
Computes the strand normal, taking the normal at the surface into account.
This eases the coloring and lighting of hair a lot, especially for Strand Primitives.
Essentially hair reacts similar to ordinary surfaces and do not show
exaggerated strong and large specular highlights.

Distance
The distance in Blender units over which to blend in the normal at the surface
(if you want to use *Surface Diffuse* only for Grass/Fur at greater distances).

Texturing along the Strand
==========================

Strands can be textured along the strand, i.e. from root to tip. To do that you have to select
*Strand/Particle* in the *Coordinates* select menu in the
*Mapping* panel of the *Material* tab.

Pretty much the most important setting is shown in Fig. :ref:`fig-bi-material-strands-alpha`,
how to fade the tip of a strand to alpha to make nice, fuzzy-looking hair.
Normally you would use a linear blend texture for this.

.. list-table::

* - .. _fig-bi-material-strands-alpha:

.. figure:: /images/materials_texture_mapping.png

Fading a strand to alpha.

- .. figure:: /images/render_blender-render_materials_properties_strands_fading.png

The render result.

You may of course set any attribute you like, especially color.
Be careful with specularity; hairs tend to get too shiny.

Strand Render Simplification
============================

If you use Strand Primitives (*Strand render* button)
and have activated *Interpolated Children*,
the *Child Simplification* option appears.
The strand render has options to remove child strands as the object's faces become smaller.

.. figure:: /images/render_blender-render_materials_properties_strand-simplification.png

Strand render child simplification.

Reference Size
This is the approximate size of the object on screen (in pixels), after which simplification starts.
Rate
How fast strands are removed.
Transition
The transition period for fading out strands as they are removed.
Viewport
This removes strands on faces that are outside of the viewport.

Rate
Controls how fast these are removed.

*********************
Subsurface Scattering
*********************

Many organic and inorganic materials are not totally opaque right at the surface,
so light does not just bounce off the top surface. Instead,
some light also penetrates the skin surface deeply, and scatters around inside,
taking on the color of the insides and emerging back out at a different location.
Human/animal skin, the skin of grapes, tomatoes, fruits, wax, gels (like honey, or Jello)
and so on all have subsurface scattering (SSS),
and photo-realism really cannot be achieved without it.

It is important to understand that subsurface scattering and diffuse are one and the same. The
difference is in how far light can diffuse beneath the surface before it is absorbed or
transmitted back out.

How it works
============

Actually calculating the light path beneath the surface of an object is not practical.
But it has been shown that it is not necessary to do this,
and that one can use a different approach.

Blender calculates SSS in two steps:

- At first the irradiance, or brightness, of the surface is calculated,
from the front side of the object as well as from its back side.
This is pretty much the same as in a normal render.
Ambient Occlusion, Radiosity, the type of diffuse Shader, the light color, etc. are taken into account.
- In the second step, the final image is rendered, but now the SSS shader replaces the diffuse shader.
Instead of the lamps, the calculated lightmap is used.
The brightness of a surface point is the calculated "Average" of the brightness of its surrounding points.
Depending on your settings the whole surface may be taken into account,
and it is a bit more complicated than simply calculating the average,
but do not bother too much with the math behind it.

Instead let us see what SSS does to a distinct light point.

.. list-table::

* - .. figure:: /images/materials-sss.jpg
:width: 320px

No SSS.

- .. figure:: /images/materials-sss1.jpg
:width: 320px

Small SSS radius.

* - .. figure:: /images/materials-sss2.jpg
:width: 320px

SSS radius enlarged.

- .. figure:: /images/materials-sss3.jpg
:width: 320px

SSS with very large red radius value.

If you turn on SSS, the light is distributed over a larger area.
The size of this area depends on the radius values.
Instead of distributing all colors with the same amount,
you may choose different radius values for each of the RGB colors.

If you use a very large radius value for a color,
its light is evenly distributed over the whole object.

.. note:: Note about scatter radius

Because of the way this scattering is calculated, when using large radius values,
you will notice fringing artifacts that appear as the complementary
color to the predominant color of the scattering.
Above, you see in the last image a bluish band in the illuminated area.
This is an unfortunate limitation.
A way to lessen this effect is use multiple passes with different scatter radii, and average them.

Enabling Subsurface Scattering
==============================

.. figure:: /images/material-sss-panel.png

The SSS Panel. SSS is already enabled.

- Enable SSS by clicking on the *Subsurface Scattering* button.
- Accessible at the top are various presets.
When you select a preset,
the *Radius* values, the *RGB Radius* and the :term:`IOR` are set for you.
The remaining options are not set (because they are mostly dependent on the size of your object).

*Subsurface Scattering* does not need ray tracing.
But since it is dependent on the incident light and shadows,
you need proper shadow calculation (which may need ray tracing).

Options
=======

The numeric sliders control how the light is scattered:

IOR
The :term:`Index Of Refraction` value determines the falloff of incident light.
Higher values means that light falls off faster.
The effect is quite subtle and changes the distribution function only a little bit.
By the examination of many different materials, values of (1.3 to 1.5)
have been found to work well for most materials.
If you know the exact material you are trying to simulate, see :ref:`transparency-ior-common`.
Scale
The scale of your object, in Blender units, across which you want the scattering effect to take place.
Scale of 1.0 means 1 Blender unit equals 1 millimeter,
scale of 0.001 means 1 Blender unit equals 1 meter.
If you want to work out what scale value to use in your scene,
just use the formula: (size in Blender units)/(real world size in millimeters)=scale.

Scattering Color (Albedo)
Albedo is the probability that light will survive a scattering event.
If you think of scattering as a filter, this is the height of the filter.
It is multiplied by the surface color. In practice, this is unintuitive.
It should be the same as the surface color,
however, changing this value has unintuitive results on the scattering effect:

The darker the color the more light is scattered. A value of 1 will produce no scattering effect.

So if you set it to green, the lit areas of the object will appear as green, and green is scattered only a little.
Therefore the darker areas will appear in red and blue.
You can compensate the different scattering by setting a larger radius for the color.
RGB Radius
This is not in fact the radius of the subsurface scattering,
but the average path length between scattering events.
As the light travels through the object it bounces around then emerges from the surface at some other point.
This value corresponds to the average length the light travels between each bounce.
The longer the path length is, the further the light is allowed to scatter.
This is the main source of a material's perceived "scatter color."
A material like skin will have a higher red radius than green and blue.
Subsurface scattering is the diffusion of light beneath the surface.
You control how far the light spreads to achieve a specific result.

Blend
Color
This controls how much the RGB option modulates the diffuse color and textures.
Note that even with this option set to 0.0, the RGB option still influences the scattering behavior.
Texture
How much the surface texture is blurred along with the shading.
Scattering Weight
Front
Factor to increase or decrease the front scattering.
When light enters through the front of the object, how much is absorbed or added?
(Normally 1.0 or 100%).
Back
Factor to increase or decrease the back scattering. Light hitting an object from behind can go all the way
through the object and come out on the front of the object. This happens mostly on thin objects,
like hands and ears.

Error
This parameter controls how precisely the algorithm samples the surrounding points.
Leaving it at 0.05 should give images without artifacts. It can be set higher to speed up rendering,
potentially with errors.

Setting it at 1.0 is a good way to quickly get a preview of the look, with errors.

Developing your own SSS material
================================

The Traditional Approach
------------------------

A more common but less intuitive approach is to use "layering".
This is a simplified version of the layering approach.
See the external links for more information:

- Set the SSS color on a value of your choice, normally the predominant color of the object.
If you want to use different radii for the colors, do not make it too dark.
- Set the scale factor. If you want to see much translucency you need small objects or large scale values.
- Set the radius values.
- Adjust the brightness with the *Front* and *Back* values.

A more intuitive approach
=========================

- Set the Scattering color to 0.5
- Set the Front weight to 2.0
- Set the scale factor based on the size of your object relative to the scene.
If you want to see much translucency you need small objects or large scale values.
- Set the radius values appropriately.

Examples
========

Skin
----

.. list-table::
Increasing SSS scale (`blend-file &lt;https://wiki.blender.org/index.php/:File:MH-SSS-head-001.blend&gt;`__).

* - .. figure:: /images/material-sss-mh-head-1.jpg
:width: 100px

Scale: 1.

- .. figure:: /images/material-sss-mh-head-2.jpg
:width: 100px

Scale: 2.

- .. figure:: /images/material-sss-mh-head-3.jpg
:width: 100px

Scale: 3.

- .. figure:: /images/material-sss-mh-head-4.jpg
:width: 100px

Scale: 4.

- .. figure:: /images/material-sss-mh-head-5.jpg
:width: 100px

Scale: 5.

.. seealso::

- `Development Release Log: Subsurface Scattering
&lt;https://www.blender.org/development/release-logs/blender-244/subsurface-scattering/&gt;`__.
- `Ben Simonds: Three Layer SSS in Blender Demystified
&lt;https://bensimonds.com/2010/05/31/three-layer-sss-in-blender-demystified/&gt;`__.

************
Transparency
************

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Material --&gt; Transparency`

Materials in Blender can be set to be transparent,
so that light can pass through any objects using the material.
Transparency is controlled using an "alpha" channel, where each pixel has an additional value,
range 0-1, in addition to its RGB color values. If alpha=0, then the pixel is transparent,
and the RGB values for the surface contribute nothing to the pixel's appearance; for alpha=1,
the surface is fully opaque,
and the color of the surface determines the final color of the pixel.

.. figure:: /images/materials_properties_transparency.jpg

Transparency Panel.

In Blender, there are three ways in which the transparency of a material can be set:
Mask, Z-Buffer and Ray-trace. Each of these is explained in more detail below.
The :doc:`Material Preview &lt;/render/blender_render/materials/properties/preview&gt;`
option with a sphere object gives a good demonstration
of the capabilities of these three options.

Common Options
==============

The following property controls are available for all transparency options:

Alpha
Sets the transparency of the material by setting all pixels in the alpha channel to the given value.
Fresnel
Sets the power of the Fresnel effect.
The Fresnel effect controls how transparent the material is,
depending on the angle between the surface normal and the viewing direction.
Typically, the larger the angle, the more opaque a material becomes
(this generally occurs on the outline of the object).
Specular
Controls the alpha/falloff for the specular color.
Blend
Controls the blending between transparent and non-transparent areas. Only used if Fresnel is greater than 0.

Mask
----

This option simply masks the Background. It uses the alpha channel to mix the color of each
pixel on the active object plane with the color of the corresponding background pixel,
according to the alpha channel of the pixel. Thus for alpha = 1,
the object color is seen -- the object is completely opaque; but if alpha = 0,
only the background is seen -- the object is transparent
(but note that any other object behind the active object disappears).

This is useful for making textures of solid or semi-transparent objects from photographic
reference material, i.e. a mask is made with alpha opaque for pixels within the object,
and transparent for pixels outside the object.

.. seealso::

:doc:`Mask Transparency &lt;/render/blender_render/materials/properties/transparency&gt;`.

Z Buffer
========

This uses the alpha buffer for transparent faces.
The alpha value of each pixel determines the mix of the basic color of the material,
and the color of the pixel is determined from the objects/background behind it.
Only basic settings are available with this option; it does not calculate refractions.

Raytraced Transparency
======================

Uses ray tracing to calculate refractions. Ray tracing allows for complex refractions,
falloff, and blurring,
and is used for simulating the refraction of light rays through a transparent material,
like a lens.

.. note::

The Raytrace option is only available in the Blender Render and Cycles render
engines, but not in the Game Engine.

A ray is sent from the camera and travels through the scene until it encounters an object.
If the first object hit by the ray is non-transparent,
then the ray takes the color of the object.

If the object is transparent, then the ray continues its path through it to the next object,
and so on, until a non-transparent object is finally encountered which gives the whole chain
of rays its color. Eventually,
the first transparent object inherits the colors of its background,
proportional to its *Alpha* value
(and the Alpha value of each transparent Material hit in between).

But while the ray travels through the transparent object,
it can be deflected from its course according to the Index of Refraction (IOR)
of the material. When you actually look through a plain sphere of glass,
you will notice that the background is upside-down and distorted:
this is all because of the Index of Refraction of glass.

.. note:: Enable Raytracing

To get ray-traced transparency, you need to:

- Enable ray tracing in your Render settings.
This is done in the :menuselection:`Render --&gt; Shading` panel. Ray tracing is enabled by default.
- Set your Alpha value to something other than 1.0.
- In order for the background material to receive light passing through your transparent object,
*Receive Transparent* must be turned on for that material in the :menuselection:`Material --&gt; Shadow` panel.

Options
=======

.. figure:: /images/material-raytrace_transp-panel.png

The Transparency Panel.

In addition to the common options given above, the following property controls are available:

IOR
Index of Refraction. Sets how much a ray traveling through the material will be refracted,
hence producing a distorted image of its background. See
`IOR values for Common Materials`_ below.
Filter
Amount of filtering for transparent ray trace. The higher this value,
the more the base color of the material will show.
The material will still be transparent but it will start to take on the color of the material.
Disabled (0.0) by default.
Falloff
How fast light is absorbed as it passes through the material. Gives 'depth' and 'thickness' to glass.
Limit
Materials thicker than this are not transparent.
This is used to control the threshold after which the filter color starts to come into play.
Depth
Sets the maximum number of transparent surfaces a single ray can travel through. There is no typical value.
Transparent objects outside the *Depth* range will be rendered pitch black if viewed through the
transparent object that the *Depth* is set for. In other words,
if you notice black areas on the surface of a transparent object,
the solution is probably to increase its *Depth* value
(this is a common issue with ray tracing transparent objects).
You may also need to turn on transparent shadows on the background object.

Gloss
Settings for the glossiness of the material.

Amount
The clarity of the refraction. Set this to something lower than zero to get a blurry refraction.
Threshold
Threshold for adaptive sampling.
If a sample contributes less than this amount (as a percentage), sampling is stopped.
Samples
Number of cone samples averaged for blurry refraction.

Examples
========

Index of Refraction
-------------------

.. huge image

.. figure:: /images/material-raytrace_transp-ior-examples.jpg

Influence of the IOR of an Object on the distortion of the background:
spheres of Water, Glass and Diamond (top to bottom).

(Influence of the IOR of an Object on the distortion of the background:
spheres of Water, Glass and Diamond (top to bottom)).
There are different values for typical materials: Air: 1.000 (no refraction),
Alcohol: 1.329, Glass: 1.517, Plastic: 1.460, Water: 1.333 and Diamond: 2.417.

Fresnel
-------

.. list-table:: Pieces of glass rotated in various directions to demonstrate the angle-dependent Fresnel effect.
Note that the major difference is the lack of IOR effect in the latter case.
(Download `blend-file &lt;https://wiki.blender.org/index.php/:File:Manual25-Material-FresnelExample.blend&gt;`__.)

* - .. figure:: /images/material-raytrace_transp-fresnelexampel.jpg
:width: 320px

With ray-traced transparency.

- .. figure:: /images/material-raytrace_transp-fresnelexampelztransp.jpg
:width: 320px

With alpha buffered transparency.

.. list-table::

* - .. figure:: /images/material-raytrace_transp-fresnelsettings.png
:width: 320px

Settings for Fresnel using ray-traced.

- .. figure:: /images/material-raytrace_transp-fresnelsettingsztransp.png
:width: 320px

Settings for Fresnel using Z transparency.

.. note::

The specular highlight in the F4 glass tile
(which is facing midway between the light and the camera); the Fresnel effect can be seen in
row C and column 6 where the faces are turned away from the camera.

The amount of Fresnel effect can be controlled by either increasing the *Blend*
value or decreasing the *Alpha* value.

Depth
-----

.. figure:: /images/material-transp-3glassesexample.jpg

A simple scene with three glasses on a surface, and three lamps.
Depth was set to 4, 8, 12, and 14, resulting in render times of 24 sec, 34 sec, 6 min, and 11 min respectively.
(Download `blend-file &lt;https://wiki.blender.org/index.php/:File:Manual25-Material-3GlassesExample.blend&gt;`__.)

Increasing *Depth* also considerably increases render time.
Each time a light ray passes through a surface,
the ray-tracing algorithm is called recursively. In the example above,
each side of each glass has an exterior and an interior surface.
Light rays thus have to pass through four surfaces for each glass.

But not only that, at every point on a surface, some of the light can be reflected,
or mirrored off the surface in various directions.
This results in multiple rays needing to be calculated for each point
(often referred to as a `tree of rays &lt;https://www.cs.unc.edu/~rademach/xroads-RT/RTarticle.html&gt;`__).
In each of the rendered images above there are 640×400=256 000 pixels.
By increasing *Depth*, at least one tree of rays is added to each pixel.

Be kind to your computer. Carefully placing objects in a scene to avoid overlapping
transparent objects is often an interesting alternative.

Hints
=====

Transparent shadows
-------------------

.. list-table::

* - .. figure:: /images/material-transp_shadow-example-notrasha.jpg
:width: 320px

No transparent shadows.

- .. figure:: /images/material-transp_shadow-example-envlight.jpg
:width: 320px

No transparent shadows, environment lighting enabled.

* - .. figure:: /images/material-transp_shadow-example-trasha.jpg
:width: 320px

Transparent shadows enabled, alpha set to 0.0.

- .. figure:: /images/material-transp_shadow-example-trasha2.jpg
:width: 320px

As previous, alpha set to 0.25.

* - .. figure:: /images/material-transp_shadow-example-trasha-ao1.jpg
:width: 320px

Transparent shadows with ambient occlusion set to multiply, distance 1 (radius of sphere).

- .. figure:: /images/material-transp_shadow-example-trasha-ao2.jpg
:width: 320px

As previous, distance increased to 2 (diameter of sphere).

By default, the shadows of transparent objects are rendered solid black,
as if the object was not transparent at all. But in reality,
the more transparent an object is, the lighter its shadow will be.

In Blender, transparent shadows are set on the materials that receive the shadows from the
transparent object.
This is enabled and disabled with the *Receive Transparent* button,
in the :menuselection:`Material --&gt; Shadow` panel. The shadow's brightness is
dependent on the *Alpha* value of the shadow casting material.

Alternatives to transparent ray-traced shadows can be found in the *World* tab,
namely the *Ambient Occlusion*, *Environment Lighting*,
and *Gather* panels. Alternatively, a texture can be used to control the
*Intensity* value of the shadow-receiving material.

.. _transparency-ior-common:

IOR values for Common Materials
-------------------------------

The following list provides some index of refraction values to use when ray-traced
transparency is used for various liquids, solids (gems), and gases:

.. Sections ordered by density (low -&gt; high)

Gases
^^^^^

.. hlist::
:columns: 3

- Air ``1.000``
- Carbon Dioxide ``1.000449``
- Oxygen ``1.000276``

Common Liquids
^^^^^^^^^^^^^^

.. hlist::
:columns: 3

- Alcohol ``1.329``
- Milk ``1.35``
- Oil, vegetable (50- C) ``1.47``
- Shampoo ``1.362``
- Water (0- C) ``1.33346``
- Water (100- C) ``1.31766``
- Water (20- C) ``1.33283``
- Water (gas) ``1.000261``
- Water (35- C, room temp) ``1.33157``
- Vodka ``1.363``

Common Transparent Materials
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. hlist::
:columns: 3

- Glass ``1.51714``
- Ice ``1.309``
- Rock Salt ``1.544``

Common Opaque Materials
^^^^^^^^^^^^^^^^^^^^^^^

.. hlist::
:columns: 3

- Asphalt ``1.635``
- Chalk ``1.510``
- Plastic ``1.46``
- Rubber, Natural ``1.5191``
- Silicon ``4.24``

Gemstones
^^^^^^^^^

.. hlist::
:columns: 3

- Diamond ``2.417``
- Jade, Nephrite ``1.61``
- Opal ``1.45``
- Ruby ``1.757 - 1.779``

Metals
^^^^^^

.. hlist::
:columns: 3

- Aluminum ``1.44``
- Bronze ``1.18``
- Copper ``1.10``
- Gold ``0.47``
- Iron ``1.51``
- Lead ``2.01``
- Platinum ``2.33``
- Silver ``0.18``
- Steel ``2.50``
- Titanium ``2.16``

**************
Halo Rendering
**************

.. figure:: /images/materials-helorender-activate.jpg
:width: 300px

Activating halo rendering.

Halo materials renders each of the objects points as glowing dots or a little clouds of light.
Although they are not really lights because they do not cast light into the scene like a lamp.
These are called *Halos* because you can see them, but they do not have any substance.

Halos are rendered with vertex shaders and not with face shaders.

This material is useful for simulating special effects, like particle effects or lens flares.

Options
=======

.. figure:: /images/materials-halos.png
:width: 309px

Halo panels.

To enable *Halos*, press the *Halo* button in the *Material* menu's top panel.

As you will see in the 3D View, the mesh faces are no longer rendered.
Instead just the vertex is rendered, since that is where each halo will originate.
Halos can be hard to find in a crowded scene, so name it well for easy location in
:doc:`the outliner &lt;/editors/outliner&gt;`.

In the Properties editors, where we normally find the *Diffuse*,
*Specular*, and *Shading* panels,
we now see panels relative to the *Halo* characteristics:

Halo Panel
----------

Alpha
The transparency.
Diffuse Color
The color of the halo itself.
Seed
If non-zero, randomizes the ring dimension and line location.
To use, give any (integer) number to start the random-number generator.
Size
Sets the dimension of the halo
Hardness
Sets the hardness of the halo. Similar to specular hardness
Add
Determine how much the halo colors are 'added to',
rather than mixed with, the colors of the objects behind and together with other halos.
By increasing Add, the Halo will appear to light up objects that move behind it or through the Halo field.

.. figure:: /images/materials-haloadd.jpg

Effect of Add.

Texture
Gives halo a texture. By default,
textures are applied to objects with Object coordinates and reflect on the halos by affecting their color,
as a whole, on the basis of the color of the vertex originating the halo.
Enable this feature to have the texture take effect *within* the halo,
and hence to have it with varying colors or transparencies; this will map the whole texture to *every* halo.
This technique proves very useful when you want to create a realistic rain effect using particle systems,
or similar.
Vertex Normal
Uses the vertex normal to specify the dimension of the halo.
Extreme Alpha
Boosts alpha.
Shaded
Lets halo receive light and shadows from external objects.

When shaded is enabled, the Halo will be affected by local light;
a lamp will make it brighter and affect its diffuse color and intensity.
Soft
Softens the edges of the halos at intersections with other geometry.

In addition, several other special effects are available.
To enable some or all of these effects, set the number of points/rings,
or set the color of each effect individually:

Rings
Adds circular rings around to the halo.
Lines
Adds lines from the center of the halo.
Star tips
Gives the halo a star shape.

You cannot use color ramps. Lines,
Rings and an assortment of special effects are available with the relevant toggle buttons,
which include Flare, Rings, Lines, Star, Texture, Extreme Alpha, and Shaded.
*Halo Variations* shows the result of applying a halo material to a single vertex mesh.

.. figure:: /images/render_blender-render_materials_special-effects_halo02.jpg

Halo Variations.

Flare Panel
-----------

Enabling Flare Renders the halo as a lens flare.

Size
Sets the factor by which the flare is larger than the halo.
Boost
Gives the flare extra strength.
Seed
Specifies an offset in the flare seed table.
Subflares
Sets the number of subflares.
Subsize
Sets the dimensions of the subflares, dots, and circles.

Lens Flares
^^^^^^^^^^^

Our eyes have been trained to believe that an image is real if it shows
artifacts that result from the mechanical process of photography.
*Motion blur*, *Depth of Field*, and *lens flares*
are just three examples of these artifacts.
The first two are discussed in the *chapter rendering*;
the latter can be produced with special halos.
A simulated lens flare tells the viewer that the image was created with a
camera, which makes the viewer think that it is authentic.

We create lens flares in Blender from a mesh object using first the *Halo* button
and then the *Flare* options in the *Shaders* Panel of the material
settings. Try turning on *Rings* and *Lines*,
but keep the colors for these settings
fairly subtle. Play with the *Flares:* number and *Fl. seed:*
settings until you arrive at something that is pleasing to the eye.
You might need to play with *Boost:* for a stronger effect
Fig. :ref:`fig-bi-material-halo-flare` settings.

Note that this tool does not simulate the physics of photons
traveling through a glass lens; it's just an eye candy.

Blender's lens flare looks nice in motion,
and disappears when another object occludes the flare mesh.

.. _fig-bi-material-halo-flare:

.. figure:: /images/render_blender-render_materials_special-effects_halo04.jpg
:width: 630px

Lens Flare.

Halo Texturing
==============

By default, textures are applied to objects with Object coordinates and reflects on the halos
by affecting their color, as a whole,
on the basis of the color of the vertex originating the halo.
To have the texture take effect *within* the halo, and hence to have it with varying colors
or transparencies press the *Texture* button;
this will map the whole texture to *every* halo. This technique proves very useful when you
want to create a realistic rain effect using particle systems, or similar.

Another Option is Shaded. When shaded is enabled, the Halo will be affect by local light;
a lamp will make it brighter and affect its diffuse color and intensity.

Examples
========

Dotmatrix Display
-----------------

Let us use a halo material to create a dotmatrix display:

#. To begin, add a grid with the dimensions 32×16.
Then add a camera and adjust your scene so that you have a nice view of the billboard.
#. Use a 2D image program to create some red text on a black background,
using a simple and bold font, you can just save the picture below on your hard drive...).
:ref:`fig-bi-material-halo-matrix-texture` shows an image 512 pixels wide by 64 pixels high,
with some black space at both sides.

.. _fig-bi-material-halo-matrix-texture:

.. figure:: /images/render_blender-render_materials_special-effects_halo_dotmatrix2.jpg

Dot matrix image texture.

- Add a material for the billboard, and set it to the type *Halo*.
Set the *Halo Size* to 0.06 and when you render the scene you should see a grid of white spots.
- Add a Texture, then change to the Texture Buttons and make it an image texture.
When you load your picture and render again you should see some red tinted dots in the grid.
- Return to the Material Buttons and adjust the *size X* parameter to about 0.5 then render again;
the text should now be centered on the Billboard.
- To remove the white dots, adjust the material color to a dark red and render.
You should now have only red dots, but the billboard is still too dark.
To fix this enter *Edit Mode* for the board and copy all vertices using the :kbd:`Shift-D` shortcut
(take care not to move them!).
Then adjust the brightness with the *Add* value in the Halo panel.

.. _fig-bi-material-halo-dotmatrix:

.. figure:: /images/render_blender-render_materials_special-effects_halo_dotmatrix.jpg

Dot Matrix display.

You can now animate the texture to move over the billboard,
using the *Offset X* value in the *Texture* tab of the Mapping panel.
(You could use a higher resolution for the grid,
but if you do you will have to adjust the size of the halos by shrinking them,
or they will overlap. Fig. :ref:`fig-bi-material-halo-dotmatrix`).

.. note:: Note about material indices

Halo materials only work when applied using the first material index.
Any material(s) in a subsequent material index will not be rendered.

###########################
Special Material Effects
###########################

.. toctree::
:maxdepth: 2

halo.rst
volume.rst
wire.rst

****************
Volume Rendering
****************

.. figure:: /images/materials-volumerender-activate.jpg
:width: 300px

Activating Volume rendering.

Volume rendering is a method for rendering light as it passes through participating media,
within a 3D region. The implementation in Blender a physically based model,
which represents the various interactions of light in a volume relatively realistically.

.. figure:: /images/render_blender-render_materials_volume_volume_eq.jpg

Volume rendering.

Rendering a volume is different from
:doc:`Solid Render &lt;/render/blender_render/materials/properties/diffuse_shaders&gt;`.
For volume light enters a 3D region of space (defined as the volume)
that may be filled with small particles, such as smoke, mist or clouds.
The light bounces around off the various molecules, being scattered or absorbed,
until some light passes through the volume and reaches the camera.
In order for that volume to be visible, the renderer must figure out how much material the
light has passed through and how it has acted and reacted within that volume,
the volume object needs to contain a 3D region of space, for example a :term:`manifold` closed mesh,
such as a cube, not just a flat surface like a plane. To get an image,
the renderer has to step through that region, and see how much 'stuff' is there (density)
in order to see how light is absorbed or scattered or whatever. This can be a time consuming
process since it has to check a lot of points in space and evaluate the density at each.

Options
=======

Density
-------

.. figure:: /images/render_blender-render_materials_volume_density.jpg

Constant density vs textured density.

Many things can happen to the light as it passes through the volume,
which will influence the final color that arrives at the camera.
These represent physical interactions that happen in the real world,
and most of these are dependent on the density of the volume,
which can either be a constant density throughout, or varied, controlled by a texture. It is
by controlling the density that one can get the typical 'volumetric' effects such as clouds or
thick smoke.

Density
The base density of the material. Other densities from textures are added on top.
Density Scale
A global multiplier to increase or decrease the apparent density.
This can be useful for getting consistent results across different scene scales.

Shading
-------

.. figure:: /images/render_blender-render_materials_volume_scattering1.jpg

Spot lamp scattering in a constant volume.

When light enters a volume from an external source, it does not just pass straight through.
Light gets scattered off tiny particles in the volume,
and some proportion of that light reaches the camera. This property makes it possible to see
light beams as they travel though a volume and are scattered towards the eye.

.. figure:: /images/materials-volumerender-options-shading.png

Shading options.

Scattering
The amount of light that is scattered out of the volume.
The more light that is scattered out of the volume, the less it will penetrate through the rest of the volume.
Raising this parameter can have the effect of making the volume seem denser,
as the light is scattered out quickly at the 'surface' of the volume,
leaving the areas internal to the volume darker, as the light does not reach it.

Note in the examples below, the less light that is scattered out of the volume,
the more easily it penetrates throughout the volume and to the shadow.

.. list-table::

* - .. figure:: /images/render_blender-render_materials_volume_scatter-sc0_5.jpg
:width: 150px

Scattering: 0.5.

- .. figure:: /images/render_blender-render_materials_volume_scatter-sc1_0.jpg
:width: 150px

Scattering: 1.0.

- .. figure:: /images/render_blender-render_materials_volume_scatter-sc2_0.jpg
:width: 150px

Scattering: 2.0.

- .. figure:: /images/render_blender-render_materials_volume_scatter-sc5_0.jpg
:width: 150px

Scattering: 5.0.

Asymmetry
---------

.. figure:: /images/render_blender-render_materials_volume_phase_diagram.png
:width: 300px

Isotropic and Anisotropic scattering.

The default method for scattering light in a volume is for the light to be deflected evenly in
all directions, also known as Isotropic scattering.
In real life different types of media can scatter light in different angular directions,
known as Anisotropic scattering.
Back-scattering means that light is scattered more towards the incoming light direction, and
forward-scattering means it is scattered along the same direction as the light is traveling.

Asymmetry
Asymmetry controls the range between back-scattering (-1.0) and forward-scattering (1.0).
The default value of 0.0 gives Isotropic scattering (even in all directions).

Transmission
------------

Transmission is a general term for light that is transmitted throughout a volume.

This transmitted light can be the result of various different interactions, for example:

- the left over result of incoming light after it has reflected/scattered out of the volume
- the left over result of light after being absorbed by the volume (and converted to heat)

Here, the transmission color is used to set the end result color
that light becomes after it is transmitted through the volume.

Transmission Color
The resultant color of light that is transmitted through the volume.

Note in the examples below, as more light is scattered out of the volume,
there is less available to be transmitted through.

.. list-table::

* - .. figure:: /images/render_blender-render_materials_volume_tr_y-sc0_5.jpg
:width: 150px

Transmission color: Yellow, Scattering: 0.5.

- .. figure:: /images/render_blender-render_materials_volume_tr_y-sc1_0.jpg
:width: 150px

Transmission color: Yellow, Scattering: 1.0.

- .. figure:: /images/render_blender-render_materials_volume_tr_y-sc2_0.jpg
:width: 150px

Transmission color: Yellow, Scattering: 2.0.

- .. figure:: /images/render_blender-render_materials_volume_tr_y-sc5_0.jpg
:width: 150px

Transmission color: Yellow, Scattering: 5.0.

Emission
--------

Some volumes can emit light where there was none before, via chemical or thermal processes,
such as fire. This light is generated from the volume itself and is independent of light
coming from external sources.

Currently, this emitted light does not affect other volumes or surfaces
(similar to surface material type, 'Emit' option).

Emission Color
The color of light that is emitted by the volume.
Emission
An intensity multiplier for the emitted color, for scaling up and down.

.. list-table::

* - .. figure:: /images/render_blender-render_materials_volume_emission-0_25-sc0_5.jpg
:width: 150px

Emission 0.25, Scattering: 0.5.

- .. figure:: /images/render_blender-render_materials_volume_emission-0_25-sc1_0.jpg
:width: 150px

Emission 0.25, Scattering: 1.0.

- .. figure:: /images/render_blender-render_materials_volume_emission-0_25-sc2_0.jpg
:width: 150px

Emission 0.25, Scattering: 2.0.

- .. figure:: /images/render_blender-render_materials_volume_emission-0_25-sc5_0.jpg
:width: 150px

Emission 0.25, Scattering: 5.0.

Reflection
----------

The *Reflection* parameters can be used to tint or scale the light that is scattered out of the
volume. This only affects light that has come from lamps and been scattered out,
it does not affect the color of transmitted or emitted light and is.

These settings are not physically correct, because they do not conserve energy.
This means the light scattering out does not affect the remaining light,
that is transmitted throughout the rest of the volume.

For example, physically speaking,
if the orange components of the light are scattered out of the volume towards the camera,
only the inverse of that (blue) will remain to continue penetrating through the volume,
causing the volume to take on a multi-colored appearance, which can be difficult to use.
To make it a bit easier to plainly set the color of the volume,
you can use the reflection parameters to quickly set an overall tint.

Reflection Color
The color of light that is scattered out of the volume.
Reflection
An intensity multiplier for the reflection, for scaling up and down.

Hints
^^^^^

Ideally try to accomplish as much as you can with the other volume settings and lighting
before using the reflection controls. If you stick to what is physically plausible,
the material will act correctly,
and be more predictable and usable in a wider range of lighting scenarios.
Of course you can always break the rules too!

.. list-table::

* - .. figure:: /images/render_blender-render_materials_volume_reflection-sc0_5.jpg
:width: 150px

Reflection: Green, Scattering: 0.5.

- .. figure:: /images/render_blender-render_materials_volume_reflection-sc1_0.jpg
:width: 150px

Reflection: Green, Scattering: 1.0.

- .. figure:: /images/render_blender-render_materials_volume_reflection-sc2_0.jpg
:width: 150px

Reflection: Green, Scattering: 2.0.

- .. figure:: /images/render_blender-render_materials_volume_reflection-sc5_0.jpg
:width: 150px

Reflection: Green, Scattering: 5.0.

.. list-table::

* - .. figure:: /images/render_blender-render_materials_volume_refl_g-tr_y-sc0_5.jpg
:width: 150px

Reflection: Green, Transmission: Yellow, Scattering: 0.5.

- .. figure:: /images/render_blender-render_materials_volume_refl_g-tr_y-sc1_0.jpg
:width: 150px

Reflection: Green, Transmission: Yellow, Scattering: 1.0.

- .. figure:: /images/render_blender-render_materials_volume_refl_g-tr_y-sc2_0.jpg
:width: 150px

Reflection: Green, Transmission: Yellow, Scattering: 2.0.

- .. figure:: /images/render_blender-render_materials_volume_refl_g-tr_y-sc5_0.jpg
:width: 150px

Reflection: Green, Transmission: Yellow, Scattering: 5.0.

Lighting
========

.. figure:: /images/materials-volumerender-options-lighting.jpg

Lighting options.

Several shading modes are available,
providing a range of options between fast to render and physically accurate.

Lighting Mode
Shadeless
Shadeless is the simplest, useful for thin, wispy mist or steam.
Shadowed
Shadowed is similar, but with shadows of external objects.
Shaded
Shaded uses a volumetric single-scattering method, for self-shading the volume as light penetrates through.
Multiple Scattering
Allows multiple scatter calculations.
Shaded + Multiple Scattering
Combines Shaded and Multiple Scattering functionality.

Shaded Options
External Shadows
Receive shadows from sources outside the volume (temporary).
Light Cache
Pre-calculate the shading information into a voxel grid, speeds up shading at slightly less accuracy.
Resolution
Resolution of the voxel grid, low resolutions are faster, high resolutions use more memory.

Multiple Scattering Options
Diffusion
Diffusion factor, the strength of the blurring effect.
Spread
Proportional distance over which the light is diffused.
Intensity
Multiplier for multiple scattered light energy.

Transparency
============

The transparency settings are the same as
:doc:`Solid Render &lt;/render/blender_render/materials/properties/diffuse_shaders&gt;` except you have less settings.
For volume rendering you only have:

- Mask
- Z Transparency
- Raytrace

Integration
===========

.. figure:: /images/materials-volumerender-options-integration.jpg

Integration options.

Step Calculation Method
Method of calculating the step through the volume.

Randomized
Randomized method of calculating the step.
Constant
Constant method of calculating the step.

Step Size
Distance between subsequent volume depth samples.
Step Sizes determine how noisy the volume is.
Higher values result in lower render times and higher noise.
Depth Cutoff
Stop ray marching early if transmission drops below this luminance threshold.
Higher values will give a speedups in dense volumes at the expense of accuracy.

Options
=======

.. figure:: /images/materials-volumerender-options.jpg

Material volume options.

Traceable
Allow this material to calculate raytracing.
Full Oversample
Force this material to render full shading/textures for all anti-aliasing samples.
Use Mist
Use mist with this material (in world settings).

Light Group
Limit lighting of this material to lamps in this group.
Exclusive
Material uses this group exclusively. Lamps are excluded from other scene lighting.

Smoke and Fire
==============

Create the Material
-------------------

The material must be a volumetric material with a Density of 0, and a high Density Scale.

.. figure:: /images/render_blender-render_materials_volume_tab.jpg
:width: 300px

The Material Settings.

Smoke requires a complex material to render correctly. Select the big cube and go to the material tab.
There change the material to 'Volume' and set the density to 0.
If you set the density to values bigger than 0 the domain cube will be filled with the volume material.
The `other settings &lt;https://wiki.blender.org/index.php/User:Broken/VolumeRenderingDev&gt;`__
will affect the smoke, though. We'll cover those later.

Add the Texture
---------------

In addition, Smoke requires its own texture,
you can use a volumetric texture known as
:doc:`Voxel Data &lt;/render/blender_render/textures/types/volume/index&gt;`.
You must remember to set the domain object and change the influence.

.. figure:: /images/render_blender-render_materials_volume_fire-texture-tab0.jpg

The texture settings.

Go to the texture tab and change the type to *Voxel Data*.
Under the Voxel Data-Settings set the domain object to our domain cube
(it should be listed just as 'Cube' since we are using Blender's default cube.
Under Influence check 'Density' and leave it at 1.000
(Emission should be automatically checked, too).
Now you should be able to render single frames. You can choose to color your smoke as well,
by turning *Emission Color* back on.

.. figure:: /images/smoke_render.jpg

Finished Result.

.. tip:: To see the smoke more clearly.

Under the world tab, choose a very dark color for the horizon.

Smoke Simulator with fire texture
---------------------------------

You can also turn your smoke into fire with another texture! To make fire,
turn up the Emission Value in the Materials panel.

.. figure:: /images/render_blender-render_materials_volume_fire-material-tab.jpg
:width: 300px

The Fire material.

Then, add another texture (Keep the old texture or the smoke will not show).
Give it a fiery color ramp- which colors based on the alpha,
and change the influence to emission and emission color. Change the blend to Multiply.

.. figure:: /images/render_blender-render_materials_volume_fire-texture-tab.jpg
:width: 300px

The fire texture settings.

.. figure:: /images/render_blender-render_materials_volume_fire-render3.jpg

The fire render.

***********
Wire Render
***********

.. figure:: /images/materials_render_wire0.png
:width: 320px

Wire Render.

The Wire Render option in the Materials section provides a way of showing a rendered image of
the edges in an object.
Each edge is rendered as a single-pixel image of the edges which make up the mesh. The colors,
alpha and other relevant properties of the lines are selected with the same control panels as
provided by the Surface rendered image.

.. figure:: /images/materials_demo_wire.jpg
:width: 320px

Wire Render.

#####################
Optimizing Renders
#####################

.. toctree::
:maxdepth: 2

quality.rst
performance.rst
.. This page includes some overly detailed &amp; spesific infomration should be simplified.
- ideasman42

**************************
Performance Considerations
**************************

Optimizing Render Performance
=============================

"A watched pot never boils" is the old saying, but you may wonder why your render takes so long to create,
or worse, crashes mid-way through!
Well, there is lots going on and lots you can do to speed up rendering or enable a complicated render to complete.
Also, it is possible to render a very complicated scene on a mediocre PC by being "render-smart".
Here is a "top ten" list of things to do or not do in order to speed up
rendering or even avoid crashes during scene render.
Some options may decrease the quality of your render, but for draft renders you may not care.

If you get the message "Malloc returns nil", in plain English that means the memory allocator
tried to get more physical memory for Blender but came back empty-handed.
This means that you do not have enough memory available to render the scene,
and Blender cannot continue.
You will need to do one or more of the following tasks on this page in order to render.

Hardware Improvements
=====================

- Install more system memory.
- Upgrade your CPU to a multi-core/multiprocessor.
- Upgrade your OpenGL video drivers.
- Get faster memory, up to your PC's motherboard limit.
- Use or set up a render farm using all available PCs in your house, or use a render farm.

Operating System Configuration
==============================

- Increase Blender's processing priority through your OS.
- Increase your swap file space used by the OS for memory swapping, also called virtual memory pagefile size,
up to the size of your physical memory.
- Use a system-monitor to check if any other processes using significant CPU or RAM can be closed.
- Render in *background mode* (from the command line), saves extra memory.

Blender Settings
================

- Increase the MEM Cache Limit in the User Preferences System &amp; OpenGL tab.
- Switch to an Orthographic camera, and render your own "parts" of the scene as separate images,
and then paste those parts together in GIMP.
An old trick in making your own panorama with a real camera is to take three or so pictures of a very wide
(beach sunset) scene, where you take one picture, rotate to the right, snap another, then another,
and when you get the pictures developed, you overlap them to make a very wide landscape image.
Do the same in Blender: render out one shot to a file,
then move the camera to look at a different area of the scene, and render that shot.
Each shot will be of a smaller area and thus take in fewer polygons/faces.
Be sure that when you position your camera that you snap overlapping shots, so that you can then match them up.
If you do not want to use GIMP, you can use compositing nodes and the Translate node to match them up in Blender.
- Minimize the render window (and the Blender window, if the UV/image editor is used).
ATI users report dramatic speedup on a per frame basis, which adds up over the frame range.
- Use the Big Render script to render sub-sections of the overall image, and then paste them together.

Scene and Specific Objects
==========================

#. Remove lamps, or move them to unrendered layers, or tie them to layers.
#. Turn off some lamp's shadows, using only one or two main sun lamps to cast shadows.
A few "shadows only" lights will render faster than every light having shadows on.
#. Use Buffer Shadows rather than ray-traced Shadows.
#. Bake your shadows using Render Baking Full Render bake on surfaces that do not move.
Use that texture for that mesh, then disable shadows for that material.
#. Simplify meshes (remove polygons). The more vertices you have in camera, the more time it takes to render.
#. Remove Doubles, or use the Decimator mesh edit feature.
#. Remove Subdivision Surface and Multiresolution modifiers.
#. Delete backsides of meshes (removing unseen geometry).
#. Render just a few objects at a time; in the beginning of your project,
render the background objects and sets that will not change and will always be in the background.
#. Put the buildings on another layer, and, through render layers, do not render them.
Then composite them back in later.
#. Make the camera static so that you can better accomplish the above two ideas.
#. Avoid use of Area lights.
#. Make materials Shadeless.
#. Render Bake AO and textures, and then make those materials Shadeless.
#. Decrease the Clip distance for spot lights.
#. Decrease the Clip distance for the camera.
#. Turn off world AO.
#. Turn off Material SSS.
#. Use smaller image textures. A 256×256 image takes only 1% of the memory that a 2k image does,
often with no loss of quality in the ultimate render.
#. Reduce Subdivision Surfaces. Each level quadruples (4x) the number of faces from the previous level.
#. Reduce Multires.
#. Make a matte render of background objects, like buildings,
and put the image of them on a billboard in the scene instead of the object themselves.
This will reduce vertex/face count.
#. If you have lots of linked instances of an object, use DupliFaces, as these are instanced. If you have 100 of them,
Blender will only store the geometry for 1 (Instances themselves take a small amount of memory).

Render Settings
===============

:doc:`Output Panel &lt;/render/output/output&gt;`
- Disable *Edge* rendering.
- *Save Buffers*.

- Render to an :ref:`UV/Image Editor &lt;editors-uv-image-index&gt;`,
not a pop-up. :doc:`Render Window &lt;/render/output/render_panel&gt;`.
- Use multiple *Threads* on a multi-core CPU (with multiple *Parts*).
- Decrease the frame count of the animation (and use a lower framerate for the same duration of animation).
For example, render 30 frames at 10 frames per second for a 3-second animation,
instead of 75 frames at 25 frames per second.
:doc:`Render Layers Panel &lt;/render/post_process/layers&gt;`
- Render only the Layers of interest.
- Render with all lights set to one simple spot (enter its name in the *Light:* field).
- Render with one material override (enter its name in the Mat: field).

- Disable unnecessary Render Passes, such as Z,
or only render the pass of interest, such as Diffuse.
Shading Panel
- Turn off Shadows.
- Turn off Environment Mapping.
- Turn off Panoramic Rendering.
- Turn off Raytracing.
- Turn off SSS Subsurface Scattering.
- Turn off or lower oversampling/aliasing OSA.
- Turn off or lower Motion Blur.

- Render in Parts. This will also allow you to render **huge** images on a weak PC.
On a multi-core PC, it will assign a thread to each part as well.
- Increase the octree resolution.
- Render at a percentage size of your final resolution (like 25%).
- Turn off *Fields* rendering.
- Use *Border* rendering to render a subset of the full image.
:doc:`Bake Panel &lt;/render/blender_render/bake&gt;`
- Bake Full Render creates a UV Texture that colors the objects based on materials,
and then uses that UV Texture shadeless instead of the material.
- Bake Ambient Occlusion only.
- Bake textures for objects.
- Baking Normals or Displacement does not speed up render time, and are used for other things.
:doc:`Format Panel &lt;/render/output/output&gt;`
- Render at a lower resolution. Smaller pictures take less time to render.
- Choose a faster CODEC or CODEC settings.
- Render in black and white (*BW* button).
- If using ``FFMPEG``, do not activate *Multiplex audio*.
- If using ``FFMPEG``, *Autosplit Output* (*Video* panel button).

- Render only RGB if you just need color; the A channel (*RGBA* button)
takes more memory and is unused when saving a movie file.

Multi-Pass Compositing
======================

Another strategy that can be used to address the problem of long (re-)render times is to
structure your workflow from the ground up so that you make aggressive use of *compositing*,
as described in the "Post-Production" section. In this approach,
you break down each shot into components that can be rendered separately,
then you combine those separately-rendered elements to achieve the finished clip.
For instance:

- If the camera is not moving, then neither is the background: only a single frame is needed.
(The same is true of any non-moving object within the frame.) These individual elements,
having been generated *once,* can be re-used as many times as necessary over as many frames as necessary.
- Both shadows and highlights can be captured separately from the objects that are being illuminated or shadowed,
such that the intensity, color, and depth of the effect can be adjusted later without re-rendering.
- Start by using lights that do not cast shadows (shadow calculations are big time-killers). Then,
use "shadow-only" lights (which cast shadows, but do not cast light)
to create shadows *only* where you judge that they are actually necessary
(it is very often the case that only a few of the shadows which could exist in the scene actually matter,
and that the rest of them simply will not be noticed).
- Tricky lighting situations can be avoided by handling the objects separately,
then combining the individually-rendered clips and "tweaking" the result.

This is a very familiar idea. Modern sound recordings, for example, always use a "multi-track" approach.
Individual components of the song are captured separately and in isolation, then the components are "mixed" together.
The "final mix" then goes through additional processing stages, called *mastering*,
to produce the finished product(s) (in fact, the features and design of modern
sound-processing software are directly comparable to that of Blender's node-based compositor).

There are compelling advantages to this approach:

- If something is "not quite right," you do not necessarily have to start over from scratch.
- In practice, the deadline-killer is *re-* rendering, which ordinarily must be done (in its entirety)
just because "'one little thing' about the shot is wrong." Compositing helps to avoid this, because (ideally...)
only the specific parts that are found to be in error must be repeated (or, maybe,
the error can be blocked out with a "garbage matte" and a corrected version can be inserted in its place).
- Sometimes you might find that it is *almost* what you wanted, but now you would like to *add*
this and maybe *take away* that." A compositing-based approach enables you to do just that, and furthermore,
to do so *non-destructively.* In other words, having generated the "addition" (or the "mask")
as a separate channel of information, you can now fine-tune its influence in the overall "mix",
or even change your mind and remove it altogether, all without permanently altering anything.
- By and large, these stages work *two-* dimensionally, manipulating what is by that time
"a raster bitmap with R, G, B, Alpha and Z-Depth information," so they are consistently fast.
- Since each discrete rendering task has been simplified, the computer can carry them out using much fewer resources.
- The tasks can be distributed among several different computers.
- "After all, the scene does not actually have to be *physically perfect,* to be *convincing*".
A compositing-based approach lets you take full advantage of this. You can focus your attention (and Blender's)
upon those specific aspects of the scene which will actually make a noticeable difference.
It is possible to save a considerable amount of time by consciously choosing to exclude
less-important aspects which (although "technically correct") probably will not be noticed.

Of course, this approach is not without its own set of trade-offs. You must devise a workable
asset-management system for keeping track of exactly what material you have, where it is,
whether it is up-to-date, and exactly how to re-create it. You must understand and use the
"library linking" features of Blender to allow you to refer to objects, nodes, materials,
textures and scenes in a carefully-organized collection of other files.
You need to have a very clear notion, *in advance*,
of exactly what the finished shot must consist of and what the task breakdown must be.
You must be a scrupulous note-taker and record-keeper. But sometimes this is the best way,
if not the *only* way, to accomplish a substantial production.

**************
Render Quality
**************

Many factors go into the quality of the rendered image. Rendering a scene without changing any
of the render settings is probably going to produce a rather unpleasant image.
In previous chapters, you have learned how to model, shade, texture, and light scenes.
Optimizing settings with respect to those areas will help to produce quality images,
but there are some important settings that come into play before pressing the render button.
These can directly affect the look of the rendered image.

The next section covers render layers and render passes,
both of which allow you to compose an image from several elements of a scene.
In some cases it is necessary to render effects straight out of the renderer,
rather than creating them in "post."

Color Management and Exposure
=============================

One important aspect of 3D rendering that is often overlooked is color management.
Without color management, or more commonly, linear rendering,
render engines interpret scene lighting correctly,
but display them incorrectly on your monitor. Blender simplifies this workflow,
but it is important to know how the color space of a rendered image factors into your pipeline.

.. seealso::

:doc:`Color Management and Exposure &lt;/render/post_process/color_management&gt;`.

Anti-Aliasing
=============

Anti-Aliasing removes jagged edges that appear in contrasting areas of color.
This is a very important aspect of render quality. Without this render setting,
images usually appear particularly CG and amateur.

.. seealso::

:doc:`Anti-Aliasing &lt;/render/blender_render/settings/antialiasing&gt;`.

Exposure (Lighting)
===================

Exposure is, in physical terms, the length of time a camera's film or sensor is exposed to light.
Longer exposure times create a brighter image.
In CG, the recorded light values are offset to simulate longer or shorter exposures.
This can be achieved through lighting settings, or better, through
:doc:`Color Management settings &lt;/render/post_process/color_management&gt;`

.. seealso::

:doc:`Exposure (Lighting) &lt;/render/blender_render/world/exposure&gt;`.

Motion Blur
===========

Cameras have a certain shutter speed (the length of time the film is exposed to the lights of the scene).
Things that are in motion while the picture is taken will have some degree of blurring.
Faster-moving objects will appear more blurred than slower objects.
This is an important effect in CG because it is an artifact that we expect to see,
and when it is missing, an image may not be believable.

.. seealso::

:doc:`Motion Blur &lt;/render/blender_render/settings/motion_blur&gt;`.
..    TODO/Review: {{review|copy=X}}.

**************
Edge Rendering
**************

.. figure:: /images/render_blender-render_post-processing_edges_toon-examples.png
:width: 240px

A scene with Toon materials.

Blender's toon shaders can give your rendering a comic-book-like or manga-like appearance,
affecting the shades of colors.
The effect is not perfect since real comics and manga also usually have china ink outlines.
Blender can add this feature as a post-processing operation.

Options
=======

.. figure:: /images/render_blender-render_post-processing-panel.png

Toon edge buttons.

Edge
This makes Blender search for edges in your rendering and add an 'outline' to them.

Before repeating the rendering it is necessary to set some parameters:

Threshold
The threshold of the angle between faces for drawing edges,
from 0 to 255. A value of 10 would just give outline of object against the background,
whereas higher settings start to add outlines on surface edges,
starting with sharper angles. At maximum intensity,
edge will even faintly display geometry subdivided edge lines in areas of imperfect smoothing.
Color RGB
The color of the rendered edges.

Examples
========

.. figure:: /images/render_blender-render_post-processing_edges_toon-examples-edge.png
:width: 400px

Scene re-rendered with toon edge set.

It is possible to separate out the edge layer using a render layer dedicated to that purpose.
The alpha channel is 0 where there is no edge, and 1 where the edge is.
By separating out the edge layer, you can blur it, change its color, mask it, etc.
The image above shows how to do this.
In this example, an Edge render layer is created that only has the Sky and Edge layers
The other render layer omits the Edge layer, so it returns just the normal image.
On the output panel *Edge* is enabled with a width of 10 in black.
Then that layer goes through a blur node. Using the Alpha Over node,
then the cube is composited on top of the blurred edge.
The result gives a soft-shadow kind of effect.
Note that Premultiply is set, because the Edge image already has an alpha of 1.0 set.

******
Fields
******

.. figure:: /images/render_blender-render_post-progressing_fields.png

Field Rendering result.

The TV standards prescribe that there should be 25 frames per second (PAL)
or 30 frames per second (NTSC).
Since the phosphors of the screen do not maintain luminosity for very long,
this could produce a noticeable flickering.

To minimize this, a TV does not represent frames as a computer does ('progressive' mode),
but rather represents half-frames, or *fields* at a double refresh rate,
hence 50 half frames per second on PAL and 60 half frames per second on NTSC.
This was originally bound to the frequency of power lines in Europe (50Hz) and the US (60Hz).

In particular, fields are "interlaced" in the sense that one field presents all the even lines
of the complete frame and the subsequent field the odd ones.

Since there is a non-negligible time difference between each field (1/50 or 1/60 of a second)
merely rendering a frame the usual way and splitting it into two half frames does not work.
A noticeable jitter of the edges of moving objects would be present.

Options
=======

Fields
------

Enable field rendering. When the *Fields* button in the *Render* Panel is pressed
(*Post Processing* section), Blender prepares each frame in two passes.
On the first it renders only the even lines,
then it advances in time by half a time step and renders all the odd lines.
This produces odd results on a PC screen (Field Rendering result). but will show correctly on a TV set.

Upper First / Lower First
Toggles between rendering the even and odd frames first.
Still
Disables the half-frame time step between fields (*x*).

.. note:: Setting up the correct field order

Blender's default setting is to produce Even fields *before*
Odd fields; this complies with European PAL standards. Odd fields are scanned
first on NTSC.

Of course, if you make the wrong selection things are even worse than if no Field rendering at
all was used!

If you are really confused, a simple trick to determine the correct field order is to render a
short test animation of a white square moving from left to right on a black background.
Prepare one version with odd field order and another with even field order,
and look at them on a television screen.
The one with the right field order will look smooth and the other one horrible.
Doing this simple test will save you *hours* of wasted rendering time...

.. note:: Fields and Composite Nodes

Nodes are currently not field-aware. This is partly due to the fact that in fields,
too much information is missing to do good neighborhood operations (blur, vector blur etc.).
The solution is to render your animation at double the frame rate without fields and do the
interlacing of the footage afterwards.

##################
Post Processing
##################

.. toctree::
:maxdepth: 2

edges.rst
fields.rst

*************
Anti-Aliasing
*************

A computer generated image is made up of pixels;
each pixel can of course only be a single color. In the rendering process the rendering engine
must therefore assign a single color to each pixel on the basis of what object is shown in
that pixel. This often leads to poor results, especially at sharp boundaries,
or where thin lines are present, and it is particularly evident for oblique lines.

To overcome this problem, which is known as *Aliasing*,
it is possible to resort to an Anti-Aliasing technique. Basically,
each pixel is 'oversampled', by rendering it as if it were five pixels or more,
and assigning an 'average' color to the rendered pixel.

The buttons to control Anti-Aliasing, or Over Sampling (OSA),
are below the rendering button in the *Render* Panel (*Render Panel.*).

Options
=======

Anti-Aliasing (check box)
Enables oversampling.

Samples
The number of samples per pixel. Higher value produces better edges, but slows down the rendering.

5, 8, 11, 16

By default, we use in Blender a fixed "Distributed Jitter" table. The samples within a pixel
are distributed and jittered in a way that guarantees two characteristics:

- Each sample has equal distances to its neighbor samples.
- The samples cover all sub-pixel positions equally, both horizontally and vertically.

The images below show Blender sample patterns for 5, 8, 11 and 16 samples.
To show that the distribution is equalized over multiple pixels, the neighbor pixel patterns were drawn as well.
Note that each pixel has an identical pattern.

.. list-table::

* - .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-pattern-5.jpg

5 samples.

- .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-pattern-8.jpg

8 samples.

- .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-pattern-11.jpg

11 samples.

- .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-pattern-16.jpg

16 samples.

Full Sample
For every anti-aliasing sample, save the entire Render Layer results.
This solves anti-aliasing issues with compositing.

Filtering
=========

When the samples have been rendered,
we've got color and alpha information available per sample.
It then is important to define how much each sample contributes to a pixel.

The simplest method is to average all samples and make that the pixel color.
This is called using a "Box Filter". The disadvantage of this method is that it does not take
into account that some samples are very close to the edge of a pixel,
and therefore could influence the color of the neighbor pixel(s) as well.

Filter menu: Set The filter type to use to 'average' the samples:

Box
A low-quality box-shaped curve.

.. note::

This filter is relatively low quality.
You can see that only the samples within the pixel itself are added to the pixel's color.
For the other filters,
the formula ensures that a certain amount of the sample color gets distributed over the other pixels as well.
Tent
A simplistic filter that gives sharp results.
Quadratic
A Quadratic curve.
Cubic
A Cubic curve.
Gauss
Gaussian distribution, the most blurry.
Catmull-Rom
Catmull-Rom filter, gives the most sharpening.
Mitchell-Netravali
A good all-around filter that gives reasonable sharpness.

.. list-table::

* - .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-graph-box.jpg

Box.

- .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-graph-tent.jpg

Tent.

- .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-graph-quadratic.jpg

Quadratic.

- .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-graph-cubic.jpg

Cubic.

* - .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-graph-gaussian.jpg

Gaussian.

- .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-graph-catmullrom.jpg

Catmull-Rom.

- .. figure:: /images/render_blender-render_settings_antialiasing_oversampling-graph-mitchell-netravali.jpg

Mitchell-Netravali.

- ..

Filter Size
===========

Making the filter size value smaller will squeeze the samples more into the center,
and blur the image more. A larger filter size makes the result sharper.
Notice that the last two filters also have a negative part;
this will give an extra sharpening result.

Examples
========

.. list-table::

* - .. figure:: /images/render_blender-render_settings_antialiasing_02.png

Todo.

- .. figure:: /images/render_blender-render_settings_antialiasing_osa8_box.jpg

AA 8, Box filter.

* - .. figure:: /images/render_blender-render_settings_antialiasing_osa8_tent.jpg

AA 8, Tent filter.

- .. figure:: /images/render_blender-render_settings_antialiasing_osa8_quad.jpg

AA 8, Quadratic filter.

* - .. figure:: /images/render_blender-render_settings_antialiasing_osa8_cubic.jpg

AA 8, Cubic filter.

- .. figure:: /images/render_blender-render_settings_antialiasing_osa8_gauss.jpg

AA 8, Gaussian filter.

* - .. figure:: /images/render_blender-render_settings_antialiasing_osa8_catrom.jpg

AA 8, Catmull-Rom filter.

- .. figure:: /images/render_blender-render_settings_antialiasing_osa8_mitch.jpg

AA 8, Mitchell-Netravali filter.

###################
Render Settings
###################

.. toctree::
:maxdepth: 2

layers.rst
passes.rst
shading.rst
motion_blur.rst
antialiasing.rst

*************
Render Layers
*************

This section covers only the Render Layer settings appropriate for the Blender Render engine.
For the engine-independent settings, see :doc:`this section &lt;/render/post_process/layers&gt;`.

Light Override
Enter the name of a light group, and the scene will be lit with only those lights.

Examples of where this might be used:

- Using multiple Render Layers with different light group overrides
adds the possibility to tweak light intensity and color
in the compositor, i.e. to avoid re-renders.
- Speed up a draft render by using only a few lights instead of all of them.

Include Options
===============

Each render layer has its own set of features which can be enabled/disabled for the whole layer.
This could be used to save render time and gives control over the passes:

Zmask
Actives masking with the selected Mask Layers. Only render what is in *front* of the solid Z values.

Negate
Only render what is *behind* the solid Z values.
All Z
Z-values are computed for everything in view, not just those things that are rendered. When disabled,
objects not included in the render have no ("infinite") z value.
Solid
Solid faces are rendered. All normal meshes are solid faced.
Halo
Halo materials are rendered.
ZTransp
Transparency may be Z-based or Ray-traced. If Z-based,
enabling *Ztransp* renders transparent areas with the z-value of what is behind the transparent area.
Sky
Turning on Sky renders the sky, as defined in your material world settings. Otherwise,
a black alpha transparent background is rendered.
Edge
If Edge is enable in the Post Processing panel, objects in this Render Layer are given an outline edge.
Turning on Edge pulls in the Edge settings from the Render tab, and adds an outline to the objects.
Edges also have to be enabled on the Render tab.
Strand
Strands are strings of static particles that are colored as part of the material settings;
they look like strands of hair or grass.
Freestyle
Render the Freestyle strokes on this layer.

***********
Motion Blur
***********

Blender's animations are by default rendered as a sequence of *perfectly still* images.
While great for stop-motion and time-lapses, this is unrealistic, since fast-moving
objects do appear to be blurred in the direction of motion,
both in a movie frame and in a photograph from a real-world camera.

Blender has two ways to achieve motion blur:

Sampled Motion Blur
===================

Blender can be made to render the current frame and some more 'virtual' frames in between it and the next frame,
then merge them all together to obtain an image where moving objects are 'blurred'.

This method is slow, but produces good results.
It can be activated in the *Sampled Motion Blur* panel of the render settings.
This kind of motion blur is done during the render.

Motion Samples
Set the number of samples to take for each frame.
The higher the samples, the smoother the blur effect,
but the longer the render, as each virtual intermediate frame has to be rendered.
Shutter
Time (in frames) the shutter is open.
If you are rendering at 24 fps, and the Shutter is set to 0.5,
the time in between frames is 41.67 ms, so the
shutter is open for half that, 20.83 ms.

.. note::

Samples are taken only from the *next* frame, not the previous one.
Therefore the blurred object will appear to be slightly ahead of how it would look without motion blur.

Vector Blur
===========

:doc:`Vector Blur &lt;/compositing/types/filter/vector_blur&gt;`
is faster but sometimes has unwanted side-effects which are sometimes difficult to avoid.

Vector blur is a process done in compositing (post-render time), by rendering the
scene without any blur, plus a pass that has movement information for each pixel.
This information is a vector map which describes a 2D or 3D direction and magnitude.
The compositor uses that data to blur each pixel in the given direction.

Examples
========

To better grasp the concept, let us assume that we have a cube 2 units wide,
uniformly moving 1 unit to the right at each frame.
The scale beneath the cube helps in appreciating the movement of 1 Blender unit.

.. list-table::

* - .. figure:: /images/render_blender-render_motion-blur_02.png
:width: 320px

Frame 1 of the moving cube without Motion Blur.

- .. figure:: /images/render_blender-render_motion-blur_03.png
:width: 320px

Frame 2 of the moving cube without Motion Blur.

.. figure:: /images/render_blender-render_motion-blur_04.png
:width: 320px

Frame 1 when Sampled Motion Blur is enabled and eight 'intermediate' frames are computed.
Shutter is set to 0.5 , thus the image eight samples are rendered between frame 1 and halfway to frame 2.

.. list-table::

* - .. figure:: /images/render_blender-render_motion-blur_05.png
:width: 320px

The effect of an increased shutter value.

- .. figure:: /images/render_blender-render_motion-blur_06.png
:width: 320px

Even further increased shutter value.

Values greater than 1 are physically impossible in a real-world camera, but can be used to exaggerate the effect.
Better results than those shown can be obtained by using higher samples than 8,
but, of course, since as many *separate* renders as samples are needed,
a Motion Blur render takes that many times more time than a non-Motion Blur one.

Hints
=====

Sampled Motion Blur can be used as an additional form of
:doc:`Anti-Aliasing &lt;/render/blender_render/settings/antialiasing&gt;`,
since aliasing artifacts are computed differently for each sample and averaged together at the end.
..    TODO/Review: {{review|copy=X}}.

*************
Render Passes
*************

Render Passes are necessary because of the different things the Blender Render Engine must
calculate to give you the final image.
In each 'pass' the engine calculates different interactions between objects.

Render Passes In Detail
=======================

Everything you see in a render must be calculated for the final image.
All interactions between objects in your scene, lighting, cameras, background images,
world settings, etc.,
must all be separately calculated in different passes for different reasons,
such as calculating shadows.

In a render, every pixel has been calculated several times to make sure it will show the right
color for the right part of the image.
Various things that are calculated in a standard render include:

- Where are shadows cast?
- How is ambient light in the environment blocked (occluded) by objects in the scene?
- How is light reflected off mirrored surfaces?
Like shadows, lines are calculated, except this time they come from the camera and bounce off mirrored surfaces,
so that when these lines hit an object, the engine calculates that this is what the camera should see.
- How is light bent (refracted) as is passes through transparent objects?
Does it go straight through? Does it bend? If so, at what depth in the object?
- What designated objects are in the scene, and what is their outline?
Should the object appear blurred, or should it appear in sharp focus?
- How fast is something moving (velocity)?
Should it appear blurred given our frame rate or is it slow enough to still be focused on properly?
- How far away from the camera are objects' surfaces (Z-depth)?
Can the object's surfaces be seen at all, or are they being blocked by another object's geometry?
- Does an object have a normal vector (bumpmap)?
Do shadows and apparent geometry need to be calculated for any objects?
- Is there any specularity ? Are objects with textures such as metal shiny at all?

The answer to each of the above questions is an image or map, as shown below:

.. figure:: /images/render_blender-render_settings_passes_example.jpg
:width: 600px

Each Render Pass puts out an image or a map. For the purposes of this example,
a Render Layer was defined to produce all possible outputs. When a Render Layer input-node
was added to the node diagram and the Render Layer input-node was subsequently associated with
the Render Layer, all of the layer's outputs appeared as connection points on the right-hand
(output) side of the node.

Render Passes that produce Images can be directly viewed in a viewer, or,
if they are the only pass that is rendered, saved as the render image. If the pass is enabled,
it can be saved in a multilayer OpenEXR format.

If the Render Pass output is not an image but is a map,
it needs to be translated into something that we can see. For example, the Z-depth map is an
array of values that specifies how far away from the camera each pixel is;
values range between +/-3,000,000 Blender Units or so. The intermediate node you see above,
between the Render Layer output socket and the Viewer node input socket (such as Map Value)
does this translation or scaling. You must use that specific kind of translation node to get
good results if you intend on operating on that map as an image. You must then,
after making any adjustments,
run the map back through that node to re-scale it back to the original before saving.

Selecting Render Passes
=======================

.. figure:: /images/render_blender-render_settings_renderlayer-panel.png

Render Passes are the various distinct outputs that the renderer is able to generate.
All of the following render outputs are normally combined into a single output known,
appropriately enough, as the *Combined* output.
But you can also select any of them to be output as a separate pass. (If you do so, in most
cases you can choose whether to *also* continue to include it in the Combined output.)

Some of these outputs must be enabled and used within your scene
(and not just selected in the Render Layer panel) in order to show anything.
For example, if you do not have any lights in your scene,
or those lights have been set to not cast shadows,
or objects in the limelight do not have materials which have been set to receive shadows,
the *Shadow* pass will be blank; there is simply nothing to show you.
If you have not enabled *Ambient Occlusion* in your World environment settings,
the *AO* pass will be blank, even if you select it here.

To save time and drive space, you have to tell Blender each of the passes to render in the Render Layers panel
(which we first introduced on :doc:`the previous page &lt;/render/post_process/layers&gt;`):

Combined
This renders everything in the image, even if it is not necessary.
("The whole enchilada," so to speak.) This is all the options below,
blended into a single output, *except* those options which you have indicated should be omitted from this pass,
as indicated with the camera button.
Z
The Z-depth map; how far away each pixel is from the camera. Used for Depth-Of-Field (DOF).
The depth map is inverse linear *(1/distance)* from the camera clip start.
Vector
The direction and speed things are moving. Used with Vector Blur.
Normal
Calculates lighting and apparent geometry for a bumpmap (an image which is used to fake detail on an object)
or for changing the apparent direction of light falling on an object.
UV
Allows texturing after rendering. See UV node.
Mist
Deliver Mist factor pass.
Object Index
Masks selected objects. See :doc:`/compositing/types/converter/id_mask`.
Color
The color of materials without shading.
Diffuse
The diffuse shading of materials.
Specular
Specular highlights.
Shadow
Shadows cast. Make sure shadows are cast by your lights (positive or negative), and received by materials.
To use this pass, mix multiply it with the Diffuse pass.
Emit
Emission pass.
AO
Ambient Occlusion. Make sure it is turned on in your environment and that Ray Tracing is enabled.
Environment
Environment lighting.
Indirect
Indirect lighting pass.
Reflection
Reflection off mirrors and other reflective surfaces (highly waxed white floors, for example).
Mix Add this pass to Diffuse to use it.
Refraction
Refraction of colors through transparent meshes. Mix Add this pass to the Diffuse pass to use it.

When you enable a pass, the appropriate socket on the Render Layers node shows up like magic,
and can be used as shown in the example above.

Excluding Render Passes
=======================

As we said, the *Combined* output is an amalgam of several outputs which are *also*
available separately. When you select one of these outputs,
they will be provided separately *and also* included in the Combined pass.

When you enable the Camera icon that is beside several of the pass options,
the particular pass will be excluded from the combined pass.
They will be made available separately *but not* included in the combined pass.

Using Render Passes
===================

The primary purpose of Render Passes is to enable you to process the various outputs in
different ways, by constructing networks of render nodes.
You can achieve many special effects,
and economize considerably on the render times of complicated scenes,
by creative and effective use of this facility.
We'll show you a few examples of this in just a moment.

Quite a bit of information about the typical uses for some of the passes is discussed
elsewhere:

- Image: Since this is the main product, all of Blender uses it.
- Alpha: See the *Alpha Over* node and all of the *Matte* nodes.
- Z: See the *Defocus* node.
- Vector: See the *Vector Blur* node.
- Normal: See the *Normal* node.

Recoloring Shadows
------------------

.. figure:: /images/render_blender-render_settings_passes_example2.png
:width: 600px

Let us run the Shadow buffer through a colorization node setup, then recombine it;
all your shadows will be artificially colored.
Lots of threads in this node setup are shown to the right, so let us walk through it.
On the left is the Render Layer input node:
it refers to one of the Render Layers that we have defined for our scene. In the scene,
we have a reflective ball on a pedestal standing in front of a backdrop. Everything
(except the ball) is gray. We use a standard four-light rig: backfill placed high,
two sidefills at ground level, and a key light above and to the left of camera. Suzanne,
a monkey-shaped geometry, is standing in front of the key light,
so her shadow is cast into the scene on the floor.
The ball casts shadows onto the backdrop and floor.

The output channels of the Render Layer node are determined by which buttons we selected when
defining our Render Layer.
The top two viewers show you the image output using the Shadow as the Alpha channel,
and the node next to it just the Shadow channel. Where the Shadow is dark,
the image in the left viewer is transparent.
We have used the Shadow to cut out parts of the image.

We then take the shadow through an RGB Curve, which is set to magnify just the Blue by 75%;
so a gray shadow of RGB(40, 40, 40) becomes RGB(40, 40, 40×1.75=70).
That blue-tinged shadow is shown in the bottom viewer. Now we have two options:
Alpha Over and Mix. For either option:

- Use the Shadow map as a Factor.
- Feed the Blue Shadow to the Top Socket.
- Feed the core or base image to the Bottom Socket.

The resulting image is the same in either case; a blue shadow.
Note that Suzanne's reflection is not blue; there is a different Render Pass for that.

You could just as easily swap in another image entirely; for example,
the shadow map from another render layer.
You can even take an image from another project entirely and use that instead
(using the Image Input node), to get a different effect. (For example,
an effect similar to a *Star Wars Episode One* movie poster,
where Anakin Skywalker already casts the shadow of Darth Vader.)

Compositing Ambient Occlusion
-----------------------------

.. figure:: /images/render_blender-render_settings_passes_ao.png
:width: 600px

AO is a geometry-based dirt shader, making corners darker.
It is separately enabled in the World settings and computed as a separate pass. When enabled,
it has one of three Modes: *Add*, *Subtract* , *Both* and a variable *Energy* level
(which changes the intensity of the shading).
The third variable is the amount of Ambient light that the material receives.
If it does not receive any, then ambient occlusion does not affect it.
Based on these variables, Blender computes an AO pass.
If you call it out as a separate pass and wish to composite it back into your image,
you will need to enable the Color and Diffuse pass as well.

To configure your setup, consider the example image above.

#. First, depending on the AO mode do one of the following: If AO mode is Add: directly use the AO pass.
If AO mode is Sub: Calculate AO - 1, or if AO mode is Both: Calculate 2 × AO - 1.
#. Multiply the output of Step 1 with the AO energy level.
#. Multiply the output of Step 2 with the material's ambience value.
If you have materials which receive different ambience light levels (0.5 is the default),
one would have to create an ambience map based on Object ID.
#. Multiply the output of Step 3 with the color pass.
#. Add the output of Step 4 to the diffuse pass.

If shadows, colored ambient light, specularity, reflections, and/or refractions are involved
they have to be added to the diffuse pass before adding the converted AO pass.

Vector Blurring Shadows
-----------------------

.. figure:: /images/render_blender-render_settings_passes_vector-blurring-shadows.png
:width: 600px

When using Vector Blur instead of Motion Blur, objects in motion are blurred,
but objects at rest (with respect to the camera) are not blurred.
The crossover is the shadow of the object in motion. Above,
we have a cube in motion across a ground plane.
If we just ran the combined pass through Vector Blur,
you can see the result in the lower right-hand corner; the box is blurred,
but its shadow is sharply in focus, and thus the image does not look realistic.

Therefore, we need to separate out the diffuse and shadow passes from the floor by creating a
"Floor" render layer. That render layer has Diffuse and Shadow passes enabled,
and only renders the floor object (layer 2). Another render layer ("Cube")
renders the Z and Vector passes, and only renders the cube (on layer 1). Using the Blur node,
we blur the shadow pass, and then combine the diffuse and blurred shadow by multiplying them
together in a Mix Multiply node; we then have a blurred shadow on a crisp ground plane.
We can then mix the vector-blurred object to provide a realistic-looking image.

Conclusion
==========

Render Passes can be manipulated to give you almost complete control over your final image.
Causing objects to cast shadows that are not really their shadows,
making objects appear out of focus or sharply in focus like a real camera, manipulating colors
just for final post-processing or just reconfiguring your render passes to save render time,
are all things which you might wish to manipulate the render engine for.

*******
Shading
*******

Globally de/activates engine features in :menuselection:`Render --&gt; Shading` panel...

Texture
All :doc:`/render/blender_render/textures/properties/influence/index`
e.g. color, but also normal and displacement maps.
Shadows
All :doc:`/render/blender_render/lighting/shadows/index` calculation.
Subsurface Scattering
All :doc:`/render/blender_render/materials/properties/subsurface_scattering`.
Environment Map
The :ref:`world texture &lt;bi-world-texture&gt;`.
Ray Tracing
The :doc:`shadow tracing &lt;/render/blender_render/lighting/shadows/raytraced_properties&gt;`.
Alpha
Switches between a world background to be the sky or transparent.

Sky, Transparency
World Space Shading
Shading can optionally be computed in world space rather than camera space.
This affects e.g. normal and lamp vectors. This is often more convenient and matches other engines behavior.

*******************
Assigning a Texture
*******************

This page just shows how to add a texture to a slot.
The :doc:`/render/blender_render/textures/texture_panel` is explained on the previous page.

.. figure:: /images/render_blender-render_textures_texture-panel.png

Texture panel.

Creating a new Texture Data-Block in a new Texture Slot
=======================================================

Select an empty slot, then click on the *New* button.

This will do two things:

- It will create a new texture data-block.
- Also, it will add a new slot in the textures stack.

Creating a new Texture Data-Block in a non-empty slot
=====================================================

Select a non-empty slot, then click on the *Plus* button.

This will do two things:

- It will create a new texture data-block, with a new name, by
making a copy of the texture data-block assigned to the selected slot.
- It will assign this new data-block to the selected slot.

Sharing a Texture Data-Block in a non-empty slot
================================================

- Select a non-empty slot, then click on the *Browse* button.
This will open a menu showing all the available Texture data-blocks in this file.
- Choose a texture data-block in the menu to assign it to the selected slot.
This will share the chosen texture with more than one object,
hence the *Number of users* shown in the texture data-block will increase by one.
.. _textures-index:

###########
Textures
###########

.. toctree::
:titlesonly:
:maxdepth: 2

introduction.rst
texture_panel.rst
assigning_a_texture.rst
properties/index.rst
types/index.rst
nodes/index.rst
..    TODO/Review: {{review|text=Empty introductory sections: World Textures, Brush Textures}}.

************
Introduction
************

In CGI, texture mapping is a method to add detail to surfaces by projecting images and
patterns onto those surfaces.
The projected images and patterns can be set to affect not only color, but also specularity,
reflection, transparency, and even fake 3-dimensional depth. Most often,
the images and patterns are projected during render time,
but texture mapping is also used to sculpt, paint and deform objects.

.. seealso::

Texture processing for :doc:`Combined Textures &lt;/render/blender_render/textures/nodes/introduction&gt;`
in the Compositor.

Material Textures
=================

The material settings that we've seen so far produce smooth, *uniform* objects,
but such objects are not particularly true to reality,
where uniformity tends to be uncommon and out of place.
In order to deal with this unrealistic uniformity,
Blender allows the user to apply *textures* which can modify the reflectivity, specularity,
roughness and other surface qualities of a material.

.. figure:: /images/render_blender-render_textures_introduction_layers.jpg
:width: 320px

Textures Layer on base Material.

Textures are like additional layers on top of the base material.
Textures affect one or more aspects of the object's net coloring.
The net color you see is a sort of layering of effects, as shown in this example image.
The layers, if you will, are:

- Your object, lit with *ambient* light based on your world settings.
- Your base *material*, which colors the whole surface in a uniform color that reacts to light,
giving different shades of the diffuse, specular,
and mirror colors based on the way light passes through and into the surface of the object.
- A *primary texture* layer that overlays a purple marble coloring.
- A *second cloud texture* that makes the surface transparent
in a misty/foggy sort of way by affecting the Alpha value.
- These two textures are *mixed* with the base material to provide the net effect: a cube of purplish-brown fog.

.. figure:: /images/render_blender-render_textures_introduction_somemetal.jpg
:width: 320px

Some Metal Textures.

This notion of using *more than one* texture, to achieve a combined effect,
is one of the "hidden secrets" of creating realistic-looking objects.
If you carefully "look at the light" while examining any real-life object,
you will observe that the final appearance of that object is best described as the combination,
in different ways and in different amounts, of several distinct underlying visual characteristics.
These characteristics might be more (or less) strongly apparent at different angles,
under different lighting conditions, and so forth.
Blender allows you to achieve this in many ways.

You can use "a stack of texture layers" as described
in :doc:`this section &lt;/render/blender_render/textures/texture_panel&gt;`,
or you can also use arbitrarily-complex networks of "texture nodes"
as discussed :doc:`here &lt;/render/blender_render/textures/nodes/introduction&gt;`.

################
Texture Nodes
################

.. toctree::
:maxdepth: 2

introduction.rst

Node Types
==========

.. toctree::
:maxdepth: 1

types/color/index.rst
types/converter/index.rst
types/distort/index.rst
types/input/index.rst
types/output/index.rst
types/patterns/index.rst
types/textures/index.rst
.. |texture-button| image:: /images/icons_texture.png
:width: 1.1em

************
Introduction
************

As an alternative to using the :doc:`Texture Stack &lt;/render/blender_render/textures/texture_panel&gt;`,
Blender includes a node-based texture generation system, which enables textures creation by combining colors,
patterns and other textures in the same way as shader writing with
:doc:`Material Nodes &lt;/render/blender_render/materials/nodes/index&gt;`.

.. figure:: /images/render_blender-render_textures_nodes_introduction_types-combined.jpg
:width: 300px

Combined textures based on nodes.

These textures can be used in the same places as regular textures:
They can be placed in texture channels, in material nodes, in particle systems,
and even inside other textures.

.. note::

Node-based textures do **not** work for realtime display, they will only be visible in rendered images.

Using Texture Nodes
===================

To use texture nodes with the current texture, open the :doc:`Node Editor &lt;/editors/node_editor/index&gt;`
and set it to *Texture* mode by clicking the "Texture" icon (|texture-button|) in its header.

To start adding nodes, a material has to be to selected.
A new texture can be created by either clicking the *New* button in the Node editor,
or the *New* button in the texture panel. Once a texture is selected, it can be
toggled to a function as a regular texture or a node texture by clicking the *Use Nodes* option in the Node Editor.

The default node setup will appear: a red-and-white checkerboard node connected to an
*Output* named "Default". For *texture* nodes, multiple Outputs
can exist in the node setup. Compare to other types of node contexts, which are limited to one active Output node.
See the next section for details.

For instructions on how to add, remove and manipulate the nodes in the tree,
see the :doc:`Node Editor &lt;/editors/node_editor/index&gt;` reference.

Using Multiple Outputs
======================

Each texture defined with Texture Nodes can have several outputs,
which can then be used for different things. For example,
a texture that defines both a diffuse (color) map and a normal map.
This can be done by:

- Create two texture slots in the texture list, and set them to the same texture data-block.
- Add two *Output* nodes to the node tree,
and type new names into their *Name* text-boxes: e.g. "Diffuse" for one and "Normal" for the other.
- Underneath the texture list view in the texture panel, a selector with the names of the outputs are shown.
For each entry in the texture list, select the desired output by changing the menu entry
e.g. set on to *Diffuse* and the other to *Normal*).

These named outputs could be used, when the material is defined with Material Nodes.
In this case, Texture Channels are probably not used. Instead, insert the
*Texture* nodes into the Material Node tree by using :menuselection:`Add --&gt; Input --&gt; Texture`.
Inside the just added texture node the output to use can then be selected (e.g. *Diffuse* or *Normal*).
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/converter/combine_separate.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/hue_saturation.rst

###############
Color Nodes
###############

.. toctree::
:maxdepth: 1

invert.rst
mix_rgb.rst
rgb_curves.rst
hue_saturation.rst
combine_separate.rst

.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/invert.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/mix.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/color/rgb_curves.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/converter/color_ramp.rst

*************
Distance Node
*************

.. figure:: /images/render_blender-render_textures_nodes_converter_distance.png
:align: right

Distance node.

Computes the distance between two 3D coordinates.

Inputs
======

Coordinate 1
First coordinate point.
Coordinate 2
Second coordinate point.

Properties
==========

This node has no properties.

Outputs
=======

Value
Calculated distance.

###################
Converter Nodes
###################

.. toctree::
:maxdepth: 1

color_ramp.rst
distance.rst
math.rst
rgb_to_bw.rst
value_to_normal.rst

.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/converter/math.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/converter/rgb_to_bw.rst

********************
Value to Normal Node
********************

.. figure:: /images/render_blender-render_textures_nodes_converter_value-to-normal.png
:align: right

Value to Normal node.

Computes a normal map.

Inputs
======

Val
The height map to compute the normal map from.
Nabla
Size of derivative offset used for calculating normals.

Properties
==========

This node has no properties.

Outputs
=======

Normal
Standard normal output.

*******
At Node
*******

.. figure:: /images/render_blender-render_textures_nodes_distort_at.png
:align: right

At node.

Returns the color of a texture at the specified coordinates.

Inputs
======

Texture
Standard image input.
Coordinates
The point at which to sample the color. For images, the space is between -1 and 1 for X and Y.
If the coordinates are not spatially varying, the node will return a single color.

Properties
==========

This node has no properties.

Outputs
=======

Texture
Standard image output.

#################
Distort Nodes
#################

These nodes allow you to change the mapping of a texture.

.. toctree::
:maxdepth: 1

at.rst
rotate.rst
scale.rst
translate.rst

***********
Rotate Node
***********

.. figure:: /images/render_blender-render_textures_nodes_distort_rotate.png
:align: right

Rotate node.

Rotate the texture coordinates of an image or texture.

Inputs
======

Color
Standard image input.
Turns
The number of times to rotate the coordinates 360 degrees about the specified axis.
Axis
The axis to rotate the mapping about.

Properties
==========

This node has no properties.

Outputs
=======

Color
Standard image output.

**********
Scale Node
**********

.. figure:: /images/render_blender-render_textures_nodes_distort_scale.png
:align: right

Scale node.

Scale the texture coordinates of an image or texture.

Inputs
======

Color
Standard image input.
Scale
The amount to scale the coordinates in each of the three axes.

Properties
==========

This node has no properties.

Outputs
=======

Color
Standard image output.

**************
Translate Node
**************

.. figure:: /images/render_blender-render_textures_nodes_distort_translate.png
:align: right

Translate node.

Translate the texture coordinates of an image or texture.

Inputs
======

Color
Standard image input.
Offset
The amount to offset the coordinates in each of the three axes.

Properties
==========

This node has no properties.

Outputs
=======

Color
Standard image output.

****************
Coordinates Node
****************

.. figure:: /images/render_blender-render_textures_nodes_input_coordinates.png
:align: right

Coordinates node.

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

Coordinates
The Coordinates node outputs the geometry local coordinates,
relative to its bounding box as RGB colors:

- Red channel corresponds to X value.
- Green channel corresponds to Y value.
- Green channel corresponds to Z value.

**********
Image Node
**********

.. figure:: /images/render_blender-render_textures_nodes_input_image.png
:align: right

Image node.

The image node can be used to load an external image.

Inputs
======

This node has no inputs.

Properties
==========

Image
See :ref:`ui-data-block`.

Outputs
=======

Color
Standard color output.

###############
Input Nodes
###############

Input nodes provide input data for other nodes.

.. toctree::
:maxdepth: 1

coordinates.rst
image.rst
texture.rst
time.rst

************
Texture Node
************

.. figure:: /images/render_blender-render_textures_nodes_input_texture.png
:align: right

Texture node.

The texture node can be used to load another node based or non-node based texture.

Inputs
======

These two colors can be used to remap a grayscale texture.

Color 1
White Level.
Color 2
Black Level.

Properties
==========

Texture
The texture could be selected from a list of textures available in the current blend-file or link in textures.
The textures themselves could not be edited in this note, but in the Texture panel.

Outputs
=======

Color
Standard color output.

.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../../compositing/types/input/time.rst

################
Output Nodes
################

These nodes serve as an outputs for node textures.

.. toctree::
:maxdepth: 1

output.rst
viewer.rst

***********
Output Node
***********

.. figure:: /images/render_blender-render_textures_nodes_output_output.png
:align: right

Output node.

This node contains the result of the node texture.

Multiple output nodes can exist in a node texture, however, only one of them is active.
The active one is set in the Texture Panel in the *Output* selector.

Inputs
======

Color
The color data that the texture renders.
Normal
The normal map that the texture will output.

Properties
==========

File path
Output ID.

Outputs
=======

This node has no outputs.

***********
Viewer Node
***********

.. figure:: /images/render_blender-render_textures_nodes_output_viewer.png
:align: right

Viewer node.

The viewer node can be used to preview the results of a node.

Inputs
======

Color
Standard image input.

Properties
==========

This node has no inputs.

Outputs
=======

This node has no outputs.

***********
Bricks Node
***********

.. figure:: /images/render_blender-render_textures_nodes_patterns_bricks.png
:align: right

Bricks node.

The Bricks node creates a brick like pattern.

Inputs
======

Bricks 1, Bricks 2
Sets the color range of the bricks. Brick colors are chosen randomly between these two colors.
Mortar
Sets the mortar color, in between the bricks.
Thickness
Sets the thickness of the mortar.
Bias
The bias of randomly chosen colors,
between (-1 to 1). -1 Makes all bricks Color 1, and a value of 1 makes them all Color 2.
Brick Width
Sets the horizontal size of all the bricks.
Row Height
Sets the vertical size of all the bricks.

Properties
==========

Offset
The relative offset of the next row of bricks.
Frequency
Offset every N rows. The brick pattern offset repeats every N rows.
Squash
Scales the bricks in every N rows by this amount.
Frequency
Squash every N rows.

Outputs
=======

Color
Standard color output.

************
Checker Node
************

.. figure:: /images/render_blender-render_textures_nodes_patterns_checker.png
:align: right

Checker node.

The checker node creates a checkerboard pattern.

Inputs
======

color 1, color 2
Image inputs setting the color of the squares.
Size
The scale of the checker pattern.

Properties
==========

This node has no properties.

Outputs
=======

Color
Standard image output.

##################
Pattern Nodes
##################

.. toctree::
:maxdepth: 1

checker.rst
bricks.rst

**********
Blend Node
**********

.. figure:: /images/render_blender-render_textures_nodes_textures_blend.png

Blend node.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/blend&gt;`

***********
Clouds Node
***********

.. figure:: /images/render_blender-render_textures_nodes_textures_clouds.png

Clouds node.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/clouds&gt;`

********************
Distorted Noise Node
********************

.. figure:: /images/render_blender-render_textures_nodes_textures_distorted-noise.png

Distorted Noise node.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/distorted_noise&gt;`

#################
Texture Nodes
#################

These nodes generate procedural textures,
and function just like their non node based counterparts.

.. rubric:: Common Options

Color 1/Color 2
Remaps the procedural texture with these colors. These do not function in the Magic node.

.. toctree::
:maxdepth: 1

blend.rst
clouds.rst
distorted_noise.rst
magic.rst
marble.rst
musgrave.rst
noise.rst
stucci.rst
voronoi.rst
wood.rst

**********
Magic Node
**********

.. figure:: /images/render_blender-render_textures_nodes_textures_magic.png

Magic node.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/magic&gt;`

***********
Marble Node
***********

.. figure:: /images/render_blender-render_textures_nodes_textures_marble.png

Marble node.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/marble&gt;`

*************
Musgrave Node
*************

.. figure:: /images/render_blender-render_textures_nodes_textures_musgrave.png

Musgrave.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/musgrave&gt;`

**********
Noise Node
**********

Noise
=====

.. figure:: /images/render_blender-render_textures_nodes_textures_noise.png

Noise.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/noise&gt;`

***********
Stucci Node
***********

.. figure:: /images/render_blender-render_textures_nodes_textures_stucci.png

Stucci.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/stucci&gt;`

************
Voronoi Node
************

.. figure:: /images/render_blender-render_textures_nodes_textures_voronoi.png

Voronoi node.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/voronoi&gt;`

*********
Wood Node
*********

.. figure:: /images/render_blender-render_textures_nodes_textures_wood.png

Wood node.

See :doc:`Here &lt;/render/blender_render/textures/types/procedural/wood&gt;`

******
Colors
******

.. figure:: /images/render_blender-render_textures_properties_color-panel.png
:width: 300px

Colors panel.

The *Ramp* button activates a color ramp which allows you to remap the colors of a texture to new ones.
See :doc:`Ramps &lt;/render/blender_render/materials/properties/ramps&gt;` for information on using ramps.

The color of a texture can be modified with the *Brightness*, *Contrast*,
and *Saturation* buttons. All textures with RGB-Values, including
*Images* and *Environment Maps*, may be modified with the RGB sliders.

R, G, B
Tint the color of a texture by brightening each red, green and blue channel.
Brightness
Change the overall brightness/intensity of the texture.
Contrast
Change the contrast of the texture.
Saturation
Change the saturation of the texture.

######################
Texture Properties
######################

.. toctree::
:maxdepth: 2

preview.rst
color.rst
mapping.rst
influence/index.rst

**********************
Texture Blending Modes
**********************

Blending Modes are different methods of controlling how the texture influences material
properties. While a blending mode defines the specific operation performed,
blending factor controls the amount, the overall "strength" of this operation.
For textures such blending factor is set via sliders in the Influence panel.

Blend
Blending operation to perform. See :term:`Color Blend Modes` for details on each blending mode.
RGB to Intensity
With this option enabled, an RGB texture (affects color) is used as an intensity texture (affects a value).
Blend Color
If the texture is mapped to Color,
what color is blended in according to the intensity of the texture?
Negative
The effect of the Texture is negated. Normally white means on, black means off, *Negative* reverses that.
Stencil
The active texture is used as a mask for all following textures.
This is useful for semitransparent textures and "Dirt Maps".
Black sets the pixel to "untexturable". The *Stencil* mode works similar to a layer mask in a 2D program.
The effect of a stencil texture cannot be overridden, only extended. You need an intensity map as input.
Destination Value
The value (not for RGB) with which the Intensity texture blends with the current value. Two examples:

- The *Emit* value is normally 0. With a texture mapped to *Emit* you will get maximal effect,
because *DVar* is 1 by default. If you set *DVar* to 0 no texture will have any effect.
- If you want transparent material, and use a texture mapped to *Alpha*,
nothing happens with the default settings, because the *Alpha* value in the *Material* panel is 1.
So you have to set *DVar* to 0 to get transparent material (and of course *Z Transparency* also).
This is a common problem for beginners. Or do it the other way round: set *Alpha* to 0 and leave *Dvar* on 1.
Of course the texture is used inverted then.

********************
Bump and Normal Maps
********************

*Normal Maps* and *Bump Maps* both serve the same purpose:
they simulate the impression of a detailed 3D surface,
by modifying the shading as if the surface had lots of small angles, rather than being completely flat.
Because it is just modifying the shading of each pixel,
this will not cast any shadows and will not obstruct other objects. If the camera angle is too flat to the surface,
you will notice that the surface is not really shaped.

Both *Bump Maps* and *Normal Maps* work by modifying the normal angle
(the direction pointing perpendicular from a face), which influences how a pixel is shaded.
Although the terms *Normal Map* and *Bump Map* are often used
synonymously, there are certain differences.

Bump maps
These are textures that store an *intensity*, the relative height of pixels from the viewpoint of the camera.
The pixels seem to be moved by the required distance in the direction of the face normals.
(The "bump" consists only of a displacement, which takes place along the existing, and unchanged,
normal-vector of the face.) You may either use grayscale pictures or the intensity values of a RGB-Texture
(including images).

Normal maps
These are images that store a *direction*, the direction of normals directly in the RGB values of an image.
They are much more accurate, as rather than only simulating the pixel being away from the face along a line,
they can simulate that pixel being moved at any direction, in an arbitrary way.
The drawbacks to normal maps are that unlike bump maps, which can easily be painted by hand,
normal maps usually have to be generated in some way,
often from higher resolution geometry than the geometry you are applying the map to.

Normal maps in Blender store a normal as follows:

- Red maps from (0 - 255) to X (-1.0 - 1.0)
- Green maps from (0 - 255) to Y (-1.0 - 1.0)
- Blue maps from (0 - 255) to Z (0.0 - 1.0)

Since normals all point towards a viewer, negative Z-values are not stored (they would be invisible anyway).
In Blender we store a full blue range, although some other implementations also map blue colors (128 - 255) to
(0.0 - 1.0). The latter convention is used in "Doom 3" for example.

Workflow
========

The steps involved in making and using Bump and Normal Maps is:

- Model a highly detailed ("hi-poly") model.
- Bake the Bump and/or Normal maps.
- Make a low-poly, less detailed model.
- Map the map to the low-poly model using a common coordinate system.

Consult the Modeling section for how to model a highly detailed model using the Mesh tools.
How much detail you put in is totally up to you. The more ridges and details (knobs, creases,
protrusions) you put in, the more detailed your map will be.

Baking a map, simply put, is to take the detail of a high polygon mesh, and apply it to a similar object.
The similar object is identical to the high-poly mesh except with less vertices.
Use the :doc:`Render Bake &lt;/render/blender_render/bake&gt;` feature in Blender to accomplish this.

Modeling a low-poly using Blender's Mesh editing tools. In general,
the same or similar faces should exist that reflect the model. For example,
a highly detailed ear may have 1000 faces in the high-poly model. In the low-poly model,
this may be replaced with a single plane, oriented in the same direction as the detailed ear mesh.
*(Tip:* Blender's :doc:`multi-resolution mesh &lt;/modeling/modifiers/generate/multiresolution&gt;`
modeling feature can be used to good effect here.)

Mapping is the process of applying a texture to the low-poly mesh.
Consult the :doc:`Textures Mapping section &lt;/render/blender_render/textures/properties/mapping&gt;`
for more information on applying a texture to a mesh's material.Special considerations for Bump and Normal Maps is:

- When using a Bump map, map the texture to *Normal* and enable *No RGB*.
- When using a Normal map, map the texture to *Normal*.

The coordinate systems of the two objects must match. For example, if you bake using a UV map of the high-poly model,
you must UV map the low poly model and line up its UV coordinates to match the outline of the high-poly image
(see :ref:`UV unwrapping &lt;editors-uv-image-index&gt;` to line up with the high-poly map edges.

*****************
Displacement Maps
*****************

Displacement mapping allows a texture input to manipulate the position of vertices on rendered geometry.
Unlike :doc:`Normal or Bump mapping &lt;/render/blender_render/textures/properties/influence/bump_and_normal&gt;`,
where the shading is distorted to give an illusion of a bump (discussed on the previous page),
Displacement Maps create real bumps, creases, ridges, etc in the actual mesh. Thus,
the mesh deformations can cast shadows, occlude other objects,
and do everything that changes in real geometry can do, but, on the other hand, requires a lot more vertices to work.

Options
=======

In the :doc:`Influence panel &lt;/render/blender_render/textures/properties/influence/introduction&gt;`,
the strength of the displacement is controlled by the *Displace* and *Normal* sliders:

- If a texture provides only normal information (e.g. *Stucci*),
vertices move according to the texture's normal data.
The normal displacement is controlled by the *Normal* slider.
- If a texture provides only intensity information (e.g. *Magic*, derived from color),
vertices move along the directions of their normals (a vertex has no normal itself,
it is the resulting vector of the adjacent faces). White pixels move outward in the direction of the normal,
black pixels move in the opposite direction.
The amount of displacement is controlled with the *Displace* slider.

The two modes are not exclusive. Many texture types provide both information
(*Clouds*, *Wood*, *Marble*, *Image*).
The amount of each type can be mixed using the respective sliders.
Intensity displacement gives a smoother, more continuous surface,
since the vertices are displaced only outward.
Normal displacement gives a more aggregated surface,
since the vertices are displaced in multiple directions.

The depth of the displacement is scaled with an object's scale,
but not with the relative size of the data.
This means if you double the size of an object in object mode,
the depth of the displacement is also doubled, so the relative displacement appears the same.
If you scale inside *Edit Mode*, the displacement depth is not changed,
and thus the relative depth appears smaller.

Hints
=====

Displacement maps move the rendered faces, not the physical mesh faces. So,
in 3D View the surface may appear smooth, but render bumpy. To give a detailed surface,
there has to be faces to displace and have to be very small.
This creates the trade-off between using memory and CPU time versus render quality.

From best to worst, displacement works with these object types using the methods listed to
control the render face size:

:doc:`Subdivision Surface &lt;/modeling/modifiers/generate/subsurf&gt;` *Meshes*
Rendered face size is controlled with render subdivision level. Displacement really likes smooth normals.
Manually ( *Edit Mode* ) :doc:`subdivided &lt;/modeling/meshes/editing/subdividing/subdivide&gt;` meshes
Control render faces with number of subdivides.
(This can be combined with the above methods).
Displaces exactly the same Simple Subdivision Surface,
however, the overhead of drawing extra faces can slow down editing.
:doc:`Meta Objects &lt;/modeling/metas/introduction&gt;`
Control render faces with render wiresize. Small wire == more faces.

The following are available, but currently do not work well.
It is recommended that you convert these to meshes before rendering.

Open :doc:`NURBS Surfaces &lt;/modeling/surfaces/introduction&gt;`
Control render faces with U/V *Surface Resolution*. Higher numbers give more faces. (Note normal errors).
Closed NURBS Surfaces
Control with *Surface Resolution* controls. (Note the normal errors, and how implicit seam shows).
:doc:`Curves &lt;/modeling/curves/introduction&gt;` **and** :doc:`Text &lt;/modeling/texts/introduction&gt;`
Control with *Surface Resolution* controls. Higher gives more render faces.
(Note that the large flat surfaces have few render faces to displace).

.. note:: Displace Modifier

If you want more control over your displacement,
you will probably want to use the :doc:`Displace Modifier &lt;/modeling/modifiers/deform/displace&gt;`.
This feature has lots of different options so that you can customize the displacement exactly to your liking.

############
Influence
############

.. toctree::
:maxdepth: 2

introduction.rst
blending_modes.rst
bump_and_normal.rst
displacement.rst

************
Introduction
************

Not only can textures affect the color of a material,
they can also affect many of the other properties of a material.
The different aspects of a material that a texture influences are
controlled in the *Influence* panel.

.. note::

Texture options for *Surface* and *Wire* materials and in some cases also for *Volume* and *Halo* materials.

Surface and Wire materials
==========================

.. figure:: /images/render_blender-render_textures_properties_influence_surface.png

Texture Influence panel for a Surface material.

Diffuse
-------

Intensity
Amount texture affects affects diffuse reflectivity
Color
Amount texture affect the basic color or RGB value of the material
Alpha
Influences the opacity of the material.
Also use *Z Transparency* for light and if combining multiple channels.
Translucency
Influences the Translucency amount.

Specular
--------

Intensity
Amount texture affect specular reflectivity
Color
Influences the *Specular* color, the color of the reflections created by the lamps on a glossy material.
Hardness
Influences the specular hardness amount.
A DVar of 1 is equivalent to a Hardness of 130, a DVar of 0.5 is equivalent to a Hardness of 65.

Shading
-------

Ambient
Influences the amount of Ambient light the material receives.
Emit
Influences the amount of light Emitted by the material.
Mirror
Influences the mirror color. This works with environment maps and raytraced reflection.
Ray Mirror
Influences the strength of raytraced mirror reflection.

Geometry
--------

Normal
Commonly called bump mapping, this alters the direction of the surface normal.
This is used to fake surface imperfections or unevenness via bump mapping, or to create reliefs.
Warp
*Warp* allows textures to influence/distort the texture coordinates of a next texture channel.
The distortion remains active over all subsequent channels, until a new Warp has been set.
Setting the factor at zero cancels out the effect.
Displace
Influences the Displacement of vertices,
for using :doc:`Displacement Maps &lt;/render/blender_render/textures/properties/influence/displacement&gt;`.

Other Controls
--------------

Bump Mapping
Settings for bump mapping.

Method
Best Quality, Default, Compatible, Original
Space
Texture Space, Object Space, View Space

Volume materials
================

.. figure:: /images/render_blender-render_textures_properties_influence_volume.png

Texture Influence panel for Volume material.

Special texture options for *Volume* materials.

Density
Causes the texture to affect the volume's density.
Emission
Causes the texture to affect the volume's emission.
Scattering
Amount the texture affects scattering.
Reflection
Amount the texture affects brightness of out-scattered light
Emission Color
Amount the texture affects emission color.
Transmission
Amount the texture affects result color after light has been scattered/absorbed.
Reflection Color
Amount the texture affects color of out-scattered light.

Halo materials
==============

.. figure:: /images/render_blender-render_textures_properties_influence_halo.png

Texture Influence panel for a Halo material.

Special texture options for *Halo* materials.

Size
Amount the texture affects ray mirror.
Hardness
Amount the texture affects hardness.
Add
Amount the texture affects translucency.
..    TODO/Review: {{review|text=missing dupli part}}.

*******
Mapping
*******

Textures need mapping coordinates, to determine how they are applied to the object.
The mapping specifies how the texture will ultimately wrap itself to the object.

For example,
a 2D image texture could be configured to wrap itself around a cylindrical shaped object.

.. figure:: /images/render_blender-render_texture_mapping_panel_generated.png

Mapping panel.

Coordinates
===========

Mapping works by using a set of coordinates to guide the mapping process.
These coordinates can come from anywhere, usually the object to which the texture is being applied to.

Global
The scene's global 3D coordinates. This is also useful for animations;
if you move the object, the texture moves across it.
It can be useful for letting objects appear or disappear at a certain position in space.
Object
Uses an object as source for coordinates. Often used with an *Empty*,
this is an easy way to place a small image at a given point on the object.
This object can also be animated, to move a texture around or through a surface.

Object
Select the name of an object.
Generated
The original undeformed coordinates of the object. This is the default option for mapping textures.
UV
UV mapping is a very precise way of mapping a 2D texture to a 3D surface.
Each vertex of a mesh has its own UV co-ordinates which can be unwrapped and laid flat like a skin.
You can almost think of UV coordinates as a mapping that works on a 2D plane with its own local coordinate system
to the plane on which it is operating on.
This mapping is especially useful when using 2D images as textures,
as seen in :ref:`UV Mapping &lt;editors-uv-image-index&gt;`.
You can use multiple textures with one set of UV coordinates.

UV Map
UV map to use for mapping.
Strand/Particle
Uses normalized 1D strand texture coordinate or particle age (X) and trail position (Y).
Use when texture is applied to hair strands or particles.
Window
The rendered image window coordinates. This is well suited to blending two objects.
Normal
Uses the direction of the surface's normal vector as coordinates.
This is very useful when creating certain special effects that depend on viewing angle.
Reflection
Uses the direction of the reflection vector as coordinates.
This is useful for adding reflection maps. You will need this input when Environment Mapping.
Stress
Uses the difference of edge length compared to original coordinates of the mesh.
This is useful, for example, when a mesh is deformed by modifiers.
Tangent
Uses the optional tangent vector as texture coordinates.

Projection
==========

Flat
Flat mapping gives the best results on single planar faces.
It does produce interesting effects on the sphere, but compared to a sphere-mapped sphere the result looks flat.
On faces that are not in the mapping plane the last pixel of the texture is extended,
which produces stripes on the cube and cylinder.
Cube
Cube mapping often gives the most useful results when the objects are not too curvy and organic
(notice the seams on the sphere).
Tube
Tube mapping maps the texture around an object like a label on a bottle.
The texture is therefore more stretched on the cylinder.
This mapping is of course very good for making the label on a bottle or assigning stickers to rounded objects.
However, this is not a cylindrical mapping so the ends of the cylinder are undefined.
Sphere
Sphere mapping is the best type for mapping a sphere,
and it is perfect for making planets and similar objects.
It is often very useful for creating organic objects.
It also produces interesting effects on a cylinder.

Inheriting coordinates from the parent object
=============================================

From Dupli
Duplis instanced from vertices, faces, or particles,
inherit texture coordinates from their parent.

.. Explaination Todo

Coordinate Offset, Scaling and Transformation
=============================================

Offset
The texture co-ordinates can be translated by an offset.
Enlarging of the Offset moves the texture towards the top left.
Size
These buttons allow you to change the mapping of axes between the texture's own coordinate system,
and the mapping system you choose (Generated, UV, etcetera.)
More precisely, to each axis of the texture corresponds one of four choices,
that allow you to select to which axis in the mapping system it maps! This implies several points:

- For 2D textures (such as images), only the first two rows are relevant, as they have no Z data.
- You can rotate a 2D picture a quarter turn by setting the first row (i.e. X texture axis) to Y,
and the second row (Y texture axis) to X.
- When you map no texture axis (i.e. the three "void" buttons are set),
you will get a solid uniform texture, as you use zero dimension (i.e. a dot, or pixel) of it
(and then Blender extends or repeats this point's color along all axes.)
- When you only map one texture axis (i.e. two "void" buttons are enabled)
you will get a "striped" texture, as you only use one dimension (i.e. a line of pixel) of it,
(and then Blender stretches this line along the two other axes).
- The same goes, for 3D textures (i.e. procedural ones), when one axis is mapped to nothing,
Blender extends the plan ("slice") along the relevant third axis.

*******
Preview
*******

.. figure:: /images/render_blender-render_textures_properties_preview-panel.jpg
:width: 300px

Preview panel.

The texture preview panel provides a quick pre-visualization of how the texture looks on its
own, without mapping.

Preview
Choose to display only the flat texture,
only the material :doc:`/render/blender_render/materials/properties/preview`, or both side-by-side.

Texture, Material/World, Both
Show Alpha
Show alpha in preview:

- If Alpha: Use is checked in the :doc:`Image Sampling &lt;/render/blender_render/textures/types/image/options&gt;`
panel, the image's alpha channel is displayed.
- If Alpha: Use is unchecked,
an alpha channel based on averaged rgb values is displayed like it would be used by the Alpha slider in the
:doc:`Influence &lt;/render/blender_render/textures/properties/influence/introduction&gt;` panel.

*************
Texture Panel
*************

In the Properties editor, choose the Texture tab: this will show the Texture panel.

.. figure:: /images/render_blender-render_textures_texture-panel.png

Texture panel.

Texture Context
The radio button selects the texture data type, that is,
the kind of texture that is being edited.

World
:doc:`World Background &lt;/render/blender_render/world/world_panel&gt;`.
Material/Lamp
Material type is described in the following section.
:doc:`/render/blender_render/lighting/lights/textures` in the lightning section.
Brush
Brush textures are applied in :doc:`/sculpt_paint/index`.

Textures Stack
==============

Active Texture
The Texture slots are displayed in a :ref:`ui-list-view`.
The order in the stack defines how textures are overlayed in the rendered image.
The checkbox enables/disables the selected texture.

Texture Data-Block
==================

Texture
The Texture :ref:`ui-data-block` for the selected texture slot.

Texture Type
============

Texture Type
Choose the type of texture that is used for the current texture data-block.
These types are described in detail :doc:`in this section &lt;/render/blender_render/textures/index&gt;`.
..    TODO/Review: {{review|text=area filter|im=update screenshot?}}.

****************
Environment Maps
****************

Environment maps take a render of the 3D scene and apply it to a texture,
to use for faking reflections. If you want to achieve a very realistic result,
raytraced reflections are a good solution.
Environment Maps are another way to create reflective surfaces,
but they are not so simple to set up.

So why should one use Environment Maps?

- The main reason is probably that they can be much faster than raytracing reflections.
In certain situations they need to be calculated only once, and may be reused like any ordinary texture.
You may even modify the precalculated Environment Map in an image editor.
- Environment maps can also be blurred and render even faster because the resolution can then be lowered.
Blurring a reflection with the raytracer always adds to the render time, sometimes quite a lot.
- :doc:`Halos &lt;/render/blender_render/materials/special_effects/halo&gt;`
(a visualization type for particles) are not visible to raytraced reflections,
so you need to setup environment maps to reflect them.
- :doc:`Keypoint strands &lt;/physics/particles/emitter/render&gt;`
(another visualization type for particles) are also not visible to raytraced reflections,
so you need to setup environment maps to reflect them.

Just as we render the light that reaches the viewing plane using the camera to define a
viewpoint, we can render the light that reaches the
surface of an object (and hence, the light that might ultimately be reflected to the camera).
Blender's environment mapping renders a
cubic image map of the scene in the six cardinal directions from any point. When the six tiles
of the image are mapped onto an object using the *Reflection* input coordinates,
they create the visual complexity that the eye expects to see from shiny reflections.

.. note::

It is useful to remember here that the true goal of this technique is *believability*,
not *accuracy*. The eye does not need a physically accurate simulation of the light's travel;
it just needs to be lulled into believing that the scene is real by seeing the complexity it
expects. The most unbelievable thing about most rendered images is the sterility,
not the inaccuracy.

Options
=======

.. important::

For correct results, the mapping of an environment map texture must be set to *Reflection*
(reflection co-ordinates) in the Map Input panel of the Material tab.

.. _fig-bi-environment-panel:

.. figure:: /images/render_blender-render_textures_environment-map.png

Reflecting plane Environment Map settings.

Blender allows three types of environment maps,
as you can see in Fig. :ref:`fig-bi-environment-panel`:

Static
The map is only calculated once during an animation or after loading a file.
Animated
The map is calculated each time a rendering takes place.
This means moving Objects are displayed correctly in mirroring surfaces.
Image File
When saved as an image file, environment maps can be loaded from an image file.
This allows the fastest rendering with environment maps,
and also gives the ability to modify or use the environment map in an external application.

When using planar reflections, if the camera is the only moving object and you have a reflecting plane,
the Empty must move too and you must use *Animated* environment map.
If the reflecting object is small and the Empty is in its center, the environment map can be *Static*,
even if the object itself rotates since the Empty does not move. If, on the other hand,
the Object translates the Empty should follow it and the environment map be of *Animated* type.
Specials
Clear Environment Map
Clears the currently rendered environment map from memory.
This is useful to refresh a *Static* environment maps and you have changed
things in your scene since the last time the environment map was rendered.
*Animated* environment maps do this automatically on every render.
Save Environment Map
Saves the currently stored static environment map to an image file on a drive.
This can be loaded again with *Load*.
Clear All Environment Maps
Does the same as *Free Data*, but with all environment maps in the scene.
This is a useful shortcut when using recursive environment maps (when the *Depth* is greater than 0).

.. note::

Environment Map calculation can be disabled at a global level
by the *Environment Map* Tog Button in the Render
Panel of the Rendering Buttons.

Viewpoint Object
Environment maps are created from the perspective of a specified object.
The location of this object will determine how 'correct' the reflection looks,
though different locations are needed for different reflecting surfaces.
Usually, an Empty is used as this object:

- For planar reflections, the object should be in a location mirrored from the camera,
on the other side of the plane of reflection (see Examples).
This is the most accurate usage of Environment maps.
- For spherical reflections, the object should be in the center of the sphere. Generally,
if the reflecting sphere's object center point is in the center of its vertices,
you can just use the name of the actual sphere object as the *Viewpoint Object*
- For irregular reflections, there is no hard and fast rule,
you will probably need to experiment and hope that the inaccuracy does not matter.

Ignore Layers
The layers to exclude from the environment map creation.
Since environment maps work by rendering the scene from the location of the *Viewpoint Object*,
you will need to exclude the actual reflecting surface from the environment map,
otherwise it will occlude other objects that should be reflected on the surface itself.

Eg. If you are rendering an environment map from the center of a sphere,
all the environment map will show by default is the inside of the sphere.
You will need to move the sphere to a separate layer, then exclude that layer from the environment map render,
so that the environment map will show (and hence reflect) all the objects outside the sphere.

Resolution
The resolution of the cubic environment map render. Higher resolutions will give a sharper texture (reflection),
but will be slower to render.

Depth
The number of recursive environment map renders.
If there are multiple reflecting objects using environment maps in the scene, some may appear solid,
as they will not render each other's reflections. In order to show reflections within reflections,
the environment maps need to be made multiple times, recursively,
so that the effects of one environment map can be seen in another environment map. See Examples.

Clipping Start/End
The clipping boundaries of the virtual camera when rendering the environment map.
Sets the minimum and maximum distance from the camera that will be visible in the map.

Environment Map Sampling
------------------------

.. figure:: /images/render_blender-render_textures_environment-map-sampling.png

Environment Map Sampling.

Filter
Box
Box Filter
EWA
Elliptical Weighted Average.
One of the most efficient direct convolution algorithms developed by Paul Heckbert and Ned Greene in the 1980s.
For each texel, EWA samples, weights,
and accumulates texels within an elliptical footprint and then divides the result by the sum of the weights.

Eccentricity
Maximum eccentricity (higher gives less blur at distant/oblique angles, but is also slower)
FELINE
FELINE (Fast Elliptical Lines),
uses several isotropic probes at several points along a line in texture space
to produce an anisotropic filter to reduce aliasing artifacts without considerably increasing rendering time.

Probes
Maximum number of samples (higher gives less blur at distant/oblique angles, but is also slower)

Area
Eccentricity
Maximum eccentricity (higher gives less blur at distant/oblique angles, but is also slower)

Filter Size
The amount of blurring applied to the texture.
Higher values will blur the environment map to fake blurry reflections.

Minimum Filter Size
Use Filter Size as a minimal filter value in pixels.

Examples
========

In this example,
an empty is used as the *Viewpoint Object* of the reflecting plane's environment map.
It is located in the specular position of the camera with respect to the reflecting surface.
(This is possible, strictly speaking, only for planar reflecting surfaces.) Ideally, the
location of the empty would mirror the location of the camera across the plane of the polygon
onto which it is being mapped.

.. list-table::
:widths: 58 42

* - .. figure:: /images/render_blender-render_textures_types_environment_example-1.png

Planar reflection example.

- .. figure:: /images/render_blender-render_textures_types_environment_example-2.jpg

Sphere on a reflecting surface.

The following images show the effect of the *Depth*.
The first render has depth set to 0. This means the environment map on the plane has rendered
before the environment map of the sphere, so the sphere's reflection is not shown.
By raising the *Depth*, the environment map is rendered recursively,
in order to get reflections of reflections.

.. list-table::

* - .. figure:: /images/render_blender-render_textures_types_environment_example-3.jpg

Reflecting sphere on a reflecting surface.

- .. figure:: /images/render_blender-render_textures_types_environment_example-4.jpg

Reflecting sphere on a reflecting surface with multiple reflections.

Limitations
===========

Because environment maps are calculated from the exact location of the *Viewpoint Object's* object center,
and not from actual reflecting surface, they can often be inaccurate, especially with spheres.
In the following image, the rectangular prism and the smaller spheres
are touching the sides of the large reflecting sphere,
but because the environment map is calculated from the center of the sphere,
the surrounding objects look artificially far away.

.. figure:: /images/render_blender-render_textures_types_environment_limitations.jpg

Inaccurate spherical reflection, the colored objects are artificially offset.

##################
Image or Movie
##################

.. toctree::
:titlesonly:
:maxdepth: 2

introduction.rst
workflow.rst
options.rst

************
Introduction
************

The term *Image Texture* simply means that a graphic image,
which is a pixel grid composed of R, G, B, and sometimes Alpha values.
It is used as the input source to the texture.
As with other types of textures, this information can be used in a number of ways,
not only as a simple "decal".

*Video textures* are a some kind of Image textures and
based on movie file or sequence of successive numbered separate images.
They are added in the same way that image textures are.

When the Texture Type *Image or Movie* is selected, three new panels present
themselves allowing to control most aspects of how image textures are applied:
*Image*, *Image Sampling*, and *Image Mapping*.

About Image Based Texturing
===========================

Texture images take up precious memory space,
often being loaded into a special video memory bank that is very fast and very expensive,
so it is often very small. So, keep the images as small as possible.
A 64×64 image takes up only one fourth the memory of a 128×128 image.

For photo-realistic rendering of objects in animations, often larger image textures are used,
because the object might be zoomed in on in camera moves. In general, you want to use a
texture sized proportionally to the number of pixels that it will occupy in the final render.
Ultimately, you only have a certain amount of physical RAM to hold an image texture and the
model and to provide work space when rendering your image.

For the most efficient memory usage, image textures should be square, with dimensions as powers of 2,
such as 32×32, 64×64, 128×128, 256×256, 1024×1024, 2048×2048, and 4096×4096.

If you can re-use images across different meshes, this greatly reduces memory requirements.
You can re-use images if you map those areas of the meshes that "look alike" to a layout that
uses the common image. In the overview below,
the left image is re-used for both the sphere and a portion of the monkey.
The monkey uses two layouts, one which has one UV map of a few faces,
and another that has three maps.

.. figure:: /images/render_blender-render_textures_image_introduction_uv-overview.jpg

How all the parts of UV Texturing work together.

When using file textures, it is very important that you have
:doc:`Mapped the UVs &lt;/editors/uv_image/uv_editing/unwrapping/index&gt;`
of the mesh, and they are laid out appropriately.

You do not have to UV map the *entire* mesh.
The sphere above on the left has some faces mapped,
but other faces use procedural materials and textures.
Only use UV Textures for those portions of your mesh where you want very graphic,
precise detail. For example,
a model of a vase only needs UV Texture for the rim where decorative artwork is incorporated.
A throw pillow does not need a different image for the back as the front;
in fact many throw pillows have a fabric (procedural material) back.

As another example, you should UV map both eyes of a head to the same image
(unless you want one bloodshot and the other clear).
Mapping both sides of a face to the same image might not be advisable,
because the location of freckles and skin defects are not symmetrical.
You could of course change the UV map for one side of the face to slightly offset,
but it might be noticeable.
Ears are another example where images or section of an images can be mapped to similar faces.

UV Textures vs. Procedural Textures
===================================

A Material Texture, that has a Map Input of UV,
and is an image texture that is mapped to Color, is equivalent to a UV Texture.
It provides much more flexibility, because it can be sized and offset, and the degree to which
it affects the color of your object can be controlled in the Map To panel. In addition,
you can have different images for each texture channel; one for color, one for alpha,
one for normals, one for specularity, one for reflectivity, *etc.* Procedural textures,
like Clouds, are incredibly simple and useful for adding realism and details to an image.

.. list-table::
:header-rows: 1
:class: valign
:widths: 40 60

* - UV Texture
- Procedural Texture
* - Image maps to precise coordinates on the selected faces of the mesh.
- Pattern is generated dynamically, and is mapped to the entire mesh (or portion covered by that material).
* - The Image maps once to a range of mesh faces specifically selected.
- Maps once to all the faces to which that material is assigned; either the whole mesh or a portion.
* - Image is mapped once to faces.
- Size XYZ in the Map Input allows tiling the texture many times across faces.
Number of times depends on size of mesh.
* - Affect the color and the alpha of the object.
- Can also affect normals (bumpiness), reflectivity, emit, displacement,
and a dozen other aspects of the mesh's appearance; can even warp or stencil subsequent textures.
* - Can have many for a mesh.
- Can be layered, up to 10 textures can be applied, layering on one another.
Many mix methods for mixing multiple channels together.
* - Any Image type (still, video, rendered). Generated test grid available.
- Many different types: clouds, wood grain, marble, noise, and even magic.
* - Provides the UV layout for animated textures.
- Noise is the only animated procedural texture.
* - Takes very limited graphics memory
- Uses no or little memory; instead uses CPU compute power.

So, in a sense, a single UV texture for a mesh is simpler but more limited than using multiple textures
(mapped to UV coordinates), because they do one specific thing very well:
adding image details to a range of faces of a mesh.
They work together if the procedural texture maps to the UV coordinates specified in your layout.
As discussed earlier, you can map multiple UV textures to different images using
the UV Coordinate mapping system in the Map Input panel.

.. |small-pic| image:: /images/render_blender-render_textures_types_image_options_interpolation.png

*******
Options
*******

Image
=====

In the *Image* panel we tell Blender which source file to use.

Image
The Image :ref:`ui-data-block`. For the options see :doc:`/editors/uv_image/image/image_settings`.

Image Sampling
==============

In the *Image Sampling* panel we can control how the information is retrieved from the image.

.. list-table::

* - .. figure:: /images/render_blender-render_texture_image_bahnhofstrasse.jpg
:width: 320px

Background image.

- .. figure:: /images/render_blender-render_texture_image_map-to-eingabewerte.png
:width: 320px

Foreground image.

The two images presented here are used to demonstrate the different image options.
The *background image* is an ordinary JPG-file,
the *foreground image* is a PNG-file with various alpha and grayscale values.
The vertical bar on the right side of the foreground image is an Alpha blend,
the horizontal bar has 50% alpha.

.. list-table::

* - .. figure:: /images/render_blender-render_texture_image_usealpha.jpg
:width: 320px

Foreground image with *Use* alpha. The alpha values of the pixels are evaluated.

- .. figure:: /images/render_blender-render_texture_image_calcalpha.jpg
:width: 320px

Foreground image with *Calculate* alpha.

Alpha
Options related to transparency.

Use
Works with PNG and TGA files since they can save transparency information (Foreground Image with Use Alpha).
Where the alpha value in the image is less than 1.0,
the object will be partially transparent and stuff behind it will show.
Calculate
Calculate an alpha based on the RGB values of the Image.
Black (0, 0, 0) is transparent, white (1, 1, 1) opaque.
Enable this option if the image texture is a mask.
Note that mask images can use shades of gray that translate to semi-transparency,
like ghosts, flames, and smoke/fog.
Invert
Reverses the alpha value.
Use this option if the mask image has white where you want it transparent and vice-versa.

Flip X/Y Axis
Rotates the image 90 degrees counterclockwise when rendered.

.. figure:: /images/render_blender-render_textures_image_options_image-sampling-panel.png

Image Sampling panel.

Normal Map
This tells Blender that the image is to be used to create the illusion of a bumpy surface,
with each of the three RGB channels controlling how to fake a shadow from a surface irregularity.
Needs specially prepared input pictures.
See :doc:`Bump and Normal Maps &lt;/render/blender_render/textures/properties/influence/bump_and_normal&gt;`.

Normal Map Space:
- *Tangent*
- *Object*
- *World*
- *Camera*

Derivative Map
Use red and green as derivative values.

MIP Map
`MIP Maps &lt;https://en.wikipedia.org/wiki/Mipmap&gt;`__ are pre-calculated, smaller,
filtered Textures for a certain size. A series of pictures is generated, each half the size of the former one.
This optimizes the filtering process. By default, this option is enabled and speeds up rendering
(especially useful in the :doc:`Game Engine &lt;/game_engine/index&gt;`). When this option is OFF,
you generally get a sharper image, but this can significantly increase calculation time if the filter dimension
(see below) becomes large. Without MIP Maps you may get varying pictures from slightly different camera angles,
when the Textures become very small. This would be noticeable in an animation.

MIP Map Gaussian filter
Used in conjunction with MIP Map, it enables the MIP Map to be made smaller based on color similarities.
In the :doc:`Game Engine &lt;/game_engine/index&gt;`, you want your textures,
especially your MIP Map textures, to be as small as possible to increase rendering speed and frame rate.

Interpolation
This option interpolates the pixels of an image.
This becomes visible when you enlarge the picture. By default, this option is on.
Turn this option off to keep the individual pixels visible and if they are correctly anti-aliased.
This last feature is useful for regular patterns, such as lines and tiles;
they remain 'sharp' even when enlarged considerably.
When you enlarge this 10×10 pixel Image |small-pic|
the difference with and without *Interpolation* is clearly visible.
Turn this image off if you are using digital photos to preserve crispness.

.. list-table::
Enlarged Image texture without and with *Interpolation*

* - .. figure:: /images/render_blender-render_textures_types_image_options_interpolation-off.png

- .. figure:: /images/render_blender-render_textures_types_image_options_interpolation-on.png

Filter
The filter size used in rendering, and also by the options *MipMap* and *Interpolation*.
If you notice gray lines or outlines around the textured object, particularly where the image is transparent,
turn this value down from 1.0 to 0.1 or so.

Texture Filter Type
Texture filter to use for image sampling.
Just like a *pixel* represents a *pic* ture *el* ement, a *texel* represents a *tex* ture *el* ement.
When a texture (2D texture space) is mapped onto a 3D model (3D model space),
different algorithms can be used to compute a value for each pixel based on samplings from several texels.

Box
A fast and simple nearest-neighbor interpolation known as Monte Carlo integration
EWA (Elliptical Weighted Average)
One of the most efficient direct
convolution algorithms developed by Paul Heckbert and Ned Greene in the 1980s.
For each texel, EWA samples, weights, and accumulates texels within an elliptical
footprint and then divides the result by the sum of the weights.

Eccentricity
Maximum Eccentricity. Higher values give less blur at distant/oblique angles, but is slower
FELINE (Fast Elliptical Lines)
Uses several isotropic probes at several points along a line in texture space to produce an anisotropic
filter to reduce aliasing artifacts without considerably increasing rendering time.

Probes
Number of probes to use. An integer between 1 and 256.
Further reading: McCormack, J; Farkas, KI; Perry, R; Jouppi, NP (1999)
`Simple and Table Feline: Fast Elliptical Lines for Anisotropic Texture Mapping
&lt;http://www.hpl.hp.com/techreports/Compaq-DEC/WRL-99-1.pdf&gt;`__, WRL
Area
Area filter to use for image sampling.

Eccentricity
Maximum Eccentricity. Higher values give less blur at distant/oblique angles, but is slower.

Filter Size
The filter size used by MIP Map and Interpolation.
Minimum Filter Size
Use Filter Size as a minimal filter value in pixels.

Image Mapping
=============

.. figure:: /images/render_blender-render_textures_image_options_image-mapping-panel.png

Image Mapping panel.

In the *Image Mapping* panel,
we can control how the image is mapped or projected onto the 3D model.

Extension
Extend
Outside the image the colors of the edges are extended.
Clip
Clip to image size and set exterior pixels as transparent.
Outside the image, an alpha value of 0.0 is returned.
This allows you to 'paste' a small logo on a large object.
Clip Cube
Clips to cubic-shaped area around the images and sets exterior pixels as transparent.
The same as Clip, but now the 'Z' coordinate is calculated as well.
An alpha value of 0.0 is returned outside a cube-shaped area around the image.
Repeat
The image is repeated horizontally and vertically.

Repeat
X/Y repetition multiplier.
Mirror
Mirror on X/Y axes. This buttons allow you to map the texture as a mirror, or automatic flip of the image,
in the corresponding X and/or Y direction.
Checker
Checkerboards quickly made.
You can use the option *size* on the *Mapping* panel as well to create the desired number of checkers.

Even / Odd
Set even/odd tiles
Distance
Governs the distance between the checkers in parts of the texture size.

Crop Minimum / Crop Maximum
The offset and the size of the texture in relation to the texture space.
Pixels outside this space are ignored.
Use these to crop, or choose a portion of a larger image to use as the texture.

********
Workflow
********

The process consists of the following steps:

- Create the Mesh. :doc:`Unwrap &lt;/editors/uv_image/uv_editing/unwrapping/index&gt;` it into one or more
:doc:`UV Layouts &lt;/editors/uv_image/uv_editing/layout_management&gt;`.
- Create one or more Materials for the Mesh.
- Create one or more images for each UV Layout and aspect of the texture. Either
- Paint directly on the mesh using Texture Paint in the 3D View,
- Load and/or edit an image in the UV/Image Editor, or
- Bake the existing materials into an image for the UV/Image Editor.
- Apply those images as UV Textures to the mesh to affect one or more aspects of the mesh.
This is done by using one or more of the numerous Map To options. For example,
- Map to Color to affect the diffuse coloring of the mesh,
- Map to Nor to affect the normal direction to give the surface a bumpy or creased look, or
- Map to Spec (specularity) to make certain areas look shiny and oily.
- Layer the Textures to create a convincing result.

Using Images and Materials
==========================

To use an image as the color and alpha (transparency) of the texture, you can create an image
in an external paint program and tell the UV/Image Editor to Open that file as the texture,
or you can create a New image and save it as the texture.

If you want to start off by creating an image using an external paint program,
you will want to save an outline of your UV faces by using the *Save UV Face Layout* tool located in the UVs menu.
This is discussed :ref:`here &lt;uv-image-export-layout&gt;`.

Creating an Image Texture
-------------------------

To create an image within Blender,
you have to first create a :doc:`New Blank &lt;/editors/uv_image/uv_editing/applying_image&gt;`
Image with a uniform color or test grid.
After that, you can color the image using the:

- Vertex colors as the basis for an image.
- Render Bake image based on how the mesh looks in the scene.

After you have created your image,
you can modify it using Blender's built-in
:doc:`Texture Paint &lt;/sculpt_paint/painting/texture_paint/introduction&gt;`
or any external image painting program.

.. note:: See Texture in 3D View but does not Render

You may be able to see the texture in Textured display mode in the 3D View;
this is all that is required to have textures show up in Blender's Game Engine. Rendering, however,
requires a material.
You must have a *Face Textures* material assigned to the mesh for it to render using the UV Texture.
In the Material settings, Add New material to a selected object and enable *Face Textures*.

Examples
========

There may be one UV Layout for the face of a character, and another for their clothes. Now,
to texture the clothes, you need to create an image at least for the Color of the clothes, and
possible a "bump" texture to give the fabric the appearance of some weave by creating a
different image for the Normal of the clothes. Where the fabric is worn,
for example at the elbows and knees, the sheen, or Specularity, of the fabric will vary and
you will want a different image that tells Blender how to vary the Specularity.
Where the fabric is folded over or creased,
you want another image that maps Displacement to the mesh to physically deform the mesh.
Each of these are examples of applying an image as a texture to the mesh.

As another example, the face is the subject of many questions and tutorials. In general,
you will want to create a Material that has the basic skin color, appropriate shaders,
and sub-surface scattering. Then you will want to layer on additional UV Textures for:

- Freckle map for Color and Normal aspects.
- Subdermal veins and tendons for Displacement.
- Creases and Wrinkles and skin cell stratification for Normal.
- Makeup images for Color.
- Oily maps for Specularity.
- For a zombie, Alpha transparency where the flesh has rotted away.
- Under chin and inside nostrils that receive less Ambient light.
- Thin skin is more translucent, so a map is needed for that.

Each image is mapped by using another Texture Channel.
Each of these maps are images which are applied to the different aspects (Color, Normal,
Specularity) of the image. Tileable images can be repeated to give a smaller,
denser pattern by using the Texture controls for repeat or size.

Layering UV Textures
--------------------

.. list-table::

* - .. figure:: /images/render_blender-render_textures_image_workflow_uv-layer_one.jpg
:width: 320px

Base UV Texture.

- .. figure:: /images/render_blender-render_textures_image_workflow_uv-layer-two.jpg
:width: 320px

Layered UV Texture.

Great textures are formed by layering images on top of one another.
You start with a base layer, which is the base paint. Each successive layer on top of that is
somewhat transparent to let the bottom layers show through,
but opaque where you want to add on to details.

To avoid massive confusion, all image textures for a mesh usually use the same UV map.
If you do, each image will line up with the one below it,
and they will layer on top of one another like the examples shown to the right. To do this,
just create one UV Texture (map) as described in this section. Then,
create material image textures as described in the procedural materials section.
Instead of mapping to Original Coordinates (OrCo), map to UV.

Use that map name repeatedly in the :menuselection:`Material --&gt; Textures --&gt; Map Input`
panel by selecting *UV* and typing the name in the text field. In the example to the right,
our UV Texture is called "Head" (you may have to expand the image to see the panel settings).
Then, the image texture shown will be mapped using the UV coordinates.
In the "Base UV Texture" example to the right, the face has two textures UV mapped;
one for a base color, and another for spots, blemishes and makeup.

Both textures use the same UV Texture map as their Map Input, and both affect Color.
The Makeup texture is transparent except where there is color,
so that the base color texture shows through.
Note that the colors were too strong on the image,
so they amount of the diffuse color affects is turned down to 60% in the second layer (the blemish layer).

Normally, we think of image textures affecting the color of a mesh. Realism and
photo-realistic rendering is a combination of many different ways that light interacts with
the surface of the mesh. The image texture can be Mapped To not only color,
but also *Normal* (bumpiness)
or *Reflection* or any of the other attributes specified in the Map To panel.

If you paint a gray-scale image (laid out according to the UV Layout)
with white where the skin is oily and shiny, and dark where it is not,
you would map that input image according to the UV Layout, but have it affect Specularity
(not color).

To make portions of a mesh transparent and thus reveal another mesh surface underneath,
you would paint a gray-scale image with black where you want the texture transparent,
map input to UV, and map it to Alpha (not color). To make portions of a mesh,
like a piece of hot metal, appear to glow, you would use a gray-scale image mapped to Emit.

Believe it or not, this is only "the tip of the iceberg!" If everything that is been described
here just is not enough for you, the *texture nodes* feature,
introduced in recent versions of Blender,
enables you to layer and combine textures in almost any way you can imagine.

Mix and Match Materials
-----------------------

.. figure:: /images/render_blender-render_textures_image_workflow_uv-mixmat.jpg
:align: right

You can mix and match procedural materials and textures, vertex paint,
and UV textures onto the same mesh.

The image to the right has a world with a red ambient light.
The material has both Vertex Color Paint and Face Textures enabled,
and receives half of ambient light. A weak cloud texture affects color, mixing in a tan color.
The right vertices are vertex painted yellow and the left is unpainted procedural gray.
The UV Texture is a stock arrow image from the public domain texture CD.
Scene lighting is a white light off to the right.
From this information and the User Manual thus far,
you should now be able to recreate this image.

You can also assign :ref:`multiple materials &lt;bi-multiple-materials&gt;`
to the mesh based on which faces you want to be procedural and which you want to be texture-mapped.
Just do not UV map the faces you want to be procedural.

You can use UV Textures and Vertex Paint (:kbd:`V` in the 3D View) simultaneously,
if both are enabled in the Material settings.
The vertex colors are used to modulate the brightness or color of the UV image texture:

- UV Texture is at the base *(Face Textures)*
- Vertex paint affects its colors, then
- Procedural textures are laid on top of that,
- Area lights shine on the surface, casting shadows and what not, and finally
- Ambient light lights it up.

.. figure:: /images/render_blender-render_textures_image_workflow_uv-vertex-colors.jpg
:width: 550px

Vertex colors modulate texture.

A UV Layout can only have one image, although you can tile and animate the image.
Since a layout is a bunch of arranged UV Maps, and a UV Map maps many mesh faces,
a face can therefore only have one UV Texture image,
and the UV coordinates for that face must fit entirely on the image.
If you want a face to have multiple images, split the face into parts,
and assign each part its own image. *(Or* you can get fancy with Nodes,
but that is another story ...)

Using Alpha Transparency
------------------------

.. figure:: /images/render_blender-render_textures_image_workflow_uv-alpha.jpg
:align: right
:width: 200px

Alpha UV Textures.

Alpha 0.0 (transparent) areas of a UV Image render as black.
Unlike a procedural texture, they do not make the base material transparent,
since UV Textures do not operate on the base procedural material.
The UV texture overrides any procedural color underneath.
Procedural Textures are applied on top of UV Textures,
so a procedural image texture would override any UV Texture. Transparent (black)
areas of a procedural texture mapped to alpha operate on top of anything else,
making the object transparent in those places.
The only thing that modulates visible parts of a UV Texture are the Vertex Colors.
In the example to the right,
the finger image is transparent at the cuff and top of the finger and is used as a UV Texture.
All three balls have a base material of blue and a marbling texture.
The base material color is not used whenever Face Textures is enabled.

The top left ball has not had any vertex painting,
and the finger is mapped to the middle band, and the texture is mapped to a pink color.
As you can see, the base material has Vertex Color Paint and Face Textures enabled;
the base color blue is not used, but the texture is. With no vertex painting,
there is nothing to modulate the UV Texture colors, so the finger shows as white.
Transparent areas of the UV Image show as black.

The top right ball has had a pink vertex color applied to the vertical band of faces
(in the 3D View editor, select the faces in UV Paint Mode, switch to Vertex Paint Mode,
pick a pink color, and :menuselection:`Paint --&gt; Set Vertex Colors`).
The finger is mapped to the middle vertical band of faces,
and Vertex Color and Face Textures are enabled.
The texture is mapped to Alpha black and multiplies the base material alpha value which is 1.0.
Thus, white areas of the texture are 1.0, and 1.0 times 1.0 is 1.0
so that area is opaque and shows. Black areas of the procedural texture, 0.0,
multiply the base material to be transparent. As you can see, the unmapped faces
(left and right sides of the ball) show the vertex paint (none, which is gray)
and the painted ones show pink, and the middle stripe that is both painted and mapped change
the white UV Texture areas to pink.
Where the procedural texture says to make the object transparent,
the green background shows through.
Transparent areas of the UV Texture insist on rendering black.

The bottom ball uses multiple materials. Most of the ball (all faces except the middle band)
is a base material that does not have Face Textures (nor Vertex Color Paint)
enabled. Without it enabled,
the base blue material color shows and the pink color texture is mixed on top.
The middle band is assigned a new material (2 Mat 2)
that *does* have vertex paint and Face Textures enabled.
The middle band of faces were vertex painted yellow,
so the white parts of the finger are yellow. Where the pink texture runs over the UV texture,
the mixed color changes to green, since pink and yellow make a green.

If you want the two images to show through one another, and mix together,
you need to use Alpha. The base material can have an image texture with an Alpha setting,
allowing the underlying UV Texture to show through.

To overlay multiple UV images, you have several options:

- Create multiple UV Textures which map the same,
and then use different images (with Alpha) and Blender will overlay them automatically.
- Use the :doc:`Composite Nodes &lt;/compositing/index&gt;` to combine the two images via the Alpha Over node,
creating and saving the composite image. Open that composited image as the UV Texture.
- Use an external paint program to alpha overlay the images and save the file,
and load it as the face's UV Texture
- Define two objects, one just inside the other.
The inner object would have the base image,
and the outer image the overlaid image with a material alpha less than one (1.0).
- Use the :doc:`Material nodes &lt;/render/blender_render/materials/nodes/index&gt;`
to combine the two images via the Alpha Over or Mix node,
thus creating a third noded material that you use as the material for the face.
Using this approach, you will not have to UV map;
simply assign the material to the face using the Multiple Materials.

################
Texture Types
################

.. toctree::
:maxdepth: 2

image/index.rst
procedural/index.rst
environment.rst
volume/index.rst

*****
Blend
*****

.. figure:: /images/render_blender-render_textures_procedural_blend.png

Blend Texture Panels.

Often used for
This is one of the most frequently used procedural textures.
You can use blend textures to blend other textures together (with *Stencil*),
or to create nice effects (especially with the *Mapping: Normal* trick).

.. note::

Remember that if you use a ramp to create a custom blending, you may have to use *No RGB*,
if the *Mapping* value needs an intensity input.

Result(s)
Intensity. The Blend texture generates a smoothly interpolated progression.

Options
=======

Progression
Profile of blend.

Linear
A linear progression.

Quadratic
A quadratic progression.
Easing
A flowing, non-linear progression.
Diagonal
A diagonal progression.
Spherical
A progression with the shape of a three-dimensional ball.
Quadratic Sphere
A quadratic progression with the shape of a three-dimensional ball.
Radial
A radial progression:
*Horizontal* / *Vertical*.
The direction of the progression is flipped a quarter turn.

******
Clouds
******

.. figure:: /images/render_blender-render_textures_procedural_clouds.png

Clouds Texture Panels.

Clouds represent Perlin noise. In addition, each noise-based Blender texture
(with the exception of Voronoi and simple noise) has a "Noise Basis" setting that allows the
user to select which algorithm is used to generate the texture.

Often used for
Clouds, Fire, Smoke. Well-suited to be used as a Bump map, giving an overall irregularity to the material.
Result(s)
*Greyscale* (default) or RGB *Color*

Options
=======

Greyscale
The standard noise, gives an intensity
Color
The noise gives an RGB value
Noise
*Soft* or *Hard*, changes contrast and sharpness
Size
The dimension of the Noise table
Depth
The depth of the *Clouds* calculation.
A higher number results in a long calculation time, but also in finer details.

***************
Distorted Noise
***************

.. figure:: /images/render_blender-render_textures_procedural_distorted-noise.png

Distorted Noise Texture Panels.

*Distortion Noise* takes the option that you pick from *Noise Basis* and filters it, to create hybrid pattern.

Often used for
Grunge, very complex and versatile.
Result(s)
Intensity.

Options
=======

Noise Distortion
The texture to use to distort another.
Basis
The texture to be distorted.
Noise
The size of the noise generated.
Distortion
The amount that *Distortion Noise* affects *Basis*.

######################
Procedural Textures
######################

.. toctree::
:maxdepth: 1

introduction.rst
ocean.rst
blend.rst
clouds.rst
distorted_noise.rst
magic.rst
marble.rst
musgrave.rst
noise.rst
stucci.rst
voronoi.rst
wood.rst

************
Introduction
************

.. figure:: /images/render_blender-render_textures_procedural_menu.jpg
:width: 240px

The Texture Type list in the Texture panel of the Texture Buttons. (Non procedural textures darkened out.).

Procedural textures are textures that are defined mathematically.
They are generally relatively simple to use,
because they do not need to be mapped in a special way.
This does not mean that procedural textures cannot become very complex.

These types of textures are 'real' 3D. By that we mean that they fit together perfectly at the
edges and continue to look like what they are meant to look like even when they are cut;
as if a block of wood had really been cut in two.
Procedural textures are not filtered or anti-aliased. This is hardly ever a problem:
the user can easily keep the specified frequencies within acceptable limits.

These are the available types:

- :doc:`Blend &lt;/render/blender_render/textures/types/procedural/blend&gt;`
- :doc:`Clouds &lt;/render/blender_render/textures/types/procedural/clouds&gt;`
- :doc:`Distorted Noise &lt;/render/blender_render/textures/types/procedural/distorted_noise&gt;`
- :doc:`Magic &lt;/render/blender_render/textures/types/procedural/magic&gt;`
- :doc:`Marble &lt;/render/blender_render/textures/types/procedural/marble&gt;`
- :doc:`Musgrave &lt;/render/blender_render/textures/types/procedural/musgrave&gt;`
- :doc:`Noise &lt;/render/blender_render/textures/types/procedural/noise&gt;`
- :doc:`Stucci &lt;/render/blender_render/textures/types/procedural/stucci&gt;`
- :doc:`Voronoi &lt;/render/blender_render/textures/types/procedural/voronoi&gt;`
- :doc:`Wood &lt;/render/blender_render/textures/types/procedural/wood&gt;`

Common options
==============

Noise Basis
-----------

Each noise-based Blender texture (with the exception of Voronoi and simple noise) has a
*Noise Basis* setting that allows the user to select which algorithm is used to
generate the texture. This list includes the original Blender noise algorithm.
The *Noise Basis* settings makes the procedural textures extremely flexible (especially *Musgrave*).

The *Noise Basis* governs the structural appearance of the texture:

.. list-table::

* - .. figure:: /images/render_blender-render_textures_procedural_noise-basis-blender-original.jpg
:width: 160px

Blender Original.

- .. figure:: /images/render_blender-render_textures_procedural_noise-basis-voronoi-f1.jpg
:width: 160px

Voronoi F1.

- .. figure:: /images/render_blender-render_textures_procedural_noise-basis-voronoi-f2-f1.jpg
:width: 160px

Voronoi F2-F1.

* - .. figure:: /images/render_blender-render_textures_procedural_noise-basis-original-perlin.jpg
:width: 160px

Original Perlin.

- .. figure:: /images/render_blender-render_textures_procedural_noise-basis-voronoi-f2.jpg
:width: 160px

Voronoi F2.

- .. figure:: /images/render_blender-render_textures_procedural_noise-basis-voronoi-crackle.jpg
:width: 160px

Voronoi Crackle.

* - .. figure:: /images/render_blender-render_textures_procedural_noise-basis-improved-perlin.jpg
:width: 160px

Improved Perlin.

- .. figure:: /images/render_blender-render_textures_procedural_noise-basis-voronoi-f3.jpg
:width: 160px

Voronoi F3.

- .. figure:: /images/render_blender-render_textures_procedural_noise-basis-cell-noise.jpg
:width: 160px

Cell Noise.

* - .. figure:: /images/render_blender-render_textures_procedural_noise-basis-voronoi-f4.jpg
:width: 160px

Voronoi F4.

- ..

- ..

There are two more possible settings for *Noise Basis*, which are relatively similar to *Blender Original*:
Improved Perlin and Original Perlin.

Nabla
-----

Almost all procedural textures in Blender use derivatives for calculating normals for texture mapping
(with as exception *Blend* and *Magic*). This is important for Normal and Displacement Maps.
The strength of the effect is controlled with the *Nabla* Number Button.

Hints
=====

Use the size buttons in the *Mapping* panel to set the size that the procedural textures are mapped to.

Procedural textures can either produce colored textures, intensity only textures,
textures with alpha values and normal textures.
If intensity only ones are used the result is a black and white texture,
which can be greatly enhanced by the use of ramps.
If on the other hand you use ramps and need an intensity value,
you have to switch on *No RGB* in the *Mapping* panel.

*****
Magic
*****

.. figure:: /images/render_blender-render_textures_procedural_magic.png

Magic Texture Panels.

Often used for
Not frequently used. It can be used for "Thin Film Interference",
if you set *Mapping* to *Reflection* and use a relatively high *Turbulence*.
Result(s)
RGB color. The RGB components are generated independently with a sine formula.

Options
=======

Depth
The depth of the calculation. A higher number results in a long calculation time, but also in finer details.
Turbulence
The strength of the pattern.

******
Marble
******

.. figure:: /images/render_blender-render_textures_procedural_marble.png

Marble Texture Panels.

Often used for
Marble, Fire, Noise with a structure.
Result(s)
Intensity value only.

Bands are generated based on the sine, saw, or triangular formula and noise turbulence.

Options
=======

Marble Type
Three settings for soft to more clearly defined *Marble*.

Soft, Sharp, Sharper
Noise basis
Shape of wave to produce bands.

Sine, Saw, Triangle
Noise Type
The noise function works with two methods.

Soft, Hard
Size
The dimensions of the noise table
Depth
The depth of the *Marble* calculation.
A higher value results in greater calculation time, but also in finer details.
Turbulence
The turbulence of the sine bands.

********
Musgrave
********

.. figure:: /images/render_blender-render_textures_procedural_musgrave.png

Musgrave Texture Panels.

Often used for
Organic materials, but it is very flexible. You can do nearly everything with it.
Result(s)
Intensity.

Options
=======

Type
This procedural texture has five noise types on which the resulting pattern can be based
and they are selectable from a select menu at the top of the tab. The five types are:

- Hetero Terrain
- Fractal Brownian Motion (fBm)
- Hybrid Multifractal
- Ridged Multifractal
- Multifractal

These noise types determine the manner in which Blender layers successive copies of the same
pattern on top of each other at varying contrasts and scales.

Examples with Basis: Voronoi: F1, Dimension: 0.5, Lacunarity: 0.15, Octave: 2.0.

.. list-table::

* - .. figure:: /images/render_blender-render_textures_procedural_musgrave_heteroterrain.jpg
:width: 120px

Hetero Terrain.

- .. figure:: /images/render_blender-render_textures_procedural_musgrave_fbm.jpg
:width: 120px

Fractal Brownian Motion.

- .. figure:: /images/render_blender-render_textures_procedural_musgrave_hybridmultifractal.jpg
:width: 120px

Hybrid Multifractal.

- .. figure:: /images/render_blender-render_textures_procedural_musgrave_ridgedmultifractal.jpg
:width: 120px

Ridged Multifractal.

- .. figure:: /images/render_blender-render_textures_procedural_musgrave_multifractal.jpg
:width: 120px

Multifractal.

.. not implemented yet?
In addition to the five noise types, Musgrave has a noise basis setting which determines the
algorithm that generates the noise itself.
These are the same noise basis options found in the other procedural textures.

The main noise types have four characteristics:

Dimension
Fractal dimension controls the contrast of a layer relative to the previous layer in the texture.
The higher the fractal dimension, the higher the contrast between each layer,
and thus the more detail shows in the texture.
Lacunarity
Lacunarity controls the scaling of each layer of the Musgrave texture,
meaning that each additional layer will have a scale that is the inverse of the value which shows on the button.
i.e. Lacunarity = 2 --&gt; Scale = 1/2 original.
Octaves
Octave controls the number of times the original noise pattern is overlayed on itself and
scaled/contrasted with the fractal dimension and lacunarity settings.
Intensity
Light intensity. Called *Offset* for *Hetero Terrain*.

The *Hybrid Multifractal* and *Ridged Multifractal* types have these additional settings:

Offset
Both have a "Fractal Offset" button that serves as a "sea level"
adjustment and indicates the base height of the resulting bump map.
Bump values below this threshold will be returned as zero.
Gain
Setting which determines the range of values created by the function.
The higher the number, the greater the range.
This is a fast way to bring out additional details in a texture where extremes are normally clipped off.

*****
Noise
*****

.. figure:: /images/render_blender-render_textures_procedural_noise.png

Noise Texture Panel.

Although this looks great, it is not Perlin Noise! This is a true, randomly generated Noise.
This gives a different result every time, for every frame, for every pixel.

Options
=======

There are no options for this noise.

Often used for
White noise in an animation. This is not well suited if you do not want an animation.
For material displacement or bump, use clouds instead.
Result(s)
Intensity.
.. TODO - see: https://developer.blender.org/T46281
.. TODO replace tooltip text.

*************
Ocean Texture
*************

.. figure:: /images/render_blender-render_textures_procedural_ocean.png
:align: right

Texture generated by an :doc:`/modeling/modifiers/simulate/ocean`.

Options
=======

Modifier Object
Object containing the Ocean Modifier.
Output
The data that is output by the texture.

Displacement
Output XYZ displacement in RGB channels.
Foam
Output foam (wave overlap) amount in single channel.
Eigenvalues
Positive Eigenvalues.
Eigenvector (-)
Negative Eigenvectors.
Eigenvector (+)
Positive Eigenvectors.

******
Stucci
******

.. figure:: /images/render_blender-render_textures_procedural_stucci.png

Stucci Texture Panels.

The *Stucci* texture is based on noise functions.

Often used for
Stone, Asphalt, Oranges. Normally for Bump-Mapping to create grainy surfaces.
Result(s)
Normals and Intensity.

Options
=======

Plastic / Wall In / Wall out
Plastic is the standard Stucci, while the "walls" is where Stucci gets it name.
This is a typical wall structure with holes or bumps.
Soft / Hard
There are two methods available for working with Noise.
Size
Dimension of the Noise table.
Turbulence
Depth of the *Stucci* calculations.

*******
Voronoi
*******

.. figure:: /images/render_blender-render_textures_procedural_voronoi.png

Voronoi Texture Panels.

Often used for
Very convincing Metal, especially the "Hammered" effect. Organic shaders (e.g. scales, veins in skin).
Result(s)
Intensity (default) and Color.

Options
=======

Distance Metric
This procedural texture has seven Distance Metric options.
These determine the algorithm to find the distance between cells of the texture. These options are:

- Minkovsky
- Minkovsky 4
- Minkovsky 1/2
- Chebychev
- Manhattan
- Distance Squared
- Actual Distance

The *Minkovsky* setting has a user definable value (the *Exponent* button)
which determines the Minkovsky exponent *e* of the distance function:

(*x*\ :sup:`e` + *y*\ :sup:`e` + *z*\ :sup:`e`\)\ :sup:`1/e`

A value of one produces the *Manhattan* distance metric, a value less than one produces stars
(at 0.5, it gives a *Minkovsky 1/2*), and higher values produce square cells (at 4.0,
it gives a *Minkovsky 4*, at 10.0, a *Chebychev*).
So nearly all Distance Settings are basically the same -- a variation of *Minkowsky*.

You can get irregularly-shaped rounded cells with the
*Actual Distance* / *Distance Squared* options.

.. list-table::

* - .. figure:: /images/render_blender-render_textures_procedural_voronoi_minkovsky0_5.jpg
:width: 200px

Minkovsky Exponent: 0.5 (Minkovsky 1/2).

- .. figure:: /images/render_blender-render_textures_procedural_voronoi_minkovsky1.jpg
:width: 200px

Minkovsky Exponent: 1 (Manhattan).

- .. figure:: /images/render_blender-render_textures_procedural_voronoi_minkovsky2.jpg
:width: 200px

Minkovsky Exponent: 2 (Actual Distance).

* - .. figure:: /images/render_blender-render_textures_procedural_voronoi_minkovsky4.jpg
:width: 200px

Minkovsky Exponent: 4 (Minkovsky 4).

- .. figure:: /images/render_blender-render_textures_procedural_voronoi_minkovsky10.jpg
:width: 200px

Minkovsky Exponent: 10 (Chebychev).

- .. figure:: /images/render_blender-render_textures_procedural_voronoi_distancesquared.jpg
:width: 200px

Distance Squared (More contrast than Actual Distance).

Feature Weights
These four sliders at the bottom of the Voronoi panel represent the values of the four Worley constants,
which are used to calculate the distances between each cell in the texture based on the distance metric.
Adjusting these values can have some interesting effects on the end result...

.. (no gallery yet) Check the Samples Gallery for some examples of these settings and what textures they produce.

Coloring
Four settings (*Intensity*, *Position*, *Position and Outline*, and *Position, Outline, and Intensity*)
that can use four different noise basis as methods to calculate color and intensity of the texture output.
This gives the Voronoi texture you create with the "Worley Sliders"
a completely different appearance and is the equivalent of the noise basis setting found on the other textures.

****
Wood
****

.. figure:: /images/render_blender-render_textures_procedural_wood.png

Wood Texture Panels.

Often used for
Woods and ring-shaped patterns.
Result(s)
Intensity only.

Options
=======

Noise Basis
Shape of wave to produce bands

Sine, Saw, Triangle
Wood Type
Set the bands to either straight or ring-shaped, with or without turbulence.

Bands, Rings, Band Noise, Ring Noise
Noise Type
There are two methods available for the Noise function

Soft, Hard
Size
Dimension of the Noise table
Turbulence
Turbulence of the Band Noise and Ring Noise types

#######################
Volumetric Textures
#######################

.. toctree::
:maxdepth: 2

voxel_data.rst
point_density.rst
..    TODO/Review: {{review|partial=X|im=examples}}.

*********************
Point Density Texture
*********************

Point density renders a given point cloud (object vertices or particle system) as a 3D volume,
using a user-defined radius for the points. Internally,
the system uses a BVH data structure for fast range lookups.

The rendered points are spherical by default, with various smooth falloff options,
as well as simple Turbulence options for displacing the result with noise, adding fine detail.
When using Point Density with a particle system,
additional particle info such as particle velocity, age, and speed,
can be visualized using a color/alpha ramp gradient.

Options
=======

.. figure:: /images/render_blender-render_textures_volume_point-density.png

Point Density panel.

Point Data
Particle System
Particle System, Generate point density from a particle system.
Object Vertices
Object Vertices, Generate point density from an object's vertices.

Object
Object to tak epoint data from.
Radius
Radius of the points.

System
Particle system to use.

Falloff
Standard
Todo.
Smooth
Todo.
Soft
Todo.
Softness
Todo.
Constant
Todo.
Density is constant within lookup radius.
Root
Todo.
Particle Age
Todo.
Particle Velocity
Todo.
Velocity Scale
Todo.

Falloff Curve
Use a custom falloff.

Cache
Coordinate system to cache particles in.

Global Space
Todo.
Emit Object Space
Todo.
Emit Object Location
Todo.

Color Source
Data to derive the color results from.

Constant
Constant color
Particle Color Sources
Particle Age
Lifetime mapped as 0.0 - 1.0 intensity.
Particle Speed
Particle speed (absolute magnitude of velocity) mapped as 0.0 - 1.0 intensity.
An additional color ramp can be used to convert intensity to RGB colors.

Scale
Multiplier to bring particle speed within an acceptable range.
Particle Velocity
XYZ velocity mapped to RGB colors.

Scale
Multiplier to bring particle speed within an acceptable range.
Vertex Color Sources
Vertex Color
Use a vertex color layer for coloring the point density texture.

.. note::

Vertex colors are defined per face corner.
A single vertex can have as many different colors as faces it is part of.
The actual color of the point density texture is averaged from all vertex corners.

Vertex Weight
Use a weights from a vertex group as intensity values.
An additional color ramp can be used to convert intensity to RGB colors.
Vertex Normals
Use object-space vertex normals as RGB values.

Turbulence
----------

.. figure:: /images/render_blender-render_textures_volume_point-density-turbulence.png

Turbulence panel.

Adds directed noise to the density at render time.

Influence
Method for driving added turbulent noise.

Static
Noise patterns will remain unchanged, faster and suitable for stills.
Particle Velocity
Turbulent noise driven by particle velocity.
Particle Age
Turbulent noise driven by the particle's age between birth and death.
Global Time
Turbulent noise driven by the global current frame.

Noise Basis
See :doc:`Here &lt;/render/blender_render/textures/types/procedural/introduction&gt;`.

Size
Scale of the turbulent noise.
Depth
Level of detail in the added turbulent noise.
Turbulence Strength
Strength of the added turbulent noise.
..    TODO/Review: {{review|partial=X|text=elaborate|im=needs images}}.

**********
Voxel Data
**********

Voxel data renders a voxel source, working very similarly to an image texture, but in 3D.
Various input data source types are available (such as smoke voxel data, or external files),
as well as various interpolation methods.

The default voxel data source, Smoke, is used for rendering smoke simulations.
Other sources include binary raw formats, and Image Sequence,
which can be used to stack a sequence of images into a 3D representation,
which is a common format for medical volume data such as CT scans.

Settings
========

.. figure:: /images/render_blender-render_textures_volume_voxel-data.png

Voxel Data panel.

File Format
Blender Voxel
Default binary voxel file format.
8 bit RAW
8 bit grayscale binary data.
Image Sequence
Generate voxels from a sequence of image slices.
Smoke
Render voxels from a Blender smoke simulation.

Source Path
The external source data file to use for 8 bit Raw data and Blender Voxel formats.

Domain Object (Smoke)
Object used as the smoke simulation domain.

Source
Smoke
Use smoke density and color as texture data.
Flame
Use flame temperature as texture data.
Heat
Use smoke heat as texture data. Values from -2.0 to 2.0 are used.
Velocity
Use smoke velocity as texture data.

Resolution
Resolution of the voxel grid when using 8 bit Raw data.

Interpolation
Nearest Neighbor
No interpolation, fast but blocky and low quality.
Linear
Good smoothness and speed.
Quadratic
Mid-range quality and speed.
Cubic Catmull-Rom
Smoothed high quality interpolation, but slower.

Extension
Extend
Extend by repeating edge pixels of the image.
Clip
Clip to image size and set exterior pixels as transparent.
Repeat
Cause the image to repeat horizontally and vertically.

Intensity
Multiplier for intensity values.
..    TODO/Review: {{review|partial=X}}.

********************
Environment Lighting
********************

Environment light provides light coming from all directions.

Light is calculated with a ray-traced method which is the same as that used by Ambient
Occlusion. The difference is that Environment lighting takes into account the "ambient"
parameter of the material shading settings,
which indicates the amount of ambient light/color that that material receives.

.. figure:: /images/lighting-el.jpg

Environment Lighting panel.

Also, you can choose the environment color source (white, sky color, sky texture)
and the light energy.

Energy
Defines the strength of environment light.
Environment Color
Defines where the color of the environment light comes from.

Using both settings simultaneously produces better global lighting.

It is good for mimicking the sky in outdoor lighting.
Environment lighting can be fairly noisy at times.
..    TODO/Review: {{review|}}.

*****************
Ambient Occlusion
*****************

Ambient Occlusion is a sophisticated ray-tracing calculation which simulates soft global
illumination shadows by faking darkness perceived in corners and at mesh intersections,
creases, and cracks, where ambient light is occluded, or blocked.

There is no such thing as AO in real life; AO is a specific not-physically-accurate
(but generally nice-looking) rendering trick.
It basically samples a hemisphere around each point on the face,
sees what proportion of that hemisphere is occluded by other geometry,
and shades the pixel accordingly.

It is got nothing to do with light at all; it is purely a rendering trick that tends to look
nice because generally in real life surfaces that are close together (like small cracks)
will be darker than surfaces that do not have anything in front of them, because of shadows,
dirt, etc.

The AO process, though, approximates this result;
it is not simulating light bouncing around or going through things.
That is why AO still works when you do not have any lights in the scene,
and it is why just switching on AO alone is a very bad way of "lighting" a scene.

You must have ray tracing enabled as a *Render* panel option in the
*Shading* section for this to work.

You must have an ambient light color set as you desire. By default, the ambient light color
(world) is black, simulating midnight in the basement during a power outage.
Applying that color as ambient will actually darken all colors.
A good outdoor mid-day color is RGB(0.9, 0.9, 0.8)
which is a whitish yellow sunny kind of color on a bright-but-not-harshly-bright day.

Options
=======

.. figure:: /images/render_blender-render_world_ambient-occlusion.png

The World panel with ambient color sliders highlighted.

Factor
The strength of the AO effect, a multiplier for addition.

Ambient Occlusion is composited during the render. Two blending modes are available:

Add
The pixel receives light according to the number of non-obstructed rays.
The scene is lighter. This simulates global illumination.
Multiply
Ambient occlusion is multiplied over the shading, making things darker.

.. note::

If *Multiply* is chosen, there must be other light sources; otherwise the scene will be pitch black.
In the other two cases the scene is lit even if no explicit light is present, just from the AO effect.
Although many people like to use AO alone as a quick shortcut to light a scene,
the results it gives will be muted and flat, like an overcast day. In most cases,
it is best to light a scene properly with Blender's standard lamps, then use AO on top of that,
set to *Multiply*, for the additional details and contact shadows.

The *Gather* panel contains settings for the ambient occlusion quality.
Note that these settings also apply to Environment Lighting and Indirect Lighting.

Ambient occlusion has two main methods of calculation:
*Raytrace* and *Approximate*.

Gather
------

Raytrace
^^^^^^^^

.. figure:: /images/render_blender-render_world_ambient-occlusion_gather.png

The Ambient Occlusion panel, Raytrace method.

The *Raytrace* method gives the more accurate, but also the more noisy results.
You can get a nearly noiseless image, but at the cost of render time... It is the only option if
you want to use the colors of your sky's texture.

Attenuation
Length of rays defines how far away other faces may be and still have an occlusion effect.
The longer this distance, the greater impact that far-away geometry will have on the occlusion effect.
A high *Distance* value also means that the renderer has to search a greater area for geometry that occludes,
so render time can be optimized by making this distance as short as possible for the visual effect that you want.

.. rubric:: Sampling

Sampling Method
Constant QMC
The base Quasi-Monte Carlo, gives evenly and randomly distributed rays.
Adaptive QMC
An improved method of QMC,
that tries to determine when the sample rate can be lowered or the sample skipped, based on its two settings:

Threshold
The limit below which the sample is considered fully occluded ("black")
or un-occluded ("white"), and skipped.
Adapt to Speed
A factor to reduce AO sampling on fast-moving pixels.
As it uses the *Vector* render pass, that must also be enabled
(see :doc:`render passes page &lt;/render/post_process/layers&gt;`).

.. note:: About QMC

See also the
:ref:`raytraced shadows page &lt;render-blender-internal-quasi-monte-carlo&gt;`
for more info about the Quasi-Monte Carlo sampling method.

Constant Jittered
The historical sample method, more prone to "bias" artifacts...

Bias
The angle (in radians) the hemisphere will be made narrower
(i.e. the hemisphere will no longer be a real hemisphere: its section will no longer be a semicircle,
but an arc of a circle of: pi - *bias* radians).

The bias setting allows you to control how smooth "smooth" faces will appear in AO rendering.
Since AO occurs on the original faceted mesh,
it is possible that the AO light makes faces visible even on objects with "smooth" on.
This is due to the way AO rays are shot, and can be controlled with the *Bias* slider.
Note that while it might even happen with QMC sampling methods,
it is much more visible with the *Constant Jittered* one and anyway,
you have no *Bias* option for QMC.

.. list-table::

* - .. figure:: /images/render_blender-render_world_ambient-occlusion_bias0-05.jpg
:width: 200px

24×24 UV Sphere with Bias: 0.05 (default).
Note the facets on the sphere's surface even though it is set to smooth.

- .. figure:: /images/render_blender-render_world_ambient-occlusion_bias0-15.jpg
:width: 200px

Raising the Bias to 0.15 removes the faceted artifacts.

Samples
The number of rays used to detect if an object is occluded.
Higher numbers of samples give smoother and more accurate results, at the expense of slower render times.
The default value of 5 is usually good for previews.
The actual number of rays shot out is the square of this number (i.e.
*Samples* at 5 means 25 rays). Rays are shot at the hemisphere according to a random pattern
(determined by the sample methods described above); this causes differences in the occlusion pattern of
neighboring pixels unless the number of shot rays is big enough to produce good statistical data.

.. list-table::

* - .. figure:: /images/render_blender-render_world_ambient-occlusion_3samples.jpg
:width: 200px

Ambient Occlusion with 3 Samples.

- .. figure:: /images/render_blender-render_world_ambient-occlusion_6samples.jpg
:width: 200px

Ambient Occlusion with 6 Samples.

- .. figure:: /images/render_blender-render_world_ambient-occlusion_12samples.jpg
:width: 200px

Ambient Occlusion with 12 Samples.

Approximate
^^^^^^^^^^^

.. figure:: /images/render_blender-render_world_ambient-occlusion_gather2.png

The Ambient Occlusion panel, Approximate method.

The *Approximate* method gives a much smoother result for the same amount of render
time, but as its name states, it is only an approximation of the *Raytrace* method,
which implies it might produce some artifacts and it cannot use the sky's texture
as the base color.

This method seems to tend to "over-occlude" the results.
You have two complementary options to reduce this problem:

Passes
Set the number of pre-processing passes, between (0 to 10) passes.
Keeping the pre-processing passes high will increase render time
but will also clear some artifacts and over-occlusions.
Error
This is the tolerance factor for approximation error
(i.e. the max allowed difference between approximated result and fully computed result).
The lower, the slower the render, but the more accurate the results...
Ranges between (0.0 to 10.0), defaults to 0.250.
Pixel Cache
When enabled, it will keep values of computed pixels to interpolate it with its neighbors.
This further speeds up the render, generally without visible loss in quality...
Correction
A correction factor to reduce over-occlusion. Ranges between (0.0 to 1.0) correction.

Common Settings
---------------

Falloff
When activated, the distance to the occluding objects will influence the "depth" of the shadow.
This means that the further away the occluding geometry is, the lighter its "shadow" will be.
This effect only occurs when the *Strength* factor is higher than 0.0.
It mimics light dispersion in the atmosphere...

Strength
Controls the attenuation of the shadows enabled with *Use Falloff*.
Higher values give a shorter shadow, as it falls off more quickly
(corresponding to a more foggy/dusty atmosphere).
Ranges from (0.0 to 10.0), default is 0.0, which means no falloff.

Technical Details
=================

Ambient occlusion is calculated by casting rays from each visible point,
and by counting how many of them actually reach the sky, and how many, on the other hand,
are obstructed by objects.

The amount of light on the point is then proportional to the number of rays which have
"escaped" and have reached the sky. This is done by firing a hemisphere of shadow rays around.
If a ray hits another face (it is occluded) then that ray is considered "shadow",
otherwise it is considered "light".
The ratio between "shadow" and "light" rays defines how bright a given pixel is.

Hints
=====

Ambient occlusion is a ray-tracing technique (at least with the *Raytrace* method), so it tends to be slow.
Furthermore, performance severely depends on octree size,
see the :doc:`rendering chapter &lt;/render/index&gt;` for more information.
..    TODO/Review: {{review|}}.

******************
Exposure and Range
******************

.. admonition:: Reference
:class: refbox

| Mode:     All modes
| Panel:    :menuselection:`Render Layer --&gt; Color management`

*Exposure* and *Range* are similar to the "Color Curves" tool in Gimp or Photoshop.

These controls affect the rendered image, and the results are baked into the render.
For information on achieving similar affects with render controls,
see :doc:`Color Management and Exposure &lt;/render/post_process/color_management&gt;`.

Previously Blender clipped color directly with 1.0 (or 255)
when it exceeded the possible RGB space.
This caused ugly banding and overblown highlights when light overflowed
Fig. :ref:`fig-bi-light-exposure-teapot`.

Using an exponential correction formula, this now can be nicely corrected.

Options
=======

.. figure:: /images/render_blender-render_world_exposure_world-panel.png

Exposure and Range sliders.

Exposure
The exponential curvature, with (0.0 to 1.0) (linear to curved).
Range
The range of input colors that are mapped to visible colors (0.0 to 1.0).

So without *Exposure* we will get a linear correction of all color values:

Range &gt; 1.0
The picture will become darker; with *Range* = 2.0,
a color value of 1.0 (the brightest by default) will be clipped to 0.5
(half bright) (*Range*: 2.0).
Range &lt; 1.0
The picture will become brighter; with *Range* = 0.5,
a color value of 0.5 (half bright by default) will be clipped to 1.0
(the brightest) (*Range*: 0.5).

Examples
========

With a linear correction every color value will get changed,
which is probably not what we want. *Exposure* brightens the darker pixels,
so that the darker parts of the image will not be changed at all
(*Range* : 2.0, *Exposure* : 0.3).

.. _fig-bi-light-exposure-teapot:

.. list-table:: Utah Teapot.

* - .. figure:: /images/render_blender-render_world_exposure_denseteapot.jpg
:width: 320px

An overexposed teapot.

- .. figure:: /images/render_blender-render_world_exposure_denseteapot-range2.jpg
:width: 320px

Range: 2.0.

* - .. figure:: /images/render_blender-render_world_exposure_denseteapot-range0_5.jpg
:width: 320px

Range: 0.5.

- .. figure:: /images/render_blender-render_world_exposure_denseteapot-range2_0-exposure0_3.jpg
:width: 320px

Range: 2.0, Exposure: 0.3.

.. hint::

Try to find the best *Range* value,
so that overexposed parts are barely not too bright. Now turn up the *Exposure*
value until the overall brightness of the image is satisfying.
This is especially useful with area lamps.
.. _world-index:

########
World
########

.. toctree::
:maxdepth: 2

introduction.rst
world_panel.rst
exposure.rst
ambient_light.rst
indirect_lighting.rst
ambient_occlusion.rst
mist.rst

*****************
Indirect Lighting
*****************

*Indirect Lighting* adds indirect light bouncing of surrounding objects.
It models the light that is reflected from other surfaces to the current surface.
Is more comprehensive, more physically correct, and produces more realistic images.
It is also more computationally expensive.
Take a look at the following examples of a scene lit with Direct Lighting and both
Direct and Indirect Lighting:

.. list-table::
Images courtesy of `rastermon.com &lt;https://web.archive.org/web/20050204031559/https://rastermon.com/GI1.htm&gt;`__.

* - .. figure:: /images/lighting-inderect_lighting-01.png

Direct Lighting Schematic.

- .. figure:: /images/lighting-inderect_lighting-02.jpg

Direct Lighting Render.

* - .. figure:: /images/lighting-inderect_lighting-03.png

Direct and Indirect Lighting Schematic.

- .. figure:: /images/lighting-inderect_lighting-04.jpg

Direct and Indirect Lighting Render.

Indirect Lighting only works with Approximate gather method.

.. figure:: /images/lighting-inderect_lighting.png
:width: 300px

Indirect Lighting parameters.

Options
=======

The *Indirect Lighting* panel contains two options:

Factor
Defines how much surrounding objects contribute to light.

Bounces
Number of indirect diffuse light bounces.

The *Gather* panel contains settings for the indirect lighting quality.
Note that these settings also apply to Environment Lighting and Ambient Occlusion.

Approximate
-----------

.. figure:: /images/render_blender-render_world_ambient-occlusion_gather2.png

The Indirect Lighting panel, Approximate method.

The *Approximate* method gives a much smoother result for the same amount of render
time, but as its name states, it is only an approximation of the *Raytrace* method,
which implies it might produce some artifacts
and it cannot use the sky's texture as the base color.

This method seems to tend to "over-occlude" the results.
You have two complementary options to reduce this problem:

Passes
Set the number of pre-processing passes, between (0 to 10) passes.
Keeping the pre-processing passes high will increase render time, but will also
clear some artifacts and over-occlusions.
Error
This is the tolerance factor for approximation error (i.e.
the max allowed difference between approximated result and fully computed result).
The lower, the slower the render, but the more accurate the results...
Ranges between (0.0 to 10.0), defaults to 0.250.

Pixel Cache
When enabled, it will keep values of computed pixels to interpolate it with its neighbors.
This further speeds up the render, generally without visible loss in quality...

Correction
A correction factor to reduce over-occlusion. Ranges between (0.0 to 1.0) correction.
..    TODO/Review: {{review|partial=X|text=
missing some words on options that are explain in lighting and no explanation about Gather}}.

************
Introduction
************

.. figure:: /images/render_blender-render_world_introduction_world-panel.png

World tab.

The world buttons let you set up the shading of your scene in general.
It can provide ambient color, and special effects such as mist,
but a very common use of a *World* is to shade a background color.

These are accessible via the *World* tab.

You have:

:doc:`Background &lt;/render/blender_render/world/world_panel&gt;`
The color and texture of the world background, with special settings for mapping coordinates.
:doc:`Mist &lt;/render/blender_render/world/mist&gt;`
Add a mist to your scene to enhance the feeling of depth.

While these world settings offers a simple way of adding effects to a scene,
:doc:`compositing nodes &lt;/compositing/index&gt;` are often preferred, though more complex to master,
for the additional control and options they offer.
For example, filtering the Z value (distance from camera) or normals (direction of surfaces)
through compositing nodes can further increase the depth and spacial clarity of a scene.

****
Mist
****

Mist can greatly enhance the illusion of depth in your rendering. To create mist,
Blender makes objects farther away more transparent (decreasing their Alpha value)
so that they mix more of the background color with the object color. With Mist enabled,
the further the object is away from the camera the less its alpha value will be.

Option
======

.. figure:: /images/render_blender-render_world_mist-panel.png
:width: 305px

Mist panel.

Mist check box
Toggles mist on and off.
Minimum
An overall minimum intensity, or strength, of the mist.
Start
The distance from the camera at which the mist starts to fade in
Depth
The distance from *Start* of the mist, that it fades in over.
Objects further from the camera than *Start + Depth* are completely hidden by the mist.
Height
Makes the mist intensity decrease with height, for a more realistic effect.
If greater than 0, it sets, in Blender units,
an interval around z=0 in which the mist goes from maximum intensity (below) to zero (above).
Falloff
The decay rate of the mist (*Quadratic*, *Linear*, *Inverse Quadratic*).
These settings control the rate of change of the mist's strength further and further into the distance.

.. note:: Mist distances

To visualize the mist distances in the 3D View, select your camera, go to the camera menu, and enable *Show Mist*.

The camera will show mist limits as a line projecting from the camera starting from
*Start* and of distance *Depth*.

To get a better view to evaluate the *Mist* visualization,
:kbd:`Shift-Numpad1` with the camera selected and
:kbd:`Numpad5` to toggle perspective view on and off.
This will place the 3D View right over the camera looking down.

Transparency
============

Because *Mist* works by adjusting transparency,
this can sometimes cause objects to be partially transparent when they should not be.
One workaround is to set the Mist settings as desired, but turn Mist off.
The Mist data is still available for compositing even though it is off.
Use :doc:`Do Composite &lt;/compositing/index&gt;`
and the :doc:`Node Editor &lt;/editors/node_editor/index&gt;` to feed the Mist pass to an
:doc:`Alpha Over &lt;/compositing/types/color/alpha_over&gt;` to blend the background color
(or a render layer with just the sky) with the rendered image.
This produces the mist effect but since Mist is off the object transparency (or lack of) is preserved.

Examples
========

.. figure:: /images/render_blender-render_world_mist-example1.jpg

Mist example.

In this example (`blend-file &lt;https://wiki.blender.org/index.php/:File:25-Manual-World-Mist-Example1.blend&gt;`__)
the :menuselection:`Mist --&gt; Height` options has been limited to create smoke covering the floor.

***********
World panel
***********

World
The World :ref:`ui-data-block`.
Texture Count
Shows the count of textures in the world texture stack.

.. note:: Background Image in 3D

To use an image as a background image in your 3D View,
for example as a reference when doing a model,
see :doc:`using a Background Image &lt;/editors/3dview/properties/background_images&gt;`

Preview
=======

Shows a view inside a sphere, on which the background textures are mapped.

World (Background)
==================

.. figure:: /images/render_blender-render_world_background_world-panel.png

World panel.

Sky
---

How colors below are interpreted depends on which kind of *Sky* is chosen.

None Enabled
If none of these three buttons is checked, your background will just be plain flat color (using the horizon one).
Paper Sky
If this option is added, the gradient keeps its characteristics, but it is clipped in the image
(it stays on a horizontal plane (parallel to XY plane): what ever the angle of the camera may be,
the horizon is always at the middle of the image).
Blend Sky
The background color is blended from horizon to zenith. If only this button is pressed,
the gradient runs from the bottom to the top of the rendered image regardless of the camera orientation.
Real Sky
If this option is added, the gradient produced has two transitions, from nadir (same color as zenith)
to horizon to zenith; the blending is also dependent on the camera orientation, which makes it more realistic.
The horizon color is exactly at the horizon (on the XY plane),
and the zenith color is used for points vertically above and below the camera.

.. seealso::

When using a *Sun Lamp* options for
:doc:`/render/blender_render/lighting/lamps/sun/sky_and_atmosphere` are available in the *Lamp* tab.

Colors
------

Horizon Color
The RGB color at the horizon.
Zenith Color
The RGB color at the zenith (overhead).
Ambient Color
:term:`Ambient Light`. See also :doc:`/render/blender_render/world/indirect_lighting`.

Exposure and Range
------------------

See :doc:`/render/blender_render/world/exposure`.

.. _bi-world-texture:

Textures
========

Mapping
-------

Instead of a color, or blend of two colors, Blender can use an 2D image which it maps to a
very large Box or sphere which encompasses the entire scene,
or which it maps to a virtual space around the scene.

The World textures are accessible in the texture menu (just select *World* first,
then *Texture*. They are used much like the Materials textures,
except for a couple of differences. The textures can be mapped according to:

.. figure:: /images/render_blender-render_world_background_texture-coordinates.png
:align: right

Texture Coordinates select menu.

Texture Coordinates
View
The default orientation, aligned with the co-ordinates of the final render.
Global
Uses global coordinates.
Angular Map
Used to wrap a standard hemisphere angular map around the scene in a dome.
This can be used for image based lighting with *Ambient Occlusion* set to sky color.
You will generally need a high dynamic range image (HDRI) angular map.
(It will look like a weird spherical image).
Sphere
Sphere mapping, similar to that of materials.
Tube
Wrap the rectangular texture around in a cylinder, similar to that of materials.
Object
Position the texture relative to a specified object's local texture space.

Influence
---------

.. figure:: /images/render_blender-render_world_background_texture-influence.png

Texture Influence panel.

The texture affects color only, but in four different ways:

Blend
Makes the Horizon color appear where the texture is non-zero.
Horizon
Affect the color of the horizon.
Zenith Up
Affect the zenith color overhead.
Zenith Down
Affect the zenith color underneath.

If you are disappointed that your camera appears to carry the texture with it rather than
rotate through the texture,
you should check the Real Sky checkbox in the World panel.

*************
Render Baking
*************

Refer to the Blender Render page for :doc:`general baking guidelines &lt;/render/blender_render/bake&gt;`

Cycles uses the render settings (samples, bounces, ...) for baking.
This way the quality of the baked textures should match the result you get from the rendered scene.

The baking happens into the respective active textures of the object materials.
The active texture is the last selected Image Texture node of the material node tree.
That means the active object (or the selected objects, when not baking 'Selected to Active') needs a material,
and that material needs at least an Image Texture node, with the image to be used for the baking.
Note, the node does not need to be connected to any other node.
The active texture is what projection painting and the viewport use as a criteria to which image to use.
This way after the baking is done you can automatically preview the baked result in the Texture mode.

Options
=======

.. figure:: /images/cycles-bake-ao.png

Ambient Occlusion Pass.

Bake Mode
---------

Combined
Bakes all materials, textures, and lighting except specularity.

.. figure:: /images/cycles-bake-combined.png

Combined Pass Options.

The passes that contribute to the combined pass can be toggled individually to form the final map.
Ambient Occlusion
Bakes ambient occlusion as specified in the World panels. Ignores all lights in the scene.
Shadow
Bakes shadows and lighting.
Normals
Bakes normals to an RGB image.

.. figure:: /images/cycles-bake-normal.png

Normal Pass Options.

Normal Space
Normals can be baked in different spaces:

Object space
Normals in object coordinates, independent of object transformation, but dependent on deformation.
Tangent space
Normals in tangent space coordinates, independent of object transformation and deformation.
This is the default, and the right choice in most cases, since then the normal map can be used for animated
objects too.
Normal Swizzle
Axis to bake into the red, green and blue channel.

For materials the same spaces can be chosen in the image texture options next to the existing *Normal Map*
setting. For correct results, the setting here should match the setting used for baking.

UV
Bakes colors of materials and textures only, without shading.
Emit
Bakes Emission, or the Glow color of a material.
Environment
Bakes the environment as seen from the center of the object.
Diffuse, Glossy, Transmission, Subsurface
Bakes the diffuse, glossiness, transmission of subsurface pass of a material.

.. figure:: /images/cycles-bake-diffuse.png

Diffuse Pass Options.

- If only color is selected you get the pass color,
which is a property of the surface and independent of sampling refinement.
- If color is not selected, you get the direct and/or indirect contributions in grayscale.
- If color and either direct or indirect is selected you get the direct and/or indirect contributions colored.

Additional Options
==================

Margin
Baked result is extended this many pixels beyond the border of each UV "island," to soften seams in the texture.
Clear
If selected, clears the image before baking render.
Select to Active
Bake shading on the surface of selected objects to the active object.
The rays are cast from the lowpoly object inwards towards the highpoly object.
If the highpoly object is not entirely involved by the lowpoly object, you can tweak the rays start point with
*Ray Distance* or *Cage Extrusion* (depending on whether or not you are using cage).
For even more control you can use a *Cage Object*.

.. note:: Memory Usage

There is a CPU fixed memory footprint for every object used to bake from.
In order to avoid crashes due to lack of memory the highpoly objects can be joined before the baking process.
The render tiles parameter also influence the memory usage, so the bigger the tile the less overhead you have,
but the more memory it will take during baking (either in GPU or CPU).

Cage
Cast rays to active object from a cage.
A cage is a ballooned-out version of the lowpoly mesh created either automatically
(by adjusting the ray distance) or manually (by specifying an object to use).
When not using a cage the rays will conform to the mesh normals. This produces glitches on the edges,
but it is a preferable method when baking into planes to avoid the need of adding extra loops around the edges.
Ray Distance
Distance to use for the inward ray cast when using selected to active.
Ray distance is only available when not using *Cage*.
Cage Extrusion
Distance to use for the inward ray cast when using *Selected to Active* and *Cage*.
The inward rays are casted from a version of the active object with disabled Edge Split Modifiers.
Hard splits (e.g., when the Edge Split Modifier is applied) should be avoided because they will lead to non-smooth
normals around the edges.
Cage
Object to use as cage instead of calculating the cage from the active object with the *Cage Extrusion*.

.. note::

When the base mesh extruded does not give good results,
you can create a copy of the base mesh and modify it to use as a *Cage*.
Both meshes need to have the same :term:`topology` (number of faces and face order).

******
Camera
******

Lens
====

Type
----

Perspective
^^^^^^^^^^^

Focal Length/Field of View
Control the field of view set by lens property or by angle as selected in the *Lens Unit* menu.

.. figure:: /images/cycles_camera_persp.png
:width: 300px

.. hint:: Dolly Zoom

While the camera is moving towards an object the *Focal Length* property can be decreased
to produce a *Dolly Zoom* camera effect, or vice versa.

`This video &lt;https://vimeo.com/15837189&gt;`__ demos the *Dolly Zoom* camera effect.

Orthographic
^^^^^^^^^^^^

Scale
Controls the size of objects projected on the image.

.. figure:: /images/cycles_camera_ortho.png
:width: 300px

.. _cycles-panoramic-camera:

Panoramic
^^^^^^^^^

Cycles supports Equirectangular and Fisheye panoramic cameras.
Note that these cannot be displayed with OpenGL rendering in the view-port;
they will only work for rendering.

Equirectangular
"""""""""""""""

Render a panoramic view of the scenes from the camera location and use an equirectangular projection,
always rendering the full 360° over the X-axis and 180° over the Y-axis.

This projection is compatible with the environment texture as used for world shaders,
so it can be used to render an environment map. To match the default mapping,
set the camera object rotation to (90, 0, -90) or pointing along the positive X-axis. This
corresponds to looking at the center of the image using the default environment texture
mapping.

Minimum/Maximum Latitude/Longitude
Limits of the vertical and horizontal field of view angles.

Fisheye
"""""""

Fisheye lenses are typically wide angle lenses with strong distortion,
useful for creating panoramic images for e.g. dome projection, or as an artistic effect.

The *Fisheye Equisolid* lens will best match real cameras.
It provides a lens focal length and field of view angle,
and will also take the sensor dimensions into account.

The *Fisheye Equidistant* lens does not correspond to any real lens model; it will
give a circular fish-eye that does not take any sensor information into account but rather uses
the whole sensor. This is a good lens for full dome projection.

Lens
Lens focal length in millimeter.
Field of View
Field of view angle, going to 360 and more to capture the whole environment.

Mirror Ball
"""""""""""

ToDo.

.. _render-cycles-camera-clipping:

Clipping
--------

Clip Start and End
The interval in which objects are directly visible,
Any objects outside this range still influence the image indirectly,
as further light bounces are not clipped.

When *Limits* in the *Display* panel is enabled,
the clip bounds will be visible as two yellow connected dots on the camera line of sight.

.. tip::

Changing the clipping value can have a serious impact on render performance.
It is important to always set the *Start* and *End* values to a safe distance that is both not too extreme,
nor too small to have the best possible render times.

.. seealso::

- :ref:`Blender Render Camera Clipping &lt;camera-clipping&gt;`.
- :doc:`3D View clipping &lt;/editors/3dview/properties/panels&gt;`.

Depth of Field
==============

.. figure:: /images/render_cycles_camera_depth-of-field-panel.png

Focus
-----

Object
Set an object to be used as a focal point by the camera, causing the camera
to focus on the selected object origin.
Distance
When an *Focus* object is not used, the camera can be set to focus on an area in 3D
space set by the distance from the camera.
Using the *Limit* Display option, you are able to view the distance in the 3D space.

Viewport
--------

High Quality
Enables the High Quality *view-port* depth of field, giving a more accurate
representation of *depth of field*. This allows the view-port depth of field
to be closely represented to that of the render and render preview depth of field.
F-Stop
Viewport depth of field aperture measured in F-Stops. Smaller numbers will
cause more blur in the view-port, OpenGL renders, and sequencer.
Blades
The number of polygonal sides to give blurred objects in the view-port.
The minimum number of blades needed to enable the bokeh effect is 3 (triangle).
(Only available with High Quality).

Aperture
--------

Aperture type
Use F-Stop or Radius to set the aperture for the render, and render preview.
F-Stop is the focal ratio, where Radius is the radius of the focal point.
Size/Number
Aperture radius *size*, or F-Stop *number* used for the render, and render preview.
Using the F-Stop with a low number, or Radius with a large size will result in a strong blur,
also allowing the use of the *bokeh effect*.
Blades
Total number of polygonal blades used to alter the shape of the blurred objects
in the render, and render preview. As with the view-port, the minimum amount of
blades to enable the bokeh effect is 3, resulting in a triangle shaped blur.
Rotation
Rotate the polygonal blades along the facing axis, and will rotate in a clockwise,
and counter-clockwise fashion.
Ratio
Change the amount of distortion to simulate the anamorphic bokeh effect.
A setting of 1.0 shows no distortion, where a number below 1.0 will cause a horizontal distortion,
and a higher number will cause a vertical distortion.

.. figure:: /images/cycles_camera_dof_bokeh.jpg

.. seealso:: Switching between Cameras

By :ref:`binding the camera to markers &lt;marker-bind-camera&gt;`.
.. |tick|  unicode:: U+2714
.. |cross| unicode:: U+2717

***************
Render Features
***************

This page offers a comparison of available features on CPU, CUDA and OpenCL.

.. list-table::
:header-rows: 1

* - Feature
- CPU
- CUDA (NVIDIA GPU)
- OpenCL (AMD GPU)
* - :abbr:`Basic Shading (Includes Node Shaders and Textures, Ambient Occlusion, Global Illumination...)`
- |tick|
- |tick|
- |tick|
* - Transparent Shadows
- |tick|
- |tick|
- |tick|
* - Motion Blur
- |tick|
- |tick|
- |tick|
* - Hair
- |tick|
- |tick|
- |tick|
* - Volume
- |tick|
- |tick|
- |tick|
* - Smoke / Fire
- |tick|
- |tick|
- |tick|
* - Subsurface Scattering
- |tick|
- |tick|
- |tick|
* - Open Shading Language
- |tick|
- |cross|
- |cross|
* - CMJ sampling
- |tick|
- |tick|
- |tick|
* - Branched Path integrator
- |tick|
- |tick|
- |tick|
* - Displacement/Subdivision
- |tick| :sup:`(experimental)`
- |tick| :sup:`(experimental)`
- |tick| :sup:`(experimental)`

.. _cycles-experimental-features:

Experimental Features
=====================

Experimental features are disabled / hidden by default,
but can be enabled by setting *Feature Set* to *Experimental* in the Render properties.
Enabling the *Experimental Feature Set* will use experimental
and incomplete features that might be broken or change in the future.

.. figure:: /images/render_cycles_features_experimental.png
.. _render-cycles-gpu-rendering:

*************
GPU Rendering
*************

Introduction
============

:abbr:`GPU (Graphics Processing Unit)` rendering makes it possible to use your
graphics card for rendering, instead of the CPU.
This can speed up rendering, because modern GPUs are designed to do quite a lot of number crunching.
On the other hand, they also have some limitations in rendering complex scenes, due to more limited memory,
and issues with interactivity when using the same graphics card for display and rendering.

Cycles has two GPU rendering modes: *CUDA*,
which is the preferred method for Nvidia graphics cards; and *OpenCL*,
which supports rendering on AMD graphics cards.

Configuration
=============

To enable GPU rendering, go into the User Preferences, and under the System tab,
select the Compute Device(s) to use. Next, for each scene,
you can configure to use CPU or GPU rendering in the Render properties.

CUDA
----

Nvidia :abbr:`CUDA (Compute Unified Device Architecture)`
is supported for GPU rendering with *Nvidia* graphics cards.
We support graphics cards starting from GTX 4xx (computing capability 2.0).

Cycles requires recent Nvidia drivers to be installed, on all operating systems.

`List of CUDA cards with shader model &lt;https://developer.nvidia.com/cuda-gpus&gt;`__.

OpenCL
------

:abbr:`OpenCL (Open Computing Language)` is supported for GPU
rendering with *AMD* graphics cards.
We only support graphics cards with :abbr:`GCN (Graphics Core Next)` architecture (HD 7xxx and above).
Not all HD 7xxx cards are GCN cards though, you can check if your card is
`here &lt;https://en.wikipedia.org/wiki/List_of_AMD_graphics_processing_units&gt;`__.

Cycles requires recent AMD drivers to be installed, on all operating systems.

Supported Features and Limitations
==================================

For an overview of supported features, check the comparison in the
:doc:`Features &lt;/render/cycles/features&gt;`.

CUDA limitations:
The maximum amount of individual textures is limited to 88 byte-image textures (``PNG``, ``JPEG``, ..)
and 5 float-image textures (``OpenEXR``, 16 bit ``TIFF``, ..) on GTX 4xx/5xx cards.
Newer cards do not have this limit.

Frequently Asked Questions
==========================

Why is Blender unresponsive during rendering?
---------------------------------------------

While a graphics card is rendering, it cannot redraw the user interface, which makes Blender unresponsive.
We attempt to avoid this problem by giving back control over the GPU as often as possible,
but a completely smooth interaction cannot be guaranteed, especially on heavy scenes.
This is a limitation of graphics cards for which no true solution exists,
though we might be able to improve this somewhat in the future.

If possible, it is best to install more than one GPU,
using one for display and the other(s) for rendering.

Why does a scene that renders on the CPU not render on the GPU?
---------------------------------------------------------------

There maybe be multiple causes,
but the most common is that there is not enough memory on your graphics card.
We can currently only render scenes that fit in graphics card memory,
and this is usually smaller than that of the CPU. Note that, for example, 8k, 4k,
2k and 1k image textures take up respectively 256MB, 64MB, 16MB and 4MB of memory.

We do intend to add a system to support scenes bigger than GPU memory,
but this will not be added soon.

Can multiple GPUs be used for rendering?
----------------------------------------

Yes, go to :menuselection:`User Preferences --&gt; System --&gt; Compute Device Panel`, and configure it as you desire.

Would multiple GPUs increase available memory?
----------------------------------------------

No, each GPU can only access its own memory.

What renders faster, Nvidia or AMD, CUDA or OpenCL?
---------------------------------------------------

Currently Nvidia with CUDA is rendering faster. There is no fundamental reason why this should
be so, because we do not use any CUDA specific features, but the compiler appears to be more mature,
and can better support big kernels.
OpenCL support is still in an early stage and has not been optimized as much.

Error Messages
==============

Unsupported GNU version! gcc 4.7 and up are not supported!
----------------------------------------------------------

On Linux, depending on your GCC version you might get this error.

If so, delete the following line in ``/usr/local/cuda/include/host_config.h``

::

#error -- unsupported GNU version! gcc 4.7 and up are not supported!

CUDA Error: Invalid kernel image
--------------------------------

If you get this error on MS-Windows 64-bit, be sure to use the 64-bit build of Blender,
not the 32-bit version.

CUDA Error: Kernel compilation failed
-------------------------------------

This error may happen if you have a new Nvidia graphics card that is not yet supported by
the Blender version and CUDA toolkit you have installed.
In this case Blender may try to dynamically build a kernel for your graphics card and fail.

In this case you can:

#. Check if the latest Blender version (official or `experimental builds
&lt;https://builder.blender.org/download/experimental/&gt;`_) supports your graphics card.
#. If you build Blender yourself, try to download and install a newer CUDA developer toolkit.

Normally users do not need to install the CUDA toolkit as Blender comes with precompiled kernels.

CUDA Error: Out of memory
-------------------------

This usually means there is not enough memory to store the scene on the GPU.
We can currently only render scenes that fit in graphics card memory,
and this is usually smaller than that of the CPU. See above for more details.

The Nvidia OpenGL driver lost connection with the display driver
----------------------------------------------------------------

If a GPU is used for both display and rendering,
MS-Windows has a limit on the time the GPU can do render computations.
If you have a particularly heavy scene, Cycles can take up too much GPU time.
Reducing Tile Size in the Performance panel may alleviate the issue,
but the only real solution is to use separate graphics cards for display and rendering.

Another solution can be to increase the timeout,
although this will make the user interface less responsive when rendering heavy scenes.
`Learn More Here &lt;https://msdn.microsoft.com/en-us/Library/Windows/Hardware/ff570087%28v=vs.85%29.aspx&gt;`__.

CUDA error: Unknown error in cuCtxSynchronize()
-----------------------------------------------

An unknown error can have many causes, but one possibility is that it is a timeout.
See the above answer for solutions.
.. _bpy.types.Cycles:

#######################
Cycles Render Engine
#######################

.. toctree::
:titlesonly:
:maxdepth: 2

introduction.rst
materials/index.rst
lamps.rst
world.rst
nodes/index.rst
camera.rst
features.rst
settings/index.rst
gpu_rendering.rst
baking.rst
optimizations/index.rst

************
Introduction
************

.. figure:: /images/cycles_introduction.jpg

Cycles is Blender’s ray-tracing production render engine.

To use Cycles, it must be set as the active render engine in the top header. Once that is done,
interactive rendering can be started by setting a 3D View editor to draw mode Rendered using :kbd:`Shift-Z`.
The render will keep updating as modifications are done,
such as changing a material color, changing a lamp's intensity or moving objects around.
To perform a full render go to :menuselection:`Properties --&gt; Render`
here you can either choose to render a still image or an :doc:`Animation &lt;/render/workflows/animations&gt;`.

Cycles may be able to use your :abbr:`GPU (Graphics Processing Unit, or Graphics Card)` to render.
To see if and how you can use your GPU for rendering, see the documentation on
:doc:`GPU Rendering &lt;/render/cycles/gpu_rendering&gt;`.

.. note:: Cycles Outside of Blender

Since its release under a permissive open-source (Apache 2.0) license,
it’s also in use by other 3D tools, such as Poser and Rhino.
Cycles can be used as part of Blender and as stand-alone,
making it a flexible solution for ray-traced rendering.

.. seealso::

- Blender.org's `Cycles Gallery &lt;https://www.blender.org/features/cycles&gt;`__
showing examples of what Cycles can render.
- `Developer documentation &lt;https://wiki.blender.org/index.php/Dev:Source/Render/Cycles&gt;`__
is available as well.

*****
Lamps
*****

Next to lighting from the background and any object with an emission shader,
lamps are another way to add light into the scene.
The difference is that they are not directly visible in the rendered image,
and can be more easily managed as objects of their own type.

Common Settings
===============

Type
Currently *Point*, *Spot*, *Area* and *Sun* lamps are supported.
*Hemi* lamps are not supported, and will be rendered as sun lamps.

.. Hemi lamps may start working in the future, so it's best not to enable them to preserve compatibility.

Size
Size of the lamp in Blender Units; increasing this will result in softer shadows and shading.
Samples
For the branch path tracing integrator, this specifies the number of direct light samples per AA sample.
Point lamps might need only one sample, while area lamps typically need more.
Max Bounces
Maximum number of times light from the lamp is allowed to :term:`bounce &lt;light bounces&gt;`.
Limited by :ref:`scene-wide bounce settings &lt;cycles-bounces&gt;`
Cast Shadow
By disabling this option, light from lamps will not be blocked by objects in-between.
This can speed up rendering by not having to trace rays to the light source.
Multiple Importance Sample
By default lamps use only direct light sampling. For area lights and sharp glossy reflections, however,
this can be noisy,
and enabling this option will enable indirect light sampling to be used in addition to reduce noise.

Lamp Types
==========

Point Lamp
----------

Point lamps emit light equally in all directions.
By setting the *Size* larger than zero, they become spherical lamps,
which give softer shadows and shading. The strength of point lamps is specified in Watts.

Spot Lamp
---------

Spot lamps emit light in a particular direction, inside a cone.
By setting the *Size* larger than zero, they can cast softer shadows and shading.
The size parameter defines the size of the cone,
while the blend parameter can soften the edges of the cone.

.. _render-cycles-lamps-area:

Area Lamp
---------

Area lamps emit light from a square or rectangular area with a Lambertian distribution.

Shape
Shape of the lamp.

Rectangle
The shape of the lamp can be represented as a rectangle and changed with the "X" and "Y" values.
Square
The shape of the lamp can be represented as a square and changed with the *Size* property.

.. _render-cycles-lamps-area-portals:

Light Portals
^^^^^^^^^^^^^

Area lamps can also function as light portals to help sample the environment light,
and significantly reduce noise in interior scenes.
Note that rendering with portals is usually slower, but as it converges more quickly, less samples are required.

Light portals work by enabling the *Portal* option, and placing areas lamps in
windows, door openings, and any place where light will enter the interior.

In outdoor scenes most rays do not bounce much and just fly off into the sky and therefore,
light portals are not helpful for outdoor scenes.

.. figure:: /images/cycles_portals2.jpg
.. figure:: /images/cycles_portals.jpg

White Room model by Jay Hardy.

Sun Lamp
--------

Sun lamps emit light in a given direction. Their position is not taken into account;
they are always located outside of the scene, infinitely far away,
and will not result in any distance falloff.

Because they are not located inside the scene, their strength uses different units,
and should typically be set to lower values than other lights.
.. _render-cycles-materials-displacement:

************
Displacement
************

The shape of the surface and the volume inside its mesh may be altered by the displacement shaders.
This way, textures can then be used to make the mesh surface more detailed.

There are two types of displacement methods that can be used: `True Displacement`_  and `Bump Mapping`_.
Depending on the settings, the displacement may be virtual,
only modifying the surface normals to give the impression of displacement,
known as bump mapping, or a combination of real and virtual displacement.

.. tip::

It is also possible to use the both method by choosing *Displacement + Bump*
in the :ref:`Material Setttings &lt;cycles-materials-settings-displace&gt;`.

.. figure:: /images/cycles_materials_displacement_example.jpg

Subdivision Rate 2, Bump, True, Both

Bump Mapping
============

When using the *Bump* method for displacement a "bump map" is used to create fake displacement
by using light and shadow effects. A bump map is actually one of the older types displacement methods
(see `True Displacement`_ for a newer method).

Typically, bump maps are grayscale images with 8-bits of color information.
This means that they only have 256 different shades of black, gray, or white.
These grayscale values are used to tell Blender two thing: up or down.

When values in a bump map are close to 50% gray, there is little to no detail that comes through on the surface.
When values get closer to white, the effect start to appear as if they are pulling out the surface.
To contrast that, when values closer to black, they appear to be pushing into the surface.

Bump maps are really great for creating tiny details on a model, for example, pores or wrinkles on skin.
Bump maps can be created in a 2D drawing,
or photo editing application just remember to save the image as a grayscale to save memory while rendering.

.. important::

Because bump mapping is a fake effect, it is easily broken when viewing a model at the wrong angle.
This means that it is not recommended for animations.

.. _render-cycles-materials-displacement-true:

True Displacement
=================

.. note::

Implementation not finished yet, marked as an :ref:`Experimental Feature Set &lt;cycles-experimental-features&gt;`

Different from bump mapping, *True Displacement* is not a fake effect.
When using *True Displacement* the actual mesh geometry will be displaced before render.
This gives the best quality results, if the mesh is finely subdivided.
As a result this method is also the most memory intensive.

When using true displacement you should not just use a bump map as the displacement texture.
Different from bump maps displacement maps should not use 8-bits when saved.
While you can use 8-bit textures, they do not translate into 3D space well.
Instead, you should save the images with either 16 or 32-bits.

.. tip::

In order to get the appropriate amount of subdivision it is recommended to use
:ref:`Adaptive Subdivision &lt;render-cycles-settings-object-subdivision&gt;`

.. seealso::

The :doc:`Displace Modifier &lt;/modeling/modifiers/deform/displace&gt;` can also be used to displace a mesh.

Controls
--------

You may find that there is a limit to using *True Displacement*
compared to using the :doc:`Displace Modifier &lt;/modeling/modifiers/deform/displace&gt;`.
However, These can be easy fixed with using a :doc:`Math Node &lt;/render/cycles/nodes/types/converter/math&gt;`.
In the example below is a node setup to give the same settings as the *Displace Modifier*.

.. figure:: /images/render_cycles_displace-true_controls.png

Math nodes used to add Mid-level and Strength.

In the example above a math node is used twice, the first math node uses the add operator.
This operation can be used to control the mid-level of the displacement.
The second math node uses the multiply operation to control how strong the displacement effect is.
Higher values would give you larger displacement and lower values give smaller displacement.

############
Materials
############

.. toctree::
:maxdepth: 2

introduction.rst
surface.rst
volume.rst
displacement.rst
settings.rst
texture_editing.rst

************
Introduction
************

Materials define the appearance of meshes, curves and other objects.
They consist of three shaders, defining the appearance of the surface of the mesh,
the volume inside the mesh, and displacement of the surface of the mesh.

.. figure:: /images/cycles_material_shaders.png
:align: center

Surface Shader
==============

The surface shader defines the light interaction at the surface of the mesh.

.. seealso::

:doc:`Surface Shader &lt;/render/cycles/materials/surface&gt;`.

Volume Shader
=============

When the surface shader does not reflect or absorb light, it enters into the volume.
If no volume shader is specified, it will pass straight through to the other side of the mesh.

If it is defined,
a volume shader describes the light interaction as it passes through the volume of the mesh.
Light may be scattered, absorbed, or emitted at any point in the volume.

A material may have both a surface and a volume shader, or only one of either.
Using both may be useful for materials such as glass, water or ice,
where you want some of the light to be absorbed as it passes through the surface,
combined with e.g. a glass or glossy shader at the surface.

.. seealso::

:doc:`Volume Shader &lt;/render/cycles/materials/volume&gt;`.

Displacement
============

The shape of the surface and the volume inside it may be altered by displacement shaders.
This way, textures can then be used to make the mesh surface more detailed.

Depending on the settings, the displacement may be virtual,
only modifying the surface normals to give the impression of displacement,
which is known as bump mapping, or a combination of real and virtual displacement.

.. seealso::

:doc:`Displacement &lt;/render/cycles/materials/displacement&gt;`.

Energy Conservation
===================

The material system is built with physics-based rendering in mind,
cleanly separating how a material looks and which rendering algorithm is used to render it.
This makes it easier to achieve realistic results and balanced lighting,
though there are a few things to keep in mind.

In order for materials to work well with global illumination, they should be,
speaking in terms of physics, energy conserving.
That means they cannot reflect more light than comes in.
This property is not strictly enforced, but if colors are in the range 0.0 to 1.0, and
:abbr:`BSDF (Bidirectional scattering distribution function)` s are only mixed together with the
Mix Shader node, this will automatically be true.

It is however, possible to break this,
with color values higher than 1.0 or using the Add Shader node, but one must be careful when
doing this to keep materials behaving predictably under various lighting conditions.
It can result in a reflection adding light into the system at each bounce,
turning a :abbr:`BSDF (Bidirectional scattering distribution function)` into a kind of emitter.

*****************
Material Settings
*****************

.. figure:: /images/cycles_materials_settings.png
:align: right

Material Settings.

Surface
=======

Multiple Importance Sample
By default objects with emitting materials use both direct and indirect light sampling methods,
but in some cases it may lead to less noise overall to disable direct light sampling for some materials.
This can be done by disabling the *Multiple Importance Sample* option.
This is especially useful on large objects that emit little light compared to other light sources.

This option will only have an influence if the material contains an emission node;
it will be automatically disabled otherwise.

Transparent Shadows
Use transparent shadows if it contains a :doc:`Transparent BSDF &lt;/render/cycles/nodes/types/shaders/transparent&gt;`,
disabling will render faster but will not give accurate shadows.

Volume
======

Similar volume settings as the :ref:`World settings &lt;render-cycles-integrator-world-settings&gt;` per material.

.. _cycles-materials-settings-displace:

Displacement
============

.. note::

These Options are only available if :ref:`Experimental Feature Set &lt;cycles-experimental-features&gt;` is turned on.

Displacement Method
Method used preform :doc:`Displacement &lt;/render/cycles/materials/displacement&gt;` on materials.

True Displacement
Mesh vertices will be displaced before rendering, modifying the actual mesh.
This gives the best quality results, if the mesh is finely subdivided.
As a result, this method is also the most memory intensive.
Bump Mapping
When executing the surface shader, a modified surface normal is used instead of the true normal.
This is a quick alternative to true displacement, but only an approximation.
Surface silhouettes will not be accurate and there will be no self-shadowing of the displacement.
Displacement + Bump
Both methods can be combined, to do displacement on a coarser mesh,
and use bump mapping for the final detail.

Viewport Settings
=================

Viewport Color
--------------

Color
TODO.
Alpha
TODO.

Viewport Specular
-----------------

Color
TODO.
Hardness
TODO.

Viewport Alpha
--------------

Blend Mode
:term:`Blend modes` for transparent faces.

Opaque
Render color of textured face as color.
Add
Render transparent and add color of face.
Alpha Clip
Use the image alpha values clipped with no blending (binary alpha).
Alpha Blend
Render polygon transparent, depending on alpha channel of the texture.
Alpha Sort
Sort faces for correct alpha drawing (slow, use *Alpha Clip* instead when possible).
Alpha Anti-Aliasing
Use texture alpha ad an anti-aliasing mask, requires multi-sample OpenGL display.

Pass Index
----------

Pass Index
Index number for the *Material Index* :doc:`render pass &lt;/render/cycles/settings/passes&gt;`.
This can be used to give a mask to a material and then be read with the
:doc:`ID Mask Node &lt;/compositing/types/converter/id_mask&gt;` in the compositor.
.. _surface:

*******
Surface
*******

The surface shader defines the light interaction at the surface of the mesh. One or more
:abbr:`BSDF (Bidirectional scattering distribution function)`'s specify if incoming light is
reflected back, refracted into the mesh, or absorbed.

Emission defines how light is emitted from the surface,
allowing any surface to become a light source.

Terminology
===========

BSDF
stands for bidirectional scattering distribution function.
It defines how light is reflected and refracted at a surface.
Reflection
:abbr:`BSDF (Bidirectional scattering distribution function)` s
reflect an incoming ray on the same side of the surface.
Transmission
:abbr:`BSDF (Bidirectional scattering distribution function)` s
transmit an incoming ray through the surface, leaving on the other side.
Refraction
:abbr:`BSDF (Bidirectional scattering distribution function)` s are a type of *Transmission*,
transmitting an incoming ray and changing its direction as it exits on the other side of the surface.

BSDF Parameters
===============

A major difference from non-physically based renderers is that direct light reflection from
lamps and indirect light reflection of other surfaces are not decoupled, but rather handled
using a single :abbr:`BSDF (Bidirectional scattering distribution function)`.
This limits the possibilities a bit, but we believe overall it is helpful in creating
consistent-looking renders with fewer parameters to tune.

Roughness
For the glossy :abbr:`BSDF (Bidirectional scattering distribution function)` s,
the *roughness* parameter controls the sharpness of the reflection, from 0.0 (perfectly sharp)
to 1.0 (very soft). Compared to *hardness* or *exponent* parameters,
it has the advantage of being in the range 0.0..1.0,
and as a result gives more linear control and is more easily textureable.
The relation is roughly: *roughness* = 1 - 1/*hardness*

.. note::

Currently Blender is coded to use an unsquared model.
So if you are using a :term:`Roughness Map` chances are that the result will not be accurate.
To fix this, you can square the texture by connecting the texture to a
:doc:`Math node &lt;/render/cycles/nodes/types/converter/math&gt;`
and either setting it to *Multiply* and inputing the texture in both input sockets,
or use the *Power* function and setting the second input to 2.

***************
Texture Editing
***************

3D View draw types, UV mapping,
and texture painting work somewhat differently when Cycles is enabled.
UV Maps no longer get image textures assigned themselves;
rather they must always be assigned by adding an image texture node to a material.

3D View Draw Types
==================

The Texture draw types used for Blender Internal have been replaced by three others in Cycles:

Texture
This draw mode is used for editing, painting and mapping individual textures.
Lighting is the same as in solid mode, so this is similar to the existing textured solid for Blender Internal.
The texture drawn is the active image texture node for the material.
Material
A simplified version of the entire material is drawn using GLSL shaders.
This uses solid lighting, and also is mostly useful for editing, painting and mapping textures,
but while seeing how they integrate with the material.
Rendered
In this draw mode the render engine does the drawing,
interactively refining the full rendered image by taking more samples.
Unlike offline rendering, objects still use the viewport rather than render resolution and visibility.

.. figure:: /images/render_cycles_materials_texture-editing_draw-modes.jpg

Material draw modes (Texture, Material, Rendered).

Texture Properties
==================

.. figure:: /images/cycles_texture_tab_menu.jpg
:width: 225px
:align: right

In the texture properties,
the texture can now be selected from a list that contains all texture nodes from the world,
lamps and materials, but also from e.g. modifiers, brushes and physics fields.

For shading nodes, the available textures are Cycles textures. For others,
Blender textures are still used, but this will change in the future.

.. container:: lead

.. clear

Painting &amp; UV Editing
=====================

.. figure:: /images/cycles_texture_active.png
:align: right

For texture paint mode,
the image that is painted on is taken from the active image texture node.
This can be selected in the Node editor or the texture properties,
and it is indicated as blue in the material properties.

For UV mapping, the active UV map as specified in the mesh properties is used.
Assigning images in the UV/Image editor also affects the active image texture node.

******
Volume
******

Volume rendering can be used to render effects like fire, smoke, mist, absorption in glass,
and many other effects that cannot be represented by surface meshes alone.

To set up a volume, you create a mesh that defines the bounds within which the volume exists.
In the material you typically remove the surface nodes and instead connect volume nodes to
define the shading inside the volume.
For effects such as absorption in glass you can use both a surface and volume shader.
The world can also use a volume shader to create effects such as mist.

Volume Shaders
==============

Cycles supports three volume shader nodes,
that model particular effects as light passes through the volume and interacts with it:

- Volume Absorption will absorb part of the light as it passes through the volume.
This can be used to shade for example black smoke or colored glass objects, or mixed with the volume scatter node.
This node is somewhat similar to the transparent BSDF node,
it blocks part of the light and lets other light pass straight through.
- Volume Scatter lets light scatter in other directions as it hits particles in the volume.
The anisotropy defines in which direction the light is more likely to scatter.
A value of 0 will let light scatter evenly in all directions (somewhat similar to the diffuse BSDF node),
negative values let light scatter mostly backwards, and positive values let light scatter mostly forward.
This can be used to shade white smoke or clouds for example.
- Emission will emit light from the volume. This can be used to shade fire for example.

.. figure:: /images/cycles_materials_volume.jpg
:align: center

Volume Shader: Absorption/Absorption + Scatter/Emission.

Density
-------

All volume shaders have a density input.
The density defines how much of the light will interact with the volume,
getting absorbed or scattered, and how much will pass straight through. For effects such as
smoke you would specify a density field to indicate where in the volume there is smoke and how
much (density bigger than 0), and where there is no smoke (density equals 0).

Volumes in real life consist of particles,
a higher density means there are more particles per unit volume. More particles means there is
a higher chance for light to collide with a particle and get absorbed or scattered,
rather than passing straight through.

Volume Material
===============

Interaction with the Surface Shader
-----------------------------------

A material may have both a surface and a volume shader, or only one of either.
Using both may be useful for materials such as glass, water or ice,
where you want some of the light to be absorbed as it passes through the surface,
combined with e.g. a glass or glossy shader at the surface.

When the surface shader does not reflect or absorb light, it enters into the volume.
If no volume shader is specified, it will pass straight through to the other side of the mesh.
If it is defined,
a volume shader describes the light interaction as it passes through the volume of the mesh.
Light may be scattered, absorbed, or emitted at any point in the volume.

Mesh Topology
-------------

Meshes used for volume render should be closed and :term:`manifold`.
That means that there should be no holes in the mesh. Each edge must be connected to exactly two
faces such that there are no holes or T-shaped faces where three or more faces are connected to an
edge.

Normals must point outside for correct results.
The normals are used to determine if a ray enters or exits a volume,
and if they point in a wrong direction, or there is a hole in the mesh,
then the renderer is unable to decide what is the inside or outside of the volume.

These rules are the same as for rendering glass refraction correctly.

Volume World
============

A volume shader can also be applied to the entirely world, filling the entire space.

Currently, this is most useful for night time or other dark scenes,
as the world surface shader or sun lamps will have no effect if a volume shader is used.
This is because the world background is assumed to be infinitely far away,
which is accurate enough for the sun for example.
However, for modeling effects such as fog or atmospheric scattering,
it is not a good assumption that the volume fills the entire space,
as most of the distance between the sun and the earth is empty space.
For such effects it is be better to create a volume object surrounding the scene.
The size of this object will determine how much light is scattered or absorbed.

Smoke
=====

Creating a smoke material for cycles can be difficult however
the image below shows a good setup on how to do this.

.. figure:: /images/cycles_materials_smoke.png

Smoke and Fire Material.

Scattering Bounces
==================

Real world effects such as scattering in clouds or subsurface scattering require many
scattering bounces. However, unbiased rendering of such effects is slow and noisy. In typical
movie production scenes only 0 or 1 bounces might be used to keep render times under control.
The effect you get when rendering with zero volume bounces is what is known as
"single scattering", the effect from more bounces is "multiple scattering".

For rendering materials like skin or milk, the subsurface scattering shader is an
approximation of such multiple scattering effects
that is significantly more efficient but not as accurate.

For materials such as clouds or smoke that do not have a well defined surface,
volume rendering is required. These look best with many scattering bounces,
but in practice one might have to limit the number of bounces to keep render times acceptable.

Limitations
===========

Currently, the following are not not support:

- Correct ray visibility for volume meshes

Not available on GPU:

- Equi Angular/MIS Volume Sampling
- Volume Multi Light sampling

########
Nodes
########

.. toctree::
:maxdepth: 2

introduction.rst
osl.rst

Node Types
==========

.. toctree::
:maxdepth: 1

types/input/index.rst
types/output/index.rst
types/shaders/index.rst
types/textures/index.rst
types/color/index.rst
types/vector/index.rst
types/converter/index.rst
types/script.rst

************
Introduction
************

Materials, lights and backgrounds are all defined using a network of shading nodes.
These nodes output values, vectors, colors and shaders.

Shaders
=======

An important concept to understand when building node setups is
that of the *shader socket*. The output of all surface and
volume shaders is a shader, describing lighting interaction at the surface or of the volume,
rather than the color of the surface.

There are a few types of shaders available as nodes:

:abbr:`BSDF (Bidirectional scattering distribution function)` shader
Describe light reflection, refraction and absorption at an object surface.
Emission shader
Describe light emission at an object surface or in a volume.
Volume shader
Describe light scattering inside a volume.
Background shader
Describe light emission from the environment.

Each shader node has a color input, and outputs a shader.
These can then be mixed and added together using Mix and Add Shader nodes.
No other operations are permitted.
The resulting output can then be used by the render engine to compute all light interactions,
for direct lighting or global illumination.

.. seealso::

:doc:`Shaders &lt;/render/cycles/nodes/types/shaders/index&gt;`

Textures
========

Each texture type in Cycles corresponds to a node,
with a texture coordinate and various parameters as input, and a color or value as output.
No texture data-blocks are needed; instead node groups can be used for reusing texture setups.

For UV mapping and texture painting in the viewport, the Image texture node must be used.
When setting such a node as active, it will be drawn in Textured draw mode,
and can be painted on in texture paint mode.

The default texture coordinates for all nodes are Generated coordinates,
with the exception of Image textures that use UV coordinates by default.
Each node includes some options to modify the texture mapping and resulting color,
and these can be edited in the texture properties.

.. seealso::

:doc:`Textures &lt;/render/cycles/nodes/types/textures/index&gt;`.

More
====

Nodes for geometric data, texture coordinates,
layering shaders and non-physically based tricks can be found in:

- :doc:`Vector Nodes &lt;/render/cycles/nodes/types/vector/index&gt;`,
- :doc:`Color Nodes &lt;/render/cycles/nodes/types/color/index&gt;`,
- :doc:`Converter Nodes &lt;/render/cycles/nodes/types/converter/index&gt;`

Open Shading Language
=====================

Custom nodes can be written using the Open Shading Language.

.. seealso::

:doc:`Open Shading Language &lt;/render/cycles/nodes/osl&gt;`.

.. Editors Note: This page gets copied into :doc:`&lt;/render/cycles/nodes/script&gt;`

*********************
Open Shading Language
*********************

It is also possible to create your own nodes using
`Open Shading Language &lt;https://github.com/imageworks/OpenShadingLanguage&gt;`__ (OSL).
Note that these nodes will only work for CPU rendering;
there is no support for running OSL code on the GPU.

To enable it, select *Open Shading Language* as the shading system in the render settings.

.. note::

On Linux, C/C++ compiler tools (in particular /usr/bin/cpp)
must be installed to compile OSL scripts.

Script Node
===========

.. figure:: /images/render_cycles_nodes_script.png
:align: right

Script Node.

OSL was designed for node-based shading,
and *each* OSL shader corresponds to *one* node in a node setup. To add an OSL shader,
add a script node and link it to a text data-block or an external file. Input and output
sockets will be created from the shader parameters on clicking the update button in the node
or the text editor.

OSL shaders can be linked to the node in a few different ways. With the *Internal* mode,
a text data-block is used to store the OSL shader, and the OSO bytecode is stored in the node itself.
This is useful for distributing a blend-file with everything packed into it.

The *External* mode can be used to specify a ``.osl`` file from a drive,
and this will then be automatically compiled into a ``.oso`` file in the same directory.
It is also possible to specify a path to a ``.oso`` file, which will then be used directly,
with compilation done manually by the user. The third option is to specify just the module name,
which will be looked up in the shader search path.

The shader search path is located in the same place as the scripts or configuration path, under:

Linux
.. parsed-literal:: $HOME/.config/blender/|BLENDER_VERSION|/shaders/
MS-Windows
.. parsed-literal:: C:\\Users\\$user\\AppData\\Roaming\\Blender Foundation\\Blender\\\ |BLENDER_VERSION|\\shaders\\
macOS
.. parsed-literal:: /Users/$USER/Library/Application Support/Blender/|BLENDER_VERSION|/shaders/

.. tip::

For use in production, we suggest to use a node group to wrap shader script nodes,
and link that into other blend-files.
This makes it easier to make changes to the node afterwards as sockets are added or removed,
without having to update the script nodes in all files.

Writing Shaders
===============

For more details on how to write shaders, see the
`OSL specification &lt;https://github.com/imageworks/OpenShadingLanguage/blob/master/src/doc/osl-languagespec.pdf&gt;`__.
Here is a simple example:

.. code-block:: cpp

shader simple_material(
color Diffuse_Color = color(0.6, 0.8, 0.6),
float Noise_Factor = 0.5,
output closure color BSDF = diffuse(N))
{
color material_color = Diffuse_Color * mix(1.0, noise(P * 10.0), Noise_Factor);
BSDF = material_color * diffuse(N);
}

Closures
========

OSL is different from, for example, RSL or GLSL, in that it does not have a light loop.
There is no access to lights in the scene,
and the material must be built from closures that are implemented in the render engine itself.
This is more limited, but also makes it possible for the render engine to do optimizations and
ensure all shaders can be importance sampled.

The available closures in Cycles correspond to the shader nodes and their sockets;
for more details on what they do and the meaning of the parameters,
see the :doc:`shader nodes manual &lt;/render/cycles/nodes/types/shaders/index&gt;`.

BSDF
----

- ``diffuse(N)``
- ``oren_nayar(N, roughness)``
- ``diffuse_ramp(N, colors[8])``
- ``phong_ramp(N, exponent, colors[8])``
- ``diffuse_toon(N, size, smooth)``
- ``glossy_toon(N, size, smooth)``
- ``translucent(N)``
- ``reflection(N)``
- ``refraction(N, ior)``
- ``transparent()``
- ``microfacet_ggx(N, roughness)``
- ``microfacet_ggx_aniso(N, T, ax, ay)``
- ``microfacet_ggx_refraction(N, roughness, ior)``
- ``microfacet_beckmann(N, roughness)``
- ``microfacet_beckmann_aniso(N, T, ax, ay)``
- ``microfacet_beckmann_refraction(N, roughness, ior)``
- ``ashikhmin_shirley(N, T, ax, ay)``
- ``ashikhmin_velvet(N, roughness)``

Hair
----

- ``hair_reflection(N, roughnessu, roughnessv, T, offset)``
- ``hair_transmission(N, roughnessu, roughnessv, T, offset)``

BSSRDF
------

- ``bssrdf_cubic(N, radius, texture_blur, sharpness)``
- ``bssrdf_gaussian(N, radius, texture_blur)``

Volume
------

- ``henyey_greenstein(g)``
- ``absorption()``

Other
-----

- ``emission()``
- ``ambient_occlusion()``
- ``holdout()``
- ``background()``

Attributes
==========

Some object, particle and mesh attributes are available to the built-in getattribute()
function. UV maps and vertex colors can be retrieved using their name.
Other attributes are listed below:

``geom:generated``
Generated texture coordinates.
``geom:uv``
Default render UV map.
``geom:dupli_generated``
For instances, generated coordinate from duplicator object.
``geom:dupli_uv``
For instances, UV coordinate from duplicator object.
``geom:trianglevertices``
3 vertex coordinates of the triangle.
``geom:numpolyvertices``
Number of vertices in the polygon (always returns three currently).
``geom:polyvertices``
Vertex coordinates array of the polygon (always three vertices currently).
``geom:name``
Name of the object.
``geom:is_curve``
Is object a strand or not.
``geom:curve_intercept``
Point along the strand, from root to tip.
``geom:curve_thickness``
Thickness of the strand.
``geom:curve_tangent_normal``
Tangent Normal of the strand.
``path:ray_length``
Ray distance since last hit.
``object:location``
Object location.
``object:index``
Object index number.
``object:random``
Per object random number generated from object index and name.
``material:index``
Material index number.
``particle:index``
Particle instance number.
``particle:age``
Particle age in frames.
``particle:lifetime``
Total lifespan of particle in frames.
``particle:location``
Location of the particle.
``particle:size``
Size of the particle.
``particle:velocity``
Velocity of the particle.
``particle:angular_velocity``
Angular velocity of the particle.

Trace
=====

We support the ``trace(point pos, vector dir, ...)``
function, to trace rays from the OSL shader.
The "shade" parameter is not supported currently,
but attributes can be retrieved from the object that was hit using the ``getmessage("trace", ..)`` function.
See the OSL specification for details on how to use this.

This function cannot be used instead of lighting;
the main purpose is to allow shaders to "probe" nearby geometry,
for example to apply a projected texture that can be blocked by geometry,
apply more "wear" to exposed geometry, or make other ambient occlusion-like effects.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/color/bright_contrast.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/color/gamma.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/color/hue_saturation.rst

##############
Color Nodes
##############

.. toctree::
:maxdepth: 1

bright_contrast.rst
gamma.rst
hue_saturation.rst
invert.rst
light_falloff.rst
mix.rst
rgb_curves.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/color/invert.rst

******************
Light Falloff Node
******************

.. figure:: /images/render_cycles_nodes_color_light-falloff.png
:align: right

Light Falloff Node.

The *Light Falloff* node allows you to manipulate how light intensity decreases over distance.
In reality light will always fall off quadratically; however,
it can be useful to manipulate as a non-physically based lighting trick.
Note that using Linear or Constant falloff may cause more light to be introduced with every global
illumination bounce, making the resulting image extremely bright if many bounces are used.

Inputs
======

Strength
Light strength before applying falloff modification.
Smooth
Smooth intensity of light near light sources. This can avoid harsh highlights,
and reduce global illumination noise. 0.0 corresponds to no smoothing; higher values smooth more.
The maximum light strength will be strength/smooth.

Properties
==========

This node has no properties.

Outputs
=======

Quadratic
Quadratic light falloff; this will leave strength unmodified if smooth is 0.0 and corresponds to reality.
Linear
Linear light falloff, giving a slower decrease in intensity over distance.
Constant
Constant light falloff, where the distance to the light has no influence on its intensity.

Examples
========

Todo.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/color/mix.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/color/rgb_curves.rst

**************
Blackbody Node
**************

.. figure:: /images/render_cycles_nodes_converter_blackbody.png
:align: right

Blackbody Node.

The *Blackbody* node converts a blackbody temperature to RGB value.
This can be useful for materials that emit light at natural occurring frequencies.

Inputs
======

Temperature
The temperature in Kelvin.

Properties
==========

This node has no properties.

Outputs
=======

Color
RGB color output.

Examples
========

.. figure:: /images/cycles_nodes_blackbody_example.jpg

Example of the color ranges of the Blackbody node.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/converter/color_ramp.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/converter/combine_separate.rst

##################
Converter Nodes
##################

.. toctree::
:maxdepth: 1

blackbody.rst
color_ramp.rst
combine_separate.rst
math.rst
rgb_to_bw.rst
vector_math.rst
wavelength.rst
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/converter/math.rst
:end-before: Examples
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/converter/rgb_to_bw.rst

****************
Vector Math Node
****************

.. figure:: /images/render_blender-render_materials_nodes_converter_vector-math.png
:align: right

Vector Math Node.

The *Vector Math* node performs the selected math operation on vectors.
Select the math function by clicking the up-down selector where the "Add" selection is shown.

Inputs
======

Vector
Input vector 1 (upper). The value can be provided by another node or set manually.
Vector
Input vector 2 (lower). The value can be provided by another node or set manually.

Properties
==========

Operation
Selector the math function for conversion.

Add
Adding input 1 and 2.
Subtract
Subtracting input 1 and 2.
Average
Averaging input 1 and 2.
Dot Product
Algebraic operation that takes two equal-length sequences of vectors 1 and 2 and returns a single number.
The Result is a scalar.
Cross Product
Geometric binary operation on two vectors 1 and 2 in three-dimensional space.
It results in a vector which is perpendicular to both and therefore normal to the plane containing them.
The Result is a vector.
Normalize
Normalizing input 1 and 2.

Outputs
=======

Vector
Output vector, converted by the node.
Value
Output value, converted by the node.

Example
=======

Todo.

***************
Wavelength Node
***************

.. figure:: /images/render_cycles_nodes_converter_wavelength.png
:align: right

Wavelength Node.

The *Wavelength* node converts a wavelength value to a RGB value.
This can be used to achieve a specific color on the light spectrum.

Inputs
======

Wavelength
The color wavelength from 380 to 780 nanometers.

Properties
==========

This node has no inputs.

Outputs
=======

Color
RGB color output.

Examples
========

.. figure:: /images/cycles_nodes_wavelength_example.jpg

Example of Wavelength node.

**************
Attribute Node
**************

.. figure:: /images/render_cycles_nodes_input_attribute.png
:align: right

Attribute Node.

The *Attribute* node allows you to retrieve attributes attached to an object or mesh.

Inputs
======

This node has no inputs.

Properties
==========

Name
Name of the attribute. Currently, the following are the most important ones that you will need to know:

Vertex Color Layers
These can be retrieved this by their names.
Density
Gives a scalar defining the density of any smoke inside the
:doc:`Smoke Domain &lt;/physics/smoke/types/domain&gt;`.
Flame
Gives a scalar defining the density of any fire inside the :doc:`Smoke Domain &lt;/physics/smoke/types/domain&gt;`.
All three outputs are the same.
Color
Gives the color of the smoke inside the :doc:`Smoke Domain &lt;/physics/smoke/types/domain&gt;`.
The color and vector outputs are the same. The Factor output is an average of the channels.
Ocean Foam
Gives a scalar define where foam might appear when using an
:doc:`Ocean Modifier &lt;/modeling/modifiers/simulate/ocean&gt;`.
This depends on the name you give this property.

.. seealso::

For a full list of options see `This Tread &lt;https://blender.stackexchange.com/questions/14262#14267&gt;`__
on the Blender Stack Exchange.

Outputs
=======

Color
RGB color interpolated from the attribute.
Vector
XYZ vector interpolated from the attribute.
Factor
Scalar value interpolated from the attribute.

****************
Camera Data Node
****************

.. figure:: /images/render_cycles_nodes_input_camera-data.png
:align: right

Camera Data Node.

The *Camera Data* node is used for getting information about what
the camera is view in order to achieve different effects.

.. Add more explanation of what it is and how it works (TODO).
http://blender.stackexchange.com/questions/27764

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

View Vector
A Camera space vector from the camera to the shading point.
View Z Depth
The distance each pixel is away from the camera.
View Distance
Distance from the camera to the shading point.

************
Fresnel Node
************

.. figure:: /images/render_cycles_nodes_input_fresnel.png
:align: right

Fresnel Node.

The *Fresnel* or *Dielectric Fresnel* node computes how much light is reflected off a layer,
where the rest will be refracted through the layer.
The resulting weight can be used for layering shaders with the *Mix Shader* node.
It is dependent on the angle between the surface normal and the viewing direction.

The most common use is to mix between two BSDFs using it as a blending factor in a mix shader node.
For a simple glass material you would mix between a glossy refraction and glossy reflection.
At grazing angles more light will be reflected than refracted as happens in reality.

For a two-layered material with a diffuse base and a glossy coating,
you can use the same setup, mixing between a diffuse and glossy BSDF. By using the Fresnel as
the blending factor you are specifying that any light which is refracted through the glossy
coating layer would hit the diffuse base and be reflected off that.

Inputs
======

IOR
Index of refraction (:term:`IOR`) of the material being entered.
Normal
Input meant for plugging in bump or normal maps which will affect the output.

Properties
==========

This node has no properties.

Outputs
=======

Factor
Fresnel weight, indicating the probability with which light
will reflect off the layer rather than passing through.

*************
Geometry Node
*************

.. figure:: /images/render_cycles_nodes_input_geometry.png
:align: right

Geometry Node.

The *Geometry* node gives geometric information about the current shading point.
All vector coordinates are in *World Space*. For volume shaders,
only the position and incoming vector are available.

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

Position
Position of the shading point.
Normal
Shading normal at the surface (includes smooth normals and bump mapping).
Tangent
Tangent at the surface.
True Normal
Geometry or flat normal of the surface.
Incoming
Vector pointing towards the point the shading point is being viewed from.
Parametric
Parametric coordinates of the shading point on the surface.
Backfacing
1.0 if the face is being viewed from the back side, 0.0 for the front side.
Pointiness
An approximation of the curvature of the mesh per-vertex.
Lighter values indicate convex angles, darker values indicate concave angles.
It allows you to do effects like dirt maps and wear-off effects.

**************
Hair Info Node
**************

.. figure:: /images/render_cycles_nodes_input_hair-info.png
:align: right

Hair Info Node.

The *Hair Info* node gives access to :doc:`Hair &lt;/physics/particles/hair/index&gt;` information.

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

Is Strand
Returns 1 when the shader is acting on a strand, otherwise 0.
Intercept
The point along the strand where the ray hits the strand (1 at the tip and 0 at the root).
Thickness
The thickness of the strand at the point where the ray hits the strand.
Tangent Normal
Tangent normal of the strand.

##############
Input Nodes
##############

.. toctree::
:maxdepth: 1

attribute.rst
camera_data.rst
fresnel.rst
geometry.rst
hair_info.rst
layer_weight.rst
light_path.rst
object_info.rst
particle_info.rst
rgb.rst
tangent.rst
texture_coordinate.rst
uv_map.rst
value.rst
wireframe.rst

*****************
Layer Weight Node
*****************

.. figure:: /images/render_cycles_nodes_input_layer-weight.png
:align: right

Layer Weight Node.

The *Layer Weight* node outputs a weight typically used for layering shaders with the *Mix Shader* node.

Inputs
======

Blend
Bias the output towards all 0 or all 1. Useful for uneven mixing of shaders.
Normal
Input meant for plugging in bump or normal maps which will affect the output.

Properties
==========

This node has no properties.

Outputs
=======

Fresnel
Dielectric Fresnel weight, useful for example for layering diffuse and
glossy shaders to create a plastic material. This is like the Fresnel node,
except that the input of this node is in the often more-convenient 0.0 to 1.0 range.
Facing
Weight that blends from the first to the second shader
as the surface goes from facing the viewer to viewing it at a grazing angle.

***************
Light Path Node
***************

.. figure:: /images/render_cycles_nodes_input_light-path.png
:align: right

Light Path Node.

The *Light Path* node is used to find out for which kind of incoming ray the shader is being executed;
particularly useful for non-physically based tricks. More information about the meaning of each type
is in the :doc:`Light Paths &lt;/render/cycles/settings/light_paths&gt;` documentation.

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

Is Camera Ray
1.0 if shading is executed for a camera ray, 0.0 otherwise.
Is Shadow Ray
1.0 if shading is executed for a shadow ray, 0.0 otherwise.
Is Diffuse Ray
1.0 if shading is executed for a diffuse ray, 0.0 otherwise.
Is Glossy Ray
1.0 if shading is executed for a glossy ray, 0.0 otherwise.
Is Singular Ray
1.0 if shading is executed for a singular ray, 0.0 otherwise.
Is Reflection Ray
1.0 if shading is executed for a reflection ray, 0.0 otherwise.
Is Transmission Ray
1.0 if shading is executed for a transmission ray, 0.0 otherwise.
Ray Length
Distance traveled by the light ray from the last bounce or camera.
Ray Depth
Number of times the ray has "bounced", i.e. been reflected or transmitted on interaction with a surface.

.. note::

Passing through a transparent shader
:ref:`does not count as a normal "bounce" &lt;render-cycles-light-paths-transparency&gt;`.

Transparent Depth
Returns the number of transparent surfaces passed through.
Transmission Depth
Replace a Transmission lightpath after X bounces with another shader, e.g a Diffuse one.
This can be used to avoid black surfaces, due to low amount of max bounces.

****************
Object Info Node
****************

.. figure:: /images/render_cycles_nodes_input_object-info.png
:align: right

Object Info Node.

The *Object Info* node gives information about the object instance.
This can be useful to give some variation to a single material assigned to multiple instances,
either manually controlled through the object index, based on the object location,
or randomized for each instance. For example a Noise texture can give random colors or a Color
ramp can give a range of colors to be randomly picked from.

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

Location
Location of the object in world space.
Object Index
Object pass index, same as in the Object Index pass.transformed.
Material Index
Material pass index, same as in the Material Index pass.
Random
Random number unique to a single object instance.

.. note::

Note that this node only works for material shading nodes;
it does nothing for lamp and world shading nodes.

******************
Particle Info Node
******************

.. figure:: /images/render_cycles_nodes_input_particle-info.png
:align: right

Particle Info Node.

The *Particle Info* node is for objects instanced from a :doc:`Particle System &lt;/physics/particles/index&gt;`,
this node give access to the data of the particle that spawned the instance.

.. note::

This node currently only supports parent particles, info from child particles is not available.

.. is this still true? ^^

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

Index
Index number of the particle (from 0 to number of particles).
Age
Age of the particle in frames.
Lifetime
Total lifespan of the particle in frames.
Location
Location of the particle.
Size
Size of the particle.
Velocity
Velocity of the particle.
Angular Velocity
Angular velocity of the particle.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/input/rgb.rst

************
Tangent Node
************

.. figure:: /images/render_cycles_nodes_input_tangent.png
:align: right

Tangent Node.

The *Tangent* node generates a tangent direction for the Anisotropic BSDF.

Inputs
======

This node has no inputs.

Properties
==========

Direction Type
The tangent direction can be derived from a cylindrical projection around the X,
Y, or Z axis (Radial), or from a manually created UV Map for full control.

Outputs
=======

Tangent
The tangent direction vector.

***********************
Texture Coordinate Node
***********************

.. figure:: /images/render_cycles_nodes_input_texture-coordinate.png
:align: right

Texture Coordinate Node.

The *Texture Coordinate* node is commonly used for the coordinates of textures,
typically used as inputs for the *Vector* input for texture nodes.

Inputs
======

This node has no inputs.

Properties
==========

Object
Specific object to use for object space coordinates.
This only affects the *Object* output.

.. _cycles-nodes-input-texture-coordinate-from-dupli:

From Dupli
If the material is applied to a dupli object, use texture coordinates from the parent object.
This only affects the *Generated* and *UV* outputs.

.. figure:: /images/cycles_nodes_from_dupli_comparison.png

From left to right: Sphere with UV mapped texture.
Small spheres duplicated to the faces of the textured sphere using
:doc:`duplifaces &lt;/editors/3dview/object/properties/duplication/duplifaces&gt;`.
Small spheres with *From Dupli* enabled, using the UV map of the large sphere.

.. note::

*From Dupli* only works with the UV output when the dupli object is instanced from faces,
either with :doc:`particles &lt;/physics/particles/introduction&gt;` or
:doc:`duplifaces &lt;/editors/3dview/object/properties/duplication/duplifaces&gt;`.

Outputs
=======

Generated
Automatically-generated texture coordinates from the vertex positions of the mesh without deformation,
keeping them sticking to the surface under animation. Range from 0.0 to 1.
0 over the bounding box of the undeformed mesh.
Normal
Object space normal, for texturing objects with the texture staying fixed on the object as it transformed.
UV
UV texture coordinates from the active render UV map.
Object
Position coordinate in object space.
Camera
Position coordinate in camera space.
Window
Location of shading point on the screen, ranging from 0.0 to 1.
0 from the left to right side and bottom to top of the render.
Reflection
Vector in the direction of a sharp reflection, typically used for environment maps.

***********
UV Map Node
***********

.. figure:: /images/render_cycles_nodes_input_uv-map.png
:align: right

UV Map Node.

The *UV Map* node is used to retrieve specific UV maps. Unlike the :doc:`Texture Coordinate Node
&lt;/render/cycles/nodes/types/input/texture_coordinate&gt;` which only provides the active UV map,
this node can retrieve any UV map belonging to the object using the material.

Inputs
======

This node has no inputs.

Properties
==========

From Dupli
See the :ref:`From Dupli &lt;cycles-nodes-input-texture-coordinate-from-dupli&gt;`
option of the :doc:`Texture Coordinate Node &lt;/render/cycles/nodes/types/input/texture_coordinate&gt;`.

UV Map
UV map to use.

Outputs
=======

UV
UV mapping coordinates from the specified UV map.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/input/value.rst

**************
Wireframe Node
**************

.. figure:: /images/render_cycles_nodes_input_wireframe.png
:align: right

Wireframe Node.

The *Wireframe* node is used to retrieve the edges of an object as it appears to cycles.
As meshes are triangulated before being processed by cycles,
topology will always appear triangulated when viewed with the *Wireframe node*.

Inputs
======

This node has no inputs.

Properties
==========

Pixel Size
When enabled, the size of edge lines are set in screen space.
Size
Thickness of the edge lines.

Outputs
=======

Factor
Black and white mask showing white lines representing edges according to the object's :term:`topology`.

Examples
========

Todo.

###############
Output Nodes
###############

Output nodes are the final node in every node tree.
Although you can add more than one, only one will be used (indicated by a colored or darkened header).
Output nodes are always preceded by :doc:`Shaders &lt;/render/cycles/nodes/types/shaders/index&gt;`
except in the case of the :doc:`Displacement &lt;/render/cycles/materials/displacement&gt;` of a Material Output.

.. toctree::
:maxdepth: 1

material.rst
lamp.rst
world.rst

*********
Lamp Node
*********

The *Lamp Output* node is used to output light information to a lamp object.

Inputs
======

Surface
Not an actual surface, but the final output of a :doc:`Lamp &lt;/render/cycles/lamps&gt;` Object.

Properties
==========

This node has no properties.

Outputs
=======

This node has no outputs.

*************
Material Node
*************

The *Material Output* node is used to output surface material information to a surface object.

Inputs
======

Surface
The surface output of the material.
Volume
Used to output of the different volume shaders.

.. seealso::

The types of volume shaders are:

- :doc:`Emission &lt;/render/cycles/nodes/types/shaders/emission&gt;` shader.
- :doc:`Volume Absorption &lt;/render/cycles/nodes/types/shaders/volume_absorption&gt;` shader.
- :doc:`Volume Scatter &lt;/render/cycles/nodes/types/shaders/volume_scatter&gt;` shader.

Displacement
Used to create bump mapping or actual subdivided :doc:`Displacement &lt;/render/cycles/materials/displacement&gt;`.

Properties
==========

This node has no properties.

Outputs
=======

This node has no outputs.

**********
World Node
**********

The *World Output* node is used to output light a color information
to the scene's :doc:`World &lt;/render/cycles/world&gt;`.

Inputs
======

Surface
The appearance of the environment,
usually preceded by a :doc:`Background &lt;/render/cycles/nodes/types/shaders/background&gt;` shader.
Volume
Used to add volumetric effects to the world.
See the :doc:`Volume Absorption &lt;/render/cycles/nodes/types/shaders/volume_absorption&gt;`
and :doc:`Volume Scatter &lt;/render/cycles/nodes/types/shaders/volume_scatter&gt;` for more information.

.. note::

It is not possible to have and HDR and volumetric due to the fact that
HDR's are assumed to be an infant distance from the camera.

Properties
==========

This node has no properties.

Outputs
=======

This node has no outputs.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.

***********
Script Node
***********

.. include:: ../osl.rst
:start-line: 21

********
Add Node
********

.. figure:: /images/render_cycles_nodes_shaders_add-shader.png
:align: right

Add Node.

The *Add* node is uses to add to *Shaders* together.

Inputs
======

Shaders
Standard shader inputs.

Properties
==========

This node has no properties.

Outputs
=======

Shader
Standard shader output.

Example
=======

.. figure:: /images/cycles_nodes_shader_mix_example.jpg

A mix of a glossy and a diffuse shader makes a nice ceramic material.

****************
Anisotropic Node
****************

.. figure:: /images/render_cycles_nodes_shaders_anisotropic-bsdf.png
:align: right

Anisotropic Node.

The *Anisotropic* :abbr:`BSDF (Bidirectional scattering distribution function)`
node is used to add a glossy reflection, with separate control over U and V direction roughness.
The tangents used for shading are derived from the active UV map. If no UV map is available,
they are automatically generated using a sphere mapping based on the mesh bounding box.

Inputs
======

Color
Color of the surface, or physically speaking, the probability that light is reflected for each wavelength.
Roughness
Sharpness of the reflection; perfectly sharp at 0.0 and smoother with higher values.
Anisotropy
Amount of anisotropy in the reflection; 0.0 gives a round highlight.
Higher values give elongated highlights orthogonal to the tangent direction;
negative values give highlights shaped along the tangent direction.
Rotation
Rotation of the anisotropic tangent direction.
Value 0.0 equals 0° rotation, 0.25 equals 90° and 1.0 equals 360° = 0° .
This can be used to texture the tangent direction.
Normal
Normal used for shading; if nothing is connected the default shading normal is used.
Tangent
Tangent used for shading; if nothing is connected the default shading tangent is used.

Properties
==========

Distribution
Microfacet distribution to use. *Sharp* results in perfectly sharp reflections like a mirror,
while *Beckmann*, *GGX* and *Ashikhmin-Shirley* can use the *Roughness* input for blurry reflections.

Outputs
=======

BSDF output
Standard shader output.

Examples
========

.. list-table::

* - .. figure:: /images/cycles_nodes_shader_anisotropic_rot0.jpg

Anisotropic rotation on 0.

- .. figure:: /images/cycles_nodes_shader_anisotropic_rot025.jpg

Anisotropic rotation on 0.25 (90°)

**********************
Ambient Occlusion Node
**********************

.. figure:: /images/render_cycles_nodes_shaders_ambient-occlusion.png
:align: right

Ambient Occlusion Node.

The *Ambient Occlusion* shader node gives per-material control for the amount of AO.
When AO is enabled in the world, it affects all diffuse BSDFs in the scene.
With this option it is possible to let only some materials be affected by AO,
or to let it influence some materials more or less than others.

Inputs
======

Color
Surface reflection color.

Properties
==========

This node has no properties.

Outputs
=======

AO
Standard shader output.

Example
=======

.. figure:: /images/cycles_nodes_shader_ao_example.jpg

White AO shader.

***************
Background Node
***************

.. figure:: /images/render_cycles_nodes_shaders_background.png
:align: right

Background Node.

The *Background* shader node is used to add background light emission.
This node should only be used for the world surface output; it is ignored in other cases.

Inputs
======

Color
Color of the emitted light.
Strength
Strength of the emitted light.

Properties
==========

This node has no properties.

Outputs
=======

Background
Standard shader output.

Examples
========

Todo.

************
Diffuse Node
************

.. figure:: /images/render_cycles_nodes_shaders_diffuse-bsdf.png
:align: right

Diffuse Node.

The *Diffuse* :abbr:`BSDF (Bidirectional scattering distribution function)`
node is used to add Lambertian and Oren-Nayar diffuse reflection.

Inputs
======

Color
Color of the surface, or physically speaking,
the probability that light is reflected or transmitted for each wavelength.
Roughness
Surface roughness; 0.0 gives standard Lambertian reflection, higher values activate the Oren-Nayar BSDF.
Normal
Normal used for shading; if nothing is connected the default shading normal is used.

Properties
==========

This node has no properties.

Outputs
=======

BSDF
Standard shader output.

Examples
========

.. list-table::

* - .. figure:: /images/cycles_nodes_shader_diffuse_behavior.png

Diffuse behavior.

- ..

* - .. figure:: /images/cycles_nodes_shader_diffuse_example.jpg

- .. figure:: /images/cycles_nodes_shader_diffuse_example_oren-nayar.jpg

*************
Emission Node
*************

.. figure:: /images/render_cycles_nodes_shaders_emission.png
:align: right

Emission Node.

The *Emission* node is used to add Lambertian emission shader.
This can for example, be used for material and lamp surface outputs.

Cycles uses a physically correct light falloff by default,
whereas Blender Internal uses a smoothed falloff with a Distance parameter.
A similar effect can be found by using the Light Falloff node with the Smooth parameter.

Lamp strength for point, spot and area lamps is specified in Watts.
This means you typically need higher values than Blender Internal,
as you could not use a 1W lamp to light a room; you need something stronger like a 100W lamp.

Sun lamps are specified in Watts/m\ :sup:`2`\, which require much smaller values like 1 W/m\ :sup:`2`\.
This can be confusing, but specifying strength in Watts would not have been convenient;
the real sun for example has strength 384.6×10\ :sup:`24`\W.
Emission shaders on meshes are also in Watts/m\ :sup:`2`\.

Inputs
======

Color
Color of the emitted light.
Strength
Strength of the emitted light. For point and area lamps, the unit is Watts.
For materials, a value of 1.0 will ensure that the object in the image has
the exact same color as the Color input, i.e. make it 'shadeless'.

Properties
==========

This node has no properties.

Outputs
=======

Emission
The Emission shader output can both be plugged in the *Surface Input* as well as
the *Volume Input* of the :doc:`Material &lt;/render/cycles/nodes/types/output/material&gt;` output node.

Examples
========

.. list-table::

* - .. figure:: /images/cycles_nodes_shader_emission_example.jpg

Emission shader, with strength at 1.0.

- .. figure:: /images/cycles_nodes_shader_emission_example_bright.jpg

Emission shader, with strength at 3.0.

**********
Glass Node
**********

.. figure:: /images/render_cycles_nodes_shaders_glass-bsdf.png
:align: right

Glass Node.

The *Glass* :abbr:`BSDF (Bidirectional scattering distribution function)`
node is used to add a Glass-like shader mixing refraction and reflection at grazing angles.
Like the transparent shader, only pure white will make it transparent.
The glass shader tends to cause noise due to caustics.
Since the Cycles path tracing integrator is not very good at rendering caustics,
it helps to combine this with a transparent shader for shadows;
for :ref:`more details see here &lt;render-cycles-reducing-noise-glass-and-transp-shadows&gt;`.

Inputs
======

Color
Color of the surface, or physically speaking, the probability that light is transmitted for each wavelength.
Roughness
Influences sharpness of the refraction; perfectly sharp at 0.0 and smoother with higher values.
IOR
Index of refraction (:term:`IOR`) defining how much the ray changes direction. At 1.
0 rays pass straight through like transparent; higher values give more refraction.
Normal
Normal used for shading.

Properties
==========

Distribution
See :doc:`/render/cycles/nodes/types/shaders/glossy`.

Outputs
=======

BSDF
Standard shader output.

Examples
========

.. list-table::
:header-rows: 1

* - Sharp Glass
- Rough Glass
* - .. figure:: /images/cycles_nodes_shader_glass_sharp_behavior.png
- .. figure:: /images/cycles_nodes_shader_glass_behavior.png
* - .. figure:: /images/cycles_nodes_shader_glass_example.jpg
- .. figure:: /images/cycles_nodes_shader_glass_example_rough.jpg

***********
Glossy Node
***********

.. figure:: /images/render_cycles_nodes_shaders_glossy-bsdf.png
:align: right

Glossy Node.

The *Glossy* :abbr:`BSDF (Bidirectional scattering distribution function)`
node is used to add reflection with microfacet distribution, used for materials such as metal or mirrors.

Inputs
======

Color
Color of the surface, or physically speaking, the probability that light is reflected for each wavelength.
Roughness
Input for the surface roughness resulting in sharp to blurry reflections.
Normal
Normal used for shading.

Properties
==========

Distribution
Microfacet distribution to use.

Sharp
Results in perfectly sharp reflections like a mirror. The *Roughness* value is not used.
Multiple-scattering GGX
Takes multiple bounce (scattering) events between microfacets into account.
This gives a more energy conserving results, which would else be visible as excessive darkening.

Beckmann, GGX, Ashikhmin-Shirley

Outputs
=======

BSDF
Standard shader output.

Examples
========

.. list-table::
:header-rows: 1

* - Sharp Glossy
- Rough Glossy
* - .. figure:: /images/cycles_nodes_shader_glossy_behavior_sharp.png
- .. figure:: /images/cycles_nodes_shader_glossy_behavior.png
* - .. figure:: /images/cycles_nodes_shader_glossy_example.jpg
- .. figure:: /images/cycles_nodes_shader_glossyrough.jpg

*********
Hair Node
*********

.. figure:: /images/render_cycles_nodes_shaders_hair-bsdf.png
:align: right

Hair Node.

The *Hair* :abbr:`BSDF (Bidirectional scattering distribution function)`
node is used to add shading for :doc:`Hair &lt;/physics/particles/hair/index&gt;`.

Inputs
======

Color
Color of the hair.
Offset
Controls the way the light is rotated (angular shift) for the reflection/transmission.
Roughness U/V
Controls the roughness in the direction light is skewed, and perpendicular to it.
Tangent
Input tangent.

Properties
==========

Component
There are two components that can be used to control the look of the hair.
Usually you are going to want each of these and use a :doc:`Mix Node &lt;/render/cycles/nodes/types/shaders/mix&gt;`.

Reflection
The light that bounces off the surface of the hair.
Transmission
The light that passes through the hair and comes out the other side.

Outputs
=======

BSDF
Standard shader output.

Examples
========

Todo.

************
Holdout Node
************

.. figure:: /images/render_cycles_nodes_shaders_holdout.png
:align: right

Holdout Node.

The *Holdout* shader node is used to create a "hole" in the image with zero alpha
transparency, which is useful for compositing (see :term:`alpha channel`).

Note that the holdout shader can only create alpha when
:menuselection:`Properties --&gt; Render --&gt; Film --&gt; Transparent` is enabled.
If it is disabled, the holdout shader will be black.

Inputs
======

This node has no inputs.

Properties
==========

This node has no properties.

Outputs
=======

Holdout
Standard shader output.

Examples
========

.. figure:: /images/cycles_nodes_shader_holdout_example.jpg

The checkered area is a region with zero alpha.
.. _shaders:

###############
Shader Nodes
###############

.. toctree::
:maxdepth: 1

add.rst
anisotropic.rst
ao.rst
background.rst
diffuse.rst
emission.rst
glass.rst
glossy.rst
hair.rst
holdout.rst
mix.rst
refraction.rst
sss.rst
toon.rst
translucent.rst
transparent.rst
velvet.rst
volume_absorption.rst
volume_scatter.rst

********
Mix Node
********

.. figure:: /images/render_cycles_nodes_shaders_mix-shader.png
:align: right

Mix Node.

The *Mix* node is used to mix two shaders together. Mixing can be used for material layering,
where the *Factor* input may, for example, be connected to a *Blend Weight* node.

Inputs
======

Shader
Shaders to mix, such that incoming rays hit either with the specified probability in the *Factor* socket.
Factor
Blend weight to use for mixing two shaders;
at zero it uses the first shader entirely and at one the second shader.

Properties
==========

This node has no properties.

Outputs
=======

Shader
Standard shader output.

Examples
========

.. figure:: /images/cycles_nodes_shader_mix_example.jpg

A mix of a glossy and a diffuse shader makes a nice ceramic material.

***************
Refraction Node
***************

.. figure:: /images/render_cycles_nodes_shaders_refraction-bsdf.png
:align: right

Refraction Node.

The *Refraction* :abbr:`BSDF (Bidirectional scattering distribution function)`
node is used to add glossy refraction with sharp or microfacet distribution,
used for materials that transmit light. For best results this node should be considered as a
building block and not be used on its own,
but rather mixed with a glossy node using a Fresnel factor.
Otherwise it will give quite dark results at the edges for glossy refraction.

Inputs
======

Color
Color of the surface, or physically speaking, the probability that light is refracted for each wavelength.
Roughness
Influences sharpness of the refraction; perfectly sharp at 0.0 and smoother with higher values.
Normal
Normal used for shading; if nothing is connected the default shading normal is used.

Properties
==========

Distribution
Microfacet distribution to use. *Sharp* results in perfectly sharp refractions,
while *Beckmann* and *GGX* can use the *Roughness* input for blurry refractions.

Outputs
=======

BSDF
Standard shader output.

Examples
========

.. figure:: /images/cycles_nodes_shader_refraction_example.jpg

Refraction Shader.

**************************
Subsurface Scattering Node
**************************

.. figure:: /images/render_cycles_nodes_shaders_subsurface-scattering.png
:align: right

Subsurface Scattering Node.

The *Subsurface Scattering* node is used to add simple subsurface multiple scattering,
for materials such as skin, wax, marble, milk and others. For these materials,
rather than light being reflect directly off the surface, it will penetrate the surface and
bounce around internally before getting absorbed or leaving the surface at a nearby point.

How far the color scatters on average can be configured per RGB color channel. For example,
for skin, red colors scatter further, which gives distinctive red-colored shadows,
and a soft appearance.

Inputs
======

Color
Color of the surface, or physically speaking, the probability that light is reflected for each wavelength.
Scale
Global scale factor for the scattering radius.
Radius
Scattering radius for each RGB color channel, the maximum distance that light can scatter.
Sharpness
Used only with *Cubic* falloff.
Values increasing from 0 to 1 prevents softening of sharp edges and reduces unwanted darkening.
Normal
Normal used for shading; if nothing is connected the default shading normal is used.
Texture Blur
How much of the texture will be blurred along with the lighting,
mixing the texture at the incoming and outgoing points on the surface.
Note that the right choice depends on the texture.
Consider for example a texture created from a photograph of skin,
in this cases the colors will already be pre-blurred and texture blur could be set to 0.
Even for hand painted textures no or minimal blurring might be appropriate,
as a texture artist would likely paint in softening already,
one would usually not even know what an unblurred skin texture looks like, we always see it blurred.
For a procedural texture on the other hand this option would likely have a higher value.

Properties
==========

Falloff
Lighting distance falloff function.

Cubic
Is a sharp falloff useful for many simple materials. The function is :math:`(radius - x)^3`.
Gaussian
Gives a smoother falloff following a normal distribution,
which is particularly useful for more advanced materials that use measured
data that was fitted to one or more such Gaussian functions.
The function is :math:`e^{-8x^2/ radius^2}`,
such that the radius roughly matches the maximum falloff distance.
To match a given measured variance *v*, set :math:`radius = sqrt(16 × v)`.
Christensen-Burley
Is an approximation to physically based volume scattering.
Gives less blurry results than Cubic and Gaussian functions.

Outputs
=======

BSSRDF
:abbr:`BSSRDF (Bidirectional subsurface scattering distribution function)` shader output.

Examples
========

.. figure:: /images/cycles_nodes_shader_sss_example.jpg

A skin-toned SSS shader with color radius (1.0, 0.8, 0.5).

*********
Toon Node
*********

.. figure:: /images/render_cycles_nodes_shaders_toon-bsdf.png
:align: right

Toon Node.

The *Toon* :abbr:`BSDF (Bidirectional scattering distribution function)`
is used to create *Diffuse* and *Glossy* materials with cartoon light effects.

Inputs
======

Color
Color of the surface, or physically speaking, the probability that light is reflected for each wavelength.
Size
Parameter between 0.0 and 1.0 that gives an angle of reflection between 0° and 90°.
Smooth
This value specifies an angle over which a smooth transition from full to no reflection happens.
Normal
Normal used for shading; if nothing is connected the default shading normal is used.

Properties
==========

Component
ToDo

Outputs
=======

BSDF
Standard shader output.

Examples
========

.. figure:: /images/cycles_nodes_shader_toon_example.jpg

Toon Shader.

****************
Translucent Node
****************

.. figure:: /images/render_cycles_nodes_shaders_translucent-bsdf.png
:align: right

Translucent Node.

The *Translucent* :abbr:`BSDF (Bidirectional scattering distribution function)`
is used to add Lambertian diffuse transmission.

Inputs
======

Color
Color of the surface, or physically speaking, the probability that light is transmitted for each wavelength.
Normal
Normal used for shading; if nothing is connected the default shading normal is used.

Properties
==========

This node has no properties.

Outputs
=======

BSDF output
Standard shader output.

Examples
========

.. figure:: /images/cycles_nodes_shader_translucent_behavior.png
:align: center

.. figure:: /images/cycles_nodes_shader_translucent_example.jpg
:align: center

Translucent Shader.

****************
Transparent Node
****************

.. figure:: /images/render_cycles_nodes_shaders_transparent-bsdf.png
:align: right

Transparent Node.

The *Transparent* :abbr:`BSDF (Bidirectional scattering distribution function)`
node is used to add transparency without refraction, passing straight through the surface,
as if there were no geometry there. Useful with alpha maps, for example.
This shader :ref:`affects light paths somewhat differently &lt;render-cycles-light-paths-transparency&gt;`
than other :abbr:`BSDF (Bidirectional scattering distribution function)`\ s.
Note that only pure white transparent shaders are completely transparent.

Inputs
======

Color
Color of the surface, or physically speaking,
the probability for each wavelength that light is blocked or passes straight through the surface.

Properties
==========

This node has no properties.

Outputs
=======

BSDF
Standard shader output.

Examples
========

.. list-table::

* - .. figure:: /images/cycles_nodes_shader_transparent_behavior.png
:align: center

Transparent behavior.

- ..

* - .. figure:: /images/cycles_nodes_shader_transparent_example.jpg

Transparent Shader (pure white).

- .. figure:: /images/cycles_nodes_shader_transparent_example_dark.jpg

Transparent Shader (gray).

***********
Velvet Node
***********

.. figure:: /images/render_cycles_nodes_shaders_velvet-bsdf.png
:align: right

Velvet Node.

The *Velvet* :abbr:`BSDF (Bidirectional scattering distribution function)`
node is used to add reflection to materials such as cloth.
It is meant to be used together with other shaders (such as a *Diffuse Shader*)
and is not particularly useful on its own.

Inputs
======

Color
Color of the surface, or physically speaking, the probability that light is reflected for each wavelength.
Sigma
Variance of the normal distribution,
controlling the sharpness of the peak. It can be thought of as a kind of *roughness*.
Normal
Normal used for shading; if nothing is connected the default shading normal is used.

Properties
==========

This node has no properties.

Outputs
=======

BSDF
Standard shader output.

Examples
========

.. figure:: /images/cycles_nodes_shader_velvet_behavior.png
:align: center

.. figure:: /images/cycles_nodes_shader_velvet_example.jpg
:align: center

The Velvet Shader.
.. Todo add links to settings that control these:

**********************
Volume Absorption Node
**********************

.. figure:: /images/render_cycles_nodes_shaders_volume-absorption.png
:align: right

Volume Absorption Node.

The *Volume Absorption* node allows light to be absorbed as is passes through the volume.
Typical usage for this node would be water and glass.
It can also be used with the :doc:`Volume Scatter &lt;/render/cycles/nodes/types/shaders/volume_scatter&gt;`
node to create smoke.

Inputs
======

Color
Color of the volume.
Density
The density of the absorption effect.

Properties
==========

This node has no properties.

Outputs
=======

Volume
The Volume Shader output must be plugged into the *Volume Input*
of the :doc:`Material &lt;/render/cycles/nodes/types/output/material&gt;` output node.

Examples
========

.. figure:: /images/cycles_nodes_shader_volume_absorbtion.png

Example of Volume Absorption.

*******************
Volume Scatter Node
*******************

.. figure:: /images/render_cycles_nodes_shaders_volume-scatter.png
:align: right

Volume Scatter Node.

The *Volume Scatter* node allows light to be scattered scatter light as is passes through it.
Typical usage would be to add fog to a scene. It can also be used with
the :doc:`Volume Absorption &lt;/render/cycles/nodes/types/shaders/volume_absorption&gt;`
Node to create smoke.

Inputs
=======

Color
Color of the volume.
Density
The density of the scatter effect.
Anisotropy
Controls the look of the scatter effect depending on the direction of the light passing through it.

Properties
==========

Volume
The Volume Shader output must be plugged into the *Volume Input*
of the :doc:`Material &lt;/render/cycles/nodes/types/output/material&gt;` output node.

Examples
========

.. figure:: /images/cycles_nodes_shader_volume_scatter.png

Example of Volume Scatter.

******************
Brick Texture Node
******************

.. figure:: /images/render_cycles_nodes_textures_brick-texture.png
:align: right

Brick Texture Node.

The *Brick Texture* is used to add a procedural texture producing bricks.

Inputs
======

Color 1/2 and Mortar
Color of the bricks and mortar.
Scale
Overall texture scale.
Mortar Size
The Mortar size; 0 means no Mortar.
Bias
The color variation between *Color 1/2*.
Values of -1 and 1 only use one of the two colors; values in between mix the colors.
Brick Width
The width of the bricks.
Row Height
The height of the brick rows.

Properties
==========

Offset
Determines the brick offset of the various rows.
Frequency
Determines the offset frequency. A value of 2 gives an even/uneven pattern of rows.
Squash
Amount of brick squashing.
Frequency
Brick squashing frequency.

Outputs
=======

Color
Texture color output.
Factor
Mortar mask (1 = mortar).

Examples
========

.. figure:: /images/cycles_nodes_tex_brick_example.jpg
:width: 200px

Brick texture: Colors changed, Squash 0.62, Squash Frequency 3.

********************
Checker Texture Node
********************

.. figure:: /images/render_cycles_nodes_textures_checker-texture.png
:align: right

Checker Texture Node.

The *Checker Texture* is used to add a checkerboard texture.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to Generated texture coordinates if the socket is left unconnected.
Color1, Color 2
Color of the checkers.
Scale
Overall texture scale. The scale is a factor of the bounding box of the face divided by the scale.
For example, a scale of 15 will result in 15 alternate patterns over the overall UV bounding box.
Different patterns could be achieved using other nodes to give different input patterns to this socket.
For example, using the Math Node.

Properties
==========

This node has no properties.

Outputs
=======

Color
Texture color output.
Factor
Checker 1 mask (1 = Checker 1).

Examples
========

.. figure:: /images/cycles_nodes_tex_checker.jpg
:width: 200px

Default Checker texture.

************************
Environment Texture Node
************************

.. figure:: /images/render_cycles_nodes_textures_environment-texture.png
:align: right

Environment Texture Node.

The *Environmental Texture* is used to light your scene using an environment map image file as a texture.

Inputs
======

Vector
Texture coordinate for texture lookup. If this socket is left unconnected,
the image is mapped as environment with the Z axis as up.

Properties
==========

Image Data-Block
Image data-block used as the image source.
Color Space
Type of data that the image contains, either Color or Non-Color Data.
For most color textures the default of Color should be used, but in case of e.g. a bump or alpha map,
the pixel values should be interpreted as Non-Color Data, to avoid doing any unwanted color space conversions.
Texture Interpolation
Interpolation method used for the environment texture. The following interpolations are available:

Linear
Default.
Closest
No interpolation.
Cubic
Only available when rendering on the CPU.
Smart
Bicubic when magnifying else Bilinear is used. This is only available for :doc:`OSL &lt;/render/cycles/nodes/osl&gt;`.

Projection Method
Allows you to use different types of environmental maps. The following methods are supported:

Equirectangular
Projection from an Equirectangular photo.
Mirror Ball
Projection from an orthographic photo or mirror ball.

Outputs
=======

Color
RGB color from the image.

Examples
========

.. figure:: /images/cycles_nodes_tex_environment_example.jpg
:width: 200px

HDR image from `OpenFootage.net &lt;http://www.openfootage.net/?p=986&gt;`__.

*********************
Gradient Texture Node
*********************

.. figure:: /images/render_cycles_nodes_textures_gradient-texture.png
:align: right

Gradient Texture Node.

The *Gradient Texture* node is used a gradient texture.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to Generated texture coordinates if the socket is left unconnected.

Properties
==========

Type
The gradient can be *Linear*, *Quadratic*, *Easing*, *Diagonal*,
*Spherical*, *Quadratic Sphere* or *Radial*.

Outputs
=======

Color
Texture color output.
Factor
Texture intensity output.

Examples
========

.. figure:: /images/cycles_nodes_tex_gradient_example.jpg
:width: 200px

Gradient texture using object coordinates.

******************
Image Texture Node
******************

.. figure:: /images/render_cycles_nodes_textures_image-texture.png
:align: right

Image Texture Node.

The *Image Texture* is used to add an image file as a texture.

Inputs
======

Vector
Texture coordinate for texture lookup. If this socket is left unconnected,
UV coordinates from the active UV render layer are used.

Properties
==========

Image Data-Block
Image data-block used as the image source. Currently not all images supported by Blender can be used by Cycles.
In particular, generated, packed images or animations are not supported currently.
Color Space
Type of data that the image contains, either Color or Non-Color Data.
For most color textures the default of Color should be used, but in case of e.g. a bump or alpha map,
the pixel values should be interpreted as Non-Color Data, to avoid doing any unwanted color space conversions.
Interpolation
ToDo.
Projection
Projection to use for mapping the textures.

Flat
Uses the XY coordinates for mapping.
Box
Maps the image to the six sides of a virtual box, based on the normal,
using XY, YZ and XYZ coordinates depending on the side.

Blend
For Box mapping, the amount to blend between sides of the box,
to get rid of sharp transitions between the different sides.
Blending is useful to map a procedural-like image texture pattern seamlessly on a model.
0.0 gives no blending; higher values give a smoother transition.

Sphere
Sphere mapping is the best type for mapping a sphere,
and it is perfect for making planets and similar objects.
It is often very useful for creating organic objects.
Tube
Maps the texture around an object like a label on a bottle.
The texture is therefore more stretched on the cylinder.
This mapping is of course very good for making the label on a bottle,
or assigning stickers to rounded objects. However,
this is not a cylindrical mapping so the ends of the cylinder are undefined.

Extension
Extension defines how the image is extrapolated past the original bounds:

Repeat
Will repeat the image horizontally and vertically giving tiled-looking result.
Extend
Will extend the image by repeating pixels on its edges.
Clip
Clip to the original image size and set all the exterior pixels values to transparent black.

Outputs
=======

Color
RGB color from image. If the image has alpha, the color is premultiplied with alpha if the Alpha output is used,
and unpremultiplied or straight if the Alpha output is not used.
Alpha
Alpha channel from image.

Examples
========

.. figure:: /images/cycles_nodes_tex_image_example.jpg

Image texture from `GoodTextures.com &lt;http://www.goodtextures.com/&gt;`__.
.. _textures:

################
Texture Nodes
################

.. toctree::
:maxdepth: 1

brick.rst
checker.rst
environment.rst
gradient.rst
image.rst
magic.rst
musgrave.rst
noise.rst
point_density.rst
sky.rst
voronoi.rst
wave.rst

******************
Magic Texture Node
******************

.. figure:: /images/render_cycles_nodes_textures_magic-texture.png
:align: right

Magic Texture Node.

The *Magic Texture* node is used to add psychedelic color texture.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to Generated texture coordinates if the socket is left unconnected.
Scale
Scale of the texture.
Distortion
Amount of distortion.

Properties
==========

Depth
Number of iterations.

Outputs
=======

Color
Texture color output.
Factor
Texture intensity output.

Examples
========

.. figure:: /images/cycles_nodes_tex_magic.jpg
:width: 200px

Magic texture: Depth 10, Distortion 2.0.

*********************
Musgrave Texture Node
*********************

.. figure:: /images/render_cycles_nodes_textures_musgrave-texture.png
:align: right

Musgrave Texture Node.

The *Musgrave Texture* is used to add an advanced procedural noise texture.

.. tip::

The *Musgrave Texture* often needs some adjustments
(multiplication and addition) in order to see more detail.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to Generated texture coordinates if the socket is left unconnected.
Scale
Overall texture scale.
Detail
Amount of noise detail.
Dimension
The highest fractal dimension, specified as the highest scale for the steps of the intensity.
Lacunarity
The space of the lacunarity, specified as a frequency factor.
Offset
The offset of the fractal, specified between black and white values (Intensity).
Gain
A multiplier for the gain input.

Properties
==========

Type
Multifractal, Ridged Multifractal, Hybrid Multifractal, fBM, Hetero Terrain.

Outputs
=======

Color
Texture color output.
Factor
Texture intensity output.

Examples
========

.. list-table:: Remapped Musgrave texture such that most values are visible.
:widths: 65 35

* - .. figure:: /images/cycles_nodes_tex_musgrave_nodes.png
:width: 460px

Nodes for the image to the right.

- .. figure:: /images/cycles_nodes_tex_musgrave.jpg
:width: 320px

Musgrave texture.

******************
Noise Texture Node
******************

.. figure:: /images/render_cycles_nodes_textures_noise-texture.png
:align: right

Noise Texture Node.

The *Noise Texture* is used to add procedural Perlin noise texture,
similar to the *Clouds* texture in *Blender Internal*.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to Generated texture coordinates if the socket is left unconnected.
Scale
Overall texture scale.
Detail
Amount of noise detail.
Distortion
Amount of distortion.

Properties
==========

This node has no properties.

Outputs
=======

Color
Texture color output.
Factor
Texture intensity output.

Examples
========

.. figure:: /images/cycles_nodes_tex_noise.jpg
:width: 200px

Noise Texture with high detail.

******************
Point Density Node
******************

.. figure:: /images/render_cycles_nodes_textures_point-density.png
:align: right

Point Density Node.

The *Point Density* node is used to add volumetric points for each particle or vertex of another object.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to global position (*Position* output of *Geometry* node) if the socket is left unconnected.

Properties
==========

Point Data
Where to get points from.

Particle System
Use each particle position from the specified particle system.
Object Vertices
Use each vertex position from the specified object.
Object
Which object's vertices or particle system will be used.
Particle System
Particle positions from this system will be used.
Space
The coordinate system for mapping points.

World Space
Map each point exactly where the source particle/vertex is.
Object Space
Fit the points from the source particles/vertices
inside the bounding box of the object with the point density texture.

.. TODO As far as I can tell this is how it works, but should be checked with a developer.

Radius
Radius from the shaded sample to look for points within.

.. TODO Same as tooltip, this does not make much sense to me.

Interpolation
Texel filtering type.

Closest
No interpolation, use nearest texel. Produces blocky looking points.
Linear
Interpolate linearly between texels, producing soft, round points.
Cubic
Use cubic falloff, producing very soft points. Useful when points are very densely packed.
Resolution
The dimensions of the texture holding the point data.
Color Source
Which attribute of the particle system or mesh is used to color the output.

Particle Color Sources
Particle Age
Lifetime mapped as (0.0 - 1.0) intensity.
Particle Speed
Particle speed (absolute magnitude of velocity) mapped as (0.0 - 1.0) intensity.
Particle Velocity
XYZ velocity mapped to RGB colors.
Vertex Color Sources
Vertex Color
Use a vertex color layer for coloring the point density texture.

.. note::

Vertex colors are defined per face corner.
A single vertex can have as many different colors as faces it is part of.
The actual color of the point density texture is averaged from all vertex corners.

Vertex Weight
Use a weights from a vertex group as intensity values.
Vertex Normals
Use object-space vertex normals as RGB values.

Outputs
=======

Color
Texture color output.
Density
Density of volume.

Examples
========

.. figure:: /images/cycles_nodes_tex_point_density.jpg
:width: 200px

Domain object with Point Density texture using vertices from ball as points.

****************
Sky Texture Node
****************

.. figure:: /images/render_cycles_nodes_textures_sky-texture.png
:align: right

Sky Texture Node.

The *Sky Texture* node adds a procedural Sky texture.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to Generated texture coordinates if the socket is left unconnected.

Properties
==========

Sky Type
Sky model to use.

Preetham, Hosek/Wilkie
Sun Direction
Sun direction vector.
Turbidity
Atmospheric turbidity.

- 2: Arctic like
- 3: clear sky
- 6: warm/moist day
- 10: hazy day

Ground Albedo
Amount of light reflected from the planet surface back into the atmosphere.
(RGB 0,0,0 is black, 1,1,1 is white).

Outputs
=======

Color
Texture color output.

Examples
========

.. figure:: /images/cycles_nodes_tex_sky.jpg
:width: 200px

Sky Texture.
.. Define Voronoi? Glossary?

********************
Voronoi Texture Node
********************

.. figure:: /images/render_cycles_nodes_textures_voronoi-texture.png
:align: right

Voronoi Texture Node.

The *Voronoi Texture* node adds a procedural texture producing Voronoi cells.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to Generated texture coordinates if the socket is left unconnected.
Scale
Overall texture scale.

Properties
==========

Coloring
*Intensity* or *Cells* output.

Outputs
=======

Color
Texture color output.
Factor
Texture intensity output.

Examples
========

.. list-table::

* - .. figure:: /images/cycles_nodes_tex_voronoi_intensity.jpg
:width: 200px

Voronoi texture, type: Intensity.

- .. figure:: /images/cycles_nodes_tex_voronoi_cells.jpg
:width: 200px

Voronoi texture, type: Cells.

*****************
Wave Texture Node
*****************

.. figure:: /images/render_cycles_nodes_textures_wave-texture.png
:align: right

Wave Texture Node.

The *Wave Texture* node adds procedural bands or rings with noise distortion.

Inputs
======

Vector
Texture coordinate to sample texture at;
defaults to Generated texture coordinates if the socket is left unconnected.
Scale
Overall texture scale.
Distortion
Amount of distortion of the wave (similar to the Marble texture in Blender Internal).
Detail
Amount of distortion noise detail.
Detail Scale
Scale of distortion noise.

Properties
==========

Type
*Bands* or *Rings* shaped waves.
Wave Profile
Controls the look of the wave type.

Saw
Uses a sawtooth profile.
Sine
Uses the standard sine profile.

Outputs
=======

Color
Texture color output.
Factor
Texture intensity output.

Examples
========

.. figure:: /images/cycles_nodes_tex_wave.jpg
:width: 200px

Default wave texture.

*********
Bump Node
*********

.. figure:: /images/render_cycles_nodes_vector_bump.png
:align: right

Bump Node.

The *Bump* node generates a perturbed normal from a height texture, for bump mapping.
The height value will be sampled at the shading point and two nearby points
on the surface to determine the local direction of the normal.

Inputs
======

Strength
Strength of the bump mapping effect, interpolating between no bump mapping and full bump mapping.
Distance
Multiplier for the height value to control the overall distance for bump mapping.
Height
Scalar value giving the height offset from the surface at the shading point; this is where you plug in textures.
Normal
Standard normal input.

Properties
==========

Invert
Invert the bump mapping, to displace into the surface instead of out.

Outputs
=======

Normal
Standard normal output.

Examples
========

.. figure:: /images/cycles_bump_node_setup.png

The above node setup will only bump the diffuse part of the shader,
simulating a bumpy diffuse surface coated with a smooth glossy "glaze" layer.

.. figure:: /images/cycles_bump_node_example.png
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/vector/vector_curves.rst

###############
Vector Nodes
###############

.. toctree::
:maxdepth: 1

bump.rst
curves.rst
mapping.rst
normal.rst
normal_map.rst
transform.rst

************
Mapping Node
************

The *Mapping* nodes is used to transform a coordinate; typically used for modifying texture coordinates.

Inputs
======

Vector
Vector to be transformed.

Properties
==========

Vector type
Todo.

Texture
Todo.
Point
Todo.
Vector
Todo.
Normal
Todo.

Location
Vector translation.
Rotation
Rotation of the vector along XYZ axes.
Scale
Scale of the vector.

Min
Todo.
Max
Todo.

Outputs
=======

Vector
Transformed vector.

Examples
========

Todo.
.. DO NOT EDIT FILE. This is simply a stub which copies every thing from the link below.
.. include:: ../../../../../compositing/types/vector/normal.rst

***************
Normal Map Node
***************

.. figure:: /images/render_blender-render_materials_nodes_vector_normal-map.png
:align: right

Normal Map Node.

The *Normal Map* node generate a perturbed normal from an RGB normal map image.
This is usually chained with an *Image Texture* node in the color input,
to specify the normal map image. For tangent space normal maps,
the UV coordinates for the image must match,
and the image texture should be set to *Non-Color* mode to give correct results.

Inputs
======

Strength
Strength of the normal mapping effect.
Color
RGB color that encodes the normal in the specified space.

Properties
==========

Space
The input RGB color can be in one of three spaces: Tangent, Object and World space.
Tangent space normal maps are the most common, as they support object transformation and mesh deformations.
Object space normal maps keep sticking to the surface under object transformations,
while World normal maps do not.
UV Map
Name of the UV map to derive normal mapping tangents from. When chained with an Image Texture node,
this UV map should be the same as the UV map used to map the texture.

Outputs
=======

Normal
Normal that can be used as an input to BSDF nodes.

Examples
========

Todo.

*********************
Vector Transform Node
*********************

.. figure:: /images/render_blender-render_materials_nodes_vector_transform.png
:align: right

Vector Transform node.

The *Vector Transform* node allows converting a Vector,
Point or Normal between World and Camera and Object coordinate space.

Inputs
======

Vector Input
Standard vector input.

Properties
==========

Type
Specifies the input/output type.

Vector, Point, Normal.
Convert From
Coordinate Space to convert from:

World, Object, Camera.
Convert To
Coordinate Space to convert to:

World, Object, Camera.

Outputs
=======

Vector Output
The transformed output vector.

Examples
========

Todo.

#####################
Optimizing Renders
#####################

.. toctree::
:maxdepth: 2

reducing_noise.rst
nodes.rst

************
Shader Nodes
************

Cycles applies a number of shader node optimizations both at compile time and runtime.
By exploiting them it is possible to design complicated "Uber Shader"
style node groups that incur minimal render time overhead for unused features.

Node Optimizations
==================

As the first step in preparing a node shader for execution,
Cycles expands all node groups, as if using the Ungroup tool,
and discards UI only features like frames and reroute nodes.

After that, it applies some obvious transformations
For example, it can (the list is not exhaustive):

- Replace the following nodes with the constant result of their evaluation,
if all their inputs are determined to be constant:

RGB, Value, Mix RGB, Math, Vector Math, RGB to BW, Gamma, Bright Contrast,
Invert, Separate/Combine RGB/XYZ/HSV, Blackbody, RGB Curves, Vector Curves, Color Ramps.

- Detect Mix RGB, Math and Vector Math nodes that become no-op (without Clamp)
or evaluate to 0 as a result of addition, subtraction, multiplication,
division or dot/cross product with a known constant 0 or 1 input,
and replace with the apropriate input link or constant result.
- Eliminate Mix RGB Mix (without Clamp) and Mix Shader nodes when
Factor is known to be 0 or 1 by replacing with the appropriate input value or link.
- Eliminate no-op Mix RGB (except Burn, Dodge, Lighten, or enabled Clamp),
Invert, RGB Curves and Vector Curves nodes with known zero Factor.
- Eliminate Emission and Background shader nodes that do not emit any light,
and Add Shader nodes with one or both input arguments missing.
- Eliminate Bump with constant Height input, using its Normal input or Geometry Normal instead.
- Combine multiple copies of the same node with the same inputs into only one instance.

Finally, any nodes that end up not connected either directly or indirectly to the output node are removed.

Runtime Optimizations
=====================

When executing shaders, a special optimization is applied to Mix Shader nodes.
If Factor evaluates to 0 or 1, any nodes that are only reachable via the unused branch of the mix are not evaluated.

This can substantially reduce the performance cost of combining multiple materials
in one shader with vertex color, texture, or other input used as a switch.

Open Shading Language
=====================

If Open Shading Language is chosen as the rendering back-end,
node shaders are translated to OSL code and then compiled and executed by the OSL runtime.
In the process it applies its own extensive set of optimizations, both at compile time and runtime.

Open Shading Language can optimize out Script nodes if their outputs are unused or constant,
even if their OSL shaders have side effects like debug tracing and message passing,
which may be confusing. For that reason message passing with ``setmessage`` and ``getmessage``
should generally not be used for passing information forward in the graph;
explicitly passing information through sockets should be preferred.

**************
Reducing Noise
**************

When performing a final render, it is important to reduce noise as much as possible.
Here we will discuss a number of tricks that, while breaking the laws of physics,
are particularly important when rendering animations within a reasonable time.
Click to enlarge the example images to see the noise differences well.

Path Tracing
============

Cycles uses path tracing with next event estimation,
which is not good at rendering all types of light effects, like caustics, but has the
advantage of being able to render more detailed and larger scenes compared to some other
rendering algorithms. This is because we do not need to store, for example,
a photon map in memory,
and because we can keep rays relatively coherent to use an on-demand image cache,
compared to e.g. bidirectional path tracing.

.. figure:: /images/render_cycles_settings_light-path-rays.png

We do the inverse of what reality does,
tracing light rays from the camera into the scene and onto lights,
rather than from the light sources into the scene and then into the camera.
This has the advantage that we do not waste light rays that will not end up in the camera,
but also means that it is difficult to find some light paths that may contribute a lot.
Light rays will be sent either according to the surface BRDF,
or in the direction of known light sources (lamps, emitting meshes with Sample as Lamp).

.. seealso::

For more details, see the
:doc:`Light Paths &lt;/render/cycles/settings/light_paths&gt;` and
:doc:`Integrator &lt;/render/cycles/settings/integrator&gt;` documentation.

Where Noise Comes From
======================

To understand where noise can come from, take for example this scene.
When we trace a light ray into the specified location, this is what the diffuse shader "sees".
To find the light that is reflected from this surface,
we need to find the average color from all these pixels.
Note the glossy highlight on the sphere,
and the bright spot the lamp casts on the nearby wall. These hotspots are 100x brighter than
other parts of the image and will contribute significantly to the lighting of this pixel.

.. list-table::

* - .. figure:: /images/cycles_noise_fisheye_reference.jpg
:width: 180px

- .. figure:: /images/cycles_noise_fisheye.jpg
:width: 180px

- .. figure:: /images/cycles_noise_fisheye_hotspot.jpg
:width: 180px

The lamp is a known light source, so it will not be too hard to find,
but the glossy highlight(s) that it causes are a different matter.
The best we can do with path tracing is to distribute light rays randomly over the hemisphere,
hoping to find all the important bright spots. If for some pixels we miss some bright spot,
but we do find it for another, that results in noise. The more samples we take,
the higher the probability that we cover all the important sources of light.

With some tricks we can reduce this noise. If we blur the bright spots,
they become bigger and less intense, making them easier to find and less noisy.
This will not give the same exact result,
but often it's close enough when viewed through a diffuse or soft glossy reflection.
Below is an example of using Filter Glossy and Smooth Light Falloff.

.. list-table::

* - .. figure:: /images/cycles_noise_fisheye_blur_reference.jpg
:width: 180px

- .. figure:: /images/cycles_noise_fisheye_blur.jpg
:width: 180px

- .. figure:: /images/cycles_noise_fisheye_blur_hotspot.jpg
:width: 180px

Bounces
=======

In reality light will bounce a huge number of times due to the speed of light being very high.
In practice more bounces will introduce more noise, and it might be good to use something like
the Limited Global Illumination preset that uses *fewer* bounces for different shader
types. Diffuse surfaces typically can get away with fewer bounces,
while glossy surfaces need a few more,
and transmission shaders such as glass usually need the most.

.. list-table::

* - .. figure:: /images/cycles_noise_0bounce.jpg
:width: 180px

- .. figure:: /images/cycles_noise_2bounce.jpg
:width: 180px

- .. figure:: /images/cycles_noise_4bounce.jpg
:width: 180px

Also important is to use shader colors that do **not** have components of value 1.0 or
values near that; try to keep the maximum value to 0.8 or less and make your lights brighter.
In reality, surfaces are rarely perfectly reflecting all light,
but there are of course exceptions; usually glass will let most light through,
which is why we need more bounces there. High values for the color components tend to
introduce noise because light intensity then does not decrease much as it bounces off each
surface.

Caustics and Filter Glossy
==========================

Caustics are a well-known source of noise, causing fireflies.
They happen because the renderer has difficulty finding specular highlights
viewed through a soft glossy or diffuse reflection.
There is a :ref:`No Caustics &lt;render-cycles-integrator-no-caustics&gt;`
option to disable glossy behind a diffuse reflection entirely.
Many render engines will typically disable caustics by default.

.. list-table::

* - .. figure:: /images/cycles_noise_reference.jpg
:width: 180px

- .. figure:: /images/cycles_noise_no_caustics.jpg
:width: 180px

- .. figure:: /images/cycles_noise_filter_glossy.jpg
:width: 180px

However, using No Caustics will result in missing light,
and it still does not cover the case where a sharp glossy reflection is viewed through a soft glossy reflection.
There is a :ref:`Filter Glossy &lt;render-cycles-integrator-filter-glossy&gt;`
option to reduce the noise from such cases at the cost of accuracy.
This will blur the sharp glossy reflection to make it easier to find, by increasing the shader Roughness.

The above images show default settings, no caustics, and filter glossy set to 1.0.

Light Falloff
=============

In reality light in a vacuum will always fall off at a rate of 1/(distance^2).
However, as distance goes to zero,
this value goes to infinity and we can get very bright spots in the image.
These are mostly a problem for indirect lighting, where the probability of hitting such a
small but extremely bright spot is low and so happens only rarely.
This is a typical recipe for fireflies.

.. list-table::

* - .. figure:: /images/cycles_noise_falloff_hard.jpg
:width: 180px

- .. figure:: /images/cycles_noise_falloff_soft.jpg
:width: 180px

To reduce this problem, the :doc:`Light Falloff &lt;/render/cycles/nodes/types/color/light_falloff&gt;`
node has a *Smooth factor*, that can be used to reduce the maximum intensity
a light can contribute to nearby surfaces. The images above show default falloff and smooth value 1.0.

Sample as Lamp
==============

Materials with emission shaders can be configured to be *sampled as lamp*
(:doc:`/render/cycles/materials/settings`).
This means that they will get rays sent directly towards them,
rather than ending up there based on rays randomly bouncing around.
For very bright mesh light sources, this can reduce noise significantly.
However, when the emission is not particularly bright,
this will take samples away from other brighter light sources for which it is important to find them this way.

The optimal setting here is difficult to guess; it may be a matter of trial and error,
but often it is clear that a somewhat glowing object may be only contributing light locally,
while a mesh light used as a lamp would need this option enabled.
Here is an example where the emissive spheres contribute little to the lighting,
and the image renders with slightly less noise by disabling Sample as Lamp on them.

.. list-table::

* - .. figure:: /images/cycles_noise_sample_lamp.jpg
:width: 180px

- .. figure:: /images/cycles_noise_no_sample_lamp.jpg
:width: 180px

The world background also has a *Sample as Lamp* (:ref:`render-cycles-integrator-world-settings`) option.
This is mostly useful for environment maps that have small bright spots in them, rather than being smooth.
This option will then, in a preprocess, determine the bright spots, and send light rays directly towards them. Again,
enabling this option may take samples away from more important light sources if it is not needed.

.. _render-cycles-reducing-noise-glass-and-transp-shadows:

Glass and Transparent Shadows
=============================

With caustics disabled, glass will miss shadows,
and with filter glossy they might be too soft.
We can make a glass shader that will use a Glass BSDF when viewed *directly*,
and a Transparent BSDF when viewed *indirectly*. The Transparent BSDF can be used for
transparent shadows to find light sources straight through surfaces,
and will give properly-colored shadows, but without the caustics.
The Light Path node is used to determine when to use which of the two shaders.

.. figure:: /images/render_cycles_noise_glass_group.png

Optimized glass shader.

Above we can see the node setup used for the glass transparency trick;
on the left the render has too much shadow due to missing caustics,
and on the right the render with the trick.

.. list-table::

* - .. figure:: /images/cycles_noise_glass_too_much_shadow.jpg
:width: 180px

- .. figure:: /images/cycles_noise_glass_trick.jpg
:width: 180px

Light Portals
=============

When rendering a daylight indoor scene where most of the light is coming in through a window
or door opening, it is difficult for the integrator to find its way to them.
To fix this, use :ref:`Light Portals &lt;render-cycles-lamps-area-portals&gt;`,
these work by adding a :ref:`Area Lamp &lt;render-cycles-lamps-area&gt;`.
You then will need to modify its shape to match that of the opening that you are trying to fill.

.. figure:: /images/cycles_portals2.jpg
.. figure:: /images/cycles_portals.jpg

.. _render-cycles-reducing-noise-clamp-samples:

Clamp Fireflies
===============

Ideally with all the previous tricks, fireflies would be eliminated, but they could still happen. For that,
the *intensity* that any individual light ray sample will contribute to a pixel can be *clamped*
to a maximum value with the integrator :ref:`Clamp setting &lt;render-cycles-integrator-clamp-samples&gt;`.

If set too low this can cause missing highlights in the image,
which might be useful to preserve for camera effects such as bloom or glare.
To mitigate this conundrum it's often useful to clamp only indirect bounces,
leaving highlights directly visible to the camera untouched.

.. list-table::

* - .. figure:: /images/cycles_noise_noclamp.jpg
:width: 180px

- .. figure:: /images/cycles_noise_clamp_4.jpg
:width: 180px
.. _bpy.types.CyclesRenderSettings.:

###################
Render Settings
###################

.. toctree::
:maxdepth: 2

integrator.rst
light_paths.rst
passes.rst
performance.rst
motion_blur.rst
objects/index.rst

**********
Integrator
**********

The integrator is the rendering algorithm used to compute the lighting.
Cycles currently supports a path tracing integrator with direct light sampling.
It works well for various lighting setups,
but is not as suitable for caustics and some other complex lighting situations.

Rays are traced from the camera into the scene,
bouncing around until they find a light source such as a lamp, an object emitting light,
or the world background. To find lamps and surfaces emitting light,
both indirect light sampling (letting the ray follow the surface BSDF)
and direct light sampling (picking a light source and tracing a ray towards it) are used.

Sampling
========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render --&gt; Sampling`

Sample Method
There are two integrator modes that can be used: *Path Tracing* and *Branched Path Tracing*.
Square Samples
Square the amount samples.
Seed
Seed value for integrator to get different noise patterns.

Animate Seed (clock icon)
This button which can be found on the right side of the *Seed*
value can be used to give different seed values. It is a good idea to enable this
when making animation because in the real world each frame has a different noise pattern.

.. _render-cycles-integrator-clamp-samples:

Clamp Direct
This option limits the maximum intensity a sample from rays which have not yet bounced can contribute to a pixel.
It reduces noise at the cost of accuracy. Setting this option to 0.0 disables clamping altogether.
Lower have a greater affect (dimmer samples) on the resulting image than higher values.

.. note::

A common issue encountered with *Path Tracing* is the occurrence of "fireflies":
improbable samples that contribute very high values to pixels.
This option provides a way to limit that. However, note that as you clamp out such values,
other bright lights/reflections will be dimmed as well.

Care must be taken when using this setting to find a balance between mitigating fireflies and losing
intentionally bright parts. It is often useful to clamp indirect bounces separately,
as they tend to cause more fireflies than direct bounces. See the *Clamp Indirect* setting.

Clamp Indirect
The same as *Clamp Direct*, but for rays which have bounced multiple times.

Pattern
Random sampling pattern used by the integrator.

Sobol
Uses a Sobol pattern to decide the random sapling pattern used by the integrator.
See `Sobol sequence &lt;https://en.wikipedia.org/wiki/Sobol_sequence&gt;`__ on Wikipedia for more information.
Correlated Multi-Jitter
Uses a Correlated Multi-Jitter pattern to decide the random sapling pattern used by the integrator. See
`this Pixar paper &lt;http://graphics.pixar.com/library/MultiJitteredSampling/paper.pdf&gt;`__ for more information.

.. _render-cycles-integrator-layer-samples:

Layer Samples
When render layers have per layer number of samples set, this option specifies how to use them.

Use
ToDo
Bounded
Bound render layer samples by scene samples.
Ignore
Ignore render layer sample settings.

Path Tracing
------------

The *Path Tracing* integrator is a pure path tracer;
at each hit it will bounce light in one direction and pick one light to receive lighting from.
This makes each individual sample faster to compute,
but will typically require more samples to clean up the noise.

Render Samples
Number of paths to trace for each pixel in the final render. As more samples are taken,
the solution becomes less noisy and more accurate.
Preview Samples
Number of samples for viewport rendering.

Branched Path Tracing
---------------------

The non-progressive Branched Path Tracing integrator offers finer control over sampling.
It is similar to *Path Tracing*, but at the first hit it will split the path for
different surface components and will take all lights into account for shading instead of just one.

This makes each sample slower, but will reduce noise,
especially in scenes dominated by direct or one-bounce lighting.
To get the same number of diffuse samples as in the path tracing integrator, note that e.g.
250 path tracing samples = 10 AA samples x 25 diffuse samples.
The Sampling panel shows this total number of samples.

AA Render Samples
Number of samples to take for each pixel in the final render. More samples will improve antialiasing.
AA Preview Samples
Number of samples for viewport rendering.

Diffuse Samples
Number of diffuse bounce samples to take for each AA sample.
Glossy Samples
Number of glossy bounce samples to take for each AA sample.
Transmission Samples
Number of transmission bounce samples to take for each AA sample.
AO Samples
Number of ambient occlusion samples to take for each AA sample.
Mesh Light Samples
Number of mesh light samples to take for each AA sample.
Subsurface Samples
Number of subsurface scattering samples to take for each AA sample.
Volume Samples
Number of volume scattering samples to take for each AA sample.

Sample All Direct Lights
When enabled, Cycles will samples all lights in the scene for direct bounces, instead of randomly picking one.
Disabling this can improve performance, when using a lot of AA Samples anyway, to clear up the render.
Sample All Indirect Lights
Similar to direct light, but for indirects lights. This can reduce noise in scenes with many lights.

Light Paths
===========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render --&gt; Light Paths`

.. _cycles-bounces:

Bounces
-------

Max Bounces
Maximum number of light bounces. For best quality, this should be set to the maximum. However, in practice,
it may be good to set it to lower values for faster rendering.
Setting it to maximum 0 bounces results in direct lighting only.
Min Bounces
Minimum number of light bounces for each path,
after which the integrator uses Russian Roulette to terminate paths that contribute less to the image.
Setting this higher gives less noise, but may also increase render time considerably. For a low number of bounces,
it is strongly recommended to set this equal to the maximum number of bounces.

Diffuse Bounces
Maximum number of diffuse bounces.
Glossy Bounces
Maximum number of glossy bounces.
Transmission Bounces
Maximum number of transmission bounces.
Volume Bounces
Maximum number of volume scattering bounces.

Transparency
------------

Transparency Max
Maximum number of transparency bounces.
Transparency Min
Minimum number of transparency bounces, after which Russian Roulette termination is used.
Transparent Shadows
For direct light sampling,
use transparency of surfaces in between to produce shadows affected by transparency of those surfaces.

Caustics &amp; Filter Glossy
------------------------

.. _render-cycles-integrator-no-caustics:

Reflective Caustics
While in principle path tracing supports rendering of caustics with a sufficient number of samples,
in practice it may be inefficient to the point that there is just too much noise.
This option can be unchecked, to disable reflective caustics.
Refractive Caustics
The same as above, but for refractive caustics.

.. _render-cycles-integrator-filter-glossy:

Filter Glossy
When using a value higher than 0.0, this will blur glossy reflections after blurry bounces,
to reduce noise at the cost of accuracy. 1.0 is a good starting value to tweak.

Some light paths have a low probability of being found while contributing much light to the pixel.
As a result these light paths will be found in some pixels and not in others, causing fireflies. An example of
such a difficult path might be a small light that is causing a small specular highlight on a sharp glossy
material, which we are seeing through a rough glossy material.
In fact in such a case we practically have a caustic.

With path tracing it is difficult to find the specular highlight,
but if we increase the roughness on the material, the highlight gets bigger and softer, and so easier to find.
Often this blurring will hardly be noticeable, because we are seeing it through a blurry material anyway,
but there are also cases where this will lead to a loss of detail in lighting.

.. seealso::

See :ref:`Reducing Noise &lt;render-cycles-reducing-noise-clamp-samples&gt;`
for examples of the clamp settings in use.

Geometry
========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render --&gt; Geometry`

Volume Sampling
---------------

Step Size
Distance between volume shader samples when rendering the volume.
Lower values give more accurate and detailed results but also increased render time.
Max Steps
Maximum number of steps through the volume before giving up,
to protect from extremely long render times with big objects or small step sizes.

.. _cycles-subdivision-rate:

Subdivision Rate
----------------

These settings are used to control the :ref:`True Displacement &lt;render-cycles-materials-displacement-true&gt;`.

.. note::

These Options are only available if :ref:`Experimental Feature Set &lt;cycles-experimental-features&gt;` is turned on.

Render
Size of :term:`micropolygons` in pixels.
Preview
Size of :term:`micropolygons` in pixels while preview rendering.

.. _bpy.types.CyclesRenderSettings.max_subdivisions:

Max Subdivisions
Stop subdividing when this level is reached even if the dice rate would produce finer :term:`tessellation`.

***********
Light Paths
***********

Ray Types
=========

Ray types can be divided into four categories:

- Camera: the ray comes straight from the camera.
- Reflection: the ray is generated by a reflection off a surface.
- Transmission: the ray is generated by a transmission through a surface.
- Shadow: the ray is used for (transparent) shadows.

Reflection and transmission rays can further have these properties:

- Diffuse: the ray is generated by a diffuse reflection or transmission (translucency).
- Glossy: the ray is generated by a glossy specular reflection or transmission.
- Singular: the ray is generated by a perfectly sharp reflection or transmission.

The Light Path node can be used to find out the type of ray the shading is being computed for.

.. figure:: /images/render_cycles_settings_light-path-rays.png

Bounce Control
==============

The maximum number of light bounces can be controlled manually.
While ideally this should be infinite,
in practice a smaller number of bounces may be sufficient,
or some light interactions may be intentionally left out for faster convergence.
The number of diffuse reflection,
glossy reflection and transmission bounces can also be controlled individually.

Light paths are terminated probabilistically when specifying a minimum number of light bounces
lower than the maximum. In that case paths longer than minimum will be randomly stopped when
they are expected to contribute less light to the image.
This will still converge to the same image, but renders faster while possibly being noisier.

A common source of noise is caustics, which are diffuse bounces followed by a glossy bounce
(assuming we start from the camera). An option is available to disable these entirely.

.. _render-cycles-light-paths-transparency:

Transparency
============

The transparent :abbr:`BSDF (Bidirectional scattering distribution function)` shader is given
special treatment. When a ray passes through it, light passes straight on,
as if there was no geometry there.
The ray type does not change when passing through a transparent BSDF.

Alpha pass output is also different for the transparent :abbr:`BSDF (Bidirectional scattering
distribution function)`. Other transmission :abbr:`BSDF (Bidirectional scattering distribution
function)` s are considered opaque, because they change the light direction.
As such they cannot be used for alpha-over compositing, while this is possible with the
transparent :abbr:`BSDF (Bidirectional scattering distribution function)`.

The maximum number of transparent bounces is controlled separately from other bounces.
It is also possible to use probabilistic termination of transparent bounces,
which might help rendering many layers of transparency.

Note that while semantically the ray passes through as if no geometry was hit, rendering
performance is affected as each transparency step requires executing the shader and tracing a
ray.

Ray Visibility
==============

Objects can be set to be invisible to particular ray types:

- Camera
- Diffuse reflection
- Glossy reflection
- Transmission
- Shadow

Properties Editor :menuselection:`Object --&gt; Cycles Settings --&gt; Ray visibility`.

This can be used, for example, to make an emitting mesh invisible to camera rays.
For duplicators, visibility is inherited; if the parent object is hidden for some ray types,
the children will be hidden for these too.

In terms of performance, using these options is more efficient that using a shader node setup
that achieves the same effect.
Objects invisible to a certain ray will be skipped in ray traversal already,
leading to fewer rays cast and shaders executed.

******************
Motion Blur &amp; Film
******************

Motion Blur
===========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render --&gt; Motion Blur`

Blender's animations are by default rendered as a sequence of *perfectly still* images.
While great for stop-motion and time-lapses, this is unrealistic, since fast-moving
objects do appear to be blurred in the direction of motion,
both in a movie frame and in a photograph from a real-world camera.

.. figure:: /images/render_cycles_settings_motion_blur_example.jpg

Cycles Motion Blur Example.

.. note::

If there are particles or other physics system in a scene,
be sure to bake them before rendering,
otherwise you might not get correct or consistent motion.

Options
-------

.. figure:: /images/render_cycles_settings_motion_blur_settings.png
:width: 175px
:align: right

Cycles Motion Blur Settings.

Position
Controls at what point the shutter opens in relation to the frame.

- End on frame
- Center on frame
- Start on frame

Shutter Speed
Time between frames over which motion blur is computed. Shutter time 1.0 blurs over the length of 1 frame,
2.0 over the length of two frames, from the previous to the next.
Shutter Curve
Curve defining how the shutter opens and closes.

Shutter Type
Replicates CMOS cameras by rendering a rolling shutter effect using scanlines.

- Top Bottom: Renders rolling shutter from the top of the image from the bottom.

Rolling Shutter Duration
Controls balance between pure rolling shutter effect and pure motion blur effect.
With zero being no rolling shutter and one being all rolling shutter.

.. warning::

An object modifier setup that changes mesh topology over time will cause severe problems.

Common examples of this are animated Booleans, Deformation before Edge Split, Remesh, Skin or Decimate modifiers.

.. seealso::

Each object has its own settings to control motion blur.
These options can be found in the Object tab of the Properties editor.
See :ref:`object setting &lt;render-cycles-settings-object-motion-blur&gt;` for more information.

Film
====

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render --&gt; Film`

Exposure
This can be used to change the brightness of an image.
Different then the *Exposure* option found in the :ref:`Color management &lt;render-post-color-management&gt;`
panel this exposure option works  is *on the data* while the Color management exposure is *on the view*.
Transparent
ToDo
Pixel Filter
.. Sensor simulation or Anti-aliasing.

Blackman-Harris, Box, Gaussian

Width
ToDo.
.. _render-cycles-settings-object-subdivision:

********************
Adaptive Subdivision
********************

.. note::

Implementation not finished yet, marked as an :ref:`Experimental Feature Set &lt;cycles-experimental-features&gt;`

When using the *Experimental Feature Set* the
:doc:`Subdivision Surface Modifier &lt;/modeling/modifiers/generate/subsurf&gt;`
gets changed to control the subdivision of a mesh at the time of rendering.
For this, all the other settings are the same except the *View* and *Render* settings.
These previously mentioned settings get removed/renamed and the following settings are added:

.. figure:: /images/cycles_materials_displacement_mod.png
:align: right

Subdivision Surface Modifier.

.. rubric:: Preview

Levels
The levels of subdivision to see in the 3D View,
this works the same as the *View* setting on the original *Subdivision Modifier*.

.. rubric:: Render

Adaptive
Use OpenSubdiv to give different subdivision levels to near and far objects automatically.
This allows nearer object to get more subdivisions and far objects to get less.

Dicing Rate
When using *Adaptive* the *Render Levels* property gets changed to *Dicing Rate*,
this property is used to multiply the :ref:`scene dicing rate &lt;cycles-subdivision-rate&gt;`.

.. figure:: /images/cycles-displacement-dicing.png

Subdivision Off/On, Dicing Rate: 1.0 - 0.3 - 0.05 (Monkeys look identical in viewport, no modifiers).

Levels
The levels of subdivision to see in the final render,
this works the same as the *Render* setting on the original *Subdivision Modifier*.

Known limitations
=================

- Missing support for UV subdivision.
- Creases do not match Blender creases currently.
- Instanced are currently uninstanced, leading to increased memory usage.
For those it is better to use non-adaptive subdivision still.
- Multi-view renders can have some inconsistencies between views.
- Editing displacement shaders while using :ref:`True Displacement &lt;render-cycles-materials-displacement-true&gt;`
does not update the viewport.

**************
Hair Particles
**************

These are extra settings for :doc:`Hair Particles &lt;/physics/particles/hair/index&gt;` used by Cycles.

Hair Rendering
==============

These are global settings that apply to all instances of hair systems.
They can be found inside the *Cycles Hair Rendering* panel under the particle tab.

.. Which also can to be deactivated.

The resolution of the strands is controlled by the step values in particle settings.
Each hair system uses the material identified in the particle settings in the same way as Blender Internal.

Primitive
---------

Triangles
Uses a triangle mesh.

Resolution
ToDo.
Line Segments
Uses a straight curve primitive.
Curve Segments
Uses a smooth Cardinal curve primitive. These interpolate a path through the curve keys.
However, it renders slower than line segments.

Curve Subdivisions
The interpolated path is subdivided to give points to connect.
The parameter subdivisions sets the number of divisions used.

Further Options
---------------

Shape
Thick
Cylindrical segments between two points.
Ribbons
Are flat planes following the strand direction facing the camera.
Cull back-faces
Excludes strands emitted from the mesh back facing the camera.
Min Pixels
Strands that are further away will be made wider, which is compensated with transparency to keep the look similar.
This effect is only applied for camera rays. It works best with ribbon primitives.
Max Extension
ToDo.

Hair Settings
=============

The Cycles Hair Settings, under the particle tab, are used to control each hair particle system's strand properties.

Shape
A shape parameter that controls the transition in thickness between the root and tip.
Negative values make the primitive rounded more towards the top,
the value of zero gives makes the primitive linear,
and positive values makes the primitive rounded more towards the bottom.

Thickness
---------

Root
Multiplier of the hair width at the root.
Tip
Multiplier of the hair width at the tip.
Scaling
Multiplier for the *Root* and *Tip* values. This can be used to change the thickness of the hair.

.. Particle width scaling relative to the object scale.

Close tip
Sets the thickness at the tip to zero, even when using a non-zero tip multiplier.

Texture
=======

ToDo

###################
Object Settings
###################

These are options that are scattered though out Blender,
and are often only available in certain contexts.

.. toctree::
:maxdepth: 2

adaptive_subsurf.rst
motion_blur.rst
hair.rst
.. _render-cycles-settings-object-motion-blur:

***********
Motion Blur
***********

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Object --&gt; Motion Blur`

Each object has its own motion blur settings along with the
:doc:`Scene Level Motion Blur &lt;/render/cycles/settings/motion_blur&gt;`
These settings can be found in the :doc:`Object Properties &lt;/editors/3dview/object/properties/introduction&gt;`
tab of the Properties editor.

Deformation
Enables motion blur for deformed meshes such as animated characters, including hair.
Steps
Controls accuracy of deformation motion blur, more steps gives more memory usage.
The actual number of time steps is :math:`2^{steps -1}`.

************************
Render Layers and Passes
************************

Layers
======

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Scene --&gt; Layer`

This section covers only the Render Layer settings appropriate for the Blender Render engine.
For the engine-independent settings, see :doc:`this section &lt;/render/post_process/layers&gt;`.

Exclude
Scene layers are shared between all render layers;
however, sometimes it is useful to leave out some object influence for a particular render layer.
That is what this option allows you to do.
Material
Overrides all materials in the render layer.
Samples
Render layer samples to override the scene samples.
Controlled by the :ref:`layer samples &lt;render-cycles-integrator-layer-samples&gt;` in the sampling panel.
Use Environment
Disables rendering the *Environment* render pass in the final render.
Use AO
Disables rendering the *Ambient Occlusion* render pass in the final render.
Use Surfaces
Disables rendering object materials in the final render.
Use Hair
Disables rendering hair strands in the final render.

.. _render-cycles-passes:

Passes
======

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Scene --&gt; Passes`

Passes can be used to split rendered images into colors, direct and indirect light to edit them individually,
and also to extract data such as depth or normals.

Lighting Passes
---------------

Diffuse Direct
Direct lighting from diffuse BSDFs. We define direct lighting as coming from lamps, emitting surfaces,
the background, or ambient occlusion after a single reflection or transmission off a surface.
BSDF color is not included in this pass.
Diffuse Indirect
Indirect lighting from diffuse BSDFs. We define indirect lighting as coming from lamps,
emitting surfaces or the background after more than one reflection or transmission off a surface.
BSDF color is not included in this pass.
Diffuse Color
Color weights of diffuse BSDFs. These weights are the color input socket for BSDF nodes,
modified by any Mix and Add Shader nodes.
Glossy Direct, Indirect, Color
Same as above, but for glossy BSDFs.
Transmission Direct, Indirect, Color
Same as above, but for transmission BSDFs.
Subsurface Direct, Indirect, Color
Same as above, but for subsurface BSDFs.
Emission
Emission from directly visible surfaces.
Environment
Emission from the directly visible background. When the film is set to transparent,
this can be used to get the environment color and composite it back in.
Shadow
Shadows from lamp objects. Mostly useful for compositing objects with shadow into existing footage.
Ambient Occlusion
Ambient occlusion from directly visible surfaces. BSDF color or AO factor is not included; i.e.
it gives a 'normalized' value between 0 and 1.

.. note::

:doc:`Transparent BSDFs are given special treatment &lt;/render/cycles/settings/light_paths&gt;`.
A fully transparent surface is treated as if there is no surface there at all;
a partially transparent surface is treated as if only part of the light rays can pass through.
This means it is not included in the Transmission passes;
for that a glass BSDF with index of refraction 1.0 can be used.

Combining
^^^^^^^^^

All these lighting passes can be combined to produce the final image as follows:

.. figure:: /images/render_cycles_settings_passes-combine.png

Data Passes
-----------

Combined
The final combination of render passes with everything included.
Z
Distance in :term:`BU` to any visible surfaces.

.. note::

The Z pass only uses one sample.
When depth values need to be blended in case of motion blur or :term:`DOF`, use the mist pass.

Mist
Distance to visible surfaces, mapped to the 0.0-1.0 range.
When enabled, settings are in :ref:`World tab &lt;render-cycles-integrator-world-mist&gt;`.
This pass can be used in compositing to add fade out object that are further away.

Normal
Surface normal used for shading.
Vector
Motion vectors for the vector blur node. The four components consist of 2D vectors
giving the motion towards the next and previous frame position in pixel space.
UV
Default render UV coordinates.
Object Index
Creates a mask of the object that can be later read by the
:doc:`ID Mask Node &lt;/compositing/types/converter/id_mask&gt;` in the compositor.
Material Index
Creates a mask of the material that can be later read by the
:doc:`ID Mask Node &lt;/compositing/types/converter/id_mask&gt;` in the compositor.

.. note:: The Z, Object Index and Material Index passes are not anti-aliased.

Alpha Threshold
Z, Index, normal, UV and vector passes are
only affected by surfaces with alpha transparency equal to or higher than this threshold.
With value 0.0 the first surface hit will always write to these passes, regardless of transparency.
With higher values surfaces that are mostly transparent can be skipped until an opaque surface is encountered.

***********
Performance
***********

Threads
-------

Mode
Auto-detect
Automatically chooses the amount threads to match the number of logical processors on your computer.

Fixed
Manually choose the amount threads to use for rendering. This can be useful for example,
if you want to use your computer while rendering you can set the property
to a thread count lower the amount of logical processors on your computer.

Tiles
-----

Tile Order
Order of rendering tiles. This does not significantly affect performance.

Tile size X/Y
The size of the tiles for rendering.

Depending on what device you are using for rendering, different tile sizes can give faster renders.
For CPU rendering smaller tiles sizes (like 32 x 32) tend to be faster, while for
:doc:`GPU rendering &lt;/render/cycles/gpu_rendering&gt;` larger tile sizes give better performance (like 256 x 256).

Progressive Refine
Instead of rendering each tile until it has finished every sample, refine the whole image progressively.
Note that progressive rendering is slightly slower than tiled rendering,
but time can be saved by manually stopping the render when the noise level is low enough.

For rendering animations it is best to disable this feature, as stopping a frame early is not possible.

Save Buffers
Saves all render layers and passes to the temp directory on a drive, and read them back after rendering has
finished. This saves memory usage during rendering, particularly when using many render layers and passes.

Viewport
--------

Viewport BVH Type
Dynamic BVH
Objects can be transformed, added and deleted interactively, at the cost of slower renders.
Static BVH
Object modifications require a complete :term:`BVH` rebuild which reduces interactivity but renders faster.

Start Resolution
Resolution to start rendering preview at, progressively increase it to the full viewport size.

Final Render
------------

Persistent Images
Keep image data in memory after rendering, for faster re-renders at the cost of extra memory usage when
performing other tasks in Blender.

Acceleration Structure
----------------------

Use Spatial Splits
Spatial splits improve rendering performance in scenes with a mix of large and small polygons. The
downsides are longer BVH build times and slightly increased memory usage.

Use Hair BVH
Use a special type of :term:`BVH` for rendering hair.
The bounding boxes are not axis aligned allowing a spatially closer fit to the hair geometry.
Disabling this option will reduce memory, at the cost of increasing hair render time.

*****
World
*****

.. figure:: /images/cycles-environment-lighting.jpg
:align: right

Lighting with an HDR image.

The world environment can emit light, ranging from a single solid color, physical sky model,
to arbitrary textures.

Surface
=======

The surface shader defines the light emission from the environment into the scene.
The world surface is rendered as if it is very distant from the scene,
and as such there is no two-way interacting between objects in the scene and the environment,
only light coming in. The only shader accepted is the Background node with a color input and
strength factor for the intensity of the light.

Image Based Lighting
--------------------

For image based lighting,
use the Environment Texture node rather than the Image Texture node for correct mapping.
This supports *Equirectangular* (also known as Lat/Long) for environment maps,
and *Mirror Ball* mapping for converting photos of mirror balls to environment maps.

Volume
======

A volume shader can be applied to the entirely world, filling the entire space.

Currently this is most useful for night time or other dark scenes,
as the world surface shader or sun lamps will have no effect if a volume shader is used.
This is because the world background is assumed to be infinitely far away,
which is accurate enough for the sun for example.
However, for modeling effects such as fog or atmospheric scattering,
it is not a good assumption that the volume fills the entire space,
as most of the distance between the sun and the earth is empty space.
For such effects it is be better to create a volume object surrounding the scene.
The size of this object will determine how much light is scattered or absorbed.

Ambient Occlusion
=================

Ambient occlusion is a lighting method based on how much a point on a surface is occluded by
nearby surfaces. This is a trick that is not physically accurate,
but it is useful to emphasize shapes of surfaces,
or as a cheap way to get an effect that looks a bit like indirect lighting.

Factor
The strength of the ambient occlusion; value 1.0 is like a white world shader.
Distance
Distance from shading point to trace rays.
A shorter distance emphasizes nearby features,
while longer distances make it also take objects further away into account.

Lighting from ambient occlusion is only applied to diffuse reflection BSDFs;
glossy or transmission BSDFs are not affected.
Transparency of surfaces will be taken into account, i.e.
a half-transparent surface will only half occlude.

An alternative method of using Ambient Occlusion on a per-shader basis is to use the
:doc:`Ambient Occlusion &lt;/render/cycles/nodes/types/shaders/ao&gt;` shader.

.. _render-cycles-integrator-world-mist:

Mist Pass
=========

Shown when the Mist pass is enabled.

Start
ToDo.
Depth
ToDo.
Falloff
ToDo.

.. tip::

A visualization can be activated in the :menuselection:`Camera --&gt; Display` panel.

.. _render-cycles-integrator-world-settings:

Settings
========

Surface
-------

Multiple Importance Sample
Enabling this will sample the background texture such that lighter parts are favored,
creating an importance map. It will producing less noise in the render in trade of artifacts (fireflies).
It is almost always a good idea to enable this when
using an image texture to light the scene, otherwise noise can take a very long time to converge.

Below is a comparison between *Multiple Importance Sample* off and on.
Both images are rendered for 25 seconds (Off: 1500 samples, On: 1000 samples).

.. list-table::

* - .. figure:: /images/cycles-mis-off.jpg

Multiple Importance Sample Off.

- .. figure:: /images/cycles-mis-on.jpg

Multiple Importance Sample On.

Map Resolution
Sets the resolution of the importance map.
A higher resolution will better detect small features in the map and give more accurate sampling.
but conversely will take up more memory and render slightly slower.
Higher values also may produce less noise when using high-res images.
Max Bounces
Maximal number of bounces the background light will contribute to the render.

.. seealso::

See :doc:`Reducing Noise &lt;/render/cycles/optimizations/reducing_noise&gt;`
for more information on how to reduce noise.

.. _render-cycles-integrator-world-settings-volume:

Volume
------

Sampling Method
Distance
If you have got a pretty dense volume that is lit from far away
then *Distance* sampling is usually more efficient.
Equiangular
If you have got a light inside or near the volume then *equiangular* sampling is better.
Multiple Importance
If you have a combination of both, then the multiple importance sampling will be better.

Interpolation
Interpolation method to use for the volume.

Linear
Good smoothness and speed.
Cubic
Smoothed high quality interpolation, but slower.

Homogeneous Volume
Assume volume has the same density everywhere (not using any textures), for faster rendering.
For example absorption in a glass object would typically not have any textures,
and by knowing this we can avoid taking small steps to sample the volume shader.

Ray Visibility
==============

As with other objects,
*Ray Visibility* allows you to control which other shaders can "see" the environment.

Tricks
======

Sometimes it may be useful to have a different background that is directly visible versus one
that is indirectly lighting the objects. A simple solution to this is to add a Mix node,
with the Blend Factor set to Is Camera Ray. The first input color is then the indirect color,
and the second the directly visible color. This is useful when using a high-res image for the
background and a low-res image for the actual lighting.

Similarly, adding the *Is Camera* and *Is Glossy* rays will mean that the high-res image
will also be visible in reflections.

.. figure:: /images/render_cycles_world_tricks.png

Nodes for the trick above.

************
Core Options
************

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render --&gt; Freestyle`

.. figure:: /images/render_freestyle_core-options.png

Freestyle core options.

Freestyle can be activated with the checkbox in the header of the Freestyle panel in the *Render* tab.

Line Thickness
There are two different modes for defining the base line thickness:

Absolute
The line thickness is given by a user-specified number of pixels. The default value is 1.0.
Relative
The unit line thickness is scaled by the proportion of the present vertical image resolution to 480 pixels.
For instance, the *unit line thickness* is 1.0 with the image height set to 480 px, 1.5 with 720 px
and 2.0 with 960 px.

Line Thickness
Only for *Absolute* line thickness: base line thickness in pixels is 1.0 by default.

**********************
Freestyle SVG Exporter
**********************

SVG exporting for Freestyle is available through an add-on.

.. figure:: /images/render_freestyle_svg-export_suzanne.svg
:align: center

An example of a SVG result produced by the Freestyle SVG Exporter.

This add-on can be enabled via :menuselection:`User Preferences --&gt; Add-ons --&gt; Render --&gt; Freestyle SVG Exporter`.
The GUI for the exporter should now be visible in the render tab of the Properties editor.
The exported ``.svg`` file is written to the default output path
:menuselection:`Properties editor --&gt; Render --&gt; Output`.

Options
=======

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render --&gt; Freestyle SVG Export`

.. figure:: /images/render_freestyle_svg-export-panel.png
:align: right

Freestyle SVG Export panel.

Mode
Option between Frame and Animation. Frame will render a single frame,
Animation will bundle all rendered frames into a single ``.svg`` file.
Split at Invisible
By default the exporter will not take invisible vertices into account and export them like they are visible.
Some stroke modifiers, like Blueprint, mark vertices as invisible to achieve a certain effect. Enabling this
option will make the paths split when encountering an invisible vertex, which leads to a better result.
Fill Contours
The contour of objects is filled with their material color.

.. note::

This feature is somewhat unstable -- especially with animations.

Stroke Cap Style
Defines the style the stroke caps will have in the SVG output.

Mitter
Corners with sharp edges.
Round
Corners are smoothed.
Bevel
Corners are beveled.

Exportable Properties
=====================

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render Layers --&gt; Freestyle Line Style SVG Export`

Because the representation of Freestyle strokes and SVG path objects is fundamentally different, an one-on-one
translation between Freestyle and SVG is not possible. The main shortcoming of SVG compared to Freestyle is that
Freestyle defines style per-point, where SVG defines it per-path. This means that Freestyle can produce much more
complex results that are impossible to achieve in SVG.

There are extended options for the exporter, located at the specific panels of the Freestyle renderer at the
Render Layers tab of the Properties editor. Those options are located at the Freestyle Line Style SVG
Export panel, at the bottom of the tab.

The properties (no modifiers applied) that can be exported are:

- Base color
- Base alpha
- Base thickness
- Dashes

Animations
==========

The exporter supports the creation of SVG animations. When the Mode is set to Animation, all frames from a render --
one when rendering a frame (:kbd:`F12`)
or all when rendering an animation (:kbd:`Shift-F12`) -- are saved into a single file.
Most modern browsers support the rendering of SVG animations.

.. figure:: /images/render_freestyle_svg-export_cube.svg
:align: center

An SVG animation rendered with the exporter.

Exporting Fills
---------------

Fills are colored areas extracted from a Freestyle render result. Specifically, they are defined by a combination of
the Contour and External Contour edge type, combined with some predicates. The fill result can be unexpected,
when the SVG renderer cannot correctly draw the path that the exporter has generated.
This problem is extra apparent in animations.

.. figure:: /images/render_freestyle_svg-export_pallet.svg
:align: center

An example of a .svg result produced by the Freestyle SVG Exporter.
Model by `Julien Deswaef &lt;https://github.com/xuv&gt;`__.

Fills support holes and layering. When using layers, the exporter tries to render objects with the same material as
the patch. The exporting of fills and especially the order in which they are layered is by no means perfect.
In most cases, these problems can be easily solved in Inkscape or a text editor.
.. _render-freestyle:

############
Freestyle
############

.. toctree::
:maxdepth: 2

introduction.rst
core.rst
viewmap.rst
parameter_editor/index.rst
python.rst
line.rst
export_svg.rst

************
Introduction
************

What is FreeStyle?
==================

FreeStyle is an edge- and line-based non-photorealistic (NPR) rendering engine.
It relies on mesh data and z-depth information to draw lines on selected edge types.
Various line styles can be added to produce artistic ("hand drawn", "painted", etc.)
or technical (hard line) looks.

The two operating modes: :doc:`Python Scripting &lt;/render/freestyle/python&gt;` and
:doc:`Parameter Editor &lt;/render/freestyle/parameter_editor/index&gt;` --
allow a powerful diversity of line styles and results. Line styles such as Japanese big brush, cartoon, blueprint,
thickness-with-depth are already pre-scripted in Python. The Parameter Editor mode allows intuitive editing of
features such as dotted lines and easy setup of multiple line types and edge definitions. On top of all of that,
with the introduction of line style modifiers, the sky is the limit!

.. list-table::

* - .. figure:: /images/render_freestyle_introduction_example-1.png

ATV buggy by Rylan Wright (RONIN). CC BY.
(`File:AtvBuggy.zip &lt;https://wiki.blender.org/index.php/File:AtvBuggy.zip&gt;`__)

- .. figure:: /images/render_freestyle_introduction_example-2.png

By mato.sus304. CC BY-SA.
(`File:Mato_sus304_cut02.zip &lt;https://wiki.blender.org/index.php/File:Mato_sus304_cut02.zip&gt;`__)

* - .. figure:: /images/render_freestyle_introduction_example-3.png

A cartoon scene from `OHA Studio &lt;http://oha-studios.com/&gt;`__
© Mechanimotion Entertainment.
(`the blend-file &lt;https://download.blender.org/demo/test/FreeStyle_demo_file.blend.zip&gt;`__).

- .. figure:: /images/render_freestyle_introduction_example-4.png

Blueprint render of Martin M-130 from 1935 by LightBWK. CC0. Warning:
heavy file! designed for stress test Blender to the limits and may crash Blender.
(`File:M-130Blueprint.zip &lt;https://wiki.blender.org/index.php/File:M-130Blueprint.zip&gt;`__)

More artwork can be found at `Release Note Artwork Showcase
&lt;https://wiki.blender.org/index.php/Dev:Ref/Release_Notes/2.67/FreeStyle#FreeStyle_Artwork_Showcase&gt;`__.

The Big Picture
===============

- Activate FreeStyle by :menuselection:`Properties Editor --&gt; Render tab --&gt; FreeStyle` panel's checkbox.
- FreeStyle settings are located in the new *Render Layers* tab.
- One render layer can only have one viewmap. A viewmap holds the edge detection settings (Crease Angle,
Culling toggle, Face Smoothness toggle, Material Boundaries toggle,
Sphere Radius and Kr Derivative Epsilon advanced options).
- A viewmap can have multiple line sets.
- A line set controls which line types and selections will be rendered, from lines based on your scene.
- Each line set uses one line style (which can be shared between multiple line sets).
- A line style tells FreeStyle how to render the linked line sets in terms of color, alpha,
thickness and other aspects.

.. figure:: /images/render_freestyle_introduction_view-map-processes.png

Block diagram of FreeStyle view map and processes.

Known Limitations
=================

- Highly memory demanding: All mesh objects in a render layer are loaded at once.
- Only faced mesh objects are supported. The following kinds of meshes are ignored:

- Mesh faces with wire materials.
- Mesh faces with completely transparent materials.
- Mesh faces with the *Cast Only* material option enabled.

- Transparent faces are treated as opaque faces.
- No edges at face intersections are detected yet.
- Layer masks do not work with FreeStyle.
- FreeStyle rendering results do not have any Z depth information.
- Panoramic cameras are not supported.

****
Line
****

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Material --&gt; Freestyle Line`

Line Color
Specifies the line colors on a per-material basis.
Priority
Specify the ordering of competing line colors at material boundaries.

.. seealso::

A use case of the line color priority is detailed in a Freestyle development
`blog article &lt;http://freestyleintegration.wordpress.com/2014/07/07/line-color-priority/&gt;`__.

###################
Parameter Editor
###################

.. toctree::
:maxdepth: 2

introduction.rst
line_set.rst
line_style/index.rst

************
Introduction
************

.. figure:: /images/render_freestyle_parameter-editor-mode.png

Parameter Editor Mode.

The Freestyle *Parameter Editor Mode* is a user-friendly interface
to define and control line sets and line styles.

:doc:`Line Sets &lt;/render/freestyle/parameter_editor/line_set&gt;`
Control which of the edges detected by Freestyle will actually be used (rendered).
:doc:`Line Styles &lt;/render/freestyle/parameter_editor/line_style/introduction&gt;`
Control how the selected edges are rendered.

A view map (hence a render layer) can have multiple line sets,
and each line set is linked to one line style.

********
Line Set
********

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render Layer --&gt; Freestyle Line Set`

A line set selects, among the lines (edges) detected by Freestyle,
which ones will be rendered using its attached
:doc:`line style &lt;/render/freestyle/parameter_editor/line_style/introduction&gt;`, through various methods.

.. figure:: /images/render_freestyle_line-set.png

Freestyle Line Set panel

Selection By
============

Visibility
----------

There are three choices for selecting edges by visibility.

Visible
Only lines occluded by no surfaces are rendered.
Hidden
Lines occluded by at least one surface are rendered.

.. figure:: /images/render_freestyle_line-set_visibility_hidden-edges.png

Proof of concept of visible and hidden edges by LightBWK
(`Sample blend-file &lt;https://wiki.blender.org/index.php/File:HiddenCreaseEdgeMark.zip&gt;`__)

QI Range
QI stands for *Quantitative Invisibility*. Lines occluded by a number of surfaces in the given range are rendered.

Start and End
Min/max number of occluding surfaces for a line to be rendered.

.. figure:: /images/render_freestyle_line-set_visibility_qi-range.png

QI Range proof of concept demo, Start: 3, End: 7, by LightBWK
(`Sample blend-file &lt;https://wiki.blender.org/index.php/File:QI-Range.zip&gt;`__)

Edge Types
----------

Edge types are basic algorithms for the selection of lines from geometry. When using the
parameter editor you have to choose at least one edge type in order to get a render output,
but several edge types can be combined in one line set.
Edge types can also be excluded from calculation by pressing the *X* next to them.

.. figure:: /images/render_freestyle_line-set_edge-types_basic.png

Examples of some basic edge types:
Silhouette (green), Crease (black), Border (blue) and Edge Marks (red)
(`File:EdgeType.zip &lt;https://wiki.blender.org/index.php/File:EdgeType.zip&gt;`__ by LightBWK)

Silhouette
Draws silhouettes around your closed objects; it is often good for organic objects (like Suzanne &amp; Sphere),
and bad for sharp edges, like a box. It cannot render open mesh objects like open cylinders and flat planes.
The output is affected by the *Kr Derivative Epsilon* viewmap setting.

Crease
Shows only edges whose adjacent faces form an angle greater than the defined viewmap's *Crease Angle*.

.. figure:: /images/render_freestyle_line-set_edge-types_crease.png
:width: 600px

Crease Angle proof of concept for 121º by LightBWK
( `the blend-file &lt;https://wiki.blender.org/index.php/File:CreaseAngle.zip&gt;`__)

Border
Border is for open/unclosed edge meshes; an open cylinder has an open edge at the top and bottom,
and a plane is open all around. Suzanne's eye socket is an open edge. All open edges will have lines rendered.
This depends on the mesh structure.

Edge Marks
Renders marked edges. See
`Edge Marks`_ for details.

Contour
Draws the outer edges and inner open border.

External Contour
Draws the contour lines, but only on the outer edges.

.. figure:: /images/render_freestyle_line-set_edge-types_contour.png
:width: 600px

Left pair: Contour; Right pair: External Contour.

Suggestive Contour
Draws some lines which would form the contour of the mesh if the viewport was shifted.
Depends on your viewmap settings for *Kr Derivative Epsilon* and *Sphere Radius*
(further information: `File:Manual-2.6-Render-Freestyle-PrincetownLinestyle.pdf
&lt;https://wiki.blender.org/index.php/File:Manual-2.6-Render-Freestyle-PrincetownLinestyle.pdf&gt;`__).

Material Boundary
Draws lines where two materials meet on the same object.

Ridge &amp; Valley
Draws ridges and valleys. Depends on your *Sphere Radius* viewmap settings.

Edge Marks
^^^^^^^^^^

.. figure:: /images/render_freestyle_line-set_edge-marks.png

Edge Mark setting in the Line Sets tab.

In edit mode you can mark "Freestyle Edges" in the same manner you can mark "Seams" for UV
unwrapping or "Sharp" for edge split.
These marked edges are available to render when you select *Edge Mark*.

This is done as follows:

#. Select the mesh object and enter *Edit Mode*.
#. Select the edges you want to be marked.
#. Press :kbd:`Ctrl-E` and select *Mark Freestyle Edge*.

Edge marks are useful when you want to draw lines along particular mesh edges.
The examples below explain the use of edge marks.

.. figure:: /images/render_freestyle_line-set_edge-marks_mark-freestyle-edge.png

Marking Freestyle Edges in edit mode.

The edge marks are highlighted in green.

.. list-table::

* - .. figure:: /images/render_freestyle_line-set_edge-marks_example-1.png

Render without Edge Marks.

- .. figure:: /images/render_freestyle_line-set_edge-marks_example-2.png

Render with Edge Marks enabled.

With edge marks enabled, the previously-marked lines are always rendered.
You can see the black contour lines and the blue lines that are made with edge marks.

What are edge marks good for?

- When you need to render marks on an almost-flat plane, when other edge types cannot detect any line.
- When you want full control of edge rendering. Often used for edges of squarish shapes.
- Mark the whole base mesh to be rendered for base mesh preview.

What are edge marks not good for?

- Round outer edges (use instead *Contour*/*External Contour*/*Silhouette*).

Face Marks
----------

.. figure:: /images/render_freestyle_line-set_face-marks.png

Face mark options.

To set a face mark:

#. Select a mesh object and enter *Edit Mode*.
#. Select the faces you want to be marked.
#. Press :kbd:`Ctrl-F` and select *Mark Freestyle Face*.

Face marks are useful for removing lines from certain areas of a mesh.

In this example, two faces of the default cube are marked like the image on the left.
On the right is a render without face marks activated.

.. list-table::

* - .. figure:: /images/render_freestyle_line-set_face-marks_example-1.png

Marked Faces (Edit Mode).

- .. figure:: /images/render_freestyle_line-set_face-marks_example-2.png

Render Output.

The line selection can be controlled via inclusion and faces options:

Inclusive/Exclusive
Whether to include or exclude edges matching defined face mark conditions from the line set.

One Face
(De)select all edges which have one or both neighbor faces marked.
Both Faces
(De)select all edges which have both of their neighbor faces marked.

The image below shows the resulting combinations.

.. list-table::

* - .. figure:: /images/render_freestyle_line-set_face-marks_example-3.png

Inclusive, One Face.

- .. figure:: /images/render_freestyle_line-set_face-marks_example-4.png

Inclusive, Both Faces.

.. list-table::

* - .. figure:: /images/render_freestyle_line-set_face-marks_example-5.png

Exclusive, One Face.

- .. figure:: /images/render_freestyle_line-set_face-marks_example-6.png

Exclusive, Both Faces.

Group
-----

You can include or exclude objects for line calculation, based on their belonging to a group.

Group
The name of the object group to use.

Inclusive/Exclusive
Whether to include or exclude lines from those objects in this line set.

Image Border
------------

If enabled,
Freestyle only takes geometry within the image border into consideration for line calculation.
This reduces render times but increases continuity problems when geometry is moved out of and
into camera view.

****
Tabs
****

Color
=====

.. figure:: /images/render_freestyle_line-style_color.png

Line Style Color UI.

In this tab you control the color of your strokes.

Base Color
The base color for this line style.

Alpha
=====

.. figure:: /images/render_freestyle_line-style_alpha.png

Line Style Alpha UI.

In this tab you control the alpha (transparency) of your strokes.

Base Transparency
The base alpha for this line style.

Thickness
=========

In this tab you control the thickness of your strokes.

.. figure:: /images/render_freestyle_line-style_thickness.png

Base Thickness
The base thickness for this line style.

Thickness Position
Control the position of stroke thickness from the original (backbone) stroke geometry. There are four choices:

Center
The thickness is evenly split to the left and right side of the stroke geometry.
Inside
The strokes are drawn within object boundary.
Outside
The strokes are drawn outside the object boundary.
Relative
This allows you to specify the relative position by a number between 0.0 (inside) and 1.0 (outside),
in the *Thickness Ratio* number button just below.

The thickness position options are applied only to strokes of edge types
*Silhouette* and *Border*,
since these are the only edge types defined in terms of the object boundary.
Strokes of other edge types are always drawn using the *Center* option.

Geometry
========

.. figure:: /images/render_freestyle_line-style_geometry.png

Line Style Geometry Overall UI.

In this tab you control the geometry of your strokes.
It contains only the option to add modifiers.

Texture
=======

.. figure:: /images/render_freestyle_line-style_texture.png

Line Style Texture.

Use Nodes/Textures
Blender Render uses texture mapping and influence panels.
In Cycles textures are defined by means of
shader :doc:`nodes &lt;/render/freestyle/parameter_editor/line_style/nodes/index&gt;`.
Spacing Along Stroke
Allows to set the "pace" of textures mapped along the length of strokes.
Go to LineStyle Textures
The "Go to LineStyle Textures" button is a shortcut to texture settings in the other tab.

#########################
Line Style &amp; Modifiers
#########################

.. toctree::
:maxdepth: 2

introduction.rst
strokes.rst
alpha.rst
nodes/index.rst
modifiers/index.rst

************
Introduction
************

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render Layer --&gt; Freestyle Line Style`

.. figure:: /images/render_freestyle_line-style_introduction_line-style-panel.png

Line Style UI.

In Freestyle, the line style settings define the appearance of a line set using five main aspects:

- :doc:`Stroke &lt;/render/freestyle/parameter_editor/line_style/strokes&gt;`
- :doc:`Color, Alpha, Thickness, Geometry, Texture &lt;/render/freestyle/parameter_editor/line_style/alpha&gt;`

These allow you to get many different styles of renders
(technical draw, rough sketch, cartoon, oriental calligraphy, etc.).

You can create as many line styles as you wish, and reuse a given line style for several line
sets by selecting it from the select menu next to its name.

.. note:: Length Unit

Unless otherwise specified, all lengths in line style settings are in pixels (either relative or absolute,
as specified in the :doc:`core options &lt;/render/freestyle/core&gt;`).

.. figure:: /images/render_freestyle_line-style_introduction_line-style-example.png

Line Style demo `File:LineStyles.zip &lt;https://wiki.blender.org/index.php/File:LineStyles.zip&gt;`__.

********
Geometry
********

These modifiers have no mix nor influence settings,
as they always completely apply to the strokes' geometry (like object modifiers do). They take
the resulting two-dimensional strokes from the Freestyle line set and displace or deform them
in various ways.

As with other modifier stacks in Blender, they are applied from top to bottom.

2D Offset
=========

The *2D Offset* modifier adds some two-dimensional offsets to the stroke backbone
geometry. It has two sets of independent options/effects:

.. figure:: /images/render_freestyle_line-style_geometry_2d-offset.png

Start and End
These two options add the given amount of offset to the start (or end) point of the stroke, along the (2D)
normal at those points. The effect is blended over the whole stroke, if you for example,
set only *Start* to 50, the start of the stroke is offset 50 pixels along its normal,
the middle of the stroke, 25 pixels along its own normal, and the end point is not moved.
X and Y
These two options simply add a constant horizontal and/or vertical offset to the whole stroke.

2D Transform
============

The *2D Transform* modifier applies two-dimensional scaling and/or rotation to the
stroke backbone geometry. Scale is applied before rotation.

The center (pivot point) of these 2D transformations can be:

.. figure:: /images/render_freestyle_line-style_geometry_2d-transform.png

Stroke Center
The median point of the stroke.
Stroke Start
The beginning point of the stroke.
Stroke End
The end point of the stroke.
Stroke Point Parameter
The *Stroke Point Parameter* factor controls where along the stroke the pivot point is
(start point if set to 0.0; end point if set to 1.0).
Absolute 2D Point
The *Pivot X* and *Pivot Y* allows you to define the position of the pivot point in the final
render (from the bottom left corner).

.. important::

Currently, you have to take into account the *real* render size,
i.e. resolution **and** resolution percentage.

Scale X and Scale Y
The scaling factors, in their respective axes.
Rotation Angle
The rotation angle.

.. figure:: /images/render_freestyle_line-style_geometry_2d-transform_example.png
:width: 430px

2D Transform modifier
`File:Toycar_Three_Contours.zip &lt;https://wiki.blender.org/index.php/File:Toycar_Three_Contours.zip&gt;`__.

Backbone Stretcher
==================

.. figure:: /images/render_freestyle_line-style_geometry_backbone-stretcher.png

The *Backbone Stretcher* modifier stretches (adds some length to)
the beginning and end of the stroke.

Backbone Length
Length to add to the strokes' ends.

Bézier Curve
============

.. figure:: /images/render_freestyle_line-style_geometry_bezier-curve.png

The *Bézier Curve* modifier replaces the stroke by a Bézier approximation of it.

Error
The maximum distance allowed between the new Bézier curve and the original stroke.

.. figure:: /images/render_freestyle_line-style_geometry_bezier-curve_example.png
:width: 430px

Bézier Curve modifier demo by T.K.
`File:toycar_bezier.zip &lt;https://wiki.blender.org/index.php/File:toycar_bezier.zip&gt;`__.

Blueprint
=========

The *Blueprint* modifier produces blueprint-like strokes using either circular,
elliptical, or square contours. A blueprint here refers to those lines drawn at the beginning
of free-hand drawing to capture the silhouette of objects with a simple shape such as circles,
ellipses and squares.

.. figure:: /images/render_freestyle_line-style_geometry_blueprint.png

Shape
Which base shapes to use for this blueprint: *Circles*, *Ellipses* or *Squares*.
Rounds
How many rounds are generated, as if the pen draws the same stroke several times
(i.e. how many times the process is repeated).
Random Radius and Random Center
For the *Circles* and *Ellipses* shapes.
Adds some randomness to each round in the relevant aspect.
Using more than one round with no randomness would be meaningless, as they would draw over each other exactly.
Backbone Length and Random Backbone
For the *Squares* shapes.
The first adds some extra length to each edge of the generated squares (also affected by the second parameter).
The second adds some randomness to the squares.

Note that the *Min 2D Length* feature from the *Strokes* settings is quite
handy here, to avoid the noise generated by small strokes...

Guiding Lines
=============

The *Guiding Lines* modifier replaces a stroke by a straight line connecting both of
its ends.

.. figure:: /images/render_freestyle_line-style_geometry_guiding-lines.png

Offset
Offset the start and end points along the original stroke, before generating the new straight one.

This modifier will produce reasonable results when strokes are short enough,
because shorter strokes are more likely to be well approximated by straight lines. Therefore,
it is recommended to use this modifier together with one of the splitting options
(by 2D angle or by 2D length) from the *Strokes* panel.

.. figure:: /images/render_freestyle_line-style_geometry_guiding-lines_example.png
:width: 430px

Guiding Lines modifier Demo by T.K.
`File:Toycar_Guiding_Line.zip &lt;https://wiki.blender.org/index.php/File:Toycar_Guiding_Line.zip&gt;`__.

Perlin Noise 1D
===============

The *Perlin Noise 1D* modifier adds one-dimensional Perlin noise to the stroke.
The curvilinear abscissa (value between 0 and 1 determined by a point's position
relative to the first and last point of a stroke) is used as the input to the
noise function to generate noisy displacements.

This means that this modifier will give an identical result for two strokes with the same length and sampling
interval.

.. figure:: /images/render_freestyle_line-style_geometry_perlin-noise-1d.png

Frequency
How dense the noise is (kind of a scale factor along the stroke).
Amplitude
How much the noise distorts the stroke in the *Angle* direction.
Seed
The seed of the random generator (the same seed over a stroke will always give the same result).
Octaves
The "level of detail" of the noise.
Angle
In which direction the noise is applied (0.0 is fully horizontal).

Perlin Noise 2D
===============

.. figure:: /images/render_freestyle_line-style_geometry_perlin-noise-2d.png

The *Perlin Noise 2D* modifier adds one-dimensional Perlin noise to the stroke.  The modifier generates noisy
displacements using 2D coordinates of stroke vertices as the input of the noise generator.

Its settings are exactly the same as the *Perlin Noise 1D* modifier.

Polygonization
==============

.. figure:: /images/render_freestyle_line-style_geometry_polygonization.png

The *Polygonization* modifier simplifies strokes as much as possible
(in other words, it transforms smooth strokes into jagged polylines).

Error
The maximum distance allowed between the new simplified stroke and the original one
(the larger this value is, the more jagged/approximated the resulting polylines are).

Sampling
========

The *Sampling* modifier changes the definition, precision of the stroke,
for the following modifiers.

.. figure:: /images/render_freestyle_line-style_geometry_sampling.png

Sampling
The smaller this value, the more precise are the strokes.
Be careful; too small values will require a huge amount of time and memory during render!

Simplification
==============

The *Simplification* modifier merges stroke vertices that lie close to one another,
like the *Decimate* modifier for meshes.

.. figure:: /images/render_freestyle_line-style_geometry_simplification.png

Tolerance
Measure for how close points have to be to each other to be merged.
A higher tolerance means more vertices are merged.

.. figure:: /images/render_freestyle_line-style_geometry_simplification_example.png
:width: 600px
:align: center

Sinus Displacement
==================

The *Sinus Displacement* modifier adds a sinusoidal displacement to the stroke.

.. figure:: /images/render_freestyle_line-style_geometry_sinus-displacement.png

Wavelength
How wide the undulations are along the stroke.
Amplitude
How high the undulations are across the stroke.
Phase
Allows "offsetting" ("moving") the undulations along the stroke.

.. figure:: /images/render_freestyle_line-style_geometry_sinus-displacement_example.png
:width: 430px

Sinus Displacement modifier demo by T.K.
`File:Toycar_Sinus.zip &lt;https://wiki.blender.org/index.php/File:Toycar_Sinus.zip&gt;`__.

Spatial Noise
=============

The *Spatial Noise* modifier adds some spatial noise to the stroke.
Spatial noise displacements are added in the normal direction
(i.e., the direction perpendicular to the tangent line) evaluated at each stroke vertex.

.. figure:: /images/render_freestyle_line-style_geometry_spatial-noise.png

Amplitude
How much the noise distorts the stroke.
Scale
How wide the noise is along the stroke.
Octaves
The level of detail of the noise.
Smooth
When enabled, apply some smoothing over the generated noise.
Pure Random
When disabled, the next generated random value depends on the previous one;
otherwise they are completely independent. Disabling this setting gives a more "consistent" noise along a stroke.

Tip Remover
===========

The *Tip Remover* modifier removes a piece of the stroke at its beginning and end.

.. figure:: /images/render_freestyle_line-style_geometry_tip-remover.png

Tip Length
Length of stroke to remove at both of its tips.

#############
Modifiers
#############

.. toctree::
:maxdepth: 2

properties.rst
geometry.rst

**********
Properties
**********

There are several modifiers for stroke vertex properties (i.e., line color, alpha transparency and thickness)
available. As with other modifier stacks in Blender, they are applied from top to bottom.

Common Options
==============

Mix
The modifier output can be mixed with the base property using the usual methods
(see for example the :doc:`Mix compositing node &lt;/compositing/types/color/mix&gt;`
for further discussion of this topic).
Influence
How much the result of this modifier affects the current property.

Mapping
---------

Mapping between the defined range and the range input of the modifier.
e.g. a range of crease values.

Color
^^^^^

Color Ramp
A :ref:`color ramp &lt;ui-color-ramp-widget&gt;` that maps the property to a stroke color.

Alpha
^^^^^

Mapping
Either a linear progression (from 0.0 to 1.0),
or a custom mapping :ref:`curve &lt;ui-curve-widget&gt;`.

.. note::

Note the linear non-inverted option is equivalent to "do nothing",
as original values from materials are already in the (0.0 to 1.0) range.
Thats the case for: Crease Angle, 3D Curvature, Material, Noise, Tangent.

Invert
Inverts the *Mapping*.

Thickness
^^^^^^^^^

Min Thickness and Max Thickness
The minimum and maximum assigned thickness.
Mapping
Either a linear progression (from *Min Thickness* to *Max Thickness*),
or a custom mapping curve (on the same range).
Invert
Inverts the *Mapping*.

Types
=====

Along Stroke
------------

The *Along Stroke* modifier alters the base property with a new one from
a given range mapped along each stroke's length. In other words,
it applies a gradient along each stroke.

Calligraphy
-----------

The *Calligraphy* modifier (thickness only) mimics some broad and flat pens for calligraphy.
It generates different thickness based on the orientation of the stroke.

.. figure:: /images/render_freestyle_line-style_thickness_calligraphy.png

Orientation
The angle (orientation) of the virtual drawing tool, from the vertical axis of the picture.
For example, an angle of 0.0 mimics a pen aligned  with the vertical axis.
Hence, the thickest strokes will be the vertical ones i.e. stroke's direction is aligned with the angle, and
the thinnest will be the horizontal ones i.e. stroke's direction is perpendicular to the angle.

.. figure:: /images/render_freestyle_line-style_thickness_calligraphy_example.png
:width: 430px

Calligraphy modifier demo by T.K.
`File:Toycar_Calligraphy.zip &lt;https://wiki.blender.org/index.php/File:Toycar_Calligraphy.zip&gt;`__.

Crease Angle
------------

A modifier based on the Crease Angle (angle between two adjacent faces).
If a stroke segment does not lie on a crease (i.e., the edge does not have the *Crease Angle nature*,
its properties are not touched by the modifier.

.. figure:: /images/render_freestyle_line-style_alpha_crease-angle.png

Alpha Modifier.

Min Angle and Max Angle
The range of input values to the mapping.
Out-of-range crease angle values will be clamped by the
Min and Max angles and their corresponding property values.

.. figure:: /images/render_freestyle_line-style_color_crease-angle_example.png
:width: 430px

Crease Angle modifier demo by T.K.
`File:Render_freestyle_modifier_crease_angle.blend
&lt;https://wiki.blender.org/uploads/b/b4/Render_freestyle_modifier_crease_angle.blend&gt;`__.

Curvature 3D
------------

.. figure:: /images/render_freestyle_line-style_color_curvature-3d-example.png
:width: 430px

Curvature 3D modifier demo by T.K.
`File:Render_freestyle_modifier_curvature_3d.blend
&lt;https://wiki.blender.org/index.php/File:Render_freestyle_modifier_curvature_3d.blend&gt;`__.

A modifier based on radial curvatures of the underlying 3D surface.
The `curvature &lt;https://en.wikipedia.org/wiki/Curvature&gt;`__ of a 2D curve
at a point is a measure of how quickly the curve turns at the point.
The quicker the turn is, the larger the curvature is at the point.
The curvature is zero if the curve is a straight line.
Radial curvatures are those computed for a 2D curve that appears at the cross-section
between the 3D surface and a plane defined by the view point (camera location)
and the normal direction of the surface at the point.

For radial curvatures to be calculated (and therefore for this modifier to have any effect),
the *Face Smoothness* option has to be turned on and the object needs to have *Smooth Shading*.

.. figure:: /images/render_freestyle_line-style_alpha_curvature-3d.png

Alpha Modifier.

Min Curvature and Max Curvature
The limits of the mapping.
If the current point of the stroke is at *Min Curvature* or less from the target,
it will take the start point of the mapping, and conversely,
if it is at *Max Curvature* or more from the target, it will take the end point value of the mapping.

Distance from Camera
--------------------

The *Distance from Camera* modifier alters the base property with a new one from
a given range using the distance to the active camera as the parameter.

.. figure:: /images/render_freestyle_line-style_alpha_distance-from-camera.png

Alpha Modifier.

Range Min and Range Max
The limits of the mapping from "distance to camera" to "property in mapping".
If the current point of the stroke is at *Range Min* or less from the active camera,
it will take the start value, and conversely,
if it is at *Range Max* or more from the camera, it will take the end value.
These values are in the current scene's units, not in pixels!
Fill Range by Selection
Set the min/max range values from the distances between the current selected objects and the camera.

Distance from Object
--------------------

The *Distance from Object* modifier alters the base property with a new one from
a range, using the distance to a given object as the parameter.

.. figure:: /images/render_freestyle_line-style_alpha_distance-from-object.png

Alpha Modifier.

Target
The object to measure distance from.

Range Min and Range Max
Similar to *Distance to Camera* but to the object.
Fill Range by Selection
Set the min/max range values from the distances between the current selected objects and the target.

The other settings are those of the standard Blender color ramp!

Material
--------

.. figure:: /images/render_freestyle_line-style_color_material.png

Color Modifier.

The *Material* modifier alters the base property with a new one taken from a given range mapped on
the current material under the stroke.

You can use various properties of the materials, among which many are mono-component
(i.e. give B&amp;W results). In this case for the color modifier, an optional color ramp can be used to
map these grayscale values to colored ones.

In the reverse case properties of the materials, which are multi-components
(i.e. give RGB results) the mean value will be used for alpha and thickness modifiers.

If used with the *Split by Material* option in the *Stroke* tab,
the result will not be blurred between materials along the strokes.

.. figure:: /images/render_freestyle_line-style_color_material_example.png
:width: 430px

Material modifiers demo by T.K.
`File:Lilies_Color_Material.zip &lt;https://wiki.blender.org/index.php/File:Lilies_Color_Material.zip&gt;`__.

Noise
-----

The *Noise* modifier uses a pseudo-random number generator to variably distribute the property along the stroke.

.. figure:: /images/render_freestyle_line-style_thickness_noise.png

Thickness Modifier.

Amplitude
The maximum value of the noise. A higher amplitude means a less transparent (more solid) stroke.
Period
The period of the noise. This means how quickly the property value can change.
A higher value means a more smoothly changing color along the stroke.
Seed
Seed used by the pseudo-random number generator.
Asymmetric
Thickness only -- Allows the thickness to be distributed unevenly at every point.
Internally, the stroke is represented as a backbone with a thickness to the right and left side.
All other thickness shaders make sure that the left and right thickness values are equal.
For the Noise shader however, a meaningful (and good-looking) result
can be created by assigning different values to either side of the backbone.

.. figure:: /images/render_freestyle_line-style_thickness_noise_example.png
:width: 430px

Effect generated with a noise thickness modifier using asymmetric thickness.

Tangent
-------

This modifier bases its effect on the traveling direction of the stroke evaluated at the stroke's vertices.

#########
Nodes
#########

.. toctree::
:maxdepth: 1

uv_along_stroke.rst
output.rst

**********************
Line Style Output Node
**********************

.. figure:: /images/render_freestyle_line-style_nodes_ouput.png
:align: right

Line Style Output Node.

The *Line Style Output* node specifies how to mix the texture information
into the base color of line styles.

In Blender Render equivalent options can be found in
:menuselection:`Properties editor --&gt; Texture --&gt; Influence` panel.

Inputs
======

Color
Color input for the texture.
Color Factor
Standard mix factor of the *Color* value.
Alpha
Alpha input for the texture.
Alpha Factor
Standard mix factor of the *Alpha* value.

Properties
==========

Mix
The Blend types could be selected in the select menu.
See :term:`Color Blend Modes` for details on each blending mode.
Clamp
Limit the highest color value to not exceed 1.

Outputs
=======

This node has no outputs.

***************
UV Along Stroke
***************

.. figure:: /images/render_freestyle_line-style_nodes_uv-along-stoke.png
:align: right

UV Along Stroke Node.

The *UV Along Stroke* input node is maps textures along the stroke length,
making it possible to mimic pencil, paintbrush, and other art medium marks.

In Blender Render equivalent options can be found in
:menuselection:`Properties editor --&gt; Texture --&gt; Mapping` panel.

.. note::

These UV maps become available only during the Freestyle rendering process.
Hence, the UV Along Stroke node cannot be replaced by the conventional UV Map input node
which takes an existing UV map already defined as part of mesh data.

Inputs
======

This node has no inputs.

Properties
==========

Use Tips
Allows to use lower quarters of a texture image for the head and tail tips of a stroke,
while the upper half for the stroke body.

Outputs
=======

UV
UV maps defined along strokes.

Example
=======

The following screen capture shows a typical shader node tree that maps a floral texture image along strokes.
The UV Along Stroke input node retrieves UV maps defined by Freestyle along generated strokes, and
feeds them to the Vector input channel of the Image Texture node.
A texture image is selected in the Image Texture node,
and its color is fed to the Alpha channel of the Line Style Output node.
Since the Alpha Factor is set to one, the texture image replaces the base alpha transparency of the active line style
(shown in the Freestyle Line Style panel).
On the other hand, the Mix blend mode is selected in the Line Style Output node with the Color Factor set to zero,
so that the gradient line color specified in the active line style is applied along strokes.

.. figure:: /images/render_freestyle_line-style_nodes_uv-along-stoke_example.png

`.blend &lt;https://wiki.blender.org/index.php/File:Blender_272_textured_strokes_in_cycles.blend&gt;`__

It is noted that the texture image (FS_floral_brush.png)
shown in the screen capture is an example of Freestyle brush images with tips.
Specifically, the upper half of the image is used as a seamless horizontal tile of the stroke body,
whereas the parts in the lower half are tips (stroke caps) at both ends of the stroke.

******
Stroke
******

Strokes are the final rendered lines. Yet you can tweaks them, for example,
by removing the ones longer/shorter than some threshold,
chaining lines into a single stroke or breaking a stroke into several ones based on angles,
dashed pattern, etc.

Chaining
========

.. figure:: /images/render_freestyle_line-style_stroke_chaining.png

Chaining.

By default all retrieved lines from the line set are chained together.
There are two basic chaining methods:

Plain
The default chaining method; it creates simple chains.

Sketchy
This chaining option allows for generating chains of feature edges with sketchy multiple strokes.
Basically, it generates *Round* strokes instead of a single one.
It is only really useful if you use some random-driven modifiers in the line style!

Rounds
It specifies the number of rounds in sketchy strokes.

Chaining can also be turned off to render each line separately,
which can be useful for line styles which depend on accurate representation of the line set.

Splitting
=========

.. figure:: /images/render_freestyle_line-style_stroke_splitting.png

Splitting.

You can split up chains of Freestyle lines by checking one of the following:

Min, Max 2D Angle
Splits chains of feature edges when they make a 2D angle above (or below) a minimum (or maximum) threshold.
2D Length
Splits chains when they are longer than the given value.
Material Boundary
Splits chains of feature edges if they cross from one material to another.

Split Dash, Gap
Splits the chains using the given dashed pattern ("D" stands for "dash",
"G" stands for "gap"; see also `Dashed Line`_).

D1, G1, D2, G2, D3, G3

Sorting
=======

.. figure:: /images/render_freestyle_line-style_stroke_sorting.png

Sorting.

You can sort the order of your strokes, allowing the lines to stack in the order given.

Sort key
A sort key is used to determine the stacking order of lines.

Distance from camera
Lines closer to the camera lie on top of further lines.
2D length
Longer lines lie on top of shorter lines.
Projected X, Y
Sort by the projected X or Y value in the image coordinate system.
Integration Type
Use in tandem with the Sort Key to determine the range for sorting.
Since the distance of a line from the camera may vary over vertices,
this option computes the sort key for a line from the values computed at
individual vertices. The value computed for the line is:

Mean
The mean of the values obtained for the vertices.
Min
The minimum of the values obtained for the vertices.
Max
The maximum of the values obtained for the vertices.
First
The value obtained for the first vertex.
Last
The value obtained for the last vertex.
Sort Order
With the given result you can choose to "Reverse" the sort order.

Selection
=========

.. figure:: /images/render_freestyle_line-style_stroke_selection.png

Selection.

You can also choose to only render selected chains.

Minimal, Maximal 2D Length
Chains longer and/or shorter than * 2D Length*.
Chain Count
Allows the selection of first N chains.

Caps
----

.. figure:: /images/render_freestyle_line-style_stroke_caps.png

Line tip caps.

You can choose between three types of line caps:

Butt
Flat cap, exactly at the point the line ends.
Round
A half circle centered on the end point of the line.
Square
A square centered on the end point of the line (hence, like the circle,
the drawn end of the line is slightly extended compared to its computed value).

.. figure:: /images/render_freestyle_line-style_stroke_caps_example.png

Line caps example.

Dashed Line
===========

.. figure:: /images/render_freestyle_line-style_stroke_dashed-line.png

Dashes Line UI.

By enabling the *Dashed Line* check box,
you can specify three pairs of dash and gap lengths.
Dash values define the lengths of dash strokes,
while gap values specify intervals between two dashes.

If a zero gap is specified,
then the corresponding dash is ignored even if it has a non-zero value.

Dashes are treated as separate strokes, meaning that you can apply line caps,
as well as color, alpha and thickness modifiers.

*********************
Python Scripting Mode
*********************

The Python Scripting mode offers full programmability for line stylization.
In this control mode, all stylization operations are written as Python scripts referred to as
style modules in the Freestyle terminology. The input to a style module is a view map (i.e.,
a set of detected feature edges), and the output is a set of stylized strokes.

A style module is composed of successive calls of five basic operators: selection, chaining,
splitting, sorting and stroke creation. The selection operator identifies a subset of input
feature edges based on one or more user-defined selection conditions (predicates).
The selected edges are processed with the chaining,
splitting and sorting operators to build chains of feature edges. These operators are also
controlled by user-supplied predicates and functions in order to determine how to transform
the feature edges into chains. Finally,
the chains are transformed into stylized strokes by the stroke creation operator,
which takes a list of user-defined stroke shaders.

Python style modules are stored within blend-files as text data-blocks.
External style module files first need to be loaded in the Text Editor.
Then the select menu within an entry of the style module stack
allows you to select a module from the list of loaded style modules.

.. figure:: /images/render_freestyle_python-scripting-mode.png

A screen capture of a style module (cartoon.py) loaded in the Text Editor (left),
as well as Freestyle options in the Python Scripting mode in the Render Layers buttons (right).

Freestyle for Blender comes with a number of Python style modules that can serve as a starting
point of your own style module writing. See also the section of the Freestyle Python API in
the Blender Python API reference manual for the full detail of style module constructs.

.. list-table::

* - .. figure:: /images/render_freestyle_python-scripting-mode_example-1.jpg
:width: 320px

By T.K. using the Python Scripting mode.

(`File:Turning_Pages.zip &lt;https://wiki.blender.org/index.php/File:Turning_Pages.zip&gt;`__, CC0)

- .. figure:: /images/render_freestyle_python-scripting-mode_example-2.png
:width: 320px

By T.K. using the Python Scripting mode.

(`File:Lily_Broken_Topology.zip &lt;https://wiki.blender.org/index.php/File:Lily_Broken_Topology.zip&gt;`__, CC0)

Writing Style Modules
=====================

A style module is a piece of code responsible for the stylization of Freestyle line drawing.
The input of a style module is a set of feature edges called view map (ViewMap).
The output is a set of stylized lines also referred to as strokes. A style module is
structured as a pipeline of operations that allow for building strokes from the input edges
within the view map.

There are five kinds of operations (listed with corresponding operator functions):

- Selection ``Operators.select()``
- Chaining ``Operators.chain(), Operators.bidirectional_chain()``
- Splitting ``Operators.sequential_split(), Operators.recursive_split()``
- Sorting ``Operators.sort()``
- Stroke creation ``Operators.create()``

The input view map is populated with a set of ViewEdge objects. The selection operation is
used to pick up ViewEdges of interest to artists based on user-defined selection conditions
(predicates). Chaining operations take the subset of ViewEdges and build Chains by
concatenating ViewEdges according to user-defined predicates and functions.
The Chains can be further refined by splitting them into smaller pieces (e.g.,
at points where edges make an acute turn) and selecting a fraction of them (e.g.,
to keep only those longer than a length threshold).
The sorting operation is used to arrange the stacking order of chains to draw one line on top of another.
The chains are finally transformed into stylized strokes
by the stroke creation operation applying a series of stroke shaders to individual chains.

ViewEdges, Chains and Strokes are generically referred to as one-dimensional (1D) elements.
A 1D element is a polyline that is a series of connected straight lines.
Vertices of 1D elements are called 0D elements in general.

All the operators act on a set of active 1D elements.
The initial active set is the set of ViewEdges in the input view map.
The active set is updated by the operators.

Selection
---------

The selection operator goes through every element of the active set and keeps only the ones
satisfying a certain predicate.
The ``Operators.select()`` method takes as the argument a unary
predicate that works on any ``Interface1D`` that represents a 1D element.
For example::

Operators.select(QuantitativeInvisibilityUP1D(0))

This selection operation uses the ``QuantitativeInvisibilityUP1D`` predicate to select only the
visible ``ViewEdge`` (more precisely, those whose quantitative invisibility is equal to 0).
The selection operator is intended to selectively apply the style to a fraction of the active 1D elements.

It is noted that ``QuantitativeInvisibilityUP1D`` is a class implementing the predicate that tests
line visibility, and the ``Operators.select()``
method takes an instance of the predicate class as argument. The testing of the predicate for
a given 1D element is actually done by calling the predicate instance, that is,
by invoking the ``__call__`` method of the predicate class.
In other words, the ``Operators.select()`` method takes as argument a functor
which in turn takes an ``Interface0D`` object as argument.
The Freestyle Python API employs functors extensively to implement predicates,
as well as functions.

Chaining
--------

The chaining operators act on the set of active ``ViewEdge`` objects and determine the topology of the future strokes.
The idea is to implement an iterator to traverse the ViewMap graph by marching along ViewEdges.
The iterator defines a chaining rule that determines the next
``ViewEdge`` to follow at a given vertex (see ``ViewEdgeIterator``).
Several such iterators are provided as part of the Freestyle Python API
(see ``ChainPredicateIterator`` and ``ChainSilhouetteIterator``).
Custom iterators can be defined by inheriting the ``ViewEdgeIterator`` class.
The chaining operator also takes as argument a UnaryPredicate working on ``Interface1D`` as a stopping criterion.
The chaining stops when the iterator has reached a ``ViewEdge`` satisfying this
predicate during the march along the graph.

Chaining can be either unidirectional ``Operators.chain()`` or bidirectional ``Operators.bidirectional_chain()``.
In the latter case, the chaining will propagate in the two directions from the starting edge.

The following is a code example of bidirectional chaining::

Operators.bidirectional_chain(
ChainSilhouetteIterator(),
NotUP1D(QuantitativeInvisibilityUP1D(0)),
)

The chaining operator uses the ``ChainSilhouetteIterator`` as the chaining rule and stops chaining
as soon as the iterator has come to an invisible ``ViewEdge``.

The chaining operators process the set of active ``ViewEdge`` objects in order.
The active ViewEdges can be previously sorted using the ``Operators.sort()`` method (see below).
It starts a chain with the first ``ViewEdge`` of the active set.
All ViewEdges that have already been involved in the chaining process are marked
(in the case of the example above, the time stamp of each ``ViewEdge`` is modified by default),
in order not to process the same ``ViewEdge`` twice.
Once the chaining reaches a ``ViewEdge`` that satisfies the stopping predicate,
the chain is terminated.
Then a new chain is started from the first unmarked ``ViewEdge`` in the active set.
This operation is repeated until the last unmarked ``ViewEdge`` of the active set was processed.
At the end of the chaining operation,
the active set is set to the Chains that have just been constructed.

Splitting
---------

The splitting operation is used to refine the topology of each Chain.
Splitting is performed either sequentially or recursively. Sequential splitting
``Operators.sequentialSplit()`` in its basic form,
parses the Chain at a given arbitrary resolution and evaluates a unary predicate
(working on 0D elements) at each point along the Chain.
Every time the predicate is satisfied, the chain is split into two chains.
At the end of the sequential split operation,
the active set of chains is set to the new chains. ::

Operators.sequentialSplit(TrueUP0D(), 2)

In this example, the chain is split every 2 units.
A more elaborated version uses two predicates instead of one: One to determine the starting
point of the new chain and the other to determine its ending point. This second version can
lead to a set of Chains that are disjoint or that overlap if the two predicates are different.
(see ``Operators.sequentialSplit()`` for more details).

Recursive splitting ``Operators.recursiveSplit()`` evaluates a function on the 0D elements
along the Chain at a given resolution and find the point that gives the maximum value for the
function. The Chain is then split into two at that point.
This process is recursively repeated on each of the two new Chains,
until the input Chain satisfies a user-specified stopping condition. ::

func = Curvature2DAngleF0D()
Operators.recursive_split(func, NotUP1D(HigherLengthUP1D(5)), 5)

In the code example above,
the Chains are recursively split at points of the highest 2D curvature.
The curvature is evaluated at points along the Chain at a resolution of 5 units.
Chains shorter than 5 units will not be split anymore.

Sorting
-------

The sorting operator ``Operators.sort()`` arranges the stacking order of active 1D elements.
It takes as argument a binary predicate used as a "smaller than" operator to order two 1D elements. ::

Operators.sort(Length2DBP1D())

In this code example, the sorting uses the ``Length2DBP1D`` binary predicate to sort the
``Interface1D`` objects in the ascending order in terms of 2D length.

The sorting is particularly useful when combined with causal density. Indeed,
the causal density evaluates the density of the resulting image as it is modified. If we wish
to use such a tool to decide to remove strokes whenever the local density is too high,
it is important to control the order in which the strokes are drawn. In this case,
we would use the sorting operator to insure that the most "important" lines are drawn first.

Stroke creation
---------------

Finally, the stroke creation operator ``Operators.create()``
takes the active set of Chains as input and build Strokes. The operator takes two arguments.
The first is a unary predicate that works on ``Interface1D`` that is designed to make a last
selection on the set of chains.
A Chain that does not satisfy the condition will not lead to a Stroke.
The second input is a list of shaders that will be responsible for the shading of each built stroke. ::

shaders_list = [
SamplingShader(5.0),
ConstantThicknessShader(2),
ConstantColorShader(0.2,0.2,0.2,1),
]
Operators.create(DensityUP1D(8,0.1, IntegrationType.MEAN), shaders_list)

In this example,
the ``DensityUP1D`` predicate is used to remove all Chains whose mean density is higher than 0.1.
Each chain is transformed into a stroke by resampling it so as to have a point every 5 units
and assigning to it a constant thickness of 2 units and a dark gray constant color.

User control on the pipeline definition
---------------------------------------

Style module writing offers different types of user control,
even though individual style modules have a fixed pipeline structure.
One is the sequencing of different pipeline control structures, and another is through the
definition of functor objects that are passed as argument all along the pipeline.

Different pipeline control structures can be defined by sequencing the selection,
chaining, splitting, and sorting operations.
The stroke creation is always the last operation that concludes a style module.

Predicates, functions, chaining iterators, and stroke shaders can be defined by inheriting
base classes and overriding appropriate methods. See the reference manual entries of the
following base classes for more information on the user-scriptable constructs.

.. TODO: should these really be listed??? link to API docs seems more appropriate - ideasman42

.. hlist::
:columns: 2

- ``UnaryPredicate0D``
- ``UnaryPredicate1D``
- ``BinaryPredicate0D``
- ``BinaryPredicate1D``
- ``UnaryFunction0DDouble``
- ``UnaryFunction0DEdgeNature``
- ``UnaryFunction0DFloat``
- ``UnaryFunction0DId``
- ``UnaryFunction0DMaterial``
- ``UnaryFunction0DUnsigned``
- ``UnaryFunction0DVec2f``
- ``UnaryFunction0DVec3f``
- ``UnaryFunction0DVectorViewShape``
- ``UnaryFunction0DViewShape``
- ``UnaryFunction1DDouble``
- ``UnaryFunction1DEdgeNature``
- ``UnaryFunction1DFloat``
- ``UnaryFunction1DUnsigned``
- ``UnaryFunction1DVec2f``
- ``UnaryFunction1DVec3f``
- ``UnaryFunction1DVectorViewShape``
- ``UnaryFunction1DVoid``
- ``ViewEdgeIterator``
- ``StrokeShader``

********
Viewmaps
********

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render Layer --&gt; Freestyle`

.. figure:: /images/render_freestyle_view-map_freestyle-panel.png

Freestyle panel.

There is only one viewmap per render layer. It controls the edge detection parameters.

Control Mode
Which detected edges are actually rendered, and how, can be controlled either through:

Parameter Editor Mode
The user-friendly :doc:`parameter editor &lt;/render/freestyle/parameter_editor/index&gt;`.
Python Scripting Mode
Powerful but complex :doc:`Python scripting &lt;/render/freestyle/python&gt;`.

View Map Cache
A option to reuse a previously computed view map for subsequent rendering.
The cache is automatically updated when the mesh geometry of the input 3D scene has been changed.

This functionality offers a major performance boost for Freestyle animation rendering
when camera-space mesh geometry is static, as well as for repeated still renders
with updates of line stylization options.

Although the ''View map cache'' checkbox is a render layer option, the cache memory is
shared by all render layers and scenes. This means that if Freestyle is used for two or more render layers
(possibly in different scenes through the compositor),
then the cached view map for one render layer is replaced by a new view map
for another render layer and hence no performance gain is expected.
Face Smoothness
When enabled, *Smooth Shading* will be taken into account for edges calculation.
Crease Angle
If two adjacent faces form an angle less than the defined *Crease Angle*,
the edge between them will be rendered when using *Crease* edge type selection in a line set.
The value also affects *Silhouette* edge type selection.
Culling
Ignore the edges that are out of view (saves some processing time and memory,
but may reduce the quality of the result in some cases).

Advanced Options
================

.. figure:: /images/render_freestyle_view-map_freestyle-panel-advanced.png

Advanced Options enabled.

*Sphere Radius* affects the calculation of curvatures for *Ridge*,
*Valley* and *Suggestive Contour* edge type selection in a line set.

Kr Derivative Epsilon
It provides you with control over the output of *Suggestive Contour* and *Silhouette*
edge type selection (further information in
`this pdf &lt;https://wiki.blender.org/index.php/file:Manual-2.6-Render-Freestyle-PrincetownLinestyle.pdf&gt;`__).
.. _render-index:

#########
Render
#########

.. toctree::
:maxdepth: 2

introduction.rst
blender_render/index.rst
cycles/index.rst
output/index.rst
post_process/index.rst
freestyle/index.rst
workflows/index.rst
opengl.rst
audio/index.rst

************
Introduction
************

Rendering is the process of creating a 2D image (or video) from your 3D scene.
What that image looks like is based on four factors which the user can control:

- A :doc:`Camera &lt;/render/blender_render/camera/introduction&gt;`
- The :doc:`Lighting &lt;/render/blender_render/lighting/introduction&gt;` in your scene
- The :doc:`Material &lt;/render/blender_render/materials/introduction&gt;` of each object
- Various render settings (quality, image size, layers etc)

Your computer will perform various complex calculations
based on those factors in order to give you your rendered image.
This process may take some time depending on the complexity of the scene and your hardware.

Once the render is complete, it is possible to do additional manipulation of the image,
called :doc:`Post Processing &lt;/render/post_process/index&gt;`.

Finally, the output can be saved to an image or video file
using one of the :doc:`Output Formats &lt;/render/output/output&gt;`.

Workflow
========

In general, the process for rendering is:

#. Position the camera
#. Light the scene
#. Setup materials
#. Render a test image using lower quality settings
#. Change or fix anything you noticed in the render
#. Repeat the above two steps until you are satisfied
#. Render a high quality image, change or fix any issues and repeat until satisfied
#. Save your image to a file, or render the animation to a video or image sequence.

Render Engines
==============

The Render Engine is the set of code which controls how your materials and lighting are used,
and ultimately what the rendered image looks like.

Some engines may be better at certain things than others due
to the math they use or core principles around which they were written.

Blender includes two render engines by default:

- :doc:`Blender Render &lt;/render/blender_render/index&gt;`
- :doc:`Cycles &lt;/render/cycles/index&gt;`

More render engines from third-party developers can also be added using
:doc:`Add-ons &lt;/preferences/addons&gt;`

*************
OpenGL Render
*************

OpenGL rendering uses the 3d View's drawing for quick *preview* renders.

This allows you to inspect your animatic
(for object movements, alternate angles, etc.).

This can also be used to preview your animations --
in the event your scene is too complex for your system to play back in real-time in the 3D View.

You can use OpenGL to render both images and animations.

Below is a comparison between the OpenGL render and a final render using
the Cycles Render engine.

.. list-table:: Model by © 2016 pokedstudio.com

* - .. figure:: /images/render_opengl_example-opengl-render.jpg
:width: 320px

OpenGL Render.

- .. figure:: /images/render_opengl_example-cycles-render.jpg
:width: 320px

Full Render.

.. tip:: Showing Only Rendered Objects

To access this option, enable the *Only Render* in the :doc:`Display Panel &lt;/editors/3dview/properties/panels&gt;`.

While this option is not specific to OpenGL rendering, its often useful to enable,
since it removes data such as rigs and empties that can be a distraction.

Settings
========

.. admonition:: Reference
:class: refbox

| Menu:     :menuselection:`Info Editor --&gt; Render --&gt; OpenGL Render Options`

For the most part, *OpenGL Render* uses the view-port settings,
Sampling and Alpha Transparency Mode options can be set by
the :menuselection:`Render --&gt; OpenGL Render Options` from the Info Editor header.
Additionally, some render settings are used too:

- Render Dimensions
- Render Aspect
- File Format &amp; Output (file-path, format, compression settings... etc).

Rendering
=========

Activating OpenGL render from the menu will render from the active camera.

You can also render any view-port, from the header of the *3D View*,
using the small button showing a *Camera*.

.. figure:: /images/render_opengl_view-port-render-buttons.png

OpenGL Render buttons.

As with a normal render, you can abort it with :kbd:`Esc`.

Render a Still Image
Click on the small button showing a *camera* in the header of the 3D View.

Or from the menu: :menuselection:`Render --&gt; OpenGL Render Image`
from the header of the *Info Editor*
Render an Animation
Click on the small button showing a *slate* in the header of the 3D View.

Or from the menu: :menuselection:`Render --&gt; OpenGL Render Animation`
from the header of the *Info Editor*
Render from the Sequencer
Click on the small button showing a *slate* in the header of *Sequencer* preview region.

Using scene strips in the sequencer you can edit together scenes to quickly render an entire sequence of shots.

This can be activated using the render icons in the sequencer's playback header.

Known Limitations
=================

OpenGL Anti-Aliasing Support
----------------------------

Some graphics cards do not support this feature
(known as the frame-buffer multi-sample OpenGL extensions).

In this case rendering works but no anti-aliasing is performed.

Enabling *Full Sample*, can be used to workaround this limit,
because it does not rely on hardware multi-sample support.

.. hint::

Exact extensions needed, as listed in output from :ref:`help-system-info` (OpenGL section):

- ``GL_ARB_texture_multisample``
- ``GL_EXT_framebuffer_blit``
- ``GL_EXT_framebuffer_multisample_blit_scaled``
- ``GL_EXT_framebuffer_multisample``
.. |numsp| unicode:: U+2007

****************
Animation Player
****************

The :menuselection:`Info Editor --&gt; Render --&gt; Play Rendered Animation`
menu will play back the rendered animation in a new window.

You can also drop images or movie files in a running animation player.
It will then restart the player with the new data.

A external player can also be used instead of the one included in Blender.
To do this, select it in the :doc:`User Preferences &lt;/preferences/file&gt;`.

Shortcuts
=========

The following table shows the available hotkeys for the animation player.

.. rubric:: Playback

.. list-table::
:header-rows: 1

* - Action
- Hotkey
* - Start/Pause:
- :kbd:`Spacebar`
* - Start playback (when paused):
- :kbd:`Enter`
* - Quit:
- :kbd:`Esc`

.. rubric:: Timeline

.. list-table::
:header-rows: 1

* - Action
- Hotkey
* - Scrub in time:
- :kbd:`LMB`
* - Step back one frame:
- :kbd:`Left`
* - Step forward one frame:
- :kbd:`Right`
* - Step back 10 frames:
- :kbd:`Down`
* - Step forward 10 frames:
- :kbd:`Up`
* - Manual frame stepping:
- :kbd:`NumpadPeriod`

.. rubric:: Playback Options

.. list-table::
:header-rows: 1

* - Action
- Hotkey
* - Backward playback:
- :kbd:`Shift-Down`
* - Forward playback
- :kbd:`Shift-Up`
* - Slow down playback:
- :kbd:`Minus`
* - Speed up playback:
- :kbd:`Plus`
* - Toggle looping:
- :kbd:`Numpad0`
* - Toggle frame skipping:
- :kbd:`A`
* - Toggle ping-pong:
- :kbd:`P`

.. rubric:: Display

.. list-table::
:header-rows: 1

* - Action
- Hotkey
* - Toggle Time Cursor (Indicator):
- :kbd:`I`
* - Flip drawing on the X axis:
- :kbd:`F`
* - Flip drawing on the Y axis:
- :kbd:`Shift-F`
* - Hold to show frame numbers:
- :kbd:`Shift`
* - Zoom in:
- :kbd:`Ctrl-Plus`
* - Zoom out:
- :kbd:`Ctrl-Minus`

.. rubric:: Frame rate

- 60 fps :kbd:`Numpad1`
- 50 fps :kbd:`Numpad2`
- 30 fps :kbd:`Numpad3`
- 25 fps :kbd:`Numpad4`
- 24 fps :kbd:`Shift-Numpad4`
- 20 fps :kbd:`Numpad5`
- 15 fps :kbd:`Numpad6`
- 12 fps :kbd:`Numpad7`
- 10 fps :kbd:`Numpad8`
- |numsp|\ 6 fps :kbd:`Numpad9`
- |numsp|\ 5 fps :kbd:`NumpadSlash`

################
Render Output
################

.. toctree::
:maxdepth: 2

render_panel.rst
output.rst
video.rst
metadata.rst
animation_player.rst

********
Metadata
********

.. figure:: /images/render_output_metadata-panel.png

Metadata panel.

The *Metadata* panel includes options for writing meta-data into render output.

.. note::

Only some image formats support metadata:
See :doc:`image formats &lt;/data_system/files/media/image_formats&gt;`.

Stamp Output
Add metadata has text to the render.

Stamp Text Color
Set the color and alpha of the stamp text.
Stamp Background
Set the color and alpha of the color behind the text.
Font Size
Set the size of the text.
Draw Labels
Draws the labels before the metadata text. For example,
"Camera" infront of camera name etc.

.. rubric:: Enabled Metadata

Stamping can include the following data.

Time
Includes the current scene time and render frame as ``HH:MM:SS.FF``
Date
Includes the current date and time.
Render Time
Includes the render time.
Frame
Includes the frame number.
Scene
Includes the name of the active scene.
Memory
Includes the peak memory usage.
Note
Includes a custom note.

.. hint::

It can be useful to use the *Note* field if you are setting up a render-farm.

Since you can script any information you like into it,
such as an identifier for the render-node or the job-number.

For details on stamping arbitrary values,
see: `this page &lt;https://blender.stackexchange.com/questions/26643&gt;`__.

Camera
Includes the name of the active camera.
Lens
Includes the name of the active camera's lens value.
Filename
Includes the filename of the blend-file.
Marker
Includes the name of the last marker.
Seq. Strip
Includes the name of the foreground sequence strip.

.. rubric:: Sequencer

Strip Metadata
Use metadata from the strips in the sequencer.

**************
Output Options
**************

The first step in the rendering process is to determine and set the output options.
This includes render size, frame rate, pixel aspect ratio, output location, and file type.

.. _render-tab-dimensions:

Dimensions panel
================

.. figure:: /images/render_output_dimensions-panel.png

Dimensions Panel.

Render Presets
Common format presets for TVs and screens.

Resolution
X/Y
The number of pixels horizontally and vertically in the image.
Percentage
Slider to reduce or increase the size of the rendered image relative to the X/Y values above.
This is useful for small test renders that are the same proportions as the final image.

Aspect Ratio
Older televisions may have non-square pixels,
so this can be used to control the shape of the pixels along the respective axis.
This will *pre-distorted* the images which will look stretched on a computer screen,
but which will display correctly on a TV set.
It is important that you use the correct pixel aspect ratio when rendering to prevent re-scaling,
resulting in lowered image quality.

See :doc:`Video Output &lt;/render/output/video&gt;` for details on pixel aspect ratio.

Border
You can render just a portion of the view instead of the entire frame. While in Camera View,
press :kbd:`Ctrl-B` and drag a rectangle to define the area you want to render.
:kbd:`Ctrl-Alt-B` is the shortcut to disable the border.

.. note::

This disables the *Save Buffers* option in *Performance* and *Full Sample* option in *Anti-Aliasing*.

Enabling *Crop* will crop the rendered image to the *Border* size,
instead of rendering a black region around it.

Frame Range
Set the *Start* and *End* frames for :doc:`Rendering Animations &lt;/render/workflows/animations&gt;`.
*Step* controls the number of frames to advance by for each frame in the timeline.

Frame Rate
For an :doc:`Animation &lt;/render/workflows/animations&gt;`
the frame rate is how many frames will be displayed per second.

Time Remapping
Use to remap the length of an animation.

.. _render-tab-output:

Output Panel
============

.. figure:: /images/render_output_output-panel.png

Output panel.

This panel provides options for setting the location of rendered frames for animations,
and the quality of the saved images.

File Path
Choose the location to save rendered frames.

When rendering an animation,
the frame number is appended at the end of the file name with four padded zeros (e.g. ``image0001.png``).
You can set a custom padding size by adding the appropriate number of ``#`` anywhere in the file name
(e.g. ``image_##_test.png`` translates to ``image_01_test.png``).

This setting expands :doc:`relative paths &lt;/data_system/files/relative_paths&gt;`
where a ``//`` prefix represents the directory of the current blend-file.
Overwrite
Overwrite existing files when rendering.
Placeholders
Create empty placeholder frames while rendering.
File Extensions
Adds the correct file extensions per file type to the output files.
Cache Result
Saves the rendered image and passes to a Multilayer EXR-file in temporary location on your hard drive.
This allows the compositor to read these to improve performance, especially for heavy compositing.
Output Format
Choose the file format to save to.
Based on which format is used, other options such as channels, bit-depth and compression level are available.

.. hint:: Primitive Render-Farm

An easy way to get multiple machines to share the rendering workload is to:

- Set up a shared directory over a network file-system.
- Disable *Overwrite*, enable  *Placeholders* in the Render *Output* panel.
- Start as many machines as you wish rendering to that directory

************
Render Panel
************

.. figure:: /images/render_output_render-panel.png
:align: right

Render panel.

Render :kbd:`F12`
Starts rendering a still image of the current frame.
Animation :kbd:`Ctrl-F12`
Starts rendering an animation.
See :doc:`Rendering Animations &lt;/render/workflows/animations&gt;` for more detail.
Audio
Mixes all the audio found in a scene and mixes into one file.
See :doc:`/render/audio/introduction`.

By default the biggest area is replaced with the UV/Image Editor and the render appears.

To chancel the rendering process click the chancel button ``X`` besides the progressbar in the Info Editor,
or press :kbd:`Esc`.

Display
=======

Renders are displayed in the UV/Image Editor. You can set the way this is displayed to several
different options in the Display menu:

Display
Keep UI
The image is rendered to the UV/Image Editor, but the UI remains the same.
You will need to open the UV/Image Editor manually to see the render result.
New Window
A new floating window opens up, displaying the render.
Image Editor
One of the existing editors is replaced with the UV/Image Editor, showing the render.
Full Screen
The UV/Image Editor replaces the UI, showing the render.
Lock Interface
Lock interface during rendering in favor of giving more memory to the renderer.

************
Video Output
************

Preparing your work for video
=============================

Once you master the trick of animation you will surely start to produce wonderful
animations, encoded with your favorite codecs,
and possibly you will share them on the Internet with the rest of the community.

Sooner or later you will be struck with the desire to build an animation for television,
or maybe burn your own DVDs. To spare you some disappointment,
here are some tips specifically targeted at Video preparation.
The first and principal one is to remember the double-dashed white lines in the camera view!

If you render for PC then the whole rendered image which lies within the *outer* dashed
rectangle will be shown. For television, some lines and some part of the lines will be lost
due to the mechanics of the electron beam scanning in your TV's cathode ray tube. You are
guaranteed that what is within the *inner* dashed rectangle in camera view will be visible
on the screen. Everything within the two rectangles may or may not be visible,
depending on the given TV set that your audience watches the video on.

.. Remove:? Talk to Sergey.

Color Saturation
================

Most video tapes and video signals are not based on the RGB model but on the YCrCb model:
more precisely, the YUV in Europe (PAL), and the YIQ in the USA (NTSC),
the latter being quite similar to the former. Hence some knowledge of this is necessary too.

The YCrCb model sends information as 'Luminance', or intensity (Y)
and two 'Crominance' signals, red and blue (Cr and Cb).
Actually a Black and White TV set shows only luminance,
while color TV sets reconstruct color from Crominances (and from luminance).
Construction of the YCrCb values from the RGB ones takes two steps
(the constants *in italics* depend on the system: PAL or NTSC):

First, the Gamma correction (*g* varies: 2.2 for NTSC, 2.8 for PAL):

- R' = R\ :sup:`1/g`
- G' = G\ :sup:`1/g`
- B' = B\ :sup:`1/g`

Then, the conversion itself:

- Y = 0.299R' + 0.587G' + 0.114B'
- Cr = *a*\ :sub:`1` (R' - Y) + *b*\ :sub:`1` (B' - Y)
- Cb = *a*\ :sub:`2` (R' - Y) + *b*\ :sub:`2` (B' - Y)

Whereas a standard 24 bit RGB picture has 8 bits for each channel, to keep bandwidth down,
and considering that the human eye is more sensitive to luminance than to chrominance,
the luminance signal is sent with more bits than the two chrominance signals.
This bit expansion results in a smaller dynamic of colors in video,
than what you are used to on monitors.
You hence have to keep in mind that not all colors can be correctly displayed.

A rule of thumb is to keep the colors as 'grayish' or 'unsaturated' as possible;
this roughly means keeping the dynamics of your colors within 80% of one another.
In other words,
the difference between the highest RGB value and the lowest RGB value should not exceed 0.8
(0 - 1 range) or 200 (0 - 255 range).

This is not strict, something more than 0.8 is acceptable, but an RGB display with color
contrast that ranges from 0.0 to 1.0 will appear to be very ugly (over-saturated) on video,
while appearing bright and dynamic on a computer monitor.

Encoding Panel
==============

.. figure:: /images/render_output_encoding-panel.png

Encoding panel.

Here you choose which video codec you want to use, and compression settings.
With all of these compression choices, there is a tradeoff between file size,
compatibility across platforms, and playback quality.

When you view the :doc:`System Console &lt;/advanced/command_line/introduction&gt;`,
you can see some of the output of the encoding process.
You will see even more output if you execute Blender as ``blender -d``.

Presets
You can use the presets, which choose optimum settings for you for that type of output.
Format
Video container or file type. For a list of all available options see
:doc:`video formats &lt;/data_system/files/media/video_formats&gt;`.

Codec
Chooses the method of compression and encoding.
For a list of all available options see :doc:`video formats &lt;/data_system/files/media/video_formats&gt;`.
Lossless Output
Allows the ability to perfectly reconstruct compressed data from compressed data.
Bitrate
Set the average `bitrate &lt;https://en.wikipedia.org/wiki/Bit_rate&gt;`__ (quality),
which is the count of binary digits per frame.
See also: `FFmpeg -b:v &lt;https://ffmpeg.org/ffmpeg.html#Description&gt;`__.
GOP Size
The number of pictures per `Group of Pictures &lt;https://en.wikipedia.org/wiki/Group_of_pictures&gt;`__.
Set to 0 for "intra_only", which disables `inter-frame &lt;https://en.wikipedia.org/wiki/Inter-frame&gt;`__ video.
From FFmpeg docs: "For streaming at very low bitrate application, use a low frame rate and a small GOP size.
This is especially true for RealVideo where the Linux player does not seem to be very fast,
so it can miss frames".
Autosplit Output
If your video is HUGE and exceeds 2Gig, enable Autosplit Output.
The main control over output filesize is the GOP or keyframe interlace.
A higher number generally leads to a smaller file but needs a higher-powered device to replay it.
Mux
`Multiplexing &lt;http://www.afterdawn.com/glossary/term.cfm/multiplexing&gt;`__ settings.

Rate
Maximum bit rate of the multiplexed stream.
Packet Size
Reduces data fragmentation or muxer overhead depending on the source.

.. note:: Standards

Some codecs cannot encode off-the-wall video sizes,
so stick to the XY sizes used in the presets for standard TV sizes.

Rate
The bitrate control also includes a *Minimum* and a *Maximum*.

Buffer
The `decoder bitstream buffer &lt;https://en.wikipedia.org/wiki/Video_buffering_verifier&gt;`__ size.

.. _render-output-video-encoding-audio:

Audio Codec
Audio conainer used, For a list of all available options see
:doc:`video formats &lt;/data_system/files/media/video_formats&gt;`.
Bitrate
For each codec, you can control the bitrate (quality) of the sound in the movie.
Higher bitrates are bigger files that stream worse but sound better.
Use powers of 2 for compatibility.
Volume
Sets the output volume of the audio.

Tips
----

Choosing which format to use depends on what you are going to do with the image.

If you are animating a movie and are not going to do any post-processing or special effects on
it, use either ``AVI-JPEG`` or ``AVI Codec`` and choose the XviD open codec.
If you want to output your movie with sound that you have loaded into the VSE,
use M-PEG.

If you are going to do post-processing on your movie, it is best to use a frameset rendered as "OpenEXR" images;
if you only want one file, then choose "AVI Raw". While AVI Raw is huge,
it preserves the exact quality of output for post-processing.
After post-processing (compositing and/or sequencing), you should compress the video.

.. tip::

You do not want to post-process a compressed file because the compression artifacts might
throw off what you are trying to accomplish with the post-processing.

Note that you might not want to render directly to a video format.
If a problem occurs while rendering, you have to re-render all frames from the beginning.
If you first render out a set of static images (such as the default PNG, or the higher-quality OpenEXR),
you can stitch them together with an :doc:`Image Strip &lt;/editors/vse/sequencer/strips/image_movie&gt;`
in the Video Sequence Editor.
This way, you can easily:

- Restart the rendering from the place (the frame) where the problem occurred.
- Try out different video options in seconds, rather than minutes or hours.
- Enjoy the rest of the features of the VSE,
such as adding Image Strips from previous renders, audio, video clips, etc.
..    TODO/Review: {{review|partial=X|im=needs images}}.

****************
Color Management
****************

Color management is one of the most important tools that an artist can use.
It allows an artist to make sure that an image stays the same from rendering, to saving, to post processing.
Color management also allows an artist to tweak things like exposure, gamma, or the overall color grade.

.. figure:: /images/render_post-processing_different-exposures.jpg
:width: 300px
:align: right

Different views and exposures of the same render.

To achieve color management in Blender, the `OpenColorIO &lt;http://opencolorio.org/&gt;`__
(OCIO) library has been integrated into Blender.
This library offers fine control over different :abbr:`LUT (Look Up Table)`
along with integrating your own set of color profiles to keep your work linearized with other software.

Scene Linear Color Space
========================

For correct results, different :term:`color spaces &lt;color space&gt;`
are needed for rendering display and storage of images.
Rendering and compositing is best done in scene *linear* color space,
which corresponds more closely to nature, and makes computations more physically accurate.

.. figure:: /images/render_post-processing_linear-workflow.png

An example of a linear workflow.

If the colors are linear, it means that if in reality, we double the number of photons,
the color values are also doubled. Put another way,
if we have two photos/renders each with one of two lights on, and add those images together,
the result would be the same as a render/photo with both lights on. It follows that such a
radiometrically linear space is best for photo-realistic rendering and compositing.

However, these values do not directly correspond to human perception or the way display devices
work and image files are often stored in different color spaces,
so we have to take care to do the right conversion into and out of this linear color space.

.. _render-post-color-management:

Settings
========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Scene --&gt; Color Management`

.. figure:: /images/render_post-processing_color-management-panel.png

Scene settings for color management.

Display
-------

Correct display of renders requires a conversion to the display device color space, which can be configured here.
A computer monitor works differently from a digital cinema projector HDTV. The scene properties have these settings:

Display Device
The device that the image is being viewed on.

Most computer monitors are configured for the sRGB color space,
and so when working on a computer usually this option should just be left to the default.
It would typically be changed when viewing the image on another display device connected to the computer,
or when writing out image files intended to be displayed on another device.

Rec709 is commonly used for HDTVs, while XYZ and DCI-P3 are common for digital projectors.

Color management can be disabled by setting the device to None.

.. figure:: /images/render_post-processing_linear-display-space.png

Conversion from linear to display device space.

Render
------

There is also an artistic choice to be made for renders. Partially that is
because display devices cannot display the full spectrum of colors and only have limited
brightness, so we can squeeze the colors to fit in the gamut of the device.
Besides that, it can also be useful to give the renders a particular look, e.g.
as if they have been printed on real film.

Another common use case is when you want to inspect renders,
to see details in dark shadows or bright highlights, or identify render errors.
Such settings would be only used temporarily and not get used for final renders.

View
These are different ways to view the image on the same display device.

Default
Does no extra conversion besides the conversion for the display device.
RRT
Uses the ACES Reference Rendering Transform, to simulate a film-like look.
Film
Uses a technique known as film emulation to give renders a look
similar to what might be expected from a film based camera.
This is usually done by crushing the blacks and decreasing the contrast of the image.
Raw
Intended for inspecting the image but not for final export.
Raw gives the image without any color space conversion.
Log
Intended for inspecting the image but not for final export.
Log works similar to Raw but gives a more "flat" view of the image without very dark or light areas.
Exposure
Used to control the image brightness (in stops) applied before color space conversion. :math:`2^(stops) × value`
Gamma
Extra gamma correction applied after color space conversion. Note that the default sRGB or Rec709 color space
conversions already include a gamma correction of approximately 2.2 (except the *Raw* and *Log* views),
so this would be applied in addition to that.
Look
Choose an artistic effect from a set of measured film response data which
roughly emulates the look of certain film types. Applied before color space conversion.
Use Curves
Adjust RGB Curves to control image colors before color space conversion.
Read more about using the :ref:`ui-curve-widget`.

Sequencer
---------

Color Space
The color space that the sequencer operates in. By default, the sequencer operates in sRGB space,
but it can also be set to work in Linear space like the Compositing nodes, or another color space.
Different color spaces will give different results for color correction, crossfades, and other operations.

Image Files
===========

When loading and saving media formats it is important to have color management in mind.
File formats such as PNG or JPEG will typically store colors in a color space ready for
display, not in a linear space. When they are, for example, used as textures in renders,
they need to be converted to linear first, and when saving renders for display on the web,
they also need to be converted to a display space. Other file formats like OpenEXR store
linear color spaces and as such are useful as intermediate files in production.

When working with image files, the default color space is usually the right one.
If this is not the case,
the color space of the image file can be configured in the image settings. A common situation
where manual changes are needed is when working with or baking normal maps or displacement maps,
for example. Such maps do not actually store colors, just data encoded as colors.
In such cases, they should be marked as *Non-Color Data*.

Image data-blocks will always store float buffers in memory in the scene linear color space,
while a byte buffer in memory and files in a drive are stored in the color space specified with this setting:

Color Space
The color space of the image file on a drive. This depends on the file format,
for example, PNG or JPEG images are often stored in sRGB, while OpenEXR images are stored in a linear color space.
Some images such as normal, bump or stencil maps do not strictly contain 'colors',
and on such values, no color space conversion should ever be applied.
For such images, the color space should be set to *None*.

.. figure:: /images/render_post_cm_image_settings.jpg

Image settings for color management.

By default only renders are displayed and saved with the render view transformations applied.
These are the Render Result and Viewer image data-blocks,
and the files saved directly to a drive with the Render Animation operator.
However, when loading a render saved to an intermediate OpenEXR file,
Blender cannot detect automatically that this is a render (it could be e.g.
an image texture or displacement map).
We need to specify that this is a render and that we want the transformations applied,
with these two settings:

View as Render
Display the image data-block (not only renders) with view transform, exposure, gamma, RGB curves applied.
Useful for viewing rendered frames in linear OpenEXR files the same as when rendering them directly.
Save as Render
Option in the image save operator to apply the view transform, exposure, gamma, RGB curves.
This is useful for saving linear OpenEXR to e.g. PNG or JPEG files in display space.

OpenColorIO Configuration
=========================

Blender comes with a standard OpenColorIO configuration that
contains a number of useful display devices and view transforms.
The reference linear :term:`color space` used is the linear color space
with Rec. 709 chromaticities and D65 white point.

However, OpenColorIO was also designed to give a consistent user experience across
`multiple applications &lt;http://opencolorio.org/CompatibleSoftware.html&gt;`__,
and for this, a single shared configuration file can be used. Blender will use the standard
OCIO environment variable to read an OpenColorIO configuration other than the default Blender
one. More information about how to set up such a workflow can be found on the
`OpenColorIO website &lt;http://opencolorio.org/&gt;`__.

We currently use the following color space rules:

scene_linear
Color space used for rendering, compositing, and storing all float precision images in memory.
default_sequencer
Default color space for sequencer, *scene_linear* if not specified
default_byte
Default color space for byte precision images and files, *texture_paint* if not specified.
default_float
Default color space for float precision images and files, *scene_linear* if not specified.

The standard Blender configuration also includes some support for
`ACES &lt;https://www.oscars.org/science-technology/sci-tech-projects/aces&gt;`__
(`code and documentation &lt;https://github.com/ampas/aces-dev&gt;`__),
even though we have a different linear color space.
It is possible to load and save EXR files with the Linear ACES color space,
and the RRT view transform can be used to view images with their standard display transform.
However, the ACES gamut is larger than the Rec. 709 gamut,
so for best results, an ACES specific configuration file should be used.
OpenColorIO provides an `ACES configuration &lt;http://opencolorio.org/configurations/index.html&gt;`__ file,
though it may need a few more tweaks to be usable in production.

##################
Post Processing
##################

There are several effects you can enable in the Render Settings that add visual elements to
rendered images, after the rendering has completed. These are not done in camera,
but rather composited on top of the image.

.. toctree::
:maxdepth: 2

layers.rst
panel.rst
color_management.rst

*************
Render Layers
*************

Render layers allow you to render your scene in separate layers,
usually with the intension of compositing them back together afterwards.

This can be useful for several purposes, such as color correcting certain elements differently,
blurring the foreground as a fast manual method of creating DoF,
or reducing the render quality for unimportant objects.

Using Render Layers can also save you from having to re-render your entire image each time you change something,
allowing you to instead re-render only the layer(s) that you need.

Layer List
==========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Scene --&gt; Scene`

.. figure:: /images/render_post-processing_layer-list.png

Layer list.

This is a list of all the Render Layers in the current scene.

Only layers which are enabled (checkbox on right is ticked) will be rendered.
If the *Pin* icon at the bottom right of the list is enabled, only the active (highlighted) layer will be rendered.

Render Layers can be added and removed using the ``+`` and ``-`` buttons on the right,
and existing layers can be renamed by double clicking on their name.

Layer Panel
===========

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Scene --&gt; Layer`

.. figure:: /images/render_post-processing_layer-panel.png

Layer panel.

The Layer Panel shows the settings of the active Render Layer from the list above.

You can select multiple layers using :kbd:`Shift-LMB`.

Scene
The Scene Layers, showing which are currently visible and will be rendered.
Layer
The Scene Layers which are associated with the active Render Layer.
Objects in those Scene Layers will be rendered in that Render Layer.
When an object is in the Scene Layers but not the Render Layer,
it will still cast shadows and be visible in reflections, so it is still indirectly visible.
Mask Layer
Objects on these will mask out other objects appearing behind them.
This can be used for compositing objects into footage,
to take into accounts objects in front of the virtual objects blocking the view from the camera.
Material Override
Overrides all material settings to use the Material chosen here.

Examples of where this might be used:

- To check lighting by using a plain diffuse material on all objects
- Render a wireframe of the scene
- Create a custom render pass such as an anti-aliased matte or global coordinates.

.. seealso::

Additional options shown in this panel are different for each render engine. See these options for:

- :doc:`Blender Render &lt;/render/blender_render/settings/layers&gt;`
- :doc:`Cycles &lt;/render/cycles/settings/passes&gt;`

Usage
=====

Each Render Layer has an associated set of :doc:`Scene Layers &lt;/editors/3dview/object/properties/relations/layers&gt;`.
Objects which are on one of the associated Scene Layers are shown in that Render Layer,
as long as that Scene Layer is also visible.

.. warning::

Only the objects in visible Scene Layers will be rendered.
So, if only Scene Layer 1 is visible and your Render Layer set specifies to render only Layers 2 and 3,
nothing will be rendered.

*********************
Post Processing Panel
*********************

.. admonition:: Reference
:class: refbox

| Panel:    :menuselection:`Properties editor --&gt; Render --&gt; Post Processing`

The Post Processing panel is used to control different options used to process your image after rendering.

.. figure:: /images/render_post-processing_post-processing-panel.png
:align: right

Post Processing Panel.

Sequencer
Renders the output of the sequence editor, instead of the view from the 3D scene's active camera.
If the sequence contains scene strips, these will also be rendered as part of the pipeline.
If *Compositing* is also enabled, the Scene strip will be the output of the Compositor.
Compositing
Renders the output from the compositing node setup,
and then pumps all images through the Composite node map,
displaying the image fed to the Composite Output node.

Dithering
=========

Dithering is a technique for blurring pixels to prevent banding that is seen in areas of
gradients, where stair-stepping appears between colors.
Banding artifacts are more noticeable when gradients are longer, or less steep.
Dithering was developed for graphics with low bit depths,
meaning they had a limited range of possible colors.

Dithering works by taking pixel values and comparing them with a threshold and neighboring
pixels then does calculations to generate the appropriate color. Dithering creates the
perceived effect of a larger color palette by creating a sort of visual color mixing.
For example, if you take a grid and distribute red and yellow pixels evenly across it,
the image would appear to be orange.

The *Dither* value ranges from 0 to 2.

.. note::

When using *Blender Internal* Render you get a few more options and these are discussed
:doc:`here &lt;/render/blender_render/post_processing/index&gt;`.

********************
Rendering Animations
********************

While rendering stills will allow you to view and save the image from the render buffer when
it is complete, animations are a series of images, or frames,
and are automatically saved directly out to a drive after being rendered.

After rendering the frames, you may need to edit the clips,
or first use the Compositor to do green-screen masking, matting, color correction, DOF,
and so on to the images. That result is then fed to the Sequencer where the strips are cut and
mixed and a final overlay is done.

Finally you can render out from the Sequencer and compress the frames into a playable movie clip.

Workflow
========

Generally, you do a lot of intermediate renders of different frames in your animation to check
for timing, lighting, placement, materials, and so on. At some point,
you are ready to make a final render of the complete animation for publication.

There are two approaches you can use when making a movie, or animation, with or without sound.
The approach you should use depends on the amount of CPU time you will need to render the movie.
You can render a "typical" frame at the desired resolution,
and then multiply by the number of frames that will ultimately go into the movie, to arrive at an total render time.

If the total render time is an hour or more, you want to use the "Frame Sequence" approach.
For example, if you are rendering an one-minute video clip for film, there will be
(60 seconds per minute) X (24 frames per second) or 1440 frames per minute.
If each frame takes 30 seconds to render,
then you will be able to render two frames per minute, or need 720 minutes (12 hours)
of render time.

Rendering takes all available CPU time; you should render overnight,
when the computer is not needed, or set Blender to a low priority while rendering,
and work on other things (be careful with the RAM space!).

.. rubric:: Direct Approach

The Direct Approach, which is highly **not** recommended and not a standard practice,
is where you set your output format to an AVI or MOV format,
and click *Animation* to render your scene directly out to a movie file.
Blender creates one file that holds all the frames of your animation. You can then use
Blender's VSE to add an audio track to the animation and render out to an MPEG format to
complete your movie.

.. rubric:: Frame Sequence

The Frame Sequence is a much more stable approach,
where you set your output format to a still format (such as JPG, PNG or MultiLayer),
and click *Animation* to render your scene out to a set of images,
where each image is a frame in the sequence.

Blender creates a file for each frame of the animation.
You can then use Blender's compositor to perform any frame manipulation (post processing).
You can then use Blender's VSE to load that final image sequence,
add an audio track to the animation, and render out to an MPEG format to complete your movie.
The Frame Sequence approach is a little more complicated and takes more drive space,
but gives you more flexibility.

Here are some guidelines to help you choose an approach.

.. rubric:: Direct Approach

- short segments with total render time &lt; 1 hour
- stable power supply
- computer not needed for other uses

.. rubric:: Frame Sequence Approach

- total render time &gt; 1 hour
- post-production work needed
- Color/lighting adjustment
- Green screen/matte replacement
- Layering/compositing
- Multiple formats and sizes of ultimate product
- intermediate frames/adjustments needed for compression/codec
- precise timing (e.g. lip-sync to audio track) needed in parts
- may need to interrupt rendering to use the computer, and want to be able to resume rendering where you left off.

Frame Sequence Workflow
=======================

#. First prepare your animation.
#. In the *Dimensions* panel, choose the render size, Pixel Aspect Ratio, and the Range of Frames to use,
as well as the frame rate, which should already be set.
#. In the Output panel set up your animation to be rendered out as images,
generally using a format that does not compromise any quality.
#. Choose the output path and file type in the Output panel as well, for example ``//render/my-anim-``.
#. Confirm the range of your animation frame Start and End.
#. Save your blend-file.
#. Press the big *Animation* button.
Do a long task [like sleeping, playing a video game, or cleaning your driveway]
while you wait for your computer to finish rendering the frames.
#. Once the animation is finished,
use your OS file explorer to navigate into the output folder ("``render`` in this example).
You will see lots of images (.png or .exr, etc... depending on the format you chose to render)
that have a sequence number attached to them ranging from 0000 to a max of 9999. These are your single frames.
#. In Blender, now go into the :doc:`video sequence editor &lt;/editors/vse/index&gt;`.
#. Choose *Add Image* from the add menu. Select all the frames from your output folder that you want to include
in your animation (Press A to Select All easily). They will be added as a strip to the sequence editor.
#. Now you can edit the strip and add effects or simply leave it like it is.
You can add other strips, like an audio strip.
#. Scrub through the animation, checking that you have included all the frames.
#. In the Scene Render buttons, in the Post Processing panel, activate *Sequencer*.
#. In the Output panel, choose the container and codec you want (e.g.  ``MPEG H.264``) and configure them.
The video codecs are described on the previous page: :doc:`Output Options &lt;/render/output/output&gt;`.
#. Click the *Animation* render button and Blender will render out the sequence editor output into your movie.

Why go through all this hassle? Well, first of all, if you render out single frames you can
stop the render at any time by pressing :kbd:`Esc` in the render window or UV/image editor.
You will not lose the frames you have already rendered,
since they have been written out to individual files.
You can always adjust the range you want to continue from where you left off.

You can edit the frames afterwards and post-process them.
You can add neat effects in the sequence editor.
You can render the same sequence into different resolutions (640×480, 320×240, etc)
and use different codecs (to get different file sizes and quality)
with almost no effort whatsoever.

Hints
=====

Your computer accidentally turns off in the middle of rendering your movie!
Unless your animation renders in a few minutes,
it is best to render the animation as separate image files.
Instead of rendering directly to a compressed movie file, use a loss-less format (e.g. ``PNG``).

This allows you an easy recovery if there is a problem and you have to re-start the rendering,
since the frames you have already rendered will still be in the output directory.

Just disable the *Overwrite* option to start rendering where you left off.

You can then make a movie out of the separate frames with Blender's sequence editor
or use 3rd party encoding software.

Animation Preview
It can be useful to render a subset of the animated sequence,
since only part of an animation may have an error.

Using an image format for output,
you can use the *Frame Step* option to render every *N'th* frame.
Then disable *Overwrite* and re-render with *Frame Step* set to 1.

************
Command Line
************

In some situations we want to increase the render speed,
access Blender remotely to render something or build scripts that use the command line.

One advantage of using the command line is that we do not need a graphical display
(no need for X server on Linux for example)
and consequently we can render via a remote shell (typically SSH).

See :doc:`Command Line Arguments &lt;/advanced/command_line/arguments&gt;`
for a full list of arguments
(for example to specify which scene to render, the end frame number, etc...), or simply run:

.. code-block:: sh

blender --help

.. note::

Arguments are executed in the order they are given!

The following command will not work, since the output and extension are set after Blender is told to render:

.. code-block:: sh

blender -b file.blend -a -x 1 -o //render

The following command will behave as expected:

.. code-block:: sh

blender -b file.blend -x 1 -o //render -a

**Always** position ``-f`` or ``-a`` as the last arguments.

Platforms
=========

How to actually execute Blender from the command line depends on the platform and where you
have installed Blender. Here are basic instructions for the different platforms.

Linux
-----

Open a terminal, then go to the directory where Blender is installed,
and run Blender like this:

.. code-block:: sh

cd &lt;blender installation directory&gt;
./blender

If you have Blender installed in your ``PATH``
(usually when Blender is installed through a distribution package), you can simply run:

.. code-block:: sh

blender

macOS
-----

Open the terminal application, go to the directory where Blender is installed,
and run the executable within the app bundle, with commands like this:

.. code-block:: sh

cd /Applications/Blender
./blender.app/Contents/MacOS/blender

If you need to do this often,
you can make an alias so that typing just ``blender`` in the terminal works.
For that you can run a command like this in the terminal (with the appropriate path).

.. code-block:: sh

echo "alias blender=/Applications/Blender/blender.app/Contents/MacOS/blender" &gt;&gt; ~/.profile

If you then open a new terminal, the following command will work:

.. code-block:: sh

blender

MS-Windows
----------

Open the Command Prompt, go to the directory where Blender is installed,
and then run Blender:

.. code-block:: bat

cd c:\&lt;blender installation directory&gt;
blender

You can also add the Blender folder to your system ``PATH`` so that do you do not have to ``cd`` to it each time.

Examples
========

Single Image
------------

.. code-block:: sh

blender -b file.blend -f 10

``-b``
Render in the background (without UI).
``file.blend``
Path to the blend-file to render.
``-f 10``
Render only the 10th frame.

.. code-block:: sh

blender -b file.blend -o /project/renders/frame_##### -F EXR -f -2

``-o /project/renders/frame_#####``
Path of where to save the rendered image, using five padded zeros for the frame number.
``-F EXR``
Override the image format specified in the blend-file and save to an OpenEXR image.
``-f -2``
Render only the second last frame.

.. warning::

Arguments are case sensitive! ``-F`` and ``-f`` are not the same.

Animation
---------

.. code-block:: sh

blender -b file.blend -a

``-a``
Render the whole animation using all the settings saved in the blend-file.

.. code-block:: sh

blender -b file.blend -E BLENDER_RENDER -s 10 -e 500 -t 2 -a

``-E BLENDER_RENDER``
Use the "Blender Render" engine.
For a list of available render engines, run ``blender -E help``.
``-s 10 -e 500``
Set the start frame to ``10`` and the end frame to ``500``.
``-t 2``
Use only two threads.
.. _render-workflows:

############
Workflows
############

.. toctree::
:maxdepth: 2

animations.rst
command_line.rst
multiview/index.rst
#############
Multiview
#############

.. toctree::
:maxdepth: 2

introduction.rst
usage.rst

************
Introduction
************

.. figure:: /images/multiview_workflow_3.png

Since version 2.75, Blender has come with a new feature called Multiview.
Multiview is a complete toolset for working with stereoscopic rendering in Blender.
It works with both the Blender Internal and Cycles
rendering engines and it also supports many different stereo 3D visualization types.

.. note::

If you have a real 3D display at some point you can change the 3D display mode in the Window menu,
by calling the Stereo 3D operator.
Be aware that some modes require a fullscreen editor to work, and this can be taxing on your CPU.

*****
Usage
*****

For example, we will take an existing blend
file that was made for monoscopic rendering and transform it to be stereo 3D ready.

.. figure:: /images/multiview_workflow_render_anaglyph.png

Creature Factory 2 by Andy Goralczyk Rendered in Stereo 3D (anaglyph).

.. note::

Multi-View drawing requires capable graphics card and drivers with *Triple Buffer* support.
If the *Automatic* mode does not work,
set the *Window Draw Method* in the :doc:`System User Preferences &lt;/preferences/system&gt;`.

Introduction
============

Start opening up your project file, in this case ``turntable.blend`` from the *Creature Factory 2*
Open Movie Workshop series from the Blender Institute by Andy Goralczyk.

.. figure:: /images/multiview_workflow_1.png
:width: 1213px

Turn Table Creature Factory 2.

Views Setup
===========

Go to the :doc:`Render Layers &lt;/render/post_process/layers&gt;` panel and enable *Views* for this scene.

.. figure:: /images/render_workflows_multiview_views-panel.png

Scene Render Views.

.. note::

When you turn on *Views* in the scene, you get 3D preview in the viewport,
as well as multiple panels that are now accessible all over the user interface.

.. figure:: /images/multiview_workflow_3.png
:width: 1213px

Viewport with 3D visualization.

Camera
======

To tweak the stereo 3D parameters, select the camera in the Outliner.
In the Camera panel go to the Stereoscopy tab and change the *Convergence Distance*.

The viewport will respond in real-time to those changes allowing you to preview the current depth value of the scene.

.. figure:: /images/render_workflows_multiview_camera-stereoscopy-panel.png

Stereo Convergence Distance.

Viewport
========

Before fine-tuning the camera parameters, you can set the
convergence plane in the viewport based in your scene depth layout.
Go outside the camera view and you will instantly see the convergence plane in front of the camera.

You can toggle this and other display settings in the Stereoscopy panel of the 3D Views properties region.
In the following image, the cameras frustum volumes are also visible.

.. figure:: /images/multiview_workflow_5.png
:width: 700px

Viewport Plane and Volume Stereo Preview.

Stereo 3D Display
=================

If you have a real 3D display at some point, you can change the 3D display mode in the Window menu,
by calling the Stereo 3D operator.
Be aware that some modes require a fullscreen editor to work.

.. figure:: /images/multiview_window_stereo_3d.png

Window Menu, Stereo 3D Operator.

OpenGL Preview
==============

.. only:: builder_html

.. figure:: /images/multiview_workflow_6.gif
:width: 300px
:align: right

Turn Table OpenGL Rendering Preview.

Before rendering your scene you can save an OpenGL preview of the animation for testing in the final display.
In the Render Output panel you can choose the output *Views Format*.

The options include individual files per view, top-bottom, anaglyph among others.
Pick the one that fits your display requirements.

.. only:: latex or epub

An example image can be found at:
https://docs.blender.org/manual/en/dev/_images/multiview_workflow_6.gif

Rendering and UV/Image Editor
=============================

Once you are happy with the results you can render out the final animation.
In the UV/Image Editor you can inspect the individual views and the stereo result.

Image Formats
=============

Your final animation can be saved in more robust formats than the ones used by the OpenGL render preview.
In this example we saved as cross-eyed side-by-side stereo 3D.

.. figure:: /images/multiview_workflow_render_sidebyside.png

Side by Side Cross-Eye Format.

Final Considerations
====================

As this guide showed, there is more to stereo 3D rendering than just generate two images.
The earlier the stereo pipeline is considered the smoother it will get.
The following sections are a more in-depth view of the individual components we visited in the workflow.

Window Stereo 3D Display
========================

An essential component of the Stereoscopy pipeline is the ability to display the stereo image in a proper display.
Blender supports from high-end 3D displays to simple red-cyan glasses.
On top of that you can set a different display mode for each window.

The display mode can be changed via the Window menu
or if you create your own shortcuts for the ``wm.set_stereo_3d`` operator.

.. figure:: /images/multiview_window_stereo_3d.png

Window Menu, Stereo 3D Operator.

Display Mode
------------

Anaglyph
Render two differently filtered colored images for each eye.
Anaglyph glasses are required. We support Red-Cyan, Green-Magenta and Yellow-Blue glasses.
Interlace
Render two images for each eye into one interlaced image.
A 3D-ready monitor is required.  We support Row, Column and Checkerboard Interleaved.
An option to Swap Left/Right helps to adjust the image for the screen. This method works better in fullscreen.
Time Sequential
Renders alternate eyes.
This method is also known as Page Flip.
This requires the graphic card to support Quad Buffer and it only works in fullscreen.
Side-by-Side
Render images for left and right eye side-by-side.
There is an option to support Cross-Eye glasses.
It works only in fullscreen, and it should be used with the Full Editor operator.
Top-Bottom
Render images for left and right eye one above another.
It works only in fullscreen, and it should be used with the Full Editor operator.

.. note:: Full Screen Stereo 3D Modes

If you have a 3D display most of the time
you will use it to see in stereo 3D you will have to go to the fullscreen mode.
In fact some modes will only work in the full window mode that hides most of the user interface from the work area.
In this case it is recommended to work with two monitors,
using the 3D screen for visualizing the stereo result
while the other screen can be used for the regular Blender work.

Stereo 3D Camera
================

When using the Stereo 3D scene view setup a stereo pair is created
on-the-fly and used for rendering and previsualization.
For all the purposes this works as two cameras that share most parameters (focal length, clipping, ...).
The stereo pair, however, is offsetted, and can have unique rotation and shift between itself.

.. figure:: /images/render_workflows_multiview_camera-stereoscopy-panel.png

Stereo 3D Camera Settings.

Interocular Distance
Set the distance between the camera pair.
Although the convergence of a stereo pair can be changed in post-production,
different interocular distances will produce different results
due to the parts of the scene being occluded from each point of view.
Convergence Plane Distance
The converge point for the stereo cameras.
This is often the distance between a projector and the projection screen.
You can visualize this in the 3D View.

Convergence Mode
----------------

Off-Axis
The stereo camera pair is separated by the interocular distance,
and shifted inwards so it converges in the convergence plane.
This is the ideal format since it is the one closest to how the human vision works.
Parallel
This method produces two parallel cameras that do not converge.
Since this method needs to be manually converged it cannot be used for viewing.
This method is common when combining real footage with rendered elements.
Toe-in
A less common approach is to rotate the cameras instead of shifting their frustum.
The Toe-in method is rarely used in modern 3D productions.
Pivot
The stereo pair can be constructed around the active camera with a new camera built for each eye
(Center Pivot) or using the existing camera and creating (Left or Right).
The latter is what is used when only one eye needs to be rendered for an existing mono 2D project.

Viewport Stereo 3D
==================

When you enable 'Views' in the Render Layer panel, a new area is available in the 3D View properties region.
In this panel you can pick whether to see the stereo 3D in the viewport, or which camera to see.
It also allow you to see the Cameras, the Plane and the Volume of the stereo cameras.

.. figure:: /images/render_workflows_multiview_3d-view-stereoscopy-panel.png

Viewport Stereo 3D Settings.

Cameras
When working with the Stereo 3D Views setup you can inspect what
each individual generated camera is looking or the combined result of them.
In the Multi-View mode you can see the combined result of the left and right cameras
(when available) or the current selected camera.
Plane
The convergence plane represents the screen as it is perceived by the audience.
Visualizing it in the 3D View allows you to layout your scene
based on your depth script outside the camera view.
Volume
The intersection of the stereo cameras frustums helps planning the show
by avoiding elements being visible by only one camera.
The volume is defined by the camera's start and end clipping distances.
The areas that are in the frustum of one camera only are known as *retinal rivalry areas*.
They are tolerated in the negative space (the region from the convergence plane into the image)
but are to be avoided at all costs in the positive space (the area from the convergence plane to the camera).

.. figure:: /images/multiview_volume.png
:width: 402px

Viewport 3D: Convergence Plane and Volume Display.

Multi-View and Stereo 3D Image I/O
==================================

Multi-View and Stereo 3D
Multi-View images can be saved in special formats according to the production requirements.
By default the system saves each view as an individual file, thus generating as many files as views to be rendered.
In stereo 3D productions, for the final deployment or even
intermediary previews it is convenient to save stereo 3D images,
that are ready to use with 3D displays or simple anaglyph glasses.
The formats supported match the display modes available for the window.
Lossy-Formats
Some stereo 3D formats represent a considerable loss of data.
For example, the Anaglyph format will cap out entire color channels from the original image.
The Top-Bottom compressed will discard half of your vertical resolution data.
The Interlace will mash your data considerably.
Once you export in those formats, you can still import the image
back in Blender, for it to be treated as Stereo 3D.
You will need to match the window stereo 3D display mode to the image stereo 3D format though.
Lossless Formats
Some formats will preserve the original data,
leading to no problems on exporting and importing the files back in Blender.
The Individual option will produce separate images that
(if saved in a lossless encoding such as ``PNG`` or ``OpenEXR``)
can be loaded back in production with no loss of data.
For the Stereo 3D formats the only lossless options are
*Top-Bottom* and *Side-by-Side* without the Squeezed Frame option.
Multi-View OpenEXR
Another option is to use Multi-View OpenEXR files.
This format can save multiple views in a single file and is backward compatible
with old OpenEXR viewers (you see only one view though).
Multi-View native support is only available to OpenEXR.

Image Editor
============

View Menu
After you render your scene with Stereo 3D you will be able to see
the rendered result in the combined stereo 3D or to inspect the individual views.
This works for Viewer nodes, render results or opened images.

.. figure:: /images/render_workflows_multiview_image-editor-header.png

Stereo 3D and View menu.

Views Format
When you drag and drop an image into the UV/Image Editor, Blender will open it as an individual images at first.
If your image was saved with one of the Stereo 3D formats, you can change how
Blender should interpret the image by switching the mode to Stereo 3D,
turning on Use Multi-View and picking the corresponding stereo method.

.. figure:: /images/render_workflows_multiview_image-editor-multi-view.png

Views Formats and Stereo 3D.

Compositor
==========

The compositor works smoothly with Multi-View.
The compositing of a view is completed before the remaining views start to be composited.
The pipeline is the same as the single-view workflow, with the difference that you can use Image,
Movies or Image Sequences in any of the supported Multi-View formats.

.. figure:: /images/multiview_compositor.png

Compositor, Backdrop and Split Viewer Node.

The views to render are defined in the current scene views,
in a similar way as you define the composite output resolution in the current scene render panel,
regardless of the Image nodes resolutions or Render Layers from different scenes.

.. note:: Single-View Images

If the image from an Image Node does not have the view you are trying to render,
the image will be treated as a single-view image.

Switch View Node
If you need to treat the views separately you can use the
:doc:`Switch View node &lt;/compositing/types/converter/switch_view&gt;`
to combine the views before an output node.

.. tip:: Performance

By default, when compositing and rendering from the user interface all views are rendered and then composited.
During test iterations you can disable all but one view from the Scene Views panel,
and re-enable it after you get the final look.

*************
Editing Bones
*************

.. (todo) same as armature

Add Menu
========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Add`
| Hotkey:   :kbd:`Shift-A`

In the 3D View, :kbd:`Shift-A` to add a new bone to your armature.

This bone will be:

- of one Blender Unit of length,
- oriented towards the global Z axis,
- with its root placed at the 3D cursor position,
- with no relationship with any other bone of the armature.

Extrude
=======

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Extrude`
| Hotkey:   :kbd:`E`, :kbd:`Shift-E`

When you press :kbd:`E`, for each selected tip
(either explicitly or implicitly), a new bone is created.
This bone will be the child of "its" tip owner, and connected to it. As usual,
once extrusion is done, only the new bones' tips are selected, and in grab mode,
so you can place them to your liking. See Fig. :ref:`fig-rig-bones-extrusion`.

.. _fig-rig-bones-extrusion:

.. list-table:: Extrusion example.

* - .. figure:: /images/rigging_armatures_editing_bones_extrusion-1.png
:width: 320px

An armature with three selected tips.

- .. figure:: /images/rigging_armatures_editing_bones_extrusion-2.png
:width: 320px

The three extruded bones.

You also can use the rotating/scaling extrusions,
as with meshes, by pressing respectively :kbd:`E-R` and :kbd:`E-S` --
as well as :doc:`locked &lt;/editors/3dview/object/editing/transform/control/precision/axis_locking&gt;`
extrusion along a global or local axis.

.. _fig-rig-bone-mirror:

.. list-table:: Mirror extrusion example.

* - .. figure:: /images/rigging_armatures_editing_bones_mirror-extrusion-1.png
:width: 320px

A single selected bone's tip.

- .. figure:: /images/rigging_armatures_editing_bones_mirror-extrusion-2.png
:width: 320px

The two mirror-extruded bones.

Bones have an extra "mirror extruding" tool, called by pressing :kbd:`Shift-E`.
By default, it behaves exactly like the standard extrusion.
But once you have enabled the X-Axis mirror editing option
(see `X-Axis Mirror`_),
each extruded tip will produce *two new bones*, having the same name except for the "_L"/ "_R" suffix
(for left/right, see the :ref:`next page &lt;armature-editing-naming-conventions&gt;`).
The "_L" bone behaves like the single one produced by the default extrusion --
you can grab/rotate/scale it exactly the same way.
The "_R" bone is its mirror counterpart (along the armature's local X axis), see Fig. :ref:`fig-rig-bone-mirror`.

.. important::

Canceling the extrude action causes the newly created bones to snap back to the source position,
(creating zero length bones). These will be removed when exiting Edit Mode,
however, they can cause confusion and it's unlikely you want to keep them.
If you realize the problem immediately undo the extrude action.

In case you are wondering, you cannot just press :kbd:`X` to solve this as you would in mesh editing,
because extrusion selects the newly created tips, and as explained below the Delete tool ignores bones' joints.
To get rid of these extruded bones without undoing, you would have to move the tips,
then select the bones and delete (`Delete Selected Bone(s)`_) them.

Mouse Clicks
------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Hotkey:   :kbd:`Ctrl-LMB`

If at least one bone is selected, :kbd:`Ctrl-LMB` -clicking adds a new bone.

About the new bone's tip:

- after you :kbd:`Ctrl-LMB` -clicked it becomes the active element in the armature,
- it appears to be right where you clicked, but...
- ...(as in mesh editing) it will be on the plane parallel to the view and passing through the 3D cursor.

The position of the root and the parenting of the new bone depends on the active element:

.. figure:: /images/rigging_armatures_editing_bones_mouse-clicks-1.png
:width: 300px

Ctrl-clicking when the active element is a bone.

If the active element is a *bone*

- the new bone's root is placed on the active bone's tip
- the new bone is parented and connected to the active bone
(check the Outliner in Fig. :ref:`fig-rig-bone-active-tip`).

.. _fig-rig-bone-active-tip:

.. figure:: /images/rigging_armatures_editing_bones_mouse-clicks-2.png
:width: 300px

Ctrl-clicking when the active element is a tip.

If the active element is a *tip* :

- the new bone's root is placed on the active tip
- the new bone is parented and connected to the bone owning the active tip
(check the Outliner in Fig. :ref:`fig-rig-bone-active-tip`).

.. _fig-rig-bone-disconnected-tip:

.. figure:: /images/rigging_armatures_editing_bones_mouse-clicks-3.png
:width: 300px

Ctrl-clicking when the active element is a disconnected root.

If the active element is a *disconnected root* :

- the new bone's root is placed on the active root
- the new bone is **not** parented to the bone owning the active root
(check the Outliner in Fig. :ref:`fig-rig-bone-disconnected-tip`).

And hence the new bone will **not** be connected to any bone.

.. _fig-rig-bone-connected-root:

.. figure:: /images/rigging_armatures_editing_bones_mouse-clicks-4.png
:width: 300px

Ctrl-clicking when the active element is a connected root.

If the active element is a *connected root* :

- the new bone's root is placed on the active root
- the new bone **is** parented and connected to the parent of the bone owning the active root
(check the Outliner in Fig. :ref:`fig-rig-bone-connected-root`).

This should be obvious because if the active element is a connected root then the active
element is also the tip of the parent bone, so it is the same as the second case.

As the tip of the new bone becomes the active element,
you can repeat these :kbd:`Ctrl-RMB` several times,
to consecutively add several bones to the end of the same chain.

Fill between Joints
===================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Fill Between Joints`
| Hotkey:   :kbd:`F`

The main use of this tool is to create one bone between two selected joints by pressing
:kbd:`F`, similar to how in mesh editing you can "create edges/faces".

If you have one root and one tip selected, the new bone:

- Will have the root placed on the selected tip.
- Will have the tip placed on the selected root.
- Will be parented and connected to the bone owning the selected tip.

.. list-table:: Fill between a tip and a root.

* - .. figure:: /images/rigging_armatures_editing_bones_fill-joints-1.png
:width: 320px

Active tip on the left.

- .. figure:: /images/rigging_armatures_editing_bones_fill-joints-2.png
:width: 320px

Active tip on the right.

If you have two tips selected, the new bone:

- Will have the root placed on the selected tip closest to the 3D cursor.
- Will have the tip placed on the other selected tip.
- Will be parented and connected to the bone owning the tip used as the new bone's root.

.. list-table:: Fill between tips.

* - .. figure:: /images/rigging_armatures_editing_bones_fill-joints-3.png
:width: 320px

3D cursor on the left.

- .. figure:: /images/rigging_armatures_editing_bones_fill-joints-4.png
:width: 320px

3D cursor on the right.

If you have two roots selected, you will face a small problem due to the event system in
Blender not updating the interface in real time.

When clicking :kbd:`F`, similar to the previous case, you will see a new bone:

- With the root placed on the selected root closest to the 3D cursor.
- With the tip placed on the other selected root.
- Parented and connected to the bone owning the root used as the new bone's root.

If you try to move the new bone, Blender will update the interface and you will see that the
new bone's root moves to the tip of the parent bone.

.. list-table:: Fill between roots.

* - .. figure:: /images/rigging_armatures_editing_bones_fill-joints-5.png
:width: 320px

Before UI update (3D cursor on the left).

- .. figure:: /images/rigging_armatures_editing_bones_fill-joints-6.png
:width: 320px

After UI update, correct visualization.

Clicking :kbd:`F` with only one bone joint selected will create a bone from the selected
joint to the 3D cursor position, and it will not parent it to any bone in the armature.

.. list-table:: Fill with only one bone joint selected.

* - .. figure:: /images/rigging_armatures_editing_bones_fill-joints-7.png
:width: 320px

Fill with only one tip selected.

- .. figure:: /images/rigging_armatures_editing_bones_fill-joints-8.png
:width: 320px

Fill with only one root selected.

You will get an error when:

- Trying to fill two joints of the same bone.
- Trying to fill more than two bone joints.

Duplicate
=========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Duplicate`
| Hotkey:   :kbd:`Shift-D`

.. note::

This tool works on selected bones; selected joints are ignored.

As in mesh editing, by pressing :kbd:`Shift-D`:

- the selected bones will be duplicated,
- the duplicates become the selected elements and they are placed in grab mode,
so you can move them wherever you like.

If you select part of a chain, by duplicating it you will get a copy of the selected chain,
so the copied bones are interconnected exactly like the original ones.

The duplicate of a bone which is parented to another bone will also be parented to the same
bone, even if the root bone is not selected for the duplication. Be aware, though,
that if a bone is parented **and** connected to an unselected bone,
its copy will be parented, but **not** connected to the unselected bone
(see Fig. :ref:`fig-rig-bone-duplication`).

.. _fig-rig-bone-duplication:

.. list-table:: Duplication example.

* - .. figure:: /images/rigging_armatures_editing_bones_duplication-1.png
:width: 320px

An armature with three selected bones and a selected single root.

- .. figure:: /images/rigging_armatures_editing_bones_duplication-2.png
:width: 320px

The three duplicated bones. Note that the selected chain is preserved in the copy,
and that Bone.006 is parented but not connected to Bone.001, as indicated by the black dashed line.
Similarly, Bone.007 is parented but not connected to Bone.003.

Split
=====

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Split`
| Hotkey:   :kbd:`Y`

Disconnects the selection and clears the parent at the start and end. ToDo.

Delete Selected Bone(s)
=======================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Delete Selected Bone(s)`
| Hotkey:   :kbd:`X`

This tool delete selected bones, selected *joints* are ignored.

If you delete a bone in a chain, its child(ren)
will be automatically re-parented to its own parent, but **not** connected,
to avoid deforming the whole armature.

.. list-table:: Deletion example.

* - .. figure:: /images/rigging_armatures_editing_bones_deletion-1.png
:width: 320px

An armature with two selected bones, just before deletion.

- .. figure:: /images/rigging_armatures_editing_bones_deletion-2.png
:width: 320px

The two bones have been deleted. Note that Bone.002,
previously connected to the deleted Bone.001, is now parented but not connected to Bone.

Dissolve
========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     none
| Hotkey:   :kbd:`Ctrl-X`

ToDo.

Merge Bones
===========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Merge Bones`
| Hotkey:   :kbd:`Alt-M`

You can merge together several selected bones, as long as they form a chain.
Each sub-chain formed by the selected bones will give one bone,
whose root will be the root of the root bone, and whose tip will be the tip of the tip bone.

Confirm by clicking on :menuselection:`Merge Selected Bones --&gt; Within Chains`.

If another (non-selected) chain origins from inside of the merged chain of bones,
it will be parented to the resultant merged bone. If they were connected,
it will be connected to the new bone.

Here is a strange subtlety (see Fig. :ref:`fig-rig-bone-merge`): even though connected
(the root bone of the unmerged chain has no root sphere),
the bones are not visually connected. This will be done as soon as you edit one bone,
differently depending in which chain is the edited bone
(compare the bottom two images of the example to understand this better).

.. _fig-rig-bone-merge:

.. list-table:: Merge example.

* - .. figure:: /images/rigging_armatures_editing_bones_merge-1.png
:width: 320px

An armature with a selected chain, and a single selected bone, just before merging.

- .. figure:: /images/rigging_armatures_editing_bones_merge-2.png
:width: 320px

Bones Bone, Bone.001 and Bone.002 have been merged in Bone.006,
whereas Bone.005 was not modified. Note Bone.003, connected to Bone.006 but not yet "really" connected.

* - .. figure:: /images/rigging_armatures_editing_bones_merge-3.png
:width: 320px

Bone.004 has been rotated, and hence the tip of Bone.006 was moved to the root of Bone.003.

- .. figure:: /images/rigging_armatures_editing_bones_merge-4.png
:width: 320px

The tip of Bone.006 has been translated, and hence the root of Bone.003 was moved to the tip of "Bone.006"

Subdivide
=========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Subdivide`, :menuselection:`Specials --&gt; Subdivide`

You can subdivide bones, to get two or more bones where there was just one bone.
The tool will subdivide all selected bones, preserving the existing relationships:
the bones created from a subdivision always form a connected chain of bones.

To create an arbitrary number of bones from each selected bone in the
Subdivide Multi Operator panel.

Number of Cuts
Specifies the number of cuts. As in mesh editing,
if you set *n* cuts, you will get *n* + 1 bones for each selected bone.

.. list-table:: Subdivision example.

* - .. figure:: /images/rigging_armatures_editing_bones_subdivision-1.png
:width: 320px

An armature with one selected bone, just before multi-subdivision.

- .. figure:: /images/rigging_armatures_editing_bones_subdivision-2.png
:width: 320px

The selected bone has been "cut" two times, giving three sub-bones.

Locking Bones
=============

You can prevent a bone from being transformed in *Edit Mode* in several ways:

.. The active bone can be locked clicking on *Lock*
in the *Transform* panel (:kbd:`N` in a 3D View);

- All bones can be locked clicking on the *Lock* checkbox
of their Transform panel in the *Bones* tab;
- Press :kbd:`Shift-W` :menuselection:`Toggle Bone Options --&gt; Locked`
- Select :menuselection:`Armature --&gt; Bone Settings --&gt; Toggle a Setting`).

*If the root of a locked bone is connected to the tip of an unlocked bone,
it will not be locked*, i.e. you will be able to move it to your liking.
This means that in a chain of connected bones, when you lock one bone,
you only really lock its tip. With unconnected bones, the locking is effective on both joints of the bone.

X-Axis Mirror
=============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Options --&gt; Armature Options --&gt; X-Axis Mirror`

This option enables automatic mirroring of editing actions along the X axis.
Another very useful tool is the *X-Axis Mirror* editing option by
:menuselection:`Tool panel --&gt; Armature Options`, while Armature is selected in *Edit Mode*.
When you have pairs of bones of the same name with just a different "side suffix"
(e.g. ".R"/".L", or "_right"/"_left" ...), once this option is enabled,
each time you transform (move/rotate/scale...) a bone, its "other side" counterpart will be transformed accordingly,
through a symmetry along the armature local X axis.
As most rigs have at least one axis of symmetry (animals, humans, ...),
it is an easy way to spare you half of the editing work!

.. seealso::

:ref:`naming bones &lt;armature-editing-naming-bones&gt;`.

Separate Bones
==============

You can, as with meshes, separate the selected bones in a new armature object
:menuselection:`Armature --&gt; Separate`, :kbd:`Ctrl-Alt-P` and of course,
in *Object Mode*, you can join all selected armatures in one
:menuselection:`Object --&gt; Join Objects`, :kbd:`Ctrl-J`.

##########
Editing
##########

.. toctree::
:maxdepth: 2

introduction.rst
transform.rst
bones.rst
naming.rst
parenting.rst
properties.rst
sketching.rst
templating.rst

************
Introduction
************

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Hotkey:   :kbd:`Tab`

As with any other object, you edit your armature in *Edit Mode* :kbd:`Tab`.

Editing an armature means two main domains of action:

- :doc:`Editing the bones &lt;/rigging/armatures/bones/editing/bones&gt;` -- i.e.
adding/inserting/deleting/extruding/sub-dividing/joining them...
- :doc:`Editing the bones' properties &lt;/rigging/armatures/bones/editing/properties&gt;` --
this includes key features, like transform properties (e.g. grab, scale, etc...)
and relationships between bones (parenting and connecting),
as well as bones' names, influence, behavior in *Pose Mode*, etc.

These are standard editing methods, quite similar for example to
:doc:`meshes &lt;/modeling/meshes/editing/introduction&gt;` editing.
Blender also features a more advanced "armature sketching" tool,
called :doc:`Etch-a-Ton &lt;/rigging/armatures/bones/editing/sketching&gt;`.
The same tool might also be used in :doc:`templating &lt;/rigging/armatures/bones/editing/templating&gt;`,
i.e. using another armature as template for the current one...

.. important::

One important thing to understand about armature editing is that you
edit the *rest position* of your armature, i.e. its "default state".
An armature in its *rest position* has all bones with *no* rotation and scaled to 1.0 in their own local space.

The different :doc:`poses &lt;/rigging/armatures/posing/index&gt;`
you might create afterwards are based on this rest position.
So if you modify it in *Edit Mode*, all the poses already existing will also be modified.
Thus you should in general be sure that your armature is definitive before starting to
:doc:`skin &lt;/rigging/armatures/skinning/index&gt;` and :doc:`pose &lt;/rigging/armatures/posing/index&gt;` it!

.. note::

Please note that some tools work on bones' joints, while others work on bones themselves.
Be careful not to get confused.
.. _armature-editing-naming-bones:

******
Naming
******

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    :menuselection:`Properties region --&gt; Item`,
:menuselection:`Bones tab --&gt; Bones panel`

You can rename your bones, either using the *name* field of the *Item*
panel in the 3D Views, for the active bone,
or using the *name* field in each bone of the *Bones* tab in *Edit Mode*.

.. (todo) naming with the Outliner

Blender also provides you some tools that take advantage of bones named in a left/right
symmetry fashion, and others that automatically name the bones of an armature.
Let us look at this in detail.

.. _armature-editing-naming-conventions:

Naming Conventions
==================

Naming conventions in Blender are not only useful for you in finding the right bone,
but also to tell Blender when any two of them are counterparts.

In case your armature can be mirrored in half (i.e. it is bilaterally symmetrical),
it is worthwhile to stick to a left/right naming convention.
This will enable you to use some tools that will probably save you time and effort
(like the *X-Axis Mirror* editing tool we saw above...).

.. figure:: /images/rigging_armatures_editing_properties_bone-naming.png

An example of left/right bone naming in a simple rig.

#. First you should give your bones meaningful base-names, like "leg", "arm", "finger", "back", "foot", etc.
#. If you have a bone that has a copy on the other side (a pair), like an arm,
give it one of the following separators:

- Left/right separators can be either the second position
"L\ **_**\ calfbone" or last-but-one "calfbone\ **.**\R"
- If there is a lower or upper case "L", "R", "left" or "right", Blender handles the counterpart correctly.
See below for a list of valid separators.
Pick one and stick to it as close as possible when rigging; it will pay off.

Examples of valid saparators:

- (nothing): handLeft --&gt; handRight
- ``_`` (underscore): hand\ **_**\L --&gt; hand\ **_**\R
- ``.`` (dot): hand\ **.**\l --&gt; hand\ **.**\r
- ``-`` (dash): hand\ **-**\l --&gt; hand\ **-**\r
- `` `` (space): hand LEFT --&gt; hand RIGHT

.. note::

Note that all examples above are also valid with the left/right part placed before the name.
You can only use the short "L"/ "R" code if you use a separator (e.g "handL"/ "handR" will not work!).

#. Before Blender handles an armature for mirroring or flipping,
it first removes the number extension, e.g. ".001".
#. You can copy a bone named "bla.L" and flip it over using :menuselection:`Specials --&gt; Flip Left-Right Names`.
Blender will name the copy "bla.L.001" and flipping the name will give you "bla.R".

Flip Name
=========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Flip Name`,
:menuselection:`Specials --&gt; Flip Name`

You can flip left/right markers (see above) in selected bone names,
using :menuselection:`Armature --&gt; Flip Name`.
This can be useful if you have constructed half of a symmetrical rig
(marked for a left or right side) and duplicated and mirrored it,
and want to update the names for the new side.
Blender will swap text in bone names according to the above naming conventions,
and remove number extensions if possible.

AutoName
========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; AutoName Left/Right`,
:menuselection:`Armature --&gt; AutoName Front/Back`, :menuselection:`Armature --&gt; AutoName Top/Bottom`

The three *AutoName* entries of the *Armature* and *Specials* menu :kbd:`W`
allows you to automatically add a suffix to all selected bones, based
on the position of their root relative to the armature center and its local coordinates:

AutoName Left/Right
will add the ".L" suffix to all bones with a *positive* X-coordinate root,
and the ".R" suffix to all bones with a *negative* X-coordinate root.
If the root is exactly at 0.0 on the X-axis, the X-coordinate of the tip is used.
If both joints are at 0.0 on the X-axis, the bone will just get a period suffix, with no "L"/ "R"
(as Blender cannot decide whether it is a left or right bone...).
AutoName Front/Back
will add the ".Bk" suffix to all bones with a *positive* Y-coordinate root,
and the ".Fr" suffix to all bones with a *negative* Y-coordinate root.
The same as with *AutoName Left-Right* goes for 0.0 Y-coordinate bones...
AutoName Top/Bottom
will add the ".Top" suffix to all bones with a *positive* Z-coordinate root,
and the ".Bot" suffix to all bones with a *negative* Z-coordinate root.
The same as with *AutoName Left-Right* goes for 0.0 Z-coordinate bones...
.. _armature-bone-chain-edit:

*********
Parenting
*********

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    Armature
| Menu:     :menuselection:`Armature --&gt; Parent --&gt; ...`
| Hotkey:   :kbd:`Ctrl-P`, :kbd:`Alt-P`

You can edit the relationships between bones (and hence create/modify the chains of bones)
both from the 3D Views and the Properties editor. Whatever method you prefer,
it's always a matter of deciding, for each bone, if it has to be parented to another one,
and if so, if it should be connected to it.

To parent and/or connect bones, you can:

- In a 3D View, select the bone and *then* its future parent, and press :kbd:`Ctrl-P`
(or :menuselection:`Armature --&gt; Parent --&gt; Make Parent...`).
In the small *Make Parent* menu that pops up, choose *Connected*
if you want the child to be connected to its parent, else click on *Keep Offset*.
If you have selected more than two bones, they will all be parented to the last selected one.
If you only select one already-parented bone, or all selected bones are already parented to the last selected one,
your only choice is to connect them, if not already done.
If you select only one non-parented bone, you will get the *Need selected bone(s)* error message...

.. note::

With this method, the newly-children bones will not be scaled nor rotated --
they will just be translated if you chose to connect them to their parent's tip.

- In the Properties editor, *Bones* tab, for each selected bone,
you can select its parent in the *Parent* data-ID to the upper right corner of its Relations panel.
If you want them to be connected, just enable the checkbox to the right of the list.

.. note::

With this method, the tip of the child bone will never be translated --
so if *Connected* is enabled, the child bone will be completely transformed by the operation.

.. list-table::
Parenting example.

* - .. figure:: /images/rigging_armatures_editing_properties_parenting-1.png
:width: 320px

The starting armature, with Bone.005 parented and connected to Bone.004.

- .. figure:: /images/rigging_armatures_editing_properties_parenting-4.png
:width: 320px

Bone.005 re-parented to Bone.002, but not connected to it
(same result, using either :kbd:`Ctrl-P-2` in 3D View, or the Bones tab settings).

* - .. figure:: /images/rigging_armatures_editing_properties_parenting-2.png
:width: 320px

Bone.005 parented and connected to Bone.002, using :kbd:`Ctrl-P-1` in 3D View.

- .. figure:: /images/rigging_armatures_editing_properties_parenting-3.png
:width: 320px

Bone.005 parented and connected to Bone.002.

Using the Parent data-ID of Bone.005 Relations panel.

To disconnect and/or free bones, you can:

- In a 3D View, select the desired bones, and press :kbd:`Alt-P`
(or :menuselection:`Armature --&gt; Parent --&gt; Clear Parent...`).
In the small *Clear Parent* menu that pops up, choose *Clear Parent* to completely free all selected bones,
or *Disconnect Bone* if you just want to break their connections.
- In the Properties editor, *Bones* tab, for each selected bone, you can select no parent in the
*Parent* data-ID of its Relations panel, to free it completely.
If you just want to disconnect it from its parent, disable the *Connected* checkbox.

Note that relationships with non-selected children are never modified.
..    TODO/Review: {{review|copy=X}}.

**********
Properties
**********

.. _armature-bone-properties:

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Bone Settings --&gt; ...`
| Hotkey:   :kbd:`Shift-W`, :kbd:`Ctrl-Shift-W`, :kbd:`Alt-W`

Most bones' properties (excepted the transform ones) are regrouped in each bone's panels,
in the *Bones* tab in *Edit Mode*. Let us detail them.

Note that some of them are also available in the 3D Views,
through the three pop-up menus within the same entry:

- *Toggle Setting*: :kbd:`Shift-W` or :menuselection:`Armature --&gt; Bone Settings --&gt; Toggle a Setting`
- *Enable Setting*: :kbd:`Ctrl-Shift-W` or :menuselection:`Armature --&gt; Bone Settings --&gt; Enable a Setting`
- *Disable Setting*: :kbd:`Alt-W` or :menuselection:`Armature --&gt; Bone Settings --&gt; Disable a Setting`

Draw Wire
ToDo.
Deform
(also :kbd:`Shift-W` :menuselection:`--&gt; (Deform, ...)`).
Multiply Vertex Group by Envelope
(also :kbd:`Shift-W` :menuselection:`--&gt; (Multiply Vertex Group by Envelope, ...)`)

These settings control how the bone influences its geometry, along with the bones' joints radius.
This will be detailed in the :doc:`skinning part &lt;/rigging/armatures/skinning/index&gt;`.
Inherit Rotation
These settings affect the behavior of children bones while transforming their parent in *Pose Mode*,
so this will be detailed in the :doc:`posing part &lt;/rigging/armatures/posing/index&gt;` !
Inherit Scale
ToDo.
Lock
(also :kbd:`Shift-W` :menuselection:`--&gt; (Locked, ...)`)
This will prevent all editing of the bone in *Edit Mode*;
see :doc:`previous page &lt;/rigging/armatures/bones/editing/bones&gt;`.
..    TODO/Review: {{review|im=some images need updated|text=retarget conversion method}}.

******************
Skeleton Sketching
******************

.. figure:: /images/rigging_armatures_editing_sketching_skeleton-sketching-panel.png
:align: right

The Bone Sketching panel.

If you think that creating a whole rig by hand, bone after bone, is quite boring, be happy:
some Blender developers had the same feeling, and created the Skeleton Sketching tool,
formerly the Etch-a-ton tool, which basically allows you to "draw" (sketch)
whole chains of bones at once.

Skeleton Sketching is obviously only available in *Edit Mode*, in the 3D Views.
You control it through its *Skeleton Sketching* panel
in the *Transform panel*, which you can open with :kbd:`N`.
Use the mouse :kbd:`LMB` to draw strokes, and :kbd:`RMB` for gestures.
Showing its tool panel will not enable sketching. You must tick the checkbox next
to *Skeleton Sketching* to start drawing bone chains
(otherwise, you remain in the standard *Edit Mode*...).

Sketching is done in two steps:

- `Drawing Chains`_ (called "strokes"). Each stroke corresponds to a chain of bones.
- `Converting to Bones`_, using different methods.

The *point of view* is important, as it determines the future bones' roll angle:
the Z axis of a future bone will be aligned with the view Z axis of the 3D View in
which you draw its "parent" stroke (unless you use the *Template* converting method...).
Strokes are drawn in the current view plane passing through the 3D cursor,
but you can create somewhat "3D" strokes using the *Adjust* drawing option in different views (see below).

If you enable the small *Quick Sketch* option, the two steps are merged into one:
once you have finalized the drawing of a stroke (see `Drawing Chains`_),
it is immediately converted to bones (using the current active method) and deleted.
This option makes bone sketching quick and efficient, but you lose all the advanced stroke editing possibilities.

Sketches are **not** saved into blend-files,
so you cannot interrupt a sketching session without losing all your work!
Note also that the sketching is common to the whole Blender session, i.e.
there is only one set of strokes (one sketch) in Blender, and not one per armature, or even per file...

Drawing Chains
==============

So, each stroke you draw will be a chain of bones, oriented from the starting point
(the reddest or most orange part of the stroke) to its end (its whitest part).
A stroke is made of several segments, delimited by small black dots.
There will be at least one bone per segment
(except with the *Template* conversion method,
see :doc:`next page &lt;/rigging/armatures/bones/editing/templating&gt;`),
so all black points represents future bones' joints.
There are two types of segments, which can be mixed together:

.. figure:: /images/rigging_armatures_editing_sketching_strokes-example.png

Strokes example. From top to bottom:
A selected polygonal stroke of four straight segments, oriented from left to right.
An unselected free stroke of two segments, oriented from left to right.
A mixed stroke, with one straight segment between two free ones, right to left.

Straight Segments
-----------------

To create a straight segment, click :kbd:`LMB` at its starting point.
Then move the mouse cursor, without pressing any button,
a dashed red line represents the future segment.
Click :kbd:`LMB` again to finalize it.
Each straight segment of a stroke will always create one and only one bone,
whatever convert algorithm you use (except for the *Template* conversion method).

.. list-table::
Drawing straight segments example.

* - .. figure:: /images/rigging_armatures_editing_sketching_poly-stroke-1.png

The first segment has been started with a :kbd:`LMB` click and the mouse moved to its end point.

- .. figure:: /images/rigging_armatures_editing_sketching_poly-stroke-2.png

The first segment has been finalized by a second :kbd:`LMB` click, which also started a new segment...

- .. figure:: /images/rigging_armatures_editing_sketching_poly-stroke-3.png

Repeating these steps, we now have a four-segment polygonal stroke.

Free Segments
-------------

To create a free (curved) segment, click and hold :kbd:`LMB` at its starting point.
Then draw your segment by moving the mouse cursor -- as in any paint program! Release
:kbd:`LMB` to finalize the segment. You will then be creating a new straight segment,
so if you would rather start a new free segment, you must immediately re-press :kbd:`LMB`.

The free segments of a stroke will create different number of bones, in different manners,
depending on the conversion method used. The future bones' joints for the current selected method are
represented by small green dots for each one of those segments, for the selected strokes only.

The free segment drawing uses the same *Manhattan Distance*
setting as the :doc:`grease pencil tool &lt;/interface/grease_pencil/introduction&gt;`
(*User Preferences*, *Edit Methods* "panel", *Grease Pencil* group)
to control where and when to add a new point to the segment. So if you feel your free segments are too detailed,
raise this value a bit, and if you find them too jagged, lower it.

.. list-table::
Drawing free segments example.

* - .. figure:: /images/rigging_armatures_editing_sketching_free-stroke-1.png

While drawing a first free segment with click and drag :kbd:`LMB`.

- .. figure:: /images/rigging_armatures_editing_sketching_free-stroke-2.png

The first free segment finalized by releasing :kbd:`LMB`.

* - .. figure:: /images/rigging_armatures_editing_sketching_free-stroke-3.png

If you now move the mouse without pressing :kbd:`LMB` again, you will create a straight segment...

- .. figure:: /images/rigging_armatures_editing_sketching_free-stroke-4.png

But if you immediately click again and drag :kbd:`LMB` you will instead start a new free segment.

You finalize a whole stroke by clicking :kbd:`RMB`. You can cancel the stroke you are drawing by pressing :kbd:`Esc`.
You can also snap strokes to underlying meshes by holding :kbd:`Ctrl` while drawing.
By the way, the *Peel Objects* button at the bottom of the *Bone Sketching* panel is the same thing as the
"monkey" button of the snapping header controls shown when *Volume* snap element is selected.
See the :ref:`snap to mesh &lt;transform-snap-element&gt;` page for details.

Selecting Strokes
=================

A stroke can be selected (materialized by a solid red-to-white line), or not
(shown as an orange-to-white line) - see (Strokes example) above. As usual,
you select a stroke by clicking :kbd:`RMB` on it,
you add one to/remove one from the current selection with a :kbd:`Shift-RMB` click,
and :kbd:`A` (de)selects all strokes...

Deleting
========

Hitting :kbd:`X` or clicking on the *Delete* button (*Bone Sketching* panel)
deletes the selected strokes (be careful, no warning/confirmation pop-up menu here).
See also `Gestures`_.

Modifying Strokes
=================

You can adjust, or "redraw" your strokes by enabling the *Overdraw Sketching* option
of the *Bone Sketching* panel. This will modify the behavior of the strokes drawing
(i.e. :kbd:`LMB` clicks and/or hold): when you draw, you will not create a new stroke,
but rather modify the nearest one.

The part of the old stroke that will be replaced by the new one are drawn in gray.
This option does not take into account stroke selection, i.e.
all strokes can be modified this way,
not just the selected ones... Note also that even if it is enabled,
when you draw too far away from any other existing stroke, you will not modify any of them,
but rather create a new one, as if *Overdraw Sketching* was disabled.

.. list-table::
Adjusting stroke example.

* - .. figure:: /images/rigging_armatures_editing_sketching_adjusting-stroke-1.png
:width: 350px

Adjusting a stroke: the gray part of the "unselected" (orange)
stroke will be replaced by the currently drawn "replacement".

- .. figure:: /images/rigging_armatures_editing_sketching_adjusting-stroke-2.png
:width: 350px

Stroke adjusted.

.. warning:: Undo/Redo

There is no undo/redo for sketch drawing.

Gestures
========

There quite a few things about strokes editing that are only available through gestures.
Gestures are started by clicking and holding :kbd:`Shift-LMB`
(when you are not already drawing a stroke), and materialized by blue-to-white lines.
A gesture can affect several strokes at once.

There is no direct way to cancel a gesture once you have started "drawing" it.
So the best thing to do, if you change your mind (or made a "false move"),
is to continue to draw until you get a disgusting scribble,
crossing your stroke several times.
In short, something that the gesture system would never recognize!

.. list-table::

* - .. figure:: /images/rigging_armatures_editing_sketching_gestures-canceling-1.png

An unwanted cut stroke.

- .. figure:: /images/rigging_armatures_editing_sketching_gestures-canceling-2.png

Some random drawing.

- .. figure:: /images/rigging_armatures_editing_sketching_gestures-canceling-3.png

The stroke is still in one piece.

Cut
---

To *cut* a segment (i.e. add a new black dot inside it, making two segments out of one),
"draw" a straight line crossing the chosen segment where you want to split it.

.. list-table::

* - .. figure:: /images/rigging_armatures_editing_sketching_gestures-cut-1.png

Gesture.

- .. figure:: /images/rigging_armatures_editing_sketching_gestures-cut-2.png

Result.

Delete
------

To *delete* a stroke, draw a "V" crossing the stroke to delete twice.

.. list-table::

* - .. figure:: /images/rigging_armatures_editing_sketching_gestures-delete-1.png

Gesture.

- .. figure:: /images/rigging_armatures_editing_sketching_gestures-delete-2.png

Result.

Reverse
-------

To *reverse* a stroke (i.e. the future chain of bones will be reversed),
draw a "C" crossing twice the stroke to reverse.

.. list-table::

* - .. figure:: /images/rigging_armatures_editing_sketching_gestures-reverse-1.png

Gesture.

- .. figure:: /images/rigging_armatures_editing_sketching_gestures-reverse-2.png

Result.

Converting to Bones
===================

Once you have one or more selected strokes, you can convert them to bones, using either the *Convert*
button of the *Bone Sketching* panel, or the corresponding gesture
(see `Gestures`_).
Each selected stroke will generate a chain of bones, oriented from its reddest end to its whitest one.
Note that converting a stroke does not delete it.

There are four different conversion methods with three "simple" ones, and one more advanced and complex,
*Template*, that reuses bones from the same armature or from another
one as a template for the strokes to convert, and which is detailed in
:doc:`the next page &lt;/rigging/armatures/bones/editing/templating&gt;`.
Anyway, remember that straight segments are always converted to one and only one bone
(except for the *Template* conversion method),
and that the future bones' joints are shown as green dots on selected free segments.

Remember also that the roll rotation of the created bones has been set during their "parent" stroke drawing
(except for the *Template* conversion method) - their Z axis will be aligned with the view
Z axis of the active 3D View at draw time.

Fixed
-----

With this method,
each free segment of the selected strokes will be uniformly divided in *n* parts
(set in *Number* number button), i.e. will give *n* bones.

.. list-table::

* - .. figure:: /images/rigging_armatures_editing_sketching_convert-fixed-1.png
:width: 320px

The Fixed conversion preview on selected strokes.

- .. figure:: /images/rigging_armatures_editing_sketching_convert-fixed-2.png
:width: 320px

The Fixed conversion result.

Adaptive
----------

With this method, each free segment of the selected strokes will create as many bones as
necessary to follow its shape closely enough. This "closely enough" parameter being set by
the *Threshold* number button; higher values giving more bones,
following more closely the segments' shape.
So the more twisted a free segment, the more bones it will generate.

.. list-table::

* - .. figure:: /images/rigging_armatures_editing_sketching_convert-adaptive-1.png
:width: 320px

The Adaptive conversion preview on selected strokes.

- .. figure:: /images/rigging_armatures_editing_sketching_convert-adaptive-2.png
:width: 320px

The Adaptive conversion result.

Length
------

With this method,
each free segment of the selected strokes will create as many bones as necessary,
so that none of them is longer than the *Length* number button value
(in Blender Units).

.. list-table::

* - .. figure:: /images/rigging_armatures_editing_sketching_convert-length-1.png
:width: 200px

The Length conversion preview on selected strokes.

- .. figure:: /images/rigging_armatures_editing_sketching_convert-length-2.png
:width: 200px

Using a larger length value.

- .. figure:: /images/rigging_armatures_editing_sketching_convert-length-3.png
:width: 200px

The Length conversion result.

Retarget
--------

Retarget template bone chain to stroke.

Template
Template armature that will be retargeted to the stroke.
This is a more complex topic, detailed in its :doc:`own page &lt;/rigging/armatures/bones/editing/templating&gt;`.

Retarget roll mode
None
Do not adjust roll.
View
Roll bones to face the view.
Joint
Roll bone to original joint plane offset.

Autoname
Todo.
Number
Todo.
Side
Todo.
..    TODO/Review: {{review|copy=X}}.

*******************
Armature Templating
*******************

The idea of templating is to use an already existing armature as base ("template")
to create a new armature. It differs from a simple copy in that you can directly define the
new armature different in some aspects than its reference rig.

In Blender, the only templating tool is the bone sketching one
(Etch-a-ton, described in :doc:`the previous page &lt;/rigging/armatures/bones/editing/sketching&gt;`),
with its *Template* conversion method, so you should have read its page before this one!

Using Bone Sketching
====================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Panel:    Bone Sketching (3D View editor)
| Menu:     :menuselection:`Armature --&gt; Bone Sketching`
| Hotkey:   :kbd:`P`

The *Template* conversion method of *Bone Sketching* tool maps a copy of
existing bones to each selected stroke. The new bones will inherit some of their properties
(influence, number of segments, etc.) from the corresponding bones in the template,
but they will acquire their lengths, rolls and rotation from the sketch;
so these properties would be different as compared to the template.

This is easier to understand with some examples.

In the following image, "armature.002" is set as the template,
and the stroke maps with "chain_a" of this template.
None of the bones are selected in the template.
Note that there is no second stroke to map with chain "chain_b" of the template.
The result is shown at right:
Blender creates a copy of "chain_a" and matches the bones with the stroke.

Blender also creates a copy of "chain_b", but this chain is not altered in any way;
because this tool can map only one selected chain with a stroke.

In the following example, no template is selected. (In other words, all the action is within the armature itself.)

Two bones are selected in "chain_b",
and the property panel is set to map the joints with the stroke. So these two selected bones
are copied and the newly created copy of the chain is matched with the stroke.
(Note that the newly created bones are named in continuation of the original chain.)

.. list-table::

* - .. figure:: /images/rigging_armatures_editing_templating_sketching-panel-1.png

Conversion settings.

- .. figure:: /images/rigging_armatures_editing_templating_stroke-conversion-1.png

Before conversion.

- .. figure:: /images/rigging_armatures_editing_templating_stroke-conversion-2.png

After conversion.

If you had selected both the chains ("Chain_a" and "Chain_b"),
you would have still got the same result as in the example above,
because the tool maps to stroke only one selected chain.

In the following example also, only one chain is selected,
but there are three strokes to map to. In this case, the same chain is copied three times
(once for each stroke) and then mapped to individual strokes.
Note how a two-bone chain is fitted to a three-segment stroke.

.. list-table::
The newly created bones are numbered sequentially, after the original bones' names.

* - .. figure:: /images/rigging_armatures_editing_templating_stroke-multi-conversion-1.png

Before conversion.

- .. figure:: /images/rigging_armatures_editing_templating_stroke-multi-conversion-2.png

After conversion.

OK now, here are some important ground rules:

- This conversion method can use as reference bones either the selected bones in the *currently* edited armature,
or *all* bones from another armature.
In general, it is a better idea to create new "templated" bones inside the "reference"
armature, so you can precisely select which bones to use as template --
if you want the new bones in a different armature, you can then use the *Separate*
:kbd:`Ctrl-Alt-P` and optionally *Join* (:kbd:`Ctrl-J` in *Object Mode*) tools...
- This tool only considers *one* chain of bones,
so it is better to select only one chain of bones inside the current armature
(or use a single-chain armature object as template).
Else, the chain of the template containing the first created bones will be mapped to the
selected strokes, and the other chains will just be "copied" *as is*, without any modification.
- This tool maps the same chain of bones on all selected strokes,
so you cannot use multiple strokes to map a multi-chains template --
you will rather get a whole set of new bones for each selected stroke!
- If you have strokes only made of straight segments,
they must have *at least* as much segments as there are bones in the template chain
(else, the newly created chain is not mapped at all to the stroke,
and remains an exact duplicate of its template).
If there are more segments than necessary,
the conversion algorithm will chose the best "joints" for the bones to fit to the reference chain,
using the same influence settings as for free segments (*Angle*, *Length* and *Definition* settings, see below).
- If you try to *Convert* without template bones (i.e.
either an empty armature selected as template,
or no bones selected in the current edited armature),
you will get the error message ``No Template and no deforming bones selected``, and nothing will occur.

.. list-table::
The *Skeleton Sketching* panel with *Retarget* conversion method enabled.

* - .. figure:: /images/rigging_armatures_editing_templating_sketching-panel-1.png

With current edited armature as template.

- .. figure:: /images/rigging_armatures_editing_templating_sketching-panel-2.png

With another armature as template.

Now, here are the settings of this conversion method:

No, View, Joint buttons
These three toggle buttons (mutually exclusive) control how the roll angle of newly created bones is affected:

No
Do not alter the bones roll (i.e. the new bones' rolls fit their reference ones).
View
Roll each bone so that one of its X, Y or Z local axis is aligned
(as much as possible) with the current view's Z axis.
Joint
New bones roll fit their original rotation (as *No* option),
but with regards to the bend of the joint with its parent.

.. list-table:: Templating: bone roll example.

* - .. figure:: /images/rigging_armatures_editing_templating_bone-roll-1.png

With No roll option.

- .. figure:: /images/rigging_armatures_editing_templating_bone-roll-2.png

With View roll option.

- .. figure:: /images/rigging_armatures_editing_templating_bone-roll-3.png

With Joint roll option.

The "Bone.003" to "Bone.005" chain is the mapped-to-stroke
version of "Bone" to "Bone.002" selected one, and "Bone.001" has a modified roll angle.

Template
In this data-ID you can select the armature to use as template.
If you choose *None*, the selected bones from the currently edited armature will be used as reference,
else all bones of the other armature will be used.

*Angle*, *Length*, *Definition* are numeric fields.
These settings control how the template is mapped to the selected strokes.
Each one can have a value between (0.0 and 10.0), the default being 1.0.

Angle
Controls the influence of the angle of the joints (i.e. angle between bones). The higher this value,
the more the conversion process will try to preserve these joints angle in the new chain.
Length
Controls the influence of the bones' length. The higher this value,
the more the conversion process will try to preserve these lengths in the new bones.
Definition
Controls the influence of the stroke's shape. The higher this value,
the more the conversion process will try to follow the stroke with the new chain.

.. figure:: /images/rigging_armatures_editing_templating_influence-weights.png

Examples of Template conversions for various influence weights values,
with one stroke quite similar to the template chain's shape, and one stroke very different.

Side and Number text fields, *auto* button
These control how the new bones are named. By default,
they just take the same names as the originals from the template, except for the final number,
increased as needed. However, if the template bones have "&amp;s" somewhere in their name,
this "placeholder" will be replaced in the "templated" bones' names by the content of the *Side* text field.
Similarly, a "&amp;n" placeholder will be replaced by the *Number* field content.
If you enable the small *auto* button, the *Number* field content is auto-generated,
producing a number starting from nothing, and increased each time you press the *Convert* button,
and the "&amp;s" placeholder is replaced by the side of the bone (relative to the local X axis:
"r" for negative X values, "l" for positive ones).

.. list-table::
Naming and placeholders, using a simple leg template.

* - .. figure:: /images/rigging_armatures_editing_templating_sketching-panel-3.png
:width: 200px

Conversion settings.

- .. figure:: /images/rigging_armatures_editing_templating_name-placeholders-1.png
:width: 200px

Before conversion (note the &amp;n and &amp;s
placeholders in template bones' names).

- .. figure:: /images/rigging_armatures_editing_templating_name-placeholders-2.png
:width: 200px

After conversion: the placeholders have been replaced by the
content of the S and N text fields of the Bone Sketching panel.

.. list-table::
Auto naming and placeholders, using a simple leg template.

* - .. figure:: /images/rigging_armatures_editing_templating_sketching-panel-4.png
:width: 200px

Conversion settings.

- .. figure:: /images/rigging_armatures_editing_templating_auto-naming-1.png
:width: 200px

Before conversion (note that, in the Bone Sketching panel,
the S and N fields are empty, and the small "auto" button is enabled).

- .. figure:: /images/rigging_armatures_editing_templating_auto-naming-2.png
:width: 200px

After conversion.

Static text line
The line just above the *Peel Objects* button gives you two informations:

- The *n* joints part gives you the number of joints
(i.e. bones' joints, with connected joints considered as one joint),
either from the selected bones of the edited armature, or in the whole other template armature.
- The second part is only present when another armature has been selected as template --
it gives you the *root bone's name* of the chain that will be mapped to the strokes.
Or, while you are drawing a stroke with straight segments,
the name of the bone corresponding to the current segment
(and "Done" when you have enough segments for all bones in the template chain).

*********
Transform
*********

Transform
=========

.. figure:: /images/rigging_armatures_editing_properties_transform-panel.png
:align: right
:figwidth: 165px

The Transform panel for armatures in Edit Mode.

We will not detail here the various transformations of bones, nor things like axis locking, pivot points, and so on,
as they are common to most object editing, and already described in the
:doc:`mesh section &lt;/editors/3dview/object/editing/transform/control/index&gt;`.
The same goes for mirroring,
as it is nearly the same as with :doc:`mesh editing &lt;/modeling/meshes/editing/transform/mirror&gt;`.
Just keep in mind that bones' roots and tips behave more or less like meshes' vertices,
and bones themselves act like edges in a mesh.

As you know, bones can have two types of relationships: They can be parented,
and in addition connected. Parented bones behave in *Edit Mode* exactly as if they
had no relations. They can be grabbed, rotated, scaled, etc.
a parent bone without affecting its descendants. However,
connected bones must always have parent's tips connected to child's roots,
so by transforming a bone, you will affect all its connected parent/children/siblings.

While with other transform tools, the "local axes" means the object's axes,
here they are the bone's own axes (when you lock to a local axis,
by pressing the relevant key twice, the constraint is applied along the selected bone's local axis,
not the armature object's axis).

Finally, you can edit in the *Transform* panel in the Properties region
the positions and radius of both joints of the active selected bone,
as well as its :ref:`roll rotation &lt;armature-bone-roll&gt;`.

Scale Radius
============

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Transform --&gt; Scale Radius`
| Hotkey:   :kbd:`Alt-S`

You can alter the radius that a bone has by selecting the head, body or tail of a bone,
and then press :kbd:`Alt-S` and move the mouse left or right.
If the body is selected the mean radius will be scaled.
And as usual, with connected bones, you scale at the same time the radius
of the parent's tip and of the children's roots.

You can also alter the bone radius by selecting the tail or head of the bone you wish to alter,
then navigate to :menuselection:`Properties Editor --&gt; Bone --&gt; Deform --&gt; Radius Section`
and entering new values for the *Tail* and *Head* number buttons.

.. list-table:: Bone Scale and Scale Radius comparison.

* - .. figure:: /images/rigging_armatures_bones_selecting_single-bone.png
:width: 320px

A single selected bone in Octahedron visualization.

- .. figure:: /images/rigging_armatures_editing_properties_scaling-bone-radius-2.png
:width: 320px

After normal scale.

* - .. figure:: /images/rigging_armatures_editing_properties_scaling-bone-radius-3.png
:width: 320px

A single selected bone in Envelope visualization.

- .. figure:: /images/rigging_armatures_editing_properties_scaling-bone-radius-4.png
:width: 320px

After Scaled Radius. Its length remains the same, but its joints' radius are bigger.

Note that when you resize a bone (either by directly scaling it,
or by moving one of its joints), Blender automatically adjusts the end-radii of its envelope
proportionally to the size of the modification. Therefore,
it is advisable to place all the bones first, and only then edit these properties.

Scale Envelope Distance
=======================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode and Pose Mode
| Menu:     :menuselection:`Armature --&gt; Transform --&gt; Scale Envelope Distance`
| Hotkey:   :kbd:`Ctrl-Alt-S`

You can alter the size of the Bone Envelope volume by clicking on the body of the bone you want to alter,
:kbd:`Ctrl-Alt-S` then drag your mouse left or right and the Bone Envelope volume will alter accordingly.

You can also alter the Bone Envelope volume by selecting the Bone you wish to alter and
then navigate to :menuselection:`Properties Editor --&gt; Bone --&gt; Deform --&gt; Envelope --&gt; Distance`
then enter a new value into it.

Altering the Bone Envelope volume does not alter the size of the bone just the range
within which it can influence vertices of child objects.

.. list-table:: Envelope scaling example.

* - .. figure:: /images/rigging_armatures_editing_properties_scaling-bone-radius-3.png
:width: 320px

A single bone selected in Envelope visualization.

- .. figure:: /images/rigging_armatures_editing_properties_scaling-bone-radius-5.png
:width: 320px

Its envelope distance scaled.

.. list-table:: "Bone size" scaling example.

* - .. figure:: /images/rigging_armatures_editing_properties_scaling-bone-size-1.png
:width: 200px

A single "default size" bone selected in B-Bone visualization.

- .. figure:: /images/rigging_armatures_editing_properties_scaling-bone-size-2.png
:width: 200px

Its envelope distance scaled.

- .. figure:: /images/rigging_armatures_editing_properties_scaling-bone-size-3.png
:width: 200px

The same armature in Object Mode and B-Bone visualization, with Bone.004's size scaled up.

Align Bones
===========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Transform --&gt; Align Bones`
| Hotkey:   :kbd:`Ctrl-Alt-A`

ToDo.

.. _armature-bone-roll:

Bone Roll
=========

In *Edit Mode*, you can control of the bones roll
(i.e. the rotation around the Y axis of the bone).

However, after editing the armature, or when using :term:`euler rotation`,
you may want to set the bone roll.

Set Bone Roll
-------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Bone Roll --&gt; Set`
| Hotkey:   :kbd:`Ctrl-R`

This is a transform mode where you can edit the roll of all selected bones.

Recalculate Bone Roll
---------------------

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Bone Roll --&gt; Recalculate`
| Hotkey:   :kbd:`Ctrl-N`

Axis Orientation
Local Tangent
Align roll relative to the axis defined by the bone and its parent.

X, Z
Global Axis
Align roll to global X, Y, Z axis.

X, Y, Z
Active Bone
Follow the rotation of the active bone.
View Axis
Set the roll to align with the view-port.
Cursor
Set the roll towards the 3D cursor.
Flip Axis
Reverse the axis direction.
Shortest Rotation
Avoids rolling the bone over 90 degrees from its current value.

Switch Direction
================

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Armature --&gt; Switch Direction`, :menuselection:`Specials --&gt; Switch Direction`
| Hotkey:   :kbd:`Alt-F`

This tool is not available from the *Armature* menu,
but only from the *Specials* pop-up menu :kbd:`W`.
It allows you to switch the direction of the selected bones (i.e.
their root will become their tip, and vice versa).

Switching the direction of a bone will generally break the chain(s) it belongs to.
However, if you switch a whole (part of a) chain, the switched bones will still be parented/connected,
but in "reversed order". See the Fig. :ref:`fig-rig-properties-switch`.

.. _fig-rig-properties-switch:

.. list-table::
Switching example.

* - .. figure:: /images/rigging_armatures_editing_properties_switch-direction-1.png
:width: 320px

An armature with one selected bone, and one selected chain of three bones, just before switching.

- .. figure:: /images/rigging_armatures_editing_properties_switch-direction-2.png
:width: 320px

The selected bones have been switched. Bone.005 is no more connected nor parented to anything.
The chain of switched bones still exists, but reversed (Now Bone.002 is its root, and Bone is its tip).
Bone.003 is now a free bone.

########
Bones
########

.. toctree::
:maxdepth: 2

introduction.rst
structure.rst
selecting.rst
editing/index.rst
properties/index.rst

************
Introduction
************

Bones are the base elements of armatures.
The visualization of bones can be set in the Armatures :doc:`/rigging/armatures/properties/display`.

.. (wip) are rigid.

.. (todo) move to bone &gt; properties &gt; deform? , extend control: fk

Classification
==============

Bones in an Armature can be generally classified into two different types:

- Deforming Bones
- Control Bones

Deforming Bones
---------------

Are bones which when transformed will result in vertices associated with
them also transforming in a similar way. Deforming Bones are directly involved in altering
the positions of vertices associated with their bones.

Control Bones
-------------

Are Bones which act in a similar way to switches,
in that, they control how other bones or objects react when they are transformed.
A Control Bone could for example act as a sliding switch control when the bone is in one
position to the left it could indicate to other bones that they react in a particular way when
transformed, when the Control Bone is positioned to the right,
transforming other bones or objects could do something completely different.
Control Bones are not directly used to alter the positions of vertices,
in fact, Control Bones often have no vertices directly associated with themselves.
.. (todo) images: https://code.blender.org/2016/05/
.. an-in-depth-look-at-how-b-bones-work-including-details-of-the-new-bendy-bones/

***********
Bendy Bones
***********

Bendy Bones (B-Bones) are an easy way to replace long chains of many small rigid bones.
A common use case for curve bones is to model spine columns or facial bones.

Technical Details
=================

Blender treats the bone as a section of a Bézier curve passing through the bones' joints.
Each *Segments* will bend and roll the  to follow this invisible curve
representing a tessellated point of the Bézier curve.
The control points at each end of the curve are the endpoints of the bone.
The shape of the B-Bones can be controlled using a series of properties or
indirectly through the neighboring bones (i.e. first child and parent).
The properties construct handles on either end of the bone to control the curvature.

.. move to constraint &gt; common?

When using the B-bone as a constraint target :ref:`ui-data-id` offers an option to follow the curvature.

.. note::

However, if the bone is used as an target rather than to deform geometry,
the roll is not taken in account.

Display
=======

You can see these segments only if bones are visualized as *B-bones*.

When not visualized as *B-Bone* s, bones are always shown as rigid sticks,
even though the bone segments are still present and effective.
This means that even in e.g. *Octahedron* visualization,
if some bones in a chain have several segments,
they will nonetheless smoothly deform their geometry...

Rest Pose
=========

The initial shape of a B-Bone can be defined in Edit Mode as a rest pose of that bone.
This is useful for curved facial features like curved eyebrows or mouths.

B-Bones have two sets of the Bendy Bone properties -- one for Edit mode (i.e. the Rest Pose/Base Rig) and
another for Pose Mode -- adding together their values to get the final transforms.

Example
=======

.. list-table::

* - .. _fig-rig-bone-intro-bbone:

.. figure:: /images/rigging_armatures_bones_introduction_b-bones-1.png
:width: 320px

The OLD B-Bones, in Edit Mode. ToDo.

- .. figure:: /images/rigging_armatures_bones_introduction_b-bones-2.png
:width: 320px

The Bézier curve superposed to the chain, with its handles placed at bones' joints.

* - .. _fig-rig-bone-intro-same:

.. figure:: /images/rigging_armatures_bones_introduction_b-bones-3.png
:width: 320px

The same armature in Object Mode.

- ..

In Fig. :ref:`fig-rig-bone-intro-bbone` we connected three bones,
each one made of five segments.

Look at Fig. :ref:`fig-rig-bone-intro-same`,
we can see how the bones' segments smoothly "blend" into each other, even for roll.

.. figure:: /images/rigging_armatures_editing_properties_b-bone-pose-mode.png

An armature in Pose Mode, B-Bone visualization: Bone.003 has one segment,
Bone.004 has four, and Bone.005 has sixteen.

Options
=======

Segments
--------

The *Segments* number button allows you to set the number of segments, which the given bone is subdivided into.
Segments are small, rigid linked child bones that interpolate between the root and the tip.
The higher this setting, the smoother "bends" the bone, but the heavier the pose calculations...

Curve XY Offsets
----------------

Applies an offsets the curve handle positions on the plane perpendicular to the bone’s primary (Y) axis.
As a result, the handle moves per-axis (XY) further from its original location, causing the curve to bend.

Roll
----

Roll In, Out
The roll value  (or twisting around the main Y axis of the bone) is interpolated per-segment,
between the start and end roll values.
It is applied as a rotational offsets on top of the previous rotation.
Inherit End Roll
ToDo.

Scale
-----

Scale In, Out
Scaling factor that adjusts the thickness of each segment for X and Z axes only, i.e. length is not affected.
Similar to *Roll* it is interpolated per-segment.

Easing
------

Ease In, Out
The *Ease In/Out* number buttons, change the "length" of the :ref:`"auto" &lt;curve-handle-type-auto&gt;` Bézier handle
to control the "root handle" and "tip handle" of the bone, respectively.

These values are proportional to the default length, which of course automatically varies depending on bone length,
angle with the handle reference, and so on.

.. list-table:: Ease In/Out settings example, with a materialized Bézier curve.

* - .. figure:: /images/rigging_armatures_editing_properties_curve-in-out-1.png
:width: 320px

Look at Bone.004: it has the default In and Out values (1.0).

- .. figure:: /images/rigging_armatures_editing_properties_curve-in-out-2.png
:width: 320px

Bone.004 with In at 2.0, and Out at 0.0.

Custom Handle Reference
-----------------------

B-Bones can use custom bones as their reference bone handles, instead of only using the parent/child bones.
To do so, enable the *Use Custom Reference Handles* toggle in Pose Mode.
If none are specified, then the BBone will only use the Bendy Bone properties.
When the option is on, just use the specified bones instead of using trying looking at the bone’s neighbors.

Relative
Instead of using the endpoints of the bones as absolute points in 3D space
it computes how far the reference bone has moved away from its rest pose.
The delta transformation is then applied as to the bone’s own endpoints to get the handle locations.
This is useful if the custom control bone is far away from its target.

.. tip:: Keying Set

The "BBone Shape" Keying Set includes all Bendy Bones properties.

Example
-------

.. figure:: /images/rigging_armatures_bones_properties_b-bones_settings-demo.png

Visualization of the Bendy Bones properties.

From Left: 1) Curve X/Y offsets, 2) Scale In/Out, 3) Roll In/Out

******
Deform
******

.. figure:: /images/rigging_armatures_bones_properties_deform-panel.png

The Deform panel.

In this panel you can set deformation options for each bone.

Turning the Deform option off,
prevent a bone from deforming the geometry at all,
overriding any weights that it might have been assigned before; It mutes its influence.

It also excludes the active bone in the automatic weight calculation when the mesh is
parented to the armature using the *Armature Deform* tool with the "With Automatic Weights" option.

.. _armature-bones-envelope:

Envelope
========

.. figure:: /images/rigging_armatures_bones_introduction_envelope-edit-mode.png
:align: right
:figwidth: 180px

Bone influence areas for envelopes method.

Envelopes is the most general skinning method. It works with all available object types for
skinning (meshes, lattices, curves, surfaces and texts).
It is based on proximity between bones and their geometry,
each bone having two different areas of influence,
shown in the *Envelope* visualization:

- The inside area, materialized by the "solid" part of the bone, and controlled by both root and tip radius.
- The outside area, materialized by the lighter part around the bone,
and controlled by the *Distance* setting.

.. seealso::

The :doc:`editing pages &lt;/rigging/armatures/bones/editing/transform&gt;` for how to edit these properties.

Distance
The Distance defines a volume which is the range within the bone
has an influence on vertices of the deformed object.
The geometry is less and less affected by the bone as it goes away by following a quadratic decay.

.. figure:: /images/rigging_armatures_parenting_envelope-distance.png

Single bone with various different envelope sizes.

Weight
A bone property, that controls the global influence of the bone over the deformed object,
when using the envelopes method.

It is only useful for the parts of geometry that are "shared",
influenced by more than one bone (generally, at the joints...) - a bone with a high weight will
have more influence on the result than one with a low weight...
Note that when set to 0.0, it has the same effect as disabling the *Deform* option.
Radius
Set the radius for the head and the tail of envelope bones.
Inside this volume, the geometry if fully affected by the bone.

.. figure:: /images/rigging_armatures_parenting_envelope-radius.png

Three Armature Bones all using Envelope Weight.

The 1st with a default radius value, the two others with differing Tail and Head radius values.

Multiply
This option controls how the two deforming methods interact, when they are both enabled.
By default, when they are both active, all vertices belonging to at least one vertex group are only deformed
through the vertex groups method. The other "orphan" vertices being handled by the envelopes one.
When you enable this option, the "deformation influence" that this bone would have on a vertex
(based from its envelope settings) is multiplied with this vertex's weight in the corresponding vertex group.
In other words, the vertex groups method is further "weighted" by the envelopes method.

*************
Display Panel
*************

.. admonition:: Reference
:class: refbox

| Mode:     Object and Pose Mode
| Panel:    :menuselection:`Bone --&gt; Display`

.. figure:: /images/rigging_armatures_visualization_custom-shape-field.png

The Display panel.

Display panel lets you customize the look of your bones taking the shape of another existing object.

Hide
Hides the selected bone.
Wireframe
When enabled, bone is displayed in wireframe mode regardless of the viewport drawing mode.
Useful for non-obstructive custom bone chains.

Custom Shape
============

Blender allows you to give to each bone of an armature a specific shape
(in *Object Mode* and *Pose Mode*), using another object as "template".
In order to be visible the *Shapes* checkbox has to be enabled
(:menuselection:`Armature --&gt; Display` panel).

Options
-------

Custom Shape
Object that defines the custom shape of the selected bone.
Bone Size
Option not to use bones length, so that changes in Edit Mode don’t resize the custom-shape.
Scale
Avoids having multiple custom-shapes at different sizes.
At
Bone that defines the display transform of this shape bone.

Workflow
--------

To assign a custom shape to a bone, you have to:

#. Switch to *Pose Mode* :kbd:`Ctrl-Tab`.
#. Select the relevant bone by clicking on it with :kbd:`RMB`.
#. Go to the *Display* panel *Custom Shape* field and select the 3D object previously created in the scene;
in this example we are using a cube and a cone. You can optionally set the *At* field to another bone.

.. figure:: /images/rigging_armatures_visualization_custom-shape-example.png

The armature with shape assigned to bone. Note the center of the Cone object.

.. note::

- These shapes will never be rendered, like any bone, they are only visible in 3D Views.
- Even if any type of object seems to be accepted by the *OB* field (meshes, curves, even metas...),
only meshes really work. All other types just make the bone invisible; nothing is drawn...
- The center of the shape object will be at the *root of the bone*
(see the :doc:`bone page &lt;/rigging/armatures/bones/index&gt;` for root/tip).
- The object properties of the shape are ignored
(i.e. if you make a parallelepiped out of a cube by modifying its dimensions in *Object Mode*,
you will still have a cube shaped bone...).
- The "along bone" axis is the Y one,
and the shape object is always scaled so that one Blender Unit stretches along the whole bone length.
- If you need to remove the custom shape of the bone,
just right click in the *Custom Shape* field and select *Reset to default value* in the pop-up menu.

So to summarize all this, you should use meshes as shape objects,
with their center at their lower -Y end, and an overall Y length of 1.0 BU.

##############
Properties
##############

.. toctree::
:maxdepth: 2

introduction.rst
bendy_bones.rst
relations.rst
display.rst
deform.rst

************
Introduction
************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode, Edit Mode and Pose Mode
| Panel:    All in Properties editor, *Bone* property

When bones are selected (hence in *Edit Mode* and *Pose Mode*), their
properties are shown in the *Bone* tab of the Properties editor.
This shows different panels used to control features of each selected bone;
the panels change depending on which mode you are working in.

.. figure:: /images/rigging_armatures_bones_properties_properties-editor.png

The Bone tab.

Relations
In this panel you can arrange sets of bones in different layers for easier manipulation.
Display
Display panel lets you customize the look of your bones taking the shape of another existing object.
Deform
In this panel you can set basic deformation properties of the bones.

Transform
=========

.. Todo, images are the same

.. figure:: /images/rigging_armatures_bones_properties_transform-panel-edit.png

The Transform panel (edit mode).

When in edit mode you can use this panel to control position and roll of individual bones.

When in pose mode you can only set location for the main bone, and you can now set rotation and scale.

.. figure:: /images/rigging_armatures_bones_properties_transform-panel-pose.png

The Transform panel (pose mode).

.. note::

This mode is only available in Edit Pose Modes.

Transform Locks
===============

.. figure:: /images/rigging_armatures_bones_properties_transform-locks-panel.png

The Transform Locks panel.

This panel appears only in pose mode and allows you to restrict position,
rotation and scale by axis on each bone in the armature.

.. note::

This mode is only available in Pose Mode.

Inverse Kinematics
==================

.. figure:: /images/rigging_armatures_bones_properties_inverse-kinematics-panel.png

The Inverse Kinematics panel.

This panel controls the way a bone or set of bones behave when linked in an inverse kinematic chain.

.. note::

This mode is only available in Pose Mode.

Custom Properties
=================

See the :doc:`Custom Properties &lt;/data_system/custom_properties&gt;` page for more information.

*********
Relations
*********

.. figure:: /images/rigging_armatures_bones_properties_relations-panel.png

The Relations panel.

In this panel you can arrange sets of bones in different layers for easier manipulation.

Bone Layers
===========

.. admonition:: Reference
:class: refbox

| Mode:     Object, Edit and Pose Mode
| Panel:    :menuselection:`Bone --&gt; Relations`

Moving bones between layers
---------------------------

Obviously, you have to be in *Edit Mode* or *Pose Mode* to move bones between
layers. Note that as with objects, bones can lay in several layers at once,
just use the usual :kbd:`Shift-LMB` clicks... First of all,
you have to select the chosen bone(s)!

- In the Properties editor, use the "layer buttons" of each selected bone Relations panel (*Bones* tab)
to control in which layer(s) it lays.
- In the *3D View* editor, use the menu :menuselection:`Armature --&gt; Move Bone To Layer` or
:menuselection:`Pose --&gt; Move Bone To Layer` or press :kbd:`M` to show the usual pop-up layers menu.
Note that this way, you assign the same layers to all selected bones.

.. _bone_relations_bone_group:

Bone Group
==========

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode

.. figure:: /images/rigging_posing_visualization_bone-group-list.png

The Bone Group data-ID.

To assign a selected bone to a given bone group use the *Bone Group* data-ID.

Object Children
===============

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode

Relative Parenting
ToDo.

.. _bone_relations_parenting:

Parenting
=========

Parent
A :ref:`ui-data-id` to select the bone to set as a parent.
Connected
The *Connected* checkbox set the head of the bone to be connected with its parent root.

Transformations
---------------

Bones relationships have effects on transformations behavior.

By default, children bones inherit:

- Their parent position, with their own offset of course.
- Their parent rotation (i.e. they keep a constant rotation relatively to their parent).
- Their parent scale, here again with their own offset.

.. list-table::
Examples of transforming parented/connected bones.

* - .. figure:: /images/rigging_posing_editing_bones-relationships-1.png
:width: 200px

The armature in its rest position.

- .. figure:: /images/rigging_posing_editing_bones-relationships-2.png
:width: 200px

Rotation of a root bone.

- .. figure:: /images/rigging_posing_editing_bones-relationships-3.png
:width: 200px

Scaling of a root bone.

Exactly like standard children objects. You can modify this behavior on a per-bone basis,
using the Relations panel in the *Bones* tab:

.. figure:: /images/rigging_armatures_bones_properties_relations-panel.png

Relations panel in Pose Mode.

Inherit Rotation
When disabled, this will "break" the rotation relationship to the bone's parent.
This means that the child will keep its rotation in the armature object space when its parent is rotated.
Inherit Scale
When disabled, this will "break" the scale relationship to the bone's parent.

These inheriting behaviors propagate along the bones' hierarchy.
So when you scale down a bone, all its descendants are by default scaled down accordingly.
However, if you set one bone's *Inherit Scale* or *Inherit Rotation*
property on in this "family", this will break the scaling propagation, i.e. this bone *and
all its descendants* will no longer be affected when you scale one of its ancestors.

.. list-table::
Examples of transforming parented/connected bones with Inherit Rotation disabled.

* - .. figure:: /images/rigging_posing_editing_bones-relationships-4.png
:width: 200px

The yellow outlined Inherit Rotation disabled bone in the armature.

- .. figure:: /images/rigging_posing_editing_bones-relationships-5.png
:width: 200px

Rotation of a bone with an Inherit Rotation disabled bone among its descendants.

- .. figure:: /images/rigging_posing_editing_bones-relationships-6.png
:width: 200px

Scaling of a bone with an Inherit Rotation disabled bone among its descendants.

Connected bones have another specificity: they cannot be translated. Indeed,
as their root must be at their parent's tip, if you do not move the parent,
you cannot move the child's root, but only its tip, which leads to a child rotation.
This is exactly what happens, when you press :kbd:`G` with a connected bone selected,
Blender automatically switches to rotation operation.

Bones relationships also have important consequences on how selections of multiple bones
behave when transformed. There are many different situations which may not be included on this list,
however, this should give a good idea of the problem:

- Non-related selected bones are transformed independently, as usual.

.. _fig-rig-pose-edit-scale:

.. figure:: /images/rigging_posing_editing_bones-relationships-7.png
:width: 320px

Scaling bones, some of them related.

- When several bones of the same "family" are selected,
*only* the "most parent" ones are really transformed --
the descendants are just handled through the parent relationship process, as if they were not selected
(see Fig. :ref:`fig-rig-pose-edit-scale` the third tip bone,
outlined in yellow, was only scaled down through the parent relationship,
exactly as the unselected ones, even though it is selected and active.
Otherwise, it should have been twice smaller!).
- When connected and unconnected bones are selected,
and you start a grab operation, only the unconnected bones are affected.
- When a child connected hinge bone is in the selection,
and the "most parent" selected one is connected, when you press :kbd:`G`,
nothing happens, because Blender remains in grab operation, which of course has no effect on a connected bone.

So, when posing a chain of bones, you should always edit its elements from the root bone to the tip bone.
This process is known as *forward kinematics* (FK).
We will see in a :ref:`later page &lt;bone-constraints-inverse-kinematics&gt;`
that Blender features another pose method,
called *inverse kinematics* (IK), which allows you to pose a whole chain just by moving its tip.

.. note::

This feature is somewhat extended/completed by
the :doc:`pose library &lt;/rigging/armatures/properties/pose_library&gt;` tool.

*********
Selecting
*********

You can select and edit bones of armatures in *Edit Mode* and in *Pose Mode*.
Here, we will see how to select bones in *Edit Mode*.
Selecting bones in *Pose Mode* is similar to selecting in *Edit Mode*
with a few specific differences that will be detailed in the :doc:`posing part &lt;/rigging/armatures/posing/selecting&gt;`.

Similar to :doc:`vertices/edges selection &lt;/modeling/meshes/selecting/introduction&gt;` in meshes,
there are two ways to select whole bones in *Edit Mode*:

- Directly, by selecting the bone's body.
- Selecting both of its joints (root and tip).

This is an important point to understand,
because selecting bones' joints only might lead to non-obvious behavior,
with respect to which bone you actually select, see the.

Note that unlike the mesh draw type the armature draw type has no effect on selection
behavior. In other words,
you can select a bone's joint or body the same way regardless of the bone visualization chosen.

Selecting Bone Joints
=====================

To select bones' joints you have the :doc:`standard selection &lt;/editors/3dview/object/selecting/index&gt;` methods.

Inverse selection
-----------------

As stated above, you have to remember that these selection tools are for bones' joints only,
not the bones' bodies.

For example, the *Inverse* selection option :kbd:`Ctrl-I`
inverts the selection of bones' joints, not of bones (see *Inverse selection*).

Remember that a bone is selected only if both its joints are selected. So,
when the selection status of bones' joints is inverted, a new set of bones is selected.

.. list-table:: Inverse selection.

* - .. figure:: /images/rigging_armatures_bones_selecting_two-bones.png
:width: 320px

Two bones selected.

- .. figure:: /images/rigging_armatures_bones_selecting_three-ends.png
:width: 320px

The result of the inverse selection :kbd:`Ctrl-I`
the bones joints selection has been inverted, and not the bones selection.

Selecting connected Bone Joints
-------------------------------

Another example is: when you select the root of a bone connected to its parent,
you also implicitly select the tip of its parent (and vice versa).

.. note::

Remember that when selecting bones' joints,
the tip of the parent bone is the "same thing" as the root of its children bones.

Selecting Bones
===============

By :kbd:`RMB` -clicking on a bone's body, you will select it
(and hence you will implicitly select its root and tip).

Using :kbd:`Shift-RMB`, you can add to/remove from the selection.

You also have some *advanced selection* options, based on their relations.

You can select at once all the bones in the chain which the active (last selected)
bone belongs to by using the *linked selection* tool, :kbd:`L`.

.. list-table::
Linked bones selection

* - .. figure:: /images/rigging_armatures_bones_selecting_single-bone.png
:width: 320px

A single selected bone.

- .. figure:: /images/rigging_armatures_bones_selecting_whole-chain.png
:width: 320px

Its whole chain selected with :kbd:`L`.

Mirror :kbd:`Shift-Ctrl-M`
Flip the selection from one side to another.
Pick Shortest Path :kbd:`Ctrl-RMB`
Selects the path from the active bone to the bone under the mouse.

Deselecting connected Bones
---------------------------

There is a subtlety regarding connected bones.

When you have several connected bones selected, if you deselect one bone,
its tip will be deselected, but not its root, if it is also the tip of another selected bone.

To understand this, look at Fig. :ref:`fig-rig-bone-select-deselect`.

.. _fig-rig-bone-select-deselect:

.. list-table:: Bone deselection in a selected chain.

* - .. figure:: /images/rigging_armatures_bones_selecting_whole-chain.png
:width: 320px

A selected chain.

- .. figure:: /images/rigging_armatures_bones_selecting_two-bones.png
:width: 320px

Two selected bones.

After :kbd:`Shift-RMB` -clicking "Bone.003":

- "Bone.003" 's tip (which is same as "Bone.004" 's root) is deselected.
- "Bone" is "Bone.003" 's parent. Therefore "Bone.003" 's root is same as the tip of "Bone".
Since "Bone" is still selected, its tip is selected. Thus the root of "Bone.003" remains selected.

More/Less
==========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select`

More :kbd:`Ctrl-NumpadPlus`
ToDo.
Less :kbd:`Ctrl-NumpadMinus`
ToDo.
Parent :kbd:`[`, Child :kbd:`]`
You can deselect the active bone and select its immediate parent or one of its children.
Extend Parent :kbd:`Shift-[`, Extend Child :kbd:`Shift-]`
Similar to *Parent*/*Child* but it keeps the active bone in the selection.

Similar
========

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode
| Menu:     :menuselection:`Select --&gt; Similar`
| Hotkey:   :kbd:`Shift-G`

Children
Extends the selection to all hierarchical descendant bones.
Immediate Children
Extends the selection to all direct child bones.
Siblings
Selects bones that have the same parent as the active bone.
Length
Selects bones with a similar bone length (between tip and tail) under the specified *Threshold*.
Direction (Y axis)
ToDo.
Prefix
ToDo.
Suffix
ToDo.
Layer
ToDo.

*********
Structure
*********

.. figure:: /images/rigging_armatures_bones_introduction_bones-elements.png
:align: right

The elements of a bone.

They have three elements:

- The "start joint" named *root* or *head*,
- the "body" itself,
- and the "end joint" named *tip* or *tail*.

With the default armature in edit-mode,
you can select the root and the tip, and move them as you do with mesh vertices.

Both root and tip (the "joints") define the bone by their respective position.

They also have a radius property, only useful for the envelope deformation method (see below).

Roll
====

Activating *Axes* checkbox on the :menuselection:`Armature tab --&gt; Display panel`,
will show local axes for each bone's tip. The Y axis is always aligned along the bone,
oriented from root to tip. So, this is the "roll" axis of the bones.

.. short about envelope (move deform or to skinning) then link

.. _armature-bone-influence:

Bones Influence
===============

.. figure:: /images/rigging_armatures_bones_introduction_envelope-edit-mode.png
:figwidth: 180px
:align: right

A bone in Envelope visualization, in Edit Mode.

Basically, a bone controls a geometry when vertices "follow" the bone. This is like how the
muscles and skin of your finger follow your finger-bone when you move a finger.

To do this, you have to define the strength of *influences* a bone has on a certain vertex.

The simplest way is to have each bone affecting those parts of the geometry that are within a
given range from it. This is called the *envelope technique*,
because each bone can control only the geometry "enveloped" by its own influence area.

If a bone is visualized as *Envelope*,
in *Edit Mode* and in *Pose Mode* you can see the area of influence,
which depends on:

- The *distance* property and
- the root's radius and the tip's radius.

.. figure:: /images/rigging_armatures_bones_introduction_envelope-pose-mode.png
:width: 300px

Our armature in Envelope visualization, in Pose Mode.

All these influence parameters are further detailed in the :doc:`skinning pages &lt;/rigging/armatures/skinning/index&gt;`.
.. _armatures-index:

############
Armatures
############

.. toctree::
:maxdepth: 2

introduction.rst
bones/index.rst
properties/index.rst
structure.rst
skinning/index.rst
posing/index.rst

************
Introduction
************

An Armature in Blender can be thought of as similar to the armature of a real skeleton,
and just like a real skeleton an Armature can consist of many bones. These bones can be moved
around and anything that they are attached to or associated with will move and deform in a
similar way.

An "armature" is a type of object used for :doc:`rigging &lt;/rigging/index&gt;`.
A rig are the controls and strings that move a marionette (puppet).
Armature object borrows many ideas from real life skeletons.

Your first armature
===================

In order to see what we are talking about, let us try to add the default armature in Blender.

(Note that armature editing details are explained in the
:doc:`armatures editing section &lt;/rigging/armatures/bones/editing/index&gt;`).

Open a default scene, then:

#. Delete all objects in the scene.
#. Make sure the cursor is in the world origin with :kbd:`Shift-C`.
#. Press :kbd:`Numpad1` to see the world in Front view.
#. Add a *Single Bone* (:menuselection:`Add --&gt; Armature --&gt; Single Bone`).
#. Press :kbd:`NumpadDelete` to see the armature at maximum zoom.

.. figure:: /images/rigging_armatures_introduction.png

The default armature.

The Armature Object
===================

As you can see, an armature is like any other object type in Blender:

- It has a center, a position, a rotation and a scale factor.
- It has an Object Data data-block, that can be edited in *Edit Mode*.
- It can be linked to other scenes, and the same armature data can be reused on multiple objects.
- All animation you do in *Object Mode* is only working on the whole object,
not the armature's bones (use the *Pose Mode* to do this).

As armatures are designed to be posed, either for a static or animated scene,
they have a specific state, called "rest position". This is the armature's default "shape",
the default position/rotation/scale of its bones, as set in *Edit Mode*.

In *Edit Mode*, you will always see your armature in rest position,
whereas in *Object Mode* and *Pose Mode*,
you usually get the current "pose" of the armature
(unless you enable the *Rest Position* button of the *Armature* panel).

Armature Chapter Overview
=========================

In the "Armatures" section, we will only talk about armatures themselves,
and specifically we will talk about:

- The basics of :doc:`bones &lt;/rigging/armatures/bones/index&gt;`.
- The different :doc:`armature visualizations &lt;/rigging/armatures/properties/display&gt;`.
- The armature :doc:`structure types &lt;/rigging/armatures/structure&gt;`.
- How to :doc:`Select Bones &lt;/rigging/armatures/bones/selecting&gt;`,
- How to :doc:`Edit Armatures &lt;/rigging/armatures/bones/editing/index&gt;`,
- How to :doc:`Edit Bones &lt;/rigging/armatures/bones/editing/bones&gt;`,
- How to :doc:`edit bones properties &lt;/rigging/armatures/bones/editing/properties&gt;`,
- How to sketch armatures with the :doc:`Etch-a-Ton tool &lt;/rigging/armatures/bones/editing/sketching&gt;`,
- How to use :doc:`templates &lt;/rigging/armatures/bones/editing/templating&gt;`.

####################
Bone Constraints
####################

.. toctree::
:maxdepth: 1

introduction.rst

.. _bone-constraints-inverse-kinematics:

Inverse Kinematics
==================

.. toctree::
:maxdepth: 1

inverse_kinematics/introduction.rst
inverse_kinematics/spline_ik.rst
..    TODO/Review: {{review|}}.

************
Introduction
************

.. figure:: /images/rigging_posing_constraints.png
:align: right
:figwidth: 280px

The Constraints panel in Pose Mode,
with one Limit Rotation constraint applied to the active bone.

As bones behave like objects in *Pose Mode*, they can also be constrained. This is
why the *Constraints* tab is shown in both *Object Mode* and
*Edit Mode*. This panel contains the constraints *of the active
bone* (its name is displayed at the top of the panel,
in the *To Bone:...* static text field).

Constraining bones can be used to control their degree of freedom in their pose transformations,
using e.g. the *Limit* constraints.
You can also use constraints to make a bone track another object/bone
(inside the same object, or in another armature), etc.
And the :ref:`inverse kinematics feature &lt;bone-constraints-inverse-kinematics&gt;`
is also mainly available through the *IK Solver* constraint, which is specific to bones.

For example, a human elbow cannot rotate backward (unless the character has broken his hand),
nor to the sides, and its forward and roll rotations are limited in a given range
(for example, depending on the rest position of your elbow,
it may be from (0 to 160) or from (-45 to 135).

So you should apply a *Limit Rotation* constraint to the forearm bone
(as the elbow movement is the result of rotating the forearm bone around its root).

Using bones in constraints, either as owners or as targets, is discussed in detail in the
:doc:`constraints pages &lt;/rigging/constraints/index&gt;`.

************
Introduction
************

IK simplifies the animation process,
and makes it possible to make more advanced animations with lesser effort.

IK allows you to position the last bone in a bone chain and the other bones are positioned
automatically. This is like how moving someone's finger would cause his arm to follow it.
By normal posing techniques, you would have to start from the root bone,
and set bones sequentially till you reach the tip bone: When each parent bone is moved,
its child bone would inherit its location and rotation.
Thus making tiny precise changes in poses becomes harder farther down the chain,
as you may have to adjust all the parent bones first.

This effort is effectively avoided by use of IK.

Automatic IK
============

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Options --&gt; Pose Options`

Automatic IK is a tool for quick posing, it can be enabled in the tool shelf in the 3D View,
when in pose mode. When the Auto IK option is enabled, translating a bone will activate
inverse kinematics and rotate the parent bone, and the parent’s parent, and so on, to
follow the selected bone. The IK chain can only extend from a child to a parent bone
if the child is *connected* to it.

The length of the chain is increased
(if there is a connected parent available to add to it)
with :kbd:`Ctrl-PageUp` or :kbd:`Ctrl-WheelDown`,
and decreased with :kbd:`Ctrl-PageDown` or :kbd:`Ctrl-WheelUp`.
However, the initial chain length is 0, which effectively
means follow the connections to parent bones as far as possible, with no length limit.
So pressing :kbd:`Ctrl-PageUp` the first time sets the chain length to 1 (move only the selected bone),
and pressing :kbd:`Ctrl-PageDown` at this point sets it back to 0 (unlimited) again.
Thus, you have to press :kbd:`Ctrl-PageUp` *more than once* from the initial state
to set a finite chain length greater than 1.

This is a more limited feature than using an IK constraint, which can be configured,
but it can be useful for quick posing.

IK Constraints
==============

IK is mostly done with bone constraints.
They work by the same method but offer more choices and settings.
Please refer to these pages for detail about the settings for the constraints:

- :doc:`IK Solver &lt;/rigging/constraints/tracking/ik_solver&gt;`
- :doc:`Spline IK &lt;/rigging/constraints/tracking/spline_ik&gt;`

Armature IK Panel
=================

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Properties editor --&gt; Armature --&gt; Inverse Kinematics`

This panel is used to select the IK Solver type for the armature. *Standard* or *iTaSC*.

.. figure:: /images/rigging_armatures_properties_inverse-kinematics-panel.png

The armature IK panel.

Most the time people will use the *Standard* IK solver.
There is some documentation for the *iTaSC* "instantaneous Task Specification using
Constraints" IK solver here.

.. seealso::

`Robot IK Solver &lt;https://wiki.blender.org/index.php/Dev:Source/GameEngine/RobotIKSolver&gt;`__.

Bone IK Panel
=============

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Properties editor --&gt; Bone --&gt; Inverse Kinematics`

This panel is used to control how the *Pose Bones* work in the IK chain.

.. figure:: /images/rigging_armatures_bones_properties_inverse-kinematics-panel.png

The bone IK panel.

Lock
Disallow movement around the axis.
Stiffness
Stiffness around the axis. Influence disabled if using *Lock*.
Limit
Limit movement around the axis.
Stretch
Stretch influence to IK target.

Arm Rig Example
===============

This arm uses two bones to overcome the twist problem for the forearm.
IK locking is used to stop the forearm from bending,
but the forearm can still be twisted manually by pressing :kbd:`R-Y-Y` in *Pose Mode*,
or by using other constraints.

.. figure:: /images/rigging_posing_inverse-kinematics_introduction.png
:align: center

`IK Arm Example. &lt;https://wiki.blender.org/index.php/File:IK_Arm_Example.blend&gt;`__.

Note that, if a *Pole Target* is used, IK locking will not work on the root boot.
..    TODO/Review: {{review|partial=X|text=Need example &amp; img}}.

*********
Spline IK
*********

Spline IK is a constraint which aligns a chain of bones along a curve. By leveraging the ease
and flexibility of achieving aesthetically pleasing shapes offered by curves and the
predictability and well integrated control offered by bones,
Spline IK is an invaluable tool in the riggers' toolbox.
It is particularly well suited for rigging flexible body parts such as tails, tentacles,
and spines, as well as inorganic items such as ropes.

Full description of the settings for the spline IK are detailed on the
:doc:`Spline IK &lt;/rigging/constraints/tracking/spline_ik&gt;` page.

Basic Setup
===========

The Spline IK Constraint is not strictly an 'Inverse Kinematics' method (i.e. IK Constraint),
but rather a 'Forward Kinematics' method (i.e. normal bone posing). However,
it still shares some characteristics of the IK Constraint,
such as operating on multiple bones not being usable for Objects,
and being evaluated after all other constraints have been evaluated. It should be noted that
if a Standard IK chain and a Spline IK chain both affect a bone at the same time the Standard
IK chain takes priority. Such setups are best avoided though,
since the results may be difficult to control.

To setup Spline IK,
it is necessary to have a chain of connected bones and a curve to constrain these bones to:

- With the last bone in the chain selected,
add a :doc:`Spline IK &lt;/rigging/constraints/tracking/spline_ik&gt;`
Constraint from the Bone Constraints tab in the Properties Editor.
- Set the 'Chain Length' setting to the number of bones in the chain
(starting from and including the selected bone) that should be influenced by the curve.
- Finally, set the 'Target' field to the curve that should control the curve.

Congratulations, the bone chain is now controlled by the curve.

Settings and Controls
=====================

Roll Control
------------

To control the 'twist' or 'roll' of the Spline IK chain,
the standard methods of rotating the bones in the chain along their y-axes still apply.
For example, simply rotate the bones in the chain around their y-axes to adjust the roll of
the chain from that point onwards.
Applying copy rotation constraints on the bones should also work.

Offset Controls
---------------

The entire bone chain can be made to follow the shape of the curve while still being able to
be placed at an arbitrary point in 3D-space when the 'Chain Offset' option is enabled.
By default, this option is not enabled,
and the bones will be made to follow the curve in its untransformed position.

Thickness Controls
------------------

The thickness of the bones in the chain is controlled using the constraint's 'XZ Scale Mode'
setting. This setting determines the method used for determining the scaling on the X and Z
axes of each bone in the chain.

The available modes are:

None
this option keeps the X and Z scaling factors as 1.0.
Volume Preserve
the X and Z scaling factors are taken as the inverse of the Y scaling factor (length of the bone),
maintaining the 'volume' of the bone
Bone Original
this options just uses the X and Z scaling factors the bone would have after being evaluated in the standard way.

In addition to these modes, there is an option, *Use Curve Radius*.
When this option is enabled, the average radius of the radii of the points on the curve where
the joints of each bone are placed, are used to derive X and Z scaling factors.
This allows the scaling effects, determined using the modes above,
to be tweaked as necessary for artistic control.

Tips for Nice Setups
====================

- For optimal deformations, it is recommended that the bones are roughly the same length,
and that they are not too long, to facilitate a better fit to the curve.
Also, bones should ideally be created in a way that follows the shape of the curve in its 'rest pose' shape,
to minimize the problems in areas where the curve has sharp bends
which may be especially noticeable when stretching is disabled.
- For control of the curve, it is recommended that hooks (in particular, Bone Hooks)
are used to control the control-vertices of the curve, with one hook per control-vertex.
In general, only a few control-vertices should be needed for the curve
(e.g one for every 3-5 bones offers decent control).
- The type of curve used does not really matter,
as long as a path can be extracted from it that could also be used by the Follow Path Constraint.
This really depends on the level of control required from the hooks.
- When setting up the rigs, it is currently necessary to have the control bones
(for controlling the curve) in a separate armature to those used for deforming the meshes
(i.e. the deform rig containing the Spline IK chains).
This is to avoid creating pseudo "Dependency Cycles",
since Blender's Dependency Graph can only resolve the dependencies the control bones,
curves, and Spline IK'ed bones on an object by object basis.
..    TODO/Review: {{review|im=update}}.

.. |copy-paste| image:: /images/rigging-copypastepose.png

*******
Editing
*******

.. figure:: /images/rigging-posetools.png
:align: right

Pose Tools.

In *Pose Mode*, bones behave like objects. So the transform actions
(grab/rotate/scale, etc.) are very similar to the same ones in *Object* mode
(all available ones are regrouped in the :menuselection:`Pose --&gt; Transform` sub-menu). However,
there are some important specificities:

- Bones' relationships are crucial (see :ref:`bone_relations_parenting`).
- The "transform center" of a given bone
(i.e. its default pivot point, when it is the only selected one) is *its root*.
Note by the way that some pivot point options seem to not work properly, In fact,
except for the *3D Cursor* one, all others appear to always use the median point of the selection
(and not e.g. the active bone's root when *Active Object* is selected, etc.).

Basic Posing
============

As previously noted,
bones' transformations are performed based on the *Rest Position* of the armature,
which is its state as defined in *Edit Mode*. This means that in rest position,
in *Pose Mode*, each bone has a scale of 1.0, and null rotation and position
(as you can see it in the *Transform* panel, in the 3D Views,
:kbd:`N`).

.. figure:: /images/rigging_posing_editing_local-rotation.png

An example of locally-Y-axis locked rotation, with two bones selected.
Note that the two green lines materializing the axes are centered on the armature's center,
and not each bone's root...

Moreover, the local space for these actions is the bone's own one
(visible when you enable the *Axes* option of the *Armature* panel).
This is especially important when using axis locking, for example,
there is no specific "bone roll" tool in *Pose Mode*,
as you can rotate around the bone's main axis just by locking on the local Y axis
:kbd:`R-Y-Y`... This also works with several bones selected;
each one is locked to its own local axis!

When you pose your armature,
you are supposed to have one or more objects skinned on it! And obviously,
when you transform a bone in *Pose Mode*,
its related objects or object's shape is moved/deformed accordingly, in real time.
Unfortunately, if you have a complex rig set-up and/or a heavy skin object,
this might produce lag, and make interactive editing very painful.
If you experience such troubles, try enabling the *Delay Deform* button of the
*Armature* panel the skin objects will only be updated once you validate the
transform operation.

Auto IK
=======

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Options --&gt; Pose Options`

The auto IK option in the Tool Shelf enables a temporary IK constraint when posing bones.
The chain acts from the tip of the selected bone to root of the uppermost parent bone.
Note that this mode lacks options,
and only works by applying the resulting transform to the bones in the chain.

Clear Transform
===============

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Menu:    :menuselection:`Pose --&gt; Clear Transform`
| Hotkey:   :kbd:`Alt-G`, :kbd:`Alt-R`, :kbd:`Alt-S`

Once you have transformed some bones, if you want to return to their rest position,
just clear their transformations.

Location, Rotation, Scale :kbd:`Alt-G`, :kbd:`Alt-R`, :kbd:`Alt-S`
Clears individual transforms.
All
To clear everything at once.
Reset Unkeyed
Clears the transforms to their keyframe state.
This operator is also available in the :menuselection:`Specials --&gt; Clear User Transform` menu.

Only Selected
Operate on just the selected or all bones.

Note that in *Envelope* visualization, :kbd:`Alt-S` does not clear the scale,
but rather scales the *Distance* influence area of the selected bones (also
available through the :menuselection:`Pose --&gt; Scale Envelope Distance` menu entry,
which is only effective in *Envelope* visualization, even though it is always available...).

Apply
=====

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Menu:    :menuselection:`Pose --&gt; Apply`
| Hotkey:   :kbd:`Ctrl-A`

Conversely, you may define the current pose as the new rest position (i.e.
"apply" current transformations to the *Edit Mode*),
using the :menuselection:`Pose --&gt; Apply Pose as Restpose` menu entry
(or :kbd:`Ctrl-A` and confirm the pop-up menu). When you do so,
the skinned objects/geometry is **also** reset to its default, undeformed state,
which generally means you will have to skin it again.

In-Betweens
===========

There are several tools for editing poses in an animation.

Push Pose
---------

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tool --&gt; Tool --&gt; Pose Tools --&gt; In-Betweens: Push`
| Menu:    :menuselection:`Pose --&gt; In-Betweens --&gt; Push Pose`
| Hotkey:   :kbd:`Ctrl-E`

Push pose exaggerates the current pose.

Relax Pose
----------

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tool --&gt; Pose Tools --&gt; In-Betweens: Relax`
| Menu:    :menuselection:`Pose --&gt; In-Betweens --&gt; Relax Pose`
| Hotkey:   :kbd:`Alt-E`

Relax pose is somewhat related to the above topic, but it is only useful with keyframed bones.
When you edit such a bone (and hence take it "away" from its "keyed position"),
using this tool will progressively "bring it back" to its "keyed position",
with smaller and smaller steps as it comes near it.

Breakdowner
-----------

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tool --&gt; Pose Tools --&gt; In-Betweens: Breakdowner`
| Menu:    :menuselection:`Pose --&gt; In-Betweens --&gt; Pose Breakdowner`
| Hotkey:   :kbd:`Shift-E`

Creates a suitable breakdown pose on the current frame.

There are also in *Pose Mode* a bunch of armature-specific editing options/tools,
like :ref:`auto-bones naming &lt;armature-editing-naming-bones&gt;`,
:ref:`properties switching/enabling/disabling &lt;armature-bone-properties&gt;`, etc.,
that we already described in the armature editing pages. See the links above...

Copy/Paste Pose
===============

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Header:   Copy/Paste (|copy-paste|)
| Panel:    :menuselection:`Tool Shelf --&gt; Tool --&gt; Pose Tools --&gt; Pose: Copy, Paste`
| Menu:     :menuselection:`Pose --&gt; Copy Current Pose`,
:menuselection:`Pose --&gt; Paste Pose`, :menuselection:`Pose --&gt; Paste X-Flipped Pose`

Blender allows you to copy and paste a pose, either through the *Pose* menu, or
directly using the three "copy/paste" buttons found at the right part of the 3D Views header:

Copy Current Pose
To copy the current pose of selected bones into the pose buffer.
Paste Pose
Paste the buffered pose to the currently posed armature.
Paste X-Flipped Pose
Paste the *X axis mirrored* buffered pose to the currently posed armature.

Here are important points:

- This tool works at the Blender session level, which means you can use it across armatures, scenes, and even files.
However, the pose buffer is not saved, so you lose it when you close Blender.
- There is only one pose buffer.
- Only the selected bones are taken into account during copying (i.e. you copy only selected bones' pose).
- During pasting, on the other hand, bone selection has no importance.
The copied pose is applied on a per-name basis
(i.e. if you had a ``forearm`` bone selected when you copied the pose,
the ``forearm`` bone of the current posed armature will get its pose when you paste it --
and if there is no such named bone, nothing will happen...).
- What is copied and pasted is in fact the position/rotation/scale of each bone, in its own space.
This means that the resulting pasted pose might be very different from the originally copied one, depending on:
- The rest position of the bones, and
- The current pose of their parents.

.. list-table::

* - .. figure:: /images/rigging_posing_editing_copy-paste-pose-examples-1.png

The rest position of our original armature.

- .. figure:: /images/rigging_posing_editing_copy-paste-pose-examples-2.png

The rest position of our destination armature.

.. list-table:: Examples of pose copy/paste.

* - .. figure:: /images/rigging_posing_editing_copy-paste-pose-examples-3.png

The first copied pose (note that only two bones are selected and hence copied).

- .. figure:: /images/rigging_posing_editing_copy-paste-pose-examples-4.png

...pasted on the destination armature...

- .. figure:: /images/rigging_posing_editing_copy-paste-pose-examples-5.png

...and mirror-pasted on the destination armature.

* - .. figure:: /images/rigging_posing_editing_copy-paste-pose-examples-6.png

The same pose as above is copied, but this time with all bones selected, ...

- .. figure:: /images/rigging_posing_editing_copy-paste-pose-examples-7.png

...pasted on the destination armature...

- .. figure:: /images/rigging_posing_editing_copy-paste-pose-examples-8.png

...and mirror-pasted on the destination armature.

Propagate
=========

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tool --&gt; Pose Tools --&gt; Pose: Propagate`
| Menu:     :menuselection:`Pose --&gt; Propagate`
| Hotkey:   :kbd:`Alt-P`

The Propagate tool copies the pose of the selected bones on the current frame over
to the keyframes delimited by the *Termination Mode*.
It automates the process of copying and pasting.

ToDo.

Options
-------

Termination Mode
Modes which determine how it decides when to stop overwriting keyframes.

While Held
The most complicated of the modes available, as it tries to guess when to stop propagating by
examining the pauses in the animation curves per control (i.e. all F-Curves for a bone, instead of per F-Curve).
To Next Keyframe
Simply copies the pose to the first keyframe after (but not including any keyframe on) the current frame.
To Last Keyframe
Will simply replace the last keyframe. (i.e. making action cyclic).
Before Frame
To all keyframes between current frame and the *End frame* option.
This option is best suited for use from scripts due to the difficulties in setting this frame value,
though it is possible to set this manually via the Operator panel if necessary.
Before Last Keyframe
To all keyframes from current frame until no more are found.
On Selected Keyframes
Will apply the pose of the selected bones to all selected keyframes.
On Selected Markers
To all keyframes occurring on frames with Scene Markers after the current frame.
End Frame
Defines the upper-bound for the frame range within which keyframes
will be affected (with the lower bound being the current frame).

.. _armature-bone-hide:

Show/Hide
=========

.. admonition:: Reference
:class: refbox

| Mode:     All Modes
| Panel:    :menuselection:`Properties editor --&gt; Bone --&gt; Display`
| Menu:    :menuselection:`... --&gt; Show/Hide`

You do not have to use bone layers to show/hide some bones. As with objects,
vertices or control points, you can use :kbd:`H`:

- :kbd:`H` will hide the selected bone(s).
- :kbd:`Shift-H` will hide all bones *but the selected one(s)*.
- :kbd:`Alt-H` will show all hidden bones.

You can also use the *Hide* checkbox of the
:menuselection:`Bone tab --&gt; Display panel`.

Note that hidden bones are specific to a mode,
i.e. you can hide some bones in *Edit Mode*,
they will still be visible in *Pose Mode*, and vice-versa.
Hidden bone in *Pose Mode* are also invisible in *Object Mode*.
And in *Edit Mode*, the bone to hide must be fully selected,
not just his root or tip.
.. _posing-index:

#########
Posing
#########

.. toctree::
:maxdepth: 2

introduction.rst
selecting.rst
editing.rst
bone_constraints/index.rst
..    TODO/Review: {{review|partial=X}}.

************
Introduction
************

Once an armature is :doc:`skinned &lt;/rigging/armatures/skinning/index&gt;` by the needed object(s),
you need a way to configure the armature into postionions know as poses.
Basically, by transforming the bones, you deform or transform the skinned object(s).
However, you will notice that you cannot do not this in *Edit Mode* --
remember that *Edit Mode* is used to edit the default, base, or "rest" position of an armature.
You may also notice that you cannot use *Object Mode* either, as here you can only transform whole objects.

So, armatures have a third mode dedicated to the process of posing known as *Pose Mode*.
In rest position (as edited in *Edit Mode*), each bone has its own position/rotation/scale to neutral values
(i.e. 0.0 for position and rotation, and 1.0 for scale). Hence, when you edit a bone in *Pose Mode*,
you create an offset in the transform properties, from its rest position.
This may seem quite similar if you have worked with :doc:`relative shape keys &lt;/animation/shape_keys/index&gt;`
or :ref:`Delta Transformsin &lt;transform-delta&gt;`.

Posing Section Overview
=======================

In this section, we will see:

- How to :doc:`select and edit bones &lt;/rigging/armatures/posing/editing&gt;` in this mode.
- How to :doc:`use pose library &lt;/rigging/armatures/properties/pose_library&gt;`.
- How to :doc:`use constraints &lt;/rigging/armatures/posing/bone_constraints/introduction&gt;`
to control your bones' :abbr:`DoF (degrees of freedom)`.
- How to :ref:`use inverse kinematics features &lt;bone-constraints-inverse-kinematics&gt;`.
- How to :doc:`use the Spline inverse kinematics features
&lt;/rigging/armatures/posing/bone_constraints/inverse_kinematics/spline_ik&gt;`.

Even though it might be used for completely static purposes,
posing is heavily connected with :doc:`animation features and techniques &lt;/animation/index&gt;`.

In this part, we will try to focus on animation-independent posing,
but this is not always possible. So if you know nothing about animation in Blender,
it might be a good idea to read the :doc:`animation features and techniques &lt;/animation/index&gt;`
chapter first, and then come back here.

Visualization
=============

Bone State Colors
-----------------

The color of the bones are based on their state.
There are six different color codes, ordered here by precedence
(i.e. the bone will be of the color of the bottommost valid state):

.. hue rotation based on the bone solid.

- Gray: Default.
- Blue wireframe: in Pose Mode.
- Green: with Constraint.
- Yellow: with :doc:`IK Solver constraint &lt;/rigging/constraints/tracking/ik_solver&gt;`.
- Orange: with Targetless Solver constraint.

.. note::

When :doc:`/rigging/armatures/properties/bone_groups` colors are enabled,
the state colors will be overridden.

*********
Selecting
*********

Selection in *Pose Mode* is very similar to the one in :doc:`Edit Mode &lt;/rigging/armatures/bones/selecting&gt;`,
with a few specificities:

You can only select *whole bones* in *Pose Mode*, not roots/tips...

Grouped
=======

You can select bones based on their group and/or layer, through the *Select Grouped* pop-up menu :kbd:`Shift-G`:

- To select all bones belonging to the same group(s) as the selected ones,
use the *In Same Group* entry :kbd:`Shift-G-Numpad1`.
- To select all bones belonging to the same layer(s) as the selected ones,
use the *In Same Layer* entry :kbd:`Shift-G-Numpad2`.

***********
Bone Groups
***********

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Armature tab --&gt; Motion Paths panel`
| Menu:     :menuselection:`Pose --&gt; Bone Groups --&gt; ...`

.. figure:: /images/rigging_armatures_properties_bone-groups-panel.png

The Bone Groups panel.

This panel allows the creation, deletion and editing of Bone Groups.
The panel *Bone Groups* is available in the tab *Armature* of the Properties editor.

Bone Groups can be used for selection or to assign a color theme to a set of bones.
In example to color the left parts of the rig as blue and right parts as red.

Active Bone Group
The Bone Group :ref:`List view &lt;ui-list-view&gt;`.

Color Set
------------------------

.. figure:: /images/rigging_posing_visualization_bone-color-list.png

The Bone Color Set selector and the color buttons.

You can assign a "color theme" to a group (each bone will have these colors).
Remember you have to enable the *Colors* checkbox (*Display* panel) to see these colors.

Bone Color Set
A select menu.

- *Default Colors*: The default (gray) colors.
- *nn* - *Theme Color Set*: One of the twenty Blender presets by the theme.
- *Custom Set*: A custom set of colors, which is specific to each group.

Normal
The first color button is the color of unselected bones.
Selected
The second color button is the outline color of selected bones.
Active
The third color button is the outline color of the active bone.

As soon as you alter one of the colors, it is switched to the *Custom Set* option.

Assign and Select
-----------------

In the 3D Views, using the :menuselection:`Pose --&gt; Bone Groups` menu entries,
and/or the *Bone Groups* pop-up menu :kbd:`Ctrl-G`, you can:

Assign
Assigns the selected bones to the active bone group.
It is important to note that a bone can only belong to one group.
Remove
Removes the selected bones from the active bone group.
Select
Selects the bones in the active bone group.
Deselect
Deselects the bones in the active bone group.

.. seealso::

A single bone can be assign to a group in the :ref:`Relations panel &lt;bone_relations_bone_group&gt;`.

.. seealso::

Bones belonging to multiple groups is possible with this add-on
`Selection Sets &lt;https://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts/Animation/SelectionSets&gt;`__.

*************
Display Panel
*************

.. admonition:: Reference
:class: refbox

| Mode:     Object, Edit and Pose Mode
| Panel:    :menuselection:`Object Data --&gt; Display`

.. figure:: /images/rigging_armatures_properties_display-panel.png

The Display panel.

This controls the way the bones appear in 3D View; you have four different visualizations you can select.

Bone Types
==========

We have four basic bone visualization: Octahedral, Stick, B-Bone, Envelope and Wire:

.. list-table::

* - .. figure:: /images/rigging_armatures_bones_introduction_bones-visualization-1.png
:width: 320px

Octahedral bone display.

- .. figure:: /images/rigging_armatures_bones_introduction_bones-visualization-2.png
:width: 320px

Stick bone display.

* - .. figure:: /images/rigging_armatures_bones_introduction_bones-visualization-3.png
:width: 320px

B-Bone bone display.

- .. figure:: /images/rigging_armatures_bones_introduction_bones-visualization-4.png
:width: 320px

Envelope bone display.

Octahedral bone
This is the default visualization, well suited for most of editing tasks. It materializes:

- The bone root ("big" joint) and tip ("small" joint).
- The bone "size" (its thickness is proportional to its length).
- The bone roll (as it has a square section).

.. figure:: /images/rigging_armatures_visualization_type-octahedral.png
:width: 300px

Note the 40° rolled Bone.001 bone.

Stick bone
This is the simplest and most non-intrusive visualization.
It just materializes bones by sticks of constant (and small) thickness,
so it gives you no information about root and tip, nor bone size or roll angle.

.. figure:: /images/rigging_armatures_visualization_type-stick.png
:width: 300px

Note that Bone.001 roll angle is not visible (except by its XZ axes).

B-Bone bone
This visualization shows the curves of "smooth" multi-segmented bones;
see the :doc:`/rigging/armatures/bones/properties/bendy_bones` for details.

.. list-table::

* - .. figure:: /images/rigging_armatures_bones_introduction_b-bones-1.png
:width: 320px

An armature of B-Bones, in Edit Mode.

- .. figure:: /images/rigging_armatures_bones_introduction_b-bones-3.png
:width: 320px

The same armature in Object Mode.

Envelope bone
This visualization materializes the bone deformation influence.
More on this in the :ref:`bone page &lt;armature-bone-influence&gt;`.

.. figure:: /images/rigging_armatures_bones_introduction_envelope-pose-mode.png
:width: 300px

Wire bone
This simplest visualization shows the curves of "smooth" multi-segmented bones.

.. list-table::

* - .. figure:: /images/rigging_armatures_visualization_type-wire-pose-mode.png
:width: 320px

An armature of Wire, in Pose Mode.

- .. figure:: /images/rigging_armatures_visualization_type-wire-edit-mode.png
:width: 320px

The same armature in Edit Mode.

Draw Options
============

Names
When enabled, the name of each bone is drawn.
Colors
This is only relevant for *Pose Mode*,
and is described in detail :doc:`there &lt;/rigging/armatures/properties/bone_groups&gt;`.
Axes
When enabled, the (local) axes of each bone are drawn (only relevant for *Edit Mode* and *Pose Mode*).
X-Ray
When enabled, the bones of the armature will always be drawn on top of the solid objects
(meshes, surfaces, ...) -- i.e. they will always be visible and selectable
(this is the same option as the one found in the *Display* panel of the *Object data* tab.
Very useful when not in *Wireframe* mode.
Shapes
When enabled, the default standard bone shape is replaced,
in *Object Mode* and *Pose Mode*, by the shape of a chosen object
(see :doc:`Shaped Bones &lt;/rigging/armatures/bones/properties/display&gt;` for details).
Delay Refresh
When enabled, the bone does not deform its children when manipulating the bone in pose mode.

*****
Ghost
*****

.. admonition:: Reference
:class: refbox

| Mode:     Pose Mode
| Panel:    :menuselection:`Armature tab --&gt; Ghost panel`

.. list-table::
Ghosts examples.

* - .. figure:: /images/rigging_posing_visualization_ghost-example-1.png
:width: 240px

- .. figure:: /images/rigging_posing_visualization_ghost-example-2.png
:width: 240px

In traditional cartoon creation animators use tracing paper,
to see several frames preceding the one they are working on.
This allows them to visualize the overall movement of their character,
without having to play it back.

Blender features something very similar for armatures in *Pose Mode*: the "ghosts".
The ghosts are black outlines (more or less opaque) of the bones as they are at certain frames.

Options
=======

.. figure:: /images/rigging_posing_visualization_ghost-panel.png

The Ghost panel.

The ghosts settings are found in the *Armature* tab, only active in *Pose Mode*.

Type
Around Current Frame
This will display a given number of ghosts before and after the current frame.
The ghosts are shaded from opaque at the current frame, to transparent at the most distant frames.
In Range
This will display the ghosts of the armature's bones inside a given range of frames.
The ghosts are shaded from transparent for the first frame, to opaque at the last frame. It has four options:
On Keyframes
This is very similar to the *In Range* option, but there are ghosts only for keyframes in the armature animation
(i.e. frames at which you keyed one or more of the bones).
So it has the same options as above, except for the *Step* one (as only keyframes generate ghosts).
Oddly, the shading of ghosts is reversed compared to *In Range* - from opaque for the first keyframe,
to transparent for the last keyframe.

Range
This number button specifies how many ghosts you will have on both "sides"
(i.e. a value of 5 will give you ten ghosts, five before the current frame, and five after).
Start, End
This number button specifies the start/end frame of the range (exclusive).
Note that unfortunately, it cannot take a null or negative value,
which means you can only see ghosts starting from frame 2 included...
Step
This number button specifies whether you have a ghost for every frame
(the default value of 1), or one each two frames, each three frames, etc.

Display
-------

Selected Only
When enabled, you will only see the ghosts of selected bones
(otherwise, every bone in the armatures has ghosts...)

Finally, these ghosts are also active when playing the animation :kbd:`Alt-A`
-- this is only useful with the *Around Current Frame* option, of course...

.. note::

There is no "global switch" to disable this display feature.
To do so, you have to either set *Ghost* to 0
(for *Around Current Frame* option),
or the same frame number in both *Start* and *End*
(for the two other ghosts types).

##############
Properties
##############

.. toctree::
:maxdepth: 2

introduction.rst
skeleton.rst
display.rst
bone_groups.rst
pose_library.rst
ghost.rst

************
Introduction
************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode, Edit Mode and Pose Mode
| Panel:    All in Properties editor, *Object* property

Let us first have a general overview of the various panels gathering the armature settings,
in Properties editor, *Object* tab:

.. figure:: /images/rigging_armatures_properties_properties-editor.png

The Object property in the Properties editor.

Skeleton
In this panel you can arrange sets of bones into different layers for easier manipulation.
Display
This controls the way the bones appear in 3D View.
Bone Groups
Bone Groups are meant to be used during the rig creation to define and
assign a color to a meaningful set of bones.
Pose Library
Allows you to save different properties (location, rotation, scale) for selected bones for later use.
Ghost
Allows you to see a set of different poses, very useful when animating.
Motion Paths
In the :doc:`Motion Paths panel &lt;/animation/motion_paths&gt;` you can enable visualization
of the motion path your skeleton leaves when animated.

Inverse Kinematics
==================

.. figure:: /images/rigging_armatures_properties_inverse-kinematics-panel.png

The Inverse Kinematics panel.

Defines the type of IK solver used in your animation.

Custom Properties
=================

See the :doc:`Custom Properties &lt;/data_system/custom_properties&gt;` page for more information.

******************
Pose Library Panel
******************

.. figure:: /images/rigging_posing_pose-library.png
:align: right

The Pose Library panel.

The *Pose Library* panel is used to save, apply, and manage different armature poses.
*Pose Libraries* are saved to *Actions*. They are not generally used as actions, but can be converted to and from.

Action
A :ref:`ui-data-block` for Actions or Pose Libraries.
Pose Libraries
A :ref:`ui-list-view` of poses for the active Pose Library.

Add ``+``
If a pose is added a :ref:`pose marker &lt;marker-pose-add&gt;` is created.

Add New
Adds a new pose to the active Pose Library with the current pose of the armature.
Add New (Current Frame).
Will add a pose to the Pose Library based on the current frame selected in the Time line.
In contrast to *Add New* and *Replace Existing* which automatically allocate a pose to an action frame.
Replace Existing
Replace an existing pose in the active Pose Library with the current pose of the armature.
Apply Pose (magnifying glass icon)
Apply the active pose to the selected pose bones.
Sanitize Action (livesaver icon)
Makes a action suitable for use as a Pose Library.
This is used to convert an Action to a Pose Library.
A pose is added to the Pose Library for each frame with keyframes.

.. (todo) move to pose editing

Shortcuts
=========

3D View, Pose Mode. :menuselection:`Pose --&gt; Pose Library`

- Browse Poses. :kbd:`Ctrl-L`.
- Add Pose. :kbd:`Shift-L`.
- Rename Pose. :kbd:`Shift-Ctrl-L`.
- Remove Pose. :kbd:`Alt-L`.

********
Skeleton
********

.. figure:: /images/rigging_armatures_properties_skeleton-panel.png

The Skeleton panel.

In this panel you can arrange sets of bones into different layers for easier manipulation.

Position
========

A radio button to switch between Pose Position and Rest Position.

Whereas in *Edit Mode*, you always see your armature in its rest position,
in *Object Mode* and *Pose Mode* you see it by default in its *Pose Position*
(i.e. as it was transformed in the *Pose Mode*).
If you want to see it in the rest position in all modes,
enable the *Rest Position* button in the *Armature* tab (*Edit Mode*).

.. _armature-layers:

Armature Layers
===============

.. admonition:: Reference
:class: refbox

| Mode:     Object, Edit and Pose Mode
| Panel:    :menuselection:`Object data --&gt; Skeleton`

Each armature has 32 "Armature layers" which allow you to organize your armature by
"regrouping" sets of bones into layers; this works similar to scene layers
(those containing your objects). You can then "move" a bone to a given layer,
hide or show one or several layers, etc.

Showing/hiding bone layers
--------------------------

Only bones in active layers will be visible/editable, but they will always be effective
(i.e move objects or deform geometry), whether in an active layer or not. To
(de)activate a layer, you have several options, depending in which mode you are in:

- In all modes, use the row of small buttons at the top of the *Display Options* group, *Armature* panel.
If you want to enable/disable several layers at once, as usual, hold :kbd:`Shift` while clicking...
- In *Edit Mode* and *Pose Mode*, you can also do this from the *3D View*,
either by using the menu :menuselection:`Armature --&gt; Switch Armature Layers` or
:menuselection:`Pose --&gt; Switch Armature Layers`, or the :kbd:`Shift-M` shortcut,
to display a small pop-up menu containing the same buttons as described above
(here again, you can use :kbd:`Shift-LMB` clicks to (de)select several layers at once).

Protected Layers
----------------

You can lock a given bone layer for all :ref:`proxies &lt;object-proxy&gt;`
of your armature, i.e. all bones in this layer will not be editable.
To do so, in the *Skeleton* panel, :kbd:`Ctrl-LMB` click on the relevant button, the layer lock will be enabled.

Protected layers in proxy are restored to proxy settings on file reload and undo.
.. _skinning-index:

###########
Skinning
###########

.. toctree::
:maxdepth: 2

introduction.rst
parenting.rst
..    TODO/Review: {{review|copy=X}}.

************
Introduction
************

We have seen in :doc:`previous pages &lt;/rigging/armatures/index&gt;` how to design an armature,
create chains of bones, etc.
Now, having a good rig is not the final goal, unless you want to produce a "Dance Macabre" animation,
you will likely want to put some flesh on your skeletons!
Surprisingly, "linking" an armature to the object(s)
it should transform and/or deform is called the "skinning" process...

.. figure:: /images/rigging_skinning_introduction.png

The human mesh skinned on its armature.

In Blender, you have two main skinning types:

- You can :doc:`Parent/Constrain Objects to Bones &lt;/editors/3dview/object/properties/relations/parents&gt;` - then,
when you transform the bones in *Pose Mode*, their "children" objects are also transformed,
exactly as with a standard parent/children relationship...
The "children" are **never** deformed when using this method.
- You can :doc:`Using the Armature Modifier on entire Mesh &lt;/rigging/armatures/skinning/parenting&gt;`,
and then, some parts of this object to some bones inside this armature.
This is the more complex and powerful method,
and the only way to really deform the geometry of the object,
i.e. to modify its vertices/control points relative positions.

.. hint:: Retargeting

Retargeting which is a way to apply motion-capture data (acquired from real world) to a rig is available through
add-ons and importers.

**********************
Armature Deform Parent
**********************

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Pose Mode
| Menu:     :menuselection:`Armature --&gt; Parent --&gt; Armature Deform`
| Hotkey:   :kbd:`Ctrl-P`

Armature Deform Parenting is a way of creating and setting up
an :doc:`Armature Modifier &lt;/modeling/modifiers/deform/armature&gt;`.

To use Armature Deform Parenting you must first select all the child objects that will be
influenced by the armature and then lastly, select the armature object itself. Once all the
child objects and the armature are selected press :kbd:`Ctrl-P` and select
Armature Deform in the Set Parent To pop-up menu.

The armature will be the parent object of all the other child objects and each child object
will have a Armature Modifier with the armature associated (*Object* field).

.. figure:: /images/rigging_armatures_parenting_deform-object-mode.png

Bone associated with Mesh Object.

With Empty Groups
=================

When parenting it will create empty :doc:`vertex groups &lt;/modeling/meshes/properties/vertex_groups/index&gt;`
on the child objects (if they do not already exist) for and named after each deforming bone in the armature.
The newly created vertex groups will be empty this means they will not have any weights assigned.
Vertex groups will only be created for bones which are setup as deforming
(:menuselection:`Properties Editor --&gt; Bone --&gt; Deform Panel`).

You can then manually select the vertices and assign them to a particular vertex group of your
choosing to have bones in the armature influence them.

Choose this option if you have already created (and weighted) all the vertex groups the mesh requires.

Example
-------

For example, if you have an armature which consists of three bones named "BoneA",
"BoneB" and "BoneC" and cube mesh called "Cube". If you parent the cube to
the armature the cube will get three new vertex groups created on it called "BoneA",
"BoneB" and "BoneC". Notice that each vertex group is empty.

.. figure:: /images/rigging_armatures_parenting_bone-empty-groups.png

Cube in Edit Mode using Armature Deform with empty groups.

With Automatic Weights
======================

With Automatic Weights parenting works similar to With Empty Groups, but it will not leave the vertex groups empty.
It calculates how much influence a particular bone would have on vertices
based on the distance from those vertices to a particular bone ("bone heat" algorithm).
This influence will be assigned as weights in the vertex groups.

This method of parenting is certainly easier setup but it can often lead to armatures which do not deform child
objects in ways you would want. Overlaps can occur when it comes to determining which bones should
influence certain vertices when calculating influences for more complex armatures and child objects. Symptoms
of this confusion are that when transforming the armature in *Pose Mode* parts of the child objects do not deform
as you expect; If Blender does not give you the results you require you will have to manually alter the weights
of vertices in relation to the vertex groups they belong to and have influence in.

With Envelope Weights
=====================

Works in a similar way to With Automatic Weights. The difference is that the influences are calculated
based on the :ref:`Bone Envelopes &lt;armature-bones-envelope&gt;` settings.
It will assign to each vertex groups the vertices that are inside its bone's influence volume,
weighted depending on their distance to this bone.

This means newly included/excluded vertices or new envelope settings will not be taken into account.
You will have to apply Armature Deform With Envelope Weights parenting again.

.. tip::

If want the envelope setting to be used instantly bind the Armature Modifier to *Bone Envelopes*.

.. figure:: /images/rigging_armatures_parenting_envelope-influence.png

Two sets of Armatures each with three bones.

.. warning::

If you had defined vertex groups using same names as skinned bones, their content will be
completely overridden by both Automatic and Envelope Weights.
In this case With Empty Groups could be used instead.

.. seealso::

:ref:`weight-painting-bones`.

*********
Structure
*********

.. figure:: /images/rigging_armatures_structure_armature-example.png
:align: right

Example of a very basic armature.

Armatures mimic real skeletons. They are made out of bones, which are (by default) rigid elements.
But you have more possibilities than with real skeletons: In addition to the "natural" rotation of bones,
you can also translate and even scale them! And your bones do not have to be connected to each other;
they can be completely free if you want. However,
the most natural and useful setups imply that some bones are related to others, forming so-called "chains of bones",
which create some sort of "limbs" in your armature, as detailed in `Chains of Bones`_.

.. container:: lead

.. clear

.. _armature-bone-chain:

Chains of Bones
===============

The bones inside an armature can be completely independent from each other (i.e.
the modification of one bone does not affect the others).
But this is not often a useful set up: To create a leg,
all bones "after" the thigh bone should move "with" it in a well-coordinated manner.
This is exactly what happens in armatures by parenting a bone to the next one in the limb,
you create a "chains of bones". These chains can be ramified. For example,
five fingers attached to a single "hand" bone.

.. figure:: /images/rigging_armatures_structure_chains-of-bones.png

An armature with two chains of bones.

Bones are chained by linking the tip of the parent to the root of the child.
Root and tip can be *connected*, i.e. they are always exactly at the same point;
or they can be *free*, like in a standard parent-child object relationship.

A given bone can be the parent of several children,
and hence be part of several chains at the same time.

The bone at the beginning of a chain is called its *root bone*,
and the last bone of a chain is the *tip bone*
(do not confuse them with similar names of bones' joints!).

Chains of bones are a particularly important topic in :doc:`posing &lt;/rigging/armatures/posing/index&gt;`
(especially with the standard *forward kinematics* versus "automatic" *inverse kinematics* posing techniques).
You create/edit them in *Edit Mode*, but except in case of connected bones,
their relationships have no effect on bone transformations in this mode
(i.e. transforming a parent bone will not affect its children).

The easiest way to manage bones relationships is to use the
:ref:`Relations panel &lt;bone_relations_parenting&gt;` in the *Bone* tab.
.. _constraints-index:

##############
Constraints
##############

.. toctree::
:maxdepth: 2

introduction.rst

Interface
=========

.. toctree::
:maxdepth: 1

interface/adding_removing.rst
interface/header.rst
interface/common.rst
interface/the_stack.rst

Motion Tracking
===============

.. toctree::
:maxdepth: 1

motion_tracking/camera_solver.rst
motion_tracking/object_solver.rst
motion_tracking/follow_track.rst

Transform
=========

.. toctree::
:maxdepth: 1

transform/copy_location.rst
transform/copy_rotation.rst
transform/copy_scale.rst
transform/copy_transforms.rst
transform/limit_distance.rst
transform/limit_location.rst
transform/limit_rotation.rst
transform/limit_scale.rst
transform/maintain_volume.rst
transform/transformation.rst
transform/transform_cache.rst

Tracking
========

.. toctree::
:maxdepth: 1

tracking/clamp_to.rst
tracking/damped_track.rst
tracking/ik_solver.rst
tracking/locked_track.rst
tracking/spline_ik.rst
tracking/stretch_to.rst
tracking/track_to.rst

Relationship
============

.. toctree::
:maxdepth: 1

relationship/action.rst
relationship/child_of.rst
relationship/floor.rst
relationship/follow_path.rst
relationship/pivot.rst
relationship/rigid_body_joint.rst
relationship/shrinkwrap.rst

****************************
Adding/Removing a Constraint
****************************

What is described on this page about Object Constraints can be also be applied on Bone Constraints.

Tab
===

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Menu:    :menuselection:`Properties Editor --&gt; Constraint tab`

To add a constraint click on the *Add Object Constraint* menu in the Constraints tab.

.. figure:: /images/rigging_constraints_introduction_add-menu.png

To remove a constraint click on the "X" button
in the :doc:`header &lt;/rigging/constraints/interface/header&gt;`.

Menu
====

Add Constraint (with Targets)
-----------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Pose Mode
| Menu:    :menuselection:`Object --&gt; Constraint --&gt; Add constraint (with Targets)`
| Hotkey:   :kbd:`Ctrl-Shift-C`

Adds a constraint to the active object.
The type of constraint must be chosen from a popup window,
though it can be changed later from the *Add Constraint (with Targets)* Operator panel.
If there is an other object selected besides the active one,
that object will be the constraint target (if the chosen constraint accepts targets).

When using a bone from another armature as the target for a constraint, the tool
will look inside the non-active armature and use its active bone,
provided that armature is in Pose Mode.

Copy Constraints to Selected
-----------------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Pose Mode
| Menu:    :menuselection:`Object --&gt; Constraint --&gt; Copy Constraints to Selected Objects`
| Hotkey:   none

Copies the active object Constraints to the rest of the selected objects.

Clear Constraints
-----------------------------------

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode and Pose Mode
| Panel:    :menuselection:`Object --&gt; Constraint --&gt; Clear Object Constraints`
| Hotkey:   :kbd:`Ctrl-Alt-C`

Removes all Constraints of the selected object(s).

Track
=====

.. admonition:: Reference
:class: refbox

| Mode:     Object Mode
| Panel:    :menuselection:`Object --&gt; Track`
| Hotkey:   :kbd:`Ctrl-T`

These tools add a tracking constraint :kbd:`Ctrl-T` to the selected objects;
the target object of the constraint will be the active object, which won't have a constraint added.

- :doc:`Damped Track Constraint &lt;/rigging/constraints/tracking/damped_track&gt;`
- :doc:`Track To Constraint &lt;/rigging/constraints/tracking/track_to&gt;`
- :doc:`Lock Track Constraint &lt;/rigging/constraints/tracking/locked_track&gt;`

Clear Track :kbd:`Alt-T`
Removes all Damped Track, Track To and Lock Track Constraints from the selected objects.
Clear and Keep Transformation (Clear Track) :kbd:`Alt-T`
Removes all Track Constraint from the selected objects, while keeping the final transform caused by them.
.. (todo) target: move to ui data id if proof

******
Common
******

Target
======

The Target :ref:`ui-data-id` field lets you link the constraint to a Target object of your choosing.
This link provides data to the constraint so that it can begin to function.
For example, the Copy Location Constraint needs location data to function.
Fill in the Target field, and the Copy Location constraint will begin to use location data from the Target object.

.. figure:: /images/rigging_constraints_interface_target.png

The Target field must be filled in for the constraint to function.

By default, the Target will use the :term:`Object Origin` as the target point.

If the Target field links to a :term:`Mesh` or :term:`Lattice` object, a :term:`Vertex Group` field will appear.
Enter the name of a vertex group and the constraint will target the median point
of this vertex group instead of the object center.

.. figure:: /images/rigging_constraints_interface_target-vertex-group.png

If the Target field links to an :term:`Armature`, a :term:`Bone` field will appear
along with a :term:`Head` or :term:`Tail` slider.
Enter the name of a bone and the constraint will target the bone instead of the entire armature object center.
Slide the slider and the constraint will target the head, the tail or somewhere inbetween.

.. figure:: /images/rigging_constraints_interface_target-bone.png

Space
=====

Constraints need a frame of reference in order to function.
This frame of reference is called the "space" of the constraint.
Choosing one space vs. another will change this frame of reference
and substantially alter the behavior of a constraint.

To understand how changing the space will change the behavior of the constraint,
consider experimenting with two empties.
Make sure they display as arrows so that you can see the local axes for each empty.
Make sure to size one empty a little larger than the other so that they are both always visible
even if directly on top of each other.
Then add a constraint to one empty that targets the other and experiment thoroughly by
moving, rotating and scaling the target in many different ways.

.. figure:: /images/rigging_constraints_interface_space.png

This constraint is set to use World Space as the frame of reference for both
its Target Space and its Owner Space.

Target Space &amp; Owner Space
--------------------------

The space used to evaluate the target of the constraint is called the Target Space.
The space used to evaluate the constrained object (the object that owns the constraint) is called the owner space.
Hover over the space select menu(s) to learn whether it affects the space of the target
or the space of the owner.

When the constraints use a Target and/or/nor a Owner space there will be no, one or two selector(s).
The Copy Location constraint in example use both Target **and** Owner space.

When a constraint uses both Target and Owner space,
the Target and Owner can be any combination of space types.

Space Types
-----------

World Space
In this space type the world is the frame of reference for the object (or bone).
Location is relative to the world origin.
Rotation and Scale are oriented to the world axes.
Transformations to the object, the object's parent and any other constraints
higher up in the constraint stack are all taken into account.

Local Space
In this space type the parent of the object (or bone) is the frame of reference.
Location is relative to the parent object origin.
Rotation and Scale are oriented to the parent object axes.
Only transformations to the object itself are taken into account. Transformations to the object's parent and
any other constraints higher up in the constraint stack are **not** taken into account.

Local With Parent (bones only)
The bone properties are evaluated in its own local space,
*including* the transformations due to a possible parent relationship
(i.e. due to the chain's transformations above the bone).

Pose Space (bones only)
The bone properties are evaluated in the armature object local space
(i.e. independently from the armature transformations in *Object Mode*).
Hence, if the armature object has null transformations,
*Pose Space* will have the same effect as *World Space*.

.. _rigging-constraints-influence:

Influence
=========

The influence slider determines how much the constraint will affect the constrained object (target).

.. figure:: /images/rigging_constraints_interface_influence.png

An influence of 0.0 will have no effect.
An influence of 1.0 will have the full effect.

Values between (0.0 and 1.0), will have a partial effect, but be careful. These partial effects can
be difficult to control,
especially as the :doc:`constraint stack &lt;/rigging/constraints/interface/the_stack&gt;` grows in complexity.

The influence value is animatable, allowing constraints to be turned off, or partially on as needed.

******
Header
******

Every constraint has a header.
The interface elements of the header are explained below using a Copy Location constraint as an example.

.. figure:: /images/rigging_constraints_interface_header.png

A Header sits at the top of every constraint.

Expansion Arrow (pointing down or right)
Show or Hide the settings of the constraint.
Tidy up the :doc:`constraint stack &lt;/rigging/constraints/interface/the_stack&gt;`
by hiding constraints that do not currently need attention.
Constraints will continue to affect the scene even when hidden.

"Copy Location" (first occurrence)
The type of constraint. This is determined at the time the constraint is created.

"Copy Location" (second occurrence)
Give the constraint a meaningful name in this field, something that describes its intent.
Meaningful names help you and your team members understand what each constraint is supposed to do.

The *red* background is a warning that the constraint is not yet functional.
The background will turn *gray* when the constraint is functioning.
When this Copy Location constraint has a valid target in the "Target Field"
it will turn gray and begin to function.

Eyeball (open or closed)
Enable or Disable (Mute/Unmute) the constraint. Disabling a constraint will stop its affect on the scene.

Disabling a constraint is useful for turning off a constraint without losing all of its settings.
Disabling means you can enable the constraint at a later time with the settings intact.
Disabling is similar to setting the :ref:`Influence &lt;rigging-constraints-influence&gt;` slider to 0.0.

Up/Down Arrows
Move a constraint up or down in the :doc:`constraint stack &lt;/rigging/constraints/interface/the_stack&gt;`.
Since the stack is evaluated from top to bottom,
moving a constraint in the stack can significantly affect the final outcome of the stack.

If there is only one constraint in the stack, the arrows will not be drawn.
If the constraint is at the top of the stack, only the down arrow will be drawn.
If the constraint is at the bottom of the stack, only the up arrow will be drawn.

X
Delete the constraint from the stack.
The settings will be lost.
The constraint will no longer affect the final outcome of the stack.

*********************
The Constraints Stack
*********************

The combination of all the constraints affecting an object is called the Constraints Stack.
The Stack is in the Constraints panel, below the "Add Constraint" menu.

Constraints in the stack are evaluated from top to bottom.
The order of each constraint has a substantial impact on the final outcome of the stack.
Changing the order of the constraints can change the behavior of the entire stack.

.. figure:: /images/rigging_constraints_introduction_stack.png

The seven constraints in this example stack are evaluated from top to bottom starting with the "Action" constraint
and ending with the final "Transformation" constraint.

To change the order of a constraint use the up/down arrows in the
:doc:`header &lt;/rigging/constraints/interface/header&gt;`.

************
Introduction
************

Constraints are a way to control an object's properties
(e.g. its location, rotation, scale), using either plain static values
(like the :doc:`"limit" ones &lt;/rigging/constraints/transform/limit_location&gt;`),
or (an)other object, called "target"
(like e.g. the :doc:`"copy" ones &lt;/rigging/constraints/transform/copy_location&gt;`).

Even though constraints are useful in static projects,
their main usage is obviously in animation.

- You can control an object's animation through the targets used by its constraints
(this is a form of indirect animation). Indeed,
these targets can then control the constraint's owner's properties, and hence,
animating the targets will indirectly animate the owner.
- You can animate constraints' settings. e.g. the *Influence* or
when using an armature's bone as target,
animate where along this bone (between root and tip) lays the real target point.

They can make the eyes of a tennis player track a tennis ball bouncing across the court,
allow the wheels on a bus to all rotate together,
help a dinosaur's legs bend at the knee automatically, and
make it easy for a hand to grip the hilt of a sword and the sword to swing with the hand.

Constraints, in Blender, work with :term:`Objects &lt;Object&gt;` and :term:`Bones &lt;Bone&gt;`.
Read about using constraints in rigging
in the :doc:`Armature chapter &lt;/rigging/armatures/posing/bone_constraints/index&gt;`.

.. figure:: /images/rigging_constraints_introduction_tab-object.png

Object Constraints.

.. figure:: /images/rigging_constraints_introduction_tab-bone.png

Bone Constraints.

Constraints work in combination with each other to form a Constraint Stack.

.. figure:: /images/rigging_constraints_introduction_stack.png

The Constraint Stack is evaluated from top to bottom.

Tips
====

Constraints are a fantastic way to add sophistication and complexity to a rig.

But be careful not to rush in too quickly, piling up constraint upon constraint
until you lose all sense of how they interact with each other.

Start simply. Get to know a single constraint inside and out.
:doc:`/rigging/constraints/transform/copy_location` is a good first constraint to explore it
also has an animation example. Take the time to understand every fundamental concept behind it,
and the other constraints will make far more sense.

.. TODO, the 4x4 transform matrix vs. the transform panel

Also note that constraints internally work using 4x4 transformation matrices only.
When you use settings for specific rotation or scaling constraining,
this information is being derived from the matrix only,
not from settings in a *Bone* or *Object*. Especially for combining
rotations with non-uniform or negative scaling this can lead to unpredictable behavior.

.. TODO, the blue dashed line

************************
Camera Solver Constraint
************************

The *Camera Solver* constraint gives the owner of this constraint,
the location and rotation of the "solved camera motion".

The "solved camera motion" is where Blender thinks the physical, real world camera was,
when it filmed the video footage, relative to the thing being tracked.

.. note::

This constraint only works after you have set up a minimum of eight markers and pressed
:ref:`Solve Camera Motion &lt;editors-movie-clip-tracking-clip-solve-motion&gt;`.
(:menuselection:`Movie Clip Editor --&gt; Tool Shelf --&gt; Solve --&gt; Solve Camera Motion`)

Options
=======

.. figure:: /images/rigging_constraints_motion-tracking_camera-solver.png

Camera Solver Constraint panel.

Active Clip
Receive tracking data from the movie clip active in the movie clip editor.
If unchecked, an option appears to choose from the other clips.
Constraint to F-Curve
Applies the constraint, creating Keyframes for the transforms.

***********************
Follow Track Constraint
***********************

.. figure:: /images/rigging_constraints_motion-tracking_follow-track.png

Follow Track Constraint panel.

TODO - see: https://developer.blender.org/T46926

By default Follow Track constraint is making object have the same position at frame as track has and
motion of this objects happens on a single plane defined by camera and original object position.

Active Clip
ToDo.
3D Position
ToDo.
Undistorted
ToDo.
Frame Method
ToDo.
Camera
ToDo.
Depth Object
If this object is set, constrained object would be projected onto surface of this depth object which
can be used to make faked facial makeup.
Constraint to F-Curve
ToDo.

Example
=======

.. only:: builder_html and (not singlehtml)

.. youtube:: KZalGrjGKSA

.. only:: not builder_html and (singlehtml)

A video can be found at https://www.youtube.com/watch?v=KZalGrjGKSA

************************
Object Solver Constraint
************************

The *Object Solver* constraint gives the owner of this constraint,
the location and rotation of the "solved object motion".

The "solved object motion" is where Blender thinks the physical,
real world (tracked) object was, relative to the camera that filmed it.

Can be used to add a mesh to video for example.

.. note::

This constraint only works after you have set up a minimum of eight markers and pressed
:ref:`Solve object Motion &lt;editors-movie-clip-tracking-clip-solve-motion&gt;`.
Located at :menuselection:`Movie Clip Editor --&gt; Tool Shelf --&gt; Solve --&gt; Solve Camera Motion`

If it says *Solve Camera Motion* instead of *Solve Object Motion* then go into the
:menuselection:`Movie Clip Editor --&gt; Properties region --&gt; Objects`
and switch it from the camera, to an object.

Options
=======

.. figure:: /images/rigging_constraints_motion-tracking_object-solver.png

Object Solver Constraint panel.

Active Clip
Receive tracking data from the active movie clip in the movie clip editor.
If unchecked, an option appears to choose from the other clips.
Object
Select a tracked object to receive transform data from.
Camera
Select the camera to which the motion is parented to (if active empty scene camera is used)
Set Inverse
Moves the origin of the object to the origin of the camera
Clear Inverse
Moves the origin of the object back to the spot set in the
Movie Clip Editor :menuselection:`Tool Shelf --&gt; Solve --&gt; Orientation --&gt; Set Origin`.
Constraint to F-Curve
Applies the constraint, creating keyframes for the transforms.
..    TODO/Review: {{review|text=Notes section is a mess.}}.

*****************
Action Constraint
*****************

The *Action* constraint is powerful.
It allows you control an
:doc:`Action &lt;/editors/dope_sheet/action&gt;` using the transformations of another object.

The underlying idea of the *Action* constraint is very similar to the one behind the
:doc:`Drivers &lt;/animation/drivers/index&gt;`, except that the former uses a whole action
(i.e. a bunch a F-Curves of the same type), while the latter controls a single F-curve of their "owner"...

Note that even if the constraint accepts the *Mesh* action type,
only the *Object*,
*Pose* and *Constraint* types are really working,
as constraints can only affect objects' or bones' transform properties,
and not meshes' shapes.
Also note that only the object transformation (location, rotation, scale) is affected by the action,
if the action contains keyframes for other properties they are ignored, as constraints do not influence those.

As an example, let us assume you have defined an *Object* action
(it can be assigned to any object, or even no object at all),
and have mapped it on your owner through an *Action* constraint,
so that moving the target in the (0.0 to 2.0)
range along its X-Axis maps the action content on the owner in the (0 to 100)
frame range. This will mean that when the target's *X* property is 0.0
the owner will be as if in frame 0 of the linked action;
with the target's *X* property at 1.0
the owner will be as if in frame 50 of the linked action, etc.

Options
=======

.. figure:: /images/rigging_constraints_relationship_action.png

Action panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
Bone
When target is an armature object, use this field to select the target bone.
Transform Channel
This selector controls which transform property (location,
rotation or scale along/around one of its axes) from the target to use as "action driver".
Target Space
This constraint allows you to choose in which space to evaluate its target's transform properties.
To Action
Select the name of the action you want to use.

.. warning::

Even though it might not be in red state (UI refresh problems...),
this constraint is obviously not functional when this field does not contain a valid action.

Object Action
Bones **only**, when enabled,
this option will make the constrained bone use the "object" part of the linked action,
instead of the "same-named pose" part. This allows you to apply the action of an object to a bone.

Target Range Min/Max
The lower and upper bounds of the driving transform property value.

.. warning::

Unfortunately, here again we find the constraints limitations:

- When using a rotation property as "driver",
these values are "mapped back" to the (-180.0 to 180.0) range.
- When using a scale property as "driver", these values are limited to null or positive values.

Action Range Start/End
The starting and ending frames of the action to be mapped.

.. note::

- These values must be strictly positive.
- By default, both values are set to 0 which disables the mapping (i.e.
the owner just gets the properties defined at frame 0 of the linked action...).

Notes
=====

- When the linked action affects some location properties,
the owner's existing location is added to the result of evaluating this constraint
(exactly as when the *Offset* button of the
:doc:`Copy Location constraint &lt;/rigging/constraints/transform/copy_location&gt;` is enabled...).
- When the linked action affects some scale properties,
the owner's existing scale is multiplied with the result of evaluating this constraint.
- When the linked action affects some rotation properties,
the owner's existing rotation is overridden by the result of evaluating this constraint.
- Unlike usual, you can have a *Start* value higher than the *End* one,
or a *Min* one higher than a *Max* one: this will reverse the mapping of the action
(i.e. it will be "played" reversed...), unless you have both sets reversed, obviously!
- When using a *Constraint* action,
it is the constraint *channel's names* that are used to determine to which constraints of the
owner apply the action. E.g.
if you have a constraint channel named "trackto_empt1", its keyed *Influence* and/or *Head/Tail* values
(the only ones you can key) will be mapped to the ones of the owner's constraint named "trackto_empt1".
- Similarly, when using a *Pose* action
(which is obviously only meaningful and working when constraining a bone!),
it is the bone's name that is used to determine which bone *channel's names* from the action to use (e.g.
if the constrained bone is named "arm", it will use and only use the action's bone channel named "arm"...).
Unfortunately, using a *Pose* action on a whole armature object
(to affect all the keyed bones in the action at once) will not work...
- Note also that you can use the :doc:`pose library feature &lt;/rigging/armatures/properties/pose_library&gt;` to
create/edit a *Pose* action data-block... just remember that in this situation, there is one pose per frame!

.. vimeo:: 171554048
..    TODO/Review: {{review|im=update}}.

*******************
Child Of Constraint
*******************

*Child Of* is the constraint version of the standard parent/children relationship between objects
(the one established through the :kbd:`Ctrl-P` shortcut, in the 3D Views).

Parenting with a constraint has several advantages and enhancements,
compared to the traditional method:

- You can have several different parents for the same object
(weighting their respective influence with the *Influence* slider).
- As with any constraint, you can key (i.e. animate) its Influence setting.
This allows the object which has a Child Of constraint upon it to change over time which
target object will be considered the parent, and therefore have influence over the Child Of constrained object.

.. important::

Do not confuse this "basic" object parenting with the one that defines the
:ref:`chains of bones &lt;armature-bone-chain&gt;`
inside of an armature. This constraint is used to parent an object to a
bone (the so-called :doc:`object skinning &lt;/editors/3dview/object/properties/relations/parents&gt;`),
or even bones to bones. But do not try to use it to define chains of bones.

Options
=======

.. figure:: /images/rigging_constraints_relationship_child-of.png

Child Of panel.

Target
The target object that this object will act as a child of.
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
Location X, Y, Z
Each of these buttons will make the parent affect or not affect the location along the corresponding axis.
Rotation X, Y, Z
Each of these buttons will make the parent affect or not affect the rotation around the corresponding axis.
Scale X, Y, Z
Each of these buttons will make the parent affect or not affect the scale along the corresponding axis.

Set Inverse
By default, when you parent your owner to your target, the target becomes the origin of the owner's space.
This means that the location, rotation and scale of the owner are offset by the same properties of the target.
In other words, the owner is transformed when you parent it to your target.
This might not be desired!
So, if you want to restore your owner to its before-parenting state, click on the *Set Inverse* button.
Clear Inverse
This button reverses (cancels) the effects of the above one,
restoring the owner/child to its default state regarding its target/parent.

Tips
----

When creating a new parent relationship using this constraint, it is usually necessary to
click on the *Set Inverse* button after assigning the parent. As noted above,
this cancels out any unwanted transform from the parent, so that the owner returns to the
location/rotation/scale it was in before the constraint was applied.
Note that you should apply *Set Inverse* with all other constraints disabled
(their *Influence* set to 0.0) for a particular *Child Of* constraint,
and before transforming the target/parent (see example below).

About the toggle buttons that control which target's (i.e. parent's)
individual transform properties affect the owner,
it is usually best to leave them all enabled, or to disable all three of the given Location,
Rotation or Scale transforms.

Technical Note
==============

If you use this constraint with all channels on,
it will use a straight matrix multiplication for the parent relationship,
not decomposing the parent matrix into loc/rot/size.
This ensures any transformation correctly gets applied,
also for combinations of rotated and non-uniform scaled parents.

Examples
========

.. list-table::

* - .. figure:: /images/rigging_constraints_relationship_child-of-examples-1.png

No constraint.

Note the position of Owner empty 1.0 BU along X- and Y-Axis.

- .. figure:: /images/rigging_constraints_relationship_child-of-examples-2.png

Child Of just added.

Here you can see that Owner empty is now 1.0 BU away
from Target_1 empty along X- and Y-Axis.

* - .. figure:: /images/rigging_constraints_relationship_child-of-examples-3.png

Offset set.

Set Inverse has been clicked, and Owner is back to its original position.

- .. figure:: /images/rigging_constraints_relationship_child-of-examples-4.png

Target/parent transformed.

Target_1 has been translated in the XY plane, rotated around the Z-Axis,
and scaled along its local X-Axis.

* - .. figure:: /images/rigging_constraints_relationship_child-of-examples-5.png

Offset cleared.

Clear Inverse has been clicked. Owner is fully again controlled by Target_1.

- .. figure:: /images/rigging_constraints_relationship_child-of-examples-6.png

Offset set again.

Set Offset has been clicked again.
As you can see, it does not gives the same result as in (Target/parent transformed).
As noted above, use Set Inverse only once, before transforming your target/parent.

.. vimeo:: 171554131
..    TODO/Review: {{review|im=examples}}.

****************
Floor Constraint
****************

The *Floor* constraint allows you to use its target position
(and optionally rotation) to specify a plane with a "forbidden side",
where the owner cannot go. This plane can have any orientation you like. In other words,
it creates a floor (or a ceiling,
or a wall)! Note that it is only capable of simulating entirely flat planes,
even if you use the *Vertex Group* option.
It cannot be used for uneven floors or walls.

Options
=======

.. figure:: /images/rigging_constraints_relationship_floor.png

Floor panel.

Targets
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.

Sticky
This button makes the owner immovable when touching the "floor" plane
(it cannot slide around on the surface of the plane any more).
This is fantastic for making walk and run animations!
Use Rotation
This button forces the constraint to take the target's rotation into account.
This allows you to have a "floor" plane of any orientation you like, not just the global XY, XZ and YZ ones...
Offset
This number button allows you to offset the "floor" plane from the target's center,
by the given number of Blender Units. Use it e.g.
to account for the distance from a foot bone to the surface of the foot's mesh.

Max/Min
This set of (mutually exclusive) buttons controls which plane will be the "floor".
The buttons' names correspond indeed to the *normal* to this plane (e.g. enabling Z means "XY plane", etc.)
By default, these normals are aligned with the *global* axes.
However, if you enable *Use Rotation* (see above), they will be aligned with the *local target's axes*.
As the constraint does not only define an uncrossable plane,
but also a side of it which is forbidden to the owner,
you can choose which side by enabling either the positive or negative normal axis...
e.g. by default Z, the owner is stuck in the positive Z coordinates.

Space
Standard conversion between spaces.

.. vimeo:: 171554207
..    TODO/Review: {{review|im=examples}}.

**********************
Follow Path Constraint
**********************

The *Follow Path* constraint places its owner onto a *curve* target object,
and makes it move along this curve (or path).
It can also affect its owner's rotation to follow the curve's bends,
when the *Follow Curve* option is enabled.

It could be used for complex camera traveling,
a train on his rails and most other vehicles can also use "invisible" tracks,
the links of a bicycle chain, etc.

The owner is always evaluated in the global (world) space:

- Its location (as shown in the *Transform* panel)
is used as an offset from its normal position on the path. E.g.
if you have an owner with the (1.0, 1.0, 0.0) location,
it will be one BU away from its normal position on the curve, along the X and Y axis.
Hence, if you want your owner *on* its target path, clear its location :kbd:`Alt-G`!
- This location offset is also proportionally affected by the scale of the target curve.
Taking the same (1.0, 1.0, 0.0) offset as above,
if the curve has a scale of (2.0, 1.0, 1.0),
the owner will be offset *two* BU along the X axis (and one along the Y one)...
- When the *Curve Follow* option is enabled, its rotation is also offset to the one given by the curve (i.e.
if you want the Y axis of your object to be aligned with the curve's direction,
it must be in rest, non-constrained state, aligned with the global Y axis).
Here again, clearing your owner's rotation :kbd:`Alt-R` might be useful...

The movement of the owner along the target curve/path may be controlled in two different ways:

- The most simple is to define the number of frames of the movement,
in the :ref:`Path Animation panel &lt;curve-path-animation&gt;` of the Curve tab,
via the number button Frames, and its start frame via the constraint's Offset option
(by default, start frame: 1 [= offset of 0)], duration: 100).
- The second way, much more precise and powerful,
is to define a *Evaluation Time* interpolation curve for the *Target* path
(in the *Graph Editor*). See the :doc:`Graph Editor chapter &lt;/editors/graph_editor/fcurves/index&gt;`
to learn more about F-Curves.
- If you do not want your owner to move along the path, you can give to the target curve a flat *Speed* F-Curve
(its value will control the position of the owner along the path).

*Follow Path* is another constraint that works well with the
:doc:`Locked Track one &lt;/rigging/constraints/tracking/locked_track&gt;`.
One example is a flying camera on a path. To control the camera's roll angle,
you can use a *Locked Track* and a target object to specify the up direction, as the camera flies along the path.

.. note:: *Follow Path* and *Clamp To*

Do not confuse these two constraints. Both of them constraint the location of their owner along a curve,
but *Follow Path* is an "animation-only" constraint,
inasmuch that the position of the owner along the curve is determined by the time (i.e. current frame),
whereas the :doc:`Clamp To &lt;/rigging/constraints/tracking/clamp_to&gt;` *constraint* determines the position of its
owner along the curve using one of its location properties' values.

.. note::

Note that you also need to keyframe Evaluation Time for the Path. Select the path,
go to the *Path Animation* panel in the curve properties,
set the overall frame to the first frame of the path (e.g. frame 1),
set the value of Evaluation time to the first frame of the path (e.g. 1), right click on Evaluation time,
select create keyframe, set the overall frame to the last frame of the path (e.g. frame 100),
set the value of Evaluation time to the last frame of the path (e.g. 100), right click on Evaluation time,
select create keyframe.

.. from https://overshoot.tv/node/1123
paragraph needs cleanup but this definitely needs to be in the documentation

Options
=======

.. figure:: /images/rigging_constraints_relationship_follow-path.png

Follow Path panel.

Target
:ref:`ui-data-id` used to select the constraints target, which *must* be a curve object,
and is not functional (red state) when it has none.
Animate Path
Adds a F-Curve with options for the start and end frame. ToDo: from above.
Curve Radius
Objects scale by the curve radius. See :doc:`Curve Editing &lt;/modeling/curves/properties/geometry&gt;`
Fixed Position
Object will stay locked to a single point somewhere along the length of the curve regardless of time.
Offset
The number of frames to offset from the "animation" defined by the path (by default, from frame 1).
Follow Curve
If this option is not activated, the owner's rotation is not modified by the curve; otherwise,
it is affected depending on the following options:

Forward
The axis of the object that has to be aligned with the forward direction of the path
(i.e. tangent to the curve at the owner's position).
Up
The axis of the object that has to be aligned (as much as possible) with the world Z axis.
In fact, with this option activated, the behavior of the owner shares some properties with
the one caused by a :doc:`Locked Track constraint &lt;/rigging/constraints/tracking/locked_track&gt;`,
with the path as "axle", and the world Z axis as "magnet".

.. vimeo:: 171554266
..    TODO/Review: {{review|text=This needs a complete rewrite}}.

****************
Pivot Constraint
****************

The *Pivot* constraint allows the owner to rotate around a target object.

It was originally intended for foot rigs.

Options
=======

.. figure:: /images/rigging_constraints_relationship_pivot.png

Pivot panel.

Target
:ref:`ui-data-id` for the selection of the object to be used as a pivot point.
Pivot Offset
Offset of pivot from target.
Pivot When
Always, Z Rot, Y Rot...

Example
=======

.. vimeo:: 171554353
.. TODO/Review: {{review|text=Complete rewrite needed. Unclear and Child object field not explained what it does}}.

***************************
Rigid Body Joint Constraint
***************************

The *Rigid Body Joint* constraint is very special, it is used by the
physics part of the Blender Game Engine to simulate a joint between its owner and its target.
It offers four joint types: hinge type, ball-and-socket type, cone-twist, and generic six-DoF
(degrees of freedom) type.

.. important::

This constraint only works with the :doc:`Game Engine &lt;/game_engine/index&gt;`.

The joint point and axes are defined and fixed relative to the owner.
The target moves as if it were stuck to the center point of a stick,
the other end of the stick rotating around the joint/pivot point...

This constraint is of no use in most "standard" static or animated projects. However,
you can use its results outside of the BGE, through the :menuselection:`Game --&gt; Record Animation`.
see :doc:`Rigid Bodies &lt;/game_engine/physics/usage&gt;` for more info on this topic).

For a demo file that shows some of the different types, see: `BGE-Physics-RigidBodyJoints.blend
&lt;https://wiki.blender.org/index.php/Media:BGE-Physics-RigidBodyJoints.blend&gt;`__.

.. note::

In order for this constraint to work properly, both objects
(so the owner and the target object) need to have *Collision Bounds* enabled.

Options
=======

.. figure:: /images/rigging_constraints_relationship_rigid-body-joint.png

Rigid Body Joint panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.

Joint Type
Ball
works like an ideal ball-and-socket joint, i.e. allows rotations around all axes like a shoulder joint.
Hinge
works in one plane, like an elbow: the owner and target can only rotate around the X axis of the pivot
(joint point).

Limits
Angular limits for the X axis
Cone Twist
similar to *Ball*, this is a point-to-point joint with limits added for the cone and twist axis

Limits
Angular limits
Generic 6DOF
works like the *Ball* option,
but the target is no longer constrained at a fixed distance from the pivot point, by default
(hence the six degrees of freedom: rotation and translation around/along the three axes).
In fact, there is no longer a joint by default, with this option,
but it enables additional settings which allow you to restrict some of these DoF:

Limits
Linear and angular limits for a given axis (of the pivot) in Blender Units and degrees respectively.

Child Object
normally, leave this blank. You can reset it to blank by right clicking and selecting Reset to Default Value.

.. Is this right? 2.4 just had a 'to object'. Now we have a 'target' and a 'child object'.
These are not documented. It seems that we recreate the behavior of 2.4 by leaving the child object blank.
The target seems to be the 2.4 'to object'. What is the child object? Please explain!

Linked Collision
When enabled, this will disable the collision detection between the owner and the target
(in the physical engine of the BGE).

Display Pivot
When enabled, this will draw the pivot of the joint in the 3D Views.
Most useful, especially with the *Generic 6DOF* joint type!

Pivot
These three numeric fields allow you to relocate the pivot point, *in the owner's space*.
Axis
These three numeric fields allow you to rotate the pivot point, *in the owner's space*.
..    TODO/Review: {{review|im=examples}}.

*********************
Shrinkwrap Constraint
*********************

The *Shrinkwrap* constraint is the "object counterpart" of the
:doc:`Shrinkwrap Modifier &lt;/modeling/modifiers/deform/shrinkwrap&gt;`.
It moves the owner origin and therefore the owner object's location to the surface of its target.

This implies that the target *must* have a surface. In fact,
the constraint is even more selective, as it can only use meshes as targets. Hence,
the *Shrinkwrap* option is only shown in the *Add Constraint to Active Object* menu,
:kbd:`Ctrl-Alt-C`, (or its bone's equivalent),
when the selected inactive object is a mesh.

Options
=======

.. figure:: /images/rigging_constraints_relationship_shrinkwrap.png

Shrinkwrap panel.

Target
:ref:`ui-data-id` used to select the constraints target, which *must* be a mesh object,
and is not functional (red state) when it has none.
Distance
This number button controls the offset of the owner from the shrunk computed position on the target's surface.
Positive values place the owner "outside" of the target, and negative ones, "inside" the target.
This offset is applied along the straight line defined by the original (i.e.
before constraint) position of the owner, and the computed one on the target's surface.

Shrinkwrap Type
---------------

This selector allows you to select which method to use to compute the point on the
target's surface to which to translate the owner's center. You have three options:

Nearest Surface Point
^^^^^^^^^^^^^^^^^^^^^

The chosen target's surface's point will be the nearest one to the original owner's location.
This is the default and most commonly useful option.

Projection
^^^^^^^^^^

The target's surface point is determined by projecting the owner's center along a given axis.

Projection Axis
This axis is controlled by the radio buttons that show up when you select this type.
This mean the projection axis can only be aligned with one of the global axes,
median to both of them (XY, XZ or YZ), or to the three ones (XYZ).
When the projection of the owner's center along the selected direction does not hit the target's surface,
the owner's location is left unchanged.

+X, +Y, +Z, -X, -Y, -Z
Axis Space
ToDo.
Projection Distance
ToDo.

Nearest Vertex
^^^^^^^^^^^^^^

This method is very similar to the *Nearest Surface Point* one,
except that the owner's possible shrink locations are limited to the target's vertices.

.. vimeo:: 171554427
..    TODO/Review: {{review|im=examples}}.

*******************
Clamp To Constraint
*******************

The *Clamp To* constraint clamps an object to a curve. The *Clamp To* constraint is very similar
to the :doc:`Follow Path &lt;/rigging/constraints/relationship/follow_path&gt;` constraint,
but instead of using the evaluation time of the target curve, *Clamp To*
will get the actual location properties of its owner
(those shown in the *Transform* panel),
and judge where to put it by "mapping" this location along the target curve.

One benefit is that when you are working with *Clamp To*,
it is easier to see what your owner will be doing; since you are working in the 3D View, it
will just be a lot more precise than sliding keys around on a F-Curve and playing the
animation over and over.

A downside is that unlike in the :doc:`Follow Path constraint &lt;/rigging/constraints/relationship/follow_path&gt;`,
*Clamp To* does not have any option to track your owner's rotation (pitch, roll, yaw)
to the banking of the targeted curve, but you do not always need rotation on,
so in cases like this it's usually a lot handier to fire up a *Clamp To*,
and get the bits of rotation you do need some other way.

The mapping from the object's original position to its position on the curve is not perfect,
but uses the following simplified algorithm:

.. Note, this may not be 100% accurate

- A "main axis" is chosen, either by the user, or as the longest axis of the curve's bounding box (the default).
- The position of the object is compared to the bounding box of the curve in the direction of the main axis.
So for example if X is the main axis, and the object is aligned with the curve bounding box's left side,
the result is 0; if it is aligned with the right side, the result is 1.
- If the cyclic option is unchecked, this value is clamped in the range 0-1.
- This number is used as the curve time, to find the final position along the curve that the object is clamped to.

This algorithm does not produce exactly the desired result because curve time does not map
exactly to the main axis position. For example an object directly in the center of a curve
will be clamped to a curve time of 0.5 regardless of the shape of the curve,
because it is halfway along the curve's bounding box.
However, the 0.5 curve time position can actually be anywhere within the bounding box!

Options
=======

.. figure:: /images/rigging_constraints_tracking_clamp-to.png

Clamp To panel.

Target
The Target: field indicates which curve object the Clamp To constraint will track along.
The Target: field must be a curve object type. If this :ref:`ui-data-id` field is not filled in
then it will be highlighted in red indicating that this constraint does not have all the information
it needs to carry out its task and will therefore be ignored on the constraint stack.

Main Axis
This button group controls which global axis (X, Y or Z) is the main direction of the path.
When clamping the object to the target curve, it will not be moved significantly on this axis.
It may move a small amount on that axis because of the inexact way this constraint functions.

For example if you are animating a rocket launch,
it will be the Z axis because the main direction of the launch path is up.
The default *Auto* option chooses the axis which the curve is longest in (or X if they are equal).
This is usually the best option.

Cyclic
By default, once the object has reached one end of its target curve, it will be constrained there.
When the *Cyclic* option is enabled, as soon as it reaches one end of the curve,
it is instantaneously moved to its other end.
This is of course primarily designed for closed curves (circles &amp; co),
as this allows your owner to go around it over and over.

.. vimeo:: 171276763
..    TODO/Review: {{review|im=examples}}.

***********************
Damped Track Constraint
***********************

The *Damped Track* constraint constrains one local axis of the owner to always point towards *Target*.
In other 3D software you can find it with the name "Look at" constraint.

Options
=======

.. figure:: /images/rigging_constraints_tracking_damped-track.png

Damped Track panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
To
Once the owner object has had a Damped Track constraint applied to it,
you must then choose which axis of the object you want to point at the Target object.
You can choose between 6 axis directions (-X, -Y, -Z, X, Y, Z).
The negative axis direction cause the object to point away from the Target object along the
selected axis direction.

.. vimeo:: 171278084
..    TODO/Review: {{review|}}.

********************
IK Solver Constraint
********************

The *Inverse Kinematics* constraint implements the *inverse kinematics* armature
posing technique. Hence, it is only available for bones.
To quickly create an IK constraint with a target, select a bone in pose mode,
and press :kbd:`Shift-I`.

This constraint is fully documented in the
:ref:`Inverse Kinematics &lt;bone-constraints-inverse-kinematics&gt;` page, part of the rigging chapter.

Options
=======

.. figure:: /images/rigging_constraints_tracking_ik-solver.png

Inverse Kinematics panel.

Target
:ref:`ui-data-id` used to select the an armature.
Pole Target
Object for pole rotation.
Iterations
Maximum number of solving iterations.
Chain Length
How many bones are included in the IK effect. Set to 0 to include all bones.

Use Tail
Include bone's tail as last element in chain.
Stretch
Enable IK stretching.
Weight
Position
For Tree-IK: Weight of position control for this target.
Rotation
Chain follow rotation of target.
Target
Disable for targetless IK.
Rotation
Chain follows rotation of target.

.. vimeo:: 171279647
..    TODO/Review: {{review|im=examples}}.

***********************
Locked Track Constraint
***********************

The *Locked Track* constraint is a bit tricky to explain, both graphically and textually.
Basically, it is a :doc:`Track To constraint &lt;/rigging/constraints/tracking/track_to&gt;`, but with a locked axis, i.e.
an axis that cannot rotate (change its orientation). Hence,
the owner can only track its target by rotating around this axis,
and unless the target is in the plane perpendicular to the locked axis, and crossing the owner,
this owner cannot really point at its target.

Let us take the best real world equivalent: a compass.
It can rotate to point in the general direction of its target (the magnetic North,
or a neighbor magnet), but it cannot point *directly at it*,
because it spins like a wheel on an axle.
If a compass is sitting on a table and there is a magnet directly above it,
the compass cannot point to it. If we move the magnet more to one side of the compass,
it still cannot point *at* the target,
but it can point in the general direction of the target,
and still obey its restrictions of the axle.

When using a *Locked Track* constraint, you can think of the target as a magnet,
and the owner as a compass.
The *Lock* axis will function as the axle around which the owner spins,
and the *To* axis will function as the compass' needle.
Which axis does what is up to you!

If you have trouble understanding the buttons of this constraint, read the tool-tips,
they are pretty good. If you do not know where your object's axes are,
turn on the *Axis* button in the *Object* menu's *Draw* panel.
Or, if you are working with bones, turn on the *Axes* button in the
*Armature* menu's *Display* panel.

This constraint was designed to work cooperatively with the *Track To* constraint.
If you set the axes buttons right for these two constraints,
*Track To* can be used to point the axle at a primary target,
and *Locked Track* can spin the owner around that axle to a secondary target.

This constraints also works very well for 2D billboarding.

Options
=======

.. figure:: /images/rigging_constraints_tracking_locked-track.png

Locked track panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
To
The tracking local axis, i.e. the owner's axis to point at the target.
The negative options force the relevant axis to point away from the target.
Lock
The locked local axis, i.e. the owner's axis which cannot be re-oriented to track the target.

.. important::

If you choose the same axis for *To* and *Lock*, the constraint will no
longer be functional (red state).

.. vimeo:: 171280773
..    TODO/Review: {{review|im= examples}}.

********************
Spline IK Constraint
********************

The *Spline IK* constraint aligns a chain of bones along a curve. By leveraging the
ease and flexibility of achieving aesthetically pleasing shapes offered by curves and the
predictability and well-integrated control offered by bones,
*Spline IK* is an invaluable tool in the riggers' toolbox.
It is particularly well suited for rigging flexible body parts such as tails, tentacles,
and spines, as well as inorganic items such as ropes.

To set up *Spline IK*,
it is necessary to have a chain of connected bones and a curve to constrain these bones to:

- With the last bone in the chain selected,
add a *Spline IK* constraint from the *Bone Constraints* tab in the *Properties Editor*.
- Set the 'Chain Length' setting to the number of bones in the chain (starting from and including the selected bone)
that should be influenced by the curve.
- Finally, set *Target* to the curve that should control the curve.

Options
=======

.. figure:: /images/rigging_constraints_tracking_spline-ik.png

Spline IK panel.

Target
:ref:`ui-data-id` used to select the target curve.

Spline Fitting
--------------

Chain Length
How many bones are included in the chain.
Even Division
Ignore the relative length of the bones when fitting to the curve.
Chain Offset
Offset the entire chain relative to the root joint.

Chain Scaling
-------------

Y Stretch
Stretch the Y axis of the bones to fit the curve.
Use Curve Radius
Average radius of the endpoints is used to tweak the X and Z scaling of the bones,
on top of the X and Z scale mode.
XZ Scale Mode
Scaling that a bone undergoes to reach its target.

None
Do not scale the X and X axes.
Bone Original
Use the original scaling of the bones.
Inverse Scale
Scale of the X and Z axes is the inverse of the Y scale.
Volume Preservation
Similar to the :ref:`Stretch to &lt;constraints-stretch-to-volume-preservation&gt;` constraint.

.. seealso::

This subject is seen in depth in the
:doc:`Armature Posing section &lt;/rigging/armatures/posing/bone_constraints/inverse_kinematics/spline_ik&gt;`.

.. vimeo:: 171282278
..    TODO/Review: {{review|im=examples}}.

*********************
Stretch To Constraint
*********************

The *Stretch To* constraint causes its owner to rotate and scale its Y axis towards its target.
So it has the same tracking behavior as the :doc:`Track To constraint &lt;/rigging/constraints/tracking/track_to&gt;`.
However, it assumes that the Y axis will be the tracking and stretching axis,
and does not give you the option of using a different one.

It also optionally has some raw volumetric features,
so the owner can squash down as the target moves closer,
or thin out as the target moves farther away.
Note however, that it is not the real volume of the owner which is thus preserved,
but rather the virtual one defined by its scale values. Hence,
this feature works even with non-volumetric objects, like empties, 2D meshes or surfaces,
and curves.

With bones, the "volumetric" variation scales them along their own local axes
(remember that the local Y axis of a bone is aligned with it, from root to tip).

Options
=======

.. figure:: /images/rigging_constraints_tracking_stretch-to.png

Stretch To panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
Rest Length
This number button sets the rest distance between the owner and its target, i.e.
the distance at which there is no deformation (stretching) of the owner.

Reset
When clicked, this small button will recalculate the *Rest Length* value,
so that it corresponds to the actual distance between the owner and its target (i.e.
the distance before this constraint is applied).

.. _constraints-stretch-to-volume-preservation:

Volume Variation
This number button controls the amount of "volume" variation exponentially to the stretching amount.
Note that the 0.0 value is not allowed, if you want to disable the volume feature,
use the *None* button (see below).
Volume Min/Max
Limits for the volume preservation to a minimum and maximum scaling each by a *Bulge* factor.
Smooth
Smoothness factor to make limits less visible.
Volume
These buttons control which of the X and/or Z axes should be affected (scaled up/down)
to preserve the virtual volume while stretching along the Y axis.
If you enable the *none* button, the volumetric features are disabled.
Plane
These buttons are equivalent to the *Up* ones of the
:doc:`Track To constraint &lt;/rigging/constraints/tracking/track_to&gt;`:
they control which of the X or Z axes should be maintained (as much as possible) aligned with the global Z axis,
while tracking the target with the Y axis.

.. vimeo:: 171283118

*******************
Track To Constraint
*******************

The *Track To* constraint applies rotations to its owner,
so that it always points a given "To" axis towards its target,
with another "Up" axis permanently maintained as much aligned with the global Z axis
(by default) as possible. This tracking is similar to the "billboard tracking" in 3D
(see note below).

This is the preferred tracking constraint,
as it has a more easily controlled constraining mechanism.

This constraint shares a close relationship to the
:doc:`Inverse Kinematics constraint &lt;/rigging/constraints/tracking/ik_solver&gt;` in some ways.

.. tip:: Billboard tracking

The term "billboard" has a specific meaning in real-time CG programming (i.e. video games!),
where it is used for plane objects always facing the camera (they are indeed "trackers",
the camera being their "target"). Their main usage is as support for tree or mist textures:
if they were not permanently facing the camera, you would often see your trees squeezing to nothing,
or your mist turning into a millefeuille paste, which would be funny but not so credible.

Options
=======

.. figure:: /images/rigging_constraints_tracking_track-to.png

Track To panel.

Targets
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
To
The tracking local axis, i.e. the owner's axis to point at the target.
The negative options force the relevant axis to point away from the target.
Up
The "upward-most" local axis, i.e. the owner's axis to be aligned (as much as possible)
with the global Z axis (or target Z axis, when the *Target* button is enabled).
Target Z
By default, the owner's *Up* axis is (as much as possible) aligned with the global Z axis,
during the tracking rotations. When this button is enabled, the *Up* axis will be (as much as possible)
aligned with the target's local Z axis?
Space
Standard conversion between spaces.

.. warning::

If you choose the same axis for *To* and *Up*, the constraint will not be functional anymore (red state).

.. vimeo:: 171283522

************************
Copy Location Constraint
************************

The *Copy Location* constraint forces its owner to have the same location as its target.

.. important::

Note that if you use such a constraint on a *connected* bone, it will have
no effect, as it is the parent's tip which controls the position of your
owner bone's root.

Options
=======

.. figure:: /images/rigging_constraints_transform_copy-location.png

Copy Location panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.

X, Y, Z
These buttons control which axes are constrained.

Invert
The *Invert* buttons invert their respective preceding coordinates.

Offset
When enabled, this control allows the owner to be translated (using its current transform properties),
relative to its target's position.

Space
Standard conversion between spaces.

Examples
========

.. vimeo:: 170198049

Animation
---------

Let us animate the *Copy Location* constraint and its *Offset* button. For example,
you can make your owner (let us call it "moon") describe perfect circles centered on the (0.0, 0.0, 0.0)
point (using e.g. pydriven *LocX*/*LocY* animation curves, see :doc:`Drivers &lt;/animation/drivers/index&gt;`),
and then make it copy the location of a target (called it "earth", for example) with the *Offset* button enabled.
Congratulation, you just modeled a satellite in a (simplified) orbit around its planet.
Just do the same thing with its planet around its star (which you might call "sun", what do you think?),
and why not, for the star around its galaxy.

Here is a small animation of a "solar" system created using (among a few others)
the technique described above:

.. vimeo:: 15187945

Note that this "solar" system is not realistic at all (the wrong scale,
the "earth" is rotating in the wrong direction around the "sun", ...).

You can download the blend-file
(`download here &lt;https://wiki.blender.org/index.php/File:ManAnimationTechsUsingConstraintsExSolarSys.blend&gt;`__)
used to create this animation.

Furthermore you can also animate a few properties of each constraint using animation curves:
e.g you can animate the *Influence* of a constraint.
It is used to first stick the camera to the "moon", then to the "earth",
and finally to nothing, using two *Copy Location* constraints with *Offset* set.

************************
Copy Rotation Constraint
************************

The *Copy Rotation* constraint forces its owner to match the rotation of its target.

Options
=======

.. figure:: /images/rigging_constraints_transform_copy-rotation.png

Copy Rotation panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.

X, Y, Z
These buttons control which axes are constrained.

Invert
The *Invert* buttons invert their respective rotation values.

Offset
When enabled, this control allows the owner to be rotated (using its current transform properties),
relative to its target's orientation.

Space
Standard conversion between spaces.

.. vimeo:: 171073854

*********************
Copy Scale Constraint
*********************

The *Copy Scale* constraint forces its owner to have the same scale as its target.

.. note::

Here we talk of *scale*, not of *size*! Indeed, you can have two
objects, one much bigger than the other, and yet both of them have the same
scale. This is also true with bones: in *Pose Mode*, they all
have a unitary scale when they are in rest position, represented by their
visible length.

Options
=======

.. figure:: /images/rigging_constraints_transform_copy-scale.png

Copy Scale panel.

Target
:ref:`ui-data-id` used to select the constraints target,
and is not functional (red state) when it has none.

X, Y, Z
These buttons control along which axes the scale is constrained.

Offset
When enabled, this control allows the owner to be scaled (using its current transform properties),
relatively to its target's scale.

Space
Standard conversion between spaces.

.. vimeo:: 171077617

**************************
Copy Transforms Constraint
**************************

The *Copy Transforms* constraint forces its owner to have the same transforms as its target.

Options
=======

.. figure:: /images/rigging_constraints_transform_copy-transforms.png

Copy Transforms panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
Space
Standard conversion between spaces.

.. vimeo:: 171108888

*************************
Limit Distance Constraint
*************************

The *Limit Distance* constraint forces its owner to stay either further from,
nearer to, or exactly at a given distance from its target. In other words,
the owner's location is constrained either outside, inside,
or at the surface of a sphere centered on its target.

When you specify a (new) target, the *Distance* value is automatically set to
correspond to the distance between the owner and this target.

.. important::

Note that if you use such a constraint on a *connected* bone, it will have
no effect, as it is the parent's tip which controls the position of your
owner bone's root.

Options
=======

.. figure:: /images/rigging_constraints_transform_limit-distance.png

Limit Distance panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
Distance
This number button sets the limit distance, i.e. the radius of the constraining sphere.
Reset Distance
When clicked, this small button will reset the *Distance* value,
so that it corresponds to the actual distance between the owner and its target
(i.e. the distance before this constraint is applied).

Clamp Region
The *Limit Mode* select menu allows you to choose how to use the sphere
defined by the *Distance* setting and target's center:

Inside
The owner is constrained *inside* the sphere.
Outside
The owner is constrained *outside* the sphere.
Surface
The owner is constrained *on the surface* of the sphere.

For Transform
ToDo.

.. vimeo:: 171109014

*************************
Limit Location Constraint
*************************

An object or *unconnected* bone can be moved around the scene along the X, Y and Z axes.
This constraint restricts the amount of allowed translations along each axis,
through lower and upper bounds.

The limits for an object are calculated from its center, and the limits of a bone,
from its root.

It is interesting to note that even though the constraint limits the visual and rendered
location of its owner, its owner's data-block still allows (by default)
the object or bone to have coordinates outside the minimum and maximum ranges.
This can be seen in its *Transform* panel.

When an owner is grabbed and attempted to be moved outside the limit boundaries,
it will be constrained to those boundaries visually and when rendered, but internally,
its coordinates will still be changed beyond the limits. If the constraint is removed,
its ex-owner will seem to jump to its internally specified location.

Similarly, if its owner has an internal location that is beyond the limits, dragging it back
into the limit area will appear to do nothing until the internal coordinates are back within
the limit threshold (unless you enabled the *For Transform* option, see below).

Setting equal the min and max values of an axis,
locks the owner's movement along that axis... Although this is possible,
using the *Transformation Properties* axis locking feature is probably easier!

Options
=======

.. figure:: /images/rigging_constraints_transform_limit-location.png

Limit Location panel.

Minimum X, Minimum Y, Minimum Z
These buttons enable the lower boundary for the location of the owner's center along,
respectively, the X, Y and Z axes of the chosen *Space*.
The number button below them controls the value of their limit.
Note that if a min value is higher than its corresponding max value,
the constraint behaves as if it had the same value as the max one.

Maximum X, Maximum Y, Maximum Z
These buttons enable the upper boundary for the location of the owner's center along,
respectively, the X, Y and Z axes of the chosen *Space*.
Same options as above.

For Transform
We saw that by default, even though visually constrained,
the owner can still have coordinates out of bounds (as shown by the *Transform* panel).
Well, when you enable this button, this is no longer possible --
the owner's transform properties are also limited by the constraint.
Note however, that the constraint does not directly modify the coordinates: you have to grab
its owner one way or another for this to take effect...

Convert
This constraint allows you to choose in which space to evaluate its owner's transform properties.

.. vimeo:: 171115770

*************************
Limit Rotation Constraint
*************************

An object or bone can be rotated around the X, Y and Z axes.
This constraint restricts the amount of allowed rotations around each axis,
through lower and upper bounds.

It is interesting to note that even though the constraint limits the visual and rendered
rotations of its owner, its owner's data-block still allows (by default)
the object or bone to have rotation values outside the minimum and maximum ranges.
This can be seen in the *Transform* panel.
When an owner is rotated and attempted to be rotated outside the limit boundaries,
it will be constrained to those boundaries visually and when rendered, but internally,
its rotation values will still be changed beyond the limits. If the constraint is removed,
its ex-owner will seem to jump to its internally specified rotation.

Similarly, if its owner has an internal rotation that is beyond the limit, rotating it back
into the limit area will appear to do nothing until the internal rotation values are back
within the limit threshold (unless you enabled the *For Transform* option, see below).

Setting equal the min and max values of an axis,
locks the owner's rotation around that axis... Although this is possible,
using the *Transformation Properties* axis locking feature is probably easier.

This transform does not constrain the bone if it is manipulated by the IK solver.
For constraining the rotation of a bone for IK purposes,
see the "Inverse Kinematics" section of Bone properties.

Options
=======

.. figure:: /images/rigging_constraints_transform_limit-rotation.png

Limit Rotation panel.

Limit X, Y, Z
These buttons enable the rotation limit around respectively the X, Y and Z axes of the owner,
in the chosen *Space*.
The *Min* and *Max* numeric fields to their right control the value of their lower and upper
boundaries, respectively.

Note that:

- If a min value is higher than its corresponding max value,
the constraint behaves as if it had the same value as the max one.
- Unlike the :doc:`Limit Location constraint &lt;/rigging/constraints/transform/limit_location&gt;`,
you cannot enable separately lower or upper limits...

For Transform
We saw that by default, even though visually constrained, the owner can still have rotations out of bounds
(as shown by the *Transform* panel).
Well, when you enable this button, this is no more possible --
the owner transform properties are also limited by the constraint.
Note however, that the constraint does not directly modifies the rotation values:
you have to rotate one way or the other its owner, for this to take effect...

Convert
This constraint allows you to chose in which space evaluate its owner's transform properties.

.. vimeo:: 171115852

**********************
Limit Scale Constraint
**********************

An object or bone can be scaled along the X, Y and Z axes.
This constraint restricts the amount of allowed scalings along each axis,
through lower and upper bounds.

.. important::

This constraint does not tolerate negative scale values (those you might
use to mirror an object...): when you add it to an object or bone, even if
no axis limit is enabled, nor the *For Transform* button, as soon
as you scale your object, all negative scale values are instantaneously
inverted to positive ones... And the boundary settings can only take
strictly positive values.

It is interesting to note that even though the constraint limits the visual and rendered scale
of its owner, its owner's data-block still allows (by default)
the object or bone to have scale values outside the minimum and maximum ranges
(as long as they remain positive!).
This can be seen in its *Transform* panel.
When an owner is scaled and attempted to be moved outside the limit boundaries,
it will be constrained to those boundaries visually and when rendered, but internally,
its coordinates will still be changed beyond the limits. If the constraint is removed,
its ex-owner will seem to jump to its internally-specified scale.

Similarly, if its owner has an internal scale that is beyond the limits, scaling it back into
the limit area will appear to do nothing until the internal scale values are back within the
limit threshold (unless you enabled the *For Transform* option,
see below, or your owner has some negative scale values).

Setting equal the min and max values of an axis locks the owner's scaling along that axis.
Although this is possible,
using the *Transformation Properties* axis locking feature is probably easier.

Options
=======

.. figure:: /images/rigging_constraints_transform_limit-scale.png

Limit Scale panel.

Minimum/Maximum X, Y, Z
These buttons enable the lower boundary for the scale of the owner along respectively the X,
Y and Z axes of the chosen *Space*.
The *Min* and *Max* numeric fields to their right control the value of their lower and upper
boundaries, respectively.

.. note::

If a min value is higher than its corresponding max value,
the constraint behaves as if it had the same value as the max one.

For Transform
We saw that by default, even though visually constrained, and except for the negative values,
the owner can still have scales out of bounds (as shown by the *Transform* panel).
Well, when you enable this button, this is no longer possible,
the owner transform properties are also limited by the constraint.
Note however, that the constraint does not directly modify the scale values:
you have to scale its owner one way or another for this to take effect.
Convert
This constraint allows you to choose in which space to evaluate its owner's transform properties.

.. vimeo:: 171275278

**************************
Maintain Volume Constraint
**************************

The *Maintain Volume* constraint limits the volume of a mesh or a bone to a given
ratio of its original volume.

Options
=======

.. figure:: /images/rigging_constraints_transform_maintain-volume.png

Maintain Volume Constraint.

Free
The free-scaling axis of the object.

X, Y, Z
Volume
The bone's rest volume.
Space
This constraint allows you to choose in which space to evaluate its owner's transform properties.

.. seealso::

`Harkyman on the development of the Maintain Volume constraint
&lt;http://www.harkyman.com/2010/03/16/maintaining-bone-volume-a-new-constraint/&gt;`__.

.. vimeo:: 171275315
..    TODO/Review: {{review|im=examples}}.

*************************
Transformation Constraint
*************************

This constraint is more complex and versatile than the other "transform" constraints.
It allows you to map one type of transform properties (i.e. location, rotation or scale)
of the target, to the same or another type of transform properties of the owner,
within a given range of values (which might be different for each target and owner property).
You can also switch between axes, and use the range values not as limits,
but rather as "markers" to define a mapping between input (target) and output (owner) values.

So, e.g. you can use the position of the target along the X axis to control the rotation of
the owner around the Z-Axis, stating that 1 BU along the target X-Axis corresponds
to10 BU around the owner Z-Axis. Typical uses for this include gears (see note below),
and rotation based on location setups.

Options
=======

.. figure:: /images/rigging_constraints_transform_transformation.png

Transformation panel.

Target
:ref:`ui-data-id` used to select the constraints target, and is not functional (red state) when it has none.
Extrapolate
By default, the *min* and *max* values bound the input and output values;
all values outside these ranges are clipped to them.
When you enable this button, the *min* and *max* values are no longer strict limits,
but rather "markers" defining a proportional (linear) mapping between input and corresponding output values.
Let us illustrate that with two graphs Fig. :ref:`fig-constraints-transformation-extrapolate`.
In these pictures, the input range (in abscissa) is set to (1.0 to 4.0),
and its corresponding output range (in ordinate), to (1.0 to 2.0).
The yellow curve represents the mapping between input and output.

.. _fig-constraints-transformation-extrapolate:

.. list-table:: The Extrapolate principles.

* - .. figure:: /images/rigging_constraints_transform_transformation_extrapolate-1.png
:width: 300px

Extrapolate disabled: the output values are bounded inside the (1.0 to 2.0) range.

- .. figure:: /images/rigging_constraints_transform_transformation_extrapolate-2.png
:width: 300px

Extrapolate enabled: the output values are "free" to proportionally follow the input ones.

Source
------

It contains the input (from target) settings.

Map From
The radio buttons, allow you to select which type of property to use.

Location, Rotation, and Scale
From
Independently for each axis (X, Y, and Z) the min and max number buttons control
the lower and upper bounds of the input value range.
Note that if a min value is higher than its corresponding max value,
the constraint behaves as if it had the same value as the max one.

Source to Destination Mapping
The three *Axis Mapping* selectors allow you to select which input axis to map to,
respectively (from top to bottom), the X, Y and Z output (owner) axes.

Destination
-----------

It contains the output (to owner) settings.

Map To
The three radio buttons allow you to select which type of property to control.

Location, Rotation, and Scale
To
The *min* and *max* number buttons control the lower and upper bounds of the output value range,
independently for each mapped axis.
Note that if a min value is higher than its corresponding max value,
the constraint behaves as if it had the same value as the max one.

Space
Standard conversion between spaces.

.. note::

- When mapping transform properties to location (i.e. *Location*, *Destination* button is enabled),
the owner's existing location is added to the result of evaluating this constraint
(exactly like when the *Offset* button of the
:doc:`Copy Location constraint &lt;/rigging/constraints/transform/copy_location&gt;` is enabled...).
- Conversely, when mapping transform properties to rotation or scale,
the owner's existing rotation or scale is overridden by the result of evaluating this constraint.
- When using the rotation transform properties of the target as input,
whatever the real values are, the constraint will always "take them back" into the (-180 to 180) range
(e.g. if the target has a rotation of 420 degrees around its X-Axis,
the values used as *X* input by the constraint will be:

:math:`((420 + 180) modulo 360) - 180 = 60 - ...`

This is why this constraint is not really suited for gears!
- Similarly, when using the scale transform properties of the target as input,
whatever the real values are, the constraint will always take their absolute values (i.e. invert negative ones).
- When a *min* value is higher than its corresponding *max* one,
both are considered equal to the *max* one. This implies you cannot create "reversed" mappings...

.. vimeo:: 171275353

**************************
Transform Cache Constraint
**************************

The *Transform Cache Constraint* is used to stream animations made
at the transformation matrix level (for example rigid bodies, or camera movements).

Options
=======

Cache File
Data-block menu to select the Alembic file.

File Path
Path to Alembic file.

Is Sequence
Whether or not the cache is separated in a series of files.
Override Frame
Whether to use a custom frame for looking up data in the cache file,
instead of using the current scene frame.

Frame
The time to use for looking up the data in the cache file,
or to determine which to use in a file sequence.

Manual Transform Scale
Value by which to enlarge or shrink the object with respect to the world's origin.
Object Path
The path to the Alembic object inside the archive.
Vertices/Faces/UV/Color
Type of data to read for a mesh object respectively: vertices,
polygons, UV maps and Vertex Color layers.
.. _rigging-index:

##########
Rigging
##########

.. toctree::
:maxdepth: 2

introduction.rst

constraints/index.rst
armatures/index.rst
lattice.rst

************
Introduction
************

.. this page reads a bit too much like a tutorial/general advice,
and does not fit reference-manual style.

Rigging makes animation possible. Without a good rig animation is incredibly frustrating.
Imagine animating a bouncing ball without the ability to squash it against the ground?
Try animating a monkey swinging through the trees with no control to make the monkey's hands grab onto the branches.
What if you had to animate an army tank speeding through
the desert by positioning each tread on the tank one at a time?

.. figure:: /images/rigging_introduction_header.png

At its most basic level, rigging solves motion problems.
Imagine a door that opens into a hallway.
Without a rig, the door will not swing open properly (1).
A rig is needed to help the door swing open on its hinges (2, 3, 4), and there are many ways to rig the door.
Door 2 gets rigged by repositioning the :term:`Object Origin` of the door.
Door 3 gets rigged by :term:`Parenting` the door to an :term:`Empty`.
Door 4 gets rigged by :term:`Weight Painting` all of its :term:`Vertices` to a :term:`Bone` in an :term:`Armature`.

.. figure:: /images/rigging_introduction_door.png

Most production rigs are more complicated than a simple door,
but be careful not to rush off building complicated rigs until you have developed some experience.
Rigging is a discipline that takes practice.
Start by building simple rigs (like a bouncing ball, a tumbling box, an odometer, a clock).
Stay humble. Stay patient.
Study the fundamental concepts that make a bouncing ball bounce.
Add one rigging tool to your toolbox at a time. Test your simple rigs in actual animation projects.
And only after much trial and error,
consider putting everything together into the sophisticated character rig of your dreams.

.. seealso::

The content of this chapter is simply a reference to how rigging is accomplished in Blender.
It should be paired with additional resources such as Nathan Vegdahl's excellent (and free!)
introduction to the fundamental concepts of character rigging,
`Humane Rigging &lt;https://www.youtube.com/playlist?list=PL3wFcRXImVPOQpi-wi7uriXBkykXVUntv&gt;`__.

*******
Lattice
*******

Lattice -- or commonly called deformation cage outside of Blender.
A lattice consists of a three-dimensional non-renderable grid of vertices.
Its main use is to apply a deformation to the object it controls with a :doc:`/modeling/modifiers/deform/lattice`.
If the object is parented with *Lattice Deform* a Lattice Modifier is automatically applied.

Editing
=======

Flip (Distortion Free)
Mirrors the vertexes displacement from their base position.

U, V, W
Make Regular
Resets the whole lattice to a regular grid, where the cells are scaled to one cubic Blender Unit.

Properties
==========

.. figure:: /images/rigging_lattice_panel.png
:align: right

Lattice properties.

Lattice
A :ref:`ui-data-block`.

Lattice
-------

Points
Rate of subdivision in the axes:

U, V, W
Interpolation Type
Selector for each axis. See :ref:`fig-interpolation-type`.

Linear, Cardinal, Catmull-Rom, B-Spline
Outside
Takes only the vertices on the surface of the lattice into account.
Vertex Group
The strength of the influence assigned as a weight to the individual vertices in the selected vertex group.

Usage
=====

.. figure:: /images/rigging_lattice_view.png

Lattice around the cube object in Object Mode.

The lattice should be scaled and moved to fit around your object in Object Mode.
Any scaling applied to the object in Edit Mode will result in the object deforming.
This includes applying scale with :kbd:`Ctrl-A` as this will achieve the same result as
scaling the lattice in Edit Mode, and therefore the object.

*****
Brush
*****

Brushes
:ref:`ui-data-block` to select a preset Brush Types or a custom brush.
They are a combination of a 'tool',
along with stroke, texture, and options.

The brush can be selected by numbers:
:kbd:`0` to :kbd:`9` and :kbd:`Shift-0` to :kbd:`Shift-9`.

Add ``+``
When you add a brush, the new brush is a clone of the current one.

.. note::

In order to save in a blend-user a custom brush set a Fake User.

- Increase/decrease brush size :kbd:`[` and :kbd:`]`

Radial Control
==============

- Set brush size :kbd:`F`
- Set brush strength :kbd:`Shift-F`
- Rotate brush texture :kbd:`Ctrl-F`

You can then either adjust the value interactively or by typing in numbers.
After pressing the hotkey move the mouse to increase/reduce the value
(additionally with precision and/or snapping activated).
Finally confirm (:kbd:`LMB`, :kbd:`Enter`) or chancel (:kbd:`RMB`, :kbd:`Esc`).
.. _painting-index:

#######################
Painting &amp; Sculpting
#######################

.. toctree::
:maxdepth: 2

introduction.rst
brush.rst
texture_tex_mask.rst
stroke_curve.rst

Modes
=====

.. toctree::
:maxdepth: 2

painting/index.rst
sculpting/index.rst

************
Introduction
************

Navigate
========

Center on Last Stroke :kbd:`NumpadPeriod`
Center the View on the end of the last stroke.

###########
Painting
###########

.. toctree::
:maxdepth: 2

introduction.rst

Paint Modes
===========

.. toctree::
:maxdepth: 2

texture_paint/index.rst
vertex_paint/index.rst
weight_paint/index.rst

************
Introduction
************

Todo.

.. _painting-texture-index:

################
Texture Paint
################

.. toctree::
:maxdepth: 2

introduction.rst
tools.rst
slots_mask.rst
options.rst
.. This is for 3D View painting, 2D image painting belongs in the UV/Image editor section.

************
Introduction
************

A UV Texture is a picture (image, sequence or movie)
that is used to color the surface of a mesh.
The UV Texture is mapped to the mesh through one or more UV maps.
There are three ways to establish the image used by the UV Texture:

- Paint a flat image in the UV/Image Editor onto the currently selected UV Texture,
using its UV map to transfer the colors to the faces of the mesh.
- Paint the mesh in the 3D View, and let Blender use the currently selected UV map to update the UV Texture.
(see :ref:`Projection Painting &lt;painting-texture-index&gt;`).
- Use any image-editing (paint) program to create an image.
In the UV/Image Editor, select the UV Texture and load the image.
Blender will then use that texture's UV map to transfer the colors to the faces of the mesh.

Blender features a built-in paint mode called Texture Paint which is designed specifically to
help you edit your UV Textures and images quickly and
easily in either the UV/Image or the 3D View Editor.
Since a UV Texture is just a special-purpose image,
you can also use any external paint program. For example,
GIMP is a full-featured image manipulation program that is also open-source.

.. figure:: /images/sculpt-paint_painting_texture_example.jpg
:width: 400px

Texture painting in Blender.

Since a mesh can have layers of UV Textures, there may be many images that color the mesh.
However, each UV Texture only has one image.

Texture Paint works in both a 3D View and the UV/Image Editor.
In the 3D View in Texture Paint Mode, you paint directly on the mesh by
:ref:`projecting onto the UVs &lt;painting-texture-index&gt;`.

Getting Started
===============

Once you have unwrapped your model to a UV Map,
you can begin the texturing process.
You cannot paint on a mesh in Texture Paint Mode without **first** unwrapping your mesh,
**and** doing one of the following steps. Either:

See: :doc:`Applying Image &lt;/editors/uv_image/uv_editing/applying_image&gt;`.

After you have done one of these two things,
you can modify the image using the Texture Paint Mode:

.. figure:: /images/sculpt-paint_painting_texture_paint-mode.jpg
:width: 250px

Enabling paint mode.

- In the 3D View, select Texture Paint Mode from the mode selector in the header,
and you can paint directly onto the mesh.
- In the UV/Image Editor, switch the mode from View to Paint (shown to the right).

.. note:: Square Power of Two

Texture paint is very fast and responsive when working in the 3D View and when your image is sized as a
square where the side lengths are a power of two, e.g. 256×256, 512×512, 1024×1024, etc.

Once you enable Texture Painting, your mouse becomes a brush. To work with the UV layout
(for example, to move coordinates) you must go back to "View" mode.

As soon as you enable Texture Painting or switch to Texture Paint Mode,
brush settings become available in the Tool Shelf.

In the UV/Image Editor,
you paint on a flat canvas that is wrapped around the mesh using UV coordinates.
Any changes made in the UV/Image Editor show up immediately in the 3D View,
and vice versa.

A full complement of brushes and colors can be selected from
the Properties region in the UV/Image Editor.
Brush changes made in either panel are immediately reflected in the other panel. However,
the modified texture will **not** be saved automatically;
you must explicitly do so by :menuselection:`Image --&gt; Save` in the UV/Image Editor.

Missing Data
------------

Add Simple UVs
The *Add Simple UVs* does a simple cube unwrap followed by a pack operation.
It's still recommended to make a custom unwrap.
Add Paint Slot
ToDo.

Texture Preview
===============

If your texture is already used to color, bump map, displace, alpha-transparent, etc.,
a surface of a model in your scene (in other technical words,
is mapped to some aspect of a texture via a texture channel using UV as a map input),
you can see the effects of your painting in the context of your scene as you paint.

To do this, set up side-by-side areas, one area in 3D View set to *Texture* shading option,
and in the second area the UV/Image Editor loaded with your image.
Position the 3D View to show the object that is UV mapped to the loaded image.
In the image to the right, the texture being painted is mapped to the "Normal" attribute,
and is called "bump mapping",
where the gray-scale image is used to make the flat surface appear bumpy.
See Texture Mapping Output for more information on bump mapping.

Saving
======

If the header menu item Image has an asterisk next to it,
it means that the image has been changed, but not saved.
Use the :menuselection:`Image --&gt; Save Image`
option to save your work with a different name or overwrite the original image.

.. note:: UV Textures

Since images used as UV Textures are functionally different from other images,
you should keep them in a directory separate from other images.

The image format for saving is independent of the format for rendering.
The format for saving a UV image is selected in the header of the File browser,
and defaults to ``PNG`` (``.png``).

If Packing is enabled in the File browsers header,
or if you manually :menuselection:`Image --&gt; Pack Image`,
saving your images to a separate file is not necessary.

Using an External Image Editor
==============================

If you use an external program to edit your UV Texture, you must:

- run that paint program (GIMP, Photoshop\ :sup:`®` \, etc.)
- load the image or create a new one
- change the image, and
- re-save it within that program.
- Back in Blender, you reload the image in the UV/Image Editor.

You want to use an external program if you have teams of people using different programs that
are developing the UV textures,
or if you want to apply any special effects that Texture Paint does not feature,
or if you are much more familiar with your favorite paint program.

Known Limitations
=================

UV Overlap
----------

In general overlapping UVs are not supported (as with texture baking).

However, this is only a problem when a single brush stroke paints onto multiple faces that share a texture.

Perspective View &amp; Faces Behind the View
----------------------------------------

When painting onto a face which is partially behind the view (in perspective mode), the face cannot be painted on.
To avoid, this zoom out or use an Ortho mode viewport.

Perspective View &amp; Low Poly
---------------------------

When painting onto a face in perspective mode onto a low poly object with normals pointing away from the view,
painting may fail; to workaround disable the *Normal* option in the paint panel.

Typically this happens when painting onto the side of a cube
(see `Bug report T34665 &lt;https://developer.blender.org/T34665&gt;`__).

*******
Options
*******

Options tab.

Overlay
=======

Allows you to customize the display of curve and texture that applied to the brush.

Appearance
==========

Allows you to customize the color of the brush radius outline,
as well as specify a custom icon.

Project Paint
=============

Occlude
ToDo.
Cull
ToDo.
Normal
ToDo.
Cavity Mask
Cavity masking means that the brush will be masked if there is a cavity or a hill
on the mesh surface depending on the mesh options. The cavity algorithm is vertex-based.

Bleed
ToDo.
Dither
Amount of dithering when painting on byte images. ToDo.

Unified Settings
Brush options shared between the brush types.

Size, Color, Strength

************
Slots &amp; Mask
************

The Slots tab in the Tool Shelf.

Slot
====

The combination of images associated with UV maps is called "slots".

Painting Mode
ToDo.
Canvas Image
ToDo.
Available Paint Slots
A :ref:`ui-list-view` of slots.
To activate a certain slot to use it for paint a just :kbd:`LMB` click on it.
Clicking on a slot will also display the slot image in the UV/Image editors, if any are open.

Add/Remove Texture Paint Slot
ToDo.
Blend Type
ToDo.

UV Map
ToDo.
Save All Images
ToDo.

Mask
====

The mask can be deactivated by the checkbox in the header.

UV Map
ToDo.
Stencil Image
ToDo.
Visualization
ToDo.
Invert Stencil (black/white icon)
Inverts the mask.

*****
Tools
*****

Open the Tool Shelf in the 3D View or UV/Image Editor .

Brush
=====

.. figure:: /images/sculpt-paint_painting_texture_brush.jpg
:width: 200px

Brush Settings.

With this panel, you can create many brushes, each with unique settings (such as color and width).

Brush Types
-----------

Texture Draw
^^^^^^^^^^^^

The normal brush; paints a swath of color.

Fill
^^^^

It can be used to fill the image with the brush color.

Fill Threshold
ToDo. (2D only)

.. note:: Overrides

For projective texturing it will bypass some options for projective painting to paint the model.
This means that occluded, backfacing and normal culled faces will always get filled,
regardless of whether the options are activated in the projection paint panel.

.. tip:: Masking

Use the face selection mask to isolate faces.

Mask
^^^^

The mask feature maps an image to the mesh and uses the image intensity to
mask out certain parts of the mesh out during painting.
The mask options can be found mask panel
in the :doc:`slots tab &lt;/sculpt_paint/painting/texture_paint/slots_mask&gt;`.

Soften
^^^^^^

Blends edges between two colors.

Direction
Soften
Blur filter. ToDo.
Sharpen
The sharpen tool enhances the contrast of the image as you paint over it.

Sharp Threshold
The Threshold will only apply sharpening to only those pixels that
differ more than the threshold value from their surrounding pixels.
Blur Mode
The blur kernel type controls how neighboring pixels are weighted when calculating the blur effect.

Gaussian
Gaussian will sample the pixels near the center of the brush most.
Box
Box samples all surrounding pixels equally.

Smear
^^^^^

When you click, takes the colors under the cursor, and blends them in the direction you move the mouse.
Similar to the "smudge" tool of *Gimp*.

Clone
^^^^^

Copies the colors from the image specified to the active image.
The clone cursor can be set with :kbd:`Ctrl-LMB`.
In 2D painting the clone can be moved dragging it with :kbd:`RMB`.

Clone from paint slot
The background image is shown when this brush is selected;
use the *Strength* slider to control how prominent the background image is.

Source Clone Slot
When using the clone brush, this allows you to select an image as a clone source.

Common
------

Most brushes have common settings.

Color
The color of the brush. See :ref:`ui-color-picker`.

Press :kbd:`S` on any part of the image to sample that color and
set it as the brush color.

Flip (cycle icon) :kbd:`X`
Swaps the foreground and background color.
Radius
The radius of the brush in pixels.
Strength
How powerful the brush is when applied.

Space Attenuation (padlock icon)
Attenuate the brush strength according to spacing.
Pressure Sensitivity (hand and bulged in blue line icon)
The toggle to the right of the following three settings will enable or disable
tablet pressure sensitivity to control how strong the effect is.

Blend
Set the way the paint is applied over the underlying color. See :term:`Color Blend Modes`.

- Add Alpha: makes the image more opaque where painted.
- Erase Alpha: makes the image transparent where painted,
allowing background colors and lower-level textures to show through.
As you 'paint', the false checkerboard background will be revealed.
Using a table pen's eraser end will toggle on this mode.
- Luminosity
- Exclusion
- Vivid light
- Pin light

.. tip::

In order to see the effects of the Erase and Add Alpha mix modes in the UV/Image Editor,
you must enable the alpha channel display by clicking the Display Alpha or the Alpha-Only button.
Transparent (no alpha) areas will then show a checkered background.

Accumulate
This will allow a stroke to accumulate on itself, just like an airbrush would do.
Alpha
Opacity of the clone image display.
Use Gradient
A gradient can be used as color source. ToDo. See :ref:`ui-color-ramp-widget`.
To apply the gradient with the *Fill* brush click :kbd:`LMB` and drag to define
depending on the *Gradient Fill Mode* the gradient line, or radius, if radial gradient is used.

Mode
Pressure
Will choose a gradient color from the color band according to the stylus pressure.
Clamp
Will alter the color automatically by the distance covered by the brush and as specified.
by *Gradient spacing*. With Clamp it uses the last color of the color band after the specified.
Repeat
Similar to *Clamp*. After the last color it resets the color to the first color in the color band and
repeating the pattern.
Gradient Fill Mode
Linear, Radial

Tilling
=======

Wraps the stroke to the other side of the image as your brush moves off the opposite side of the canvas.
Very handy for making seamless textures.

X
left/right
Y
top/bottom
.. _painting-vertex-index:

###############
Vertex Paint
###############

.. toctree::
:maxdepth: 2

introduction.rst
tools.rst
options.rst

************
Introduction
************

Vertex Painting is a simple way of painting color onto an object,
by directly manipulating the color of vertices, rather than textures,
and is fairly straightforward.

When a vertex is painted,
the color of the vertex is modified according to the rules of the 'brush'. The color of all
visible planes and edges attached to the vertex are then modified with a gradient to the color
of the other connected vertices. (Note that the color of non-visible faces is not modified).

Vertex colors can be painted by first going into Edit Mode, then switching to *Vertex Paint Mode*;
however, it will not show up in the render unless you check *Vertex Color Paint* in the
:doc:`Materials Options &lt;/render/blender_render/materials/properties/options&gt;` panel.

.. list-table::

* - .. figure:: /images/sculpt-paint_painting_vertex-paint_introduction_mode-menu.png

Vertex Painting Mode.

- .. figure:: /images/sculpt-paint_painting_vertex-paint_introduction_material-options.png

Check this box.

*******
Options
*******

.. figure:: /images/sculpt-paint_painting_vertex-paint_options_panel.png
:align: right

Options for vertex painting.

Overlay
=======

Allows you to customize the display of curve and texture applied to the brush.

Appearance
==========

Allows you to customize the color of the brush radius outline,
as well as specify a custom icon.

Options
=======

Normals
Applies the Vertex Normal before painting. This does not usually affect painting.
Spray
Continues painting for as long as the mouse is held.
Unified Settings
Size
All brushes use the same size.
Strength
All brushes use the same strength.

*****
Tools
*****

The Tools Shelf contains most of the options for vertex painting.
The following sections describe the controls in each of the available panels.

.. figure:: /images/sculpt-paint_painting_vertex-paint_options_tools.png
:align: right

Vertex Painting Options.

Brush
=====

Brush
The :ref:`Data-Block menu &lt;ui-data-block&gt;` allows you to select brush presets, as well as custom brushes.
Color
Color picker.
Radius
Set the radius of the brush
Strength
Set the strength of the brush's effect.
Blend
Mix
Mixes RGB values. When set to a strength of 1.0, it will cover the underlying "paint".
Add
Adds RGB values.
Will eventually turn the entire object white as RGB values accumulate to (1.0, 1.0, 1.0): Pure White.
Subtract
Subtracts RGB values. Usually results in Black.
Multiply
Multiplies brush colors by the vertex colors.
Blur
Blurs vertex colors.
Lighten
Lightens the color of the vertices.
Darken
Darkens the color of the vertices.

****************
Hiding &amp; Masking
****************

Selection Masking
=================

If you have a complex mesh,
it is sometimes not easy to paint on all vertices in Weight Paint Mode.
Suppose you only want to paint on a small area of the Mesh and keep the rest untouched.
This is where *selection masking* comes into play. When this mode is enabled,
a brush will only paint on the selected vertices or faces.
The option is available from the header of the 3D View
(see icons surrounded by the yellow frame):

.. figure:: /images/modeling-meshes-weight-paint-select.png

You can choose between *Face Selection masking* (left icon)
and *Vertex selection masking* (right icon).

*Select* mode has some advantages over the default *Weight Paint Mode*:

- The original mesh edges are drawn, even when modifiers are active.
- You can select faces to restrict painting to the vertices of the selected faces.
- Selecting tools include:

Details about selecting
-----------------------

The following standard selection operations are supported:

- :kbd:`RMB` - Single faces. Use :kbd:`Shift-RMB` to select multiple.
- :kbd:`A` - All faces, also to de-select.
- :kbd:`B` - Border selection.
- :kbd:`C` - Circle select with brush.
- :kbd:`L` - Pick linked (under the mouse cursor).
- :kbd:`Ctrl-L` - Select linked.
- :kbd:`Ctrl-I` - Invert selection *Inverse*.

.. tip:: Selecting Deform Groups

When you are doing weight painting for deform bones (with an Armature),
you can select a deform group by selecting the corresponding bone.
However, this Vertex Group selection mode is disabled when Selection Masking is active!

Vertex Selection Masking
------------------------

.. figure:: /images/modeling-meshes-weight-paint-vertex-select.png

Vertex Selection masking.

In this mode you can select one or more vertices and then paint only on the selection.
All unselected vertices are protected from unintentional changes.

.. note::

This option can also be toggled with :kbd:`V`.

Face Selection Masking
----------------------

.. list-table::

* - .. figure:: /images/modeling-meshes-weight-paint-face-select.png

Face Selection masking.

- .. figure:: /images/modeling-meshes-weight-paint-face-select-hidden.jpg

Hidden faces.

The *Face Selection masking* allows you to select faces and limit the weight paint
tool to those faces, very similar to Vertex selection masking.

Hide/Unhide Faces
-----------------

You also can hide selected faces as in Edit Mode with the keyboard Shortcut :kbd:`H`,
then paint on the remaining visible faces and finally unhide the hidden faces again by using
:kbd:`Alt-H`

Hide/Unhide Vertices
--------------------

You cannot directly hide selected faces in vertex mask selection mode.
However, you can use a trick:

#. First go to Face selection mask mode.
#. Select the areas you want to hide and then hide the faces (as explained above).
#. Switch back to Vertex Selection mask mode.

Now the vertices belonging to the hidden Faces will remain hidden.

The Clipping Border
-------------------

To constrain the paint area further you can use the *Clipping Border*.
Press :kbd:`Alt-B` and :kbd:`LMB` -drag a rectangular area.
The selected area will be "cut out" as the area of interest.
The rest of the 3D View gets hidden.

.. figure:: /images/modeling-meshes-weight-paint-border-select.jpg

The Clipping Border is used to select interesting parts for local painting.

You make the entire mesh visible again by pressing :kbd:`Alt-B` a second time.

All weight paint tools that use the view respect this clipping, including border select,
weight gradient and of course brush strokes.
.. _painting-weight-index:

###############
Weight Paint
###############

.. toctree::
:maxdepth: 2

introduction.rst
tools.rst
weight_tools.rst
options.rst
hide_mask.rst

************
Introduction
************

Vertex Groups can potentially have a very large number of associated vertices and thus a large
number of weights (one weight per assigned vertex). *Weight Painting* is a method to
maintain large amounts of weight information in a very intuitive way.

It is primarily used for rigging meshes,
where the vertex groups are used to define the relative bone influences on the mesh.
But we use it also for controlling particle emission, hair density, many modifiers,
shape keys, etc.

.. figure:: /images/modeling-meshes-weight-paint-example.jpg

Vertex Group in Weight Paint Mode.

You enter *Weight Paint Mode* from the Mode Menu :kbd:`Ctrl-Tab`.
The selected Mesh Object is displayed slightly shaded with a rainbow color spectrum.
The color visualizes the weights associated to each vertex in the active Vertex Group.
By default blue means unweighted and Red means fully weighted.

You assign weights to the vertices of the Object by painting on it with weight brushes.
Starting to paint on a mesh automatically adds weights to the active Vertex Group
(a new Vertex Group is created if needed).

The Weighting Color Code
========================

Weights are visualized by a gradient using a cold/hot color system, such that areas of low value
(with weights close to 0.0) are drawn in blue (cold) and areas of high value
(with weights close to 1.0) are drawn in red (hot).
And all in-between values are drawn in rainbow colors (blue, green, yellow, orange, red).

.. figure:: /images/sculpt-paint_painting_weight-paint_introduction_color-code.png

The color spectrum and their respective weights.

In addition to the above described color code, Blender has a special visual notation (as an option)
for unreferenced vertices: They are drawn in black.
Thus you can see the referenced areas (drawn in cold/hot colors) and the unreferenced areas
(in black) at the same time. This is most practical when you look for weighting errors.
See :doc:`/sculpt_paint/painting/weight_paint/options`.

.. figure:: /images/sculpt-paint_painting_weight-paint_introduction_color-code-black.png

Unreferenced vertices example.

.. note::

You can customize the colors in the weight gradient by enabling
:ref:`Custom Weight Paint Range &lt;prefs-system-weight&gt;` in the *System* tab
of the *User Preferences*.

Usage
=====

.. _weight-painting-bones:

Weight Painting for Bones
-------------------------

This is one of the main uses of weight painting.
When a bone moves, vertices around the joint should move as well,
but just a little, to mimic the stretching of the skin around the joint.
Use a "light" weight (10 - 40%)
paint on the vertices around the joint so that they move a little when the bone rotates.
While there are ways to automatically assign weights to an armature
(see the :doc:`Armature section &lt;/rigging/index&gt;`),
you can do this manually. To do this from scratch, refer to the process below.
To modify automatically assigned weights, jump into the middle of the process where noted:

#. Create an armature.
#. Create a mesh that will be deformed when the armature's bone(s) move.
#. With the mesh selected, create an *Armature* modifier for your mesh
(located in the Properties editor, *Modifiers* tab).
Enter the name of the armature.

Pick up here for modifying automatically assigned weights.

#. Select the armature in 3D View, and bring the armature to *Pose Mode*
with :kbd:`Ctrl-Tab`, or the 3D View header mode selector.
#. Select a desired bone in the armature.
#. Select your mesh with :kbd:`RMB` and change immediately to *Weight Paint Mode*.
The mesh will be colored according to the weight (degree) that the selected bone movement affects the mesh.
Initially, it will be all blue (no effect).
#. Weight paint to your heart's content.
The mesh around the bone itself should be red (generally)
and fade out through the rainbow to blue for vertices farther away from the bone.

When you select a bone of the armature (which remained in *Pose Mode*),
it will activate the corresponding vertex group and display related weights.
You can only select one bone at a time in this mode (so :kbd:`Shift-LMB` clicking does not work).

.. tip::

If the mesh skins the bones, you will not be able to see the bones because the mesh is painted.
If so, turn on *X-Ray* view (:menuselection:`Properties Editor --&gt; Armature tab`).

If you paint on the mesh, a vertex group is created for the bone.
If you paint on vertices outside the group,
the painted vertices are automatically added to the vertex group.

If you have a symmetrical mesh and a symmetrical armature
you can use the option *X-Mirror*.
Then the mirrored groups with the mirrored weights are automatically created.

Weight Painting for Particles
-----------------------------

.. figure:: /images/sculpt-paint_painting_weight-paint_introduction_particles.png

Weight painted particle emission.

In example faces or vertices with zero weight generate no particles.
A weight of 0.1 will result in 10% of the amounts of particles.
This option "conserves" the total indicated number of particles, adjusting the distributions
so that the proper weights are achieved while using the actual number of particles called for.
Use this to make portions of your mesh hairier than others by weight painting a vertex group,
and then calling out the name of the vertex group in the
:doc:`Vertex Groups &lt;/physics/particles/emitter/vertex_groups&gt;`
panel :menuselection:`Properties editor --&gt; Particles tab`.

*******
Options
*******

.. figure:: /images/sculpt-paint_painting_weight-paint_properties_appearance-panel.png
:align: right

Brush appearance.

Overlay
=======

Allows you to customize the display of curve and texture that applied to the brush.

Appearance
==========

Show Brush
Makes the brush visible as a circle (on by default).
Custom Icon
Allows definition of a custom brush icon.

Options
=======

.. figure:: /images/sculpt-paint_painting_weight-paint_properties_options-panel.png
:align: right

Paint Options.

The Weight Paint Options modify the overall brush behavior:

Normals
The vertex normal (helps) determine the extent of painting. This causes an effect as if painting with light.
Spray
Constantly draw (opposed to drawing one stroke per mouse click).
Restrict
This option limits the influence of painting to vertices belonging
(even with weight 0) to the selected vertex group.
X-mirror
Use the X-mirror option for mirrored painting on groups that have symmetrical names,
like with extension ".R"/ ".L" or "_R" / "_L".
If a group has no mirrored counterpart, it will paint symmetrically on the active group itself.
You can read more about the naming convention in
:doc:`Editing Armatures: Naming conventions &lt;/rigging/armatures/bones/editing/properties&gt;`.
The convention for armatures/bones apply here as well.
Topology Mirror
Use topology-based mirroring, for when both sides of a mesh have matching mirrored topology.
Show Zero Weights
To display unreferenced and zero weighted areas in black (by default).
This helps to identify areas with very low weights that have been painted onto.

None
Deactivated.
Active
Only the active group.
All
All groups.
Unified Settings
The *Size*, *Strength* and *Weight* of the brush can be set to
be shared across different brushes, as opposed to per-brush.

*****
Tools
*****

Brush
=====

.. figure:: /images/sculpt-paint_painting_weight-paint_properties_brush-panel.png
:align: right

Brush Panel.

Painting needs paint brushes and Blender provides a Brush Panel within the Tool Shelf when it
operates in *Weight Paint Mode*.

Brush
In the :ref:`Data-Block menu &lt;ui-data-block&gt;` you find predefined Brush Presets.
And you can create your own custom presets as needed.
Weight :kbd:`W`
The weight (color) to be used by the brush.
However, the weight value is applied to the Vertex Group
in different ways depending on the selected Brush Blending mode (see below).

Use :kbd:`Ctrl-LMB` to sample the weight value of clicked vertex.
:kbd:`Shift-LMB` lets you select the group from which to sample from.
Strength
This is the amount of paint to be applied per brush stroke.
What that means exactly also depends on the Brush Blending mode.
Radius
The radius defines the area of influence of the brush.

Blend mode
The brush Blending mode defines in which way the weight value is applied to the Vertex Group while painting.

Mix
In this Blending mode the Weight value defines the *target weight* that will eventually
be reached when you paint long enough on the same location of the mesh.
And the strength determines how many strokes you need to arrive at the target weight.
Note that for strength = 1.0 the target weight is painted immediately,
and for Weight = 0.0 the brush just does nothing.
Add
In this Blending mode the specified weight value is *added* to the vertex weights.
The strength determines which fraction of the weight gets added per stroke.
However, the brush will not paint weight values above 1.0.
Subtract
In this Blending mode the specified weight value is *subtracted* from the vertex weights.
The strength determines which fraction of the weight gets removed per stroke.
However, the brush will not paint weight values below 0.0.
Lighten
In this Blending mode the specified weight value is interpreted
as the target weight. Very similar to the Mix Blending mode,
but only weights below the target weight are affected.
Weights above the target weight remain unchanged.
Darken
This Blending mode is very similar to the Lighten Blending mode.
But only weights above the target weight are affected.
Weights below the target weight remain unchanged.
Multiply
Multiplies the vertex weights with the specified weight value.
This is somewhat like subtract, but the amount of removed weight is now dependent on the Weight value itself.
Blur
Smooths out the weighting of adjacent vertices.
In this mode the Weight Value is ignored.
The strength defines how much the smoothing is applied.

Accumulate
This option keeps applying smoothing on top of the previous result.

.. hint::

- Disable when painting individual vertices on lower poly modules.
- Enable for more dense geometry, or when you want to increase the blur effect.

Auto Normalize
Ensures that all deforming vertex groups add up to one while painting. When this option is turned off,
then all weights of a vertex can have any value between 0.0 and 1.0. However, when Vertex Groups are used as
Deform Groups for character animation then Blender always interprets the weight values relative to each other.
That is, Blender always does a normalization over all deform bones. Hence in practice it is not necessary to
maintain a strict normalization and further normalizing weights should not affect animation at all.

This option works most intuitively when used to maintain normalization while painting on top of weights
that are already normalized with some other tool.
Multi-Paint
Paint on all selected Vertex Groups simultaneously, in a way that preserves their relative influence.
This can be useful when tweaking weights in an area that is affected by more than three bones at once,
e.g. certain areas on a character's face.

This option is only useful in the Armature tab, where you can select multiple Vertex Groups
by selecting multiple Pose bones. Once at least two Vertex Groups are selected, viewport colors and
paint logic switch to Multi-Paint Mode, using the sum of the selected groups' weights if Auto Normalize
is enabled, and the average otherwise. Any paint operations aimed at this collective weight are applied
to individual Vertex Group weights in such way that their ratio stays the same.

Since the ratio is undefined if all weights are zero, Multi-Paint cannot operate on vertices that do not
have any weight assigned to the relevant Vertex Groups. For this reason it also does not allow reducing
the weight all the way to zero. When used with X-Mirror, it only guarantees completely a symmetrical
result if weights are initially symmetrical.

.. tip::

While Multi-Paint cannot directly paint on zero-weight vertices,
it is possible to use the *Smooth Weight* tool to copy a reasonable non-zero weight
distribution from adjacent vertices without leaving Multi-Paint Mode or changing bone selection.

To do that, enable vertex selection, select target vertices,
and apply one iteration of the tool using vertex groups from *Selected Pose Bones* with low Factor.
After that simply paint on top to set the desired collective weight.

************
Weight Tools
************

.. figure:: /images/sculpt-paint_painting_weight-paint_weight-tools-panel.png
:align: right

Weight Paint Tools.

.. admonition:: Reference
:class: refbox

| Mode:     Edit Mode and Weight Paint Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Weight Tools`
| Menu:     :menuselection:`Weights`

Blender provides a set of helper tools for Weight Painting.
The tools are accessible from the Tool Shelf in Weight Paint Mode.
And they are located in the weight tools panel.

The Subset Option
=================

Some of the tools also provide a Subset filter to restrict their functionality to only specific vertex groups
(in the Operator panel, displayed after the tool is called) with following options:

- Active Group
- Selected Pose Bones
- Deform pose Bones
- All Groups

All tools also work with Vertex Selection Masking and Face Selection masking.
In these modes the tools operate only on selected vertices or faces.

.. tip:: About the Blend tool

The Blend tool only works when "Vertex selection masking for painting" is enabled.
Otherwise the tool button is grayed out.

Normalize All
=============

For each vertex,
this tool makes sure that the sum of the weights across all Vertex Groups is equal to 1.
This tool normalizes all of the vertex groups, except for locked groups,
which keep their weight values untouched.

Options
-------

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_normalize-all.jpg

Normalize All Options.

Lock Active
Keep the values of the active group while normalizing all the others.

Normalize
=========

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_normalize.jpg

Normalize All Options.

This tool only works on the active Vertex Group.
All vertices keep their relative weights,
but the entire set of weights is scaled up such that the highest weight value is 1.0.

Mirror
======

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_mirror.jpg

Normalize All Options.

This tool mirrors the weights from one side of the mesh to the opposite side
(only mirroring along x-axis is supported). But note,
the weights are not transferred to the corresponding opposite bone weight group.
The mirror only takes place within the selected Vertex Group.

Options
-------

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_mirror_options.jpg

Mirror Options.

Mirror Weights
Mirrors the weights of the active group to the other side. Note, this only affects the active weight group.
Flip Group Names
Exchange the names of left and right side. This option only renames the groups.
All Groups
Operate on all selected bones.
Topology Mirror
Mirror for meshes which are not 100% symmetric (approximate mirror).

.. tip:: Mirror to opposite bone

If you want to create a mirrored weight group for the opposite bone (of a symmetric character),
then you can do this:

#. Delete the target Vertex Group (where the mirrored weights will be placed).
#. Create a copy of the source bone Vertex Group (the group containing the weights which you want to copy).
#. Rename the new Vertex Group to the name of the target Vertex Group (the group you deleted above).
#. Select the Target Vertex Group and call the Mirror tool
(use only the Mirror weights option and optionally Topology Mirror if your mesh is not symmetric).

Invert
======

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_invert.jpg

Invert.

Replaces each Weight of the selected weight group by × -1.0 weight.

Examples:

- Original 1.0 converts to 0.0
- Original 0.5 remains 0.5
- Original 0.0 converts to 1.0

Options
-------

.. _fig-paint-weight-tools-mirror:

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_invert_options.jpg

Invert Options.

Subset
Restrict the tool to a subset. See above `The Subset Option`_ about how subsets are defined.
Add Weights
Add vertices that have no weight before inverting (these weights will all be set to 1.0)
Remove Weights
Remove vertices from the Vertex Group if they are 0.0 after inverting.

.. note::

Locked vertex Groups are not affected.

Clean
=====

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_clean.jpg

Invert.

Removes weights below a given threshold.
This tool is useful for clearing your weight groups of very low (or zero-) weights.

In the example shown, a cutoff value of 0.139 is used (see operator options below)
so all blue parts (left side) are cleaned out (right side).

Note, the images use the *Show Zero weights* Active option so that unreferenced
Weights are shown in Black.

Options
-------

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_clean_options.jpg

Clean Options.

Subset
Restrict the tool to a subset. See above `The Subset Option`_ for how subsets are defined.
Limit
This is the minimum weight value that will be kept in the Group.
Weights below this value will be removed from the group.
Keep Single
Ensure that the Clean tool will not create completely unreferenced vertices
(vertices which are not assigned to any Vertex Group),
so each vertex will keep at least one weight, even if it is below the limit value!

Quantize
========

Clamps each weight to a number of steps between (0 - 1).

Steps
ToDo.

Levels
======

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_levels.jpg

Invert.

Adds an offset and a scale to all weights of the selected Weight Groups.
with this tool you can raise or lower the overall "heat" of the weight group.

.. note::

No weight will ever be set to values above 1.0 or below 0.0 regardless of the settings.

Options
-------

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_levels_options.jpg

Levels Options.

Subset
Restrict the tool to a subset. See above `The Subset Option`_ for how subsets are defined.
Offset
A value from the range (-1.0 - 1.0) to be added to all weights in the Vertex Group.
Gain
All weights in the Subset are multiplied with the gain.

.. note::

Whichever *Gain* and *Offset* you choose,
in all cases the final value of each weight will be clamped to the range (0.0 - 1.0).
So you will never get negative weights or overheated areas (weight &gt; 1.0) with this tool.

.. renamed from blend to smooth in v2.76 git c402057

Smooth
======

Blends the weights of selected vertices with adjacent unselected vertices.
This tool only works in vertex select mode.

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_smooth_ex1.png

To understand what the tool really does, let us take a look at a simple example.
The selected vertex is connected to four adjacent vertices
(marked with a gray circle in the image). All adjacent vertices are unselected.
Now the tool calculates the average weight of all connected **and** unselected vertices.
In the example this is:

:math:`(1 + 0 + 0 + 0) / 4 = 0.25`

This value is multiplied by the factor given in the Operator options (see below).

- If the factor is 0.0 then actually nothing happens at all and the vertex just keeps its value.
- If the factor is 1.0 then the calculated average weight is taken (0.25 here).
- Dragging the factor from 0 to 1 gradually changes from the old value to the calculated average.

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_smooth_ex2.png

Now let us see what happens when we select all but one of the neighbors of the selected vertex as
well. Again all connected and unselected vertices are marked with a gray circle.
When we call the Smooth tool now and set the Factor to 1.0,
then we see different results for each of the selected vertices:

- The topmost and bottommost selected vertices:

are surrounded by three unselected vertices, with an average weight of :math:`(1 + 0 + 0) / 3 = 0.333`
So their color has changed to light green.

- The middle vertex:

is connected to one unselected vertex with ``weight = 1``.
So the average weight is 1.0 in this case, thus the selected vertex color has changed to red.

- The right vertex:

is surrounded by three unselected vertices with average weight = :math:`(0 + 0 + 0) / 3 = 0.0`
So the average weight is 0, thus the selected vertex color has not changed at all
(it was already blue before Smooth was applied).

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_smooth_ex3.png

Finally let us look at a practical example.
The middle edge loop has been selected
and it will be used for blending the left side to the right side of the area.

- All selected vertices have two unselected adjacent vertices.
- The average weight of the unselected vertices is :math:`(1 + 0) / 2 = 0.5`
- Thus when the *Factor* is set to 1.0 then the edge loop turns to
green and finally does blend the cold side (right) to the hot side (left).

Options
-------

.. figure:: /images/sculpt-paint_painting_weight-paint_wtools_smooth_options.png

Smooth Options.

Factor
The effective amount of blending.
When Factor is set to 0.0 then the Blend tool does not do anything.
For Factor &gt; 0 the weights of the affected vertices gradually shift from their original value
towards the average weight of all connected **and** unselected vertices (see examples above).
Iterations
ToDo.
Expand/Contract
ToDo.
Source
ToDo.

Fix Deforms
===========

ToDo.

Transfer Weights
================

Copy weights from other objects to the vertex groups of the active Object.
By default this tool copies all vertex groups contained in the selected objects to the target
object. However, you can change the tool's behavior in the Operator panel (see below).

Prepare the Copy
----------------

.. list-table::

* - .. figure:: /images/sculpt-paint_painting_weight-paint_wtools_transfer-wrong.jpg

Blending.

- .. figure:: /images/sculpt-paint_painting_weight-paint_wtools_transfer-ok.jpg

Blending.

You first select all source objects, and finally the target object
(the target object must be the active object).

It is important that the source objects and the target object are at the same location.
If they are placed side by side, then the weight transfer will not work.
You can place the objects on different layers,
but you have to ensure that all objects are visible when you call the tool.

Now ensure that the Target Object is in Weight Paint Mode.

Call the Tool
-------------

Open the Tool Shelf and locate the Weight Tools panel.
From there call the "Transfer weights" tool.
The tool will initially copy all vertex groups from the source objects.
However, the tool also has an Operator panel
(which appears at the bottom of the tool shelf).
From the Operator panel you can change the parameters to meet your needs.
(The available Operator parameters are documented below.)

Operator Panel Confusion
^^^^^^^^^^^^^^^^^^^^^^^^

You may notice that the Operator panel (see below)
stays available after the weight transfer is done.
The panel only disappears when you call another Operator that has its own Operator panel. This can
lead to confusion when you use Transfer weights repeatedly after you changed your vertex
groups. If you then use the still-visible Operator panel, then Blender will reset your work to its
state right before you initially called the Transfer Weights tool.

Workaround
^^^^^^^^^^

When you want to call the Transfer Weights tool again after you made some changes to your
vertex groups, then always use the "Transfer Weights" Button,
even if the operator panel is still available.
Unless you really want to reset your changes to the initial call of the tool.

Options
^^^^^^^

.. note::

This tool now uses the generic 'data transfer' one. Please refer to the
:doc:`Data Transfer &lt;/modeling/modifiers/modify/data_transfer&gt;` docs for options details and explanations.

Limit Total
===========

Reduce the number of weight groups per vertex to the specified Limit.
The tool removes lowest weights first until the limit is reached.

.. hint::

The tool can only work reasonably when more than one weight group is selected.

Options
-------

Subset
Restrict the tool to a subset. See above `The Subset Option`_ for how subsets are defined.
Limit
Maximum number of weights allowed on each vertex.

Weight Gradient
===============

.. figure:: /images/sculpt-paint_painting_weight-paint_tools_weightgradient.png
:width: 200px

Example of the gradient tool being used with selected vertices.

This is an interactive tool for applying a linear/radial weight gradient;
this is useful at times when painting gradual changes in weight becomes difficult.

The gradient tool can be accessed from the Tool Shelf or as a key shortcut:

- Linear: :kbd:`Alt-LMB` and drag.
- Radial: :kbd:`Alt-Ctrl-LMB` and drag.

The following weight paint options are used to control the gradient:

Weight
The gradient starts at the current selected weight value, blending out to nothing.
Strength
Lower values can be used so the gradient mixes in with the existing weights (just like with the brush).
Curve
The brush falloff curve applies to the gradient too, so you can use this to adjust the blending.

Blends the weights of selected vertices with unselected vertices.

.. hint::

This tool only works in vertex select mode.

Options
-------

Type
- Linear
- Radial

Assign
======

Assign from Bone Envelopes
Applies the envelope weight of the select the bone(s) to the selected vertex group.
Assign Automatic from Bone
Apply from the selected bone(s) to the vertex group the same "auto-weighting"
methods as available in the Parent armature menu.

******************
Adaptive Sculpting
******************

Dynamic Topology
================

.. admonition:: Reference
:class: refbox

| Mode:     Sculpt Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Dyntopo`
| Hotkey:   :kbd:`Ctrl-D`

Dynamic topology (aka dyntopo) is a dynamic tessellation sculpting method,
adds and removes details on the fly, whereas regular sculpting only affects the shape of a mesh.

This makes it possible to sculpt complex shapes out of a simple mesh,
rather than just adding details onto a modeled base mesh.

Dyntopo can be toggled with the checkbox in the header or with :kbd:`Ctrl-D`.
With dynamic topology active, most brushes will subdivide the mesh during the stroke.

Detail Type
Dyntopo uses three different detail methods to create dynamic detail to an object.

Relative Detail
This method uses a detail size based on the number of pixels, and in turn
will create topology in that size. Zoom out big details, zoom in small fines details.
Constant Detail
To keep detail uniform across the entire object, Constant Detail can be used.
The Detail is based on the percentage of a single :abbr:`BU (Blender Unit)`.
Brush Detail
Giving more control over the topology, with this method you can create topology
based on the brush size. You can increase and lower topology by simply resizing
the brush itself. The detail size is based the size of the brush itself, where
100% will create topology the size of the brush ring itself.
Detail Size :kbd:`Shift-D`
Each Detail Type's detail is set here. Depending on the Detail Type being used
this property will rather show as a pixel count (px), or percentage.

Sample Detail Size (pipette icon)
With Constant Detail Size it is possible to sample the detail value of a certain mesh area
by clicking the eyedropper icon next to the detail setting and then clicking on the area.
Detail Refine Method
When using Dynamic Topology, a certain method will be used to tell how topology
is handled. Setting the option will determine which of the methods will be used when
altering the topology.

Subdivide
Just like the subdivide tool, this method will only subdivide topology
to match the detail given.
Collapse
When topology is too dense, and is smaller than the detail given, edges will
be collapse to fit the detail size appropriately.
Subdivide Collapse
This method combines the two methods, subdividing edges smaller than the
detail size, and collapsing topology.
Detail Flood Fill
When using Constant Detail mode, this option is made available, allowing
you to fill the entire object with a uniform detail, based on the detail size.
Smooth Shading
Toggles whether mesh faces are smooth or flat shaded.
In dynamic-topology mode all faces have the same type of shading.
Optimize
If sculpting begins to slow down while dynamic topology is enabled,
use the *Optimize* button to recalculate the sculpt BVH.
Direction
Determines which direction the model will be symmetrized.
Symmetrize
Uses direction orientation to symmetrize. Since Dyntopo adds details dynamical
may happen that the model goes asymmetric, so this a good tool for that.

Multi-Resolution Modifier
=========================

The Multiresolution Modifier is needed to sculpt. The modifier will subdivide the mesh.
The more subdivision the more computing will be needed. With the Blender stack
no-destructive data, multiresolution sculpting will help when you have a clean topology base mesh.

When sculpting with multiresolution we have the ability sculpt in different level of subdivision,
this mean we can sculpt some details in subdivision level 1 and add more details in
subdivision 2 and go back to subdivision 1 correct some mistakes. While this workflow is
often used, Multiresolution Modifier has some limitations. You may end up with some mesh distortions.
As an advice, add as more details as possible before adding more subdivisions.
Clay brush, SculptDraw work better with multi-resolution sculpting to sculpt secondary forms.

- Step up one multires level :kbd:`PageUp`
- Step down one multires level :kbd:`PageDown`
- Set multires level :kbd:`Ctrl-0` to :kbd:`Ctrl-5`

.. seealso::

Read more about the :doc:`Multi Resolution Modifier &lt;/modeling/modifiers/generate/multiresolution&gt;`.

****************
Hiding &amp; Masking
****************

.. admonition:: Reference
:class: refbox

| Mode:     Sculpt Mode
| Menu:    :menuselection:`Hide/Mask`

It is sometimes useful to isolate parts of a mesh to sculpt on.

Hide
====

Portions of the mesh can be hidden in Sculpt Mode to improve performance and
to access parts of the mesh that would otherwise be difficult to access,
because they are occluded by other parts.

The hidden faces cannot be sculpted on.
Hiding is shared between Edit Mode and Sculpt Mode
(i.e. hiding/unhiding in one mode affects the other mode too.)

Hide Bounding Box :kbd:`H`
To hide a part of a mesh inside the selection.
This works similar to :ref:`Border Select &lt;select-border&gt;` tool.
Hide Bounding Box :kbd:`Shift-H`
To reveal a hidden part of a mesh inside the selection.
Show All :kbd:`Alt-H`
Reveal all hidden parts.
Hide Masked
ToDo.

.. _scupt-mask-menu:

Mask
====

Masking to control which areas of the mesh are influenced by sculpting.
In order to edit the mask, select the *Mask Brush* from the Brush panel.

Masks can be edited across the entire model:

- Invert Mask :kbd:`Ctrl-I`
- Fill Mask
- Clear Mask :kbd:`Alt-M`

.. figure:: /images/sculpt-paint_sculpting_hide-mask.jpg

Black part (hair) is masked.

The `.blend file &lt;https://download.blender.org/demo/test/freestyle_demo_file.blend.zip&gt;`__
from `OHA Studio &lt;http://oha-studios.com/&gt;`__ © Mechanimotion Entertainment.

.. _painting-sculpting-index:

############
Sculpting
############

.. toctree::
:maxdepth: 2

introduction.rst
tools.rst
options.rst
adaptive.rst
hide_mask.rst

************
Introduction
************

Overview
========

*Sculpt Mode* is similar to *Edit Mode* in that it is used to alter the shape of a model,
but Sculpt Mode uses a very different workflow:
instead of dealing with individual elements (vertices, edges, and faces),
an area of the model is altered using a brush.
In other words, instead of selecting a group of vertices,
Sculpt Mode automatically selects vertices based on where the brush is, and modifies them accordingly.

Sculpt Mode
===========

Sculpt mode is selected from the mode menu of the *3D View* header.
Once sculpt mode is activated, the Tool Shelf of the *3D View* will change
to sculpt mode specific panels. The panels will be *Brush*,
*Texture*, *Tool*, *Symmetry*, *Stroke*, *Curve*, *Appearance*, and *Options*.
A red circle will appear and follow the location of the cursor in the 3D View.

.. note::

To have a predictable brush behavior, apply the scale of your mesh.

.. figure:: /images/sculpt-paint_sculpting_mode_selector.png

3D View Mode selector: Sculpt Mode.

.. figure:: /images/sculpt-paint_sculpting_sculpt_brush_circle.png

The cursor in Sculpt Mode.

Sculpt Menus
============

Tool Menu
---------

Here you can select the type of brush preset to use.
*Reset Brush* will return the settings of a brush to its defaults.
You can also set Blender to use the current brush for *Vertex Paint Mode*,
*Weight Paint Mode*, and *Texture Paint Mode* using the toggle buttons.

Keyboard Shortcuts
==================

- Smooth stroke toggle :kbd:`Shift`
- Invert stroke toggle :kbd:`Ctrl`

Cancel Stroke in Progress :kbd:`Esc`
By pressing :kbd:`Esc` while in the middle of a sculpt stroke,
the stroke will be canceled and any changes will be undone.

*******
Options
*******

.. admonition:: Reference
:class: refbox

| Mode:     Sculpt Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Options`

Overlay Panel
=============

When enabled, the brush texture is shown in the viewport.

View
The eye icon is used as a toggle to show or hide the given brush texture.
Alpha
You can change the amount of transparency used when showing the texture using
the Alpha slider.
Stroke Overlay
The brush icon allows you to turn off the viewport overlay during strokes.

Options Panel
=============

Gravity
Factor
Setting the factor allows you to add gravity to your brush strokes,
giving it a draping effect.
Orientation
Using another object, the gravity can be oriented to the set object's local
Z axis, changing the direction of the gravity.
Threaded Sculpt
Takes advantage of multiple CPU processors to improve sculpting performance.
Fast Navigation
For *multiresolution* models, shows low resolution while navigating in the viewport.
Use Deform Only
Limits the activated modifiers on the active object to Deform Modifiers, and Multiresolution.
Constructive modifiers (like Subdivision Surface, Mirror and other) get deactivated,
because they could give inaccurate results.
Show Diffuse Color
Allows the active object to show its diffuse color when sculpting.
Unified Settings
Size
Forces the brush size to be shared across brushes.
Strength
Forces the brush strength to be shared across brushes.
Color
Not Used in Sculpt Mode.
Show Brush
Shows the brush shape in the viewport.
Color (Add/Subtract)
Set the color of the brush ring when its particular effect is active.

Appearance Panel
================

Show Brush
Shows the brush shape in the viewport.
Color (Add/Subtract)
Set the color of the brush ring when its particular effect is active.
Custom Icon
Append an image file to the active brush as an icon.

*****
Tools
*****

.. admonition:: Reference
:class: refbox

| Mode:     Sculpt Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools`

Brush
=====

Brush Type
----------

.. admonition:: Reference
:class: refbox

| Mode:     Sculpt Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Brush`
| Menu:     :menuselection:`Brush --&gt; Sculpt Tool`

.. figure:: /images/sculpt-paint_sculpting_options_brushes.png

Sculpt brushes.

Blob
Pushes mesh outward or inward into a spherical shape with settings to
control the amount of pinching at the edge of the sphere.
Clay :kbd:`C`
Similar to the *Draw* brush, but includes settings to adjust the plane on which the brush acts.
Clay Strips
Similar to the *Clay* brush, but it uses a cube test to define the brush area of influence rather than a sphere.
Crease :kbd:`Shift-C`
Creates sharp indents or ridges by pushing or pulling the mesh, while pinching the vertices together.
Fill/Deepen
Works like the Flatten brush, but only brings vertices below the brush plane upwards.
The inverse of the Scrape brush is to *Deepen* by pushing vertices above the plane downward.
Flatten/Contrast :kbd:`Shift-T`
The *Flatten* brush pulls the vertices towards the *Sculpt plane*.
The inverse of the Flatten brush is the *Contrast*
brush which pushes vertices up or down away from the *Sculpt Plane*.
Grab :kbd:`G`
Used to drag a group of points around. Unlike the other brushes,
*Grab* does not modify different points as the brush is dragged across the model.
Instead, *Grab* selects a group of vertices on mousedown, and pulls them to follow the mouse.
The effect is similar to moving a group of vertices in *Edit Mode* with proportional-editing enabled,
except that *Grab* can make use of other Sculpt Mode options (like textures and symmetry).
Inflate/Deflate :kbd:`I`
Similar to *Draw*, except that vertices in *Inflate* mode are displaced in the direction of their own normals.
Layer :kbd:`L`
This brush is similar to *Draw*, except that the height of the displacement layer is capped.
This creates the appearance of a solid layer being drawn.
This brush does not draw on top of itself; a brush stroke intersects itself.
Releasing the mouse button and starting a new stroke
will reset the depth and paint on top of the previous stroke.

Persistent
ToDo.
Set Persistent Base
ToDo.
Mask :kbd:`M`
Lets you select mesh parts to be unaffected by other brushes by painting vertex colors.
The mask values are shown as grayscale.
I.e the darker a masked area is, the less effect sculpting on it will have.
See also the options of the :ref:`scupt-mask-menu` menu.

Mask Tool
The mask brush has two modes:

Draw
Mask drawing.
Smooth :kbd:`Shift`
Pressing :kbd:`Shift` with the mask brush active will toggle the mask smoothing mode.
Nudge
Moves vertices in the direction of the brush stroke.
Pinch/Magnify :kbd:`P`
Pulls vertices towards the center of the brush.
The inverse setting is *Magnify*, in which vertices are pushed away from the center of the brush.
Rotate
Rotates vertices within the brush in the direction the cursor is moved. The initial drag direction
is the zero angle and by rotating around the center you can create a vortex effect.
Scrape/Peaks
The *Scrape* brush works like the Flatten brush, but only brings vertices above the plane downwards.
The inverse of the Scrape brush is to *Peak* by pushing vertices above the plane up away from the plane.
SculptDraw :kbd:`X`
Moves vertices inward or outward,
based the average normal of the vertices contained within the drawn brush stroke.
Smooth :kbd:`S`
As the name suggests,
eliminates irregularities in the area of the mesh within the brush's
influence by smoothing the positions of the vertices.
Snake Hook :kbd:`K`
Pulls vertices along with the movement of the brush to create long, snake-like forms.

Pinch
Snake-hook tended to loose volume along the stroke,
with pinch &gt; 0.5 its possible to sculpt shapes without loosing volume
Rake
A factor to support grabbing the mesh with rotation following the cursors motion.
Thumb
Similar to the *Nudge* brush, this one flattens the mesh in the brush area,
while moving it in the direction of the brush stroke.
Simplify
This brush collapses short edges (as defined by the detail size) whether or
not the *Collapse Short Edges* option is enabled.
This brush has no effect if dynamic topology is not enabled.
It can be found in the :menuselection:`Brush --&gt; Sculpt Tool` menu.

Common Options
--------------

Radius
This option controls the radius of the brush, measured in pixels.
:kbd:`F` allows you to change the brush size interactively by
dragging the mouse and then :kbd:`LMB` (the texture of the brush should be visible inside the circle).
Typing a number then enter while using :kbd:`F` allows you to enter the size numerically.
Brush size can be affected by enabling the pressure sensitivity icon,
if you are using a :ref:`Graphics Tablet &lt;hardware-tablet&gt;`.
Strength
Controls how much each application of the brush affects the model.
For example, higher values cause the *Draw* brush to add depth to the model more quickly,
and cause the *Smooth* brush to smooth the model more quickly.
This setting is not available for *Grab*, *Snake Hook*, or *Rotate*.

You can change the brush strength interactively by pressing :kbd:`Shift-F`
in the 3D View and then moving the brush and then :kbd:`LMB`.
You can enter the size numerically also while in :kbd:`Shift-F` sizing.
Brush strength can be affected by enabling the pressure sensitivity icon,
if a supported tablet is being used.

.. tip::

If the range of strengths does not seem to fit the model (for example,
if even the lowest strength setting still makes too large of a change on the model)
then you can scale the model (in *Edit Mode*, not *Object Mode*).
Larger sizes will make the brush's effect smaller, and vice versa.

Autosmooth
Sets the amount of smoothing to be applied to each stroke.
Normal Weight :kbd:`Ctrl`
Constrains brush movement along the surface normal.
Especially useful with the *Grab Brush*, can be temporarily enabled by holding :kbd:`Ctrl`.
e.g. Grab brush can be used to push a depression (hole) into the mesh when *Normal Weight* is set.

Applies to *Grab* and *Snake Hook* brushes.
Use Original Normal (padlock icon)
ToDo.
Sculpt Plane
Use this menu to set the plane in which the sculpting takes place.

Area Plane
The plane is located at the average height above/below the vertices within the brush area.
Essentially, this means that the direction is dependent on the surface beneath the brush.

.. (alt) The vertices are pushed towards the plane defined by vertices towards the edge of the brush.
View Plane
ToDo.
X, Y, Z Plane
Global.

ToDo.
Plane Offset
ToDo.
Trim
ToDo.
Front Faces Only
When enabled, the brush only affects vertices that are facing the viewer.
Add/Subtract :kbd:`Ctrl`
Brush direction toggle. :kbd:`Ctrl` pressed while sculpting.
Accumulate
Causes stroke dabs to accumulate on top of each other.

Symmetry/Lock Panel
===================

.. admonition:: Reference
:class: refbox

| Mode:     Sculpt Mode
| Panel:    :menuselection:`Tool Shelf --&gt; Tools --&gt; Symmetry/Lock`
| Menu:     :menuselection:`Sculpt --&gt; Symmetry/Lock`

Mirror
Mirror the brush strokes across the selected local axes.
Note that if you want to alter the directions the axes point in,
you must rotate the model in *Edit Mode*, not *Object Mode*
Radial
These settings allow for radial symmetry in the desired axes.
The number determines how many times the stroke will be repeated within 360 degrees around the central axes.
Feather
Reduces the strength of the stroke where it overlaps the planes of symmetry.
Lock
These three buttons allow you to block any modification/deformation
of your model along selected local axes, while you are sculpting it.
Tiling
Using this option allows you to seamlessly tile your strokes along the given
axes. This allows to create repeating patterns.
Tile Offset
The default tile size is set to one :abbr:`BU (Blender Unit)`. The offset allows the
option to alter the tile size along all three axes.

**************
Stroke &amp; Curve
**************

Stroke
======

.. figure:: /images/sculpt-paint_painting_weight-paint_properties_stroke-panel.png
:align: right

Stroke Panel.

Stroke Method :kbd:`E`
Defines the way brush strokes are applied to the canvas.

Dots
Apply paint on each mouse move step.
Drag Dot
Leaves only one dab on the canvas which can be placed by dragging.
Space
Creates brush stroke as a series of dots,
whose distance (spacing) is determined by the *Spacing* setting.

Spacing
Represents the percentage of the brush radius.
Limit brush application to the distance specified by spacing.
Airbrush
Flow of the brush continues as long as the mouse click is held (spray),
determined by the *Rate* setting.
With others methods the brush only modifies the color when the brush changes its location.
This option is not available for the *Grab* sculpting brush.

Rate
Interval between paints for airbrush.
Anchored
Creates a single dab at the brush location.
Clicking and dragging will resize the dab diameter.

Edge to Edge
The brush location and orientation is determined by a two point circle,
where the first click is one point, and dragging places the second point, opposite from the first.
Line
Clicking and dragging lets you define a line in screen space.
The line dabs are separated by *Spacing*, similar to space strokes.
With :kbd:`Alt` the line stroke is constrained to 45 degree increments.
Curve
Defines a curve in screen space. Curve strokes also uses *Spacing*.

Paint Curves
Stroke Curves are reusable and can be stored and selected by using the :ref:`ui-data-block` menu.
Add Points :kbd:`Ctrl-LMB`
You can define additional curve control points by using :kbd:`Ctrl-LMB`.
The handles can define by dragging the mouse before releasing the mouse button.
Transforming Points
The control points and handles can be dragged around with :kbd:`LMB`.
To ensure the handles of a control point are symmetrical,
drag them around using :kbd:`Shift-LMB`.
A few transform operators are supported such as grabbing, scaling and rotating.
Selection
The handles can be selected individually by using :kbd:`RMB`,
extend the selection by :kbd:`Shift-RMB` and deselect/select all by using :kbd:`A`.
Delete Points :kbd:`X`
To delete a curve point, use :kbd:`X`.
Draw Curve :kbd:`Enter`
To confirm and execute the curved stroke,
press :kbd:`Enter` or use the Draw Curve button.

Jitter
Jitter the position of the brush while painting.
Smooth stroke :kbd:`Shift-S`
Brush lags behind mouse and follows a smoother path.

Radius
Sets the minimum distance from the last point before stroke continues.
Factor
Sets the amount of smoothing.
Input Samples
Recent mouse locations (input samples) are averaged together to smooth brush strokes.

Curve
=====

The Curve allows you to control the *Strength* falloff of the brush.
The falloff is mapped from the center of the brush (left part of the curve)
towards its borders (right part of the curve).
Changing the shape of the curve will make the brush softer or harder.
Read more about using the :ref:`ui-curve-widget`.

.. figure:: /images/sculpt-paint_painting_vertex-paint_options_brush-curve.png

Brush curve example.

**********************
Texture &amp; Texture Mask
**********************

Texture
=======

.. figure:: /images/sculpt-paint_tex-mask_brush-texture.jpg
:width: 250px

Texture options and example.

Use the texture data-block at the bottom of the paint panel to select a pre-loaded image or
procedural texture to use as your brush pattern.

Note that in order to use it, you must have a placeholder material defined,
and that particular texture defined using the Material and Texture buttons.
It is not necessary to have that material or texture applied to any mesh anywhere;
it must only be defined.

The example to the right shows the effects of painting with a flat
(banded) wood texture.
Switching the texture to Rings makes a target/flower type of brush painting pattern.

Texture
In paint modes the texture is used as a color source,
while for sculpting it is used to determine the strength of the brush.
Brush Mapping
Sets the way the texture is applied to the brush stroke.

View Plane
If *View Plane* is enabled, the current view angle is used to project the brush texture onto the model.
I.e. the texture follows the mouse, so it appears that the texture is being dragged across the model.
In 2D painting, the texture moves with the brush.
Area Plane
Projects the brush texture along the local surface normal,
which keeps the texture from stretching when sculpting on a portion of the mesh
that is at an extreme angle to the viewpoint.
Tiled
The *Tile* option tiles the texture across the screen,
so moving the brush appears to move separately from the texture.
The *Tile* option is most useful with tileable images, rather than procedural textures.
3D
The *3D* option allows the brush to take full advantage of procedural textures.
This mode uses vertex coordinates rather than the brush location to determine what area of the texture to use.
Random
Picks a random texture coordinate to sample from for each dab.
Stencil
Stencil mapping works by projecting the paint from the camera space on the mesh or canvas.
Painting is applied only inside the boundaries of the stencil.
The stencil is displayed as an screen space overlay on the viewport.
To the transform the stencil texture and the stencil mask with additional :kbd:`Alt` pressed:

- Translate :kbd:`RMB`, :kbd:`Alt-RMB`
- Scale :kbd:`Shift-RMB`, :kbd:`Alt-Shift-RMB`
- Rotate  :kbd:`Ctrl-RMB`, :kbd:`Alt-Ctrl-RMB`

When using stencil scaling, :kbd:`X` and  :kbd:`Y` are used to constrain the scaling to one axis.
Pressing one of the buttons twice reverts to unconstrained scaling.

Image Aspect
Restore the aspect ratio of the original image to reset stretching introduce by scaling,
(image textures only). This operator can use the tiling and scale values of the brush texture
if the relevant are enabled in Operator panel.
Reset Transform
Restores the position of the stencil.

Angle :kbd:`Ctrl-F`
This is the rotation angle of the texture brush.
It can be changed interactively via :kbd:`Ctrl-F` in the 3D View.
While in the interactive rotation you can enter a value numerically as well.

Rake :kbd:`R`
Angle follows the direction of the brush stroke. Not available with *3D* textures.
(shortcut sculpting only).
Random :kbd:`R`
Angle is randomized per dab.

Random Angle
Constraints the random deviation to a range.

Offset
Offset the texture map placement in X, Y, and Z axes.
Size
Set the scale of the texture in each axis. Not available for *Drag* sculpting textures.
Sample Bias
Value added to texture samples (sculpting only).

Texture Mask
============

Brush strength is masked with a texture.

ToDo.

Pressure Masking
A mask cut-off function. It allows to clip the mask result based on pressure,
creating areas of no paint when low pressure is applied to the brush,
similar to how a real brush would behave.

Off
Deactivated.
Cutoff
Simply selects between zero and one based on stylus pressure.
Ramp
Distributes the mask effect above the pressure value.

.. Todo add GL texture limit.

*******
3D View
*******

Drawing
=======

.. _troubleshooting-depth:

Depth Buffer Glitches
---------------------

Sometimes when setting a large :ref:`clipping range &lt;3dview-view-clip&gt;`
will allow you to see both near and far objects,
but reduces the depth precision resulting in artifacts.

.. list-table::

* - .. figure:: /images/troubleshooting_3dview_graphics_z_fighting_none.png
:width: 180px

Model with no clipping artifacts.

- .. figure:: /images/troubleshooting_3dview_graphics_z_fighting_example.png
:width: 180px

Model with clipping artifacts.

- .. figure:: /images/troubleshooting_3dview_graphics_z_fighting_example_editmode.png
:width: 180px

Mesh with artifacts in Edit Mode.

To avoid this:

- Increase the near clipping when working on large scenes.
- Decrease the far clipping when objects are not viewed at a distance.

When perspective is disabled only the far Clip-End is used, very high values can still give artifacts.

This is **not** specific to Blender, all OpenGL/ DirectX graphics applications have these same limitations.

Objects Invisible in Camera View
--------------------------------

If you have a large scene, viewing it through Camera View may not display all of the Objects in the scene.
One possibility may be that the :ref:`clipping distance &lt;camera-clipping&gt;` of the camera is too low.
The camera will only show objects that fall within the clipping range.

Performance
===========

Slow Drawing
------------

There are a couple of reasons why you may be experiencing a slow viewport.

Old Hardware
Sometimes your hardware, mainly your graphics card, may be too slow to keep up with your model.
Upgrade Graphics Driver
In some cases, slow selection is resolved by using updated drivers.

Slow Selection
--------------

Blender uses OpenGL drawing for selection, some graphics card drivers are slow at performing this operation.

This becomes especially problematic on dense geometry.

Possible Solutions:

OpenGL Occlusion Queries (User Preference)
See :menuselection:`User Preferences --&gt; System --&gt; Selection`

This option defaults *Automatic*, try setting this to *OpenGL Occlusion Queries*,
since there is a significant performance difference under some configurations.
Upgrade Graphics Driver
In some cases, slow selection is resolved by using updated drivers.
*It is generally good to use recent drivers when using 3D software.*
Select Centers (Workaround)
In *Object Mode*, holding :kbd:`Ctrl` while selecting uses the object center point.
While this can be useful on its own, its has the side-effect of not relying on OpenGL selection.
Change Draw Modes (Workaround)
Using *Wireframe* or even *Bounding Box* draw modes can be used to more quickly select different objects.

.. note::

Obviously, the workarounds listed here are not long term solutions,
but it is handy to know if you are stuck using a system with poor OpenGL support.

Ultimately, if none of these options work out it may be worth upgrading your hardware.

Navigation
==========

Lost in Space
-------------

When navigating your scene, you may accidentally navigate away from your scene
and find yourself with a blank viewport. There are two ways to fixes this:

- Select an object in the :doc:`Outliner &lt;/editors/outliner&gt;`,
then zoom to that object with :menuselection:`View --&gt; Show Active` or :kbd:`NumpadPeriod`.
- Use :kbd:`Home` to fit all objects into the 3D View.

Invisible Limit Zooming In
--------------------------

Sometimes when navigating you may be trying to zoom in but it seems that you have hit a limit to how far you can zoom.
This is because Blender uses a central point to orbit around.

In practice this is good for modeling an object which you rotate about a lot to see from all sides
(think of a potter using a wheel).
However, this makes it awkward to explore a scene or model an object from the 'inside', for example.

Solutions
^^^^^^^^^

- Use :ref:`View Dolly &lt;3dview-nav-zoom-dolly&gt;`
- Use :ref:`Walk/Fly modes &lt;3dview-walk-fly&gt;`.
- Use :ref:`Auto Depth &lt;prefs-auto-depth&gt;` and :ref:`Zoom to Mouse Position &lt;prefs-zoom-mouse-pos&gt;`.
These tool will make sure the distance is always the value under the mouse cursor,
- Use :ref:`Border Zoom &lt;3dview-nav-zoom-border&gt;` as it also resets the center-point when zooming.
- Center the view around the mouse cursor :kbd:`Alt-F`.
This will take the position under the cursor and make it your viewpoint center.
- Center the view around the 3D cursor :kbd:`Alt-Home`.
- Use a :abbr:`NDOF (N-Degrees of Freedom)`, also known as a 3D mouse.
See :doc:`configuring peripherals &lt;/getting_started/installing/configuration/hardware&gt;`
for more information.

Tools
=====

.. _troubleshooting-3dview-invalid-selection:

Invalid Selection
-----------------

There are times when selection fails under some configurations,
often this is noticeable in mesh *Edit Mode*,
selecting vertices/edges/faces where random elements are selected.

Internally Blender uses :term:`OpenGL` for selection,
so the graphics card driver relies on giving correct results.

Possible Solutions:

Disable Anti-Aliasing :term:`FSAA, Multi-Sampling &lt;FSAA&gt;`
This is by far the most common cause of selection issues.

There are known problems with some graphics cards when using FSAA/multi-sampling.

You can disable this option by:

- Turning FSAA/multi-sampling off in your graphics card driver options.
- Turning *Multi-Sampling* off in the :ref:`system preferences &lt;prefs-system-multi-sampling&gt;`.
Change Anti-Aliasing Sample Settings
Depending on your OpenGL configuration,
some specific sample settings may work while others fail.

Unfortunately finding working configuration involves trial &amp; error testing.
Upgrade Graphics Driver
As with any OpenGL related issues, using recent drivers can resolve problems.

However, it should be noted that this is a fairly common problem and remains unresolved with many drivers.

*******
Crashes
*******

The most common causes of Blender crashes:

- Running out of memory.
- Issues with graphics hardware or drivers.
- Bugs in Blender.

Firstly, you may be able to recover your work with :menuselection:`File --&gt; Recover Last Session`.

To prevent the problem from happening again, you can check that the graphics drivers are up to date, upgrade your
machine's hardware (the RAM or graphics card), and disable some options that are more memory intensive:

- Reduce undo steps
:menuselection:`User Preferences --&gt; Editing --&gt; Undo Steps`.
- Disable *Region Overlap* and *Triple buffering* at
:menuselection:`User Preferences --&gt; System --&gt; Window Draw Method`.
- Using multisample, anti-aliasing also increases the memory usage and make display slower.
- On Linux, the Window Manager (KDE, Gnome, Unity) may be using hardware accelerated effects
(e.g. window shadows and transparency) that are using up the memory that Blender needs.
Try disabling the desktop effects or switch to a lightweight Window Manager.

Crash Log
=========

When Blender crashes it writes out a text file which contains informations
that may help identify the cause of the crash.

On a crash, a file is written based on the name of the currently loaded blend file,
so ``test.blend`` will create a file called ``test.crash.txt``.
The crash log for unsaved files will be written into the :ref:`temp-dir` directory.

This file contains a log of tools used up until the crash as well as some other debug information.

When reporting bugs on crashes it can be helpful to attach this file to your reports,
especially when others are unable to reproduce the crash.

*****************
Graphics Hardware
*****************

Blender makes use of OpenGL, which is typically hardware accelerated.

This means issues with the graphics card hardware and drivers can impact on Blender's behavior.
This page lists some known issues using Blender on different graphics hardware and how to troubleshoot them.

Performance
===========

When the entire interface is very slow and unresponsive (*even* with the default startup scene),
this is likely a problem with the OpenGL configuration.

Unfortunately, in this situation, you may have to do some of your own tests to find the cause,
below are some common causes and possible solutions.

Upgrade your OpenGL Driver
If you are experiencing any strange graphics problems with Blender,
it is always good to double check if you are using the latest drivers.
Disable Anti-Aliasing :term:`FSAA, Multi-Sampling &lt;FSAA&gt;`
See :ref:`Invalid Selection, Disable Anti-Aliasing &lt;troubleshooting-3dview-invalid-selection&gt;`.
Change the *Window Draw Method*
This is set in the :ref:`system preferences &lt;prefs-system-window-draw&gt;`.
It is selected automatically, however, when experiencing problems it's worth
checking if changing this resolves interface drawing problems.
.. _troubleshooting-index:

##################
Troubleshooting
##################

.. toctree::
:maxdepth: 1

startup.rst
3d_view.rst
gpu.rst
crash.rst
python.rst
recover.rst

Compatibility
=============

Some applications which integrate themselves into your system can cause problem's with Blender.

Here is a list of
`known compatibility issues &lt;https://wiki.blender.org/index.php/Dev:Source/Development/Compatibility&gt;`__.

*************
Python Errors
*************

PYTHONPATH
==========

Blender will fail to load if the ``PYTHONPATH`` is set incorrectly.

This can be useful for Python developers who want to use their own Python installation
however, it will prevent Blender from opening at all when set to an incompatible version of Python.

To see if this is the cause of an error temporary unset the environment variable and reload Blender.

See `Python's documentation &lt;https://docs.python.org/3/using/cmdline.html#envvar-PYTHONPATH&gt;`__ for details.

Pre-Compiled Libraries
======================

While not common practice, Python add-ons can be distributed with their own pre-compiled libraries.
Unlike regular Python scripts, these are not portable between different platforms.

It is possible the library is incompatible with your Blender installation
(attempting to load a library built for a different version of Python,
or loading a 32-bit library on a 64-bit system).

If the add-on contains ``.pyd`` or ``.so`` files,
check that the distribution is compatible with your operating system.

Platform Specific
=================

MS-Windows
----------

Mixed Python Libraries (DLL's)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If Python is raising errors or you have an add-on that just fails when enabled with an error, eg:
``... is not a valid Win32 application.``.

.. figure:: /images/troubleshooting_python.png

A Python traceback.

This may be caused by some inconsistency in the Python libraries.
While Blender comes with its own bundled Python interpreter, duplicate, incompatible libraries can cause problems.

To find out which Python Library caused the Problem check the error message.

This is normally reported somewhere around the bottom line of the traceback.
With the error above you see the problem is caused while trying to import ``_socket``.
This corresponds to either a file named ``_socket.py`` or ``_socket.pyd``.

To help troubleshoot this problem,
the following script can be pasted into the text edit and run to check for duplicate libraries in your search path.
(output will show in :doc:`Command Line Window &lt;/advanced/command_line/introduction&gt;`).

.. code-block:: python

import os
import sys

# Change this based on the library you wish to test
test_lib = "_socket.pyd"

def GetSystemDirectory():
from ctypes import windll, create_string_buffer, sizeof
GetSystemDirectory = windll.kernel32.GetSystemDirectoryA
buffer = create_string_buffer(260)
GetSystemDirectory(buffer, sizeof(buffer))
return os.fsdecode(buffer.value)

def library_search_paths():
return (
# Windows search paths
os.path.dirname(sys.argv[0]),
os.getcwd(),
GetSystemDirectory(),
os.environ["WINDIR"],  # GetWindowsDirectory
*os.environ["PATH"].split(";"),

# regular Python search paths
*sys.path,
)

def check_library_duplicate(libname):
paths = [p for p in library_search_paths()
if os.path.exists(os.path.join(p, libname))]

print("Library %r found in %d locations:" % (libname, len(paths)))
for p in paths:
print("- %r" % p)

check_library_duplicate(test_lib)

***************
Recovering Data
***************

Blender provides a number of ways for the user to recover from mistakes,
and reduce the chance of losing his work in the event of operation errors,
computer failures, or power outages.
There are two ways for you to recover from mistakes or problems:

At the :doc:`User Level &lt;/interface/undo_and_redo&gt;` (relating to *Actions*)

- For your actions, there are options like *Undo*, *Redo* and an *Undo History*,
used to roll back from mistakes under normal operation, or return back to a specific action.
- Blender also has new features like *Repeat* and *Repeat History*,
and the new *Redo Last* which you can use in conjunction with the options listed.

At the :ref:`System Level &lt;troubleshooting-file-recovery&gt;` (relating to *Files*)

- There are options to save your files like
*Auto Save* that saves your file automatically over time, and *Save on Quit*,
which saves your blend-file automatically when you exit Blender.

.. note::

In addition to these functions being enabled by default,
the *Save on Quit* functionality cannot be disabled.

.. _troubleshooting-file-recovery:

Options for Files (System Level)
================================

Save and Auto Save
------------------

Computer crashes, power outages,
or simply forgetting to save can result in the loss or corruption of your work.
To reduce the chance of losing files when those events occur,
Blender can use an *Autosave* function. The *File* tab of the
*User Preferences* allows you to configure the two ways that Blender provides
for you to regress to a previous version of your work.

See :ref:`prefs-auto-save` for details.

Recovering Auto Saves
---------------------

Recover Last Session
:menuselection:`File --&gt; Recover Last Session` will open the ``quit.blend``
that is saved into the :ref:`temp-dir` when you exit Blender.
Note that files in your :ref:`temp-dir` may be deleted when you reboot
(depending on your system configuration).

.. _fig-troubleshooting-file-browser:

.. figure:: /images/troubleshooting_recover_display-file-date.png

File Browser with detailed view selected.

.. tip::

When recovering files, you will navigate to your temporary folder.
It is important, when browsing, to enable the detailed list view.
Otherwise, you will not be able to figure out the dates of the auto-saved blend-files.
(See Fig. :ref:`fig-troubleshooting-file-browser`).

Recover Auto Save
:menuselection:`File --&gt; Recover Auto Save...` allows you to open the Auto Saved file.
After loading the Auto Saved version,
you may save it over the current file in your working directory as a normal blend-file.

.. important::

When recovering an Auto Saved file, you will lose any changes made since the last *Auto Save* was
performed. Only **one** *Auto Saved* file exists for each project
(i.e. Blender does not keep older versions.
Hence, you will not be able to go back more than a few minutes with this tool).

*******
Startup
*******

Blender
=======

There are some common causes for problems when using Blender. If you cannot find a solution to your problem here,
try asking the :doc:`community &lt;/getting_started/about/community&gt;` for help.

If Blender crashes on startup there are a few things to check for:

- See if your computer meets the `minimum requirements &lt;https://www.blender.org/download/requirements/&gt;`__.
- Confirm that your graphics card is supported and that the drivers support at least OpenGL 2.1.
- Make sure you are using the correct Blender version (32 or 64 bit) for your architecture.

Known causes listed below.

Python
======

If you get an error on startup like:

.. code-block:: python

Fatal Python error: Py_Initialize: unable to load the file system codec

you may have set your system's ``PYTHONPATH`` environment variable.

In this case, Blender's bundled Python will attempt to use the ``PYTHONPATH``.
If the Python version is different from the version used by Blender, this will crash Blender on startup.

To solve the problem, either clear the ``PYTHONPATH`` before starting Blender
(can also be done with a launcher script),
or set it to a compatible Python version.

#########
Readme
#########

The Blender Manual is Blender's official project to provide the user with a clear,
concise and up-to-date description of Blender's functioning in the current version.

Complementary projects are:

- `StackExchange (Q&amp;A) &lt;https://blender.stackexchange.com&gt;`__.
- `Blender Cloud &lt;https://cloud.blender.org/&gt;`__.
- `Python API reference &lt;https://www.blender.org/api/blender_python_api_current&gt;`__.

**************
Project Status
**************

Currently, there are some old 2.4x parts of the manual that need to be updated.
There are also tasks on the `current open tasks &lt;https://developer.blender.org/project/profile/53&gt;`__.

*******************
Building the Manual
*******************

- See the `installing &lt;manual/about/contribute/install/&gt;`__
page for building the manual.
- See the `contribute &lt;manual/about/contribute/&gt;`__
page for an explanation on the full work-flow and other tips.

.. seealso:: See :doc:`releases.rst` for information on releasing new versions of the manual and old revisions.

***********************
Blender Manual Releases
***********************

.. (TODO) Include some information on the release process here.

2.75
====

:Main: rBM634
:Languages: None

2.76
====

:Main: rBM1413
:Languages: rBMT208

2.77
====

:Main: rBM2856
:Languages: rBMT517

2.78
====

:Main: rBM3427
:Languages: rBMT1443

2.79
====

</plainxml>
