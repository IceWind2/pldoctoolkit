<?xml version="1.0" encoding="utf-8" ?>
<plainxml>RESET(7)                PostgreSQL 9.6.1 Documentation                RESET(7)



NAME
       RESET - restore the value of a run-time parameter to the default value

SYNOPSIS
       RESET configuration_parameter
       RESET ALL

DESCRIPTION
       RESET restores run-time parameters to their default values.  RESET is
       an alternative spelling for

           SET configuration_parameter TO DEFAULT

       Refer to SET(7) for details.

       The default value is defined as the value that the parameter would have
       had, if no SET had ever been issued for it in the current session. The
       actual source of this value might be a compiled-in default, the
       configuration file, command-line options, or per-database or per-user
       default settings. This is subtly different from defining it as "the
       value that the parameter had at session start", because if the value
       came from the configuration file, it will be reset to whatever is
       specified by the configuration file now. See Chapter 19, Server
       Configuration, in the documentation for details.

       The transactional behavior of RESET is the same as SET: its effects
       will be undone by transaction rollback.

PARAMETERS
       configuration_parameter
           Name of a settable run-time parameter. Available parameters are
           documented in Chapter 19, Server Configuration, in the
           documentation and on the SET(7) reference page.

       ALL
           Resets all settable run-time parameters to default values.

EXAMPLES
       Set the timezone configuration variable to its default value:

           RESET timezone;

COMPATIBILITY
       RESET is a PostgreSQL extension.

SEE ALSO
       SET(7), SHOW(7)



PostgreSQL 9.6.1                     2016                             RESET(7)
ALTER EXTENSION(7)      PostgreSQL 9.6.1 Documentation      ALTER EXTENSION(7)



NAME
       ALTER_EXTENSION - change the definition of an extension

SYNOPSIS
       ALTER EXTENSION name UPDATE [ TO new_version ]
       ALTER EXTENSION name SET SCHEMA new_schema
       ALTER EXTENSION name ADD member_object
       ALTER EXTENSION name DROP member_object

       where member_object is:

         ACCESS METHOD object_name |
         AGGREGATE aggregate_name ( aggregate_signature ) |
         CAST (source_type AS target_type) |
         COLLATION object_name |
         CONVERSION object_name |
         DOMAIN object_name |
         EVENT TRIGGER object_name |
         FOREIGN DATA WRAPPER object_name |
         FOREIGN TABLE object_name |
         FUNCTION function_name ( [ [ argmode ] [ argname ] argtype [, ...] ] ) |
         MATERIALIZED VIEW object_name |
         OPERATOR operator_name (left_type, right_type) |
         OPERATOR CLASS object_name USING index_method |
         OPERATOR FAMILY object_name USING index_method |
         [ PROCEDURAL ] LANGUAGE object_name |
         SCHEMA object_name |
         SEQUENCE object_name |
         SERVER object_name |
         TABLE object_name |
         TEXT SEARCH CONFIGURATION object_name |
         TEXT SEARCH DICTIONARY object_name |
         TEXT SEARCH PARSER object_name |
         TEXT SEARCH TEMPLATE object_name |
         TRANSFORM FOR type_name LANGUAGE lang_name |
         TYPE object_name |
         VIEW object_name

       and aggregate_signature is:

       * |
       [ argmode ] [ argname ] argtype [ , ... ] |
       [ [ argmode ] [ argname ] argtype [ , ... ] ] ORDER BY [ argmode ] [ argname ] argtype [ , ... ]

DESCRIPTION
       ALTER EXTENSION changes the definition of an installed extension. There
       are several subforms:

       UPDATE
           This form updates the extension to a newer version. The extension
           must supply a suitable update script (or series of scripts) that
           can modify the currently-installed version into the requested
           version.

       SET SCHEMA
           This form moves the extension's objects into another schema. The
           extension has to be relocatable for this command to succeed.

       ADD member_object
           This form adds an existing object to the extension. This is mainly
           useful in extension update scripts. The object will subsequently be
           treated as a member of the extension; notably, it can only be
           dropped by dropping the extension.

       DROP member_object
           This form removes a member object from the extension. This is
           mainly useful in extension update scripts. The object is not
           dropped, only disassociated from the extension.
       See Section 36.15, "Packaging Related Objects into an Extension", in
       the documentation for more information about these operations.

       You must own the extension to use ALTER EXTENSION. The ADD/DROP forms
       require ownership of the added/dropped object as well.

PARAMETERS
       name
           The name of an installed extension.

       new_version
           The desired new version of the extension. This can be written as
           either an identifier or a string literal. If not specified, ALTER
           EXTENSION UPDATE attempts to update to whatever is shown as the
           default version in the extension's control file.

       new_schema
           The new schema for the extension.

       object_name
       aggregate_name
       function_name
       operator_name
           The name of an object to be added to or removed from the extension.
           Names of tables, aggregates, domains, foreign tables, functions,
           operators, operator classes, operator families, sequences, text
           search objects, types, and views can be schema-qualified.

       source_type
           The name of the source data type of the cast.

       target_type
           The name of the target data type of the cast.

<!-- e06c3d92-4723-4dc4-a00a-ed8adc236e70 <=< ACCEPT -->       argmode
           The mode of a function or aggregate argument: IN, OUT, INOUT, or
           VARIADIC. If omitted, the default is IN. Note that ALTER EXTENSION
           does not actually pay any attention to OUT arguments, since only
           the input arguments are needed to determine the function's
           identity. So it is sufficient to list the IN, INOUT, and VARIADIC
           arguments.

       argname
           The name of a function or aggregate argument. Note that ALTER
           EXTENSION does not actually pay any attention to argument names,
           since only the argument data types are needed to determine the
           function's identity.

       argtype
           The data type of a function or aggregate argument.<!-- ACCEPT >=> e06c3d92-4723-4dc4-a00a-ed8adc236e70 -->

<!-- 475300f3-c025-4674-80e5-f48559d8b392 <=< ACCEPT -->       left_type
       right_type
           The data type(s) of the operator's arguments (optionally
           schema-qualified). Write NONE for the missing argument of a prefix
           or postfix operator.

       PROCEDURAL
           This is a noise word.

       type_name
           The name of the data type of the transform.

       lang_name
           The name of the language of the transform.<!-- ACCEPT >=> 475300f3-c025-4674-80e5-f48559d8b392 -->

EXAMPLES
       To update the hstore extension to version 2.0:

           ALTER EXTENSION hstore UPDATE TO '2.0';

       To change the schema of the hstore extension to utils:

           ALTER EXTENSION hstore SET SCHEMA utils;

       To add an existing function to the hstore extension:

           ALTER EXTENSION hstore ADD FUNCTION populate_record(anyelement, hstore);

COMPATIBILITY
       ALTER EXTENSION is a PostgreSQL extension.

SEE ALSO
       CREATE EXTENSION (CREATE_EXTENSION(7)), DROP EXTENSION
       (DROP_EXTENSION(7))



PostgreSQL 9.6.1                     2016                   ALTER EXTENSION(7)
SET CONSTRAINTS(7)      PostgreSQL 9.6.1 Documentation      SET CONSTRAINTS(7)



NAME
       SET_CONSTRAINTS - set constraint check timing for the current
       transaction

SYNOPSIS
       SET CONSTRAINTS { ALL | name [, ...] } { DEFERRED | IMMEDIATE }

DESCRIPTION
       SET CONSTRAINTS sets the behavior of constraint checking within the
       current transaction.  IMMEDIATE constraints are checked at the end of
       each statement.  DEFERRED constraints are not checked until transaction
       commit. Each constraint has its own IMMEDIATE or DEFERRED mode.

       Upon creation, a constraint is given one of three characteristics:
       DEFERRABLE INITIALLY DEFERRED, DEFERRABLE INITIALLY IMMEDIATE, or NOT
       DEFERRABLE. The third class is always IMMEDIATE and is not affected by
       the SET CONSTRAINTS command. The first two classes start every
       transaction in the indicated mode, but their behavior can be changed
       within a transaction by SET CONSTRAINTS.

       SET CONSTRAINTS with a list of constraint names changes the mode of
       just those constraints (which must all be deferrable). Each constraint
       name can be schema-qualified. The current schema search path is used to
       find the first matching name if no schema name is specified.  SET
       CONSTRAINTS ALL changes the mode of all deferrable constraints.

       When SET CONSTRAINTS changes the mode of a constraint from DEFERRED to
       IMMEDIATE, the new mode takes effect retroactively: any outstanding
       data modifications that would have been checked at the end of the
       transaction are instead checked during the execution of the SET
       CONSTRAINTS command. If any such constraint is violated, the SET
       CONSTRAINTS fails (and does not change the constraint mode). Thus, SET
       CONSTRAINTS can be used to force checking of constraints to occur at a
       specific point in a transaction.

       Currently, only UNIQUE, PRIMARY KEY, REFERENCES (foreign key), and
       EXCLUDE constraints are affected by this setting.  NOT NULL and CHECK
       constraints are always checked immediately when a row is inserted or
       modified (not at the end of the statement). Uniqueness and exclusion
       constraints that have not been declared DEFERRABLE are also checked
       immediately.

       The firing of triggers that are declared as "constraint triggers" is
       also controlled by this setting -- they fire at the same time that the
       associated constraint should be checked.

NOTES
       Because PostgreSQL does not require constraint names to be unique
       within a schema (but only per-table), it is possible that there is more
       than one match for a specified constraint name. In this case SET
       CONSTRAINTS will act on all matches. For a non-schema-qualified name,
       once a match or matches have been found in some schema in the search
       path, schemas appearing later in the path are not searched.

       This command only alters the behavior of constraints within the current
       transaction. Issuing this outside of a transaction block emits a
       warning and otherwise has no effect.

COMPATIBILITY
       This command complies with the behavior defined in the SQL standard,
       except for the limitation that, in PostgreSQL, it does not apply to NOT
       NULL and CHECK constraints. Also, PostgreSQL checks non-deferrable
       uniqueness constraints immediately, not at end of statement as the
       standard would suggest.



PostgreSQL 9.6.1                     2016                   SET CONSTRAINTS(7)
SECURITY LABEL(7)       PostgreSQL 9.6.1 Documentation       SECURITY LABEL(7)



NAME
       SECURITY_LABEL - define or change a security label applied to an object

SYNOPSIS
       SECURITY LABEL [ FOR provider ] ON
       {
         TABLE object_name |
         COLUMN table_name.column_name |
         AGGREGATE aggregate_name ( aggregate_signature ) |
         DATABASE object_name |
         DOMAIN object_name |
         EVENT TRIGGER object_name |
         FOREIGN TABLE object_name
         FUNCTION function_name ( [ [ argmode ] [ argname ] argtype [, ...] ] ) |
         LARGE OBJECT large_object_oid |
         MATERIALIZED VIEW object_name |
         [ PROCEDURAL ] LANGUAGE object_name |
         ROLE object_name |
         SCHEMA object_name |
         SEQUENCE object_name |
         TABLESPACE object_name |
         TYPE object_name |
         VIEW object_name
       } IS 'label'

       where aggregate_signature is:

       * |
       [ argmode ] [ argname ] argtype [ , ... ] |
       [ [ argmode ] [ argname ] argtype [ , ... ] ] ORDER BY [ argmode ] [ argname ] argtype [ , ... ]

DESCRIPTION
       SECURITY LABEL applies a security label to a database object. An
       arbitrary number of security labels, one per label provider, can be
       associated with a given database object. Label providers are loadable
       modules which register themselves by using the function
       register_label_provider.

           Note
           register_label_provider is not an SQL function; it can only be
           called from C code loaded into the backend.

       The label provider determines whether a given label is valid and
       whether it is permissible to assign that label to a given object. The
       meaning of a given label is likewise at the discretion of the label
       provider.  PostgreSQL places no restrictions on whether or how a label
       provider must interpret security labels; it merely provides a mechanism
       for storing them. In practice, this facility is intended to allow
       integration with label-based mandatory access control (MAC) systems
       such as SE-Linux. Such systems make all access control decisions based
       on object labels, rather than traditional discretionary access control
       (DAC) concepts such as users and groups.

PARAMETERS
       object_name
       table_name.column_name
       aggregate_name
       function_name
           The name of the object to be labeled. Names of tables, aggregates,
           domains, foreign tables, functions, sequences, types, and views can
           be schema-qualified.

       provider
           The name of the provider with which this label is to be associated.
           The named provider must be loaded and must consent to the proposed
           labeling operation. If exactly one provider is loaded, the provider
           name may be omitted for brevity.

<!-- e06c3d92-4723-4dc4-a00a-ed8adc236e70 <=< ACCEPT -->       argmode
           The mode of a function or aggregate argument: IN, OUT, INOUT, or
           VARIADIC. If omitted, the default is IN. Note that SECURITY LABEL
           does not actually pay any attention to OUT arguments, since only
           the input arguments are needed to determine the function's
           identity. So it is sufficient to list the IN, INOUT, and VARIADIC
           arguments.

       argname
           The name of a function or aggregate argument. Note that SECURITY
           LABEL does not actually pay any attention to argument names, since
           only the argument data types are needed to determine the function's
           identity.

       argtype
           The data type of a function or aggregate argument.<!-- ACCEPT >=> e06c3d92-4723-4dc4-a00a-ed8adc236e70 -->

       large_object_oid
           The OID of the large object.

       PROCEDURAL
           This is a noise word.

       label
           The new security label, written as a string literal; or NULL to
           drop the security label.

EXAMPLES
       The following example shows how the security label of a table might be
       changed.

           SECURITY LABEL FOR selinux ON TABLE mytable IS 'system_u:object_r:sepgsql_table_t:s0';

COMPATIBILITY
       There is no SECURITY LABEL command in the SQL standard.

SEE ALSO
       sepgsql, src/test/modules/dummy_seclabel



PostgreSQL 9.6.1                     2016                    SECURITY LABEL(7)
DO(7)                   PostgreSQL 9.6.1 Documentation                   DO(7)



NAME
       DO - execute an anonymous code block

SYNOPSIS
       DO [ LANGUAGE lang_name ] code

DESCRIPTION
       DO executes an anonymous code block, or in other words a transient
       anonymous function in a procedural language.

       The code block is treated as though it were the body of a function with
       no parameters, returning void. It is parsed and executed a single time.

       The optional LANGUAGE clause can be written either before or after the
       code block.

PARAMETERS
       code
           The procedural language code to be executed. This must be specified
           as a string literal, just as in CREATE FUNCTION. Use of a
           dollar-quoted literal is recommended.

       lang_name
           The name of the procedural language the code is written in. If
           omitted, the default is plpgsql.

NOTES
       The procedural language to be used must already have been installed
       into the current database by means of CREATE LANGUAGE.  plpgsql is
       installed by default, but other languages are not.

       The user must have USAGE privilege for the procedural language, or must
       be a superuser if the language is untrusted. This is the same privilege
       requirement as for creating a function in the language.

EXAMPLES
       Grant all privileges on all views in schema public to role webuser:

           DO $$DECLARE r record;
           BEGIN
               FOR r IN SELECT table_schema, table_name FROM information_schema.tables
                        WHERE table_type = 'VIEW' AND table_schema = 'public'
               LOOP
                   EXECUTE 'GRANT ALL ON ' || quote_ident(r.table_schema) || '.' || quote_ident(r.table_name) || ' TO webuser';
               END LOOP;
           END$$;

COMPATIBILITY
       There is no DO statement in the SQL standard.

SEE ALSO
       CREATE LANGUAGE (CREATE_LANGUAGE(7))



PostgreSQL 9.6.1                     2016                                DO(7)
CREATE DOMAIN(7)        PostgreSQL 9.6.1 Documentation        CREATE DOMAIN(7)



NAME
       CREATE_DOMAIN - define a new domain

SYNOPSIS
       CREATE DOMAIN name [ AS ] data_type
           [ COLLATE collation ]
           [ DEFAULT expression ]
           [ constraint [ ... ] ]

       where constraint is:

       [ CONSTRAINT constraint_name ]
       { NOT NULL | NULL | CHECK (expression) }

DESCRIPTION
       CREATE DOMAIN creates a new domain. A domain is essentially a data type
       with optional constraints (restrictions on the allowed set of values).
       The user who defines a domain becomes its owner.

       If a schema name is given (for example, CREATE DOMAIN myschema.mydomain
       ...) then the domain is created in the specified schema. Otherwise it
       is created in the current schema. The domain name must be unique among
       the types and domains existing in its schema.

       Domains are useful for abstracting common constraints on fields into a
       single location for maintenance. For example, several tables might
       contain email address columns, all requiring the same CHECK constraint
       to verify the address syntax. Define a domain rather than setting up
       each table's constraint individually.

       To be able to create a domain, you must have USAGE privilege on the
       underlying type.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of a domain to be created.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       data_type
           The underlying data type of the domain. This can include array
           specifiers.

       collation
           An optional collation for the domain. If no collation is specified,
           the underlying data type's default collation is used. The
           underlying type must be collatable if COLLATE is specified.

       DEFAULT expression
           The DEFAULT clause specifies a default value for columns of the
           domain data type. The value is any variable-free expression (but
           subqueries are not allowed). The data type of the default
           expression must match the data type of the domain. If no default
           value is specified, then the default value is the null value.

           The default expression will be used in any insert operation that
           does not specify a value for the column. If a default value is
           defined for a particular column, it overrides any default
           associated with the domain. In turn, the domain default overrides
           any default value associated with the underlying data type.

       CONSTRAINT constraint_name
           An optional name for a constraint. If not specified, the system
           generates a name.

       NOT NULL
           Values of this domain are prevented from being null (but see notes
           below).

       NULL
           Values of this domain are allowed to be null. This is the default.

           This clause is only intended for compatibility with nonstandard SQL
           databases. Its use is discouraged in new applications.

       CHECK (expression)
           CHECK clauses specify integrity constraints or tests which values
           of the domain must satisfy. Each constraint must be an expression
           producing a Boolean result. It should use the key word VALUE to
           refer to the value being tested. Expressions evaluating to TRUE or
           UNKNOWN succeed. If the expression produces a FALSE result, an
           error is reported and the value is not allowed to be converted to
           the domain type.

           Currently, CHECK expressions cannot contain subqueries nor refer to
           variables other than VALUE.

           When a domain has multiple CHECK constraints, they will be tested
           in alphabetical order by name. (PostgreSQL versions before 9.5 did
           not honor any particular firing order for CHECK constraints.)

NOTES
       Domain constraints, particularly NOT NULL, are checked when converting
       a value to the domain type. It is possible for a column that is
       nominally of the domain type to read as null despite there being such a
       constraint. For example, this can happen in an outer-join query, if the
       domain column is on the nullable side of the outer join. A more subtle
       example is

           INSERT INTO tab (domcol) VALUES ((SELECT domcol FROM tab WHERE false));

       The empty scalar sub-SELECT will produce a null value that is
       considered to be of the domain type, so no further constraint checking
       is applied to it, and the insertion will succeed.

       It is very difficult to avoid such problems, because of SQL's general
       assumption that a null value is a valid value of every data type. Best
       practice therefore is to design a domain's constraints so that a null
       value is allowed, and then to apply column NOT NULL constraints to
       columns of the domain type as needed, rather than directly to the
       domain type.

EXAMPLES
       This example creates the us_postal_code data type and then uses the
       type in a table definition. A regular expression test is used to verify
       that the value looks like a valid US postal code:

           CREATE DOMAIN us_postal_code AS TEXT
           CHECK(
              VALUE ~ '^\d{5}$'
           OR VALUE ~ '^\d{5}-\d{4}$'
           );

           CREATE TABLE us_snail_addy (
             address_id SERIAL PRIMARY KEY,
             street1 TEXT NOT NULL,
             street2 TEXT,
             street3 TEXT,
             city TEXT NOT NULL,
             postal us_postal_code NOT NULL
           );

COMPATIBILITY
       The command CREATE DOMAIN conforms to the SQL standard.

SEE ALSO
       ALTER DOMAIN (ALTER_DOMAIN(7)), DROP DOMAIN (DROP_DOMAIN(7))



PostgreSQL 9.6.1                     2016                     CREATE DOMAIN(7)
ALTER DEFAULT PRIVILEGESPostgreSQL 9.6.1 DocumentatALTER DEFAULT PRIVILEGES(7)



NAME
       ALTER_DEFAULT_PRIVILEGES - define default access privileges

SYNOPSIS
       ALTER DEFAULT PRIVILEGES
           [ FOR { ROLE | USER } target_role [, ...] ]
           [ IN SCHEMA schema_name [, ...] ]
           abbreviated_grant_or_revoke

       where abbreviated_grant_or_revoke is one of:

       GRANT { { SELECT | INSERT | UPDATE | DELETE | TRUNCATE | REFERENCES | TRIGGER }
           [, ...] | ALL [ PRIVILEGES ] }
           ON TABLES
           TO { [ GROUP ] role_name | PUBLIC } [, ...] [ WITH GRANT OPTION ]

       GRANT { { USAGE | SELECT | UPDATE }
           [, ...] | ALL [ PRIVILEGES ] }
           ON SEQUENCES
           TO { [ GROUP ] role_name | PUBLIC } [, ...] [ WITH GRANT OPTION ]

       GRANT { EXECUTE | ALL [ PRIVILEGES ] }
           ON FUNCTIONS
           TO { [ GROUP ] role_name | PUBLIC } [, ...] [ WITH GRANT OPTION ]

       GRANT { USAGE | ALL [ PRIVILEGES ] }
           ON TYPES
           TO { [ GROUP ] role_name | PUBLIC } [, ...] [ WITH GRANT OPTION ]

       REVOKE [ GRANT OPTION FOR ]
           { { SELECT | INSERT | UPDATE | DELETE | TRUNCATE | REFERENCES | TRIGGER }
           [, ...] | ALL [ PRIVILEGES ] }
           ON TABLES
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { { USAGE | SELECT | UPDATE }
           [, ...] | ALL [ PRIVILEGES ] }
           ON SEQUENCES
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { EXECUTE | ALL [ PRIVILEGES ] }
           ON FUNCTIONS
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { USAGE | ALL [ PRIVILEGES ] }
           ON TYPES
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

DESCRIPTION
       ALTER DEFAULT PRIVILEGES allows you to set the privileges that will be
       applied to objects created in the future. (It does not affect
       privileges assigned to already-existing objects.) Currently, only the
       privileges for tables (including views and foreign tables), sequences,
       functions, and types (including domains) can be altered.

       You can change default privileges only for objects that will be created
       by yourself or by roles that you are a member of. The privileges can be
       set globally (i.e., for all objects created in the current database),
       or just for objects created in specified schemas. Default privileges
       that are specified per-schema are added to whatever the global default
       privileges are for the particular object type.

       As explained under GRANT(7), the default privileges for any object type
       normally grant all grantable permissions to the object owner, and may
       grant some privileges to PUBLIC as well. However, this behavior can be
       changed by altering the global default privileges with ALTER DEFAULT
       PRIVILEGES.

   Parameters
       target_role
           The name of an existing role of which the current role is a member.
           If FOR ROLE is omitted, the current role is assumed.

       schema_name
           The name of an existing schema. If specified, the default
           privileges are altered for objects later created in that schema. If
           IN SCHEMA is omitted, the global default privileges are altered.

       role_name
           The name of an existing role to grant or revoke privileges for.
           This parameter, and all the other parameters in
           abbreviated_grant_or_revoke, act as described under GRANT(7) or
           REVOKE(7), except that one is setting permissions for a whole class
           of objects rather than specific named objects.

NOTES
       Use psql(1)'s \ddp command to obtain information about existing
       assignments of default privileges. The meaning of the privilege values
       is the same as explained for \dp under GRANT(7).

       If you wish to drop a role for which the default privileges have been
       altered, it is necessary to reverse the changes in its default
       privileges or use DROP OWNED BY to get rid of the default privileges
       entry for the role.

EXAMPLES
       Grant SELECT privilege to everyone for all tables (and views) you
       subsequently create in schema myschema, and allow role webuser to
       INSERT into them too:

           ALTER DEFAULT PRIVILEGES IN SCHEMA myschema GRANT SELECT ON TABLES TO PUBLIC;
           ALTER DEFAULT PRIVILEGES IN SCHEMA myschema GRANT INSERT ON TABLES TO webuser;

       Undo the above, so that subsequently-created tables won't have any more
       permissions than normal:

           ALTER DEFAULT PRIVILEGES IN SCHEMA myschema REVOKE SELECT ON TABLES FROM PUBLIC;
           ALTER DEFAULT PRIVILEGES IN SCHEMA myschema REVOKE INSERT ON TABLES FROM webuser;

       Remove the public EXECUTE permission that is normally granted on
       functions, for all functions subsequently created by role admin:

           ALTER DEFAULT PRIVILEGES FOR ROLE admin REVOKE EXECUTE ON FUNCTIONS FROM PUBLIC;

COMPATIBILITY
       There is no ALTER DEFAULT PRIVILEGES statement in the SQL standard.

SEE ALSO
       GRANT(7), REVOKE(7)



PostgreSQL 9.6.1                     2016          ALTER DEFAULT PRIVILEGES(7)
ALTER EVENT TRIGGER(7)  PostgreSQL 9.6.1 Documentation  ALTER EVENT TRIGGER(7)



NAME
       ALTER_EVENT_TRIGGER - change the definition of an event trigger

SYNOPSIS
       ALTER EVENT TRIGGER name DISABLE
       ALTER EVENT TRIGGER name ENABLE [ REPLICA | ALWAYS ]
       ALTER EVENT TRIGGER name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER EVENT TRIGGER name RENAME TO new_name

DESCRIPTION
       ALTER EVENT TRIGGER changes properties of an existing event trigger.

       You must be superuser to alter an event trigger.

PARAMETERS
       name
           The name of an existing trigger to alter.

       new_owner
           The user name of the new owner of the event trigger.

       new_name
           The new name of the event trigger.

       DISABLE/ENABLE [ REPLICA | ALWAYS ] TRIGGER
           These forms configure the firing of event triggers. A disabled
           trigger is still known to the system, but is not executed when its
           triggering event occurs. See also session_replication_role.

COMPATIBILITY
       There is no ALTER EVENT TRIGGER statement in the SQL standard.

SEE ALSO
       CREATE EVENT TRIGGER (CREATE_EVENT_TRIGGER(7)), DROP EVENT TRIGGER
       (DROP_EVENT_TRIGGER(7))



PostgreSQL 9.6.1                     2016               ALTER EVENT TRIGGER(7)
DISCARD(7)              PostgreSQL 9.6.1 Documentation              DISCARD(7)



NAME
       DISCARD - discard session state

SYNOPSIS
       DISCARD { ALL | PLANS | SEQUENCES | TEMPORARY | TEMP }

DESCRIPTION
       DISCARD releases internal resources associated with a database session.
       This command is useful for partially or fully resetting the session's
       state. There are several subcommands to release different types of
       resources; the DISCARD ALL variant subsumes all the others, and also
       resets additional state.

PARAMETERS
       PLANS
           Releases all cached query plans, forcing re-planning to occur the
           next time the associated prepared statement is used.

       SEQUENCES
           Discards all cached sequence-related state, including
           currval()/lastval() information and any preallocated sequence
           values that have not yet been returned by nextval(). (See CREATE
           SEQUENCE (CREATE_SEQUENCE(7)) for a description of preallocated
           sequence values.)

       TEMPORARY or TEMP
           Drops all temporary tables created in the current session.

       ALL
           Releases all temporary resources associated with the current
           session and resets the session to its initial state. Currently,
           this has the same effect as executing the following sequence of
           statements:

               SET SESSION AUTHORIZATION DEFAULT;
               RESET ALL;
               DEALLOCATE ALL;
               CLOSE ALL;
               UNLISTEN *;
               SELECT pg_advisory_unlock_all();
               DISCARD PLANS;
               DISCARD SEQUENCES;
               DISCARD TEMP;

NOTES
       DISCARD ALL cannot be executed inside a transaction block.

COMPATIBILITY
       DISCARD is a PostgreSQL extension.



PostgreSQL 9.6.1                     2016                           DISCARD(7)
SAVEPOINT(7)            PostgreSQL 9.6.1 Documentation            SAVEPOINT(7)



NAME
       SAVEPOINT - define a new savepoint within the current transaction

SYNOPSIS
       SAVEPOINT savepoint_name

DESCRIPTION
       SAVEPOINT establishes a new savepoint within the current transaction.

       A savepoint is a special mark inside a transaction that allows all
       commands that are executed after it was established to be rolled back,
       restoring the transaction state to what it was at the time of the
       savepoint.

PARAMETERS
       savepoint_name
           The name to give to the new savepoint.

NOTES
       Use ROLLBACK TO SAVEPOINT (ROLLBACK_TO_SAVEPOINT(7)) to rollback to a
       savepoint. Use RELEASE SAVEPOINT (RELEASE_SAVEPOINT(7)) to destroy a
       savepoint, keeping the effects of commands executed after it was
       established.

       Savepoints can only be established when inside a transaction block.
       There can be multiple savepoints defined within a transaction.

EXAMPLES
       To establish a savepoint and later undo the effects of all commands
       executed after it was established:

           BEGIN;
               INSERT INTO table1 VALUES (1);
               SAVEPOINT my_savepoint;
               INSERT INTO table1 VALUES (2);
               ROLLBACK TO SAVEPOINT my_savepoint;
               INSERT INTO table1 VALUES (3);
           COMMIT;

       The above transaction will insert the values 1 and 3, but not 2.

<!-- 01216d86-5036-4c40-bcfc-62c9554a3012 <=< ACCEPT -->       To establish and later destroy a savepoint:

           BEGIN;
               INSERT INTO table1 VALUES (3);
               SAVEPOINT my_savepoint;
               INSERT INTO table1 VALUES (4);
               RELEASE SAVEPOINT my_savepoint;
           COMMIT;

       The above transaction will insert both 3 and 4.<!-- ACCEPT >=> 01216d86-5036-4c40-bcfc-62c9554a3012 -->

COMPATIBILITY
       SQL requires a savepoint to be destroyed automatically when another
       savepoint with the same name is established. In PostgreSQL, the old
       savepoint is kept, though only the more recent one will be used when
       rolling back or releasing. (Releasing the newer savepoint with RELEASE
       SAVEPOINT will cause the older one to again become accessible to
       ROLLBACK TO SAVEPOINT and RELEASE SAVEPOINT.) Otherwise, SAVEPOINT is
       fully SQL conforming.

SEE ALSO
       BEGIN(7), COMMIT(7), RELEASE SAVEPOINT (RELEASE_SAVEPOINT(7)),
       ROLLBACK(7), ROLLBACK TO SAVEPOINT (ROLLBACK_TO_SAVEPOINT(7))



PostgreSQL 9.6.1                     2016                         SAVEPOINT(7)
ALTER TABLE(7)          PostgreSQL 9.6.1 Documentation          ALTER TABLE(7)



NAME
       ALTER_TABLE - change the definition of a table

SYNOPSIS
       ALTER TABLE [ IF EXISTS ] [ ONLY ] name [ * ]
           action [, ... ]
       ALTER TABLE [ IF EXISTS ] [ ONLY ] name [ * ]
           RENAME [ COLUMN ] column_name TO new_column_name
       ALTER TABLE [ IF EXISTS ] [ ONLY ] name [ * ]
           RENAME CONSTRAINT constraint_name TO new_constraint_name
       ALTER TABLE [ IF EXISTS ] name
           RENAME TO new_name
       ALTER TABLE [ IF EXISTS ] name
           SET SCHEMA new_schema
       ALTER TABLE ALL IN TABLESPACE name [ OWNED BY role_name [, ... ] ]
           SET TABLESPACE new_tablespace [ NOWAIT ]

       where action is one of:

<!-- e6c7b41c-88f9-487b-85aa-3e2fa5db760d <=< ACCEPT -->           ADD [ COLUMN ] [ IF NOT EXISTS ] column_name data_type [ COLLATE collation ] [ column_constraint [ ... ] ]
           DROP [ COLUMN ] [ IF EXISTS ] column_name [ RESTRICT | CASCADE ]
           ALTER [ COLUMN ] column_name [ SET DATA ] TYPE data_type [ COLLATE collation ] [ USING expression ]
           ALTER [ COLUMN ] column_name SET DEFAULT expression
           ALTER [ COLUMN ] column_name DROP DEFAULT
           ALTER [ COLUMN ] column_name { SET | DROP } NOT NULL
           ALTER [ COLUMN ] column_name SET STATISTICS integer
           ALTER [ COLUMN ] column_name SET ( attribute_option = value [, ... ] )
           ALTER [ COLUMN ] column_name RESET ( attribute_option [, ... ] )
           ALTER [ COLUMN ] column_name SET STORAGE { PLAIN | EXTERNAL | EXTENDED | MAIN }
           ADD table_constraint [ NOT VALID ]
           ADD table_constraint_using_index
           ALTER CONSTRAINT constraint_name [ DEFERRABLE | NOT DEFERRABLE ] [ INITIALLY DEFERRED | INITIALLY IMMEDIATE ]
           VALIDATE CONSTRAINT constraint_name
           DROP CONSTRAINT [ IF EXISTS ]  constraint_name [ RESTRICT | CASCADE ]
           DISABLE TRIGGER [ trigger_name | ALL | USER ]
           ENABLE TRIGGER [ trigger_name | ALL | USER ]
           ENABLE REPLICA TRIGGER trigger_name
           ENABLE ALWAYS TRIGGER trigger_name<!-- ACCEPT >=> e6c7b41c-88f9-487b-85aa-3e2fa5db760d -->
           DISABLE RULE rewrite_rule_name
           ENABLE RULE rewrite_rule_name
           ENABLE REPLICA RULE rewrite_rule_name
           ENABLE ALWAYS RULE rewrite_rule_name
           DISABLE ROW LEVEL SECURITY
           ENABLE ROW LEVEL SECURITY
           FORCE ROW LEVEL SECURITY
           NO FORCE ROW LEVEL SECURITY
           CLUSTER ON index_name
           SET WITHOUT CLUSTER
           SET WITH OIDS
           SET WITHOUT OIDS
           SET TABLESPACE new_tablespace
           SET { LOGGED | UNLOGGED }
           SET ( storage_parameter = value [, ... ] )
           RESET ( storage_parameter [, ... ] )
           INHERIT parent_table
           NO INHERIT parent_table
           OF type_name
           NOT OF
           OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
           REPLICA IDENTITY { DEFAULT | USING INDEX index_name | FULL | NOTHING }

       and table_constraint_using_index is:

           [ CONSTRAINT constraint_name ]
           { UNIQUE | PRIMARY KEY } USING INDEX index_name
           [ DEFERRABLE | NOT DEFERRABLE ] [ INITIALLY DEFERRED | INITIALLY IMMEDIATE ]

DESCRIPTION
       ALTER TABLE changes the definition of an existing table. There are
       several subforms described below. Note that the lock level required may
       differ for each subform. An ACCESS EXCLUSIVE lock is held unless
       explicitly noted. When multiple subcommands are listed, the lock held
       will be the strictest one required from any subcommand.

       ADD COLUMN [ IF NOT EXISTS ]
           This form adds a new column to the table, using the same syntax as
           CREATE TABLE (CREATE_TABLE(7)). If IF NOT EXISTS is specified and a
           column already exists with this name, no error is thrown.

<!-- 22ad55db-b1ff-4e76-b5e1-fb83846a2309 <=< ACCEPT -->       DROP COLUMN [ IF EXISTS ]
           This form drops a column from a table. Indexes and table
           constraints involving the column will be automatically dropped as
           well. You will need to say CASCADE if anything outside the table
           depends on the column, for example, foreign key references or
           views. If IF EXISTS is specified and the column does not exist, no
           error is thrown. In this case a notice is issued instead.<!-- ACCEPT >=> 22ad55db-b1ff-4e76-b5e1-fb83846a2309 -->

       SET DATA TYPE
           This form changes the type of a column of a table. Indexes and
           simple table constraints involving the column will be automatically
           converted to use the new column type by reparsing the originally
           supplied expression. The optional COLLATE clause specifies a
           collation for the new column; if omitted, the collation is the
           default for the new column type. The optional USING clause
           specifies how to compute the new column value from the old; if
           omitted, the default conversion is the same as an assignment cast
           from old data type to new. A USING clause must be provided if there
           is no implicit or assignment cast from old to new type.

       SET/DROP DEFAULT
           These forms set or remove the default value for a column. Default
           values only apply in subsequent INSERT or UPDATE commands; they do
           not cause rows already in the table to change.

       SET/DROP NOT NULL
           These forms change whether a column is marked to allow null values
           or to reject null values. You can only use SET NOT NULL when the
           column contains no null values.

       SET STATISTICS
           This form sets the per-column statistics-gathering target for
           subsequent ANALYZE(7) operations. The target can be set in the
           range 0 to 10000; alternatively, set it to -1 to revert to using
           the system default statistics target (default_statistics_target).
           For more information on the use of statistics by the PostgreSQL
           query planner, refer to Section 14.2, "Statistics Used by the
           Planner", in the documentation.

           SET STATISTICS acquires a SHARE UPDATE EXCLUSIVE lock.

       SET ( attribute_option = value [, ... ] )
       RESET ( attribute_option [, ... ] )
           This form sets or resets per-attribute options. Currently, the only
           defined per-attribute options are n_distinct and
           n_distinct_inherited, which override the number-of-distinct-values
           estimates made by subsequent ANALYZE(7) operations.  n_distinct
           affects the statistics for the table itself, while
           n_distinct_inherited affects the statistics gathered for the table
           plus its inheritance children. When set to a positive value,
           ANALYZE will assume that the column contains exactly the specified
           number of distinct nonnull values. When set to a negative value,
           which must be greater than or equal to -1, ANALYZE will assume that
           the number of distinct nonnull values in the column is linear in
           the size of the table; the exact count is to be computed by
           multiplying the estimated table size by the absolute value of the
           given number. For example, a value of -1 implies that all values in
           the column are distinct, while a value of -0.5 implies that each
           value appears twice on the average. This can be useful when the
           size of the table changes over time, since the multiplication by
           the number of rows in the table is not performed until query
           planning time. Specify a value of 0 to revert to estimating the
           number of distinct values normally. For more information on the use
           of statistics by the PostgreSQL query planner, refer to Section
           14.2, "Statistics Used by the Planner", in the documentation.

           Changing per-attribute options acquires a SHARE UPDATE EXCLUSIVE
           lock.

       SET STORAGE
           This form sets the storage mode for a column. This controls whether
           this column is held inline or in a secondary TOAST table, and
           whether the data should be compressed or not.  PLAIN must be used
           for fixed-length values such as integer and is inline,
           uncompressed.  MAIN is for inline, compressible data.  EXTERNAL is
           for external, uncompressed data, and EXTENDED is for external,
           compressed data.  EXTENDED is the default for most data types that
           support non-PLAIN storage. Use of EXTERNAL will make substring
           operations on very large text and bytea values run faster, at the
           penalty of increased storage space. Note that SET STORAGE doesn't
           itself change anything in the table, it just sets the strategy to
           be pursued during future table updates. See Section 65.2, "TOAST",
           in the documentation for more information.

       ADD table_constraint [ NOT VALID ]
           This form adds a new constraint to a table using the same syntax as
           CREATE TABLE (CREATE_TABLE(7)), plus the option NOT VALID, which is
           currently only allowed for foreign key and CHECK constraints. If
           the constraint is marked NOT VALID, the potentially-lengthy initial
           check to verify that all rows in the table satisfy the constraint
           is skipped. The constraint will still be enforced against
           subsequent inserts or updates (that is, they'll fail unless there
           is a matching row in the referenced table, in the case of foreign
           keys; and they'll fail unless the new row matches the specified
           check constraints). But the database will not assume that the
           constraint holds for all rows in the table, until it is validated
           by using the VALIDATE CONSTRAINT option.

       ADD table_constraint_using_index
           This form adds a new PRIMARY KEY or UNIQUE constraint to a table
           based on an existing unique index. All the columns of the index
           will be included in the constraint.

           The index cannot have expression columns nor be a partial index.
           Also, it must be a b-tree index with default sort ordering. These
           restrictions ensure that the index is equivalent to one that would
           be built by a regular ADD PRIMARY KEY or ADD UNIQUE command.

           If PRIMARY KEY is specified, and the index's columns are not
           already marked NOT NULL, then this command will attempt to do ALTER
           COLUMN SET NOT NULL against each such column. That requires a full
           table scan to verify the column(s) contain no nulls. In all other
           cases, this is a fast operation.

           If a constraint name is provided then the index will be renamed to
           match the constraint name. Otherwise the constraint will be named
           the same as the index.

           After this command is executed, the index is "owned" by the
           constraint, in the same way as if the index had been built by a
           regular ADD PRIMARY KEY or ADD UNIQUE command. In particular,
           dropping the constraint will make the index disappear too.

               Note
               Adding a constraint using an existing index can be helpful in
               situations where a new constraint needs to be added without
               blocking table updates for a long time. To do that, create the
               index using CREATE INDEX CONCURRENTLY, and then install it as
               an official constraint using this syntax. See the example
               below.

       ALTER CONSTRAINT
           This form alters the attributes of a constraint that was previously
           created. Currently only foreign key constraints may be altered.

       VALIDATE CONSTRAINT
           This form validates a foreign key or check constraint that was
           previously created as NOT VALID, by scanning the table to ensure
           there are no rows for which the constraint is not satisfied.
           Nothing happens if the constraint is already marked valid.

           Validation can be a long process on larger tables. The value of
           separating validation from initial creation is that you can defer
           validation to less busy times, or can be used to give additional
           time to correct pre-existing errors while preventing new errors.
           Note also that validation on its own does not prevent normal write
           commands against the table while it runs.

           Validation acquires only a SHARE UPDATE EXCLUSIVE lock on the table
           being altered. If the constraint is a foreign key then a ROW SHARE
           lock is also required on the table referenced by the constraint.

<!-- bc77072c-0c6a-4f8a-a915-bdad0da8a78b <=< ACCEPT -->       DROP CONSTRAINT [ IF EXISTS ]
           This form drops the specified constraint on a table. If IF EXISTS
           is specified and the constraint does not exist, no error is thrown.
           In this case a notice is issued instead.<!-- ACCEPT >=> bc77072c-0c6a-4f8a-a915-bdad0da8a78b -->

       DISABLE/ENABLE [ REPLICA | ALWAYS ] TRIGGER
           These forms configure the firing of trigger(s) belonging to the
           table. A disabled trigger is still known to the system, but is not
           executed when its triggering event occurs. For a deferred trigger,
           the enable status is checked when the event occurs, not when the
           trigger function is actually executed. One can disable or enable a
           single trigger specified by name, or all triggers on the table, or
           only user triggers (this option excludes internally generated
           constraint triggers such as those that are used to implement
           foreign key constraints or deferrable uniqueness and exclusion
           constraints). Disabling or enabling internally generated constraint
           triggers requires superuser privileges; it should be done with
           caution since of course the integrity of the constraint cannot be
           guaranteed if the triggers are not executed. The trigger firing
           mechanism is also affected by the configuration variable
           session_replication_role. Simply enabled triggers will fire when
           the replication role is "origin" (the default) or "local". Triggers
           configured as ENABLE REPLICA will only fire if the session is in
           "replica" mode, and triggers configured as ENABLE ALWAYS will fire
           regardless of the current replication mode.

           This command acquires a SHARE ROW EXCLUSIVE lock.

       DISABLE/ENABLE [ REPLICA | ALWAYS ] RULE
           These forms configure the firing of rewrite rules belonging to the
           table. A disabled rule is still known to the system, but is not
           applied during query rewriting. The semantics are as for
           disabled/enabled triggers. This configuration is ignored for ON
           SELECT rules, which are always applied in order to keep views
           working even if the current session is in a non-default replication
           role.

       DISABLE/ENABLE ROW LEVEL SECURITY
           These forms control the application of row security policies
           belonging to the table. If enabled and no policies exist for the
           table, then a default-deny policy is applied. Note that policies
           can exist for a table even if row level security is disabled - in
           this case, the policies will NOT be applied and the policies will
           be ignored. See also CREATE POLICY (CREATE_POLICY(7)).

       NO FORCE/FORCE ROW LEVEL SECURITY
           These forms control the application of row security policies
           belonging to the table when the user is the table owner. If
           enabled, row level security policies will be applied when the user
           is the table owner. If disabled (the default) then row level
           security will not be applied when the user is the table owner. See
           also CREATE POLICY (CREATE_POLICY(7)).

       CLUSTER ON
           This form selects the default index for future CLUSTER(7)
           operations. It does not actually re-cluster the table.

           Changing cluster options acquires a SHARE UPDATE EXCLUSIVE lock.

       SET WITHOUT CLUSTER
           This form removes the most recently used CLUSTER(7) index
           specification from the table. This affects future cluster
           operations that don't specify an index.

           Changing cluster options acquires a SHARE UPDATE EXCLUSIVE lock.

<!-- f322b4c2-95d3-444c-9ad5-8e8d3b56ac03 <=< ACCEPT -->       SET WITH OIDS
           This form adds an oid system column to the table (see Section 5.4,
           "System Columns", in the documentation). It does nothing if the
           table already has OIDs.

           Note that this is not equivalent to ADD COLUMN oid oid; that would
           add a normal column that happened to be named oid, not a system
           column.

       SET WITHOUT OIDS
           This form removes the oid system column from the table. This is
           exactly equivalent to DROP COLUMN oid RESTRICT, except that it will
           not complain if there is already no oid column.<!-- ACCEPT >=> f322b4c2-95d3-444c-9ad5-8e8d3b56ac03 -->

<!-- 2b006584-429f-4021-86e0-99ef3a6619e6 <=< ACCEPT -->       SET TABLESPACE
           This form changes the table's tablespace to the specified
           tablespace and moves the data file(s) associated with the table to
           the new tablespace. Indexes on the table, if any, are not moved;
           but they can be moved separately with additional SET TABLESPACE
           commands. All tables in the current database in a tablespace can be
           moved by using the ALL IN TABLESPACE form, which will lock all
           tables to be moved first and then move each one. This form also
           supports OWNED BY, which will only move tables owned by the roles
           specified. If the NOWAIT option is specified then the command will
           fail if it is unable to acquire all of the locks required
           immediately. Note that system catalogs are not moved by this
           command, use ALTER DATABASE or explicit ALTER TABLE invocations
           instead if desired. The information_schema relations are not
           considered part of the system catalogs and will be moved. See also
           CREATE TABLESPACE (CREATE_TABLESPACE(7)).<!-- ACCEPT >=> 2b006584-429f-4021-86e0-99ef3a6619e6 -->

       SET { LOGGED | UNLOGGED }
           This form changes the table from unlogged to logged or vice-versa
           (see UNLOGGED). It cannot be applied to a temporary table.

       SET ( storage_parameter = value [, ... ] )
           This form changes one or more storage parameters for the table. See
           Storage Parameters for details on the available parameters. Note
           that the table contents will not be modified immediately by this
           command; depending on the parameter you might need to rewrite the
           table to get the desired effects. That can be done with VACUUM
           FULL, CLUSTER(7) or one of the forms of ALTER TABLE that forces a
           table rewrite.

           Changing fillfactor and autovacuum storage parameters acquires a
           SHARE UPDATE EXCLUSIVE lock.

               Note
               While CREATE TABLE allows OIDS to be specified in the WITH
               (storage_parameter) syntax, ALTER TABLE does not treat OIDS as
               a storage parameter. Instead use the SET WITH OIDS and SET
               WITHOUT OIDS forms to change OID status.

       RESET ( storage_parameter [, ... ] )
           This form resets one or more storage parameters to their defaults.
           As with SET, a table rewrite might be needed to update the table
           entirely.

       INHERIT parent_table
           This form adds the target table as a new child of the specified
           parent table. Subsequently, queries against the parent will include
           records of the target table. To be added as a child, the target
           table must already contain all the same columns as the parent (it
           could have additional columns, too). The columns must have matching
           data types, and if they have NOT NULL constraints in the parent
           then they must also have NOT NULL constraints in the child.

           There must also be matching child-table constraints for all CHECK
           constraints of the parent, except those marked non-inheritable
           (that is, created with ALTER TABLE ... ADD CONSTRAINT ... NO
           INHERIT) in the parent, which are ignored; all child-table
           constraints matched must not be marked non-inheritable. Currently
           UNIQUE, PRIMARY KEY, and FOREIGN KEY constraints are not
           considered, but this might change in the future.

       NO INHERIT parent_table
           This form removes the target table from the list of children of the
           specified parent table. Queries against the parent table will no
           longer include records drawn from the target table.

       OF type_name
           This form links the table to a composite type as though CREATE
           TABLE OF had formed it. The table's list of column names and types
           must precisely match that of the composite type; the presence of an
           oid system column is permitted to differ. The table must not
           inherit from any other table. These restrictions ensure that CREATE
           TABLE OF would permit an equivalent table definition.

       NOT OF
           This form dissociates a typed table from its type.

       OWNER
           This form changes the owner of the table, sequence, view,
           materialized view, or foreign table to the specified user.

       REPLICA IDENTITY
           This form changes the information which is written to the
           write-ahead log to identify rows which are updated or deleted. This
           option has no effect except when logical replication is in use.
           DEFAULT (the default for non-system tables) records the old values
           of the columns of the primary key, if any.  USING INDEX records the
           old values of the columns covered by the named index, which must be
           unique, not partial, not deferrable, and include only columns
           marked NOT NULL.  FULL records the old values of all columns in the
           row.  NOTHING records no information about the old row. (This is
           the default for system tables.) In all cases, no old values are
           logged unless at least one of the columns that would be logged
           differs between the old and new versions of the row.

       RENAME
           The RENAME forms change the name of a table (or an index, sequence,
           view, materialized view, or foreign table), the name of an
           individual column in a table, or the name of a constraint of the
           table. There is no effect on the stored data.

       SET SCHEMA
           This form moves the table into another schema. Associated indexes,
           constraints, and sequences owned by table columns are moved as
           well.

       All the actions except RENAME, SET TABLESPACE and SET SCHEMA can be
       combined into a list of multiple alterations to apply in parallel. For
       example, it is possible to add several columns and/or alter the type of
       several columns in a single command. This is particularly useful with
       large tables, since only one pass over the table need be made.

       You must own the table to use ALTER TABLE. To change the schema or
       tablespace of a table, you must also have CREATE privilege on the new
       schema or tablespace. To add the table as a new child of a parent
       table, you must own the parent table as well. To alter the owner, you
       must also be a direct or indirect member of the new owning role, and
       that role must have CREATE privilege on the table's schema. (These
       restrictions enforce that altering the owner doesn't do anything you
       couldn't do by dropping and recreating the table. However, a superuser
       can alter ownership of any table anyway.) To add a column or alter a
       column type or use the OF clause, you must also have USAGE privilege on
       the data type.

PARAMETERS
       IF EXISTS
           Do not throw an error if the table does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing table to
           alter. If ONLY is specified before the table name, only that table
           is altered. If ONLY is not specified, the table and all its
           descendant tables (if any) are altered. Optionally, * can be
           specified after the table name to explicitly indicate that
           descendant tables are included.
<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->
<!-- 33010bc7-9edf-43c5-8a0d-ff696a0fbab8 <=< ACCEPT -->       column_name
           Name of a new or existing column.

       new_column_name
           New name for an existing column.

       new_name
           New name for the table.

       data_type
           Data type of the new column, or new data type for an existing
           column.

       table_constraint
           New table constraint for the table.

       constraint_name
           Name of a new or existing constraint.

       CASCADE
           Automatically drop objects that depend on the dropped column or
           constraint (for example, views referencing the column), and in turn
           all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the column or constraint if there are any dependent
           objects. This is the default behavior.

       trigger_name
           Name of a single trigger to disable or enable.

       ALL
           Disable or enable all triggers belonging to the table. (This
           requires superuser privilege if any of the triggers are internally
           generated constraint triggers such as those that are used to
           implement foreign key constraints or deferrable uniqueness and
           exclusion constraints.)

       USER
           Disable or enable all triggers belonging to the table except for
           internally generated constraint triggers such as those that are
           used to implement foreign key constraints or deferrable uniqueness
           and exclusion constraints.<!-- ACCEPT >=> 33010bc7-9edf-43c5-8a0d-ff696a0fbab8 -->

       index_name
           The name of an existing index.

       storage_parameter
           The name of a table storage parameter.

       value
           The new value for a table storage parameter. This might be a number
           or a word depending on the parameter.

       parent_table
           A parent table to associate or de-associate with this table.

       new_owner
           The user name of the new owner of the table.

       new_tablespace
           The name of the tablespace to which the table will be moved.

       new_schema
           The name of the schema to which the table will be moved.

NOTES
       The key word COLUMN is noise and can be omitted.

       When a column is added with ADD COLUMN, all existing rows in the table
       are initialized with the column's default value (NULL if no DEFAULT
       clause is specified). If there is no DEFAULT clause, this is merely a
       metadata change and does not require any immediate update of the
       table's data; the added NULL values are supplied on readout, instead.

       Adding a column with a DEFAULT clause or changing the type of an
       existing column will require the entire table and its indexes to be
       rewritten. As an exception when changing the type of an existing
       column, if the USING clause does not change the column contents and the
       old type is either binary coercible to the new type or an unconstrained
       domain over the new type, a table rewrite is not needed; but any
       indexes on the affected columns must still be rebuilt. Adding or
       removing a system oid column also requires rewriting the entire table.
       Table and/or index rebuilds may take a significant amount of time for a
       large table; and will temporarily require as much as double the disk
       space.

       Adding a CHECK or NOT NULL constraint requires scanning the table to
       verify that existing rows meet the constraint, but does not require a
       table rewrite.

       The main reason for providing the option to specify multiple changes in
       a single ALTER TABLE is that multiple table scans or rewrites can
       thereby be combined into a single pass over the table.

       The DROP COLUMN form does not physically remove the column, but simply
       makes it invisible to SQL operations. Subsequent insert and update
       operations in the table will store a null value for the column. Thus,
       dropping a column is quick but it will not immediately reduce the
       on-disk size of your table, as the space occupied by the dropped column
       is not reclaimed. The space will be reclaimed over time as existing
       rows are updated. (These statements do not apply when dropping the
       system oid column; that is done with an immediate rewrite.)

       To force immediate reclamation of space occupied by a dropped column,
       you can execute one of the forms of ALTER TABLE that performs a rewrite
       of the whole table. This results in reconstructing each row with the
       dropped column replaced by a null value.

       The rewriting forms of ALTER TABLE are not MVCC-safe. After a table
       rewrite, the table will appear empty to concurrent transactions, if
       they are using a snapshot taken before the rewrite occurred. See
       Section 13.5, "Caveats", in the documentation for more details.

       The USING option of SET DATA TYPE can actually specify any expression
       involving the old values of the row; that is, it can refer to other
       columns as well as the one being converted. This allows very general
       conversions to be done with the SET DATA TYPE syntax. Because of this
       flexibility, the USING expression is not applied to the column's
       default value (if any); the result might not be a constant expression
       as required for a default. This means that when there is no implicit or
       assignment cast from old to new type, SET DATA TYPE might fail to
       convert the default even though a USING clause is supplied. In such
       cases, drop the default with DROP DEFAULT, perform the ALTER TYPE, and
       then use SET DEFAULT to add a suitable new default. Similar
       considerations apply to indexes and constraints involving the column.

       If a table has any descendant tables, it is not permitted to add,
       rename, or change the type of a column, or rename an inherited
       constraint in the parent table without doing the same to the
       descendants. That is, ALTER TABLE ONLY will be rejected. This ensures
       that the descendants always have columns matching the parent.

       A recursive DROP COLUMN operation will remove a descendant table's
       column only if the descendant does not inherit that column from any
       other parents and never had an independent definition of the column. A
       nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN) never
       removes any descendant columns, but instead marks them as independently
       defined rather than inherited.

       The TRIGGER, CLUSTER, OWNER, and TABLESPACE actions never recurse to
       descendant tables; that is, they always act as though ONLY were
       specified. Adding a constraint recurses only for CHECK constraints that
       are not marked NO INHERIT.

       Changing any part of a system catalog table is not permitted.

       Refer to CREATE TABLE (CREATE_TABLE(7)) for a further description of
       valid parameters.  Chapter 5, Data Definition, in the documentation has
       further information on inheritance.

EXAMPLES
       To add a column of type varchar to a table:

           ALTER TABLE distributors ADD COLUMN address varchar(30);

       To drop a column from a table:

           ALTER TABLE distributors DROP COLUMN address RESTRICT;

       To change the types of two existing columns in one operation:

           ALTER TABLE distributors
               ALTER COLUMN address TYPE varchar(80),
               ALTER COLUMN name TYPE varchar(100);

       To change an integer column containing Unix timestamps to timestamp
       with time zone via a USING clause:

           ALTER TABLE foo
               ALTER COLUMN foo_timestamp SET DATA TYPE timestamp with time zone
               USING
                   timestamp with time zone 'epoch' + foo_timestamp * interval '1 second';

       The same, when the column has a default expression that won't
       automatically cast to the new data type:

           ALTER TABLE foo
               ALTER COLUMN foo_timestamp DROP DEFAULT,
               ALTER COLUMN foo_timestamp TYPE timestamp with time zone
               USING
                   timestamp with time zone 'epoch' + foo_timestamp * interval '1 second',
               ALTER COLUMN foo_timestamp SET DEFAULT now();

       To rename an existing column:

           ALTER TABLE distributors RENAME COLUMN address TO city;

       To rename an existing table:

           ALTER TABLE distributors RENAME TO suppliers;

       To rename an existing constraint:

           ALTER TABLE distributors RENAME CONSTRAINT zipchk TO zip_check;

       To add a not-null constraint to a column:

           ALTER TABLE distributors ALTER COLUMN street SET NOT NULL;

       To remove a not-null constraint from a column:

           ALTER TABLE distributors ALTER COLUMN street DROP NOT NULL;

       To add a check constraint to a table and all its children:

           ALTER TABLE distributors ADD CONSTRAINT zipchk CHECK (char_length(zipcode) = 5);

       To add a check constraint only to a table and not to its children:

           ALTER TABLE distributors ADD CONSTRAINT zipchk CHECK (char_length(zipcode) = 5) NO INHERIT;

       (The check constraint will not be inherited by future children,
       either.)

       To remove a check constraint from a table and all its children:

           ALTER TABLE distributors DROP CONSTRAINT zipchk;

       To remove a check constraint from one table only:

           ALTER TABLE ONLY distributors DROP CONSTRAINT zipchk;

       (The check constraint remains in place for any child tables.)

       To add a foreign key constraint to a table:

           ALTER TABLE distributors ADD CONSTRAINT distfk FOREIGN KEY (address) REFERENCES addresses (address);

       To add a foreign key constraint to a table with the least impact on
       other work:

           ALTER TABLE distributors ADD CONSTRAINT distfk FOREIGN KEY (address) REFERENCES addresses (address) NOT VALID;
           ALTER TABLE distributors VALIDATE CONSTRAINT distfk;

       To add a (multicolumn) unique constraint to a table:

           ALTER TABLE distributors ADD CONSTRAINT dist_id_zipcode_key UNIQUE (dist_id, zipcode);

       To add an automatically named primary key constraint to a table, noting
       that a table can only ever have one primary key:

           ALTER TABLE distributors ADD PRIMARY KEY (dist_id);

       To move a table to a different tablespace:

           ALTER TABLE distributors SET TABLESPACE fasttablespace;

       To move a table to a different schema:

           ALTER TABLE myschema.distributors SET SCHEMA yourschema;

       To recreate a primary key constraint, without blocking updates while
       the index is rebuilt:

           CREATE UNIQUE INDEX CONCURRENTLY dist_id_temp_idx ON distributors (dist_id);
           ALTER TABLE distributors DROP CONSTRAINT distributors_pkey,
               ADD CONSTRAINT distributors_pkey PRIMARY KEY USING INDEX dist_id_temp_idx;

<!-- 6f26919a-f964-4174-8c8d-6ec22f5e2be4 <=< ACCEPT -->COMPATIBILITY
       The forms ADD (without USING INDEX), DROP, SET DEFAULT, and SET DATA
       TYPE (without USING) conform with the SQL standard. The other forms are
       PostgreSQL extensions of the SQL standard. Also, the ability to specify
       more than one manipulation in a single ALTER TABLE command is an
       extension.

       ALTER TABLE DROP COLUMN can be used to drop the only column of a table,
       leaving a zero-column table. This is an extension of SQL, which
       disallows zero-column tables.
<!-- ACCEPT >=> 6f26919a-f964-4174-8c8d-6ec22f5e2be4 -->
SEE ALSO
       CREATE TABLE (CREATE_TABLE(7))



PostgreSQL 9.6.1                     2016                       ALTER TABLE(7)
NOTIFY(7)               PostgreSQL 9.6.1 Documentation               NOTIFY(7)



NAME
       NOTIFY - generate a notification

SYNOPSIS
       NOTIFY channel [ , payload ]

DESCRIPTION
       The NOTIFY command sends a notification event together with an optional
       "payload" string to each client application that has previously
       executed LISTEN channel for the specified channel name in the current
       database. Notifications are visible to all users.

       NOTIFY provides a simple interprocess communication mechanism for a
       collection of processes accessing the same PostgreSQL database. A
       payload string can be sent along with the notification, and
       higher-level mechanisms for passing structured data can be built by
       using tables in the database to pass additional data from notifier to
       listener(s).

       The information passed to the client for a notification event includes
       the notification channel name, the notifying session's server process
       PID, and the payload string, which is an empty string if it has not
       been specified.

       It is up to the database designer to define the channel names that will
       be used in a given database and what each one means. Commonly, the
       channel name is the same as the name of some table in the database, and
       the notify event essentially means, "I changed this table, take a look
       at it to see what's new". But no such association is enforced by the
       NOTIFY and LISTEN commands. For example, a database designer could use
       several different channel names to signal different sorts of changes to
       a single table. Alternatively, the payload string could be used to
       differentiate various cases.

       When NOTIFY is used to signal the occurrence of changes to a particular
       table, a useful programming technique is to put the NOTIFY in a
       statement trigger that is triggered by table updates. In this way,
       notification happens automatically when the table is changed, and the
       application programmer cannot accidentally forget to do it.

       NOTIFY interacts with SQL transactions in some important ways. Firstly,
       if a NOTIFY is executed inside a transaction, the notify events are not
       delivered until and unless the transaction is committed. This is
       appropriate, since if the transaction is aborted, all the commands
       within it have had no effect, including NOTIFY. But it can be
       disconcerting if one is expecting the notification events to be
       delivered immediately. Secondly, if a listening session receives a
       notification signal while it is within a transaction, the notification
       event will not be delivered to its connected client until just after
       the transaction is completed (either committed or aborted). Again, the
       reasoning is that if a notification were delivered within a transaction
       that was later aborted, one would want the notification to be undone
       somehow -- but the server cannot "take back" a notification once it has
       sent it to the client. So notification events are only delivered
       between transactions. The upshot of this is that applications using
       NOTIFY for real-time signaling should try to keep their transactions
       short.

       If the same channel name is signaled multiple times from the same
       transaction with identical payload strings, the database server can
       decide to deliver a single notification only. On the other hand,
       notifications with distinct payload strings will always be delivered as
       distinct notifications. Similarly, notifications from different
       transactions will never get folded into one notification. Except for
       dropping later instances of duplicate notifications, NOTIFY guarantees
       that notifications from the same transaction get delivered in the order
       they were sent. It is also guaranteed that messages from different
       transactions are delivered in the order in which the transactions
       committed.

       It is common for a client that executes NOTIFY to be listening on the
       same notification channel itself. In that case it will get back a
       notification event, just like all the other listening sessions.
       Depending on the application logic, this could result in useless work,
       for example, reading a database table to find the same updates that
       that session just wrote out. It is possible to avoid such extra work by
       noticing whether the notifying session's server process PID (supplied
       in the notification event message) is the same as one's own session's
       PID (available from libpq). When they are the same, the notification
       event is one's own work bouncing back, and can be ignored.

PARAMETERS
       channel
           Name of the notification channel to be signaled (any identifier).

       payload
           The "payload" string to be communicated along with the
           notification. This must be specified as a simple string literal. In
           the default configuration it must be shorter than 8000 bytes. (If
           binary data or large amounts of information need to be
           communicated, it's best to put it in a database table and send the
           key of the record.)

NOTES
       There is a queue that holds notifications that have been sent but not
       yet processed by all listening sessions. If this queue becomes full,
       transactions calling NOTIFY will fail at commit. The queue is quite
       large (8GB in a standard installation) and should be sufficiently sized
       for almost every use case. However, no cleanup can take place if a
       session executes LISTEN and then enters a transaction for a very long
       time. Once the queue is half full you will see warnings in the log file
       pointing you to the session that is preventing cleanup. In this case
       you should make sure that this session ends its current transaction so
       that cleanup can proceed.

       The function pg_notification_queue_usage returns the fraction of the
       queue that is currently occupied by pending notifications. See Section
       9.25, "System Information Functions", in the documentation for more
       information.

       A transaction that has executed NOTIFY cannot be prepared for two-phase
       commit.

   pg_notify
       To send a notification you can also use the function pg_notify(text,
       text). The function takes the channel name as the first argument and
       the payload as the second. The function is much easier to use than the
       NOTIFY command if you need to work with non-constant channel names and
       payloads.

EXAMPLES
       Configure and execute a listen/notify sequence from psql:

           LISTEN virtual;
           NOTIFY virtual;
           Asynchronous notification "virtual" received from server process with PID 8448.
           NOTIFY virtual, 'This is the payload';
           Asynchronous notification "virtual" with payload "This is the payload" received from server process with PID 8448.

           LISTEN foo;
           SELECT pg_notify('fo' || 'o', 'pay' || 'load');
           Asynchronous notification "foo" with payload "payload" received from server process with PID 14728.

COMPATIBILITY
       There is no NOTIFY statement in the SQL standard.

SEE ALSO
       LISTEN(7), UNLISTEN(7)



PostgreSQL 9.6.1                     2016                            NOTIFY(7)
DROP ACCESS METHOD(7)   PostgreSQL 9.6.1 Documentation   DROP ACCESS METHOD(7)



NAME
       DROP_ACCESS_METHOD - remove an access method

SYNOPSIS
       DROP ACCESS METHOD [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP ACCESS METHOD removes an existing access method. Only superusers
       can drop access methods.

PARAMETERS
       IF EXISTS
           Do not throw an error if the access method does not exist. A notice
           is issued in this case.

       name
           The name of an existing access method.

       CASCADE
           Automatically drop objects that depend on the access method (such
           as operator classes, operator families, and indexes), and in turn
           all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the access method if any objects depend on it. This
           is the default.

EXAMPLES
       Drop the access method heptree:

           DROP ACCESS METHOD heptree;

COMPATIBILITY
       DROP ACCESS METHOD is a PostgreSQL extension.

SEE ALSO
       CREATE ACCESS METHOD (CREATE_ACCESS_METHOD(7))



PostgreSQL 9.6.1                     2016                DROP ACCESS METHOD(7)
CREATE TRANSFORM(7)     PostgreSQL 9.6.1 Documentation     CREATE TRANSFORM(7)



NAME
       CREATE_TRANSFORM - define a new transform

SYNOPSIS
       CREATE [ OR REPLACE ] TRANSFORM FOR type_name LANGUAGE lang_name (
           FROM SQL WITH FUNCTION from_sql_function_name (argument_type [, ...]),
           TO SQL WITH FUNCTION to_sql_function_name (argument_type [, ...])
       );

DESCRIPTION
       CREATE TRANSFORM defines a new transform.  CREATE OR REPLACE TRANSFORM
       will either create a new transform, or replace an existing definition.

       A transform specifies how to adapt a data type to a procedural
       language. For example, when writing a function in PL/Python using the
       hstore type, PL/Python has no prior knowledge how to present hstore
       values in the Python environment. Language implementations usually
       default to using the text representation, but that is inconvenient
       when, for example, an associative array or a list would be more
       appropriate.

       A transform specifies two functions:

       o   A "from SQL" function that converts the type from the SQL
           environment to the language. This function will be invoked on the
           arguments of a function written in the language.

       o   A "to SQL" function that converts the type from the language to the
           SQL environment. This function will be invoked on the return value
           of a function written in the language.

       It is not necessary to provide both of these functions. If one is not
       specified, the language-specific default behavior will be used if
       necessary. (To prevent a transformation in a certain direction from
       happening at all, you could also write a transform function that always
       errors out.)

       To be able to create a transform, you must own and have USAGE privilege
       on the type, have USAGE privilege on the language, and own and have
       EXECUTE privilege on the from-SQL and to-SQL functions, if specified.

PARAMETERS
       type_name
           The name of the data type of the transform.

       lang_name
           The name of the language of the transform.

       from_sql_function_name(argument_type [, ...])
           The name of the function for converting the type from the SQL
           environment to the language. It must take one argument of type
           internal and return type internal. The actual argument will be of
           the type for the transform, and the function should be coded as if
           it were. (But it is not allowed to declare an SQL-level function
           returning internal without at least one argument of type internal.)
           The actual return value will be something specific to the language
           implementation.

       to_sql_function_name(argument_type [, ...])
           The name of the function for converting the type from the language
           to the SQL environment. It must take one argument of type internal
           and return the type that is the type for the transform. The actual
           argument value will be something specific to the language
           implementation.

NOTES
       Use DROP TRANSFORM (DROP_TRANSFORM(7)) to remove transforms.

EXAMPLES
       To create a transform for type hstore and language plpythonu, first set
       up the type and the language:

           CREATE TYPE hstore ...;

           CREATE LANGUAGE plpythonu ...;

       Then create the necessary functions:

           CREATE FUNCTION hstore_to_plpython(val internal) RETURNS internal
           LANGUAGE C STRICT IMMUTABLE
           AS ...;

           CREATE FUNCTION plpython_to_hstore(val internal) RETURNS hstore
           LANGUAGE C STRICT IMMUTABLE
           AS ...;

       And finally create the transform to connect them all together:

           CREATE TRANSFORM FOR hstore LANGUAGE plpythonu (
               FROM SQL WITH FUNCTION hstore_to_plpython(internal),
               TO SQL WITH FUNCTION plpython_to_hstore(internal)
           );

       In practice, these commands would be wrapped up in extensions.

       The contrib section contains a number of extensions that provide
       transforms, which can serve as real-world examples.

COMPATIBILITY
       This form of CREATE TRANSFORM is a PostgreSQL extension. There is a
       CREATE TRANSFORM command in the SQL standard, but it is for adapting
       data types to client languages. That usage is not supported by
       PostgreSQL.

SEE ALSO
       CREATE FUNCTION (CREATE_FUNCTION(7)), CREATE LANGUAGE
       (CREATE_LANGUAGE(7)), CREATE TYPE (CREATE_TYPE(7)), DROP TRANSFORM
       (DROP_TRANSFORM(7))



PostgreSQL 9.6.1                     2016                  CREATE TRANSFORM(7)
DROP TEXT SEARCH PARSER(PostgreSQL 9.6.1 DocumentatiDROP TEXT SEARCH PARSER(7)



NAME
       DROP_TEXT_SEARCH_PARSER - remove a text search parser

SYNOPSIS
       DROP TEXT SEARCH PARSER [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP TEXT SEARCH PARSER drops an existing text search parser. You must
       be a superuser to use this command.

PARAMETERS
       IF EXISTS
           Do not throw an error if the text search parser does not exist. A
           notice is issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing text search
           parser.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the text search parser,
           and in turn all objects that depend on those objects (see Section
           5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the text search parser if any objects depend on it.
           This is the default.

EXAMPLES
       Remove the text search parser my_parser:

           DROP TEXT SEARCH PARSER my_parser;

       This command will not succeed if there are any existing text search
       configurations that use the parser. Add CASCADE to drop such
       configurations along with the parser.

COMPATIBILITY
       There is no DROP TEXT SEARCH PARSER statement in the SQL standard.

SEE ALSO
       ALTER TEXT SEARCH PARSER (ALTER_TEXT_SEARCH_PARSER(7)), CREATE TEXT
       SEARCH PARSER (CREATE_TEXT_SEARCH_PARSER(7))



PostgreSQL 9.6.1                     2016           DROP TEXT SEARCH PARSER(7)
ALTER USER MAPPING(7)   PostgreSQL 9.6.1 Documentation   ALTER USER MAPPING(7)



NAME
       ALTER_USER_MAPPING - change the definition of a user mapping

SYNOPSIS
       ALTER USER MAPPING FOR { user_name | USER | CURRENT_USER | SESSION_USER | PUBLIC }
           SERVER server_name
           OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ] )

DESCRIPTION
       ALTER USER MAPPING changes the definition of a user mapping.

       The owner of a foreign server can alter user mappings for that server
       for any user. Also, a user can alter a user mapping for their own user
       name if USAGE privilege on the server has been granted to the user.

PARAMETERS
       user_name
           User name of the mapping.  CURRENT_USER and USER match the name of
           the current user.  PUBLIC is used to match all present and future
           user names in the system.

       server_name
           Server name of the user mapping.

       OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ] )
           Change options for the user mapping. The new options override any
           previously specified options.  ADD, SET, and DROP specify the
           action to be performed.  ADD is assumed if no operation is
           explicitly specified. Option names must be unique; options are also
           validated by the server's foreign-data wrapper.

EXAMPLES
       Change the password for user mapping bob, server foo:

           ALTER USER MAPPING FOR bob SERVER foo OPTIONS (SET password 'public');

COMPATIBILITY
       ALTER USER MAPPING conforms to ISO/IEC 9075-9 (SQL/MED). There is a
       subtle syntax issue: The standard omits the FOR key word. Since both
       CREATE USER MAPPING and DROP USER MAPPING use FOR in analogous
       positions, and IBM DB2 (being the other major SQL/MED implementation)
       also requires it for ALTER USER MAPPING, PostgreSQL diverges from the
       standard here in the interest of consistency and interoperability.

SEE ALSO
       CREATE USER MAPPING (CREATE_USER_MAPPING(7)), DROP USER MAPPING
       (DROP_USER_MAPPING(7))



PostgreSQL 9.6.1                     2016                ALTER USER MAPPING(7)
ALTER TEXT SEARCH TEMPLAPostgreSQL 9.6.1 DocumentALTER TEXT SEARCH TEMPLATE(7)



NAME
       ALTER_TEXT_SEARCH_TEMPLATE - change the definition of a text search
       template

SYNOPSIS
       ALTER TEXT SEARCH TEMPLATE name RENAME TO new_name
       ALTER TEXT SEARCH TEMPLATE name SET SCHEMA new_schema

DESCRIPTION
       ALTER TEXT SEARCH TEMPLATE changes the definition of a text search
       template. Currently, the only supported functionality is to change the
       template's name.

       You must be a superuser to use ALTER TEXT SEARCH TEMPLATE.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing text search
           template.
<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->
       new_name
           The new name of the text search template.

       new_schema
           The new schema for the text search template.

COMPATIBILITY
       There is no ALTER TEXT SEARCH TEMPLATE statement in the SQL standard.

SEE ALSO
       CREATE TEXT SEARCH TEMPLATE (CREATE_TEXT_SEARCH_TEMPLATE(7)), DROP TEXT
       SEARCH TEMPLATE (DROP_TEXT_SEARCH_TEMPLATE(7))



PostgreSQL 9.6.1                     2016        ALTER TEXT SEARCH TEMPLATE(7)
ALTER SEQUENCE(7)       PostgreSQL 9.6.1 Documentation       ALTER SEQUENCE(7)



NAME
       ALTER_SEQUENCE - change the definition of a sequence generator

SYNOPSIS
       ALTER SEQUENCE [ IF EXISTS ] name [ INCREMENT [ BY ] increment ]
           [ MINVALUE minvalue | NO MINVALUE ] [ MAXVALUE maxvalue | NO MAXVALUE ]
           [ START [ WITH ] start ]
           [ RESTART [ [ WITH ] restart ] ]
           [ CACHE cache ] [ [ NO ] CYCLE ]
           [ OWNED BY { table_name.column_name | NONE } ]
       ALTER SEQUENCE [ IF EXISTS ] name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER SEQUENCE [ IF EXISTS ] name RENAME TO new_name
       ALTER SEQUENCE [ IF EXISTS ] name SET SCHEMA new_schema

DESCRIPTION
       ALTER SEQUENCE changes the parameters of an existing sequence
       generator. Any parameters not specifically set in the ALTER SEQUENCE
       command retain their prior settings.

<!-- ad137a5f-7fa1-4b53-a38d-4827f1ccde6e <=< ACCEPT -->       You must own the sequence to use ALTER SEQUENCE. To change a sequence's
       schema, you must also have CREATE privilege on the new schema. To alter
       the owner, you must also be a direct or indirect member of the new
       owning role, and that role must have CREATE privilege on the sequence's
       schema. (These restrictions enforce that altering the owner doesn't do
       anything you couldn't do by dropping and recreating the sequence.
       However, a superuser can alter ownership of any sequence anyway.)<!-- ACCEPT >=> ad137a5f-7fa1-4b53-a38d-4827f1ccde6e -->

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of a sequence to be altered.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       IF EXISTS
           Do not throw an error if the sequence does not exist. A notice is
           issued in this case.

       increment
           The clause INCREMENT BY increment is optional. A positive value
           will make an ascending sequence, a negative one a descending
           sequence. If unspecified, the old increment value will be
           maintained.

       minvalue
       NO MINVALUE
           The optional clause MINVALUE minvalue determines the minimum value
           a sequence can generate. If NO MINVALUE is specified, the defaults
           of 1 and -2^63-1 for ascending and descending sequences,
           respectively, will be used. If neither option is specified, the
           current minimum value will be maintained.

       maxvalue
       NO MAXVALUE
           The optional clause MAXVALUE maxvalue determines the maximum value
           for the sequence. If NO MAXVALUE is specified, the defaults are
           2^63-1 and -1 for ascending and descending sequences, respectively,
           will be used. If neither option is specified, the current maximum
           value will be maintained.

       start
           The optional clause START WITH start changes the recorded start
           value of the sequence. This has no effect on the current sequence
           value; it simply sets the value that future ALTER SEQUENCE RESTART
           commands will use.

       restart
           The optional clause RESTART [ WITH restart ] changes the current
           value of the sequence. This is equivalent to calling the setval
           function with is_called = false: the specified value will be
           returned by the next call of nextval. Writing RESTART with no
           restart value is equivalent to supplying the start value that was
           recorded by CREATE SEQUENCE or last set by ALTER SEQUENCE START
           WITH.

<!-- 876beccf-ebcb-4002-ae74-553e963fc807 <=< ACCEPT -->       cache
           The clause CACHE cache enables sequence numbers to be preallocated
           and stored in memory for faster access. The minimum value is 1
           (only one value can be generated at a time, i.e., no cache). If
           unspecified, the old cache value will be maintained.

       CYCLE
           The optional CYCLE key word can be used to enable the sequence to
           wrap around when the maxvalue or minvalue has been reached by an
           ascending or descending sequence respectively. If the limit is
           reached, the next number generated will be the minvalue or
           maxvalue, respectively.

       NO CYCLE
           If the optional NO CYCLE key word is specified, any calls to
           nextval after the sequence has reached its maximum value will
           return an error. If neither CYCLE or NO CYCLE are specified, the
           old cycle behavior will be maintained.

       OWNED BY table_name.column_name
       OWNED BY NONE
           The OWNED BY option causes the sequence to be associated with a
           specific table column, such that if that column (or its whole
           table) is dropped, the sequence will be automatically dropped as
           well. If specified, this association replaces any previously
           specified association for the sequence. The specified table must
           have the same owner and be in the same schema as the sequence.
           Specifying OWNED BY NONE removes any existing association, making
           the sequence "free-standing".
<!-- ACCEPT >=> 876beccf-ebcb-4002-ae74-553e963fc807 -->
       new_owner
           The user name of the new owner of the sequence.

       new_name
           The new name for the sequence.

       new_schema
           The new schema for the sequence.

NOTES
       To avoid blocking of concurrent transactions that obtain numbers from
       the same sequence, ALTER SEQUENCE's effects on the sequence generation
       parameters are never rolled back; those changes take effect immediately
       and are not reversible. However, the OWNED BY, OWNER TO, RENAME TO, and
       SET SCHEMA clauses cause ordinary catalog updates that can be rolled
       back.

       ALTER SEQUENCE will not immediately affect nextval results in backends,
       other than the current one, that have preallocated (cached) sequence
       values. They will use up all cached values prior to noticing the
       changed sequence generation parameters. The current backend will be
       affected immediately.

       ALTER SEQUENCE does not affect the currval status for the sequence.
       (Before PostgreSQL 8.3, it sometimes did.)

       For historical reasons, ALTER TABLE can be used with sequences too; but
       the only variants of ALTER TABLE that are allowed with sequences are
       equivalent to the forms shown above.

EXAMPLES
       Restart a sequence called serial, at 105:

           ALTER SEQUENCE serial RESTART WITH 105;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       ALTER SEQUENCE conforms to the SQL standard, except for the START WITH,
       OWNED BY, OWNER TO, RENAME TO, and SET SCHEMA clauses, which are
       PostgreSQL extensions.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

SEE ALSO
       CREATE SEQUENCE (CREATE_SEQUENCE(7)), DROP SEQUENCE (DROP_SEQUENCE(7))



PostgreSQL 9.6.1                     2016                    ALTER SEQUENCE(7)
DROP TEXT SEARCH DICTIONPostgreSQL 9.6.1 DocumenDROPoTEXT SEARCH DICTIONARY(7)



NAME
       DROP_TEXT_SEARCH_DICTIONARY - remove a text search dictionary

SYNOPSIS
       DROP TEXT SEARCH DICTIONARY [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP TEXT SEARCH DICTIONARY drops an existing text search dictionary.
       To execute this command you must be the owner of the dictionary.

PARAMETERS
       IF EXISTS
           Do not throw an error if the text search dictionary does not exist.
           A notice is issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing text search
           dictionary.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the text search
           dictionary, and in turn all objects that depend on those objects
           (see Section 5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the text search dictionary if any objects depend on
           it. This is the default.

EXAMPLES
       Remove the text search dictionary english:

           DROP TEXT SEARCH DICTIONARY english;

       This command will not succeed if there are any existing text search
       configurations that use the dictionary. Add CASCADE to drop such
       configurations along with the dictionary.

COMPATIBILITY
       There is no DROP TEXT SEARCH DICTIONARY statement in the SQL standard.

SEE ALSO
       ALTER TEXT SEARCH DICTIONARY (ALTER_TEXT_SEARCH_DICTIONARY(7)), CREATE
       TEXT SEARCH DICTIONARY (CREATE_TEXT_SEARCH_DICTIONARY(7))



PostgreSQL 9.6.1                     2016       DROP TEXT SEARCH DICTIONARY(7)

CREATE FOREIGN DATA WRAPPostgreSQL 9.6.1 DocumenCREATE FOREIGN DATA WRAPPER(7)



NAME
       CREATE_FOREIGN_DATA_WRAPPER - define a new foreign-data wrapper

SYNOPSIS
       CREATE FOREIGN DATA WRAPPER name
           [ HANDLER handler_function | NO HANDLER ]
           [ VALIDATOR validator_function | NO VALIDATOR ]
           [ OPTIONS ( option 'value' [, ... ] ) ]

DESCRIPTION
       CREATE FOREIGN DATA WRAPPER creates a new foreign-data wrapper. The
       user who defines a foreign-data wrapper becomes its owner.

       The foreign-data wrapper name must be unique within the database.

       Only superusers can create foreign-data wrappers.

PARAMETERS
       name
           The name of the foreign-data wrapper to be created.

       HANDLER handler_function
           handler_function is the name of a previously registered function
           that will be called to retrieve the execution functions for foreign
           tables. The handler function must take no arguments, and its return
           type must be fdw_handler.

           It is possible to create a foreign-data wrapper with no handler
           function, but foreign tables using such a wrapper can only be
           declared, not accessed.

       VALIDATOR validator_function
           validator_function is the name of a previously registered function
           that will be called to check the generic options given to the
           foreign-data wrapper, as well as options for foreign servers, user
           mappings and foreign tables using the foreign-data wrapper. If no
           validator function or NO VALIDATOR is specified, then options will
           not be checked at creation time. (Foreign-data wrappers will
           possibly ignore or reject invalid option specifications at run
           time, depending on the implementation.) The validator function must
           take two arguments: one of type text[], which will contain the
           array of options as stored in the system catalogs, and one of type
           oid, which will be the OID of the system catalog containing the
           options. The return type is ignored; the function should report
           invalid options using the ereport(ERROR) function.

       OPTIONS ( option 'value' [, ... ] )
           This clause specifies options for the new foreign-data wrapper. The
           allowed option names and values are specific to each foreign data
           wrapper and are validated using the foreign-data wrapper's
           validator function. Option names must be unique.

NOTES
       PostgreSQL's foreign-data functionality is still under active
       development. Optimization of queries is primitive (and mostly left to
       the wrapper, too). Thus, there is considerable room for future
       performance improvements.

EXAMPLES
       Create a useless foreign-data wrapper dummy:

           CREATE FOREIGN DATA WRAPPER dummy;

       Create a foreign-data wrapper file with handler function
       file_fdw_handler:

           CREATE FOREIGN DATA WRAPPER file HANDLER file_fdw_handler;

       Create a foreign-data wrapper mywrapper with some options:

           CREATE FOREIGN DATA WRAPPER mywrapper
               OPTIONS (debug 'true');

COMPATIBILITY
       CREATE FOREIGN DATA WRAPPER conforms to ISO/IEC 9075-9 (SQL/MED), with
       the exception that the HANDLER and VALIDATOR clauses are extensions and
       the standard clauses LIBRARY and LANGUAGE are not implemented in
       PostgreSQL.

       Note, however, that the SQL/MED functionality as a whole is not yet
       conforming.

SEE ALSO
       ALTER FOREIGN DATA WRAPPER (ALTER_FOREIGN_DATA_WRAPPER(7)), DROP
       FOREIGN DATA WRAPPER (DROP_FOREIGN_DATA_WRAPPER(7)), CREATE SERVER
       (CREATE_SERVER(7)), CREATE USER MAPPING (CREATE_USER_MAPPING(7)),
       CREATE FOREIGN TABLE (CREATE_FOREIGN_TABLE(7))



PostgreSQL 9.6.1                     2016       CREATE FOREIGN DATA WRAPPER(7)
ALTER TYPE(7)           PostgreSQL 9.6.1 Documentation           ALTER TYPE(7)



NAME
       ALTER_TYPE - change the definition of a type

SYNOPSIS
       ALTER TYPE name action [, ... ]
       ALTER TYPE name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER TYPE name RENAME ATTRIBUTE attribute_name TO new_attribute_name [ CASCADE | RESTRICT ]
       ALTER TYPE name RENAME TO new_name
       ALTER TYPE name SET SCHEMA new_schema
       ALTER TYPE name ADD VALUE [ IF NOT EXISTS ] new_enum_value [ { BEFORE | AFTER } existing_enum_value ]

       where action is one of:

           ADD ATTRIBUTE attribute_name data_type [ COLLATE collation ] [ CASCADE | RESTRICT ]
           DROP ATTRIBUTE [ IF EXISTS ] attribute_name [ CASCADE | RESTRICT ]
           ALTER ATTRIBUTE attribute_name [ SET DATA ] TYPE data_type [ COLLATE collation ] [ CASCADE | RESTRICT ]

DESCRIPTION
       ALTER TYPE changes the definition of an existing type. There are
       several subforms:

       ADD ATTRIBUTE
           This form adds a new attribute to a composite type, using the same
           syntax as CREATE TYPE (CREATE_TYPE(7)).

       DROP ATTRIBUTE [ IF EXISTS ]
           This form drops an attribute from a composite type. If IF EXISTS is
           specified and the attribute does not exist, no error is thrown. In
           this case a notice is issued instead.

       SET DATA TYPE
           This form changes the type of an attribute of a composite type.

       OWNER
           This form changes the owner of the type.

       RENAME
           This form changes the name of the type or the name of an individual
           attribute of a composite type.

       SET SCHEMA
           This form moves the type into another schema.

       ADD VALUE [ IF NOT EXISTS ] [ BEFORE | AFTER ]
           This form adds a new value to an enum type. The new value's place
           in the enum's ordering can be specified as being BEFORE or AFTER
           one of the existing values. Otherwise, the new item is added at the
           end of the list of values.

           If IF NOT EXISTS is specified, it is not an error if the type
           already contains the new value: a notice is issued but no other
           action is taken. Otherwise, an error will occur if the new value is
           already present.

       CASCADE
           Automatically propagate the operation to typed tables of the type
           being altered, and their descendants.

       RESTRICT
           Refuse the operation if the type being altered is the type of a
           typed table. This is the default.

       The ADD ATTRIBUTE, DROP ATTRIBUTE, and ALTER ATTRIBUTE actions can be
       combined into a list of multiple alterations to apply in parallel. For
       example, it is possible to add several attributes and/or alter the type
       of several attributes in a single command.

<!-- ad137a5f-7fa1-4b53-a38d-4827f1ccde6e <=< ACCEPT -->       You must own the type to use ALTER TYPE. To change the schema of a
       type, you must also have CREATE privilege on the new schema. To alter
       the owner, you must also be a direct or indirect member of the new
       owning role, and that role must have CREATE privilege on the type's
       schema. (These restrictions enforce that altering the owner doesn't do
       anything you couldn't do by dropping and recreating the type. However,
       a superuser can alter ownership of any type anyway.) To add an
       attribute or alter an attribute type, you must also have USAGE
       privilege on the data type.<!-- ACCEPT >=> ad137a5f-7fa1-4b53-a38d-4827f1ccde6e -->

PARAMETERS
       name
           The name (possibly schema-qualified) of an existing type to alter.

       new_name
           The new name for the type.

       new_owner
           The user name of the new owner of the type.

       new_schema
           The new schema for the type.

       attribute_name
           The name of the attribute to add, alter, or drop.

       new_attribute_name
           The new name of the attribute to be renamed.

       data_type
           The data type of the attribute to add, or the new type of the
           attribute to alter.

       new_enum_value
           The new value to be added to an enum type's list of values. Like
           all enum literals, it needs to be quoted.

       existing_enum_value
           The existing enum value that the new value should be added
           immediately before or after in the enum type's sort ordering. Like
           all enum literals, it needs to be quoted.

NOTES
       ALTER TYPE ... ADD VALUE (the form that adds a new value to an enum
       type) cannot be executed inside a transaction block.

       Comparisons involving an added enum value will sometimes be slower than
       comparisons involving only original members of the enum type. This will
       usually only occur if BEFORE or AFTER is used to set the new value's
       sort position somewhere other than at the end of the list. However,
       sometimes it will happen even though the new value is added at the end
       (this occurs if the OID counter "wrapped around" since the original
       creation of the enum type). The slowdown is usually insignificant; but
       if it matters, optimal performance can be regained by dropping and
       recreating the enum type, or by dumping and reloading the database.

EXAMPLES
       To rename a data type:

           ALTER TYPE electronic_mail RENAME TO email;

       To change the owner of the type email to joe:

           ALTER TYPE email OWNER TO joe;

       To change the schema of the type email to customers:

           ALTER TYPE email SET SCHEMA customers;

       To add a new attribute to a type:

           ALTER TYPE compfoo ADD ATTRIBUTE f3 int;

       To add a new value to an enum type in a particular sort position:

           ALTER TYPE colors ADD VALUE 'orange' AFTER 'red';

COMPATIBILITY
       The variants to add and drop attributes are part of the SQL standard;
       the other variants are PostgreSQL extensions.

SEE ALSO
       CREATE TYPE (CREATE_TYPE(7)), DROP TYPE (DROP_TYPE(7))



PostgreSQL 9.6.1                     2016                        ALTER TYPE(7)
COPY(7)                 PostgreSQL 9.6.1 Documentation                 COPY(7)



NAME
       COPY - copy data between a file and a table

SYNOPSIS
       COPY table_name [ ( column_name [, ...] ) ]
           FROM { 'filename' | PROGRAM 'command' | STDIN }
           [ [ WITH ] ( option [, ...] ) ]

       COPY { table_name [ ( column_name [, ...] ) ] | ( query ) }
           TO { 'filename' | PROGRAM 'command' | STDOUT }
           [ [ WITH ] ( option [, ...] ) ]

       where option can be one of:

           FORMAT format_name
           OIDS [ boolean ]
           FREEZE [ boolean ]
           DELIMITER 'delimiter_character'
           NULL 'null_string'
           HEADER [ boolean ]
           QUOTE 'quote_character'
           ESCAPE 'escape_character'
           FORCE_QUOTE { ( column_name [, ...] ) | * }
           FORCE_NOT_NULL ( column_name [, ...] )
           FORCE_NULL ( column_name [, ...] )
           ENCODING 'encoding_name'

DESCRIPTION
       COPY moves data between PostgreSQL tables and standard file-system
       files.  COPY TO copies the contents of a table to a file, while COPY
       FROM copies data from a file to a table (appending the data to whatever
       is in the table already).  COPY TO can also copy the results of a
       SELECT query.

       If a list of columns is specified, COPY will only copy the data in the
       specified columns to or from the file. If there are any columns in the
       table that are not in the column list, COPY FROM will insert the
       default values for those columns.

       COPY with a file name instructs the PostgreSQL server to directly read
       from or write to a file. The file must be accessible by the PostgreSQL
       user (the user ID the server runs as) and the name must be specified
       from the viewpoint of the server. When PROGRAM is specified, the server
       executes the given command and reads from the standard output of the
       program, or writes to the standard input of the program. The command
       must be specified from the viewpoint of the server, and be executable
       by the PostgreSQL user. When STDIN or STDOUT is specified, data is
       transmitted via the connection between the client and the server.

PARAMETERS
       table_name
           The name (optionally schema-qualified) of an existing table.

       column_name
           An optional list of columns to be copied. If no column list is
           specified, all columns of the table will be copied.

       query
           A SELECT(7), VALUES(7), INSERT(7), UPDATE(7) or DELETE(7) command
           whose results are to be copied. Note that parentheses are required
           around the query.

           For INSERT, UPDATE and DELETE queries a RETURNING clause must be
           provided, and the target relation must not have a conditional rule,
           nor an ALSO rule, nor an INSTEAD rule that expands to multiple
           statements.

       filename
           The path name of the input or output file. An input file name can
           be an absolute or relative path, but an output file name must be an
           absolute path. Windows users might need to use an E'' string and
           double any backslashes used in the path name.

       PROGRAM
           A command to execute. In COPY FROM, the input is read from standard
           output of the command, and in COPY TO, the output is written to the
           standard input of the command.

           Note that the command is invoked by the shell, so if you need to
           pass any arguments to shell command that come from an untrusted
           source, you must be careful to strip or escape any special
           characters that might have a special meaning for the shell. For
           security reasons, it is best to use a fixed command string, or at
           least avoid passing any user input in it.

       STDIN
           Specifies that input comes from the client application.

       STDOUT
           Specifies that output goes to the client application.

       boolean
           Specifies whether the selected option should be turned on or off.
           You can write TRUE, ON, or 1 to enable the option, and FALSE, OFF,
           or 0 to disable it. The boolean value can also be omitted, in which
           case TRUE is assumed.

       FORMAT
           Selects the data format to be read or written: text, csv (Comma
           Separated Values), or binary. The default is text.

       OIDS
           Specifies copying the OID for each row. (An error is raised if OIDS
           is specified for a table that does not have OIDs, or in the case of
           copying a query.)

       FREEZE
           Requests copying the data with rows already frozen, just as they
           would be after running the VACUUM FREEZE command. This is intended
           as a performance option for initial data loading. Rows will be
           frozen only if the table being loaded has been created or truncated
           in the current subtransaction, there are no cursors open and there
           are no older snapshots held by this transaction.

           Note that all other sessions will immediately be able to see the
           data once it has been successfully loaded. This violates the normal
           rules of MVCC visibility and users specifying should be aware of
           the potential problems this might cause.

       DELIMITER
           Specifies the character that separates columns within each row
           (line) of the file. The default is a tab character in text format,
           a comma in CSV format. This must be a single one-byte character.
           This option is not allowed when using binary format.

       NULL
           Specifies the string that represents a null value. The default is
           \N (backslash-N) in text format, and an unquoted empty string in
           CSV format. You might prefer an empty string even in text format
           for cases where you don't want to distinguish nulls from empty
           strings. This option is not allowed when using binary format.

               Note
               When using COPY FROM, any data item that matches this string
               will be stored as a null value, so you should make sure that
               you use the same string as you used with COPY TO.

       HEADER
           Specifies that the file contains a header line with the names of
           each column in the file. On output, the first line contains the
           column names from the table, and on input, the first line is
           ignored. This option is allowed only when using CSV format.

       QUOTE
           Specifies the quoting character to be used when a data value is
           quoted. The default is double-quote. This must be a single one-byte
           character. This option is allowed only when using CSV format.

       ESCAPE
           Specifies the character that should appear before a data character
           that matches the QUOTE value. The default is the same as the QUOTE
           value (so that the quoting character is doubled if it appears in
           the data). This must be a single one-byte character. This option is
           allowed only when using CSV format.

       FORCE_QUOTE
           Forces quoting to be used for all non-NULL values in each specified
           column.  NULL output is never quoted. If * is specified, non-NULL
           values will be quoted in all columns. This option is allowed only
           in COPY TO, and only when using CSV format.

       FORCE_NOT_NULL
           Do not match the specified columns' values against the null string.
           In the default case where the null string is empty, this means that
           empty values will be read as zero-length strings rather than nulls,
           even when they are not quoted. This option is allowed only in COPY
           FROM, and only when using CSV format.

       FORCE_NULL
           Match the specified columns' values against the null string, even
           if it has been quoted, and if a match is found set the value to
           NULL. In the default case where the null string is empty, this
           converts a quoted empty string into NULL. This option is allowed
           only in COPY FROM, and only when using CSV format.

       ENCODING
           Specifies that the file is encoded in the encoding_name. If this
           option is omitted, the current client encoding is used. See the
           Notes below for more details.

OUTPUTS
       On successful completion, a COPY command returns a command tag of the
       form

           COPY count

       The count is the number of rows copied.

           Note
           psql will print this command tag only if the command was not COPY
           ... TO STDOUT, or the equivalent psql meta-command \copy ... to
           stdout. This is to prevent confusing the command tag with the data
           that was just printed.

NOTES
       COPY can only be used with plain tables, not with views. However, you
       can write COPY (SELECT * FROM viewname) TO ....

       COPY only deals with the specific table named; it does not copy data to
       or from child tables. Thus for example COPY table TO shows the same
       data as SELECT * FROM ONLY table. But COPY (SELECT * FROM table) TO ...
       can be used to dump all of the data in an inheritance hierarchy.

       You must have select privilege on the table whose values are read by
       COPY TO, and insert privilege on the table into which values are
       inserted by COPY FROM. It is sufficient to have column privileges on
       the column(s) listed in the command.

       Files named in a COPY command are read or written directly by the
       server, not by the client application. Therefore, they must reside on
       or be accessible to the database server machine, not the client. They
       must be accessible to and readable or writable by the PostgreSQL user
       (the user ID the server runs as), not the client. Similarly, the
       command specified with PROGRAM is executed directly by the server, not
       by the client application, must be executable by the PostgreSQL user.
       COPY naming a file or command is only allowed to database superusers,
       since it allows reading or writing any file that the server has
       privileges to access.

       Do not confuse COPY with the psql instruction \copy invokes COPY FROM
       STDIN or COPY TO STDOUT, and then fetches/stores the data in a file
       accessible to the psql client. Thus, file accessibility and access
       rights depend on the client rather than the server when \copy is used.

       It is recommended that the file name used in COPY always be specified
       as an absolute path. This is enforced by the server in the case of COPY
       TO, but for COPY FROM you do have the option of reading from a file
       specified by a relative path. The path will be interpreted relative to
       the working directory of the server process (normally the cluster's
       data directory), not the client's working directory.

       Executing a command with PROGRAM might be restricted by the operating
       system's access control mechanisms, such as SELinux.

       COPY FROM will invoke any triggers and check constraints on the
       destination table. However, it will not invoke rules.

       COPY input and output is affected by DateStyle. To ensure portability
       to other PostgreSQL installations that might use non-default DateStyle
       settings, DateStyle should be set to ISO before using COPY TO. It is
       also a good idea to avoid dumping data with IntervalStyle set to
       sql_standard, because negative interval values might be misinterpreted
       by a server that has a different setting for IntervalStyle.

       Input data is interpreted according to ENCODING option or the current
       client encoding, and output data is encoded in ENCODING or the current
       client encoding, even if the data does not pass through the client but
       is read from or written to a file directly by the server.

       COPY stops operation at the first error. This should not lead to
       problems in the event of a COPY TO, but the target table will already
       have received earlier rows in a COPY FROM. These rows will not be
       visible or accessible, but they still occupy disk space. This might
       amount to a considerable amount of wasted disk space if the failure
       happened well into a large copy operation. You might wish to invoke
       VACUUM to recover the wasted space.

       FORCE_NULL and FORCE_NOT_NULL can be used simultaneously on the same
       column. This results in converting quoted null strings to null values
       and unquoted null strings to empty strings.

FILE FORMATS
   Text Format
       When the text format is used, the data read or written is a text file
       with one line per table row. Columns in a row are separated by the
       delimiter character. The column values themselves are strings generated
       by the output function, or acceptable to the input function, of each
       attribute's data type. The specified null string is used in place of
       columns that are null.  COPY FROM will raise an error if any line of
       the input file contains more or fewer columns than are expected. If
       OIDS is specified, the OID is read or written as the first column,
       preceding the user data columns.

       End of data can be represented by a single line containing just
       backslash-period (\.). An end-of-data marker is not necessary when
       reading from a file, since the end of file serves perfectly well; it is
       needed only when copying data to or from client applications using
       pre-3.0 client protocol.

       Backslash characters (\) can be used in the COPY data to quote data
       characters that might otherwise be taken as row or column delimiters.
       In particular, the following characters must be preceded by a backslash
       if they appear as part of a column value: backslash itself, newline,
       carriage return, and the current delimiter character.

       The specified null string is sent by COPY TO without adding any
       backslashes; conversely, COPY FROM matches the input against the null
       string before removing backslashes. Therefore, a null string such as \N
       cannot be confused with the actual data value \N (which would be
       represented as \\N).

       The following special backslash sequences are recognized by COPY FROM:

       +---------+----------------------------+
       |Sequence | Represents                 |
       +---------+----------------------------+
       |\b       | Backspace (ASCII 8)        |
       +---------+----------------------------+
       |\f       | Form feed (ASCII 12)       |
       +---------+----------------------------+
       |\n       | Newline (ASCII 10)         |
       +---------+----------------------------+
       |\r       | Carriage return (ASCII 13) |
       +---------+----------------------------+
       |\t       | Tab (ASCII 9)              |
       +---------+----------------------------+
       |\v       | Vertical tab (ASCII 11)    |
       +---------+----------------------------+
       |\digits  | Backslash followed by one  |
       |         | to three octal digits      |
       |         | specifies                  |
       |         |        the character with  |
       |         | that numeric code          |
       +---------+----------------------------+
       |\xdigits | Backslash x followed by    |
       |         | one or two hex digits      |
       |         | specifies                  |
       |         |        the character with  |
       |         | that numeric code          |
       +---------+----------------------------+
       Presently, COPY TO will never emit an octal or hex-digits backslash
       sequence, but it does use the other sequences listed above for those
       control characters.

       Any other backslashed character that is not mentioned in the above
       table will be taken to represent itself. However, beware of adding
       backslashes unnecessarily, since that might accidentally produce a
       string matching the end-of-data marker (\.) or the null string (\N by
       default). These strings will be recognized before any other backslash
       processing is done.

       It is strongly recommended that applications generating COPY data
       convert data newlines and carriage returns to the \n and \r sequences
       respectively. At present it is possible to represent a data carriage
       return by a backslash and carriage return, and to represent a data
       newline by a backslash and newline. However, these representations
       might not be accepted in future releases. They are also highly
       vulnerable to corruption if the COPY file is transferred across
       different machines (for example, from Unix to Windows or vice versa).

       COPY TO will terminate each row with a Unix-style newline ("\n").
       Servers running on Microsoft Windows instead output carriage
       return/newline ("\r\n"), but only for COPY to a server file; for
       consistency across platforms, COPY TO STDOUT always sends "\n"
       regardless of server platform.  COPY FROM can handle lines ending with
       newlines, carriage returns, or carriage return/newlines. To reduce the
       risk of error due to un-backslashed newlines or carriage returns that
       were meant as data, COPY FROM will complain if the line endings in the
       input are not all alike.

   CSV Format
       This format option is used for importing and exporting the Comma
       Separated Value (CSV) file format used by many other programs, such as
       spreadsheets. Instead of the escaping rules used by PostgreSQL's
       standard text format, it produces and recognizes the common CSV
       escaping mechanism.

       The values in each record are separated by the DELIMITER character. If
       the value contains the delimiter character, the QUOTE character, the
       NULL string, a carriage return, or line feed character, then the whole
       value is prefixed and suffixed by the QUOTE character, and any
       occurrence within the value of a QUOTE character or the ESCAPE
       character is preceded by the escape character. You can also use
       FORCE_QUOTE to force quotes when outputting non-NULL values in specific
       columns.

       The CSV format has no standard way to distinguish a NULL value from an
       empty string.  PostgreSQL's COPY handles this by quoting. A NULL is
       output as the NULL parameter string and is not quoted, while a non-NULL
       value matching the NULL parameter string is quoted. For example, with
       the default settings, a NULL is written as an unquoted empty string,
       while an empty string data value is written with double quotes ("").
       Reading values follows similar rules. You can use FORCE_NOT_NULL to
       prevent NULL input comparisons for specific columns. You can also use
       FORCE_NULL to convert quoted null string data values to NULL.

       Because backslash is not a special character in the CSV format, \., the
       end-of-data marker, could also appear as a data value. To avoid any
       misinterpretation, a \.  data value appearing as a lone entry on a line
       is automatically quoted on output, and on input, if quoted, is not
       interpreted as the end-of-data marker. If you are loading a file
       created by another application that has a single unquoted column and
       might have a value of \., you might need to quote that value in the
       input file.

           Note
           In CSV format, all characters are significant. A quoted value
           surrounded by white space, or any characters other than DELIMITER,
           will include those characters. This can cause errors if you import
           data from a system that pads CSV lines with white space out to some
           fixed width. If such a situation arises you might need to
           preprocess the CSV file to remove the trailing white space, before
           importing the data into PostgreSQL.

           Note
           CSV format will both recognize and produce CSV files with quoted
           values containing embedded carriage returns and line feeds. Thus
           the files are not strictly one line per table row like text-format
           files.

           Note
           Many programs produce strange and occasionally perverse CSV files,
           so the file format is more a convention than a standard. Thus you
           might encounter some files that cannot be imported using this
           mechanism, and COPY might produce files that other programs cannot
           process.

   Binary Format
       The binary format option causes all data to be stored/read as binary
       format rather than as text. It is somewhat faster than the text and CSV
       formats, but a binary-format file is less portable across machine
       architectures and PostgreSQL versions. Also, the binary format is very
       data type specific; for example it will not work to output binary data
       from a smallint column and read it into an integer column, even though
       that would work fine in text format.

       The binary file format consists of a file header, zero or more tuples
       containing the row data, and a file trailer. Headers and data are in
       network byte order.

           Note
           PostgreSQL releases before 7.4 used a different binary file format.

       File Header
           The file header consists of 15 bytes of fixed fields, followed by a
           variable-length header extension area. The fixed fields are:

           Signature
               11-byte sequence PGCOPY\n\377\r\n\0 -- note that the zero byte
               is a required part of the signature. (The signature is designed
               to allow easy identification of files that have been munged by
               a non-8-bit-clean transfer. This signature will be changed by
               end-of-line-translation filters, dropped zero bytes, dropped
               high bits, or parity changes.)

           Flags field
               32-bit integer bit mask to denote important aspects of the file
               format. Bits are numbered from 0 (LSB) to 31 (MSB). Note that
               this field is stored in network byte order (most significant
               byte first), as are all the integer fields used in the file
               format. Bits 16-31 are reserved to denote critical file format
               issues; a reader should abort if it finds an unexpected bit set
               in this range. Bits 0-15 are reserved to signal
               backwards-compatible format issues; a reader should simply
               ignore any unexpected bits set in this range. Currently only
               one flag bit is defined, and the rest must be zero:

               Bit 16
                   if 1, OIDs are included in the data; if 0, not

           Header extension area length
               32-bit integer, length in bytes of remainder of header, not
               including self. Currently, this is zero, and the first tuple
               follows immediately. Future changes to the format might allow
               additional data to be present in the header. A reader should
               silently skip over any header extension data it does not know
               what to do with.

           The header extension area is envisioned to contain a sequence of
           self-identifying chunks. The flags field is not intended to tell
           readers what is in the extension area. Specific design of header
           extension contents is left for a later release.

           This design allows for both backwards-compatible header additions
           (add header extension chunks, or set low-order flag bits) and
           non-backwards-compatible changes (set high-order flag bits to
           signal such changes, and add supporting data to the extension area
           if needed).

       Tuples
           Each tuple begins with a 16-bit integer count of the number of
           fields in the tuple. (Presently, all tuples in a table will have
           the same count, but that might not always be true.) Then, repeated
           for each field in the tuple, there is a 32-bit length word followed
           by that many bytes of field data. (The length word does not include
           itself, and can be zero.) As a special case, -1 indicates a NULL
           field value. No value bytes follow in the NULL case.

           There is no alignment padding or any other extra data between
           fields.

           Presently, all data values in a binary-format file are assumed to
           be in binary format (format code one). It is anticipated that a
           future extension might add a header field that allows per-column
           format codes to be specified.

           To determine the appropriate binary format for the actual tuple
           data you should consult the PostgreSQL source, in particular the
           *send and *recv functions for each column's data type (typically
           these functions are found in the src/backend/utils/adt/ directory
           of the source distribution).

           If OIDs are included in the file, the OID field immediately follows
           the field-count word. It is a normal field except that it's not
           included in the field-count. In particular it has a length word --
           this will allow handling of 4-byte vs. 8-byte OIDs without too much
           pain, and will allow OIDs to be shown as null if that ever proves
           desirable.

       File Trailer
           The file trailer consists of a 16-bit integer word containing -1.
           This is easily distinguished from a tuple's field-count word.

           A reader should report an error if a field-count word is neither -1
           nor the expected number of columns. This provides an extra check
           against somehow getting out of sync with the data.

EXAMPLES
       The following example copies a table to the client using the vertical
       bar (|) as the field delimiter:

           COPY country TO STDOUT (DELIMITER '|');

       To copy data from a file into the country table:

           COPY country FROM '/usr1/proj/bray/sql/country_data';

       To copy into a file just the countries whose names start with 'A':

           COPY (SELECT * FROM country WHERE country_name LIKE 'A%') TO '/usr1/proj/bray/sql/a_list_countries.copy';

       To copy into a compressed file, you can pipe the output through an
       external compression program:

           COPY country TO PROGRAM 'gzip &amp;gt; /usr1/proj/bray/sql/country_data.gz';

       Here is a sample of data suitable for copying into a table from STDIN:

           AF      AFGHANISTAN
           AL      ALBANIA
           DZ      ALGERIA
           ZM      ZAMBIA
           ZW      ZIMBABWE

       Note that the white space on each line is actually a tab character.

       The following is the same data, output in binary format. The data is
       shown after filtering through the Unix utility od -c. The table has
       three columns; the first has type char(2), the second has type text,
       and the third has type integer. All the rows have a null value in the
       third column.

           0000000   P   G   C   O   P   Y  \n 377  \r  \n  \0  \0  \0  \0  \0  \0
           0000020  \0  \0  \0  \0 003  \0  \0  \0 002   A   F  \0  \0  \0 013   A
           0000040   F   G   H   A   N   I   S   T   A   N 377 377 377 377  \0 003
           0000060  \0  \0  \0 002   A   L  \0  \0  \0 007   A   L   B   A   N   I
           0000100   A 377 377 377 377  \0 003  \0  \0  \0 002   D   Z  \0  \0  \0
           0000120 007   A   L   G   E   R   I   A 377 377 377 377  \0 003  \0  \0
           0000140  \0 002   Z   M  \0  \0  \0 006   Z   A   M   B   I   A 377 377
           0000160 377 377  \0 003  \0  \0  \0 002   Z   W  \0  \0  \0  \b   Z   I
           0000200   M   B   A   B   W   E 377 377 377 377 377 377

COMPATIBILITY
       There is no COPY statement in the SQL standard.

       The following syntax was used before PostgreSQL version 9.0 and is
       still supported:

<!-- 54430814-a150-43f0-80b2-fb24d9ee7a80 <=< ACCEPT -->           COPY table_name [ ( column_name [, ...] ) ]
               FROM { 'filename' | STDIN }
               [ [ WITH ]
                     [ BINARY ]
                     [ OIDS ]
                     [ DELIMITER [ AS ] 'delimiter' ]
                     [ NULL [ AS ] 'null string' ]
                     [ CSV [ HEADER ]
                           [ QUOTE [ AS ] 'quote' ]
                           [ ESCAPE [ AS ] 'escape' ]
                           [ FORCE NOT NULL column_name [, ...] ] ] ]<!-- ACCEPT >=> 54430814-a150-43f0-80b2-fb24d9ee7a80 -->

<!-- 54430814-a150-43f0-80b2-fb24d9ee7a80 <=< ACCEPT -->           COPY { table_name [ ( column_name [, ...] ) ] | ( query ) }
               TO { 'filename' | STDOUT }
               [ [ WITH ]
                     [ BINARY ]
                     [ OIDS ]
                     [ DELIMITER [ AS ] 'delimiter' ]
                     [ NULL [ AS ] 'null string' ]
                     [ CSV [ HEADER ]
                           [ QUOTE [ AS ] 'quote' ]
                           [ ESCAPE [ AS ] 'escape' ]
                           [ FORCE QUOTE { column_name [, ...] | * } ] ] ]
<!-- ACCEPT >=> 54430814-a150-43f0-80b2-fb24d9ee7a80 -->
       Note that in this syntax, BINARY and CSV are treated as independent
       keywords, not as arguments of a FORMAT option.

       The following syntax was used before PostgreSQL version 7.3 and is
       still supported:

           COPY [ BINARY ] table_name [ WITH OIDS ]
               FROM { 'filename' | STDIN }
               [ [USING] DELIMITERS 'delimiter' ]
               [ WITH NULL AS 'null string' ]

           COPY [ BINARY ] table_name [ WITH OIDS ]
               TO { 'filename' | STDOUT }
               [ [USING] DELIMITERS 'delimiter' ]
               [ WITH NULL AS 'null string' ]




PostgreSQL 9.6.1                     2016                              COPY(7)
ALTER FOREIGN DATA WRAPPPostgreSQL 9.6.1 DocumentALTER FOREIGN DATA WRAPPER(7)



NAME
       ALTER_FOREIGN_DATA_WRAPPER - change the definition of a foreign-data
       wrapper

SYNOPSIS
       ALTER FOREIGN DATA WRAPPER name
           [ HANDLER handler_function | NO HANDLER ]
           [ VALIDATOR validator_function | NO VALIDATOR ]
           [ OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ]) ]
       ALTER FOREIGN DATA WRAPPER name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER FOREIGN DATA WRAPPER name RENAME TO new_name

DESCRIPTION
       ALTER FOREIGN DATA WRAPPER changes the definition of a foreign-data
       wrapper. The first form of the command changes the support functions or
       the generic options of the foreign-data wrapper (at least one clause is
       required). The second form changes the owner of the foreign-data
       wrapper.

       Only superusers can alter foreign-data wrappers. Additionally, only
       superusers can own foreign-data wrappers.

PARAMETERS
       name
           The name of an existing foreign-data wrapper.

       HANDLER handler_function
           Specifies a new handler function for the foreign-data wrapper.

       NO HANDLER
           This is used to specify that the foreign-data wrapper should no
           longer have a handler function.

           Note that foreign tables that use a foreign-data wrapper with no
           handler cannot be accessed.

       VALIDATOR validator_function
           Specifies a new validator function for the foreign-data wrapper.

           Note that it is possible that pre-existing options of the
           foreign-data wrapper, or of dependent servers, user mappings, or
           foreign tables, are invalid according to the new validator.
           PostgreSQL does not check for this. It is up to the user to make
           sure that these options are correct before using the modified
           foreign-data wrapper. However, any options specified in this ALTER
           FOREIGN DATA WRAPPER command will be checked using the new
           validator.

       NO VALIDATOR
           This is used to specify that the foreign-data wrapper should no
           longer have a validator function.

       OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ] )
           Change options for the foreign-data wrapper.  ADD, SET, and DROP
           specify the action to be performed.  ADD is assumed if no operation
           is explicitly specified. Option names must be unique; names and
           values are also validated using the foreign data wrapper's
           validator function, if any.

       new_owner
           The user name of the new owner of the foreign-data wrapper.

       new_name
           The new name for the foreign-data wrapper.

EXAMPLES
       Change a foreign-data wrapper dbi, add option foo, drop bar:

           ALTER FOREIGN DATA WRAPPER dbi OPTIONS (ADD foo '1', DROP 'bar');

       Change the foreign-data wrapper dbi validator to bob.myvalidator:

           ALTER FOREIGN DATA WRAPPER dbi VALIDATOR bob.myvalidator;

COMPATIBILITY
       ALTER FOREIGN DATA WRAPPER conforms to ISO/IEC 9075-9 (SQL/MED), except
       that the HANDLER, VALIDATOR, OWNER TO, and RENAME clauses are
       extensions.

SEE ALSO
       CREATE FOREIGN DATA WRAPPER (CREATE_FOREIGN_DATA_WRAPPER(7)), DROP
       FOREIGN DATA WRAPPER (DROP_FOREIGN_DATA_WRAPPER(7))



PostgreSQL 9.6.1                     2016        ALTER FOREIGN DATA WRAPPER(7)
CREATE OPERATOR(7)      PostgreSQL 9.6.1 Documentation      CREATE OPERATOR(7)



NAME
       CREATE_OPERATOR - define a new operator

SYNOPSIS
       CREATE OPERATOR name (
           PROCEDURE = function_name
           [, LEFTARG = left_type ] [, RIGHTARG = right_type ]
           [, COMMUTATOR = com_op ] [, NEGATOR = neg_op ]
           [, RESTRICT = res_proc ] [, JOIN = join_proc ]
           [, HASHES ] [, MERGES ]
       )

DESCRIPTION
       CREATE OPERATOR defines a new operator, name. The user who defines an
       operator becomes its owner. If a schema name is given then the operator
       is created in the specified schema. Otherwise it is created in the
       current schema.

       The operator name is a sequence of up to NAMEDATALEN-1 (63 by default)
       characters from the following list:

           + - * / &amp;lt; &amp;gt; = ~ ! @ # % ^ &amp; | ` ?

       There are a few restrictions on your choice of name:

       o   -- and /* cannot appear anywhere in an operator name, since they
           will be taken as the start of a comment.

       o   A multicharacter operator name cannot end in + or -, unless the
           name also contains at least one of these characters:

               ~ ! @ # % ^ &amp; | ` ?

           For example, @- is an allowed operator name, but *- is not. This
           restriction allows PostgreSQL to parse SQL-compliant commands
           without requiring spaces between tokens.

       o   The use of =&amp;gt; as an operator name is deprecated. It may be
           disallowed altogether in a future release.

       The operator != is mapped to &amp;lt;&amp;gt; on input, so these two names are always
       equivalent.

       At least one of LEFTARG and RIGHTARG must be defined. For binary
       operators, both must be defined. For right unary operators, only
       LEFTARG should be defined, while for left unary operators only RIGHTARG
       should be defined.

       The function_name procedure must have been previously defined using
       CREATE FUNCTION and must be defined to accept the correct number of
       arguments (either one or two) of the indicated types.

       The other clauses specify optional operator optimization clauses. Their
       meaning is detailed in Section 36.13, "Operator Optimization
       Information", in the documentation.

       To be able to create an operator, you must have USAGE privilege on the
       argument types and the return type, as well as EXECUTE privilege on the
       underlying function. If a commutator or negator operator is specified,
       you must own these operators.

PARAMETERS
       name
           The name of the operator to be defined. See above for allowable
           characters. The name can be schema-qualified, for example CREATE
           OPERATOR myschema.+ (...). If not, then the operator is created in
           the current schema. Two operators in the same schema can have the
           same name if they operate on different data types. This is called
           overloading.

       function_name
           The function used to implement this operator.

       left_type
           The data type of the operator's left operand, if any. This option
           would be omitted for a left-unary operator.

       right_type
           The data type of the operator's right operand, if any. This option
           would be omitted for a right-unary operator.

       com_op
           The commutator of this operator.

       neg_op
           The negator of this operator.

       res_proc
           The restriction selectivity estimator function for this operator.

       join_proc
           The join selectivity estimator function for this operator.

       HASHES
           Indicates this operator can support a hash join.

       MERGES
           Indicates this operator can support a merge join.

       To give a schema-qualified operator name in com_op or the other
       optional arguments, use the OPERATOR() syntax, for example:

           COMMUTATOR = OPERATOR(myschema.===) ,

NOTES
       Refer to Section 36.12, "User-defined Operators", in the documentation
       for further information.

       It is not possible to specify an operator's lexical precedence in
       CREATE OPERATOR, because the parser's precedence behavior is
       hard-wired. See Section 4.1.6, "Operator Precedence", in the
       documentation for precedence details.

       The obsolete options SORT1, SORT2, LTCMP, and GTCMP were formerly used
       to specify the names of sort operators associated with a merge-joinable
       operator. This is no longer necessary, since information about
       associated operators is found by looking at B-tree operator families
       instead. If one of these options is given, it is ignored except for
       implicitly setting MERGES true.

       Use DROP OPERATOR (DROP_OPERATOR(7)) to delete user-defined operators
       from a database. Use ALTER OPERATOR (ALTER_OPERATOR(7)) to modify
       operators in a database.

EXAMPLES
       The following command defines a new operator, area-equality, for the
       data type box:

           CREATE OPERATOR === (
               LEFTARG = box,
               RIGHTARG = box,
               PROCEDURE = area_equal_procedure,
               COMMUTATOR = ===,
               NEGATOR = !==,
               RESTRICT = area_restriction_procedure,
               JOIN = area_join_procedure,
               HASHES, MERGES
           );

COMPATIBILITY
       CREATE OPERATOR is a PostgreSQL extension. There are no provisions for
       user-defined operators in the SQL standard.

SEE ALSO
       ALTER OPERATOR (ALTER_OPERATOR(7)), CREATE OPERATOR CLASS
       (CREATE_OPERATOR_CLASS(7)), DROP OPERATOR (DROP_OPERATOR(7))



PostgreSQL 9.6.1                     2016                   CREATE OPERATOR(7)
CREATE EXTENSION(7)     PostgreSQL 9.6.1 Documentation     CREATE EXTENSION(7)



NAME
       CREATE_EXTENSION - install an extension

SYNOPSIS
       CREATE EXTENSION [ IF NOT EXISTS ] extension_name
           [ WITH ] [ SCHEMA schema_name ]
                    [ VERSION version ]
                    [ FROM old_version ]
                    [ CASCADE ]

DESCRIPTION
       CREATE EXTENSION loads a new extension into the current database. There
       must not be an extension of the same name already loaded.

       Loading an extension essentially amounts to running the extension's
       script file. The script will typically create new SQL objects such as
       functions, data types, operators and index support methods.  CREATE
       EXTENSION additionally records the identities of all the created
       objects, so that they can be dropped again if DROP EXTENSION is issued.

       Loading an extension requires the same privileges that would be
       required to create its component objects. For most extensions this
       means superuser or database owner privileges are needed. The user who
       runs CREATE EXTENSION becomes the owner of the extension for purposes
       of later privilege checks, as well as the owner of any objects created
       by the extension's script.

PARAMETERS
       IF NOT EXISTS
           Do not throw an error if an extension with the same name already
           exists. A notice is issued in this case. Note that there is no
           guarantee that the existing extension is anything like the one that
           would have been created from the currently-available script file.

       extension_name
           The name of the extension to be installed.  PostgreSQL will create
           the extension using details from the file
           SHAREDIR/extension/extension_name.control.

       schema_name
           The name of the schema in which to install the extension's objects,
           given that the extension allows its contents to be relocated. The
           named schema must already exist. If not specified, and the
           extension's control file does not specify a schema either, the
           current default object creation schema is used.

           If the extension specifies a schema parameter in its control file,
           then that schema cannot be overridden with a SCHEMA clause.
           Normally, an error will be raised if a SCHEMA clause is given and
           it conflicts with the extension's schema parameter. However, if the
           CASCADE clause is also given, then schema_name is ignored when it
           conflicts. The given schema_name will be used for installation of
           any needed extensions that do not specify schema in their control
           files.

           Remember that the extension itself is not considered to be within
           any schema: extensions have unqualified names that must be unique
           database-wide. But objects belonging to the extension can be within
           schemas.

       version
           The version of the extension to install. This can be written as
           either an identifier or a string literal. The default version is
           whatever is specified in the extension's control file.

       old_version
           FROMold_version must be specified when, and only when, you are
           attempting to install an extension that replaces an "old style"
           module that is just a collection of objects not packaged into an
           extension. This option causes CREATE EXTENSION to run an
           alternative installation script that absorbs the existing objects
           into the extension, instead of creating new objects. Be careful
           that SCHEMA specifies the schema containing these pre-existing
           objects.

           The value to use for old_version is determined by the extension's
           author, and might vary if there is more than one version of the
           old-style module that can be upgraded into an extension. For the
           standard additional modules supplied with pre-9.1 PostgreSQL, use
           unpackaged for old_version when updating a module to extension
           style.

       CASCADE
           Automatically install any extensions that this extension depends on
           that are not already installed. Their dependencies are likewise
           automatically installed, recursively. The SCHEMA clause, if given,
           applies to all extensions that get installed this way. Other
           options of the statement are not applied to automatically-installed
           extensions; in particular, their default versions are always
           selected.

NOTES
       Before you can use CREATE EXTENSION to load an extension into a
       database, the extension's supporting files must be installed.
       Information about installing the extensions supplied with PostgreSQL
       can be found in Additional Supplied Modules.

       The extensions currently available for loading can be identified from
       the pg_available_extensions or pg_available_extension_versions system
       views.

       For information about writing new extensions, see Section 36.15,
       "Packaging Related Objects into an Extension", in the documentation.

EXAMPLES
       Install the hstore extension into the current database:

           CREATE EXTENSION hstore;

       Update a pre-9.1 installation of hstore into extension style:

           CREATE EXTENSION hstore SCHEMA public FROM unpackaged;

       Be careful to specify the schema in which you installed the existing
       hstore objects.

COMPATIBILITY
       CREATE EXTENSION is a PostgreSQL extension.

SEE ALSO
       ALTER EXTENSION (ALTER_EXTENSION(7)), DROP EXTENSION
       (DROP_EXTENSION(7))



PostgreSQL 9.6.1                     2016                  CREATE EXTENSION(7)
DROP USER MAPPING(7)    PostgreSQL 9.6.1 Documentation    DROP USER MAPPING(7)



NAME
       DROP_USER_MAPPING - remove a user mapping for a foreign server

SYNOPSIS
       DROP USER MAPPING [ IF EXISTS ] FOR { user_name | USER | CURRENT_USER | PUBLIC } SERVER server_name

DESCRIPTION
       DROP USER MAPPING removes an existing user mapping from foreign server.

       The owner of a foreign server can drop user mappings for that server
       for any user. Also, a user can drop a user mapping for their own user
       name if USAGE privilege on the server has been granted to the user.

PARAMETERS
       IF EXISTS
           Do not throw an error if the user mapping does not exist. A notice
           is issued in this case.

       user_name
           User name of the mapping.  CURRENT_USER and USER match the name of
           the current user.  PUBLIC is used to match all present and future
           user names in the system.

       server_name
           Server name of the user mapping.

EXAMPLES
       Drop a user mapping bob, server foo if it exists:

           DROP USER MAPPING IF EXISTS FOR bob SERVER foo;

COMPATIBILITY
       DROP USER MAPPING conforms to ISO/IEC 9075-9 (SQL/MED). The IF EXISTS
       clause is a PostgreSQL extension.

SEE ALSO
       CREATE USER MAPPING (CREATE_USER_MAPPING(7)), ALTER USER MAPPING
       (ALTER_USER_MAPPING(7))



PostgreSQL 9.6.1                     2016                 DROP USER MAPPING(7)
LISTEN(7)               PostgreSQL 9.6.1 Documentation               LISTEN(7)



NAME
       LISTEN - listen for a notification

SYNOPSIS
       LISTEN channel

DESCRIPTION
       LISTEN registers the current session as a listener on the notification
       channel named channel. If the current session is already registered as
       a listener for this notification channel, nothing is done.

       Whenever the command NOTIFY channel is invoked, either by this session
       or another one connected to the same database, all the sessions
       currently listening on that notification channel are notified, and each
       will in turn notify its connected client application.

       A session can be unregistered for a given notification channel with the
       UNLISTEN command. A session's listen registrations are automatically
       cleared when the session ends.

       The method a client application must use to detect notification events
       depends on which PostgreSQL application programming interface it uses.
       With the libpq library, the application issues LISTEN as an ordinary
       SQL command, and then must periodically call the function PQnotifies to
       find out whether any notification events have been received. Other
       interfaces such as libpgtcl provide higher-level methods for handling
       notify events; indeed, with libpgtcl the application programmer should
       not even issue LISTEN or UNLISTEN directly. See the documentation for
       the interface you are using for more details.

       NOTIFY(7) contains a more extensive discussion of the use of LISTEN and
       NOTIFY.

PARAMETERS
       channel
           Name of a notification channel (any identifier).

NOTES
       LISTEN takes effect at transaction commit. If LISTEN or UNLISTEN is
       executed within a transaction that later rolls back, the set of
       notification channels being listened to is unchanged.

       A transaction that has executed LISTEN cannot be prepared for two-phase
       commit.

EXAMPLES
       Configure and execute a listen/notify sequence from psql:

           LISTEN virtual;
           NOTIFY virtual;
           Asynchronous notification "virtual" received from server process with PID 8448.

COMPATIBILITY
       There is no LISTEN statement in the SQL standard.

SEE ALSO
       NOTIFY(7), UNLISTEN(7)



PostgreSQL 9.6.1                     2016                            LISTEN(7)
ALTER TEXT SEARCH CONFIGPostgreSQL 9.6.1 DocALTERaTEXT SEARCH CONFIGURATION(7)



NAME
       ALTER_TEXT_SEARCH_CONFIGURATION - change the definition of a text
       search configuration

SYNOPSIS
       ALTER TEXT SEARCH CONFIGURATION name
           ADD MAPPING FOR token_type [, ... ] WITH dictionary_name [, ... ]
       ALTER TEXT SEARCH CONFIGURATION name
           ALTER MAPPING FOR token_type [, ... ] WITH dictionary_name [, ... ]
       ALTER TEXT SEARCH CONFIGURATION name
           ALTER MAPPING REPLACE old_dictionary WITH new_dictionary
       ALTER TEXT SEARCH CONFIGURATION name
           ALTER MAPPING FOR token_type [, ... ] REPLACE old_dictionary WITH new_dictionary
       ALTER TEXT SEARCH CONFIGURATION name
           DROP MAPPING [ IF EXISTS ] FOR token_type [, ... ]
       ALTER TEXT SEARCH CONFIGURATION name RENAME TO new_name
       ALTER TEXT SEARCH CONFIGURATION name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER TEXT SEARCH CONFIGURATION name SET SCHEMA new_schema

DESCRIPTION
       ALTER TEXT SEARCH CONFIGURATION changes the definition of a text search
       configuration. You can modify its mappings from token types to
       dictionaries, or change the configuration's name or owner.

       You must be the owner of the configuration to use ALTER TEXT SEARCH
       CONFIGURATION.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing text search
           configuration.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       token_type
           The name of a token type that is emitted by the configuration's
           parser.

       dictionary_name
           The name of a text search dictionary to be consulted for the
           specified token type(s). If multiple dictionaries are listed, they
           are consulted in the specified order.

       old_dictionary
           The name of a text search dictionary to be replaced in the mapping.

       new_dictionary
           The name of a text search dictionary to be substituted for
           old_dictionary.

       new_name
           The new name of the text search configuration.

       new_owner
           The new owner of the text search configuration.

       new_schema
           The new schema for the text search configuration.

       The ADD MAPPING FOR form installs a list of dictionaries to be
       consulted for the specified token type(s); it is an error if there is
       already a mapping for any of the token types. The ALTER MAPPING FOR
       form does the same, but first removing any existing mapping for those
       token types. The ALTER MAPPING REPLACE forms substitute new_dictionary
       for old_dictionary anywhere the latter appears. This is done for only
       the specified token types when FOR appears, or for all mappings of the
       configuration when it doesn't. The DROP MAPPING form removes all
       dictionaries for the specified token type(s), causing tokens of those
       types to be ignored by the text search configuration. It is an error if
       there is no mapping for the token types, unless IF EXISTS appears.

EXAMPLES
       The following example replaces the english dictionary with the swedish
       dictionary anywhere that english is used within my_config.

           ALTER TEXT SEARCH CONFIGURATION my_config
             ALTER MAPPING REPLACE english WITH swedish;

COMPATIBILITY
       There is no ALTER TEXT SEARCH CONFIGURATION statement in the SQL
       standard.

SEE ALSO
       CREATE TEXT SEARCH CONFIGURATION (CREATE_TEXT_SEARCH_CONFIGURATION(7)),
       DROP TEXT SEARCH CONFIGURATION (DROP_TEXT_SEARCH_CONFIGURATION(7))



PostgreSQL 9.6.1                     2016   ALTER TEXT SEARCH CONFIGURATION(7)
DROP CAST(7)            PostgreSQL 9.6.1 Documentation            DROP CAST(7)



NAME
       DROP_CAST - remove a cast

SYNOPSIS
       DROP CAST [ IF EXISTS ] (source_type AS target_type) [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP CAST removes a previously defined cast.

       To be able to drop a cast, you must own the source or the target data
       type. These are the same privileges that are required to create a cast.

PARAMETERS
       IF EXISTS
           Do not throw an error if the cast does not exist. A notice is
           issued in this case.

       source_type
           The name of the source data type of the cast.

       target_type
           The name of the target data type of the cast.

       CASCADE
       RESTRICT
           These key words do not have any effect, since there are no
           dependencies on casts.

EXAMPLES
       To drop the cast from type text to type int:

           DROP CAST (text AS int);

COMPATIBILITY
       The DROP CAST command conforms to the SQL standard.

SEE ALSO
       CREATE CAST (CREATE_CAST(7))



PostgreSQL 9.6.1                     2016                         DROP CAST(7)
DROP MATERIALIZED VIEW(7PostgreSQL 9.6.1 DocumentatioDROP MATERIALIZED VIEW(7)



NAME
       DROP_MATERIALIZED_VIEW - remove a materialized view

SYNOPSIS
       DROP MATERIALIZED VIEW [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP MATERIALIZED VIEW drops an existing materialized view. To execute
       this command you must be the owner of the materialized view.

PARAMETERS
       IF EXISTS
           Do not throw an error if the materialized view does not exist. A
           notice is issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the materialized view to
           remove.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the materialized view
           (such as other materialized views, or regular views), and in turn
           all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the materialized view if any objects depend on it.
           This is the default.

EXAMPLES
       This command will remove the materialized view called order_summary:

           DROP MATERIALIZED VIEW order_summary;

COMPATIBILITY
       DROP MATERIALIZED VIEW is a PostgreSQL extension.

SEE ALSO
       CREATE MATERIALIZED VIEW (CREATE_MATERIALIZED_VIEW(7)), ALTER
       MATERIALIZED VIEW (ALTER_MATERIALIZED_VIEW(7)), REFRESH MATERIALIZED
       VIEW (REFRESH_MATERIALIZED_VIEW(7))



PostgreSQL 9.6.1                     2016            DROP MATERIALIZED VIEW(7)
CREATE RULE(7)          PostgreSQL 9.6.1 Documentation          CREATE RULE(7)



NAME
       CREATE_RULE - define a new rewrite rule

SYNOPSIS
       CREATE [ OR REPLACE ] RULE name AS ON event
           TO table_name [ WHERE condition ]
           DO [ ALSO | INSTEAD ] { NOTHING | command | ( command ; command ... ) }

       where event can be one of:

           SELECT | INSERT | UPDATE | DELETE

DESCRIPTION
       CREATE RULE defines a new rule applying to a specified table or view.
       CREATE OR REPLACE RULE will either create a new rule, or replace an
       existing rule of the same name for the same table.

       The PostgreSQL rule system allows one to define an alternative action
       to be performed on insertions, updates, or deletions in database
       tables. Roughly speaking, a rule causes additional commands to be
       executed when a given command on a given table is executed.
       Alternatively, an INSTEAD rule can replace a given command by another,
       or cause a command not to be executed at all. Rules are used to
       implement SQL views as well. It is important to realize that a rule is
       really a command transformation mechanism, or command macro. The
       transformation happens before the execution of the command starts. If
       you actually want an operation that fires independently for each
       physical row, you probably want to use a trigger, not a rule. More
       information about the rules system is in Chapter 39, The Rule System,
       in the documentation.

       Presently, ON SELECT rules must be unconditional INSTEAD rules and must
       have actions that consist of a single SELECT command. Thus, an ON
       SELECT rule effectively turns the table into a view, whose visible
       contents are the rows returned by the rule's SELECT command rather than
       whatever had been stored in the table (if anything). It is considered
       better style to write a CREATE VIEW command than to create a real table
       and define an ON SELECT rule for it.

       You can create the illusion of an updatable view by defining ON INSERT,
       ON UPDATE, and ON DELETE rules (or any subset of those that's
       sufficient for your purposes) to replace update actions on the view
       with appropriate updates on other tables. If you want to support INSERT
       RETURNING and so on, then be sure to put a suitable RETURNING clause
       into each of these rules.

       There is a catch if you try to use conditional rules for complex view
       updates: there must be an unconditional INSTEAD rule for each action
       you wish to allow on the view. If the rule is conditional, or is not
       INSTEAD, then the system will still reject attempts to perform the
       update action, because it thinks it might end up trying to perform the
       action on the dummy table of the view in some cases. If you want to
       handle all the useful cases in conditional rules, add an unconditional
       DO INSTEAD NOTHING rule to ensure that the system understands it will
       never be called on to update the dummy table. Then make the conditional
       rules non-INSTEAD; in the cases where they are applied, they add to the
       default INSTEAD NOTHING action. (This method does not currently work to
       support RETURNING queries, however.)

           Note
           A view that is simple enough to be automatically updatable (see
           CREATE VIEW (CREATE_VIEW(7))) does not require a user-created rule
           in order to be updatable. While you can create an explicit rule
           anyway, the automatic update transformation will generally
           outperform an explicit rule.

           Another alternative worth considering is to use INSTEAD OF triggers
           (see CREATE TRIGGER (CREATE_TRIGGER(7))) in place of rules.

PARAMETERS
       name
           The name of a rule to create. This must be distinct from the name
           of any other rule for the same table. Multiple rules on the same
           table and same event type are applied in alphabetical name order.

       event
           The event is one of SELECT, INSERT, UPDATE, or DELETE. Note that an
           INSERT containing an ON CONFLICT clause cannot be used on tables
           that have either INSERT or UPDATE rules. Consider using an
           updatable view instead.

       table_name
           The name (optionally schema-qualified) of the table or view the
           rule applies to.

       condition
           Any SQL conditional expression (returning boolean). The condition
           expression cannot refer to any tables except NEW and OLD, and
           cannot contain aggregate functions.

       INSTEAD
           INSTEAD indicates that the commands should be executed instead of
           the original command.

       ALSO
           ALSO indicates that the commands should be executed in addition to
           the original command.

           If neither ALSO nor INSTEAD is specified, ALSO is the default.

       command
           The command or commands that make up the rule action. Valid
           commands are SELECT, INSERT, UPDATE, DELETE, or NOTIFY.

       Within condition and command, the special table names NEW and OLD can
       be used to refer to values in the referenced table.  NEW is valid in ON
       INSERT and ON UPDATE rules to refer to the new row being inserted or
       updated.  OLD is valid in ON UPDATE and ON DELETE rules to refer to the
       existing row being updated or deleted.

NOTES
       You must be the owner of a table to create or change rules for it.

       In a rule for INSERT, UPDATE, or DELETE on a view, you can add a
       RETURNING clause that emits the view's columns. This clause will be
       used to compute the outputs if the rule is triggered by an INSERT
       RETURNING, UPDATE RETURNING, or DELETE RETURNING command respectively.
       When the rule is triggered by a command without RETURNING, the rule's
       RETURNING clause will be ignored. The current implementation allows
       only unconditional INSTEAD rules to contain RETURNING; furthermore
       there can be at most one RETURNING clause among all the rules for the
       same event. (This ensures that there is only one candidate RETURNING
       clause to be used to compute the results.)  RETURNING queries on the
       view will be rejected if there is no RETURNING clause in any available
       rule.

       It is very important to take care to avoid circular rules. For example,
       though each of the following two rule definitions are accepted by
       PostgreSQL, the SELECT command would cause PostgreSQL to report an
       error because of recursive expansion of a rule:

           CREATE RULE "_RETURN" AS
               ON SELECT TO t1
               DO INSTEAD
                   SELECT * FROM t2;

           CREATE RULE "_RETURN" AS
               ON SELECT TO t2
               DO INSTEAD
                   SELECT * FROM t1;

           SELECT * FROM t1;

       Presently, if a rule action contains a NOTIFY command, the NOTIFY
       command will be executed unconditionally, that is, the NOTIFY will be
       issued even if there are not any rows that the rule should apply to.
       For example, in:

           CREATE RULE notify_me AS ON UPDATE TO mytable DO ALSO NOTIFY mytable;

           UPDATE mytable SET name = 'foo' WHERE id = 42;

       one NOTIFY event will be sent during the UPDATE, whether or not there
       are any rows that match the condition id = 42. This is an
       implementation restriction that might be fixed in future releases.

COMPATIBILITY
       CREATE RULE is a PostgreSQL language extension, as is the entire query
       rewrite system.

SEE ALSO
       ALTER RULE (ALTER_RULE(7)), DROP RULE (DROP_RULE(7))



PostgreSQL 9.6.1                     2016                       CREATE RULE(7)
ALTER TABLESPACE(7)     PostgreSQL 9.6.1 Documentation     ALTER TABLESPACE(7)



NAME
       ALTER_TABLESPACE - change the definition of a tablespace

SYNOPSIS
       ALTER TABLESPACE name RENAME TO new_name
       ALTER TABLESPACE name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER TABLESPACE name SET ( tablespace_option = value [, ... ] )
       ALTER TABLESPACE name RESET ( tablespace_option [, ... ] )

DESCRIPTION
       ALTER TABLESPACE can be used to change the definition of a tablespace.

       You must own the tablespace to change the definition of a tablespace.
       To alter the owner, you must also be a direct or indirect member of the
       new owning role. (Note that superusers have these privileges
       automatically.)

PARAMETERS
       name
           The name of an existing tablespace.

       new_name
           The new name of the tablespace. The new name cannot begin with pg_,
           as such names are reserved for system tablespaces.

       new_owner
           The new owner of the tablespace.

<!-- 0dcf2f4d-9a93-47a8-b9b7-a97b18cef24c <=< ACCEPT -->       tablespace_option
           A tablespace parameter to be set or reset. Currently, the only
           available parameters are seq_page_cost and random_page_cost.
           Setting either value for a particular tablespace will override the
           planner's usual estimate of the cost of reading pages from tables
           in that tablespace, as established by the configuration parameters
           of the same name (see seq_page_cost, random_page_cost). This may be
           useful if one tablespace is located on a disk which is faster or
           slower than the remainder of the I/O subsystem.<!-- ACCEPT >=> 0dcf2f4d-9a93-47a8-b9b7-a97b18cef24c -->

EXAMPLES
       Rename tablespace index_space to fast_raid:

           ALTER TABLESPACE index_space RENAME TO fast_raid;

       Change the owner of tablespace index_space:

           ALTER TABLESPACE index_space OWNER TO mary;

COMPATIBILITY
       There is no ALTER TABLESPACE statement in the SQL standard.

SEE ALSO
       CREATE TABLESPACE (CREATE_TABLESPACE(7)), DROP TABLESPACE
       (DROP_TABLESPACE(7))



PostgreSQL 9.6.1                     2016                  ALTER TABLESPACE(7)
ALTER FOREIGN TABLE(7)  PostgreSQL 9.6.1 Documentation  ALTER FOREIGN TABLE(7)



NAME
       ALTER_FOREIGN_TABLE - change the definition of a foreign table

SYNOPSIS
       ALTER FOREIGN TABLE [ IF EXISTS ] [ ONLY ] name [ * ]
           action [, ... ]
       ALTER FOREIGN TABLE [ IF EXISTS ] [ ONLY ] name [ * ]
           RENAME [ COLUMN ] column_name TO new_column_name
       ALTER FOREIGN TABLE [ IF EXISTS ] name
           RENAME TO new_name
       ALTER FOREIGN TABLE [ IF EXISTS ] name
           SET SCHEMA new_schema

       where action is one of:

<!-- e6c7b41c-88f9-487b-85aa-3e2fa5db760d <=< ACCEPT -->           ADD [ COLUMN ] column_name data_type [ COLLATE collation ] [ column_constraint [ ... ] ]
           DROP [ COLUMN ] [ IF EXISTS ] column_name [ RESTRICT | CASCADE ]
           ALTER [ COLUMN ] column_name [ SET DATA ] TYPE data_type [ COLLATE collation ]
           ALTER [ COLUMN ] column_name SET DEFAULT expression
           ALTER [ COLUMN ] column_name DROP DEFAULT
           ALTER [ COLUMN ] column_name { SET | DROP } NOT NULL
           ALTER [ COLUMN ] column_name SET STATISTICS integer
           ALTER [ COLUMN ] column_name SET ( attribute_option = value [, ... ] )
           ALTER [ COLUMN ] column_name RESET ( attribute_option [, ... ] )
           ALTER [ COLUMN ] column_name SET STORAGE { PLAIN | EXTERNAL | EXTENDED | MAIN }
           ALTER [ COLUMN ] column_name OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ])
           ADD table_constraint [ NOT VALID ]
           VALIDATE CONSTRAINT constraint_name
           DROP CONSTRAINT [ IF EXISTS ]  constraint_name [ RESTRICT | CASCADE ]
           DISABLE TRIGGER [ trigger_name | ALL | USER ]
           ENABLE TRIGGER [ trigger_name | ALL | USER ]
           ENABLE REPLICA TRIGGER trigger_name
           ENABLE ALWAYS TRIGGER trigger_name<!-- ACCEPT >=> e6c7b41c-88f9-487b-85aa-3e2fa5db760d -->
           SET WITH OIDS
           SET WITHOUT OIDS
           INHERIT parent_table
           NO INHERIT parent_table
           OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
           OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ])

DESCRIPTION
       ALTER FOREIGN TABLE changes the definition of an existing foreign
       table. There are several subforms:

       ADD COLUMN
           This form adds a new column to the foreign table, using the same
           syntax as CREATE FOREIGN TABLE (CREATE_FOREIGN_TABLE(7)). Unlike
           the case when adding a column to a regular table, nothing happens
           to the underlying storage: this action simply declares that some
           new column is now accessible through the foreign table.

<!-- 22ad55db-b1ff-4e76-b5e1-fb83846a2309 <=< ACCEPT -->       DROP COLUMN [ IF EXISTS ]
           This form drops a column from a foreign table. You will need to say
           CASCADE if anything outside the table depends on the column; for
           example, views. If IF EXISTS is specified and the column does not
           exist, no error is thrown. In this case a notice is issued instead.<!-- ACCEPT >=> 22ad55db-b1ff-4e76-b5e1-fb83846a2309 -->

       SET DATA TYPE
           This form changes the type of a column of a foreign table. Again,
           this has no effect on any underlying storage: this action simply
           changes the type that PostgreSQL believes the column to have.

       SET/DROP DEFAULT
           These forms set or remove the default value for a column. Default
           values only apply in subsequent INSERT or UPDATE commands; they do
           not cause rows already in the table to change.

       SET/DROP NOT NULL
           Mark a column as allowing, or not allowing, null values.

       SET STATISTICS
           This form sets the per-column statistics-gathering target for
           subsequent ANALYZE(7) operations. See the similar form of ALTER
           TABLE (ALTER_TABLE(7)) for more details.

       SET ( attribute_option = value [, ... ] )
       RESET ( attribute_option [, ... ] )
           This form sets or resets per-attribute options. See the similar
           form of ALTER TABLE (ALTER_TABLE(7)) for more details.

       SET STORAGE
           This form sets the storage mode for a column. See the similar form
           of ALTER TABLE (ALTER_TABLE(7)) for more details. Note that the
           storage mode has no effect unless the table's foreign-data wrapper
           chooses to pay attention to it.

       ADD table_constraint [ NOT VALID ]
           This form adds a new constraint to a foreign table, using the same
           syntax as CREATE FOREIGN TABLE (CREATE_FOREIGN_TABLE(7)). Currently
           only CHECK constraints are supported.

           Unlike the case when adding a constraint to a regular table,
           nothing is done to verify the constraint is correct; rather, this
           action simply declares that some new condition should be assumed to
           hold for all rows in the foreign table. (See the discussion in
           CREATE FOREIGN TABLE (CREATE_FOREIGN_TABLE(7)).) If the constraint
           is marked NOT VALID, then it isn't assumed to hold, but is only
           recorded for possible future use.

       VALIDATE CONSTRAINT
           This form marks as valid a constraint that was previously marked as
           NOT VALID. No action is taken to verify the constraint, but future
           queries will assume that it holds.

<!-- bc77072c-0c6a-4f8a-a915-bdad0da8a78b <=< ACCEPT -->       DROP CONSTRAINT [ IF EXISTS ]
           This form drops the specified constraint on a foreign table. If IF
           EXISTS is specified and the constraint does not exist, no error is
           thrown. In this case a notice is issued instead.<!-- ACCEPT >=> bc77072c-0c6a-4f8a-a915-bdad0da8a78b -->

       DISABLE/ENABLE [ REPLICA | ALWAYS ] TRIGGER
           These forms configure the firing of trigger(s) belonging to the
           foreign table. See the similar form of ALTER TABLE (ALTER_TABLE(7))
           for more details.

<!-- f322b4c2-95d3-444c-9ad5-8e8d3b56ac03 <=< ACCEPT -->       SET WITH OIDS
           This form adds an oid system column to the table (see Section 5.4,
           "System Columns", in the documentation). It does nothing if the
           table already has OIDs. Unless the table's foreign-data wrapper
           supports OIDs, this column will simply read as zeroes.

           Note that this is not equivalent to ADD COLUMN oid oid; that would
           add a normal column that happened to be named oid, not a system
           column.

       SET WITHOUT OIDS
           This form removes the oid system column from the table. This is
           exactly equivalent to DROP COLUMN oid RESTRICT, except that it will
           not complain if there is already no oid column.<!-- ACCEPT >=> f322b4c2-95d3-444c-9ad5-8e8d3b56ac03 -->

       INHERIT parent_table
           This form adds the target foreign table as a new child of the
           specified parent table. See the similar form of ALTER TABLE
           (ALTER_TABLE(7)) for more details.

       NO INHERIT parent_table
           This form removes the target foreign table from the list of
           children of the specified parent table.

       OWNER
           This form changes the owner of the foreign table to the specified
           user.

       OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ] )
           Change options for the foreign table or one of its columns.  ADD,
           SET, and DROP specify the action to be performed.  ADD is assumed
           if no operation is explicitly specified. Duplicate option names are
           not allowed (although it's OK for a table option and a column
           option to have the same name). Option names and values are also
           validated using the foreign data wrapper library.

       RENAME
           The RENAME forms change the name of a foreign table or the name of
           an individual column in a foreign table.

       SET SCHEMA
           This form moves the foreign table into another schema.

       All the actions except RENAME and SET SCHEMA can be combined into a
       list of multiple alterations to apply in parallel. For example, it is
       possible to add several columns and/or alter the type of several
       columns in a single command.

       If the command is written as ALTER FOREIGN TABLE IF EXISTS ...  and the
       foreign table does not exist, no error is thrown. A notice is issued in
       this case.

<!-- ad137a5f-7fa1-4b53-a38d-4827f1ccde6e <=< ACCEPT -->       You must own the table to use ALTER FOREIGN TABLE. To change the schema
       of a foreign table, you must also have CREATE privilege on the new
       schema. To alter the owner, you must also be a direct or indirect
       member of the new owning role, and that role must have CREATE privilege
       on the table's schema. (These restrictions enforce that altering the
       owner doesn't do anything you couldn't do by dropping and recreating
       the table. However, a superuser can alter ownership of any table
       anyway.) To add a column or alter a column type, you must also have
       USAGE privilege on the data type.<!-- ACCEPT >=> ad137a5f-7fa1-4b53-a38d-4827f1ccde6e -->

PARAMETERS
       name
           The name (possibly schema-qualified) of an existing foreign table
           to alter. If ONLY is specified before the table name, only that
           table is altered. If ONLY is not specified, the table and all its
           descendant tables (if any) are altered. Optionally, * can be
           specified after the table name to explicitly indicate that
           descendant tables are included.

<!-- 33010bc7-9edf-43c5-8a0d-ff696a0fbab8 <=< ACCEPT -->       column_name
           Name of a new or existing column.

       new_column_name
           New name for an existing column.

       new_name
           New name for the table.

       data_type
           Data type of the new column, or new data type for an existing
           column.

       table_constraint
           New table constraint for the foreign table.

       constraint_name
           Name of an existing constraint to drop.

       CASCADE
           Automatically drop objects that depend on the dropped column or
           constraint (for example, views referencing the column), and in turn
           all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the column or constraint if there are any dependent
           objects. This is the default behavior.

       trigger_name
           Name of a single trigger to disable or enable.

       ALL
           Disable or enable all triggers belonging to the foreign table.
           (This requires superuser privilege if any of the triggers are
           internally generated triggers. The core system does not add such
           triggers to foreign tables, but add-on code could do so.)

       USER
           Disable or enable all triggers belonging to the foreign table
           except for internally generated triggers.
<!-- ACCEPT >=> 33010bc7-9edf-43c5-8a0d-ff696a0fbab8 -->
       parent_table
           A parent table to associate or de-associate with this foreign
           table.

       new_owner
           The user name of the new owner of the table.

       new_schema
           The name of the schema to which the table will be moved.

NOTES
       The key word COLUMN is noise and can be omitted.

       Consistency with the foreign server is not checked when a column is
       added or removed with ADD COLUMN or DROP COLUMN, a NOT NULL or CHECK
       constraint is added, or a column type is changed with SET DATA TYPE. It
       is the user's responsibility to ensure that the table definition
       matches the remote side.

       Refer to CREATE FOREIGN TABLE (CREATE_FOREIGN_TABLE(7)) for a further
       description of valid parameters.

EXAMPLES
       To mark a column as not-null:

           ALTER FOREIGN TABLE distributors ALTER COLUMN street SET NOT NULL;

       To change options of a foreign table:

           ALTER FOREIGN TABLE myschema.distributors OPTIONS (ADD opt1 'value', SET opt2 'value2', DROP opt3 'value3');

<!-- 6f26919a-f964-4174-8c8d-6ec22f5e2be4 <=< ACCEPT -->COMPATIBILITY
       The forms ADD, DROP, and SET DATA TYPE conform with the SQL standard.
       The other forms are PostgreSQL extensions of the SQL standard. Also,
       the ability to specify more than one manipulation in a single ALTER
       FOREIGN TABLE command is an extension.

       ALTER FOREIGN TABLE DROP COLUMN can be used to drop the only column of
       a foreign table, leaving a zero-column table. This is an extension of
       SQL, which disallows zero-column foreign tables.<!-- ACCEPT >=> 6f26919a-f964-4174-8c8d-6ec22f5e2be4 -->

SEE ALSO
       CREATE FOREIGN TABLE (CREATE_FOREIGN_TABLE(7)), DROP FOREIGN TABLE
       (DROP_FOREIGN_TABLE(7))



PostgreSQL 9.6.1                     2016               ALTER FOREIGN TABLE(7)
ALTER CONVERSION(7)     PostgreSQL 9.6.1 Documentation     ALTER CONVERSION(7)



NAME
       ALTER_CONVERSION - change the definition of a conversion

SYNOPSIS
       ALTER CONVERSION name RENAME TO new_name
       ALTER CONVERSION name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER CONVERSION name SET SCHEMA new_schema

DESCRIPTION
       ALTER CONVERSION changes the definition of a conversion.

       You must own the conversion to use ALTER CONVERSION. To alter the
       owner, you must also be a direct or indirect member of the new owning
       role, and that role must have CREATE privilege on the conversion's
       schema. (These restrictions enforce that altering the owner doesn't do
       anything you couldn't do by dropping and recreating the conversion.
       However, a superuser can alter ownership of any conversion anyway.)

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing conversion.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       new_name
           The new name of the conversion.

       new_owner
           The new owner of the conversion.

       new_schema
           The new schema for the conversion.

EXAMPLES
       To rename the conversion iso_8859_1_to_utf8 to latin1_to_unicode:

           ALTER CONVERSION iso_8859_1_to_utf8 RENAME TO latin1_to_unicode;

       To change the owner of the conversion iso_8859_1_to_utf8 to joe:

           ALTER CONVERSION iso_8859_1_to_utf8 OWNER TO joe;

COMPATIBILITY
       There is no ALTER CONVERSION statement in the SQL standard.

SEE ALSO
       CREATE CONVERSION (CREATE_CONVERSION(7)), DROP CONVERSION
       (DROP_CONVERSION(7))



PostgreSQL 9.6.1                     2016                  ALTER CONVERSION(7)
DROP COLLATION(7)       PostgreSQL 9.6.1 Documentation       DROP COLLATION(7)



NAME
       DROP_COLLATION - remove a collation

SYNOPSIS
       DROP COLLATION [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP COLLATION removes a previously defined collation. To be able to
       drop a collation, you must own the collation.

PARAMETERS
       IF EXISTS
           Do not throw an error if the collation does not exist. A notice is
           issued in this case.

       name
           The name of the collation. The collation name can be
           schema-qualified.

       CASCADE
           Automatically drop objects that depend on the collation, and in
           turn all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the collation if any objects depend on it. This is
           the default.

EXAMPLES
       To drop the collation named german:

           DROP COLLATION german;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       The DROP COLLATION command conforms to the SQL standard, apart from the
       IF EXISTS option, which is a PostgreSQL extension.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

SEE ALSO
       ALTER COLLATION (ALTER_COLLATION(7)), CREATE COLLATION
       (CREATE_COLLATION(7))



PostgreSQL 9.6.1                     2016                    DROP COLLATION(7)
CREATE USER(7)          PostgreSQL 9.6.1 Documentation          CREATE USER(7)



<!-- 335d3487-bfbb-463c-9629-fa78cfc1d1e1 <=< ACCEPT -->NAME
       CREATE_USER - define a new database role

SYNOPSIS
       CREATE USER name [ [ WITH ] option [ ... ] ]

       where option can be:

             SUPERUSER | NOSUPERUSER
           | CREATEDB | NOCREATEDB
           | CREATEROLE | NOCREATEROLE
           | INHERIT | NOINHERIT
           | LOGIN | NOLOGIN
           | REPLICATION | NOREPLICATION
           | BYPASSRLS | NOBYPASSRLS
           | CONNECTION LIMIT connlimit
           | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
           | VALID UNTIL 'timestamp'
           | IN ROLE role_name [, ...]
           | IN GROUP role_name [, ...]
           | ROLE role_name [, ...]
           | ADMIN role_name [, ...]
           | USER role_name [, ...]
           | SYSID uid
<!-- ACCEPT >=> 335d3487-bfbb-463c-9629-fa78cfc1d1e1 -->
DESCRIPTION
       CREATE USER is now an alias for CREATE ROLE (CREATE_ROLE(7)). The only
       difference is that when the command is spelled CREATE USER, LOGIN is
       assumed by default, whereas NOLOGIN is assumed when the command is
       spelled CREATE ROLE.

COMPATIBILITY
       The CREATE USER statement is a PostgreSQL extension. The SQL standard
       leaves the definition of users to the implementation.

SEE ALSO
       CREATE ROLE (CREATE_ROLE(7))



PostgreSQL 9.6.1                     2016                       CREATE USER(7)
CREATE USER MAPPING(7)  PostgreSQL 9.6.1 Documentation  CREATE USER MAPPING(7)



NAME
       CREATE_USER_MAPPING - define a new mapping of a user to a foreign
       server

SYNOPSIS
       CREATE USER MAPPING FOR { user_name | USER | CURRENT_USER | PUBLIC }
           SERVER server_name
           [ OPTIONS ( option 'value' [ , ... ] ) ]

DESCRIPTION
       CREATE USER MAPPING defines a mapping of a user to a foreign server. A
       user mapping typically encapsulates connection information that a
       foreign-data wrapper uses together with the information encapsulated by
       a foreign server to access an external data resource.

       The owner of a foreign server can create user mappings for that server
       for any user. Also, a user can create a user mapping for their own user
       name if USAGE privilege on the server has been granted to the user.

PARAMETERS
       user_name
           The name of an existing user that is mapped to foreign server.
           CURRENT_USER and USER match the name of the current user. When
           PUBLIC is specified, a so-called public mapping is created that is
           used when no user-specific mapping is applicable.

       server_name
           The name of an existing server for which the user mapping is to be
           created.

       OPTIONS ( option 'value' [, ... ] )
           This clause specifies the options of the user mapping. The options
           typically define the actual user name and password of the mapping.
           Option names must be unique. The allowed option names and values
           are specific to the server's foreign-data wrapper.

EXAMPLES
       Create a user mapping for user bob, server foo:

           CREATE USER MAPPING FOR bob SERVER foo OPTIONS (user 'bob', password 'secret');

COMPATIBILITY
       CREATE USER MAPPING conforms to ISO/IEC 9075-9 (SQL/MED).

SEE ALSO
       ALTER USER MAPPING (ALTER_USER_MAPPING(7)), DROP USER MAPPING
       (DROP_USER_MAPPING(7)), CREATE FOREIGN DATA WRAPPER
       (CREATE_FOREIGN_DATA_WRAPPER(7)), CREATE SERVER (CREATE_SERVER(7))



PostgreSQL 9.6.1                     2016               CREATE USER MAPPING(7)
CREATE TRIGGER(7)       PostgreSQL 9.6.1 Documentation       CREATE TRIGGER(7)



NAME
       CREATE_TRIGGER - define a new trigger

SYNOPSIS
       CREATE [ CONSTRAINT ] TRIGGER name { BEFORE | AFTER | INSTEAD OF } { event [ OR ... ] }
           ON table_name
           [ FROM referenced_table_name ]
           [ NOT DEFERRABLE | [ DEFERRABLE ] [ INITIALLY IMMEDIATE | INITIALLY DEFERRED ] ]
           [ FOR [ EACH ] { ROW | STATEMENT } ]
           [ WHEN ( condition ) ]
           EXECUTE PROCEDURE function_name ( arguments )

       where event can be one of:

           INSERT
           UPDATE [ OF column_name [, ... ] ]
           DELETE
           TRUNCATE

DESCRIPTION
       CREATE TRIGGER creates a new trigger. The trigger will be associated
       with the specified table, view, or foreign table and will execute the
       specified function function_name when certain events occur.

       The trigger can be specified to fire before the operation is attempted
       on a row (before constraints are checked and the INSERT, UPDATE, or
       DELETE is attempted); or after the operation has completed (after
       constraints are checked and the INSERT, UPDATE, or DELETE has
       completed); or instead of the operation (in the case of inserts,
       updates or deletes on a view). If the trigger fires before or instead
       of the event, the trigger can skip the operation for the current row,
       or change the row being inserted (for INSERT and UPDATE operations
       only). If the trigger fires after the event, all changes, including the
       effects of other triggers, are "visible" to the trigger.

       A trigger that is marked FOR EACH ROW is called once for every row that
       the operation modifies. For example, a DELETE that affects 10 rows will
       cause any ON DELETE triggers on the target relation to be called 10
       separate times, once for each deleted row. In contrast, a trigger that
       is marked FOR EACH STATEMENT only executes once for any given
       operation, regardless of how many rows it modifies (in particular, an
       operation that modifies zero rows will still result in the execution of
       any applicable FOR EACH STATEMENT triggers). Note that with an INSERT
       with an ON CONFLICT DO UPDATE clause, both INSERT and UPDATE statement
       level trigger will be fired.

       Triggers that are specified to fire INSTEAD OF the trigger event must
       be marked FOR EACH ROW, and can only be defined on views.  BEFORE and
       AFTER triggers on a view must be marked as FOR EACH STATEMENT.

       In addition, triggers may be defined to fire for TRUNCATE, though only
       FOR EACH STATEMENT.

       The following table summarizes which types of triggers may be used on
       tables, views, and foreign tables:

       +-----------+----------------------+----------------+-----------------+
       |When       | Event                | Row-level      | Statement-level |
       +-----------+----------------------+----------------+-----------------+
       |           | INSERT/UPDATE/DELETE | Tables and     | Tables, views,  |
       |           |                      | foreign tables | and foreign     |
       |  BEFORE   |                      |                | tables          |
       |           +----------------------+----------------+-----------------+
       |           |       TRUNCATE       |       --       |     Tables      |
       +-----------+----------------------+----------------+-----------------+
       |           | INSERT/UPDATE/DELETE | Tables and     | Tables, views,  |
       |           |                      | foreign tables | and foreign     |
       |  AFTER    |                      |                | tables          |
       |           +----------------------+----------------+-----------------+
       |           |       TRUNCATE       |       --       |     Tables      |
       +-----------+----------------------+----------------+-----------------+
       |           | INSERT/UPDATE/DELETE |     Views      |       --        |
       |INSTEAD OF +----------------------+----------------+-----------------+
       |           |       TRUNCATE       |       --       |       --        |
       +-----------+----------------------+----------------+-----------------+

       Also, a trigger definition can specify a Boolean WHEN condition, which
       will be tested to see whether the trigger should be fired. In row-level
       triggers the WHEN condition can examine the old and/or new values of
       columns of the row. Statement-level triggers can also have WHEN
       conditions, although the feature is not so useful for them since the
       condition cannot refer to any values in the table.

       If multiple triggers of the same kind are defined for the same event,
       they will be fired in alphabetical order by name.

       When the CONSTRAINT option is specified, this command creates a
       constraint trigger. This is the same as a regular trigger except that
       the timing of the trigger firing can be adjusted using SET CONSTRAINTS
       (SET_CONSTRAINTS(7)). Constraint triggers must be AFTER ROW triggers on
       tables. They can be fired either at the end of the statement causing
       the triggering event, or at the end of the containing transaction; in
       the latter case they are said to be deferred. A pending
       deferred-trigger firing can also be forced to happen immediately by
       using SET CONSTRAINTS. Constraint triggers are expected to raise an
       exception when the constraints they implement are violated.

       SELECT does not modify any rows so you cannot create SELECT triggers.
       Rules and views are more appropriate in such cases.

       Refer to Chapter 37, Triggers, in the documentation for more
       information about triggers.

PARAMETERS
       name
           The name to give the new trigger. This must be distinct from the
           name of any other trigger for the same table. The name cannot be
           schema-qualified -- the trigger inherits the schema of its table.
           For a constraint trigger, this is also the name to use when
           modifying the trigger's behavior using SET CONSTRAINTS.

       BEFORE
       AFTER
       INSTEAD OF
           Determines whether the function is called before, after, or instead
           of the event. A constraint trigger can only be specified as AFTER.

       event
           One of INSERT, UPDATE, DELETE, or TRUNCATE; this specifies the
           event that will fire the trigger. Multiple events can be specified
           using OR.

           For UPDATE events, it is possible to specify a list of columns
           using this syntax:

               UPDATE OF column_name1 [, column_name2 ... ]

           The trigger will only fire if at least one of the listed columns is
           mentioned as a target of the UPDATE command.

           INSTEAD OF UPDATE events do not support lists of columns.

       table_name
           The name (optionally schema-qualified) of the table, view, or
           foreign table the trigger is for.

       referenced_table_name
           The (possibly schema-qualified) name of another table referenced by
           the constraint. This option is used for foreign-key constraints and
           is not recommended for general use. This can only be specified for
           constraint triggers.

       DEFERRABLE
       NOT DEFERRABLE
       INITIALLY IMMEDIATE
       INITIALLY DEFERRED
           The default timing of the trigger. See the CREATE TABLE
           (CREATE_TABLE(7)) documentation for details of these constraint
           options. This can only be specified for constraint triggers.

       FOR EACH ROW
       FOR EACH STATEMENT
           This specifies whether the trigger procedure should be fired once
           for every row affected by the trigger event, or just once per SQL
           statement. If neither is specified, FOR EACH STATEMENT is the
           default. Constraint triggers can only be specified FOR EACH ROW.

       condition
           A Boolean expression that determines whether the trigger function
           will actually be executed. If WHEN is specified, the function will
           only be called if the condition returns true. In FOR EACH ROW
           triggers, the WHEN condition can refer to columns of the old and/or
           new row values by writing OLD.column_name or NEW.column_name
           respectively. Of course, INSERT triggers cannot refer to OLD and
           DELETE triggers cannot refer to NEW.

           INSTEAD OF triggers do not support WHEN conditions.

           Currently, WHEN expressions cannot contain subqueries.

           Note that for constraint triggers, evaluation of the WHEN condition
           is not deferred, but occurs immediately after the row update
           operation is performed. If the condition does not evaluate to true
           then the trigger is not queued for deferred execution.

       function_name
           A user-supplied function that is declared as taking no arguments
           and returning type trigger, which is executed when the trigger
           fires.

       arguments
           An optional comma-separated list of arguments to be provided to the
           function when the trigger is executed. The arguments are literal
           string constants. Simple names and numeric constants can be written
           here, too, but they will all be converted to strings. Please check
           the description of the implementation language of the trigger
           function to find out how these arguments can be accessed within the
           function; it might be different from normal function arguments.

NOTES
       To create a trigger on a table, the user must have the TRIGGER
       privilege on the table. The user must also have EXECUTE privilege on
       the trigger function.

       Use DROP TRIGGER (DROP_TRIGGER(7)) to remove a trigger.

       A column-specific trigger (one defined using the UPDATE OF column_name
       syntax) will fire when any of its columns are listed as targets in the
       UPDATE command's SET list. It is possible for a column's value to
       change even when the trigger is not fired, because changes made to the
       row's contents by BEFORE UPDATE triggers are not considered.
       Conversely, a command such as UPDATE ... SET x = x ...  will fire a
       trigger on column x, even though the column's value did not change.

       In a BEFORE trigger, the WHEN condition is evaluated just before the
       function is or would be executed, so using WHEN is not materially
       different from testing the same condition at the beginning of the
       trigger function. Note in particular that the NEW row seen by the
       condition is the current value, as possibly modified by earlier
       triggers. Also, a BEFORE trigger's WHEN condition is not allowed to
       examine the system columns of the NEW row (such as oid), because those
       won't have been set yet.

       In an AFTER trigger, the WHEN condition is evaluated just after the row
       update occurs, and it determines whether an event is queued to fire the
       trigger at the end of statement. So when an AFTER trigger's WHEN
       condition does not return true, it is not necessary to queue an event
       nor to re-fetch the row at end of statement. This can result in
       significant speedups in statements that modify many rows, if the
       trigger only needs to be fired for a few of the rows.

       In PostgreSQL versions before 7.3, it was necessary to declare trigger
       functions as returning the placeholder type opaque, rather than
       trigger. To support loading of old dump files, CREATE TRIGGER will
       accept a function declared as returning opaque, but it will issue a
       notice and change the function's declared return type to trigger.

EXAMPLES
       Execute the function check_account_update whenever a row of the table
       accounts is about to be updated:

           CREATE TRIGGER check_update
               BEFORE UPDATE ON accounts
               FOR EACH ROW
               EXECUTE PROCEDURE check_account_update();

       The same, but only execute the function if column balance is specified
       as a target in the UPDATE command:

           CREATE TRIGGER check_update
               BEFORE UPDATE OF balance ON accounts
               FOR EACH ROW
               EXECUTE PROCEDURE check_account_update();

       This form only executes the function if column balance has in fact
       changed value:

           CREATE TRIGGER check_update
               BEFORE UPDATE ON accounts
               FOR EACH ROW
               WHEN (OLD.balance IS DISTINCT FROM NEW.balance)
               EXECUTE PROCEDURE check_account_update();

       Call a function to log updates of accounts, but only if something
       changed:

           CREATE TRIGGER log_update
               AFTER UPDATE ON accounts
               FOR EACH ROW
               WHEN (OLD.* IS DISTINCT FROM NEW.*)
               EXECUTE PROCEDURE log_account_update();

       Execute the function view_insert_row for each row to insert rows into
       the tables underlying a view:

           CREATE TRIGGER view_insert
               INSTEAD OF INSERT ON my_view
               FOR EACH ROW
               EXECUTE PROCEDURE view_insert_row();

       Section 37.4, "A Complete Trigger Example", in the documentation
       contains a complete example of a trigger function written in C.

COMPATIBILITY
       The CREATE TRIGGER statement in PostgreSQL implements a subset of the
       SQL standard. The following functionalities are currently missing:

       o   SQL allows you to define aliases for the "old" and "new" rows or
           tables for use in the definition of the triggered action (e.g.,
           CREATE TRIGGER ... ON tablename REFERENCING OLD ROW AS somename NEW
           ROW AS othername ...). Since PostgreSQL allows trigger procedures
           to be written in any number of user-defined languages, access to
           the data is handled in a language-specific way.

       o   PostgreSQL does not allow the old and new tables to be referenced
           in statement-level triggers, i.e., the tables that contain all the
           old and/or new rows, which are referred to by the OLD TABLE and NEW
           TABLE clauses in the SQL standard.

       o   PostgreSQL only allows the execution of a user-defined function for
           the triggered action. The standard allows the execution of a number
           of other SQL commands, such as CREATE TABLE, as the triggered
           action. This limitation is not hard to work around by creating a
           user-defined function that executes the desired commands.

       SQL specifies that multiple triggers should be fired in
       time-of-creation order.  PostgreSQL uses name order, which was judged
       to be more convenient.

       SQL specifies that BEFORE DELETE triggers on cascaded deletes fire
       after the cascaded DELETE completes. The PostgreSQL behavior is for
       BEFORE DELETE to always fire before the delete action, even a cascading
       one. This is considered more consistent. There is also nonstandard
       behavior if BEFORE triggers modify rows or prevent updates during an
       update that is caused by a referential action. This can lead to
       constraint violations or stored data that does not honor the
       referential constraint.

       The ability to specify multiple actions for a single trigger using OR
       is a PostgreSQL extension of the SQL standard.

       The ability to fire triggers for TRUNCATE is a PostgreSQL extension of
       the SQL standard, as is the ability to define statement-level triggers
       on views.

       CREATE CONSTRAINT TRIGGER is a PostgreSQL extension of the SQL
       standard.

SEE ALSO
       ALTER TRIGGER (ALTER_TRIGGER(7)), DROP TRIGGER (DROP_TRIGGER(7)),
       CREATE FUNCTION (CREATE_FUNCTION(7)), SET CONSTRAINTS
       (SET_CONSTRAINTS(7))



PostgreSQL 9.6.1                     2016                    CREATE TRIGGER(7)
VACUUM(7)               PostgreSQL 9.6.1 Documentation               VACUUM(7)



NAME
       VACUUM - garbage-collect and optionally analyze a database

SYNOPSIS
       VACUUM [ ( { FULL | FREEZE | VERBOSE | ANALYZE | DISABLE_PAGE_SKIPPING } [, ...] ) ] [ table_name [ (column_name [, ...] ) ] ]
       VACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] [ table_name ]
       VACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] ANALYZE [ table_name [ (column_name [, ...] ) ] ]

DESCRIPTION
       VACUUM reclaims storage occupied by dead tuples. In normal PostgreSQL
       operation, tuples that are deleted or obsoleted by an update are not
       physically removed from their table; they remain present until a VACUUM
       is done. Therefore it's necessary to do VACUUM periodically, especially
       on frequently-updated tables.

       With no parameter, VACUUM processes every table in the current database
       that the current user has permission to vacuum. With a parameter,
       VACUUM processes only that table.

       VACUUM ANALYZE performs a VACUUM and then an ANALYZE for each selected
       table. This is a handy combination form for routine maintenance
       scripts. See ANALYZE(7) for more details about its processing.

       Plain VACUUM (without FULL) simply reclaims space and makes it
       available for re-use. This form of the command can operate in parallel
       with normal reading and writing of the table, as an exclusive lock is
       not obtained. However, extra space is not returned to the operating
       system (in most cases); it's just kept available for re-use within the
       same table.  VACUUM FULL rewrites the entire contents of the table into
       a new disk file with no extra space, allowing unused space to be
       returned to the operating system. This form is much slower and requires
       an exclusive lock on each table while it is being processed.

       When the option list is surrounded by parentheses, the options can be
       written in any order. Without parentheses, options must be specified in
       exactly the order shown above. The parenthesized syntax was added in
       PostgreSQL 9.0; the unparenthesized syntax is deprecated.

PARAMETERS
       FULL
           Selects "full" vacuum, which can reclaim more space, but takes much
           longer and exclusively locks the table. This method also requires
           extra disk space, since it writes a new copy of the table and
           doesn't release the old copy until the operation is complete.
           Usually this should only be used when a significant amount of space
           needs to be reclaimed from within the table.

       FREEZE
           Selects aggressive "freezing" of tuples. Specifying FREEZE is
           equivalent to performing VACUUM with the vacuum_freeze_min_age and
           vacuum_freeze_table_age parameters set to zero. Aggressive freezing
           is always performed when the table is rewritten, so this option is
           redundant when FULL is specified.

       VERBOSE
           Prints a detailed vacuum activity report for each table.

       ANALYZE
           Updates statistics used by the planner to determine the most
           efficient way to execute a query.

       DISABLE_PAGE_SKIPPING
           Normally, VACUUM will skip pages based on the visibility map. Pages
           where all tuples are known to be frozen can always be skipped, and
           those where all tuples are known to be visible to all transactions
           may be skipped except when performing an aggressive vacuum.
           Furthermore, except when performing an aggressive vacuum, some
           pages may be skipped in order to avoid waiting for other sessions
           to finish using them. This option disables all page-skipping
           behavior, and is intended to be used only the contents of the
           visibility map are thought to be suspect, which should happen only
           if there is a hardware or software issue causing database
           corruption.

       table_name
           The name (optionally schema-qualified) of a specific table to
           vacuum. Defaults to all tables in the current database.

<!-- 30ab03c8-2539-4230-9ec4-441dc3a63e60 <=< ACCEPT -->       column_name
           The name of a specific column to analyze. Defaults to all columns.
           If a column list is specified, ANALYZE is implied.<!-- ACCEPT >=> 30ab03c8-2539-4230-9ec4-441dc3a63e60 -->

<!-- 46b261de-260a-4534-b162-b5163af74a4b <=< ACCEPT -->OUTPUTS
       When VERBOSE is specified, VACUUM emits progress messages to indicate
       which table is currently being processed. Various statistics about the
       tables are printed as well.<!-- ACCEPT >=> 46b261de-260a-4534-b162-b5163af74a4b -->

NOTES
       To vacuum a table, one must ordinarily be the table's owner or a
       superuser. However, database owners are allowed to vacuum all tables in
       their databases, except shared catalogs. (The restriction for shared
       catalogs means that a true database-wide VACUUM can only be performed
       by a superuser.)  VACUUM will skip over any tables that the calling
       user does not have permission to vacuum.

       VACUUM cannot be executed inside a transaction block.

       For tables with GIN indexes, VACUUM (in any form) also completes any
       pending index insertions, by moving pending index entries to the
       appropriate places in the main GIN index structure. See Section 63.4.1,
       "GIN Fast Update Technique", in the documentation for details.

       We recommend that active production databases be vacuumed frequently
       (at least nightly), in order to remove dead rows. After adding or
       deleting a large number of rows, it might be a good idea to issue a
       VACUUM ANALYZE command for the affected table. This will update the
       system catalogs with the results of all recent changes, and allow the
       PostgreSQL query planner to make better choices in planning queries.

       The FULL option is not recommended for routine use, but might be useful
       in special cases. An example is when you have deleted or updated most
       of the rows in a table and would like the table to physically shrink to
       occupy less disk space and allow faster table scans.  VACUUM FULL will
       usually shrink the table more than a plain VACUUM would.

       VACUUM causes a substantial increase in I/O traffic, which might cause
       poor performance for other active sessions. Therefore, it is sometimes
       advisable to use the cost-based vacuum delay feature. See Section
       19.4.4, "Cost-based Vacuum Delay", in the documentation for details.

       PostgreSQL includes an "autovacuum" facility which can automate routine
       vacuum maintenance. For more information about automatic and manual
       vacuuming, see Section 24.1, "Routine Vacuuming", in the documentation.

EXAMPLES
       The following is an example from running VACUUM on a table in the
       regression database:

           regression=# VACUUM (VERBOSE, ANALYZE) onek;
           INFO:  vacuuming "public.onek"
           INFO:  index "onek_unique1" now contains 1000 tuples in 14 pages
           DETAIL:  3000 index tuples were removed.
           0 index pages have been deleted, 0 are currently reusable.
           CPU 0.01s/0.08u sec elapsed 0.18 sec.
           INFO:  index "onek_unique2" now contains 1000 tuples in 16 pages
           DETAIL:  3000 index tuples were removed.
           0 index pages have been deleted, 0 are currently reusable.
           CPU 0.00s/0.07u sec elapsed 0.23 sec.
           INFO:  index "onek_hundred" now contains 1000 tuples in 13 pages
           DETAIL:  3000 index tuples were removed.
           0 index pages have been deleted, 0 are currently reusable.
           CPU 0.01s/0.08u sec elapsed 0.17 sec.
           INFO:  index "onek_stringu1" now contains 1000 tuples in 48 pages
           DETAIL:  3000 index tuples were removed.
           0 index pages have been deleted, 0 are currently reusable.
           CPU 0.01s/0.09u sec elapsed 0.59 sec.
           INFO:  "onek": removed 3000 tuples in 108 pages
           DETAIL:  CPU 0.01s/0.06u sec elapsed 0.07 sec.
           INFO:  "onek": found 3000 removable, 1000 nonremovable tuples in 143 pages
           DETAIL:  0 dead tuples cannot be removed yet.
           There were 0 unused item pointers.
           Skipped 0 pages due to buffer pins.
           0 pages are entirely empty.
           CPU 0.07s/0.39u sec elapsed 1.56 sec.
           INFO:  analyzing "public.onek"
           INFO:  "onek": 36 pages, 1000 rows sampled, 1000 estimated total rows
           VACUUM

COMPATIBILITY
       There is no VACUUM statement in the SQL standard.

SEE ALSO
       vacuumdb(1), Section 19.4.4, "Cost-based Vacuum Delay", in the
       documentation, Section 24.1.6, "The Autovacuum Daemon", in the
       documentation



PostgreSQL 9.6.1                     2016                            VACUUM(7)
REVOKE(7)               PostgreSQL 9.6.1 Documentation               REVOKE(7)



NAME
       REVOKE - remove access privileges

SYNOPSIS
       REVOKE [ GRANT OPTION FOR ]
           { { SELECT | INSERT | UPDATE | DELETE | TRUNCATE | REFERENCES | TRIGGER }
           [, ...] | ALL [ PRIVILEGES ] }
           ON { [ TABLE ] table_name [, ...]
                | ALL TABLES IN SCHEMA schema_name [, ...] }
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { { SELECT | INSERT | UPDATE | REFERENCES } ( column_name [, ...] )
           [, ...] | ALL [ PRIVILEGES ] ( column_name [, ...] ) }
           ON [ TABLE ] table_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { { USAGE | SELECT | UPDATE }
           [, ...] | ALL [ PRIVILEGES ] }
           ON { SEQUENCE sequence_name [, ...]
                | ALL SEQUENCES IN SCHEMA schema_name [, ...] }
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { { CREATE | CONNECT | TEMPORARY | TEMP } [, ...] | ALL [ PRIVILEGES ] }
           ON DATABASE database_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { USAGE | ALL [ PRIVILEGES ] }
           ON DOMAIN domain_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { USAGE | ALL [ PRIVILEGES ] }
           ON FOREIGN DATA WRAPPER fdw_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { USAGE | ALL [ PRIVILEGES ] }
           ON FOREIGN SERVER server_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { EXECUTE | ALL [ PRIVILEGES ] }
           ON { FUNCTION function_name ( [ [ argmode ] [ arg_name ] arg_type [, ...] ] ) [, ...]
                | ALL FUNCTIONS IN SCHEMA schema_name [, ...] }
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { USAGE | ALL [ PRIVILEGES ] }
           ON LANGUAGE lang_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { { SELECT | UPDATE } [, ...] | ALL [ PRIVILEGES ] }
           ON LARGE OBJECT loid [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { { CREATE | USAGE } [, ...] | ALL [ PRIVILEGES ] }
           ON SCHEMA schema_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { CREATE | ALL [ PRIVILEGES ] }
           ON TABLESPACE tablespace_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ GRANT OPTION FOR ]
           { USAGE | ALL [ PRIVILEGES ] }
           ON TYPE type_name [, ...]
           FROM { [ GROUP ] role_name | PUBLIC } [, ...]
           [ CASCADE | RESTRICT ]

       REVOKE [ ADMIN OPTION FOR ]
           role_name [, ...] FROM role_name [, ...]
           [ CASCADE | RESTRICT ]

DESCRIPTION
       The REVOKE command revokes previously granted privileges from one or
       more roles. The key word PUBLIC refers to the implicitly defined group
       of all roles.

       See the description of the GRANT(7) command for the meaning of the
       privilege types.

       Note that any particular role will have the sum of privileges granted
       directly to it, privileges granted to any role it is presently a member
       of, and privileges granted to PUBLIC. Thus, for example, revoking
       SELECT privilege from PUBLIC does not necessarily mean that all roles
       have lost SELECT privilege on the object: those who have it granted
       directly or via another role will still have it. Similarly, revoking
       SELECT from a user might not prevent that user from using SELECT if
       PUBLIC or another membership role still has SELECT rights.

       If GRANT OPTION FOR is specified, only the grant option for the
       privilege is revoked, not the privilege itself. Otherwise, both the
       privilege and the grant option are revoked.

       If a user holds a privilege with grant option and has granted it to
       other users then the privileges held by those other users are called
       dependent privileges. If the privilege or the grant option held by the
       first user is being revoked and dependent privileges exist, those
       dependent privileges are also revoked if CASCADE is specified; if it is
       not, the revoke action will fail. This recursive revocation only
       affects privileges that were granted through a chain of users that is
       traceable to the user that is the subject of this REVOKE command. Thus,
       the affected users might effectively keep the privilege if it was also
       granted through other users.

       When revoking privileges on a table, the corresponding column
       privileges (if any) are automatically revoked on each column of the
       table, as well. On the other hand, if a role has been granted
       privileges on a table, then revoking the same privileges from
       individual columns will have no effect.

       When revoking membership in a role, GRANT OPTION is instead called
       ADMIN OPTION, but the behavior is similar. Note also that this form of
       the command does not allow the noise word GROUP.

NOTES
       Use psql(1)'s \dp command to display the privileges granted on existing
       tables and columns. See GRANT(7) for information about the format. For
       non-table objects there are other \d commands that can display their
       privileges.

       A user can only revoke privileges that were granted directly by that
       user. If, for example, user A has granted a privilege with grant option
       to user B, and user B has in turned granted it to user C, then user A
       cannot revoke the privilege directly from C. Instead, user A could
       revoke the grant option from user B and use the CASCADE option so that
       the privilege is in turn revoked from user C. For another example, if
       both A and B have granted the same privilege to C, A can revoke their
       own grant but not B's grant, so C will still effectively have the
       privilege.

<!-- 2aae4b53-bcdf-4cea-9b45-c301bef902cf <=< ACCEPT -->       When a non-owner of an object attempts to REVOKE privileges on the
       object, the command will fail outright if the user has no privileges
       whatsoever on the object. As long as some privilege is available, the
       command will proceed, but it will revoke only those privileges for
       which the user has grant options. The REVOKE ALL PRIVILEGES forms will
       issue a warning message if no grant options are held, while the other
       forms will issue a warning if grant options for any of the privileges
       specifically named in the command are not held. (In principle these
       statements apply to the object owner as well, but since the owner is
       always treated as holding all grant options, the cases can never
       occur.)<!-- ACCEPT >=> 2aae4b53-bcdf-4cea-9b45-c301bef902cf -->

       If a superuser chooses to issue a GRANT or REVOKE command, the command
       is performed as though it were issued by the owner of the affected
       object. Since all privileges ultimately come from the object owner
       (possibly indirectly via chains of grant options), it is possible for a
       superuser to revoke all privileges, but this might require use of
       CASCADE as stated above.

       REVOKE can also be done by a role that is not the owner of the affected
       object, but is a member of the role that owns the object, or is a
       member of a role that holds privileges WITH GRANT OPTION on the object.
       In this case the command is performed as though it were issued by the
       containing role that actually owns the object or holds the privileges
       WITH GRANT OPTION. For example, if table t1 is owned by role g1, of
       which role u1 is a member, then u1 can revoke privileges on t1 that are
       recorded as being granted by g1. This would include grants made by u1
       as well as by other members of role g1.

       If the role executing REVOKE holds privileges indirectly via more than
       one role membership path, it is unspecified which containing role will
       be used to perform the command. In such cases it is best practice to
       use SET ROLE to become the specific role you want to do the REVOKE as.
       Failure to do so might lead to revoking privileges other than the ones
       you intended, or not revoking anything at all.

EXAMPLES
       Revoke insert privilege for the public on table films:

           REVOKE INSERT ON films FROM PUBLIC;

       Revoke all privileges from user manuel on view kinds:

           REVOKE ALL PRIVILEGES ON kinds FROM manuel;

       Note that this actually means "revoke all privileges that I granted".

       Revoke membership in role admins from user joe:

           REVOKE admins FROM joe;

COMPATIBILITY
       The compatibility notes of the GRANT(7) command apply analogously to
       REVOKE. The keyword RESTRICT or CASCADE is required according to the
       standard, but PostgreSQL assumes RESTRICT by default.

SEE ALSO
       GRANT(7)



PostgreSQL 9.6.1                     2016                            REVOKE(7)
DROP POLICY(7)          PostgreSQL 9.6.1 Documentation          DROP POLICY(7)



NAME
       DROP_POLICY - remove a row level security policy from a table

SYNOPSIS
       DROP POLICY [ IF EXISTS ] name ON table_name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP POLICY removes the specified policy from the table. Note that if
       the last policy is removed for a table and the table still has row
       level security enabled via ALTER TABLE, then the default-deny policy
       will be used.  ALTER TABLE ... DISABLE ROW LEVEL SECURITY can be used
       to disable row level security for a table, whether policies for the
       table exist or not.

PARAMETERS
       IF EXISTS
           Do not throw an error if the policy does not exist. A notice is
           issued in this case.

       name
           The name of the policy to drop.

       table_name
           The name (optionally schema-qualified) of the table that the policy
           is on.

       CASCADE
       RESTRICT
           These key words do not have any effect, since there are no
           dependencies on policies.

EXAMPLES
       To drop the policy called p1 on the table named my_table:

           DROP POLICY p1 ON my_table;


COMPATIBILITY
       DROP POLICY is a PostgreSQL extension.

SEE ALSO
       CREATE POLICY (CREATE_POLICY(7)), ALTER POLICY (ALTER_POLICY(7))



PostgreSQL 9.6.1                     2016                       DROP POLICY(7)
VALUES(7)               PostgreSQL 9.6.1 Documentation               VALUES(7)



NAME
       VALUES - compute a set of rows

SYNOPSIS
       VALUES ( expression [, ...] ) [, ...]
           [ ORDER BY sort_expression [ ASC | DESC | USING operator ] [, ...] ]
           [ LIMIT { count | ALL } ]
           [ OFFSET start [ ROW | ROWS ] ]
           [ FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } ONLY ]

DESCRIPTION
       VALUES computes a row value or set of row values specified by value
       expressions. It is most commonly used to generate a "constant table"
       within a larger command, but it can be used on its own.

       When more than one row is specified, all the rows must have the same
       number of elements. The data types of the resulting table's columns are
       determined by combining the explicit or inferred types of the
       expressions appearing in that column, using the same rules as for UNION
       (see Section 10.5, "UNION, CASE, and Related Constructs", in the
       documentation).

       Within larger commands, VALUES is syntactically allowed anywhere that
       SELECT is. Because it is treated like a SELECT by the grammar, it is
       possible to use the ORDER BY, LIMIT (or equivalently FETCH FIRST), and
       OFFSET clauses with a VALUES command.

PARAMETERS
       expression
           A constant or expression to compute and insert at the indicated
           place in the resulting table (set of rows). In a VALUES list
           appearing at the top level of an INSERT, an expression can be
           replaced by DEFAULT to indicate that the destination column's
           default value should be inserted.  DEFAULT cannot be used when
           VALUES appears in other contexts.

       sort_expression
           An expression or integer constant indicating how to sort the result
           rows. This expression can refer to the columns of the VALUES result
           as column1, column2, etc. For more details see ORDER BY Clause.

       operator
           A sorting operator. For details see ORDER BY Clause.

       count
           The maximum number of rows to return. For details see LIMIT Clause.

       start
           The number of rows to skip before starting to return rows. For
           details see LIMIT Clause.

NOTES
       VALUES lists with very large numbers of rows should be avoided, as you
       might encounter out-of-memory failures or poor performance.  VALUES
       appearing within INSERT is a special case (because the desired column
       types are known from the INSERT's target table, and need not be
       inferred by scanning the VALUES list), so it can handle larger lists
       than are practical in other contexts.

EXAMPLES
       A bare VALUES command:

           VALUES (1, 'one'), (2, 'two'), (3, 'three');

       This will return a table of two columns and three rows. It's
       effectively equivalent to:

           SELECT 1 AS column1, 'one' AS column2
           UNION ALL
           SELECT 2, 'two'
           UNION ALL
           SELECT 3, 'three';

       More usually, VALUES is used within a larger SQL command. The most
       common use is in INSERT:

           INSERT INTO films (code, title, did, date_prod, kind)
               VALUES ('T_601', 'Yojimbo', 106, '1961-06-16', 'Drama');

       In the context of INSERT, entries of a VALUES list can be DEFAULT to
       indicate that the column default should be used here instead of
       specifying a value:

           INSERT INTO films VALUES
               ('UA502', 'Bananas', 105, DEFAULT, 'Comedy', '82 minutes'),
               ('T_601', 'Yojimbo', 106, DEFAULT, 'Drama', DEFAULT);

       VALUES can also be used where a sub-SELECT might be written, for
       example in a FROM clause:

           SELECT f.*
             FROM films f, (VALUES('MGM', 'Horror'), ('UA', 'Sci-Fi')) AS t (studio, kind)
             WHERE f.studio = t.studio AND f.kind = t.kind;

           UPDATE employees SET salary = salary * v.increase
             FROM (VALUES(1, 200000, 1.2), (2, 400000, 1.4)) AS v (depno, target, increase)
             WHERE employees.depno = v.depno AND employees.sales &amp;gt;= v.target;

       Note that an AS clause is required when VALUES is used in a FROM
       clause, just as is true for SELECT. It is not required that the AS
       clause specify names for all the columns, but it's good practice to do
       so. (The default column names for VALUES are column1, column2, etc in
       PostgreSQL, but these names might be different in other database
       systems.)

       When VALUES is used in INSERT, the values are all automatically coerced
       to the data type of the corresponding destination column. When it's
       used in other contexts, it might be necessary to specify the correct
       data type. If the entries are all quoted literal constants, coercing
       the first is sufficient to determine the assumed type for all:

           SELECT * FROM machines
           WHERE ip_address IN (VALUES('192.168.0.1'::inet), ('192.168.0.10'), ('192.168.1.43'));

           Tip
           For simple IN tests, it's better to rely on the list-of-scalars
           form of IN than to write a VALUES query as shown above. The list of
           scalars method requires less writing and is often more efficient.

COMPATIBILITY
       VALUES conforms to the SQL standard.  LIMIT and OFFSET are PostgreSQL
       extensions; see also under SELECT(7).

SEE ALSO
       INSERT(7), SELECT(7)



PostgreSQL 9.6.1                     2016                            VALUES(7)
DECLARE(7)              PostgreSQL 9.6.1 Documentation              DECLARE(7)



NAME
       DECLARE - define a cursor

SYNOPSIS
       DECLARE name [ BINARY ] [ INSENSITIVE ] [ [ NO ] SCROLL ]
           CURSOR [ { WITH | WITHOUT } HOLD ] FOR query

DESCRIPTION
       DECLARE allows a user to create cursors, which can be used to retrieve
       a small number of rows at a time out of a larger query. After the
       cursor is created, rows are fetched from it using FETCH(7).

           Note
           This page describes usage of cursors at the SQL command level. If
           you are trying to use cursors inside a PL/pgSQL function, the rules
           are different -- see Section 41.7, "Cursors", in the documentation.

PARAMETERS
       name
           The name of the cursor to be created.

       BINARY
           Causes the cursor to return data in binary rather than in text
           format.

       INSENSITIVE
           Indicates that data retrieved from the cursor should be unaffected
           by updates to the table(s) underlying the cursor that occur after
           the cursor is created. In PostgreSQL, this is the default behavior;
           so this key word has no effect and is only accepted for
           compatibility with the SQL standard.

       SCROLL
       NO SCROLL
           SCROLL specifies that the cursor can be used to retrieve rows in a
           nonsequential fashion (e.g., backward). Depending upon the
           complexity of the query's execution plan, specifying SCROLL might
           impose a performance penalty on the query's execution time.  NO
           SCROLL specifies that the cursor cannot be used to retrieve rows in
           a nonsequential fashion. The default is to allow scrolling in some
           cases; this is not the same as specifying SCROLL. See NOTES for
           details.

       WITH HOLD
       WITHOUT HOLD
           WITH HOLD specifies that the cursor can continue to be used after
           the transaction that created it successfully commits.  WITHOUT HOLD
           specifies that the cursor cannot be used outside of the transaction
           that created it. If neither WITHOUT HOLD nor WITH HOLD is
           specified, WITHOUT HOLD is the default.

       query
           A SELECT(7) or VALUES(7) command which will provide the rows to be
           returned by the cursor.

       The key words BINARY, INSENSITIVE, and SCROLL can appear in any order.

NOTES
       Normal cursors return data in text format, the same as a SELECT would
       produce. The BINARY option specifies that the cursor should return data
       in binary format. This reduces conversion effort for both the server
       and client, at the cost of more programmer effort to deal with
       platform-dependent binary data formats. As an example, if a query
       returns a value of one from an integer column, you would get a string
       of 1 with a default cursor, whereas with a binary cursor you would get
       a 4-byte field containing the internal representation of the value (in
       big-endian byte order).

       Binary cursors should be used carefully. Many applications, including
       psql, are not prepared to handle binary cursors and expect data to come
       back in the text format.

           Note
           When the client application uses the "extended query" protocol to
           issue a FETCH command, the Bind protocol message specifies whether
           data is to be retrieved in text or binary format. This choice
           overrides the way that the cursor is defined. The concept of a
           binary cursor as such is thus obsolete when using extended query
           protocol -- any cursor can be treated as either text or binary.

       Unless WITH HOLD is specified, the cursor created by this command can
       only be used within the current transaction. Thus, DECLARE without WITH
       HOLD is useless outside a transaction block: the cursor would survive
       only to the completion of the statement. Therefore PostgreSQL reports
       an error if such a command is used outside a transaction block. Use
       BEGIN(7) and COMMIT(7) (or ROLLBACK(7)) to define a transaction block.

       If WITH HOLD is specified and the transaction that created the cursor
       successfully commits, the cursor can continue to be accessed by
       subsequent transactions in the same session. (But if the creating
       transaction is aborted, the cursor is removed.) A cursor created with
       WITH HOLD is closed when an explicit CLOSE command is issued on it, or
       the session ends. In the current implementation, the rows represented
       by a held cursor are copied into a temporary file or memory area so
       that they remain available for subsequent transactions.

       WITH HOLD may not be specified when the query includes FOR UPDATE or
       FOR SHARE.

       The SCROLL option should be specified when defining a cursor that will
       be used to fetch backwards. This is required by the SQL standard.
       However, for compatibility with earlier versions, PostgreSQL will allow
       backward fetches without SCROLL, if the cursor's query plan is simple
       enough that no extra overhead is needed to support it. However,
       application developers are advised not to rely on using backward
       fetches from a cursor that has not been created with SCROLL. If NO
       SCROLL is specified, then backward fetches are disallowed in any case.

       Backward fetches are also disallowed when the query includes FOR UPDATE
       or FOR SHARE; therefore SCROLL may not be specified in this case.

           Caution
           Scrollable and WITH HOLD cursors may give unexpected results if
           they invoke any volatile functions (see Section 36.6, "Function
           Volatility Categories", in the documentation). When a previously
           fetched row is re-fetched, the functions might be re-executed,
           perhaps leading to results different from the first time. One
           workaround for such cases is to declare the cursor WITH HOLD and
           commit the transaction before reading any rows from it. This will
           force the entire output of the cursor to be materialized in
           temporary storage, so that volatile functions are executed exactly
           once for each row.

       If the cursor's query includes FOR UPDATE or FOR SHARE, then returned
       rows are locked at the time they are first fetched, in the same way as
       for a regular SELECT(7) command with these options. In addition, the
       returned rows will be the most up-to-date versions; therefore these
       options provide the equivalent of what the SQL standard calls a
       "sensitive cursor". (Specifying INSENSITIVE together with FOR UPDATE or
       FOR SHARE is an error.)

           Caution
           It is generally recommended to use FOR UPDATE if the cursor is
           intended to be used with UPDATE ... WHERE CURRENT OF or DELETE ...
           WHERE CURRENT OF. Using FOR UPDATE prevents other sessions from
           changing the rows between the time they are fetched and the time
           they are updated. Without FOR UPDATE, a subsequent WHERE CURRENT OF
           command will have no effect if the row was changed since the cursor
           was created.

           Another reason to use FOR UPDATE is that without it, a subsequent
           WHERE CURRENT OF might fail if the cursor query does not meet the
           SQL standard's rules for being "simply updatable" (in particular,
           the cursor must reference just one table and not use grouping or
           ORDER BY). Cursors that are not simply updatable might work, or
           might not, depending on plan choice details; so in the worst case,
           an application might work in testing and then fail in production.

           The main reason not to use FOR UPDATE with WHERE CURRENT OF is if
           you need the cursor to be scrollable, or to be insensitive to the
           subsequent updates (that is, continue to show the old data). If
           this is a requirement, pay close heed to the caveats shown above.

       The SQL standard only makes provisions for cursors in embedded SQL. The
       PostgreSQL server does not implement an OPEN statement for cursors; a
       cursor is considered to be open when it is declared. However, ECPG, the
       embedded SQL preprocessor for PostgreSQL, supports the standard SQL
       cursor conventions, including those involving DECLARE and OPEN
       statements.

       You can see all available cursors by querying the pg_cursors system
       view.

EXAMPLES
       To declare a cursor:

           DECLARE liahona CURSOR FOR SELECT * FROM films;

       See FETCH(7) for more examples of cursor usage.

COMPATIBILITY
       The SQL standard says that it is implementation-dependent whether
       cursors are sensitive to concurrent updates of the underlying data by
       default. In PostgreSQL, cursors are insensitive by default, and can be
       made sensitive by specifying FOR UPDATE. Other products may work
       differently.

       The SQL standard allows cursors only in embedded SQL and in modules.
       PostgreSQL permits cursors to be used interactively.

       Binary cursors are a PostgreSQL extension.

SEE ALSO
       CLOSE(7), FETCH(7), MOVE(7)



PostgreSQL 9.6.1                     2016                           DECLARE(7)
CLOSE(7)                PostgreSQL 9.6.1 Documentation                CLOSE(7)



NAME
       CLOSE - close a cursor

SYNOPSIS
       CLOSE { name | ALL }

DESCRIPTION
       CLOSE frees the resources associated with an open cursor. After the
       cursor is closed, no subsequent operations are allowed on it. A cursor
       should be closed when it is no longer needed.

       Every non-holdable open cursor is implicitly closed when a transaction
       is terminated by COMMIT or ROLLBACK. A holdable cursor is implicitly
       closed if the transaction that created it aborts via ROLLBACK. If the
       creating transaction successfully commits, the holdable cursor remains
       open until an explicit CLOSE is executed, or the client disconnects.

PARAMETERS
       name
           The name of an open cursor to close.

       ALL
           Close all open cursors.

NOTES
       PostgreSQL does not have an explicit OPEN cursor statement; a cursor is
       considered open when it is declared. Use the DECLARE(7) statement to
       declare a cursor.

       You can see all available cursors by querying the pg_cursors system
       view.

       If a cursor is closed after a savepoint which is later rolled back, the
       CLOSE is not rolled back; that is, the cursor remains closed.

EXAMPLES
       Close the cursor liahona:

           CLOSE liahona;

COMPATIBILITY
       CLOSE is fully conforming with the SQL standard.  CLOSE ALL is a
       PostgreSQL extension.

SEE ALSO
       DECLARE(7), FETCH(7), MOVE(7)



PostgreSQL 9.6.1                     2016                             CLOSE(7)
CREATE SERVER(7)        PostgreSQL 9.6.1 Documentation        CREATE SERVER(7)



NAME
       CREATE_SERVER - define a new foreign server

SYNOPSIS
       CREATE SERVER server_name [ TYPE 'server_type' ] [ VERSION 'server_version' ]
           FOREIGN DATA WRAPPER fdw_name
           [ OPTIONS ( option 'value' [, ... ] ) ]

DESCRIPTION
       CREATE SERVER defines a new foreign server. The user who defines the
       server becomes its owner.

       A foreign server typically encapsulates connection information that a
       foreign-data wrapper uses to access an external data resource.
       Additional user-specific connection information may be specified by
       means of user mappings.

       The server name must be unique within the database.

       Creating a server requires USAGE privilege on the foreign-data wrapper
       being used.

PARAMETERS
       server_name
           The name of the foreign server to be created.

       server_type
           Optional server type, potentially useful to foreign-data wrappers.

       server_version
           Optional server version, potentially useful to foreign-data
           wrappers.

       fdw_name
           The name of the foreign-data wrapper that manages the server.

       OPTIONS ( option 'value' [, ... ] )
           This clause specifies the options for the server. The options
           typically define the connection details of the server, but the
           actual names and values are dependent on the server's foreign-data
           wrapper.

NOTES
       When using the dblink module, a foreign server's name can be used as an
       argument of the dblink_connect(3) function to indicate the connection
       parameters. It is necessary to have the USAGE privilege on the foreign
       server to be able to use it in this way.

EXAMPLES
       Create a server myserver that uses the foreign-data wrapper
       postgres_fdw:

           CREATE SERVER myserver FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host 'foo', dbname 'foodb', port '5432');

       See postgres_fdw for more details.

COMPATIBILITY
       CREATE SERVER conforms to ISO/IEC 9075-9 (SQL/MED).

SEE ALSO
       ALTER SERVER (ALTER_SERVER(7)), DROP SERVER (DROP_SERVER(7)), CREATE
       FOREIGN DATA WRAPPER (CREATE_FOREIGN_DATA_WRAPPER(7)), CREATE FOREIGN
       TABLE (CREATE_FOREIGN_TABLE(7)), CREATE USER MAPPING
       (CREATE_USER_MAPPING(7))



PostgreSQL 9.6.1                     2016                     CREATE SERVER(7)
ALTER VIEW(7)           PostgreSQL 9.6.1 Documentation           ALTER VIEW(7)



NAME
       ALTER_VIEW - change the definition of a view

SYNOPSIS
       ALTER VIEW [ IF EXISTS ] name ALTER [ COLUMN ] column_name SET DEFAULT expression
       ALTER VIEW [ IF EXISTS ] name ALTER [ COLUMN ] column_name DROP DEFAULT
       ALTER VIEW [ IF EXISTS ] name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER VIEW [ IF EXISTS ] name RENAME TO new_name
       ALTER VIEW [ IF EXISTS ] name SET SCHEMA new_schema
       ALTER VIEW [ IF EXISTS ] name SET ( view_option_name [= view_option_value] [, ... ] )
       ALTER VIEW [ IF EXISTS ] name RESET ( view_option_name [, ... ] )

DESCRIPTION
       ALTER VIEW changes various auxiliary properties of a view. (If you want
       to modify the view's defining query, use CREATE OR REPLACE VIEW.)

<!-- ad137a5f-7fa1-4b53-a38d-4827f1ccde6e <=< ACCEPT -->       You must own the view to use ALTER VIEW. To change a view's schema, you
       must also have CREATE privilege on the new schema. To alter the owner,
       you must also be a direct or indirect member of the new owning role,
       and that role must have CREATE privilege on the view's schema. (These
       restrictions enforce that altering the owner doesn't do anything you
       couldn't do by dropping and recreating the view. However, a superuser
       can alter ownership of any view anyway.)
<!-- ACCEPT >=> ad137a5f-7fa1-4b53-a38d-4827f1ccde6e -->
PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing view.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       IF EXISTS
           Do not throw an error if the view does not exist. A notice is
           issued in this case.

       SET/DROP DEFAULT
           These forms set or remove the default value for a column. A view
           column's default value is substituted into any INSERT or UPDATE
           command whose target is the view, before applying any rules or
           triggers for the view. The view's default will therefore take
           precedence over any default values from underlying relations.

       new_owner
           The user name of the new owner of the view.

       new_name
           The new name for the view.

       new_schema
           The new schema for the view.

       SET ( view_option_name [= view_option_value] [, ... ] )
       RESET ( view_option_name [, ... ] )
           Sets or resets a view option. Currently supported options are:

           check_option (string)
               Changes the check option of the view. The value must be local
               or cascaded.

           security_barrier (boolean)
               Changes the security-barrier property of the view. The value
               must be Boolean value, such as true or false.


NOTES
       For historical reasons, ALTER TABLE can be used with views too; but the
       only variants of ALTER TABLE that are allowed with views are equivalent
       to the ones shown above.

EXAMPLES
       To rename the view foo to bar:

           ALTER VIEW foo RENAME TO bar;

       To attach a default column value to an updatable view:

           CREATE TABLE base_table (id int, ts timestamptz);
           CREATE VIEW a_view AS SELECT * FROM base_table;
           ALTER VIEW a_view ALTER COLUMN ts SET DEFAULT now();
           INSERT INTO base_table(id) VALUES(1);  -- ts will receive a NULL
           INSERT INTO a_view(id) VALUES(2);  -- ts will receive the current time

COMPATIBILITY
       ALTER VIEW is a PostgreSQL extension of the SQL standard.

SEE ALSO
       CREATE VIEW (CREATE_VIEW(7)), DROP VIEW (DROP_VIEW(7))



PostgreSQL 9.6.1                     2016                        ALTER VIEW(7)
ALTER OPERATOR(7)       PostgreSQL 9.6.1 Documentation       ALTER OPERATOR(7)



NAME
       ALTER_OPERATOR - change the definition of an operator

SYNOPSIS
       ALTER OPERATOR name ( { left_type | NONE } , { right_type | NONE } )
           OWNER TO { new_owner | CURRENT_USER | SESSION_USER }

       ALTER OPERATOR name ( { left_type | NONE } , { right_type | NONE } )
           SET SCHEMA new_schema

       ALTER OPERATOR name ( { left_type | NONE } , { right_type | NONE } )
           SET ( {  RESTRICT = { res_proc | NONE }
                  | JOIN = { join_proc | NONE }
                } [, ... ] )

DESCRIPTION
       ALTER OPERATOR changes the definition of an operator.

       You must own the operator to use ALTER OPERATOR. To alter the owner,
       you must also be a direct or indirect member of the new owning role,
       and that role must have CREATE privilege on the operator's schema.
       (These restrictions enforce that altering the owner doesn't do anything
       you couldn't do by dropping and recreating the operator. However, a
       superuser can alter ownership of any operator anyway.)

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing operator.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       left_type
           The data type of the operator's left operand; write NONE if the
           operator has no left operand.

       right_type
           The data type of the operator's right operand; write NONE if the
           operator has no right operand.

       new_owner
           The new owner of the operator.

       new_schema
           The new schema for the operator.

       res_proc
           The restriction selectivity estimator function for this operator;
           write NONE to remove existing selectivity estimator.

       join_proc
           The join selectivity estimator function for this operator; write
           NONE to remove existing selectivity estimator.

EXAMPLES
       Change the owner of a custom operator a @@ b for type text:

           ALTER OPERATOR @@ (text, text) OWNER TO joe;

       Change the restriction and join selectivity estimator functions of a
       custom operator a &amp;&amp; b for type int[]:

           ALTER OPERATOR &amp;&amp; (_int4, _int4) SET (RESTRICT = _int_contsel, JOIN = _int_contjoinsel);

COMPATIBILITY
       There is no ALTER OPERATOR statement in the SQL standard.

SEE ALSO
       CREATE OPERATOR (CREATE_OPERATOR(7)), DROP OPERATOR (DROP_OPERATOR(7))



PostgreSQL 9.6.1                     2016                    ALTER OPERATOR(7)
CREATE TEXT SEARCH DICTIPostgreSQL 9.6.1 DocumCREATEoTEXT SEARCH DICTIONARY(7)



NAME
       CREATE_TEXT_SEARCH_DICTIONARY - define a new text search dictionary

SYNOPSIS
       CREATE TEXT SEARCH DICTIONARY name (
           TEMPLATE = template
           [, option = value [, ... ]]
       )

DESCRIPTION
       CREATE TEXT SEARCH DICTIONARY creates a new text search dictionary. A
       text search dictionary specifies a way of recognizing interesting or
       uninteresting words for searching. A dictionary depends on a text
       search template, which specifies the functions that actually perform
       the work. Typically the dictionary provides some options that control
       the detailed behavior of the template's functions.

       If a schema name is given then the text search dictionary is created in
       the specified schema. Otherwise it is created in the current schema.

       The user who defines a text search dictionary becomes its owner.

       Refer to Chapter 12, Full Text Search, in the documentation for further
       information.

PARAMETERS
       name
           The name of the text search dictionary to be created. The name can
           be schema-qualified.

       template
           The name of the text search template that will define the basic
           behavior of this dictionary.

       option
           The name of a template-specific option to be set for this
           dictionary.

       value
           The value to use for a template-specific option. If the value is
           not a simple identifier or number, it must be quoted (but you can
           always quote it, if you wish).

       The options can appear in any order.

EXAMPLES
       The following example command creates a Snowball-based dictionary with
       a nonstandard list of stop words.

           CREATE TEXT SEARCH DICTIONARY my_russian (
               template = snowball,
               language = russian,
               stopwords = myrussian
           );

COMPATIBILITY
       There is no CREATE TEXT SEARCH DICTIONARY statement in the SQL
       standard.

SEE ALSO
       ALTER TEXT SEARCH DICTIONARY (ALTER_TEXT_SEARCH_DICTIONARY(7)), DROP
       TEXT SEARCH DICTIONARY (DROP_TEXT_SEARCH_DICTIONARY(7))



PostgreSQL 9.6.1                     2016     CREATE TEXT SEARCH DICTIONARY(7)
BEGIN(7)                PostgreSQL 9.6.1 Documentation                BEGIN(7)



NAME
       BEGIN - start a transaction block

SYNOPSIS
       BEGIN [ WORK | TRANSACTION ] [ transaction_mode [, ...] ]

       where transaction_mode is one of:

           ISOLATION LEVEL { SERIALIZABLE | REPEATABLE READ | READ COMMITTED | READ UNCOMMITTED }
           READ WRITE | READ ONLY
           [ NOT ] DEFERRABLE

DESCRIPTION
       BEGIN initiates a transaction block, that is, all statements after a
       BEGIN command will be executed in a single transaction until an
       explicit COMMIT(7) or ROLLBACK(7) is given. By default (without BEGIN),
       PostgreSQL executes transactions in "autocommit" mode, that is, each
       statement is executed in its own transaction and a commit is implicitly
       performed at the end of the statement (if execution was successful,
       otherwise a rollback is done).

       Statements are executed more quickly in a transaction block, because
       transaction start/commit requires significant CPU and disk activity.
       Execution of multiple statements inside a transaction is also useful to
       ensure consistency when making several related changes: other sessions
       will be unable to see the intermediate states wherein not all the
       related updates have been done.

       If the isolation level, read/write mode, or deferrable mode is
       specified, the new transaction has those characteristics, as if SET
       TRANSACTION (SET_TRANSACTION(7)) was executed.

PARAMETERS
       WORK
       TRANSACTION
           Optional key words. They have no effect.

       Refer to SET TRANSACTION (SET_TRANSACTION(7)) for information on the
       meaning of the other parameters to this statement.

NOTES
       START TRANSACTION (START_TRANSACTION(7)) has the same functionality as
       BEGIN.

       Use COMMIT(7) or ROLLBACK(7) to terminate a transaction block.

       Issuing BEGIN when already inside a transaction block will provoke a
       warning message. The state of the transaction is not affected. To nest
       transactions within a transaction block, use savepoints (see
       SAVEPOINT(7)).

       For reasons of backwards compatibility, the commas between successive
       transaction_modes can be omitted.

EXAMPLES
       To begin a transaction block:

           BEGIN;

COMPATIBILITY
       BEGIN is a PostgreSQL language extension. It is equivalent to the
       SQL-standard command START TRANSACTION (START_TRANSACTION(7)), whose
       reference page contains additional compatibility information.

       The DEFERRABLEtransaction_mode is a PostgreSQL language extension.

       Incidentally, the BEGIN key word is used for a different purpose in
       embedded SQL. You are advised to be careful about the transaction
       semantics when porting database applications.

SEE ALSO
       COMMIT(7), ROLLBACK(7), START TRANSACTION (START_TRANSACTION(7)),
       SAVEPOINT(7)



PostgreSQL 9.6.1                     2016                             BEGIN(7)
ALTER USER(7)           PostgreSQL 9.6.1 Documentation           ALTER USER(7)



<!-- 10034cb1-0a09-4f3b-a034-a986f6882838 <=< ACCEPT -->NAME
       ALTER_USER - change a database role

SYNOPSIS
       ALTER USER role_specification [ WITH ] option [ ... ]

       where option can be:

             SUPERUSER | NOSUPERUSER
           | CREATEDB | NOCREATEDB
           | CREATEROLE | NOCREATEROLE
           | INHERIT | NOINHERIT
           | LOGIN | NOLOGIN
           | REPLICATION | NOREPLICATION
           | BYPASSRLS | NOBYPASSRLS
           | CONNECTION LIMIT connlimit
           | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
           | VALID UNTIL 'timestamp'

       ALTER USER name RENAME TO new_name

       ALTER USER role_specification SET configuration_parameter { TO | = } { value | DEFAULT }
       ALTER USER role_specification SET configuration_parameter FROM CURRENT
       ALTER USER role_specification RESET configuration_parameter
       ALTER USER role_specification RESET ALL

       where role_specification can be:

           [ GROUP ] role_name
         | CURRENT_USER
         | SESSION_USER<!-- ACCEPT >=> 10034cb1-0a09-4f3b-a034-a986f6882838 -->

DESCRIPTION
       ALTER USER is now an alias for ALTER ROLE (ALTER_ROLE(7)).

COMPATIBILITY
       The ALTER USER statement is a PostgreSQL extension. The SQL standard
       leaves the definition of users to the implementation.

SEE ALSO
       ALTER ROLE (ALTER_ROLE(7))



PostgreSQL 9.6.1                     2016                        ALTER USER(7)
CREATE INDEX(7)         PostgreSQL 9.6.1 Documentation         CREATE INDEX(7)



NAME
       CREATE_INDEX - define a new index

SYNOPSIS
       CREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] name ] ON table_name [ USING method ]
           ( { column_name | ( expression ) } [ COLLATE collation ] [ opclass ] [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, ...] )
           [ WITH ( storage_parameter = value [, ... ] ) ]
           [ TABLESPACE tablespace_name ]
           [ WHERE predicate ]

DESCRIPTION
       CREATE INDEX constructs an index on the specified column(s) of the
       specified relation, which can be a table or a materialized view.
       Indexes are primarily used to enhance database performance (though
       inappropriate use can result in slower performance).

       The key field(s) for the index are specified as column names, or
       alternatively as expressions written in parentheses. Multiple fields
       can be specified if the index method supports multicolumn indexes.

       An index field can be an expression computed from the values of one or
       more columns of the table row. This feature can be used to obtain fast
       access to data based on some transformation of the basic data. For
       example, an index computed on upper(col) would allow the clause WHERE
       upper(col) = 'JIM' to use an index.

       PostgreSQL provides the index methods B-tree, hash, GiST, SP-GiST, GIN,
       and BRIN. Users can also define their own index methods, but that is
       fairly complicated.

       When the WHERE clause is present, a partial index is created. A partial
       index is an index that contains entries for only a portion of a table,
       usually a portion that is more useful for indexing than the rest of the
       table. For example, if you have a table that contains both billed and
       unbilled orders where the unbilled orders take up a small fraction of
       the total table and yet that is an often used section, you can improve
       performance by creating an index on just that portion. Another possible
       application is to use WHERE with UNIQUE to enforce uniqueness over a
       subset of a table. See Section 11.8, "Partial Indexes", in the
       documentation for more discussion.

       The expression used in the WHERE clause can refer only to columns of
       the underlying table, but it can use all columns, not just the ones
       being indexed. Presently, subqueries and aggregate expressions are also
       forbidden in WHERE. The same restrictions apply to index fields that
       are expressions.

       All functions and operators used in an index definition must be
       "immutable", that is, their results must depend only on their arguments
       and never on any outside influence (such as the contents of another
       table or the current time). This restriction ensures that the behavior
       of the index is well-defined. To use a user-defined function in an
       index expression or WHERE clause, remember to mark the function
       immutable when you create it.

PARAMETERS
       UNIQUE
           Causes the system to check for duplicate values in the table when
           the index is created (if data already exist) and each time data is
           added. Attempts to insert or update data which would result in
           duplicate entries will generate an error.

       CONCURRENTLY
           When this option is used, PostgreSQL will build the index without
           taking any locks that prevent concurrent inserts, updates, or
           deletes on the table; whereas a standard index build locks out
           writes (but not reads) on the table until it's done. There are
           several caveats to be aware of when using this option -- see
           Building Indexes Concurrently.

       IF NOT EXISTS
           Do not throw an error if a relation with the same name already
           exists. A notice is issued in this case. Note that there is no
           guarantee that the existing index is anything like the one that
           would have been created. Index name is required when IF NOT EXISTS
           is specified.

       name
           The name of the index to be created. No schema name can be included
           here; the index is always created in the same schema as its parent
           table. If the name is omitted, PostgreSQL chooses a suitable name
           based on the parent table's name and the indexed column name(s).

       table_name
           The name (possibly schema-qualified) of the table to be indexed.

       method
           The name of the index method to be used. Choices are btree, hash,
           gist, spgist, gin, and brin. The default method is btree.

       column_name
           The name of a column of the table.

       expression
           An expression based on one or more columns of the table. The
           expression usually must be written with surrounding parentheses, as
           shown in the syntax. However, the parentheses can be omitted if the
           expression has the form of a function call.

       collation
           The name of the collation to use for the index. By default, the
           index uses the collation declared for the column to be indexed or
           the result collation of the expression to be indexed. Indexes with
           non-default collations can be useful for queries that involve
           expressions using non-default collations.

       opclass
           The name of an operator class. See below for details.

       ASC
           Specifies ascending sort order (which is the default).

       DESC
           Specifies descending sort order.

       NULLS FIRST
           Specifies that nulls sort before non-nulls. This is the default
           when DESC is specified.

       NULLS LAST
           Specifies that nulls sort after non-nulls. This is the default when
           DESC is not specified.

       storage_parameter
           The name of an index-method-specific storage parameter. See Index
           Storage Parameters for details.

       tablespace_name
           The tablespace in which to create the index. If not specified,
           default_tablespace is consulted, or temp_tablespaces for indexes on
           temporary tables.

       predicate
           The constraint expression for a partial index.

   Index Storage Parameters
       The optional WITH clause specifies storage parameters for the index.
       Each index method has its own set of allowed storage parameters. The
       B-tree, hash, GiST and SP-GiST index methods all accept this parameter:

       fillfactor
           The fillfactor for an index is a percentage that determines how
           full the index method will try to pack index pages. For B-trees,
           leaf pages are filled to this percentage during initial index
           build, and also when extending the index at the right (adding new
           largest key values). If pages subsequently become completely full,
           they will be split, leading to gradual degradation in the index's
           efficiency. B-trees use a default fillfactor of 90, but any integer
           value from 10 to 100 can be selected. If the table is static then
           fillfactor 100 is best to minimize the index's physical size, but
           for heavily updated tables a smaller fillfactor is better to
           minimize the need for page splits. The other index methods use
           fillfactor in different but roughly analogous ways; the default
           fillfactor varies between methods.

       GiST indexes additionally accept this parameter:

       buffering
           Determines whether the buffering build technique described in
           Section 61.4.1, "GiST buffering build", in the documentation is
           used to build the index. With OFF it is disabled, with ON it is
           enabled, and with AUTO it is initially disabled, but turned on
           on-the-fly once the index size reaches effective_cache_size. The
           default is AUTO.

       GIN indexes accept different parameters:

       fastupdate
           This setting controls usage of the fast update technique described
           in Section 63.4.1, "GIN Fast Update Technique", in the
           documentation. It is a Boolean parameter: ON enables fast update,
           OFF disables it. (Alternative spellings of ON and OFF are allowed
           as described in Section 19.1, "Setting Parameters", in the
           documentation.) The default is ON.

               Note
               Turning fastupdate off via ALTER INDEX prevents future
               insertions from going into the list of pending index entries,
               but does not in itself flush previous entries. You might want
               to VACUUM the table or call gin_clean_pending_list function
               afterward to ensure the pending list is emptied.

       gin_pending_list_limit
           Custom gin_pending_list_limit parameter. This value is specified in
           kilobytes.

       BRIN indexes accept a different parameter:

       pages_per_range
           Defines the number of table blocks that make up one block range for
           each entry of a BRIN index (see Section 64.1, "Introduction", in
           the documentation for more details). The default is 128.

   Building Indexes Concurrently
       Creating an index can interfere with regular operation of a database.
       Normally PostgreSQL locks the table to be indexed against writes and
       performs the entire index build with a single scan of the table. Other
       transactions can still read the table, but if they try to insert,
       update, or delete rows in the table they will block until the index
       build is finished. This could have a severe effect if the system is a
       live production database. Very large tables can take many hours to be
       indexed, and even for smaller tables, an index build can lock out
       writers for periods that are unacceptably long for a production system.

       PostgreSQL supports building indexes without locking out writes. This
       method is invoked by specifying the CONCURRENTLY option of CREATE
       INDEX. When this option is used, PostgreSQL must perform two scans of
       the table, and in addition it must wait for all existing transactions
       that could potentially modify or use the index to terminate. Thus this
       method requires more total work than a standard index build and takes
       significantly longer to complete. However, since it allows normal
       operations to continue while the index is built, this method is useful
       for adding new indexes in a production environment. Of course, the
       extra CPU and I/O load imposed by the index creation might slow other
       operations.

       In a concurrent index build, the index is actually entered into the
       system catalogs in one transaction, then two table scans occur in two
       more transactions. Before each table scan, the index build must wait
       for existing transactions that have modified the table to terminate.
       After the second scan, the index build must wait for any transactions
       that have a snapshot (see Chapter 13, Concurrency Control, in the
       documentation) predating the second scan to terminate. Then finally the
       index can be marked ready for use, and the CREATE INDEX command
       terminates. Even then, however, the index may not be immediately usable
       for queries: in the worst case, it cannot be used as long as
       transactions exist that predate the start of the index build.

       If a problem arises while scanning the table, such as a deadlock or a
       uniqueness violation in a unique index, the CREATE INDEX command will
       fail but leave behind an "invalid" index. This index will be ignored
       for querying purposes because it might be incomplete; however it will
       still consume update overhead. The psql\d command will report such an
       index as INVALID:

           postgres=# \d tab
                  Table "public.tab"
            Column |  Type   | Modifiers
           --------+---------+-----------
            col    | integer |
           Indexes:
               "idx" btree (col) INVALID

       The recommended recovery method in such cases is to drop the index and
       try again to perform CREATE INDEX CONCURRENTLY. (Another possibility is
       to rebuild the index with REINDEX. However, since REINDEX does not
       support concurrent builds, this option is unlikely to seem attractive.)

       Another caveat when building a unique index concurrently is that the
       uniqueness constraint is already being enforced against other
       transactions when the second table scan begins. This means that
       constraint violations could be reported in other queries prior to the
       index becoming available for use, or even in cases where the index
       build eventually fails. Also, if a failure does occur in the second
       scan, the "invalid" index continues to enforce its uniqueness
       constraint afterwards.

       Concurrent builds of expression indexes and partial indexes are
       supported. Errors occurring in the evaluation of these expressions
       could cause behavior similar to that described above for unique
       constraint violations.

       Regular index builds permit other regular index builds on the same
       table to occur in parallel, but only one concurrent index build can
       occur on a table at a time. In both cases, no other types of schema
       modification on the table are allowed meanwhile. Another difference is
       that a regular CREATE INDEX command can be performed within a
       transaction block, but CREATE INDEX CONCURRENTLY cannot.

NOTES
       See Chapter 11, Indexes, in the documentation for information about
       when indexes can be used, when they are not used, and in which
       particular situations they can be useful.

           Caution
           Hash index operations are not presently WAL-logged, so hash indexes
           might need to be rebuilt with REINDEX after a database crash if
           there were unwritten changes. Also, changes to hash indexes are not
           replicated over streaming or file-based replication after the
           initial base backup, so they give wrong answers to queries that
           subsequently use them. Hash indexes are also not properly restored
           during point-in-time recovery. For these reasons, hash index use is
           presently discouraged.

       Currently, only the B-tree, GiST, GIN, and BRIN index methods support
       multicolumn indexes. Up to 32 fields can be specified by default. (This
       limit can be altered when building PostgreSQL.) Only B-tree currently
       supports unique indexes.

       An operator class can be specified for each column of an index. The
       operator class identifies the operators to be used by the index for
       that column. For example, a B-tree index on four-byte integers would
       use the int4_ops class; this operator class includes comparison
       functions for four-byte integers. In practice the default operator
       class for the column's data type is usually sufficient. The main point
       of having operator classes is that for some data types, there could be
       more than one meaningful ordering. For example, we might want to sort a
       complex-number data type either by absolute value or by real part. We
       could do this by defining two operator classes for the data type and
       then selecting the proper class when making an index. More information
       about operator classes is in Section 11.9, "Operator Classes and
       Operator Families", in the documentation and in Section 36.14,
       "Interfacing Extensions To Indexes", in the documentation.

       For index methods that support ordered scans (currently, only B-tree),
       the optional clauses ASC, DESC, NULLS FIRST, and/or NULLS LAST can be
       specified to modify the sort ordering of the index. Since an ordered
       index can be scanned either forward or backward, it is not normally
       useful to create a single-column DESC index -- that sort ordering is
       already available with a regular index. The value of these options is
       that multicolumn indexes can be created that match the sort ordering
       requested by a mixed-ordering query, such as SELECT ... ORDER BY x ASC,
       y DESC. The NULLS options are useful if you need to support "nulls sort
       low" behavior, rather than the default "nulls sort high", in queries
       that depend on indexes to avoid sorting steps.

       For most index methods, the speed of creating an index is dependent on
       the setting of maintenance_work_mem. Larger values will reduce the time
       needed for index creation, so long as you don't make it larger than the
       amount of memory really available, which would drive the machine into
       swapping.

       Use DROP INDEX (DROP_INDEX(7)) to remove an index.

       Prior releases of PostgreSQL also had an R-tree index method. This
       method has been removed because it had no significant advantages over
       the GiST method. If USING rtree is specified, CREATE INDEX will
       interpret it as USING gist, to simplify conversion of old databases to
       GiST.

EXAMPLES
       To create a B-tree index on the column title in the table films:

           CREATE UNIQUE INDEX title_idx ON films (title);

       To create an index on the expression lower(title), allowing efficient
       case-insensitive searches:

           CREATE INDEX ON films ((lower(title)));

       (In this example we have chosen to omit the index name, so the system
       will choose a name, typically films_lower_idx.)

       To create an index with non-default collation:

           CREATE INDEX title_idx_german ON films (title COLLATE "de_DE");

       To create an index with non-default sort ordering of nulls:

           CREATE INDEX title_idx_nulls_low ON films (title NULLS FIRST);

       To create an index with non-default fill factor:

           CREATE UNIQUE INDEX title_idx ON films (title) WITH (fillfactor = 70);

       To create a GIN index with fast updates disabled:

           CREATE INDEX gin_idx ON documents_table USING GIN (locations) WITH (fastupdate = off);

       To create an index on the column code in the table films and have the
       index reside in the tablespace indexspace:

           CREATE INDEX code_idx ON films (code) TABLESPACE indexspace;

       To create a GiST index on a point attribute so that we can efficiently
       use box operators on the result of the conversion function:

           CREATE INDEX pointloc
               ON points USING gist (box(location,location));
           SELECT * FROM points
               WHERE box(location,location) &amp;&amp; '(0,0),(1,1)'::box;

       To create an index without locking out writes to the table:

           CREATE INDEX CONCURRENTLY sales_quantity_index ON sales_table (quantity);

COMPATIBILITY
       CREATE INDEX is a PostgreSQL language extension. There are no
       provisions for indexes in the SQL standard.

SEE ALSO
       ALTER INDEX (ALTER_INDEX(7)), DROP INDEX (DROP_INDEX(7))



PostgreSQL 9.6.1                     2016                      CREATE INDEX(7)
ALTER DATABASE(7)       PostgreSQL 9.6.1 Documentation       ALTER DATABASE(7)



NAME
       ALTER_DATABASE - change a database

SYNOPSIS
       ALTER DATABASE name [ [ WITH ] option [ ... ] ]

       where option can be:

           ALLOW_CONNECTIONS allowconn
           CONNECTION LIMIT connlimit
           IS_TEMPLATE istemplate

       ALTER DATABASE name RENAME TO new_name

       ALTER DATABASE name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }

       ALTER DATABASE name SET TABLESPACE new_tablespace

       ALTER DATABASE name SET configuration_parameter { TO | = } { value | DEFAULT }
       ALTER DATABASE name SET configuration_parameter FROM CURRENT
       ALTER DATABASE name RESET configuration_parameter
       ALTER DATABASE name RESET ALL

DESCRIPTION
       ALTER DATABASE changes the attributes of a database.

       The first form changes certain per-database settings. (See below for
       details.) Only the database owner or a superuser can change these
       settings.

       The second form changes the name of the database. Only the database
       owner or a superuser can rename a database; non-superuser owners must
       also have the CREATEDB privilege. The current database cannot be
       renamed. (Connect to a different database if you need to do that.)

       The third form changes the owner of the database. To alter the owner,
       you must own the database and also be a direct or indirect member of
       the new owning role, and you must have the CREATEDB privilege. (Note
       that superusers have all these privileges automatically.)

       The fourth form changes the default tablespace of the database. Only
       the database owner or a superuser can do this; you must also have
       create privilege for the new tablespace. This command physically moves
       any tables or indexes in the database's old default tablespace to the
       new tablespace. The new default tablespace must be empty for this
       database, and no one can be connected to the database. Tables and
       indexes in non-default tablespaces are unaffected.

       The remaining forms change the session default for a run-time
       configuration variable for a PostgreSQL database. Whenever a new
       session is subsequently started in that database, the specified value
       becomes the session default value. The database-specific default
       overrides whatever setting is present in postgresql.conf or has been
       received from the postgres command line. Only the database owner or a
       superuser can change the session defaults for a database. Certain
       variables cannot be set this way, or can only be set by a superuser.

PARAMETERS
       name
           The name of the database whose attributes are to be altered.

       allowconn
           If false then no one can connect to this database.

       connlimit
           How many concurrent connections can be made to this database. -1
           means no limit.

       istemplate
           If true, then this database can be cloned by any user with CREATEDB
           privileges; if false, then only superusers or the owner of the
           database can clone it.

       new_name
           The new name of the database.

       new_owner
           The new owner of the database.

       new_tablespace
           The new default tablespace of the database.

<!-- 253cd41f-793d-492d-acb3-228e37ef29bb <=< ACCEPT -->       configuration_parameter
       value
           Set this database's session default for the specified configuration
           parameter to the given value. If value is DEFAULT or, equivalently,
           RESET is used, the database-specific setting is removed, so the
           system-wide default setting will be inherited in new sessions. Use
           RESET ALL to clear all database-specific settings.  SET FROM
           CURRENT saves the session's current value of the parameter as the
           database-specific value.<!-- ACCEPT >=> 253cd41f-793d-492d-acb3-228e37ef29bb -->

           See SET(7) and Chapter 19, Server Configuration, in the
           documentation for more information about allowed parameter names
           and values.

NOTES
       It is also possible to tie a session default to a specific role rather
       than to a database; see ALTER ROLE (ALTER_ROLE(7)). Role-specific
       settings override database-specific ones if there is a conflict.

EXAMPLES
       To disable index scans by default in the database test:

           ALTER DATABASE test SET enable_indexscan TO off;

COMPATIBILITY
       The ALTER DATABASE statement is a PostgreSQL extension.

SEE ALSO
       CREATE DATABASE (CREATE_DATABASE(7)), DROP DATABASE (DROP_DATABASE(7)),
       SET(7), CREATE TABLESPACE (CREATE_TABLESPACE(7))



PostgreSQL 9.6.1                     2016                    ALTER DATABASE(7)
DROP DATABASE(7)        PostgreSQL 9.6.1 Documentation        DROP DATABASE(7)



NAME
       DROP_DATABASE - remove a database

SYNOPSIS
       DROP DATABASE [ IF EXISTS ] name

DESCRIPTION
       DROP DATABASE drops a database. It removes the catalog entries for the
       database and deletes the directory containing the data. It can only be
       executed by the database owner. Also, it cannot be executed while you
       or anyone else are connected to the target database. (Connect to
       postgres or any other database to issue this command.)

       DROP DATABASE cannot be undone. Use it with care!

PARAMETERS
       IF EXISTS
           Do not throw an error if the database does not exist. A notice is
           issued in this case.

       name
           The name of the database to remove.

NOTES
       DROP DATABASE cannot be executed inside a transaction block.

       This command cannot be executed while connected to the target database.
       Thus, it might be more convenient to use the program dropdb(1) instead,
       which is a wrapper around this command.

COMPATIBILITY
       There is no DROP DATABASE statement in the SQL standard.

SEE ALSO
       CREATE DATABASE (CREATE_DATABASE(7))



PostgreSQL 9.6.1                     2016                     DROP DATABASE(7)
ALTER TRIGGER(7)        PostgreSQL 9.6.1 Documentation        ALTER TRIGGER(7)



NAME
       ALTER_TRIGGER - change the definition of a trigger

SYNOPSIS
       ALTER TRIGGER name ON table_name RENAME TO new_name
       ALTER TRIGGER name ON table_name DEPENDS ON EXTENSION extension_name

DESCRIPTION
       ALTER TRIGGER changes properties of an existing trigger. The RENAME
       clause changes the name of the given trigger without otherwise changing
       the trigger definition. The DEPENDS ON EXTENSION clause marks the
       trigger as dependent on an extension, such that if the extension is
       dropped, the trigger will automatically be dropped as well.

       You must own the table on which the trigger acts to be allowed to
       change its properties.

PARAMETERS
       name
           The name of an existing trigger to alter.

       table_name
           The name of the table on which this trigger acts.

       new_name
           The new name for the trigger.

       extension_name
           The name of the extension that the trigger is to depend on.

NOTES
       The ability to temporarily enable or disable a trigger is provided by
       ALTER TABLE (ALTER_TABLE(7)), not by ALTER TRIGGER, because ALTER
       TRIGGER has no convenient way to express the option of enabling or
       disabling all of a table's triggers at once.

EXAMPLES
       To rename an existing trigger:

           ALTER TRIGGER emp_stamp ON emp RENAME TO emp_track_chgs;

       To mark a trigger as being dependent on an extension:

           ALTER TRIGGER emp_stamp ON emp DEPENDS ON EXTENSION emplib;

COMPATIBILITY
       ALTER TRIGGER is a PostgreSQL extension of the SQL standard.

SEE ALSO
       ALTER TABLE (ALTER_TABLE(7))



PostgreSQL 9.6.1                     2016                     ALTER TRIGGER(7)
DROP FOREIGN DATA WRAPPEPostgreSQL 9.6.1 DocumentaDROP FOREIGN DATA WRAPPER(7)



NAME
       DROP_FOREIGN_DATA_WRAPPER - remove a foreign-data wrapper

SYNOPSIS
       DROP FOREIGN DATA WRAPPER [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP FOREIGN DATA WRAPPER removes an existing foreign-data wrapper. To
       execute this command, the current user must be the owner of the
       foreign-data wrapper.

PARAMETERS
       IF EXISTS
           Do not throw an error if the foreign-data wrapper does not exist. A
           notice is issued in this case.

       name
           The name of an existing foreign-data wrapper.

       CASCADE
           Automatically drop objects that depend on the foreign-data wrapper
           (such as foreign tables and servers), and in turn all objects that
           depend on those objects (see Section 5.13, "Dependency Tracking",
           in the documentation).

       RESTRICT
           Refuse to drop the foreign-data wrapper if any objects depend on
           it. This is the default.

EXAMPLES
       Drop the foreign-data wrapper dbi:

           DROP FOREIGN DATA WRAPPER dbi;

COMPATIBILITY
       DROP FOREIGN DATA WRAPPER conforms to ISO/IEC 9075-9 (SQL/MED). The IF
       EXISTS clause is a PostgreSQL extension.

SEE ALSO
       CREATE FOREIGN DATA WRAPPER (CREATE_FOREIGN_DATA_WRAPPER(7)), ALTER
       FOREIGN DATA WRAPPER (ALTER_FOREIGN_DATA_WRAPPER(7))



PostgreSQL 9.6.1                     2016         DROP FOREIGN DATA WRAPPER(7)
CREATE TEXT SEARCH TEMPLPostgreSQL 9.6.1 DocumenCREATE TEXT SEARCH TEMPLATE(7)



NAME
       CREATE_TEXT_SEARCH_TEMPLATE - define a new text search template

SYNOPSIS
       CREATE TEXT SEARCH TEMPLATE name (
           [ INIT = init_function , ]
           LEXIZE = lexize_function
       )

DESCRIPTION
       CREATE TEXT SEARCH TEMPLATE creates a new text search template. Text
       search templates define the functions that implement text search
       dictionaries. A template is not useful by itself, but must be
       instantiated as a dictionary to be used. The dictionary typically
       specifies parameters to be given to the template functions.

       If a schema name is given then the text search template is created in
       the specified schema. Otherwise it is created in the current schema.

       You must be a superuser to use CREATE TEXT SEARCH TEMPLATE. This
       restriction is made because an erroneous text search template
       definition could confuse or even crash the server. The reason for
       separating templates from dictionaries is that a template encapsulates
       the "unsafe" aspects of defining a dictionary. The parameters that can
       be set when defining a dictionary are safe for unprivileged users to
       set, and so creating a dictionary need not be a privileged operation.

       Refer to Chapter 12, Full Text Search, in the documentation for further
       information.

PARAMETERS
       name
           The name of the text search template to be created. The name can be
           schema-qualified.

       init_function
           The name of the init function for the template.

       lexize_function
           The name of the lexize function for the template.

       The function names can be schema-qualified if necessary. Argument types
       are not given, since the argument list for each type of function is
       predetermined. The lexize function is required, but the init function
       is optional.

       The arguments can appear in any order, not only the one shown above.

COMPATIBILITY
       There is no CREATE TEXT SEARCH TEMPLATE statement in the SQL standard.

SEE ALSO
       ALTER TEXT SEARCH TEMPLATE (ALTER_TEXT_SEARCH_TEMPLATE(7)), DROP TEXT
       SEARCH TEMPLATE (DROP_TEXT_SEARCH_TEMPLATE(7))



PostgreSQL 9.6.1                     2016       CREATE TEXT SEARCH TEMPLATE(7)
ALTER MATERIALIZED VIEW(PostgreSQL 9.6.1 DocumentatiALTER MATERIALIZED VIEW(7)



NAME
       ALTER_MATERIALIZED_VIEW - change the definition of a materialized view

SYNOPSIS
       ALTER MATERIALIZED VIEW [ IF EXISTS ] name
           action [, ... ]
       ALTER MATERIALIZED VIEW name
           DEPENDS ON EXTENSION extension_name
       ALTER MATERIALIZED VIEW [ IF EXISTS ] name
           RENAME [ COLUMN ] column_name TO new_column_name
       ALTER MATERIALIZED VIEW [ IF EXISTS ] name
           RENAME TO new_name
       ALTER MATERIALIZED VIEW [ IF EXISTS ] name
           SET SCHEMA new_schema
       ALTER MATERIALIZED VIEW ALL IN TABLESPACE name [ OWNED BY role_name [, ... ] ]
           SET TABLESPACE new_tablespace [ NOWAIT ]

       where action is one of:

           ALTER [ COLUMN ] column_name SET STATISTICS integer
           ALTER [ COLUMN ] column_name SET ( attribute_option = value [, ... ] )
           ALTER [ COLUMN ] column_name RESET ( attribute_option [, ... ] )
           ALTER [ COLUMN ] column_name SET STORAGE { PLAIN | EXTERNAL | EXTENDED | MAIN }
           CLUSTER ON index_name
           SET WITHOUT CLUSTER
           SET ( storage_parameter = value [, ... ] )
           RESET ( storage_parameter [, ... ] )
           OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
           SET TABLESPACE new_tablespace

DESCRIPTION
       ALTER MATERIALIZED VIEW changes various auxiliary properties of an
       existing materialized view.

<!-- ad137a5f-7fa1-4b53-a38d-4827f1ccde6e <=< ACCEPT -->       You must own the materialized view to use ALTER MATERIALIZED VIEW. To
       change a materialized view's schema, you must also have CREATE
       privilege on the new schema. To alter the owner, you must also be a
       direct or indirect member of the new owning role, and that role must
       have CREATE privilege on the materialized view's schema. (These
       restrictions enforce that altering the owner doesn't do anything you
       couldn't do by dropping and recreating the materialized view. However,
       a superuser can alter ownership of any view anyway.)<!-- ACCEPT >=> ad137a5f-7fa1-4b53-a38d-4827f1ccde6e -->

       The DEPENDS ON EXTENSION form marks the materialized view as dependent
       on an extension, such that the materialized view will automatically be
       dropped if the extension is dropped.

       The statement subforms and actions available for ALTER MATERIALIZED
       VIEW are a subset of those available for ALTER TABLE, and have the same
       meaning when used for materialized views. See the descriptions for
       ALTER TABLE (ALTER_TABLE(7)) for details.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing materialized
           view.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       column_name
           Name of a new or existing column.

       extension_name
           The name of the extension that the materialized view is to depend
           on.

       new_column_name
           New name for an existing column.

       new_owner
           The user name of the new owner of the materialized view.

       new_name
           The new name for the materialized view.

       new_schema
           The new schema for the materialized view.

EXAMPLES
       To rename the materialized view foo to bar:

           ALTER MATERIALIZED VIEW foo RENAME TO bar;

COMPATIBILITY
       ALTER MATERIALIZED VIEW is a PostgreSQL extension.

SEE ALSO
       CREATE MATERIALIZED VIEW (CREATE_MATERIALIZED_VIEW(7)), DROP
       MATERIALIZED VIEW (DROP_MATERIALIZED_VIEW(7)), REFRESH MATERIALIZED
       VIEW (REFRESH_MATERIALIZED_VIEW(7))



PostgreSQL 9.6.1                     2016           ALTER MATERIALIZED VIEW(7)
DROP FUNCTION(7)        PostgreSQL 9.6.1 Documentation        DROP FUNCTION(7)



NAME
       DROP_FUNCTION - remove a function

SYNOPSIS
       DROP FUNCTION [ IF EXISTS ] name ( [ [ argmode ] [ argname ] argtype [, ...] ] )
           [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP FUNCTION removes the definition of an existing function. To
       execute this command the user must be the owner of the function. The
       argument types to the function must be specified, since several
       different functions can exist with the same name and different argument
       lists.

PARAMETERS
       IF EXISTS
           Do not throw an error if the function does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing function.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

<!-- e966425d-370d-4dbd-b6cc-15b15457e983 <=< ACCEPT -->       argmode
           The mode of an argument: IN, OUT, INOUT, or VARIADIC. If omitted,
           the default is IN. Note that DROP FUNCTION does not actually pay
           any attention to OUT arguments, since only the input arguments are
           needed to determine the function's identity. So it is sufficient to
           list the IN, INOUT, and VARIADIC arguments.

       argname
           The name of an argument. Note that DROP FUNCTION does not actually
           pay any attention to argument names, since only the argument data
           types are needed to determine the function's identity.

       argtype
           The data type(s) of the function's arguments (optionally
           schema-qualified), if any.<!-- ACCEPT >=> e966425d-370d-4dbd-b6cc-15b15457e983 -->

       CASCADE
           Automatically drop objects that depend on the function (such as
           operators or triggers), and in turn all objects that depend on
           those objects (see Section 5.13, "Dependency Tracking", in the
           documentation).

       RESTRICT
           Refuse to drop the function if any objects depend on it. This is
           the default.

EXAMPLES
       This command removes the square root function:

           DROP FUNCTION sqrt(integer);

COMPATIBILITY
       A DROP FUNCTION statement is defined in the SQL standard, but it is not
       compatible with this command.

SEE ALSO
       CREATE FUNCTION (CREATE_FUNCTION(7)), ALTER FUNCTION
       (ALTER_FUNCTION(7))



PostgreSQL 9.6.1                     2016                     DROP FUNCTION(7)
DROP FOREIGN TABLE(7)   PostgreSQL 9.6.1 Documentation   DROP FOREIGN TABLE(7)



NAME
       DROP_FOREIGN_TABLE - remove a foreign table

SYNOPSIS
       DROP FOREIGN TABLE [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP FOREIGN TABLE removes a foreign table. Only the owner of a foreign
       table can remove it.

PARAMETERS
       IF EXISTS
           Do not throw an error if the foreign table does not exist. A notice
           is issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the foreign table to
           drop.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the foreign table (such
           as views), and in turn all objects that depend on those objects
           (see Section 5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the foreign table if any objects depend on it. This
           is the default.

EXAMPLES
       To destroy two foreign tables, films and distributors:

           DROP FOREIGN TABLE films, distributors;

COMPATIBILITY
       This command conforms to the ISO/IEC 9075-9 (SQL/MED), except that the
       standard only allows one foreign table to be dropped per command, and
       apart from the IF EXISTS option, which is a PostgreSQL extension.

SEE ALSO
       ALTER FOREIGN TABLE (ALTER_FOREIGN_TABLE(7)), CREATE FOREIGN TABLE
       (CREATE_FOREIGN_TABLE(7))



PostgreSQL 9.6.1                     2016                DROP FOREIGN TABLE(7)
ALTER LANGUAGE(7)       PostgreSQL 9.6.1 Documentation       ALTER LANGUAGE(7)



NAME
       ALTER_LANGUAGE - change the definition of a procedural language

SYNOPSIS
       ALTER [ PROCEDURAL ] LANGUAGE name RENAME TO new_name
       ALTER [ PROCEDURAL ] LANGUAGE name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }

DESCRIPTION
       ALTER LANGUAGE changes the definition of a procedural language. The
       only functionality is to rename the language or assign a new owner. You
       must be superuser or owner of the language to use ALTER LANGUAGE.

PARAMETERS
       name
           Name of a language

       new_name
           The new name of the language

       new_owner
           The new owner of the language

COMPATIBILITY
       There is no ALTER LANGUAGE statement in the SQL standard.

SEE ALSO
       CREATE LANGUAGE (CREATE_LANGUAGE(7)), DROP LANGUAGE (DROP_LANGUAGE(7))



PostgreSQL 9.6.1                     2016                    ALTER LANGUAGE(7)
DROP RULE(7)            PostgreSQL 9.6.1 Documentation            DROP RULE(7)



NAME
       DROP_RULE - remove a rewrite rule

SYNOPSIS
       DROP RULE [ IF EXISTS ] name ON table_name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP RULE drops a rewrite rule.

PARAMETERS
       IF EXISTS
           Do not throw an error if the rule does not exist. A notice is
           issued in this case.

       name
           The name of the rule to drop.

       table_name
           The name (optionally schema-qualified) of the table or view that
           the rule applies to.

       CASCADE
           Automatically drop objects that depend on the rule, and in turn all
           objects that depend on those objects (see Section 5.13, "Dependency
           Tracking", in the documentation).

       RESTRICT
           Refuse to drop the rule if any objects depend on it. This is the
           default.

EXAMPLES
       To drop the rewrite rule newrule:

           DROP RULE newrule ON mytable;

COMPATIBILITY
       DROP RULE is a PostgreSQL language extension, as is the entire query
       rewrite system.

SEE ALSO
       CREATE RULE (CREATE_RULE(7)), ALTER RULE (ALTER_RULE(7))



PostgreSQL 9.6.1                     2016                         DROP RULE(7)
ROLLBACK TO SAVEPOINT(7)PostgreSQL 9.6.1 DocumentationROLLBACK TO SAVEPOINT(7)



NAME
       ROLLBACK_TO_SAVEPOINT - roll back to a savepoint

SYNOPSIS
       ROLLBACK [ WORK | TRANSACTION ] TO [ SAVEPOINT ] savepoint_name

DESCRIPTION
       Roll back all commands that were executed after the savepoint was
       established. The savepoint remains valid and can be rolled back to
       again later, if needed.

       ROLLBACK TO SAVEPOINT implicitly destroys all savepoints that were
       established after the named savepoint.

PARAMETERS
       savepoint_name
           The savepoint to roll back to.

NOTES
       Use RELEASE SAVEPOINT (RELEASE_SAVEPOINT(7)) to destroy a savepoint
       without discarding the effects of commands executed after it was
       established.

       Specifying a savepoint name that has not been established is an error.

       Cursors have somewhat non-transactional behavior with respect to
       savepoints. Any cursor that is opened inside a savepoint will be closed
       when the savepoint is rolled back. If a previously opened cursor is
       affected by a FETCH or MOVE command inside a savepoint that is later
       rolled back, the cursor remains at the position that FETCH left it
       pointing to (that is, the cursor motion caused by FETCH is not rolled
       back). Closing a cursor is not undone by rolling back, either. However,
       other side-effects caused by the cursor's query (such as side-effects
       of volatile functions called by the query) are rolled back if they
       occur during a savepoint that is later rolled back. A cursor whose
       execution causes a transaction to abort is put in a cannot-execute
       state, so while the transaction can be restored using ROLLBACK TO
       SAVEPOINT, the cursor can no longer be used.

EXAMPLES
       To undo the effects of the commands executed after my_savepoint was
       established:

           ROLLBACK TO SAVEPOINT my_savepoint;

       Cursor positions are not affected by savepoint rollback:

           BEGIN;

           DECLARE foo CURSOR FOR SELECT 1 UNION SELECT 2;

           SAVEPOINT foo;

           FETCH 1 FROM foo;
            ?column?
           ----------
                   1

           ROLLBACK TO SAVEPOINT foo;

           FETCH 1 FROM foo;
            ?column?
           ----------
                   2

           COMMIT;

COMPATIBILITY
       The SQL standard specifies that the key word SAVEPOINT is mandatory,
       but PostgreSQL and Oracle allow it to be omitted. SQL allows only WORK,
       not TRANSACTION, as a noise word after ROLLBACK. Also, SQL has an
       optional clause AND [ NO ] CHAIN which is not currently supported by
       PostgreSQL. Otherwise, this command conforms to the SQL standard.

SEE ALSO
       BEGIN(7), COMMIT(7), RELEASE SAVEPOINT (RELEASE_SAVEPOINT(7)),
       ROLLBACK(7), SAVEPOINT(7)



PostgreSQL 9.6.1                     2016             ROLLBACK TO SAVEPOINT(7)
CREATE LANGUAGE(7)      PostgreSQL 9.6.1 Documentation      CREATE LANGUAGE(7)



NAME
       CREATE_LANGUAGE - define a new procedural language

SYNOPSIS
       CREATE [ OR REPLACE ] [ PROCEDURAL ] LANGUAGE name
       CREATE [ OR REPLACE ] [ TRUSTED ] [ PROCEDURAL ] LANGUAGE name
           HANDLER call_handler [ INLINE inline_handler ] [ VALIDATOR valfunction ]

DESCRIPTION
       CREATE LANGUAGE registers a new procedural language with a PostgreSQL
       database. Subsequently, functions and trigger procedures can be defined
       in this new language.

           Note
           As of PostgreSQL 9.1, most procedural languages have been made into
           "extensions", and should therefore be installed with CREATE
           EXTENSION (CREATE_EXTENSION(7)) not CREATE LANGUAGE. Direct use of
           CREATE LANGUAGE should now be confined to extension installation
           scripts. If you have a "bare" language in your database, perhaps as
           a result of an upgrade, you can convert it to an extension using
           CREATE EXTENSION langname FROM unpackaged.

       CREATE LANGUAGE effectively associates the language name with handler
       function(s) that are responsible for executing functions written in the
       language. Refer to Chapter 54, Writing A Procedural Language Handler,
       in the documentation for more information about language handlers.

       There are two forms of the CREATE LANGUAGE command. In the first form,
       the user supplies just the name of the desired language, and the
       PostgreSQL server consults the pg_pltemplate system catalog to
       determine the correct parameters. In the second form, the user supplies
       the language parameters along with the language name. The second form
       can be used to create a language that is not defined in pg_pltemplate,
       but this approach is considered obsolescent.

       When the server finds an entry in the pg_pltemplate catalog for the
       given language name, it will use the catalog data even if the command
       includes language parameters. This behavior simplifies loading of old
       dump files, which are likely to contain out-of-date information about
       language support functions.

       Ordinarily, the user must have the PostgreSQL superuser privilege to
       register a new language. However, the owner of a database can register
       a new language within that database if the language is listed in the
       pg_pltemplate catalog and is marked as allowed to be created by
       database owners (tmpldbacreate is true). The default is that trusted
       languages can be created by database owners, but this can be adjusted
       by superusers by modifying the contents of pg_pltemplate. The creator
       of a language becomes its owner and can later drop it, rename it, or
       assign it to a new owner.

       CREATE OR REPLACE LANGUAGE will either create a new language, or
       replace an existing definition. If the language already exists, its
       parameters are updated according to the values specified or taken from
       pg_pltemplate, but the language's ownership and permissions settings do
       not change, and any existing functions written in the language are
       assumed to still be valid. In addition to the normal privilege
       requirements for creating a language, the user must be superuser or
       owner of the existing language. The REPLACE case is mainly meant to be
       used to ensure that the language exists. If the language has a
       pg_pltemplate entry then REPLACE will not actually change anything
       about an existing definition, except in the unusual case where the
       pg_pltemplate entry has been modified since the language was created.

PARAMETERS
       TRUSTED
           TRUSTED specifies that the language does not grant access to data
           that the user would not otherwise have. If this key word is omitted
           when registering the language, only users with the PostgreSQL
           superuser privilege can use this language to create new functions.

       PROCEDURAL
           This is a noise word.

       name
           The name of the new procedural language. The name must be unique
           among the languages in the database.

           For backward compatibility, the name can be enclosed by single
           quotes.

       HANDLER call_handler
           call_handler is the name of a previously registered function that
           will be called to execute the procedural language's functions. The
           call handler for a procedural language must be written in a
           compiled language such as C with version 1 call convention and
           registered with PostgreSQL as a function taking no arguments and
           returning the language_handler type, a placeholder type that is
           simply used to identify the function as a call handler.

       INLINE inline_handler
           inline_handler is the name of a previously registered function that
           will be called to execute an anonymous code block (DO(7) command)
           in this language. If no inline_handler function is specified, the
           language does not support anonymous code blocks. The handler
           function must take one argument of type internal, which will be the
           DO command's internal representation, and it will typically return
           void. The return value of the handler is ignored.

       VALIDATOR valfunction
           valfunction is the name of a previously registered function that
           will be called when a new function in the language is created, to
           validate the new function. If no validator function is specified,
           then a new function will not be checked when it is created. The
           validator function must take one argument of type oid, which will
           be the OID of the to-be-created function, and will typically return
           void.

           A validator function would typically inspect the function body for
           syntactical correctness, but it can also look at other properties
           of the function, for example if the language cannot handle certain
           argument types. To signal an error, the validator function should
           use the ereport() function. The return value of the function is
           ignored.

       The TRUSTED option and the support function name(s) are ignored if the
       server has an entry for the specified language name in pg_pltemplate.

NOTES
       The createlang(1) program is a simple wrapper around the CREATE
       LANGUAGE command. It eases installation of procedural languages from
       the shell command line.

       Use DROP LANGUAGE (DROP_LANGUAGE(7)), or better yet the droplang(1)
       program, to drop procedural languages.

       The system catalog pg_language (see Section 50.29, "pg_language", in
       the documentation) records information about the currently installed
       languages. Also, createlang has an option to list the installed
       languages.

       To create functions in a procedural language, a user must have the
       USAGE privilege for the language. By default, USAGE is granted to
       PUBLIC (i.e., everyone) for trusted languages. This can be revoked if
       desired.

       Procedural languages are local to individual databases. However, a
       language can be installed into the template1 database, which will cause
       it to be available automatically in all subsequently-created databases.

       The call handler function, the inline handler function (if any), and
       the validator function (if any) must already exist if the server does
       not have an entry for the language in pg_pltemplate. But when there is
       an entry, the functions need not already exist; they will be
       automatically defined if not present in the database. (This might
       result in CREATE LANGUAGE failing, if the shared library that
       implements the language is not available in the installation.)

       In PostgreSQL versions before 7.3, it was necessary to declare handler
       functions as returning the placeholder type opaque, rather than
       language_handler. To support loading of old dump files, CREATE LANGUAGE
       will accept a function declared as returning opaque, but it will issue
       a notice and change the function's declared return type to
       language_handler.

EXAMPLES
       The preferred way of creating any of the standard procedural languages
       is just:

           CREATE LANGUAGE plperl;

       For a language not known in the pg_pltemplate catalog, a sequence such
       as this is needed:

           CREATE FUNCTION plsample_call_handler() RETURNS language_handler
               AS '$libdir/plsample'
               LANGUAGE C;
           CREATE LANGUAGE plsample
               HANDLER plsample_call_handler;

COMPATIBILITY
       CREATE LANGUAGE is a PostgreSQL extension.

SEE ALSO
       ALTER LANGUAGE (ALTER_LANGUAGE(7)), CREATE FUNCTION
       (CREATE_FUNCTION(7)), DROP LANGUAGE (DROP_LANGUAGE(7)), GRANT(7),
       REVOKE(7), createlang(1), droplang(1)



PostgreSQL 9.6.1                     2016                   CREATE LANGUAGE(7)
CREATE FUNCTION(7)      PostgreSQL 9.6.1 Documentation      CREATE FUNCTION(7)



NAME
       CREATE_FUNCTION - define a new function

SYNOPSIS
       CREATE [ OR REPLACE ] FUNCTION
           name ( [ [ argmode ] [ argname ] argtype [ { DEFAULT | = } default_expr ] [, ...] ] )
           [ RETURNS rettype
             | RETURNS TABLE ( column_name column_type [, ...] ) ]
         { LANGUAGE lang_name
           | TRANSFORM { FOR TYPE type_name } [, ... ]
           | WINDOW
           | IMMUTABLE | STABLE | VOLATILE | [ NOT ] LEAKPROOF
           | CALLED ON NULL INPUT | RETURNS NULL ON NULL INPUT | STRICT
           | [ EXTERNAL ] SECURITY INVOKER | [ EXTERNAL ] SECURITY DEFINER
           | PARALLEL { UNSAFE | RESTRICTED | SAFE }
           | COST execution_cost
           | ROWS result_rows
           | SET configuration_parameter { TO value | = value | FROM CURRENT }
           | AS 'definition'
           | AS 'obj_file', 'link_symbol'
         } ...
           [ WITH ( attribute [, ...] ) ]

DESCRIPTION
       CREATE FUNCTION defines a new function.  CREATE OR REPLACE FUNCTION
       will either create a new function, or replace an existing definition.
       To be able to define a function, the user must have the USAGE privilege
       on the language.

       If a schema name is included, then the function is created in the
       specified schema. Otherwise it is created in the current schema. The
       name of the new function must not match any existing function with the
       same input argument types in the same schema. However, functions of
       different argument types can share a name (this is called overloading).

       To replace the current definition of an existing function, use CREATE
       OR REPLACE FUNCTION. It is not possible to change the name or argument
       types of a function this way (if you tried, you would actually be
       creating a new, distinct function). Also, CREATE OR REPLACE FUNCTION
       will not let you change the return type of an existing function. To do
       that, you must drop and recreate the function. (When using OUT
       parameters, that means you cannot change the types of any OUT
       parameters except by dropping the function.)

       When CREATE OR REPLACE FUNCTION is used to replace an existing
       function, the ownership and permissions of the function do not change.
       All other function properties are assigned the values specified or
       implied in the command. You must own the function to replace it (this
       includes being a member of the owning role).

       If you drop and then recreate a function, the new function is not the
       same entity as the old; you will have to drop existing rules, views,
       triggers, etc. that refer to the old function. Use CREATE OR REPLACE
       FUNCTION to change a function definition without breaking objects that
       refer to the function. Also, ALTER FUNCTION can be used to change most
       of the auxiliary properties of an existing function.

       The user that creates the function becomes the owner of the function.

       To be able to create a function, you must have USAGE privilege on the
       argument types and the return type.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the function to create.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       argmode
           The mode of an argument: IN, OUT, INOUT, or VARIADIC. If omitted,
           the default is IN. Only OUT arguments can follow a VARIADIC one.
           Also, OUT and INOUT arguments cannot be used together with the
           RETURNS TABLE notation.

       argname
           The name of an argument. Some languages (including SQL and
           PL/pgSQL) let you use the name in the function body. For other
           languages the name of an input argument is just extra
           documentation, so far as the function itself is concerned; but you
           can use input argument names when calling a function to improve
           readability (see Section 4.3, "Calling Functions", in the
           documentation). In any case, the name of an output argument is
           significant, because it defines the column name in the result row
           type. (If you omit the name for an output argument, the system will
           choose a default column name.)

       argtype
           The data type(s) of the function's arguments (optionally
           schema-qualified), if any. The argument types can be base,
           composite, or domain types, or can reference the type of a table
           column.

           Depending on the implementation language it might also be allowed
           to specify "pseudotypes" such as cstring. Pseudotypes indicate that
           the actual argument type is either incompletely specified, or
           outside the set of ordinary SQL data types.

           The type of a column is referenced by writing
           table_name.column_name%TYPE. Using this feature can sometimes help
           make a function independent of changes to the definition of a
           table.

       default_expr
           An expression to be used as default value if the parameter is not
           specified. The expression has to be coercible to the argument type
           of the parameter. Only input (including INOUT) parameters can have
           a default value. All input parameters following a parameter with a
           default value must have default values as well.

       rettype
           The return data type (optionally schema-qualified). The return type
           can be a base, composite, or domain type, or can reference the type
           of a table column. Depending on the implementation language it
           might also be allowed to specify "pseudotypes" such as cstring. If
           the function is not supposed to return a value, specify void as the
           return type.

           When there are OUT or INOUT parameters, the RETURNS clause can be
           omitted. If present, it must agree with the result type implied by
           the output parameters: RECORD if there are multiple output
           parameters, or the same type as the single output parameter.

           The SETOF modifier indicates that the function will return a set of
           items, rather than a single item.

           The type of a column is referenced by writing
           table_name.column_name%TYPE.

       column_name
           The name of an output column in the RETURNS TABLE syntax. This is
           effectively another way of declaring a named OUT parameter, except
           that RETURNS TABLE also implies RETURNS SETOF.

       column_type
           The data type of an output column in the RETURNS TABLE syntax.

       lang_name
           The name of the language that the function is implemented in. It
           can be sql, c, internal, or the name of a user-defined procedural
           language, e.g.  plpgsql. Enclosing the name in single quotes is
           deprecated and requires matching case.

       TRANSFORM { FOR TYPE type_name } [, ... ] }
           Lists which transforms a call to the function should apply.
           Transforms convert between SQL types and language-specific data
           types; see CREATE TRANSFORM (CREATE_TRANSFORM(7)). Procedural
           language implementations usually have hardcoded knowledge of the
           built-in types, so those don't need to be listed here. If a
           procedural language implementation does not know how to handle a
           type and no transform is supplied, it will fall back to a default
           behavior for converting data types, but this depends on the
           implementation.

       WINDOW
           WINDOW indicates that the function is a window function rather than
           a plain function. This is currently only useful for functions
           written in C. The WINDOW attribute cannot be changed when replacing
           an existing function definition.

       IMMUTABLE
       STABLE
       VOLATILE
           These attributes inform the query optimizer about the behavior of
           the function. At most one choice can be specified. If none of these
           appear, VOLATILE is the default assumption.

           IMMUTABLE indicates that the function cannot modify the database
           and always returns the same result when given the same argument
           values; that is, it does not do database lookups or otherwise use
           information not directly present in its argument list. If this
           option is given, any call of the function with all-constant
           arguments can be immediately replaced with the function value.

           STABLE indicates that the function cannot modify the database, and
           that within a single table scan it will consistently return the
           same result for the same argument values, but that its result could
           change across SQL statements. This is the appropriate selection for
           functions whose results depend on database lookups, parameter
           variables (such as the current time zone), etc. (It is
           inappropriate for AFTER triggers that wish to query rows modified
           by the current command.) Also note that the current_timestamp
           family of functions qualify as stable, since their values do not
           change within a transaction.

           VOLATILE indicates that the function value can change even within a
           single table scan, so no optimizations can be made. Relatively few
           database functions are volatile in this sense; some examples are
           random(), currval(), timeofday(). But note that any function that
           has side-effects must be classified volatile, even if its result is
           quite predictable, to prevent calls from being optimized away; an
           example is setval().

           For additional details see Section 36.6, "Function Volatility
           Categories", in the documentation.

       LEAKPROOF
           LEAKPROOF indicates that the function has no side effects. It
           reveals no information about its arguments other than by its return
           value. For example, a function which throws an error message for
           some argument values but not others, or which includes the argument
           values in any error message, is not leakproof. This affects how the
           system executes queries against views created with the
           security_barrier option or tables with row level security enabled.
           The system will enforce conditions from security policies and
           security barrier views before any user-supplied conditions from the
           query itself that contain non-leakproof functions, in order to
           prevent the inadvertent exposure of data. Functions and operators
           marked as leakproof are assumed to be trustworthy, and may be
           executed before conditions from security policies and security
           barrier views. In addition, functions which do not take arguments
           or which are not passed any arguments from the security barrier
           view or table do not have to be marked as leakproof to be executed
           before security conditions. See CREATE VIEW (CREATE_VIEW(7)) and
           Section 39.5, "Rules and Privileges", in the documentation. This
           option can only be set by the superuser.

       CALLED ON NULL INPUT
       RETURNS NULL ON NULL INPUT
       STRICT
           CALLED ON NULL INPUT (the default) indicates that the function will
           be called normally when some of its arguments are null. It is then
           the function author's responsibility to check for null values if
           necessary and respond appropriately.

           RETURNS NULL ON NULL INPUT or STRICT indicates that the function
           always returns null whenever any of its arguments are null. If this
           parameter is specified, the function is not executed when there are
           null arguments; instead a null result is assumed automatically.

       [EXTERNAL] SECURITY INVOKER
       [EXTERNAL] SECURITY DEFINER
           SECURITY INVOKER indicates that the function is to be executed with
           the privileges of the user that calls it. That is the default.
           SECURITY DEFINER specifies that the function is to be executed with
           the privileges of the user that created it.

           The key word EXTERNAL is allowed for SQL conformance, but it is
           optional since, unlike in SQL, this feature applies to all
           functions not only external ones.

       PARALLEL
           PARALLEL UNSAFE indicates that the function can't be executed in
           parallel mode and the presence of such a function in an SQL
           statement forces a serial execution plan. This is the default.
           PARALLEL RESTRICTED indicates that the function can be executed in
           parallel mode, but the execution is restricted to parallel group
           leader.  PARALLEL SAFE indicates that the function is safe to run
           in parallel mode without restriction.

           Functions should be labeled parallel unsafe if they modify any
           database state, or if they make changes to the transaction such as
           using sub-transactions, or if they access sequences or attempt to
           make persistent changes to settings (e.g.  setval). They should be
           labeled as parallel restricted if they access temporary tables,
           client connection state, cursors, prepared statements, or
           miscellaneous backend-local state which the system cannot
           synchronize in parallel mode (e.g.  setseed cannot be executed
           other than by the group leader because a change made by another
           process would not be reflected in the leader). In general, if a
           function is labeled as being safe when it is restricted or unsafe,
           or if it is labeled as being restricted when it is in fact unsafe,
           it may throw errors or produce wrong answers when used in a
           parallel query. C-language functions could in theory exhibit
           totally undefined behavior if mislabeled, since there is no way for
           the system to protect itself against arbitrary C code, but in most
           likely cases the result will be no worse than for any other
           function. If in doubt, functions should be labeled as UNSAFE, which
           is the default.

       execution_cost
           A positive number giving the estimated execution cost for the
           function, in units of cpu_operator_cost. If the function returns a
           set, this is the cost per returned row. If the cost is not
           specified, 1 unit is assumed for C-language and internal functions,
           and 100 units for functions in all other languages. Larger values
           cause the planner to try to avoid evaluating the function more
           often than necessary.

       result_rows
           A positive number giving the estimated number of rows that the
           planner should expect the function to return. This is only allowed
           when the function is declared to return a set. The default
           assumption is 1000 rows.

       configuration_parameter
       value
           The SET clause causes the specified configuration parameter to be
           set to the specified value when the function is entered, and then
           restored to its prior value when the function exits.  SET FROM
           CURRENT saves the value of the parameter that is current when
           CREATE FUNCTION is executed as the value to be applied when the
           function is entered.

           If a SET clause is attached to a function, then the effects of a
           SET LOCAL command executed inside the function for the same
           variable are restricted to the function: the configuration
           parameter's prior value is still restored at function exit.
           However, an ordinary SET command (without LOCAL) overrides the SET
           clause, much as it would do for a previous SET LOCAL command: the
           effects of such a command will persist after function exit, unless
           the current transaction is rolled back.

           See SET(7) and Chapter 19, Server Configuration, in the
           documentation for more information about allowed parameter names
           and values.

       definition
           A string constant defining the function; the meaning depends on the
           language. It can be an internal function name, the path to an
           object file, an SQL command, or text in a procedural language.

           It is often helpful to use dollar quoting (see Section 4.1.2.4,
           "Dollar-quoted String Constants", in the documentation) to write
           the function definition string, rather than the normal single quote
           syntax. Without dollar quoting, any single quotes or backslashes in
           the function definition must be escaped by doubling them.

       obj_file, link_symbol
           This form of the AS clause is used for dynamically loadable C
           language functions when the function name in the C language source
           code is not the same as the name of the SQL function. The string
           obj_file is the name of the file containing the dynamically
           loadable object, and link_symbol is the function's link symbol,
           that is, the name of the function in the C language source code. If
           the link symbol is omitted, it is assumed to be the same as the
           name of the SQL function being defined.

           When repeated CREATE FUNCTION calls refer to the same object file,
           the file is only loaded once per session. To unload and reload the
           file (perhaps during development), start a new session.

       attribute
           The historical way to specify optional pieces of information about
           the function. The following attributes can appear here:

           isStrict
               Equivalent to STRICT or RETURNS NULL ON NULL INPUT.

           isCachable
               isCachable is an obsolete equivalent of IMMUTABLE; it's still
               accepted for backwards-compatibility reasons.

           Attribute names are not case-sensitive.

       Refer to Section 36.3, "User-defined Functions", in the documentation
       for further information on writing functions.

OVERLOADING
       PostgreSQL allows function overloading; that is, the same name can be
       used for several different functions so long as they have distinct
       input argument types. However, the C names of all functions must be
       different, so you must give overloaded C functions different C names
       (for example, use the argument types as part of the C names).

       Two functions are considered the same if they have the same names and
       input argument types, ignoring any OUT parameters. Thus for example
       these declarations conflict:

           CREATE FUNCTION foo(int) ...
           CREATE FUNCTION foo(int, out text) ...

       Functions that have different argument type lists will not be
       considered to conflict at creation time, but if defaults are provided
       they might conflict in use. For example, consider

           CREATE FUNCTION foo(int) ...
           CREATE FUNCTION foo(int, int default 42) ...

       A call foo(10) will fail due to the ambiguity about which function
       should be called.

NOTES
       The full SQL type syntax is allowed for declaring a function's
       arguments and return value. However, parenthesized type modifiers
       (e.g., the precision field for type numeric) are discarded by CREATE
       FUNCTION. Thus for example CREATE FUNCTION foo (varchar(10)) ...  is
       exactly the same as CREATE FUNCTION foo (varchar) ....

       When replacing an existing function with CREATE OR REPLACE FUNCTION,
       there are restrictions on changing parameter names. You cannot change
       the name already assigned to any input parameter (although you can add
       names to parameters that had none before). If there is more than one
       output parameter, you cannot change the names of the output parameters,
       because that would change the column names of the anonymous composite
       type that describes the function's result. These restrictions are made
       to ensure that existing calls of the function do not stop working when
       it is replaced.

       If a function is declared STRICT with a VARIADIC argument, the
       strictness check tests that the variadic array as a whole is non-null.
       The function will still be called if the array has null elements.

EXAMPLES
       Here are some trivial examples to help you get started. For more
       information and examples, see Section 36.3, "User-defined Functions",
       in the documentation.

           CREATE FUNCTION add(integer, integer) RETURNS integer
               AS 'select $1 + $2;'
               LANGUAGE SQL
               IMMUTABLE
               RETURNS NULL ON NULL INPUT;

       Increment an integer, making use of an argument name, in PL/pgSQL:

           CREATE OR REPLACE FUNCTION increment(i integer) RETURNS integer AS $$
                   BEGIN
                           RETURN i + 1;
                   END;
           $$ LANGUAGE plpgsql;

       Return a record containing multiple output parameters:

           CREATE FUNCTION dup(in int, out f1 int, out f2 text)
               AS $$ SELECT $1, CAST($1 AS text) || ' is text' $$
               LANGUAGE SQL;

           SELECT * FROM dup(42);

       You can do the same thing more verbosely with an explicitly named
       composite type:

           CREATE TYPE dup_result AS (f1 int, f2 text);

           CREATE FUNCTION dup(int) RETURNS dup_result
               AS $$ SELECT $1, CAST($1 AS text) || ' is text' $$
               LANGUAGE SQL;

           SELECT * FROM dup(42);

       Another way to return multiple columns is to use a TABLE function:

           CREATE FUNCTION dup(int) RETURNS TABLE(f1 int, f2 text)
               AS $$ SELECT $1, CAST($1 AS text) || ' is text' $$
               LANGUAGE SQL;

           SELECT * FROM dup(42);

       However, a TABLE function is different from the preceding examples,
       because it actually returns a set of records, not just one record.

WRITING SECURITY DEFINER FUNCTIONS SAFELY
       Because a SECURITY DEFINER function is executed with the privileges of
       the user that created it, care is needed to ensure that the function
       cannot be misused. For security, search_path should be set to exclude
       any schemas writable by untrusted users. This prevents malicious users
       from creating objects (e.g., tables, functions, and operators) that
       mask objects intended to be used by the function. Particularly
       important in this regard is the temporary-table schema, which is
       searched first by default, and is normally writable by anyone. A secure
       arrangement can be obtained by forcing the temporary schema to be
       searched last. To do this, write pg_temp as the last entry in
       search_path. This function illustrates safe usage:

           CREATE FUNCTION check_password(uname TEXT, pass TEXT)
           RETURNS BOOLEAN AS $$
           DECLARE passed BOOLEAN;
           BEGIN
                   SELECT  (pwd = $2) INTO passed
                   FROM    pwds
                   WHERE   username = $1;

                   RETURN passed;
           END;
           $$  LANGUAGE plpgsql
               SECURITY DEFINER
               -- Set a secure search_path: trusted schema(s), then 'pg_temp'.
               SET search_path = admin, pg_temp;

       This function's intention is to access a table admin.pwds. But without
       the SET clause, or with a SET clause mentioning only admin, the
       function could be subverted by creating a temporary table named pwds.

       Before PostgreSQL version 8.3, the SET clause was not available, and so
       older functions may contain rather complicated logic to save, set, and
       restore search_path. The SET clause is far easier to use for this
       purpose.

       Another point to keep in mind is that by default, execute privilege is
       granted to PUBLIC for newly created functions (see GRANT(7) for more
       information). Frequently you will wish to restrict use of a security
       definer function to only some users. To do that, you must revoke the
       default PUBLIC privileges and then grant execute privilege selectively.
       To avoid having a window where the new function is accessible to all,
       create it and set the privileges within a single transaction. For
       example:

           BEGIN;
           CREATE FUNCTION check_password(uname TEXT, pass TEXT) ... SECURITY DEFINER;
           REVOKE ALL ON FUNCTION check_password(uname TEXT, pass TEXT) FROM PUBLIC;
           GRANT EXECUTE ON FUNCTION check_password(uname TEXT, pass TEXT) TO admins;
           COMMIT;

COMPATIBILITY
       A CREATE FUNCTION command is defined in SQL:1999 and later. The
       PostgreSQL version is similar but not fully compatible. The attributes
       are not portable, neither are the different available languages.

       For compatibility with some other database systems, argmode can be
       written either before or after argname. But only the first way is
       standard-compliant.

       For parameter defaults, the SQL standard specifies only the syntax with
       the DEFAULT key word. The syntax with = is used in T-SQL and Firebird.

SEE ALSO
       ALTER FUNCTION (ALTER_FUNCTION(7)), DROP FUNCTION (DROP_FUNCTION(7)),
       GRANT(7), LOAD(7), REVOKE(7), createlang(1)



PostgreSQL 9.6.1                     2016                   CREATE FUNCTION(7)
DROP TRANSFORM(7)       PostgreSQL 9.6.1 Documentation       DROP TRANSFORM(7)



NAME
       DROP_TRANSFORM - remove a transform

SYNOPSIS
       DROP TRANSFORM [ IF EXISTS ] FOR type_name LANGUAGE lang_name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP TRANSFORM removes a previously defined transform.

       To be able to drop a transform, you must own the type and the language.
       These are the same privileges that are required to create a transform.

PARAMETERS
       IF EXISTS
           Do not throw an error if the transform does not exist. A notice is
           issued in this case.

       type_name
           The name of the data type of the transform.

       lang_name
           The name of the language of the transform.

       CASCADE
           Automatically drop objects that depend on the transform, and in
           turn all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the transform if any objects depend on it. This is
           the default.

EXAMPLES
       To drop the transform for type hstore and language plpythonu:

           DROP TRANSFORM FOR hstore LANGUAGE plpythonu;

COMPATIBILITY
       This form of DROP TRANSFORM is a PostgreSQL extension. See CREATE
       TRANSFORM (CREATE_TRANSFORM(7)) for details.

SEE ALSO
       CREATE TRANSFORM (CREATE_TRANSFORM(7))



PostgreSQL 9.6.1                     2016                    DROP TRANSFORM(7)
CREATE OPERATOR CLASS(7)PostgreSQL 9.6.1 DocumentationCREATE OPERATOR CLASS(7)



NAME
       CREATE_OPERATOR_CLASS - define a new operator class

SYNOPSIS
       CREATE OPERATOR CLASS name [ DEFAULT ] FOR TYPE data_type
         USING index_method [ FAMILY family_name ] AS
         {  OPERATOR strategy_number operator_name [ ( op_type, op_type ) ] [ FOR SEARCH | FOR ORDER BY sort_family_name ]
          | FUNCTION support_number [ ( op_type [ , op_type ] ) ] function_name ( argument_type [, ...] )
          | STORAGE storage_type
         } [, ... ]

DESCRIPTION
       CREATE OPERATOR CLASS creates a new operator class. An operator class
       defines how a particular data type can be used with an index. The
       operator class specifies that certain operators will fill particular
       roles or "strategies" for this data type and this index method. The
       operator class also specifies the support procedures to be used by the
       index method when the operator class is selected for an index column.
       All the operators and functions used by an operator class must be
       defined before the operator class can be created.

       If a schema name is given then the operator class is created in the
       specified schema. Otherwise it is created in the current schema. Two
       operator classes in the same schema can have the same name only if they
       are for different index methods.

       The user who defines an operator class becomes its owner. Presently,
       the creating user must be a superuser. (This restriction is made
       because an erroneous operator class definition could confuse or even
       crash the server.)

       CREATE OPERATOR CLASS does not presently check whether the operator
       class definition includes all the operators and functions required by
       the index method, nor whether the operators and functions form a
       self-consistent set. It is the user's responsibility to define a valid
       operator class.

       Related operator classes can be grouped into operator families. To add
       a new operator class to an existing family, specify the FAMILY option
       in CREATE OPERATOR CLASS. Without this option, the new class is placed
       into a family named the same as the new class (creating that family if
       it doesn't already exist).

       Refer to Section 36.14, "Interfacing Extensions To Indexes", in the
       documentation for further information.

PARAMETERS
       name
           The name of the operator class to be created. The name can be
           schema-qualified.

       DEFAULT
           If present, the operator class will become the default operator
           class for its data type. At most one operator class can be the
           default for a specific data type and index method.

       data_type
           The column data type that this operator class is for.

       index_method
           The name of the index method this operator class is for.

       family_name
           The name of the existing operator family to add this operator class
           to. If not specified, a family named the same as the operator class
           is used (creating it, if it doesn't already exist).

<!-- 28d4dc75-98b1-41fd-b697-d30923dc9e5c <=< ACCEPT -->       strategy_number
           The index method's strategy number for an operator associated with
           the operator class.

       operator_name
           The name (optionally schema-qualified) of an operator associated
           with the operator class.

       op_type
           In an OPERATOR clause, the operand data type(s) of the operator, or
           NONE to signify a left-unary or right-unary operator. The operand
           data types can be omitted in the normal case where they are the
           same as the operator class's data type.

           In a FUNCTION clause, the operand data type(s) the function is
           intended to support, if different from the input data type(s) of
           the function<!-- ACCEPT >=> 28d4dc75-98b1-41fd-b697-d30923dc9e5c --> (for B-tree comparison functions and hash functions)
           or the class's data type (for B-tree sort support functions and all
           functions in GiST, SP-GiST, GIN and BRIN operator classes). These
           defaults are correct, and so op_type need not be specified in
           FUNCTION clauses, except for the case of a B-tree sort support
           function that is meant to support cross-data-type comparisons.

<!-- 9c2021b2-ea26-4764-9eb3-17e12de3ff8f <=< ACCEPT -->       sort_family_name
           The name (optionally schema-qualified) of an existing btree
           operator family that describes the sort ordering associated with an
           ordering operator.

           If neither FOR SEARCH nor FOR ORDER BY is specified, FOR SEARCH is
           the default.

       support_number
           The index method's support procedure number for a function
           associated with the operator class.

       function_name
           The name (optionally schema-qualified) of a function that is an
           index method support procedure for the operator class.

       argument_type
           The parameter data type(s) of the function.<!-- ACCEPT >=> 9c2021b2-ea26-4764-9eb3-17e12de3ff8f -->

       storage_type
           The data type actually stored in the index. Normally this is the
           same as the column data type, but some index methods (currently
           GiST, GIN and BRIN) allow it to be different. The STORAGE clause
           must be omitted unless the index method allows a different type to
           be used.

       The OPERATOR, FUNCTION, and STORAGE clauses can appear in any order.

NOTES
<!-- 09520cdb-499e-46bf-946d-3cfcacaa96e0 <=< ACCEPT -->       Because the index machinery does not check access permissions on
       functions before using them, including a function or operator in an
       operator class is tantamount to granting public execute permission on
       it. This is usually not an issue for the sorts of functions that are
       useful in an operator class.

       The operators should not be defined by SQL functions. A SQL function is
       likely to be inlined into the calling query, which will prevent the
       optimizer from recognizing that the query matches an index.

       Before PostgreSQL 8.4, the OPERATOR clause could include a RECHECK
       option. This is no longer supported because whether an index operator
       is "lossy" is now determined on-the-fly at run time. This allows
       efficient handling of cases where an operator might or might not be
       lossy.<!-- ACCEPT >=> 09520cdb-499e-46bf-946d-3cfcacaa96e0 -->

EXAMPLES
       The following example command defines a GiST index operator class for
       the data type _int4 (array of int4). See the intarray module for the
       complete example.

           CREATE OPERATOR CLASS gist__int_ops
               DEFAULT FOR TYPE _int4 USING gist AS
                   OPERATOR        3       &amp;&amp;,
                   OPERATOR        6       = (anyarray, anyarray),
                   OPERATOR        7       @&amp;gt;,
                   OPERATOR        8       &amp;lt;@,
                   OPERATOR        20      @@ (_int4, query_int),
                   FUNCTION        1       g_int_consistent (internal, _int4, smallint, oid, internal),
                   FUNCTION        2       g_int_union (internal, internal),
                   FUNCTION        3       g_int_compress (internal),
                   FUNCTION        4       g_int_decompress (internal),
                   FUNCTION        5       g_int_penalty (internal, internal, internal),
                   FUNCTION        6       g_int_picksplit (internal, internal),
                   FUNCTION        7       g_int_same (_int4, _int4, internal);

COMPATIBILITY
       CREATE OPERATOR CLASS is a PostgreSQL extension. There is no CREATE
       OPERATOR CLASS statement in the SQL standard.

SEE ALSO
       ALTER OPERATOR CLASS (ALTER_OPERATOR_CLASS(7)), DROP OPERATOR CLASS
       (DROP_OPERATOR_CLASS(7)), CREATE OPERATOR FAMILY
       (CREATE_OPERATOR_FAMILY(7)), ALTER OPERATOR FAMILY
       (ALTER_OPERATOR_FAMILY(7))



PostgreSQL 9.6.1                     2016             CREATE OPERATOR CLASS(7)
DROP ROLE(7)            PostgreSQL 9.6.1 Documentation            DROP ROLE(7)



NAME
       DROP_ROLE - remove a database role

SYNOPSIS
       DROP ROLE [ IF EXISTS ] name [, ...]

DESCRIPTION
       DROP ROLE removes the specified role(s). To drop a superuser role, you
       must be a superuser yourself; to drop non-superuser roles, you must
       have CREATEROLE privilege.

       A role cannot be removed if it is still referenced in any database of
       the cluster; an error will be raised if so. Before dropping the role,
       you must drop all the objects it owns (or reassign their ownership) and
       revoke any privileges the role has been granted on other objects. The
       REASSIGN OWNED (REASSIGN_OWNED(7)) and DROP OWNED (DROP_OWNED(7))
       commands can be useful for this purpose; see Section 21.4, "Dropping
       Roles", in the documentation for more discussion.

       However, it is not necessary to remove role memberships involving the
       role; DROP ROLE automatically revokes any memberships of the target
       role in other roles, and of other roles in the target role. The other
       roles are not dropped nor otherwise affected.

PARAMETERS
       IF EXISTS
           Do not throw an error if the role does not exist. A notice is
           issued in this case.

       name
           The name of the role to remove.

NOTES
       PostgreSQL includes a program dropuser(1) that has the same
       functionality as this command (in fact, it calls this command) but can
       be run from the command shell.

EXAMPLES
       To drop a role:

           DROP ROLE jonathan;

COMPATIBILITY
       The SQL standard defines DROP ROLE, but it allows only one role to be
       dropped at a time, and it specifies different privilege requirements
       than PostgreSQL uses.

SEE ALSO
       CREATE ROLE (CREATE_ROLE(7)), ALTER ROLE (ALTER_ROLE(7)), SET ROLE
       (SET_ROLE(7))



PostgreSQL 9.6.1                     2016                         DROP ROLE(7)
CREATE TYPE(7)          PostgreSQL 9.6.1 Documentation          CREATE TYPE(7)



NAME
       CREATE_TYPE - define a new data type

SYNOPSIS
       CREATE TYPE name AS
           ( [ attribute_name data_type [ COLLATE collation ] [, ... ] ] )

       CREATE TYPE name AS ENUM
           ( [ 'label' [, ... ] ] )

       CREATE TYPE name AS RANGE (
           SUBTYPE = subtype
           [ , SUBTYPE_OPCLASS = subtype_operator_class ]
           [ , COLLATION = collation ]
           [ , CANONICAL = canonical_function ]
           [ , SUBTYPE_DIFF = subtype_diff_function ]
       )

       CREATE TYPE name (
           INPUT = input_function,
           OUTPUT = output_function
           [ , RECEIVE = receive_function ]
           [ , SEND = send_function ]
           [ , TYPMOD_IN = type_modifier_input_function ]
           [ , TYPMOD_OUT = type_modifier_output_function ]
           [ , ANALYZE = analyze_function ]
           [ , INTERNALLENGTH = { internallength | VARIABLE } ]
           [ , PASSEDBYVALUE ]
           [ , ALIGNMENT = alignment ]
           [ , STORAGE = storage ]
           [ , LIKE = like_type ]
           [ , CATEGORY = category ]
           [ , PREFERRED = preferred ]
           [ , DEFAULT = default ]
           [ , ELEMENT = element ]
           [ , DELIMITER = delimiter ]
           [ , COLLATABLE = collatable ]
       )

       CREATE TYPE name

DESCRIPTION
       CREATE TYPE registers a new data type for use in the current database.
       The user who defines a type becomes its owner.

       If a schema name is given then the type is created in the specified
       schema. Otherwise it is created in the current schema. The type name
       must be distinct from the name of any existing type or domain in the
       same schema. (Because tables have associated data types, the type name
       must also be distinct from the name of any existing table in the same
       schema.)

       There are five forms of CREATE TYPE, as shown in the syntax synopsis
       above. They respectively create a composite type, an enum type, a range
       type, a base type, or a shell type. The first four of these are
       discussed in turn below. A shell type is simply a placeholder for a
       type to be defined later; it is created by issuing CREATE TYPE with no
       parameters except for the type name. Shell types are needed as forward
       references when creating range types and base types, as discussed in
       those sections.

   Composite Types
       The first form of CREATE TYPE creates a composite type. The composite
       type is specified by a list of attribute names and data types. An
       attribute's collation can be specified too, if its data type is
       collatable. A composite type is essentially the same as the row type of
       a table, but using CREATE TYPE avoids the need to create an actual
       table when all that is wanted is to define a type. A stand-alone
       composite type is useful, for example, as the argument or return type
       of a function.

       To be able to create a composite type, you must have USAGE privilege on
       all attribute types.

   Enumerated Types
       The second form of CREATE TYPE creates an enumerated (enum) type, as
       described in Section 8.7, "Enumerated Types", in the documentation.
       Enum types take a list of one or more quoted labels, each of which must
       be less than NAMEDATALEN bytes long (64 bytes in a standard PostgreSQL
       build).

   Range Types
       The third form of CREATE TYPE creates a new range type, as described in
       Section 8.17, "Range Types", in the documentation.

       The range type's subtype can be any type with an associated b-tree
       operator class (to determine the ordering of values for the range
       type). Normally the subtype's default b-tree operator class is used to
       determine ordering; to use a non-default operator class, specify its
       name with subtype_opclass. If the subtype is collatable, and you want
       to use a non-default collation in the range's ordering, specify the
       desired collation with the collation option.

       The optional canonical function must take one argument of the range
       type being defined, and return a value of the same type. This is used
       to convert range values to a canonical form, when applicable. See
       Section 8.17.8, "Defining New Range Types", in the documentation for
       more information. Creating a canonical function is a bit tricky, since
       it must be defined before the range type can be declared. To do this,
       you must first create a shell type, which is a placeholder type that
       has no properties except a name and an owner. This is done by issuing
       the command CREATE TYPE name, with no additional parameters. Then the
       function can be declared using the shell type as argument and result,
       and finally the range type can be declared using the same name. This
       automatically replaces the shell type entry with a valid range type.

       The optional subtype_diff function must take two values of the subtype
       type as argument, and return a double precision value representing the
       difference between the two given values. While this is optional,
       providing it allows much greater efficiency of GiST indexes on columns
       of the range type. See Section 8.17.8, "Defining New Range Types", in
       the documentation for more information.

   Base Types
       The fourth form of CREATE TYPE creates a new base type (scalar type).
       To create a new base type, you must be a superuser. (This restriction
       is made because an erroneous type definition could confuse or even
       crash the server.)

       The parameters can appear in any order, not only that illustrated
       above, and most are optional. You must register two or more functions
       (using CREATE FUNCTION) before defining the type. The support functions
       input_function and output_function are required, while the functions
       receive_function, send_function, type_modifier_input_function,
       type_modifier_output_function and analyze_function are optional.
       Generally these functions have to be coded in C or another low-level
       language.

       The input_function converts the type's external textual representation
       to the internal representation used by the operators and functions
       defined for the type.  output_function performs the reverse
       transformation. The input function can be declared as taking one
       argument of type cstring, or as taking three arguments of types
       cstring, oid, integer. The first argument is the input text as a C
       string, the second argument is the type's own OID (except for array
       types, which instead receive their element type's OID), and the third
       is the typmod of the destination column, if known (-1 will be passed if
       not). <!-- 69f11ee9-be93-4a7c-a3a7-95a505dfe57c <=< ACCEPT -->The input function must return a value of the data type itself.
       Usually, an input function should be declared STRICT; if it is not, it
       will be called with a NULL first parameter when reading a NULL input
       value. The function must still return NULL in this case, unless it
       raises an error. (This case is mainly meant to support domain input
       functions, which might need to reject NULL inputs.)<!-- ACCEPT >=> 69f11ee9-be93-4a7c-a3a7-95a505dfe57c --> The output function
       must be declared as taking one argument of the new data type. The
       output function must return type cstring. Output functions are not
       invoked for NULL values.

       The optional receive_function converts the type's external binary
       representation to the internal representation. If this function is not
       supplied, the type cannot participate in binary input. The binary
       representation should be chosen to be cheap to convert to internal
       form, while being reasonably portable. (For example, the standard
       integer data types use network byte order as the external binary
       representation, while the internal representation is in the machine's
       native byte order.) The receive function should perform adequate
       checking to ensure that the value is valid. The receive function can be
       declared as taking one argument of type internal, or as taking three
       arguments of types internal, oid, integer. The first argument is a
       pointer to a StringInfo buffer holding the received byte string; the
       optional arguments are the same as for the text input function. <!-- 69f11ee9-be93-4a7c-a3a7-95a505dfe57c <=< ACCEPT -->The
       receive function must return a value of the data type itself. Usually,
       a receive function should be declared STRICT; if it is not, it will be
       called with a NULL first parameter when reading a NULL input value. The
       function must still return NULL in this case, unless it raises an
       error. (This case is mainly meant to support domain receive functions,
       which might need to reject NULL inputs.)<!-- ACCEPT >=> 69f11ee9-be93-4a7c-a3a7-95a505dfe57c --> Similarly, the optional
       send_function converts from the internal representation to the external
       binary representation. If this function is not supplied, the type
       cannot participate in binary output. The send function must be declared
       as taking one argument of the new data type. The send function must
       return type bytea. Send functions are not invoked for NULL values.

       You should at this point be wondering how the input and output
       functions can be declared to have results or arguments of the new type,
       when they have to be created before the new type can be created. The
       answer is that the type should first be defined as a shell type, which
       is a placeholder type that has no properties except a name and an
       owner. This is done by issuing the command CREATE TYPE name, with no
       additional parameters. Then the C I/O functions can be defined
       referencing the shell type. Finally, CREATE TYPE with a full definition
       replaces the shell entry with a complete, valid type definition, after
       which the new type can be used normally.

       The optional type_modifier_input_function and
       type_modifier_output_function are needed if the type supports
       modifiers, that is optional constraints attached to a type declaration,
       such as char(5) or numeric(30,2).  PostgreSQL allows user-defined types
       to take one or more simple constants or identifiers as modifiers.
       However, this information must be capable of being packed into a single
       non-negative integer value for storage in the system catalogs. The
       type_modifier_input_function is passed the declared modifier(s) in the
       form of a cstring array. It must check the values for validity
       (throwing an error if they are wrong), and if they are correct, return
       a single non-negative integer value that will be stored as the column
       "typmod". Type modifiers will be rejected if the type does not have a
       type_modifier_input_function. The type_modifier_output_function
       converts the internal integer typmod value back to the correct form for
       user display. It must return a cstring value that is the exact string
       to append to the type name; for example numeric's function might return
       (30,2). It is allowed to omit the type_modifier_output_function, in
       which case the default display format is just the stored typmod integer
       value enclosed in parentheses.

       The optional analyze_function performs type-specific statistics
       collection for columns of the data type. By default, ANALYZE will
       attempt to gather statistics using the type's "equals" and "less-than"
       operators, if there is a default b-tree operator class for the type.
       For non-scalar types this behavior is likely to be unsuitable, so it
       can be overridden by specifying a custom analysis function. The
       analysis function must be declared to take a single argument of type
       internal, and return a boolean result. The detailed API for analysis
       functions appears in src/include/commands/vacuum.h.

       While the details of the new type's internal representation are only
       known to the I/O functions and other functions you create to work with
       the type, there are several properties of the internal representation
       that must be declared to PostgreSQL. Foremost of these is
       internallength. Base data types can be fixed-length, in which case
       internallength is a positive integer, or variable-length, indicated by
       setting internallength to VARIABLE. (Internally, this is represented by
       setting typlen to -1.) The internal representation of all
       variable-length types must start with a 4-byte integer giving the total
       length of this value of the type. (Note that the length field is often
       encoded, as described in Section 65.2, "TOAST", in the documentation;
       it's unwise to access it directly.)

       The optional flag PASSEDBYVALUE indicates that values of this data type
       are passed by value, rather than by reference. Types passed by value
       must be fixed-length, and their internal representation cannot be
       larger than the size of the Datum type (4 bytes on some machines, 8
       bytes on others).

       The alignment parameter specifies the storage alignment required for
       the data type. The allowed values equate to alignment on 1, 2, 4, or 8
       byte boundaries. Note that variable-length types must have an alignment
       of at least 4, since they necessarily contain an int4 as their first
       component.

       The storage parameter allows selection of storage strategies for
       variable-length data types. (Only plain is allowed for fixed-length
       types.)  plain specifies that data of the type will always be stored
       in-line and not compressed.  extended specifies that the system will
       first try to compress a long data value, and will move the value out of
       the main table row if it's still too long.  external allows the value
       to be moved out of the main table, but the system will not try to
       compress it.  main allows compression, but discourages moving the value
       out of the main table. (Data items with this storage strategy might
       still be moved out of the main table if there is no other way to make a
       row fit, but they will be kept in the main table preferentially over
       extended and external items.)

       All storage values other than plain imply that the functions of the
       data type can handle values that have been toasted, as described in
       Section 65.2, "TOAST", in the documentation and Section 36.11.1, "TOAST
       Considerations", in the documentation. The specific other value given
       merely determines the default TOAST storage strategy for columns of a
       toastable data type; users can pick other strategies for individual
       columns using ALTER TABLE SET STORAGE.

       The like_type parameter provides an alternative method for specifying
       the basic representation properties of a data type: copy them from some
       existing type. The values of internallength, passedbyvalue, alignment,
       and storage are copied from the named type. (It is possible, though
       usually undesirable, to override some of these values by specifying
       them along with the LIKE clause.) Specifying representation this way is
       especially useful when the low-level implementation of the new type
       "piggybacks" on an existing type in some fashion.

       The category and preferred parameters can be used to help control which
       implicit cast will be applied in ambiguous situations. Each data type
       belongs to a category named by a single ASCII character, and each type
       is either "preferred" or not within its category. The parser will
       prefer casting to preferred types (but only from other types within the
       same category) when this rule is helpful in resolving overloaded
       functions or operators. For more details see Chapter 10, Type
       Conversion, in the documentation. For types that have no implicit casts
       to or from any other types, it is sufficient to leave these settings at
       the defaults. However, for a group of related types that have implicit
       casts, it is often helpful to mark them all as belonging to a category
       and select one or two of the "most general" types as being preferred
       within the category. The category parameter is especially useful when
       adding a user-defined type to an existing built-in category, such as
       the numeric or string types. However, it is also possible to create new
       entirely-user-defined type categories. Select any ASCII character other
       than an upper-case letter to name such a category.

       A default value can be specified, in case a user wants columns of the
       data type to default to something other than the null value. Specify
       the default with the DEFAULT key word. (Such a default can be
       overridden by an explicit DEFAULT clause attached to a particular
       column.)

       To indicate that a type is an array, specify the type of the array
       elements using the ELEMENT key word. For example, to define an array of
       4-byte integers (int4), specify ELEMENT = int4. More details about
       array types appear below.

       To indicate the delimiter to be used between values in the external
       representation of arrays of this type, delimiter can be set to a
       specific character. The default delimiter is the comma (,). Note that
       the delimiter is associated with the array element type, not the array
       type itself.

       If the optional Boolean parameter collatable is true, column
       definitions and expressions of the type may carry collation information
       through use of the COLLATE clause. It is up to the implementations of
       the functions operating on the type to actually make use of the
       collation information; this does not happen automatically merely by
       marking the type collatable.

   Array Types
       Whenever a user-defined type is created, PostgreSQL automatically
       creates an associated array type, whose name consists of the element
       type's name prepended with an underscore, and truncated if necessary to
       keep it less than NAMEDATALEN bytes long. (If the name so generated
       collides with an existing type name, the process is repeated until a
       non-colliding name is found.) This implicitly-created array type is
       variable length and uses the built-in input and output functions
       array_in and array_out. The array type tracks any changes in its
       element type's owner or schema, and is dropped if the element type is.

       You might reasonably ask why there is an ELEMENT option, if the system
       makes the correct array type automatically. The only case where it's
       useful to use ELEMENT is when you are making a fixed-length type that
       happens to be internally an array of a number of identical things, and
       you want to allow these things to be accessed directly by subscripting,
       in addition to whatever operations you plan to provide for the type as
       a whole. For example, type point is represented as just two
       floating-point numbers, which can be accessed using point[0] and
       point[1]. Note that this facility only works for fixed-length types
       whose internal form is exactly a sequence of identical fixed-length
       fields. A subscriptable variable-length type must have the generalized
       internal representation used by array_in and array_out. For historical
       reasons (i.e., this is clearly wrong but it's far too late to change
       it), subscripting of fixed-length array types starts from zero, rather
       than from one as for variable-length arrays.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of a type to be created.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       attribute_name
           The name of an attribute (column) for the composite type.

       data_type
           The name of an existing data type to become a column of the
           composite type.

       collation
           The name of an existing collation to be associated with a column of
           a composite type, or with a range type.

       label
           A string literal representing the textual label associated with one
           value of an enum type.

       subtype
           The name of the element type that the range type will represent
           ranges of.

       subtype_operator_class
           The name of a b-tree operator class for the subtype.

       canonical_function
           The name of the canonicalization function for the range type.

       subtype_diff_function
           The name of a difference function for the subtype.

       input_function
           The name of a function that converts data from the type's external
           textual form to its internal form.

       output_function
           The name of a function that converts data from the type's internal
           form to its external textual form.

       receive_function
           The name of a function that converts data from the type's external
           binary form to its internal form.

       send_function
           The name of a function that converts data from the type's internal
           form to its external binary form.

       type_modifier_input_function
           The name of a function that converts an array of modifier(s) for
           the type into internal form.

       type_modifier_output_function
           The name of a function that converts the internal form of the
           type's modifier(s) to external textual form.

       analyze_function
           The name of a function that performs statistical analysis for the
           data type.

       internallength
           A numeric constant that specifies the length in bytes of the new
           type's internal representation. The default assumption is that it
           is variable-length.

       alignment
           The storage alignment requirement of the data type. If specified,
           it must be char, int2, int4, or double; the default is int4.

       storage
           The storage strategy for the data type. If specified, must be
           plain, external, extended, or main; the default is plain.

       like_type
           The name of an existing data type that the new type will have the
           same representation as. The values of internallength,
           passedbyvalue, alignment, and storage are copied from that type,
           unless overridden by explicit specification elsewhere in this
           CREATE TYPE command.

       category
           The category code (a single ASCII character) for this type. The
           default is 'U' for "user-defined type". Other standard category
           codes can be found in Table 50.56, "typcategory Codes". You may
           also choose other ASCII characters in order to create custom
           categories.

       preferred
           True if this type is a preferred type within its type category,
           else false. The default is false. Be very careful about creating a
           new preferred type within an existing type category, as this could
           cause surprising changes in behavior.

       default
           The default value for the data type. If this is omitted, the
           default is null.

       element
           The type being created is an array; this specifies the type of the
           array elements.

       delimiter
           The delimiter character to be used between values in arrays made of
           this type.

       collatable
           True if this type's operations can use collation information. The
           default is false.

NOTES
       Because there are no restrictions on use of a data type once it's been
       created, creating a base type or range type is tantamount to granting
       public execute permission on the functions mentioned in the type
       definition. This is usually not an issue for the sorts of functions
       that are useful in a type definition. But you might want to think twice
       before designing a type in a way that would require "secret"
       information to be used while converting it to or from external form.

       Before PostgreSQL version 8.3, the name of a generated array type was
       always exactly the element type's name with one underscore character
       (_) prepended. (Type names were therefore restricted in length to one
       less character than other names.) While this is still usually the case,
       the array type name may vary from this in case of maximum-length names
       or collisions with user type names that begin with underscore. Writing
       code that depends on this convention is therefore deprecated. Instead,
       use pg_type.typarray to locate the array type associated with a given
       type.

       It may be advisable to avoid using type and table names that begin with
       underscore. While the server will change generated array type names to
       avoid collisions with user-given names, there is still risk of
       confusion, particularly with old client software that may assume that
       type names beginning with underscores always represent arrays.

       Before PostgreSQL version 8.2, the shell-type creation syntax CREATE
       TYPE name did not exist. The way to create a new base type was to
       create its input function first. In this approach, PostgreSQL will
       first see the name of the new data type as the return type of the input
       function. The shell type is implicitly created in this situation, and
       then it can be referenced in the definitions of the remaining I/O
       functions. This approach still works, but is deprecated and might be
       disallowed in some future release. Also, to avoid accidentally
       cluttering the catalogs with shell types as a result of simple typos in
       function definitions, a shell type will only be made this way when the
       input function is written in C.

       In PostgreSQL versions before 7.3, it was customary to avoid creating a
       shell type at all, by replacing the functions' forward references to
       the type name with the placeholder pseudotype opaque. The cstring
       arguments and results also had to be declared as opaque before 7.3. To
       support loading of old dump files, CREATE TYPE will accept I/O
       functions declared using opaque, but it will issue a notice and change
       the function declarations to use the correct types.

EXAMPLES
       This example creates a composite type and uses it in a function
       definition:

           CREATE TYPE compfoo AS (f1 int, f2 text);

           CREATE FUNCTION getfoo() RETURNS SETOF compfoo AS $$
               SELECT fooid, fooname FROM foo
           $$ LANGUAGE SQL;

       This example creates an enumerated type and uses it in a table
       definition:

           CREATE TYPE bug_status AS ENUM ('new', 'open', 'closed');

           CREATE TABLE bug (
               id serial,
               description text,
               status bug_status
           );

       This example creates a range type:

           CREATE TYPE float8_range AS RANGE (subtype = float8, subtype_diff = float8mi);

       This example creates the base data type box and then uses the type in a
       table definition:

           CREATE TYPE box;

           CREATE FUNCTION my_box_in_function(cstring) RETURNS box AS ... ;
           CREATE FUNCTION my_box_out_function(box) RETURNS cstring AS ... ;

           CREATE TYPE box (
               INTERNALLENGTH = 16,
               INPUT = my_box_in_function,
               OUTPUT = my_box_out_function
           );

           CREATE TABLE myboxes (
               id integer,
               description box
           );

       If the internal structure of box were an array of four float4 elements,
       we might instead use:

           CREATE TYPE box (
               INTERNALLENGTH = 16,
               INPUT = my_box_in_function,
               OUTPUT = my_box_out_function,
               ELEMENT = float4
           );

       which would allow a box value's component numbers to be accessed by
       subscripting. Otherwise the type behaves the same as before.

       This example creates a large object type and uses it in a table
       definition:

           CREATE TYPE bigobj (
               INPUT = lo_filein, OUTPUT = lo_fileout,
               INTERNALLENGTH = VARIABLE
           );
           CREATE TABLE big_objs (
               id integer,
               obj bigobj
           );

       More examples, including suitable input and output functions, are in
       Section 36.11, "User-defined Types", in the documentation.

COMPATIBILITY
       The first form of the CREATE TYPE command, which creates a composite
       type, conforms to the SQL standard. The other forms are PostgreSQL
       extensions. The CREATE TYPE statement in the SQL standard also defines
       other forms that are not implemented in PostgreSQL.

       The ability to create a composite type with zero attributes is a
       PostgreSQL-specific deviation from the standard (analogous to the same
       case in CREATE TABLE).

SEE ALSO
       ALTER TYPE (ALTER_TYPE(7)), CREATE DOMAIN (CREATE_DOMAIN(7)), CREATE
       FUNCTION (CREATE_FUNCTION(7)), DROP TYPE (DROP_TYPE(7))



PostgreSQL 9.6.1                     2016                       CREATE TYPE(7)
ALTER OPERATOR CLASS(7) PostgreSQL 9.6.1 Documentation ALTER OPERATOR CLASS(7)



NAME
       ALTER_OPERATOR_CLASS - change the definition of an operator class

SYNOPSIS
       ALTER OPERATOR CLASS name USING index_method
           RENAME TO new_name

       ALTER OPERATOR CLASS name USING index_method
           OWNER TO { new_owner | CURRENT_USER | SESSION_USER }

       ALTER OPERATOR CLASS name USING index_method
           SET SCHEMA new_schema

DESCRIPTION
       ALTER OPERATOR CLASS changes the definition of an operator class.

       You must own the operator class to use ALTER OPERATOR CLASS. To alter
       the owner, you must also be a direct or indirect member of the new
       owning role, and that role must have CREATE privilege on the operator
       class's schema. (These restrictions enforce that altering the owner
       doesn't do anything you couldn't do by dropping and recreating the
       operator class. However, a superuser can alter ownership of any
       operator class anyway.)

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing operator
           class.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       index_method
           The name of the index method this operator class is for.

       new_name
           The new name of the operator class.

       new_owner
           The new owner of the operator class.

       new_schema
           The new schema for the operator class.

COMPATIBILITY
       There is no ALTER OPERATOR CLASS statement in the SQL standard.

SEE ALSO
       CREATE OPERATOR CLASS (CREATE_OPERATOR_CLASS(7)), DROP OPERATOR CLASS
       (DROP_OPERATOR_CLASS(7)), ALTER OPERATOR FAMILY
       (ALTER_OPERATOR_FAMILY(7))



PostgreSQL 9.6.1                     2016              ALTER OPERATOR CLASS(7)
DROP EXTENSION(7)       PostgreSQL 9.6.1 Documentation       DROP EXTENSION(7)



NAME
       DROP_EXTENSION - remove an extension

SYNOPSIS
       DROP EXTENSION [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP EXTENSION removes extensions from the database. Dropping an
       extension causes its component objects to be dropped as well.

       You must own the extension to use DROP EXTENSION.

PARAMETERS
       IF EXISTS
           Do not throw an error if the extension does not exist. A notice is
           issued in this case.

       name
           The name of an installed extension.

       CASCADE
           Automatically drop objects that depend on the extension, and in
           turn all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the extension if any objects depend on it (other
           than its own member objects and other extensions listed in the same
           DROP command). This is the default.

EXAMPLES
       To remove the extension hstore from the current database:

           DROP EXTENSION hstore;

       This command will fail if any of hstore's objects are in use in the
       database, for example if any tables have columns of the hstore type.
       Add the CASCADE option to forcibly remove those dependent objects as
       well.

COMPATIBILITY
       DROP EXTENSION is a PostgreSQL extension.

SEE ALSO
       CREATE EXTENSION (CREATE_EXTENSION(7)), ALTER EXTENSION
       (ALTER_EXTENSION(7))



PostgreSQL 9.6.1                     2016                    DROP EXTENSION(7)
INSERT(7)               PostgreSQL 9.6.1 Documentation               INSERT(7)



NAME
       INSERT - create new rows in a table

SYNOPSIS
       [ WITH [ RECURSIVE ] with_query [, ...] ]
       INSERT INTO table_name [ AS alias ] [ ( column_name [, ...] ) ]
           { DEFAULT VALUES | VALUES ( { expression | DEFAULT } [, ...] ) [, ...] | query }
           [ ON CONFLICT [ conflict_target ] conflict_action ]
           [ RETURNING * | output_expression [ [ AS ] output_name ] [, ...] ]

       where conflict_target can be one of:

           ( { index_column_name | ( index_expression ) } [ COLLATE collation ] [ opclass ] [, ...] ) [ WHERE index_predicate ]
           ON CONSTRAINT constraint_name

       and conflict_action is one of:

           DO NOTHING
           DO UPDATE SET { column_name = { expression | DEFAULT } |
                           ( column_name [, ...] ) = ( { expression | DEFAULT } [, ...] ) |
                           ( column_name [, ...] ) = ( sub-SELECT )
                         } [, ...]
                     [ WHERE condition ]

DESCRIPTION
       INSERT inserts new rows into a table. One can insert one or more rows
       specified by value expressions, or zero or more rows resulting from a
       query.

       The target column names can be listed in any order. If no list of
       column names is given at all, the default is all the columns of the
       table in their declared order; or the first N column names, if there
       are only N columns supplied by the VALUES clause or query. The values
       supplied by the VALUES clause or query are associated with the explicit
       or implicit column list left-to-right.

       Each column not present in the explicit or implicit column list will be
       filled with a default value, either its declared default value or null
       if there is none.

       If the expression for any column is not of the correct data type,
       automatic type conversion will be attempted.

       ON CONFLICT can be used to specify an alternative action to raising a
       unique constraint or exclusion constraint violation error. (See ON
       CONFLICT Clause below.)

       The optional RETURNING clause causes INSERT to compute and return
       value(s) based on each row actually inserted (or updated, if an ON
       CONFLICT DO UPDATE clause was used). This is primarily useful for
       obtaining values that were supplied by defaults, such as a serial
       sequence number. However, any expression using the table's columns is
       allowed. The syntax of the RETURNING list is identical to that of the
       output list of SELECT. Only rows that were successfully inserted or
       updated will be returned. For example, if a row was locked but not
       updated because an ON CONFLICT DO UPDATE ... WHERE clause condition was
       not satisfied, the row will not be returned.

       You must have INSERT privilege on a table in order to insert into it.
       If ON CONFLICT DO UPDATE is present, UPDATE privilege on the table is
       also required.

       If a column list is specified, you only need INSERT privilege on the
       listed columns. Similarly, when ON CONFLICT DO UPDATE is specified, you
       only need UPDATE privilege on the column(s) that are listed to be
       updated. However, ON CONFLICT DO UPDATE also requires SELECT privilege
       on any column whose values are read in the ON CONFLICT DO UPDATE
       expressions or condition.

       Use of the RETURNING clause requires SELECT privilege on all columns
       mentioned in RETURNING. If you use the query clause to insert rows from
       a query, you of course need to have SELECT privilege on any table or
       column used in the query.

PARAMETERS
   Inserting
       This section covers parameters that may be used when only inserting new
       rows. Parameters exclusively used with the ON CONFLICT clause are
       described separately.

       with_query
           The WITH clause allows you to specify one or more subqueries that
           can be referenced by name in the INSERT query. See Section 7.8,
           "WITH Queries (Common Table Expressions)", in the documentation and
           SELECT(7) for details.

           It is possible for the query (SELECT statement) to also contain a
           WITH clause. In such a case both sets of with_query can be
           referenced within the query, but the second one takes precedence
           since it is more closely nested.

       table_name
           The name (optionally schema-qualified) of an existing table.

       alias
           A substitute name for table_name. When an alias is provided, it
           completely hides the actual name of the table. This is particularly
           useful when ON CONFLICT DO UPDATE targets a table named excluded,
           since that's also the name of the special table representing rows
           proposed for insertion.

       column_name
           The name of a column in the table named by table_name. The column
           name can be qualified with a subfield name or array subscript, if
           needed. (Inserting into only some fields of a composite column
           leaves the other fields null.) When referencing a column with ON
           CONFLICT DO UPDATE, do not include the table's name in the
           specification of a target column. For example, INSERT INTO
           table_name ... ON CONFLICT DO UPDATE SET table_name.col = 1 is
           invalid (this follows the general behavior for UPDATE).

       DEFAULT VALUES
           All columns will be filled with their default values.

       expression
           An expression or value to assign to the corresponding column.

       DEFAULT
           The corresponding column will be filled with its default value.

       query
           A query (SELECT statement) that supplies the rows to be inserted.
           Refer to the SELECT(7) statement for a description of the syntax.

       output_expression
           An expression to be computed and returned by the INSERT command
           after each row is inserted or updated. The expression can use any
           column names of the table named by table_name. Write * to return
           all columns of the inserted or updated row(s).

       output_name
           A name to use for a returned column.

   ON CONFLICT Clause
       The optional ON CONFLICT clause specifies an alternative action to
       raising a unique violation or exclusion constraint violation error. For
       each individual row proposed for insertion, either the insertion
       proceeds, or, if an arbiter constraint or index specified by
       conflict_target is violated, the alternative conflict_action is taken.
       ON CONFLICT DO NOTHING simply avoids inserting a row as its alternative
       action.  ON CONFLICT DO UPDATE updates the existing row that conflicts
       with the row proposed for insertion as its alternative action.

       conflict_target can perform unique index inference. When performing
       inference, it consists of one or more index_column_name columns and/or
       index_expression expressions, and an optional index_predicate. All
       table_name unique indexes that, without regard to order, contain
       exactly the conflict_target-specified columns/expressions are inferred
       (chosen) as arbiter indexes. If an index_predicate is specified, it
       must, as a further requirement for inference, satisfy arbiter indexes.
       Note that this means a non-partial unique index (a unique index without
       a predicate) will be inferred (and thus used by ON CONFLICT) if such an
       index satisfying every other criteria is available. If an attempt at
       inference is unsuccessful, an error is raised.

       ON CONFLICT DO UPDATE guarantees an atomic INSERT or UPDATE outcome;
       provided there is no independent error, one of those two outcomes is
       guaranteed, even under high concurrency. This is also known as UPSERT
       -- "UPDATE or INSERT".

       conflict_target
           Specifies which conflicts ON CONFLICT takes the alternative action
           on by choosing arbiter indexes. Either performs unique index
           inference, or names a constraint explicitly. For ON CONFLICT DO
           NOTHING, it is optional to specify a conflict_target; when omitted,
           conflicts with all usable constraints (and unique indexes) are
           handled. For ON CONFLICT DO UPDATE, a conflict_targetmust be
           provided.

       conflict_action
           conflict_action specifies an alternative ON CONFLICT action. It can
           be either DO NOTHING, or a DO UPDATE clause specifying the exact
           details of the UPDATE action to be performed in case of a conflict.
           The SET and WHERE clauses in ON CONFLICT DO UPDATE have access to
           the existing row using the table's name (or an alias), and to rows
           proposed for insertion using the special excluded table.  SELECT
           privilege is required on any column in the target table where
           corresponding excluded columns are read.

           Note that the effects of all per-row BEFORE INSERT triggers are
           reflected in excluded values, since those effects may have
           contributed to the row being excluded from insertion.

       index_column_name
           The name of a table_name column. Used to infer arbiter indexes.
           Follows CREATE INDEX format.  SELECT privilege on index_column_name
           is required.

       index_expression
           Similar to index_column_name, but used to infer expressions on
           table_name columns appearing within index definitions (not simple
           columns). Follows CREATE INDEX format.  SELECT privilege on any
           column appearing within index_expression is required.

       collation
           When specified, mandates that corresponding index_column_name or
           index_expression use a particular collation in order to be matched
           during inference. Typically this is omitted, as collations usually
           do not affect whether or not a constraint violation occurs. Follows
           CREATE INDEX format.

       opclass
           When specified, mandates that corresponding index_column_name or
           index_expression use particular operator class in order to be
           matched during inference. Typically this is omitted, as the
           equality semantics are often equivalent across a type's operator
           classes anyway, or because it's sufficient to trust that the
           defined unique indexes have the pertinent definition of equality.
           Follows CREATE INDEX format.

       index_predicate
           Used to allow inference of partial unique indexes. Any indexes that
           satisfy the predicate (which need not actually be partial indexes)
           can be inferred. Follows CREATE INDEX format.  SELECT privilege on
           any column appearing within index_predicate is required.

       constraint_name
           Explicitly specifies an arbiter constraint by name, rather than
           inferring a constraint or index.

       condition
           An expression that returns a value of type boolean. Only rows for
           which this expression returns true will be updated, although all
           rows will be locked when the ON CONFLICT DO UPDATE action is taken.
           Note that condition is evaluated last, after a conflict has been
           identified as a candidate to update.

       Note that exclusion constraints are not supported as arbiters with ON
       CONFLICT DO UPDATE. In all cases, only NOT DEFERRABLE constraints and
       unique indexes are supported as arbiters.

       INSERT with an ON CONFLICT DO UPDATE clause is a "deterministic"
       statement. This means that the command will not be allowed to affect
       any single existing row more than once; a cardinality violation error
       will be raised when this situation arises. Rows proposed for insertion
       should not duplicate each other in terms of attributes constrained by
       an arbiter index or constraint.

           Tip
           It is often preferable to use unique index inference rather than
           naming a constraint directly using ON CONFLICT ON CONSTRAINT
           constraint_name. Inference will continue to work correctly when the
           underlying index is replaced by another more or less equivalent
           index in an overlapping way, for example when using CREATE UNIQUE
           INDEX ... CONCURRENTLY before dropping the index being replaced.

OUTPUTS
       On successful completion, an INSERT command returns a command tag of
       the form

           INSERT oid count

       The count is the number of rows inserted or updated. If count is
       exactly one, and the target table has OIDs, then oid is the OID
       assigned to the inserted row. The single row must have been inserted
       rather than updated. Otherwise oid is zero.

       If the INSERT command contains a RETURNING clause, the result will be
       similar to that of a SELECT statement containing the columns and values
       defined in the RETURNING list, computed over the row(s) inserted or
       updated by the command.

EXAMPLES
       Insert a single row into table films:

           INSERT INTO films VALUES
               ('UA502', 'Bananas', 105, '1971-07-13', 'Comedy', '82 minutes');

       In this example, the len column is omitted and therefore it will have
       the default value:

           INSERT INTO films (code, title, did, date_prod, kind)
               VALUES ('T_601', 'Yojimbo', 106, '1961-06-16', 'Drama');

       This example uses the DEFAULT clause for the date columns rather than
       specifying a value:

           INSERT INTO films VALUES
               ('UA502', 'Bananas', 105, DEFAULT, 'Comedy', '82 minutes');
           INSERT INTO films (code, title, did, date_prod, kind)
               VALUES ('T_601', 'Yojimbo', 106, DEFAULT, 'Drama');

       To insert a row consisting entirely of default values:

           INSERT INTO films DEFAULT VALUES;

       To insert multiple rows using the multirow VALUES syntax:

           INSERT INTO films (code, title, did, date_prod, kind) VALUES
               ('B6717', 'Tampopo', 110, '1985-02-10', 'Comedy'),
               ('HG120', 'The Dinner Game', 140, DEFAULT, 'Comedy');

       This example inserts some rows into table films from a table tmp_films
       with the same column layout as films:

           INSERT INTO films SELECT * FROM tmp_films WHERE date_prod &amp;lt; '2004-05-07';

       This example inserts into array columns:

           -- Create an empty 3x3 gameboard for noughts-and-crosses
           INSERT INTO tictactoe (game, board[1:3][1:3])
               VALUES (1, '{{" "," "," "},{" "," "," "},{" "," "," "}}');
           -- The subscripts in the above example aren't really needed
           INSERT INTO tictactoe (game, board)
               VALUES (2, '{{X," "," "},{" ",O," "},{" ",X," "}}');

       Insert a single row into table distributors, returning the sequence
       number generated by the DEFAULT clause:

           INSERT INTO distributors (did, dname) VALUES (DEFAULT, 'XYZ Widgets')
              RETURNING did;

       Increment the sales count of the salesperson who manages the account
       for Acme Corporation, and record the whole updated row along with
       current time in a log table:

           WITH upd AS (
             UPDATE employees SET sales_count = sales_count + 1 WHERE id =
               (SELECT sales_person FROM accounts WHERE name = 'Acme Corporation')
               RETURNING *
           )
           INSERT INTO employees_log SELECT *, current_timestamp FROM upd;

       Insert or update new distributors as appropriate. Assumes a unique
       index has been defined that constrains values appearing in the did
       column. Note that the special excluded table is used to reference
       values originally proposed for insertion:

           INSERT INTO distributors (did, dname)
               VALUES (5, 'Gizmo Transglobal'), (6, 'Associated Computing, Inc')
               ON CONFLICT (did) DO UPDATE SET dname = EXCLUDED.dname;

       Insert a distributor, or do nothing for rows proposed for insertion
       when an existing, excluded row (a row with a matching constrained
       column or columns after before row insert triggers fire) exists.
       Example assumes a unique index has been defined that constrains values
       appearing in the did column:

           INSERT INTO distributors (did, dname) VALUES (7, 'Redline GmbH')
               ON CONFLICT (did) DO NOTHING;

       Insert or update new distributors as appropriate. Example assumes a
       unique index has been defined that constrains values appearing in the
       did column.  WHERE clause is used to limit the rows actually updated
       (any existing row not updated will still be locked, though):

           -- Don't update existing distributors based in a certain ZIP code
           INSERT INTO distributors AS d (did, dname) VALUES (8, 'Anvil Distribution')
               ON CONFLICT (did) DO UPDATE
               SET dname = EXCLUDED.dname || ' (formerly ' || d.dname || ')'
               WHERE d.zipcode &amp;lt;&amp;gt; '21201';

           -- Name a constraint directly in the statement (uses associated
           -- index to arbitrate taking the DO NOTHING action)
           INSERT INTO distributors (did, dname) VALUES (9, 'Antwerp Design')
               ON CONFLICT ON CONSTRAINT distributors_pkey DO NOTHING;

       Insert new distributor if possible; otherwise DO NOTHING. Example
       assumes a unique index has been defined that constrains values
       appearing in the did column on a subset of rows where the is_active
       Boolean column evaluates to true:

           -- This statement could infer a partial unique index on "did"
           -- with a predicate of "WHERE is_active", but it could also
           -- just use a regular unique constraint on "did"
           INSERT INTO distributors (did, dname) VALUES (10, 'Conrad International')
               ON CONFLICT (did) WHERE is_active DO NOTHING;


<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       INSERT conforms to the SQL standard, except that the RETURNING clause
       is a PostgreSQL extension, as is the ability to use WITH with INSERT,
       and the ability to specify an alternative action with ON CONFLICT.
       Also, the case in which a column name list is omitted, but not all the
       columns are filled from the VALUES clause or query, is disallowed by
       the standard.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

       Possible limitations of the query clause are documented under
       SELECT(7).



PostgreSQL 9.6.1                     2016                            INSERT(7)
EXECUTE(7)              PostgreSQL 9.6.1 Documentation              EXECUTE(7)



NAME
       EXECUTE - execute a prepared statement

SYNOPSIS
       EXECUTE name [ ( parameter [, ...] ) ]

DESCRIPTION
       EXECUTE is used to execute a previously prepared statement. Since
       prepared statements only exist for the duration of a session, the
       prepared statement must have been created by a PREPARE statement
       executed earlier in the current session.

       If the PREPARE statement that created the statement specified some
       parameters, a compatible set of parameters must be passed to the
       EXECUTE statement, or else an error is raised. Note that (unlike
       functions) prepared statements are not overloaded based on the type or
       number of their parameters; the name of a prepared statement must be
       unique within a database session.

       For more information on the creation and usage of prepared statements,
       see PREPARE(7).

PARAMETERS
       name
           The name of the prepared statement to execute.

       parameter
           The actual value of a parameter to the prepared statement. This
           must be an expression yielding a value that is compatible with the
           data type of this parameter, as was determined when the prepared
           statement was created.

OUTPUTS
       The command tag returned by EXECUTE is that of the prepared statement,
       and not EXECUTE.

EXAMPLES
       Examples are given in the EXAMPLES section of the PREPARE(7)
       documentation.

COMPATIBILITY
       The SQL standard includes an EXECUTE statement, but it is only for use
       in embedded SQL. This version of the EXECUTE statement also uses a
       somewhat different syntax.

SEE ALSO
       DEALLOCATE(7), PREPARE(7)



PostgreSQL 9.6.1                     2016                           EXECUTE(7)
LOCK(7)                 PostgreSQL 9.6.1 Documentation                 LOCK(7)



NAME
       LOCK - lock a table

SYNOPSIS
       LOCK [ TABLE ] [ ONLY ] name [ * ] [, ...] [ IN lockmode MODE ] [ NOWAIT ]

       where lockmode is one of:

           ACCESS SHARE | ROW SHARE | ROW EXCLUSIVE | SHARE UPDATE EXCLUSIVE
           | SHARE | SHARE ROW EXCLUSIVE | EXCLUSIVE | ACCESS EXCLUSIVE

DESCRIPTION
       LOCK TABLE obtains a table-level lock, waiting if necessary for any
       conflicting locks to be released. If NOWAIT is specified, LOCK TABLE
       does not wait to acquire the desired lock: if it cannot be acquired
       immediately, the command is aborted and an error is emitted. Once
       obtained, the lock is held for the remainder of the current
       transaction. (There is no UNLOCK TABLE command; locks are always
       released at transaction end.)

       When acquiring locks automatically for commands that reference tables,
       PostgreSQL always uses the least restrictive lock mode possible.  LOCK
       TABLE provides for cases when you might need more restrictive locking.
       For example, suppose an application runs a transaction at the READ
       COMMITTED isolation level and needs to ensure that data in a table
       remains stable for the duration of the transaction. To achieve this you
       could obtain SHARE lock mode over the table before querying. This will
       prevent concurrent data changes and ensure subsequent reads of the
       table see a stable view of committed data, because SHARE lock mode
       conflicts with the ROW EXCLUSIVE lock acquired by writers, and your
       LOCK TABLE name IN SHARE MODE statement will wait until any concurrent
       holders of ROW EXCLUSIVE mode locks commit or roll back. Thus, once you
       obtain the lock, there are no uncommitted writes outstanding;
       furthermore none can begin until you release the lock.

       To achieve a similar effect when running a transaction at the
       REPEATABLE READ or SERIALIZABLE isolation level, you have to execute
       the LOCK TABLE statement before executing any SELECT or data
       modification statement. A REPEATABLE READ or SERIALIZABLE transaction's
       view of data will be frozen when its first SELECT or data modification
       statement begins. A LOCK TABLE later in the transaction will still
       prevent concurrent writes -- but it won't ensure that what the
       transaction reads corresponds to the latest committed values.

       If a transaction of this sort is going to change the data in the table,
       then it should use SHARE ROW EXCLUSIVE lock mode instead of SHARE mode.
       This ensures that only one transaction of this type runs at a time.
       Without this, a deadlock is possible: two transactions might both
       acquire SHARE mode, and then be unable to also acquire ROW EXCLUSIVE
       mode to actually perform their updates. (Note that a transaction's own
       locks never conflict, so a transaction can acquire ROW EXCLUSIVE mode
       when it holds SHARE mode -- but not if anyone else holds SHARE mode.)
       To avoid deadlocks, make sure all transactions acquire locks on the
       same objects in the same order, and if multiple lock modes are involved
       for a single object, then transactions should always acquire the most
       restrictive mode first.

       More information about the lock modes and locking strategies can be
       found in Section 13.3, "Explicit Locking", in the documentation.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing table to
           lock. If ONLY is specified before the table name, only that table
           is locked. If ONLY is not specified, the table and all its
           descendant tables (if any) are locked. Optionally, * can be
           specified after the table name to explicitly indicate that
           descendant tables are included.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

           The command LOCK TABLE a, b; is equivalent to LOCK TABLE a; LOCK
           TABLE b;. The tables are locked one-by-one in the order specified
           in the LOCK TABLE command.

       lockmode
           The lock mode specifies which locks this lock conflicts with. Lock
           modes are described in Section 13.3, "Explicit Locking", in the
           documentation.

           If no lock mode is specified, then ACCESS EXCLUSIVE, the most
           restrictive mode, is used.

       NOWAIT
           Specifies that LOCK TABLE should not wait for any conflicting locks
           to be released: if the specified lock(s) cannot be acquired
           immediately without waiting, the transaction is aborted.

NOTES
       LOCK TABLE ... IN ACCESS SHARE MODE requires SELECT privileges on the
       target table.  LOCK TABLE ... IN ROW EXCLUSIVE MODE requires INSERT,
       UPDATE, DELETE, or TRUNCATE privileges on the target table. All other
       forms of LOCK require table-level UPDATE, DELETE, or TRUNCATE
       privileges.

       LOCK TABLE is useless outside a transaction block: the lock would
       remain held only to the completion of the statement. Therefore
       PostgreSQL reports an error if LOCK is used outside a transaction
       block. Use BEGIN(7) and COMMIT(7) (or ROLLBACK(7)) to define a
       transaction block.

       LOCK TABLE only deals with table-level locks, and so the mode names
       involving ROW are all misnomers. These mode names should generally be
       read as indicating the intention of the user to acquire row-level locks
       within the locked table. Also, ROW EXCLUSIVE mode is a shareable table
       lock. Keep in mind that all the lock modes have identical semantics so
       far as LOCK TABLE is concerned, differing only in the rules about which
       modes conflict with which. For information on how to acquire an actual
       row-level lock, see Section 13.3.2, "Row-level Locks", in the
       documentation and the The Locking Clause in the SELECT reference
       documentation.

EXAMPLES
       Obtain a SHARE lock on a primary key table when going to perform
       inserts into a foreign key table:

           BEGIN WORK;
           LOCK TABLE films IN SHARE MODE;
           SELECT id FROM films
               WHERE name = 'Star Wars: Episode I - The Phantom Menace';
           -- Do ROLLBACK if record was not returned
           INSERT INTO films_user_comments VALUES
               (_id_, 'GREAT! I was waiting for it for so long!');
           COMMIT WORK;

       Take a SHARE ROW EXCLUSIVE lock on a primary key table when going to
       perform a delete operation:

           BEGIN WORK;
           LOCK TABLE films IN SHARE ROW EXCLUSIVE MODE;
           DELETE FROM films_user_comments WHERE id IN
               (SELECT id FROM films WHERE rating &amp;lt; 5);
           DELETE FROM films WHERE rating &amp;lt; 5;
           COMMIT WORK;

COMPATIBILITY
       There is no LOCK TABLE in the SQL standard, which instead uses SET
       TRANSACTION to specify concurrency levels on transactions.  PostgreSQL
       supports that too; see SET TRANSACTION (SET_TRANSACTION(7)) for
       details.

       Except for ACCESS SHARE, ACCESS EXCLUSIVE, and SHARE UPDATE EXCLUSIVE
       lock modes, the PostgreSQL lock modes and the LOCK TABLE syntax are
       compatible with those present in Oracle.



PostgreSQL 9.6.1                     2016                              LOCK(7)
DROP VIEW(7)            PostgreSQL 9.6.1 Documentation            DROP VIEW(7)



NAME
       DROP_VIEW - remove a view

SYNOPSIS
       DROP VIEW [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP VIEW drops an existing view. To execute this command you must be
       the owner of the view.

PARAMETERS
       IF EXISTS
           Do not throw an error if the view does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the view to remove.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the view (such as other
           views), and in turn all objects that depend on those objects (see
           Section 5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the view if any objects depend on it. This is the
           default.

EXAMPLES
       This command will remove the view called kinds:

           DROP VIEW kinds;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       This command conforms to the SQL standard, except that the standard
       only allows one view to be dropped per command, and apart from the IF
       EXISTS option, which is a PostgreSQL extension.
<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->
SEE ALSO
       ALTER VIEW (ALTER_VIEW(7)), CREATE VIEW (CREATE_VIEW(7))



PostgreSQL 9.6.1                     2016                         DROP VIEW(7)
CREATE TABLESPACE(7)    PostgreSQL 9.6.1 Documentation    CREATE TABLESPACE(7)



NAME
       CREATE_TABLESPACE - define a new tablespace

SYNOPSIS
       CREATE TABLESPACE tablespace_name
           [ OWNER { new_owner | CURRENT_USER | SESSION_USER } ]
           LOCATION 'directory'
           [ WITH ( tablespace_option = value [, ... ] ) ]

DESCRIPTION
       CREATE TABLESPACE registers a new cluster-wide tablespace. The
       tablespace name must be distinct from the name of any existing
       tablespace in the database cluster.

       A tablespace allows superusers to define an alternative location on the
       file system where the data files containing database objects (such as
       tables and indexes) can reside.

       A user with appropriate privileges can pass tablespace_name to CREATE
       DATABASE, CREATE TABLE, CREATE INDEX or ADD CONSTRAINT to have the data
       files for these objects stored within the specified tablespace.

           Warning
           A tablespace cannot be used independently of the cluster in which
           it is defined; see Section 22.6, "Tablespaces", in the
           documentation.

PARAMETERS
       tablespace_name
           The name of a tablespace to be created. The name cannot begin with
           pg_, as such names are reserved for system tablespaces.

       user_name
           The name of the user who will own the tablespace. If omitted,
           defaults to the user executing the command. Only superusers can
           create tablespaces, but they can assign ownership of tablespaces to
           non-superusers.

       directory
           The directory that will be used for the tablespace. The directory
           should be empty and must be owned by the PostgreSQL system user.
           The directory must be specified by an absolute path name.

<!-- 0dcf2f4d-9a93-47a8-b9b7-a97b18cef24c <=< ACCEPT -->       tablespace_option
           A tablespace parameter to be set or reset. Currently, the only
           available parameters are seq_page_cost, random_page_cost and
           effective_io_concurrency. Setting either value for a particular
           tablespace will override the planner's usual estimate of the cost
           of reading pages from tables in that tablespace, as established by
           the configuration parameters of the same name (see seq_page_cost,
           random_page_cost, effective_io_concurrency). This may be useful if
           one tablespace is located on a disk which is faster or slower than
           the remainder of the I/O subsystem.<!-- ACCEPT >=> 0dcf2f4d-9a93-47a8-b9b7-a97b18cef24c -->

NOTES
       Tablespaces are only supported on systems that support symbolic links.

       CREATE TABLESPACE cannot be executed inside a transaction block.

EXAMPLES
       Create a tablespace dbspace at /data/dbs:

           CREATE TABLESPACE dbspace LOCATION '/data/dbs';

       Create a tablespace indexspace at /data/indexes owned by user
       genevieve:

           CREATE TABLESPACE indexspace OWNER genevieve LOCATION '/data/indexes';

COMPATIBILITY
       CREATE TABLESPACE is a PostgreSQL extension.

SEE ALSO
       CREATE DATABASE (CREATE_DATABASE(7)), CREATE TABLE (CREATE_TABLE(7)),
       CREATE INDEX (CREATE_INDEX(7)), DROP TABLESPACE (DROP_TABLESPACE(7)),
       ALTER TABLESPACE (ALTER_TABLESPACE(7))



PostgreSQL 9.6.1                     2016                 CREATE TABLESPACE(7)
DROP TEXT SEARCH TEMPLATPostgreSQL 9.6.1 DocumentaDROP TEXT SEARCH TEMPLATE(7)



NAME
       DROP_TEXT_SEARCH_TEMPLATE - remove a text search template

SYNOPSIS
       DROP TEXT SEARCH TEMPLATE [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP TEXT SEARCH TEMPLATE drops an existing text search template. You
       must be a superuser to use this command.

PARAMETERS
       IF EXISTS
           Do not throw an error if the text search template does not exist. A
           notice is issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing text search
           template.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the text search template,
           and in turn all objects that depend on those objects (see Section
           5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the text search template if any objects depend on
           it. This is the default.

EXAMPLES
       Remove the text search template thesaurus:

           DROP TEXT SEARCH TEMPLATE thesaurus;

       This command will not succeed if there are any existing text search
       dictionaries that use the template. Add CASCADE to drop such
       dictionaries along with the template.

COMPATIBILITY
       There is no DROP TEXT SEARCH TEMPLATE statement in the SQL standard.

SEE ALSO
       ALTER TEXT SEARCH TEMPLATE (ALTER_TEXT_SEARCH_TEMPLATE(7)), CREATE TEXT
       SEARCH TEMPLATE (CREATE_TEXT_SEARCH_TEMPLATE(7))



PostgreSQL 9.6.1                     2016         DROP TEXT SEARCH TEMPLATE(7)
ALTER COLLATION(7)      PostgreSQL 9.6.1 Documentation      ALTER COLLATION(7)



NAME
       ALTER_COLLATION - change the definition of a collation

SYNOPSIS
       ALTER COLLATION name RENAME TO new_name
       ALTER COLLATION name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER COLLATION name SET SCHEMA new_schema

DESCRIPTION
       ALTER COLLATION changes the definition of a collation.

       You must own the collation to use ALTER COLLATION. To alter the owner,
       you must also be a direct or indirect member of the new owning role,
       and that role must have CREATE privilege on the collation's schema.
       (These restrictions enforce that altering the owner doesn't do anything
       you couldn't do by dropping and recreating the collation. However, a
       superuser can alter ownership of any collation anyway.)

PARAMETERS
       name
           The name (optionally schema-qualified) of an existing collation.

       new_name
           The new name of the collation.

       new_owner
           The new owner of the collation.

       new_schema
           The new schema for the collation.

EXAMPLES
       To rename the collation de_DE to german:

           ALTER COLLATION "de_DE" RENAME TO german;

       To change the owner of the collation en_US to joe:

           ALTER COLLATION "en_US" OWNER TO joe;

COMPATIBILITY
       There is no ALTER COLLATION statement in the SQL standard.

SEE ALSO
       CREATE COLLATION (CREATE_COLLATION(7)), DROP COLLATION
       (DROP_COLLATION(7))



PostgreSQL 9.6.1                     2016                   ALTER COLLATION(7)
CREATE TABLE AS(7)      PostgreSQL 9.6.1 Documentation      CREATE TABLE AS(7)



NAME
       CREATE_TABLE_AS - define a new table from the results of a query

SYNOPSIS
       CREATE [ [ GLOBAL | LOCAL ] { TEMPORARY | TEMP } | UNLOGGED ] TABLE [ IF NOT EXISTS ] table_name
           [ (column_name [, ...] ) ]
           [ WITH ( storage_parameter [= value] [, ... ] ) | WITH OIDS | WITHOUT OIDS ]
           [ ON COMMIT { PRESERVE ROWS | DELETE ROWS | DROP } ]
           [ TABLESPACE tablespace_name ]
           AS query
           [ WITH [ NO ] DATA ]

DESCRIPTION
       CREATE TABLE AS creates a table and fills it with data computed by a
       SELECT command. The table columns have the names and data types
       associated with the output columns of the SELECT (except that you can
       override the column names by giving an explicit list of new column
       names).

       CREATE TABLE AS bears some resemblance to creating a view, but it is
       really quite different: it creates a new table and evaluates the query
       just once to fill the new table initially. The new table will not track
       subsequent changes to the source tables of the query. In contrast, a
       view re-evaluates its defining SELECT statement whenever it is queried.

PARAMETERS
       GLOBAL or LOCAL
           Ignored for compatibility. Use of these keywords is deprecated;
           refer to CREATE TABLE (CREATE_TABLE(7)) for details.

<!-- af018221-d9ea-4be4-9e81-715f0e7548b6 <=< ACCEPT -->       TEMPORARY or TEMP
           If specified, the table is created as a temporary table. Refer to
           CREATE TABLE (CREATE_TABLE(7)) for details.

       UNLOGGED
           If specified, the table is created as an unlogged table. Refer to
           CREATE TABLE (CREATE_TABLE(7)) for details.<!-- ACCEPT >=> af018221-d9ea-4be4-9e81-715f0e7548b6 -->

       IF NOT EXISTS
           Do not throw an error if a relation with the same name already
           exists. A notice is issued in this case. Refer to CREATE TABLE
           (CREATE_TABLE(7)) for details.

       table_name
           The name (optionally schema-qualified) of the table to be created.

       column_name
           The name of a column in the new table. If column names are not
           provided, they are taken from the output column names of the query.

       WITH ( storage_parameter [= value] [, ... ] )
           This clause specifies optional storage parameters for the new
           table; see Storage Parameters for more information. The WITH clause
           can also include OIDS=TRUE (or just OIDS) to specify that rows of
           the new table should have OIDs (object identifiers) assigned to
           them, or OIDS=FALSE to specify that the rows should not have OIDs.
           See CREATE TABLE (CREATE_TABLE(7)) for more information.

<!-- 1882732d-ffcd-4a0a-a937-5764449f0507 <=< ACCEPT -->       WITH OIDS
       WITHOUT OIDS
           These are obsolescent syntaxes equivalent to WITH (OIDS) and WITH
           (OIDS=FALSE), respectively. If you wish to give both an OIDS
           setting and storage parameters, you must use the WITH ( ... )
           syntax; see above.

       ON COMMIT
           The behavior of temporary tables at the end of a transaction block
           can be controlled using ON COMMIT. The three options are:

           PRESERVE ROWS
               No special action is taken at the ends of transactions. This is
               the default behavior.

           DELETE ROWS
               All rows in the temporary table will be deleted at the end of
               each transaction block. Essentially, an automatic TRUNCATE(7)
               is done at each commit.

           DROP
               The temporary table will be dropped at the end of the current
               transaction block.

       TABLESPACE tablespace_name
           The tablespace_name is the name of the tablespace in which the new
           table is to be created. If not specified, default_tablespace is
           consulted, or temp_tablespaces if the table is temporary.<!-- ACCEPT >=> 1882732d-ffcd-4a0a-a937-5764449f0507 -->

       query
           A SELECT(7), TABLE, or VALUES(7) command, or an EXECUTE(7) command
           that runs a prepared SELECT, TABLE, or VALUES query.

       WITH [ NO ] DATA
           This clause specifies whether or not the data produced by the query
           should be copied into the new table. If not, only the table
           structure is copied. The default is to copy the data.

NOTES
       This command is functionally similar to SELECT INTO (SELECT_INTO(7)),
       but it is preferred since it is less likely to be confused with other
       uses of the SELECT INTO syntax. Furthermore, CREATE TABLE AS offers a
       superset of the functionality offered by SELECT INTO.

       The CREATE TABLE AS command allows the user to explicitly specify
       whether OIDs should be included. If the presence of OIDs is not
       explicitly specified, the default_with_oids configuration variable is
       used.

EXAMPLES
       Create a new table films_recent consisting of only recent entries from
       the table films:

           CREATE TABLE films_recent AS
             SELECT * FROM films WHERE date_prod &amp;gt;= '2002-01-01';

       To copy a table completely, the short form using the TABLE command can
       also be used:

           CREATE TABLE films2 AS
             TABLE films;

       Create a new temporary table films_recent, consisting of only recent
       entries from the table films, using a prepared statement. The new table
       has OIDs and will be dropped at commit:

           PREPARE recentfilms(date) AS
             SELECT * FROM films WHERE date_prod &amp;gt; $1;
           CREATE TEMP TABLE films_recent WITH (OIDS) ON COMMIT DROP AS
             EXECUTE recentfilms('2002-01-01');

COMPATIBILITY
       CREATE TABLE AS conforms to the SQL standard. The following are
       nonstandard extensions:

       o   The standard requires parentheses around the subquery clause; in
           PostgreSQL, these parentheses are optional.

       o   In the standard, the WITH [ NO ] DATA clause is required; in
           PostgreSQL it is optional.

       o   PostgreSQL handles temporary tables in a way rather different from
           the standard; see CREATE TABLE (CREATE_TABLE(7)) for details.

       o   The WITH clause is a PostgreSQL extension; neither storage
           parameters nor OIDs are in the standard.

       o   The PostgreSQL concept of tablespaces is not part of the standard.
           Hence, the clause TABLESPACE is an extension.

SEE ALSO
       CREATE MATERIALIZED VIEW (CREATE_MATERIALIZED_VIEW(7)), CREATE TABLE
       (CREATE_TABLE(7)), EXECUTE(7), SELECT(7), SELECT INTO (SELECT_INTO(7)),
       VALUES(7)



PostgreSQL 9.6.1                     2016                   CREATE TABLE AS(7)
DROP EVENT TRIGGER(7)   PostgreSQL 9.6.1 Documentation   DROP EVENT TRIGGER(7)



NAME
       DROP_EVENT_TRIGGER - remove an event trigger

SYNOPSIS
       DROP EVENT TRIGGER [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP EVENT TRIGGER removes an existing event trigger. To execute this
       command, the current user must be the owner of the event trigger.

PARAMETERS
       IF EXISTS
           Do not throw an error if the event trigger does not exist. A notice
           is issued in this case.

       name
           The name of the event trigger to remove.

       CASCADE
           Automatically drop objects that depend on the trigger, and in turn
           all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the trigger if any objects depend on it. This is the
           default.

EXAMPLES
       Destroy the trigger snitch:

           DROP EVENT TRIGGER snitch;

COMPATIBILITY
       There is no DROP EVENT TRIGGER statement in the SQL standard.

SEE ALSO
       CREATE EVENT TRIGGER (CREATE_EVENT_TRIGGER(7)), ALTER EVENT TRIGGER
       (ALTER_EVENT_TRIGGER(7))



PostgreSQL 9.6.1                     2016                DROP EVENT TRIGGER(7)
ALTER OPERATOR FAMILY(7)PostgreSQL 9.6.1 DocumentationALTER OPERATOR FAMILY(7)



NAME
       ALTER_OPERATOR_FAMILY - change the definition of an operator family

SYNOPSIS
       ALTER OPERATOR FAMILY name USING index_method ADD
         {  OPERATOR strategy_number operator_name ( op_type, op_type )
                     [ FOR SEARCH | FOR ORDER BY sort_family_name ]
          | FUNCTION support_number [ ( op_type [ , op_type ] ) ]
                     function_name ( argument_type [, ...] )
         } [, ... ]

       ALTER OPERATOR FAMILY name USING index_method DROP
         {  OPERATOR strategy_number ( op_type [ , op_type ] )
          | FUNCTION support_number ( op_type [ , op_type ] )
         } [, ... ]

       ALTER OPERATOR FAMILY name USING index_method
           RENAME TO new_name

       ALTER OPERATOR FAMILY name USING index_method
           OWNER TO { new_owner | CURRENT_USER | SESSION_USER }

       ALTER OPERATOR FAMILY name USING index_method
           SET SCHEMA new_schema

DESCRIPTION
       ALTER OPERATOR FAMILY changes the definition of an operator family. You
       can add operators and support functions to the family, remove them from
       the family, or change the family's name or owner.

       When operators and support functions are added to a family with ALTER
       OPERATOR FAMILY, they are not part of any specific operator class
       within the family, but are just "loose" within the family. This
       indicates that these operators and functions are compatible with the
       family's semantics, but are not required for correct functioning of any
       specific index. (Operators and functions that are so required should be
       declared as part of an operator class, instead; see CREATE OPERATOR
       CLASS (CREATE_OPERATOR_CLASS(7)).)  PostgreSQL will allow loose members
       of a family to be dropped from the family at any time, but members of
       an operator class cannot be dropped without dropping the whole class
       and any indexes that depend on it. Typically, single-data-type
       operators and functions are part of operator classes because they are
       needed to support an index on that specific data type, while
       cross-data-type operators and functions are made loose members of the
       family.

       You must be a superuser to use ALTER OPERATOR FAMILY. (This restriction
       is made because an erroneous operator family definition could confuse
       or even crash the server.)

       ALTER OPERATOR FAMILY does not presently check whether the operator
       family definition includes all the operators and functions required by
       the index method, nor whether the operators and functions form a
       self-consistent set. It is the user's responsibility to define a valid
       operator family.

       Refer to Section 36.14, "Interfacing Extensions To Indexes", in the
       documentation for further information.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing operator
           family.
<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->
       index_method
           The name of the index method this operator family is for.

<!-- 28d4dc75-98b1-41fd-b697-d30923dc9e5c <=< ACCEPT -->       strategy_number
           The index method's strategy number for an operator associated with
           the operator family.

       operator_name
           The name (optionally schema-qualified) of an operator associated
           with the operator family.

       op_type
           In an OPERATOR clause, the operand data type(s) of the operator, or
           NONE to signify a left-unary or right-unary operator. Unlike the
           comparable syntax in CREATE OPERATOR CLASS, the operand data types
           must always be specified.

           In an ADD FUNCTION clause, the operand data type(s) the function is
           intended to support, if different from the input data type(s) of
           the function<!-- ACCEPT >=> 28d4dc75-98b1-41fd-b697-d30923dc9e5c -->. For B-tree comparison functions and hash functions it
           is not necessary to specify op_type since the function's input data
           type(s) are always the correct ones to use. For B-tree sort support
           functions and all functions in GiST, SP-GiST and GIN operator
           classes, it is necessary to specify the operand data type(s) the
           function is to be used with.

           In a DROP FUNCTION clause, the operand data type(s) the function is
           intended to support must be specified.

<!-- 9c2021b2-ea26-4764-9eb3-17e12de3ff8f <=< ACCEPT -->       sort_family_name
           The name (optionally schema-qualified) of an existing btree
           operator family that describes the sort ordering associated with an
           ordering operator.

           If neither FOR SEARCH nor FOR ORDER BY is specified, FOR SEARCH is
           the default.

       support_number
           The index method's support procedure number for a function
           associated with the operator family.

       function_name
           The name (optionally schema-qualified) of a function that is an
           index method support procedure for the operator family.<!-- ACCEPT >=> 9c2021b2-ea26-4764-9eb3-17e12de3ff8f -->

       argument_type
           The parameter data type(s) of the function.

       new_name
           The new name of the operator family.

       new_owner
           The new owner of the operator family.

       new_schema
           The new schema for the operator family.

       The OPERATOR and FUNCTION clauses can appear in any order.

NOTES
       Notice that the DROP syntax only specifies the "slot" in the operator
       family, by strategy or support number and input data type(s). The name
       of the operator or function occupying the slot is not mentioned. Also,
       for DROP FUNCTION the type(s) to specify are the input data type(s) the
       function is intended to support; for GiST, SP-GiST and GIN indexes this
       might have nothing to do with the actual input argument types of the
       function.

<!-- 09520cdb-499e-46bf-946d-3cfcacaa96e0 <=< ACCEPT -->       Because the index machinery does not check access permissions on
       functions before using them, including a function or operator in an
       operator family is tantamount to granting public execute permission on
       it. This is usually not an issue for the sorts of functions that are
       useful in an operator family.

       The operators should not be defined by SQL functions. A SQL function is
       likely to be inlined into the calling query, which will prevent the
       optimizer from recognizing that the query matches an index.

       Before PostgreSQL 8.4, the OPERATOR clause could include a RECHECK
       option. This is no longer supported because whether an index operator
       is "lossy" is now determined on-the-fly at run time. This allows
       efficient handling of cases where an operator might or might not be
       lossy.<!-- ACCEPT >=> 09520cdb-499e-46bf-946d-3cfcacaa96e0 -->

EXAMPLES
       The following example command adds cross-data-type operators and
       support functions to an operator family that already contains B-tree
       operator classes for data types int4 and int2.

           ALTER OPERATOR FAMILY integer_ops USING btree ADD

             -- int4 vs int2
             OPERATOR 1 &amp;lt; (int4, int2) ,
             OPERATOR 2 &amp;lt;= (int4, int2) ,
             OPERATOR 3 = (int4, int2) ,
             OPERATOR 4 &amp;gt;= (int4, int2) ,
             OPERATOR 5 &amp;gt; (int4, int2) ,
             FUNCTION 1 btint42cmp(int4, int2) ,

             -- int2 vs int4
             OPERATOR 1 &amp;lt; (int2, int4) ,
             OPERATOR 2 &amp;lt;= (int2, int4) ,
             OPERATOR 3 = (int2, int4) ,
             OPERATOR 4 &amp;gt;= (int2, int4) ,
             OPERATOR 5 &amp;gt; (int2, int4) ,
             FUNCTION 1 btint24cmp(int2, int4) ;

       To remove these entries again:

           ALTER OPERATOR FAMILY integer_ops USING btree DROP

             -- int4 vs int2
             OPERATOR 1 (int4, int2) ,
             OPERATOR 2 (int4, int2) ,
             OPERATOR 3 (int4, int2) ,
             OPERATOR 4 (int4, int2) ,
             OPERATOR 5 (int4, int2) ,
             FUNCTION 1 (int4, int2) ,

             -- int2 vs int4
             OPERATOR 1 (int2, int4) ,
             OPERATOR 2 (int2, int4) ,
             OPERATOR 3 (int2, int4) ,
             OPERATOR 4 (int2, int4) ,
             OPERATOR 5 (int2, int4) ,
             FUNCTION 1 (int2, int4) ;

COMPATIBILITY
       There is no ALTER OPERATOR FAMILY statement in the SQL standard.

SEE ALSO
       CREATE OPERATOR FAMILY (CREATE_OPERATOR_FAMILY(7)), DROP OPERATOR
       FAMILY (DROP_OPERATOR_FAMILY(7)), CREATE OPERATOR CLASS
       (CREATE_OPERATOR_CLASS(7)), ALTER OPERATOR CLASS
       (ALTER_OPERATOR_CLASS(7)), DROP OPERATOR CLASS (DROP_OPERATOR_CLASS(7))



PostgreSQL 9.6.1                     2016             ALTER OPERATOR FAMILY(7)
START TRANSACTION(7)    PostgreSQL 9.6.1 Documentation    START TRANSACTION(7)



NAME
       START_TRANSACTION - start a transaction block

SYNOPSIS
       START TRANSACTION [ transaction_mode [, ...] ]

       where transaction_mode is one of:

           ISOLATION LEVEL { SERIALIZABLE | REPEATABLE READ | READ COMMITTED | READ UNCOMMITTED }
           READ WRITE | READ ONLY
           [ NOT ] DEFERRABLE

DESCRIPTION
       This command begins a new transaction block. If the isolation level,
       read/write mode, or deferrable mode is specified, the new transaction
       has those characteristics, as if SET TRANSACTION (SET_TRANSACTION(7))
       was executed. This is the same as the BEGIN(7) command.

PARAMETERS
       Refer to SET TRANSACTION (SET_TRANSACTION(7)) for information on the
       meaning of the parameters to this statement.

COMPATIBILITY
       In the standard, it is not necessary to issue START TRANSACTION to
       start a transaction block: any SQL command implicitly begins a block.
       PostgreSQL's behavior can be seen as implicitly issuing a COMMIT after
       each command that does not follow START TRANSACTION (or BEGIN), and it
       is therefore often called "autocommit". Other relational database
       systems might offer an autocommit feature as a convenience.

       The DEFERRABLEtransaction_mode is a PostgreSQL language extension.

       The SQL standard requires commas between successive transaction_modes,
       but for historical reasons PostgreSQL allows the commas to be omitted.

       See also the compatibility section of SET TRANSACTION
       (SET_TRANSACTION(7)).

SEE ALSO
       BEGIN(7), COMMIT(7), ROLLBACK(7), SAVEPOINT(7), SET TRANSACTION
       (SET_TRANSACTION(7))



PostgreSQL 9.6.1                     2016                 START TRANSACTION(7)
ALTER POLICY(7)         PostgreSQL 9.6.1 Documentation         ALTER POLICY(7)



NAME
       ALTER_POLICY - change the definition of a row level security policy

SYNOPSIS
       ALTER POLICY name ON table_name RENAME TO new_name

       ALTER POLICY name ON table_name
           [ TO { role_name | PUBLIC | CURRENT_USER | SESSION_USER } [, ...] ]
           [ USING ( using_expression ) ]
           [ WITH CHECK ( check_expression ) ]

DESCRIPTION
       ALTER POLICY changes the definition of an existing row-level security
       policy.

       To use ALTER POLICY, you must own the table that the policy applies to.

       In the second form of ALTER POLICY, the role list, using_expression,
       and check_expression are replaced independently if specified. When one
       of those clauses is omitted, the corresponding part of the policy is
       unchanged.

PARAMETERS
       name
           The name of an existing policy to alter.

       table_name
           The name (optionally schema-qualified) of the table that the policy
           is on.

       new_name
           The new name for the policy.

       role_name
           The role(s) to which the policy applies. Multiple roles can be
           specified at one time. To apply the policy to all roles, use
           PUBLIC.

       using_expression
           The USING expression for the policy. See CREATE POLICY
           (CREATE_POLICY(7)) for details.

       check_expression
           The WITH CHECK expression for the policy. See CREATE POLICY
           (CREATE_POLICY(7)) for details.

COMPATIBILITY
       ALTER POLICY is a PostgreSQL extension.

SEE ALSO
       CREATE POLICY (CREATE_POLICY(7)), DROP POLICY (DROP_POLICY(7))



PostgreSQL 9.6.1                     2016                      ALTER POLICY(7)

DROP LANGUAGE(7)        PostgreSQL 9.6.1 Documentation        DROP LANGUAGE(7)



NAME
       DROP_LANGUAGE - remove a procedural language

SYNOPSIS
       DROP [ PROCEDURAL ] LANGUAGE [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP LANGUAGE removes the definition of a previously registered
       procedural language. You must be a superuser or the owner of the
       language to use DROP LANGUAGE.

           Note
           As of PostgreSQL 9.1, most procedural languages have been made into
           "extensions", and should therefore be removed with DROP EXTENSION
           (DROP_EXTENSION(7)) not DROP LANGUAGE.

PARAMETERS
       IF EXISTS
           Do not throw an error if the language does not exist. A notice is
           issued in this case.

       name
           The name of an existing procedural language. For backward
           compatibility, the name can be enclosed by single quotes.

       CASCADE
           Automatically drop objects that depend on the language (such as
           functions in the language), and in turn all objects that depend on
           those objects (see Section 5.13, "Dependency Tracking", in the
           documentation).

       RESTRICT
           Refuse to drop the language if any objects depend on it. This is
           the default.

EXAMPLES
       This command removes the procedural language plsample:

           DROP LANGUAGE plsample;

COMPATIBILITY
       There is no DROP LANGUAGE statement in the SQL standard.

SEE ALSO
       ALTER LANGUAGE (ALTER_LANGUAGE(7)), CREATE LANGUAGE
       (CREATE_LANGUAGE(7)), droplang(1)



PostgreSQL 9.6.1                     2016                     DROP LANGUAGE(7)
COMMENT(7)              PostgreSQL 9.6.1 Documentation              COMMENT(7)



NAME
       COMMENT - define or change the comment of an object

SYNOPSIS
       COMMENT ON
       {
         ACCESS METHOD object_name |
         AGGREGATE aggregate_name ( aggregate_signature ) |
         CAST (source_type AS target_type) |
         COLLATION object_name |
         COLUMN relation_name.column_name |
         CONSTRAINT constraint_name ON table_name |
         CONSTRAINT constraint_name ON DOMAIN domain_name |
         CONVERSION object_name |
         DATABASE object_name |
         DOMAIN object_name |
         EXTENSION object_name |
         EVENT TRIGGER object_name |
         FOREIGN DATA WRAPPER object_name |
         FOREIGN TABLE object_name |
         FUNCTION function_name ( [ [ argmode ] [ argname ] argtype [, ...] ] ) |
         INDEX object_name |
         LARGE OBJECT large_object_oid |
         MATERIALIZED VIEW object_name |
         OPERATOR operator_name (left_type, right_type) |
         OPERATOR CLASS object_name USING index_method |
         OPERATOR FAMILY object_name USING index_method |
         POLICY policy_name ON table_name |
         [ PROCEDURAL ] LANGUAGE object_name |
         ROLE object_name |
         RULE rule_name ON table_name |
         SCHEMA object_name |
         SEQUENCE object_name |
         SERVER object_name |
         TABLE object_name |
         TABLESPACE object_name |
         TEXT SEARCH CONFIGURATION object_name |
         TEXT SEARCH DICTIONARY object_name |
         TEXT SEARCH PARSER object_name |
         TEXT SEARCH TEMPLATE object_name |
         TRANSFORM FOR type_name LANGUAGE lang_name |
         TRIGGER trigger_name ON table_name |
         TYPE object_name |
         VIEW object_name
       } IS 'text'

       where aggregate_signature is:

       * |
       [ argmode ] [ argname ] argtype [ , ... ] |
       [ [ argmode ] [ argname ] argtype [ , ... ] ] ORDER BY [ argmode ] [ argname ] argtype [ , ... ]

DESCRIPTION
       COMMENT stores a comment about a database object.

       Only one comment string is stored for each object, so to modify a
       comment, issue a new COMMENT command for the same object. To remove a
       comment, write NULL in place of the text string. Comments are
       automatically dropped when their object is dropped.

       For most kinds of object, only the object's owner can set the comment.
       Roles don't have owners, so the rule for COMMENT ON ROLE is that you
       must be superuser to comment on a superuser role, or have the
       CREATEROLE privilege to comment on non-superuser roles. Likewise,
       access methods don't have owners either; you must be superuser to
       comment on an access method. Of course, a superuser can comment on
       anything.

       Comments can be viewed using psql's \d family of commands. Other user
       interfaces to retrieve comments can be built atop the same built-in
       functions that psql uses, namely obj_description, col_description, and
       shobj_description (see Table 9.67, "Comment Information Functions").

PARAMETERS
       object_name
       relation_name.column_name
       aggregate_name
       constraint_name
       function_name
       operator_name
       policy_name
       rule_name
       trigger_name
           The name of the object to be commented. Names of tables,
           aggregates, collations, conversions, domains, foreign tables,
           functions, indexes, operators, operator classes, operator families,
           sequences, text search objects, types, and views can be
           schema-qualified. When commenting on a column, relation_name must
           refer to a table, view, composite type, or foreign table.

       table_name
       domain_name
           When creating a comment on a constraint, a trigger, a rule or a
           policy these parameters specify the name of the table or domain on
           which that object is defined.

       source_type
           The name of the source data type of the cast.

       target_type
           The name of the target data type of the cast.

<!-- e06c3d92-4723-4dc4-a00a-ed8adc236e70 <=< ACCEPT -->       argmode
           The mode of a function or aggregate argument: IN, OUT, INOUT, or
           VARIADIC. If omitted, the default is IN. Note that COMMENT does not
           actually pay any attention to OUT arguments, since only the input
           arguments are needed to determine the function's identity. So it is
           sufficient to list the IN, INOUT, and VARIADIC arguments.

       argname
           The name of a function or aggregate argument. Note that COMMENT
           does not actually pay any attention to argument names, since only
           the argument data types are needed to determine the function's
           identity.

       argtype
           The data type of a function or aggregate argument.<!-- ACCEPT >=> e06c3d92-4723-4dc4-a00a-ed8adc236e70 -->

       large_object_oid
           The OID of the large object.

<!-- 475300f3-c025-4674-80e5-f48559d8b392 <=< ACCEPT -->       left_type
       right_type
           The data type(s) of the operator's arguments (optionally
           schema-qualified). Write NONE for the missing argument of a prefix
           or postfix operator.

       PROCEDURAL
           This is a noise word.

       type_name
           The name of the data type of the transform.

       lang_name
           The name of the language of the transform.<!-- ACCEPT >=> 475300f3-c025-4674-80e5-f48559d8b392 -->

       text
           The new comment, written as a string literal; or NULL to drop the
           comment.

NOTES
       There is presently no security mechanism for viewing comments: any user
       connected to a database can see all the comments for objects in that
       database. For shared objects such as databases, roles, and tablespaces,
       comments are stored globally so any user connected to any database in
       the cluster can see all the comments for shared objects. Therefore,
       don't put security-critical information in comments.

EXAMPLES
       Attach a comment to the table mytable:

           COMMENT ON TABLE mytable IS 'This is my table.';

       Remove it again:

           COMMENT ON TABLE mytable IS NULL;

       Some more examples:

           COMMENT ON ACCESS METHOD rtree IS 'R-Tree access method';
           COMMENT ON AGGREGATE my_aggregate (double precision) IS 'Computes sample variance';
           COMMENT ON CAST (text AS int4) IS 'Allow casts from text to int4';
           COMMENT ON COLLATION "fr_CA" IS 'Canadian French';
           COMMENT ON COLUMN my_table.my_column IS 'Employee ID number';
           COMMENT ON CONVERSION my_conv IS 'Conversion to UTF8';
           COMMENT ON CONSTRAINT bar_col_cons ON bar IS 'Constrains column col';
           COMMENT ON CONSTRAINT dom_col_constr ON DOMAIN dom IS 'Constrains col of domain';
           COMMENT ON DATABASE my_database IS 'Development Database';
           COMMENT ON DOMAIN my_domain IS 'Email Address Domain';
           COMMENT ON EXTENSION hstore IS 'implements the hstore data type';
           COMMENT ON FOREIGN DATA WRAPPER mywrapper IS 'my foreign data wrapper';
           COMMENT ON FOREIGN TABLE my_foreign_table IS 'Employee Information in other database';
           COMMENT ON FUNCTION my_function (timestamp) IS 'Returns Roman Numeral';
           COMMENT ON INDEX my_index IS 'Enforces uniqueness on employee ID';
           COMMENT ON LANGUAGE plpython IS 'Python support for stored procedures';
           COMMENT ON LARGE OBJECT 346344 IS 'Planning document';
           COMMENT ON MATERIALIZED VIEW my_matview IS 'Summary of order history';
           COMMENT ON OPERATOR ^ (text, text) IS 'Performs intersection of two texts';
           COMMENT ON OPERATOR - (NONE, integer) IS 'Unary minus';
           COMMENT ON OPERATOR CLASS int4ops USING btree IS '4 byte integer operators for btrees';
           COMMENT ON OPERATOR FAMILY integer_ops USING btree IS 'all integer operators for btrees';
           COMMENT ON POLICY my_policy ON mytable IS 'Filter rows by users';
           COMMENT ON ROLE my_role IS 'Administration group for finance tables';
           COMMENT ON RULE my_rule ON my_table IS 'Logs updates of employee records';
           COMMENT ON SCHEMA my_schema IS 'Departmental data';
           COMMENT ON SEQUENCE my_sequence IS 'Used to generate primary keys';
           COMMENT ON SERVER myserver IS 'my foreign server';
           COMMENT ON TABLE my_schema.my_table IS 'Employee Information';
           COMMENT ON TABLESPACE my_tablespace IS 'Tablespace for indexes';
           COMMENT ON TEXT SEARCH CONFIGURATION my_config IS 'Special word filtering';
           COMMENT ON TEXT SEARCH DICTIONARY swedish IS 'Snowball stemmer for Swedish language';
           COMMENT ON TEXT SEARCH PARSER my_parser IS 'Splits text into words';
           COMMENT ON TEXT SEARCH TEMPLATE snowball IS 'Snowball stemmer';
           COMMENT ON TRANSFORM FOR hstore LANGUAGE plpythonu IS 'Transform between hstore and Python dict';
           COMMENT ON TRIGGER my_trigger ON my_table IS 'Used for RI';
           COMMENT ON TYPE complex IS 'Complex number data type';
           COMMENT ON VIEW my_view IS 'View of departmental costs';

COMPATIBILITY
       There is no COMMENT command in the SQL standard.



PostgreSQL 9.6.1                     2016                           COMMENT(7)
ALTER RULE(7)           PostgreSQL 9.6.1 Documentation           ALTER RULE(7)



NAME
       ALTER_RULE - change the definition of a rule

SYNOPSIS
       ALTER RULE name ON table_name RENAME TO new_name

DESCRIPTION
       ALTER RULE changes properties of an existing rule. Currently, the only
       available action is to change the rule's name.

       To use ALTER RULE, you must own the table or view that the rule applies
       to.

PARAMETERS
       name
           The name of an existing rule to alter.

       table_name
           The name (optionally schema-qualified) of the table or view that
           the rule applies to.

       new_name
           The new name for the rule.

EXAMPLES
       To rename an existing rule:

           ALTER RULE notify_all ON emp RENAME TO notify_me;

COMPATIBILITY
       ALTER RULE is a PostgreSQL language extension, as is the entire query
       rewrite system.

SEE ALSO
       CREATE RULE (CREATE_RULE(7)), DROP RULE (DROP_RULE(7))



PostgreSQL 9.6.1                     2016                        ALTER RULE(7)
DROP AGGREGATE(7)       PostgreSQL 9.6.1 Documentation       DROP AGGREGATE(7)



NAME
       DROP_AGGREGATE - remove an aggregate function

SYNOPSIS
       DROP AGGREGATE [ IF EXISTS ] name ( aggregate_signature ) [ CASCADE | RESTRICT ]

       where aggregate_signature is:

       * |
       [ argmode ] [ argname ] argtype [ , ... ] |
       [ [ argmode ] [ argname ] argtype [ , ... ] ] ORDER BY [ argmode ] [ argname ] argtype [ , ... ]

DESCRIPTION
       DROP AGGREGATE removes an existing aggregate function. To execute this
       command the current user must be the owner of the aggregate function.

PARAMETERS
       IF EXISTS
           Do not throw an error if the aggregate does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing aggregate
           function.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

<!-- 4621cdbd-9d59-444b-9354-d5b42500378a <=< ACCEPT -->       argmode
           The mode of an argument: IN or VARIADIC. If omitted, the default is
           IN.

       argname
           The name of an argument. Note that DROP AGGREGATE does not actually
           pay any attention to argument names, since only the argument data
           types are needed to determine the aggregate function's identity.

       argtype
           An input data type on which the aggregate function operates. To
           reference a zero-argument aggregate function, write * in place of
           the list of argument specifications. To reference an ordered-set
           aggregate function, write ORDER BY between the direct and
           aggregated argument specifications.<!-- ACCEPT >=> 4621cdbd-9d59-444b-9354-d5b42500378a -->

       CASCADE
           Automatically drop objects that depend on the aggregate function
           (such as views using it), and in turn all objects that depend on
           those objects (see Section 5.13, "Dependency Tracking", in the
           documentation).

       RESTRICT
           Refuse to drop the aggregate function if any objects depend on it.
           This is the default.

NOTES
       Alternative syntaxes for referencing ordered-set aggregates are
       described under ALTER AGGREGATE (ALTER_AGGREGATE(7)).

EXAMPLES
       To remove the aggregate function myavg for type integer:

           DROP AGGREGATE myavg(integer);

       To remove the hypothetical-set aggregate function myrank, which takes
       an arbitrary list of ordering columns and a matching list of direct
       arguments:

           DROP AGGREGATE myrank(VARIADIC "any" ORDER BY VARIADIC "any");


COMPATIBILITY
       There is no DROP AGGREGATE statement in the SQL standard.

SEE ALSO
       ALTER AGGREGATE (ALTER_AGGREGATE(7)), CREATE AGGREGATE
       (CREATE_AGGREGATE(7))



PostgreSQL 9.6.1                     2016                    DROP AGGREGATE(7)
EXPLAIN(7)              PostgreSQL 9.6.1 Documentation              EXPLAIN(7)



NAME
       EXPLAIN - show the execution plan of a statement

SYNOPSIS
       EXPLAIN [ ( option [, ...] ) ] statement
       EXPLAIN [ ANALYZE ] [ VERBOSE ] statement

       where option can be one of:

           ANALYZE [ boolean ]
           VERBOSE [ boolean ]
           COSTS [ boolean ]
           BUFFERS [ boolean ]
           TIMING [ boolean ]
           FORMAT { TEXT | XML | JSON | YAML }

DESCRIPTION
       This command displays the execution plan that the PostgreSQL planner
       generates for the supplied statement. The execution plan shows how the
       table(s) referenced by the statement will be scanned -- by plain
       sequential scan, index scan, etc. -- and if multiple tables are
       referenced, what join algorithms will be used to bring together the
       required rows from each input table.

       The most critical part of the display is the estimated statement
       execution cost, which is the planner's guess at how long it will take
       to run the statement (measured in cost units that are arbitrary, but
       conventionally mean disk page fetches). Actually two numbers are shown:
       the start-up cost before the first row can be returned, and the total
       cost to return all the rows. For most queries the total cost is what
       matters, but in contexts such as a subquery in EXISTS, the planner will
       choose the smallest start-up cost instead of the smallest total cost
       (since the executor will stop after getting one row, anyway). Also, if
       you limit the number of rows to return with a LIMIT clause, the planner
       makes an appropriate interpolation between the endpoint costs to
       estimate which plan is really the cheapest.

       The ANALYZE option causes the statement to be actually executed, not
       only planned. Then actual run time statistics are added to the display,
       including the total elapsed time expended within each plan node (in
       milliseconds) and the total number of rows it actually returned. This
       is useful for seeing whether the planner's estimates are close to
       reality.

           Important
           Keep in mind that the statement is actually executed when the
           ANALYZE option is used. Although EXPLAIN will discard any output
           that a SELECT would return, other side effects of the statement
           will happen as usual. If you wish to use EXPLAIN ANALYZE on an
           INSERT, UPDATE, DELETE, CREATE TABLE AS, or EXECUTE statement
           without letting the command affect your data, use this approach:

               BEGIN;
               EXPLAIN ANALYZE ...;
               ROLLBACK;

       Only the ANALYZE and VERBOSE options can be specified, and only in that
       order, without surrounding the option list in parentheses. Prior to
       PostgreSQL 9.0, the unparenthesized syntax was the only one supported.
       It is expected that all new options will be supported only in the
       parenthesized syntax.

PARAMETERS
       ANALYZE
           Carry out the command and show actual run times and other
           statistics. This parameter defaults to FALSE.

       VERBOSE
           Display additional information regarding the plan. Specifically,
           include the output column list for each node in the plan tree,
           schema-qualify table and function names, always label variables in
           expressions with their range table alias, and always print the name
           of each trigger for which statistics are displayed. This parameter
           defaults to FALSE.

       COSTS
           Include information on the estimated startup and total cost of each
           plan node, as well as the estimated number of rows and the
           estimated width of each row. This parameter defaults to TRUE.

       BUFFERS
           Include information on buffer usage. Specifically, include the
           number of shared blocks hit, read, dirtied, and written, the number
           of local blocks hit, read, dirtied, and written, and the number of
           temp blocks read and written. A hit means that a read was avoided
           because the block was found already in cache when needed. Shared
           blocks contain data from regular tables and indexes; local blocks
           contain data from temporary tables and indexes; while temp blocks
           contain short-term working data used in sorts, hashes, Materialize
           plan nodes, and similar cases. The number of blocks dirtied
           indicates the number of previously unmodified blocks that were
           changed by this query; while the number of blocks written indicates
           the number of previously-dirtied blocks evicted from cache by this
           backend during query processing. The number of blocks shown for an
           upper-level node includes those used by all its child nodes. In
           text format, only non-zero values are printed. This parameter may
           only be used when ANALYZE is also enabled. It defaults to FALSE.

       TIMING
           Include actual startup time and time spent in each node in the
           output. The overhead of repeatedly reading the system clock can
           slow down the query significantly on some systems, so it may be
           useful to set this parameter to FALSE when only actual row counts,
           and not exact times, are needed. Run time of the entire statement
           is always measured, even when node-level timing is turned off with
           this option. This parameter may only be used when ANALYZE is also
           enabled. It defaults to TRUE.

       FORMAT
           Specify the output format, which can be TEXT, XML, JSON, or YAML.
           Non-text output contains the same information as the text output
           format, but is easier for programs to parse. This parameter
           defaults to TEXT.

       boolean
           Specifies whether the selected option should be turned on or off.
           You can write TRUE, ON, or 1 to enable the option, and FALSE, OFF,
           or 0 to disable it. The boolean value can also be omitted, in which
           case TRUE is assumed.

       statement
           Any SELECT, INSERT, UPDATE, DELETE, VALUES, EXECUTE, DECLARE,
           CREATE TABLE AS, or CREATE MATERIALIZED VIEW AS statement, whose
           execution plan you wish to see.

OUTPUTS
       The command's result is a textual description of the plan selected for
       the statement, optionally annotated with execution statistics.  Section
       14.1, "Using EXPLAIN", in the documentation describes the information
       provided.

NOTES
       In order to allow the PostgreSQL query planner to make reasonably
       informed decisions when optimizing queries, the pg_statistic data
       should be up-to-date for all tables used in the query. Normally the
       autovacuum daemon will take care of that automatically. But if a table
       has recently had substantial changes in its contents, you might need to
       do a manual ANALYZE(7) rather than wait for autovacuum to catch up with
       the changes.

       In order to measure the run-time cost of each node in the execution
       plan, the current implementation of EXPLAIN ANALYZE adds profiling
       overhead to query execution. As a result, running EXPLAIN ANALYZE on a
       query can sometimes take significantly longer than executing the query
       normally. The amount of overhead depends on the nature of the query, as
       well as the platform being used. The worst case occurs for plan nodes
       that in themselves require very little time per execution, and on
       machines that have relatively slow operating system calls for obtaining
       the time of day.

EXAMPLES
       To show the plan for a simple query on a table with a single integer
       column and 10000 rows:

           EXPLAIN SELECT * FROM foo;

                                  QUERY PLAN
           ---------------------------------------------------------
            Seq Scan on foo  (cost=0.00..155.00 rows=10000 width=4)
           (1 row)

       Here is the same query, with JSON output formatting:

           EXPLAIN (FORMAT JSON) SELECT * FROM foo;
                      QUERY PLAN
           --------------------------------
            [                             +
              {                           +
                "Plan": {                 +
                  "Node Type": "Seq Scan",+
                  "Relation Name": "foo", +
                  "Alias": "foo",         +
                  "Startup Cost": 0.00,   +
                  "Total Cost": 155.00,   +
                  "Plan Rows": 10000,     +
                  "Plan Width": 4         +
                }                         +
              }                           +
            ]
           (1 row)

       If there is an index and we use a query with an indexable WHERE
       condition, EXPLAIN might show a different plan:

           EXPLAIN SELECT * FROM foo WHERE i = 4;

                                    QUERY PLAN
           --------------------------------------------------------------
            Index Scan using fi on foo  (cost=0.00..5.98 rows=1 width=4)
              Index Cond: (i = 4)
           (2 rows)

       Here is the same query, but in YAML format:

           EXPLAIN (FORMAT YAML) SELECT * FROM foo WHERE i='4';
                     QUERY PLAN
           -------------------------------
            - Plan:                      +
                Node Type: "Index Scan"  +
                Scan Direction: "Forward"+
                Index Name: "fi"         +
                Relation Name: "foo"     +
                Alias: "foo"             +
                Startup Cost: 0.00       +
                Total Cost: 5.98         +
                Plan Rows: 1             +
                Plan Width: 4            +
                Index Cond: "(i = 4)"
           (1 row)

       XML format is left as an exercise for the reader.

       Here is the same plan with cost estimates suppressed:

           EXPLAIN (COSTS FALSE) SELECT * FROM foo WHERE i = 4;

                   QUERY PLAN
           ----------------------------
            Index Scan using fi on foo
              Index Cond: (i = 4)
           (2 rows)

       Here is an example of a query plan for a query using an aggregate
       function:

           EXPLAIN SELECT sum(i) FROM foo WHERE i &amp;lt; 10;

                                        QUERY PLAN
           ---------------------------------------------------------------------
            Aggregate  (cost=23.93..23.93 rows=1 width=4)
              -&amp;gt;  Index Scan using fi on foo  (cost=0.00..23.92 rows=6 width=4)
                    Index Cond: (i &amp;lt; 10)
           (3 rows)

       Here is an example of using EXPLAIN EXECUTE to display the execution
       plan for a prepared query:

           PREPARE query(int, int) AS SELECT sum(bar) FROM test
               WHERE id &amp;gt; $1 AND id &amp;lt; $2
               GROUP BY foo;

           EXPLAIN ANALYZE EXECUTE query(100, 200);

                                                                  QUERY PLAN
           ------------------------------------------------------------------------------------------------------------------------
            HashAggregate  (cost=9.54..9.54 rows=1 width=8) (actual time=0.156..0.161 rows=11 loops=1)
              Group Key: foo
              -&amp;gt;  Index Scan using test_pkey on test  (cost=0.29..9.29 rows=50 width=8) (actual time=0.039..0.091 rows=99 loops=1)
                    Index Cond: ((id &amp;gt; $1) AND (id &amp;lt; $2))
            Planning time: 0.197 ms
            Execution time: 0.225 ms
           (6 rows)

       Of course, the specific numbers shown here depend on the actual
       contents of the tables involved. Also note that the numbers, and even
       the selected query strategy, might vary between PostgreSQL releases due
       to planner improvements. In addition, the ANALYZE command uses random
       sampling to estimate data statistics; therefore, it is possible for
       cost estimates to change after a fresh run of ANALYZE, even if the
       actual distribution of data in the table has not changed.

COMPATIBILITY
       There is no EXPLAIN statement defined in the SQL standard.

SEE ALSO
       ANALYZE(7)



PostgreSQL 9.6.1                     2016                           EXPLAIN(7)
DROP TYPE(7)            PostgreSQL 9.6.1 Documentation            DROP TYPE(7)



NAME
       DROP_TYPE - remove a data type

SYNOPSIS
       DROP TYPE [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP TYPE removes a user-defined data type. Only the owner of a type
       can remove it.

PARAMETERS
       IF EXISTS
           Do not throw an error if the type does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the data type to remove.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the type (such as table
           columns, functions, and operators), and in turn all objects that
           depend on those objects (see Section 5.13, "Dependency Tracking",
           in the documentation).

       RESTRICT
           Refuse to drop the type if any objects depend on it. This is the
           default.

EXAMPLES
       To remove the data type box:

           DROP TYPE box;

COMPATIBILITY
       This command is similar to the corresponding command in the SQL
       standard, apart from the IF EXISTS option, which is a PostgreSQL
       extension. But note that much of the CREATE TYPE command and the data
       type extension mechanisms in PostgreSQL differ from the SQL standard.

SEE ALSO
       ALTER TYPE (ALTER_TYPE(7)), CREATE TYPE (CREATE_TYPE(7))



PostgreSQL 9.6.1                     2016                         DROP TYPE(7)
CREATE CAST(7)          PostgreSQL 9.6.1 Documentation          CREATE CAST(7)



NAME
       CREATE_CAST - define a new cast

SYNOPSIS
       CREATE CAST (source_type AS target_type)
           WITH FUNCTION function_name (argument_type [, ...])
           [ AS ASSIGNMENT | AS IMPLICIT ]

       CREATE CAST (source_type AS target_type)
           WITHOUT FUNCTION
           [ AS ASSIGNMENT | AS IMPLICIT ]

       CREATE CAST (source_type AS target_type)
           WITH INOUT
           [ AS ASSIGNMENT | AS IMPLICIT ]

DESCRIPTION
       CREATE CAST defines a new cast. A cast specifies how to perform a
       conversion between two data types. For example,

           SELECT CAST(42 AS float8);

       converts the integer constant 42 to type float8 by invoking a
       previously specified function, in this case float8(int4). (If no
       suitable cast has been defined, the conversion fails.)

       Two types can be binary coercible, which means that the conversion can
       be performed "for free" without invoking any function. This requires
       that corresponding values use the same internal representation. For
       instance, the types text and varchar are binary coercible both ways.
       Binary coercibility is not necessarily a symmetric relationship. For
       example, the cast from xml to text can be performed for free in the
       present implementation, but the reverse direction requires a function
       that performs at least a syntax check. (Two types that are binary
       coercible both ways are also referred to as binary compatible.)

       You can define a cast as an I/O conversion cast by using the WITH INOUT
       syntax. An I/O conversion cast is performed by invoking the output
       function of the source data type, and passing the resulting string to
       the input function of the target data type. In many common cases, this
       feature avoids the need to write a separate cast function for
       conversion. An I/O conversion cast acts the same as a regular
       function-based cast; only the implementation is different.

       By default, a cast can be invoked only by an explicit cast request,
       that is an explicit CAST(x AS typename) or x::typename construct.

       If the cast is marked AS ASSIGNMENT then it can be invoked implicitly
       when assigning a value to a column of the target data type. For
       example, supposing that foo.f1 is a column of type text, then:

           INSERT INTO foo (f1) VALUES (42);

       will be allowed if the cast from type integer to type text is marked AS
       ASSIGNMENT, otherwise not. (We generally use the term assignment cast
       to describe this kind of cast.)

       If the cast is marked AS IMPLICIT then it can be invoked implicitly in
       any context, whether assignment or internally in an expression. (We
       generally use the term implicit cast to describe this kind of cast.)
       For example, consider this query:

           SELECT 2 + 4.0;

       The parser initially marks the constants as being of type integer and
       numeric respectively. There is no integer+numeric operator in the
       system catalogs, but there is a numeric+numeric operator. The query
       will therefore succeed if a cast from integer to numeric is available
       and is marked AS IMPLICIT -- which in fact it is. The parser will apply
       the implicit cast and resolve the query as if it had been written

           SELECT CAST ( 2 AS numeric ) + 4.0;

       Now, the catalogs also provide a cast from numeric to integer. If that
       cast were marked AS IMPLICIT -- which it is not -- then the parser
       would be faced with choosing between the above interpretation and the
       alternative of casting the numeric constant to integer and applying the
       integer+integer operator. Lacking any knowledge of which choice to
       prefer, it would give up and declare the query ambiguous. The fact that
       only one of the two casts is implicit is the way in which we teach the
       parser to prefer resolution of a mixed numeric-and-integer expression
       as numeric; there is no built-in knowledge about that.

       It is wise to be conservative about marking casts as implicit. An
       overabundance of implicit casting paths can cause PostgreSQL to choose
       surprising interpretations of commands, or to be unable to resolve
       commands at all because there are multiple possible interpretations. A
       good rule of thumb is to make a cast implicitly invokable only for
       information-preserving transformations between types in the same
       general type category. For example, the cast from int2 to int4 can
       reasonably be implicit, but the cast from float8 to int4 should
       probably be assignment-only. Cross-type-category casts, such as text to
       int4, are best made explicit-only.

           Note
           Sometimes it is necessary for usability or standards-compliance
           reasons to provide multiple implicit casts among a set of types,
           resulting in ambiguity that cannot be avoided as above. The parser
           has a fallback heuristic based on type categories and preferred
           types that can help to provide desired behavior in such cases. See
           CREATE TYPE (CREATE_TYPE(7)) for more information.

       To be able to create a cast, you must own the source or the target data
       type and have USAGE privilege on the other type. To create a
       binary-coercible cast, you must be superuser. (This restriction is made
       because an erroneous binary-coercible cast conversion can easily crash
       the server.)

PARAMETERS
       source_type
           The name of the source data type of the cast.

       target_type
           The name of the target data type of the cast.

       function_name(argument_type [, ...])
           The function used to perform the cast. The function name can be
           schema-qualified. If it is not, the function will be looked up in
           the schema search path. The function's result data type must match
           the target type of the cast. Its arguments are discussed below.

       WITHOUT FUNCTION
           Indicates that the source type is binary-coercible to the target
           type, so no function is required to perform the cast.

       WITH INOUT
           Indicates that the cast is an I/O conversion cast, performed by
           invoking the output function of the source data type, and passing
           the resulting string to the input function of the target data type.

       AS ASSIGNMENT
           Indicates that the cast can be invoked implicitly in assignment
           contexts.

       AS IMPLICIT
           Indicates that the cast can be invoked implicitly in any context.

       Cast implementation functions can have one to three arguments. The
       first argument type must be identical to or binary-coercible from the
       cast's source type. The second argument, if present, must be type
       integer; it receives the type modifier associated with the destination
       type, or -1 if there is none. The third argument, if present, must be
       type boolean; it receives true if the cast is an explicit cast, false
       otherwise. (Bizarrely, the SQL standard demands different behaviors for
       explicit and implicit casts in some cases. This argument is supplied
       for functions that must implement such casts. It is not recommended
       that you design your own data types so that this matters.)

       The return type of a cast function must be identical to or
       binary-coercible to the cast's target type.

       Ordinarily a cast must have different source and target data types.
       However, it is allowed to declare a cast with identical source and
       target types if it has a cast implementation function with more than
       one argument. This is used to represent type-specific length coercion
       functions in the system catalogs. The named function is used to coerce
       a value of the type to the type modifier value given by its second
       argument.

       When a cast has different source and target types and a function that
       takes more than one argument, it supports converting from one type to
       another and applying a length coercion in a single step. When no such
       entry is available, coercion to a type that uses a type modifier
       involves two cast steps, one to convert between data types and a second
       to apply the modifier.

       A cast to or from a domain type currently has no effect. Casting to or
       from a domain uses the casts associated with its underlying type.

NOTES
       Use DROP CAST (DROP_CAST(7)) to remove user-defined casts.

       Remember that if you want to be able to convert types both ways you
       need to declare casts both ways explicitly.

       It is normally not necessary to create casts between user-defined types
       and the standard string types (text, varchar, and char(n), as well as
       user-defined types that are defined to be in the string category).
       PostgreSQL provides automatic I/O conversion casts for that. The
       automatic casts to string types are treated as assignment casts, while
       the automatic casts from string types are explicit-only. You can
       override this behavior by declaring your own cast to replace an
       automatic cast, but usually the only reason to do so is if you want the
       conversion to be more easily invokable than the standard
       assignment-only or explicit-only setting. Another possible reason is
       that you want the conversion to behave differently from the type's I/O
       function; but that is sufficiently surprising that you should think
       twice about whether it's a good idea. (A small number of the built-in
       types do indeed have different behaviors for conversions, mostly
       because of requirements of the SQL standard.)

       While not required, it is recommended that you continue to follow this
       old convention of naming cast implementation functions after the target
       data type. Many users are used to being able to cast data types using a
       function-style notation, that is typename(x). This notation is in fact
       nothing more nor less than a call of the cast implementation function;
       it is not specially treated as a cast. If your conversion functions are
       not named to support this convention then you will have surprised
       users. Since PostgreSQL allows overloading of the same function name
       with different argument types, there is no difficulty in having
       multiple conversion functions from different types that all use the
       target type's name.

           Note
           Actually the preceding paragraph is an oversimplification: there
           are two cases in which a function-call construct will be treated as
           a cast request without having matched it to an actual function. If
           a function call name(x) does not exactly match any existing
           function, but name is the name of a data type and pg_cast provides
           a binary-coercible cast to this type from the type of x, then the
           call will be construed as a binary-coercible cast. This exception
           is made so that binary-coercible casts can be invoked using
           functional syntax, even though they lack any function. Likewise, if
           there is no pg_cast entry but the cast would be to or from a string
           type, the call will be construed as an I/O conversion cast. This
           exception allows I/O conversion casts to be invoked using
           functional syntax.

           Note
           There is also an exception to the exception: I/O conversion casts
           from composite types to string types cannot be invoked using
           functional syntax, but must be written in explicit cast syntax
           (either CAST or :: notation). This exception was added because
           after the introduction of automatically-provided I/O conversion
           casts, it was found too easy to accidentally invoke such a cast
           when a function or column reference was intended.

EXAMPLES
       To create an assignment cast from type bigint to type int4 using the
       function int4(bigint):

           CREATE CAST (bigint AS int4) WITH FUNCTION int4(bigint) AS ASSIGNMENT;

       (This cast is already predefined in the system.)

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       The CREATE CAST command conforms to the SQL standard, except that SQL
       does not make provisions for binary-coercible types or extra arguments
       to implementation functions.  AS IMPLICIT is a PostgreSQL extension,
       too.
<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->
SEE ALSO
       CREATE FUNCTION (CREATE_FUNCTION(7)), CREATE TYPE (CREATE_TYPE(7)),
       DROP CAST (DROP_CAST(7))



PostgreSQL 9.6.1                     2016                       CREATE CAST(7)
DROP DOMAIN(7)          PostgreSQL 9.6.1 Documentation          DROP DOMAIN(7)



NAME
       DROP_DOMAIN - remove a domain

SYNOPSIS
       DROP DOMAIN [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP DOMAIN removes a domain. Only the owner of a domain can remove it.

PARAMETERS
       IF EXISTS
           Do not throw an error if the domain does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing domain.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the domain (such as table
           columns), and in turn all objects that depend on those objects (see
           Section 5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the domain if any objects depend on it. This is the
           default.

EXAMPLES
       To remove the domain box:

           DROP DOMAIN box;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       This command conforms to the SQL standard, except for the IF EXISTS
       option, which is a PostgreSQL extension.
<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->
SEE ALSO
       CREATE DOMAIN (CREATE_DOMAIN(7)), ALTER DOMAIN (ALTER_DOMAIN(7))



PostgreSQL 9.6.1                     2016                       DROP DOMAIN(7)
SET SESSION AUTHORIZATIOPostgreSQL 9.6.1 DocumentaSETnSESSION AUTHORIZATION(7)



NAME
       SET_SESSION_AUTHORIZATION - set the session user identifier and the
       current user identifier of the current session

SYNOPSIS
       SET [ SESSION | LOCAL ] SESSION AUTHORIZATION user_name
       SET [ SESSION | LOCAL ] SESSION AUTHORIZATION DEFAULT
       RESET SESSION AUTHORIZATION

DESCRIPTION
       This command sets the session user identifier and the current user
       identifier of the current SQL session to be user_name. The user name
       can be written as either an identifier or a string literal. Using this
       command, it is possible, for example, to temporarily become an
       unprivileged user and later switch back to being a superuser.

       The session user identifier is initially set to be the (possibly
       authenticated) user name provided by the client. The current user
       identifier is normally equal to the session user identifier, but might
       change temporarily in the context of SECURITY DEFINER functions and
       similar mechanisms; it can also be changed by SET ROLE (SET_ROLE(7)).
       The current user identifier is relevant for permission checking.

       The session user identifier can be changed only if the initial session
       user (the authenticated user) had the superuser privilege. Otherwise,
       the command is accepted only if it specifies the authenticated user
       name.

       The SESSION and LOCAL modifiers act the same as for the regular SET(7)
       command.

       The DEFAULT and RESET forms reset the session and current user
       identifiers to be the originally authenticated user name. These forms
       can be executed by any user.

NOTES
       SET SESSION AUTHORIZATION cannot be used within a SECURITY DEFINER
       function.

EXAMPLES
           SELECT SESSION_USER, CURRENT_USER;

            session_user | current_user
           --------------+--------------
            peter        | peter

           SET SESSION AUTHORIZATION 'paul';

           SELECT SESSION_USER, CURRENT_USER;

            session_user | current_user
           --------------+--------------
            paul         | paul

COMPATIBILITY
       The SQL standard allows some other expressions to appear in place of
       the literal user_name, but these options are not important in practice.
       PostgreSQL allows identifier syntax ("username"), which SQL does not.
       SQL does not allow this command during a transaction; PostgreSQL does
       not make this restriction because there is no reason to. The SESSION
       and LOCAL modifiers are a PostgreSQL extension, as is the RESET syntax.

       The privileges necessary to execute this command are left
       implementation-defined by the standard.

SEE ALSO
       SET ROLE (SET_ROLE(7))



PostgreSQL 9.6.1                     2016         SET SESSION AUTHORIZATION(7)
MOVE(7)                 PostgreSQL 9.6.1 Documentation                 MOVE(7)



<!-- 6e8bff88-7e24-4615-8efc-03f9ef2f30b3 <=< ACCEPT -->NAME
       MOVE - position a cursor

SYNOPSIS
       MOVE [ direction [ FROM | IN ] ] cursor_name

       where direction can be empty or one of:

           NEXT
           PRIOR
           FIRST
           LAST
           ABSOLUTE count
           RELATIVE count
           count
           ALL
           FORWARD
           FORWARD count
           FORWARD ALL
           BACKWARD
           BACKWARD count
           BACKWARD ALL<!-- ACCEPT >=> 6e8bff88-7e24-4615-8efc-03f9ef2f30b3 -->

DESCRIPTION
       MOVE repositions a cursor without retrieving any data.  MOVE works
       exactly like the FETCH command, except it only positions the cursor and
       does not return rows.

       The parameters for the MOVE command are identical to those of the FETCH
       command; refer to FETCH(7) for details on syntax and usage.

OUTPUTS
       On successful completion, a MOVE command returns a command tag of the
       form

           MOVE count

       The count is the number of rows that a FETCH command with the same
       parameters would have returned (possibly zero).

EXAMPLES
           BEGIN WORK;
           DECLARE liahona CURSOR FOR SELECT * FROM films;

           -- Skip the first 5 rows:
           MOVE FORWARD 5 IN liahona;
           MOVE 5

           -- Fetch the 6th row from the cursor liahona:
           FETCH 1 FROM liahona;
            code  | title  | did | date_prod  |  kind  |  len
           -------+--------+-----+------------+--------+-------
            P_303 | 48 Hrs | 103 | 1982-10-22 | Action | 01:37
           (1 row)

           -- Close the cursor liahona and end the transaction:
           CLOSE liahona;
           COMMIT WORK;

COMPATIBILITY
       There is no MOVE statement in the SQL standard.

SEE ALSO
       CLOSE(7), DECLARE(7), FETCH(7)



PostgreSQL 9.6.1                     2016                              MOVE(7)
DROP TEXT SEARCH CONFIGUPostgreSQL 9.6.1 DocuDROPaTEXT SEARCH CONFIGURATION(7)



NAME
       DROP_TEXT_SEARCH_CONFIGURATION - remove a text search configuration

SYNOPSIS
       DROP TEXT SEARCH CONFIGURATION [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP TEXT SEARCH CONFIGURATION drops an existing text search
       configuration. To execute this command you must be the owner of the
       configuration.

PARAMETERS
       IF EXISTS
           Do not throw an error if the text search configuration does not
           exist. A notice is issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing text search
           configuration.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the text search
           configuration, and in turn all objects that depend on those objects
           (see Section 5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the text search configuration if any objects depend
           on it. This is the default.

EXAMPLES
       Remove the text search configuration my_english:

           DROP TEXT SEARCH CONFIGURATION my_english;

       This command will not succeed if there are any existing indexes that
       reference the configuration in to_tsvector calls. Add CASCADE to drop
       such indexes along with the text search configuration.

COMPATIBILITY
       There is no DROP TEXT SEARCH CONFIGURATION statement in the SQL
       standard.

SEE ALSO
       ALTER TEXT SEARCH CONFIGURATION (ALTER_TEXT_SEARCH_CONFIGURATION(7)),
       CREATE TEXT SEARCH CONFIGURATION (CREATE_TEXT_SEARCH_CONFIGURATION(7))



PostgreSQL 9.6.1                     2016    DROP TEXT SEARCH CONFIGURATION(7)
END(7)                  PostgreSQL 9.6.1 Documentation                  END(7)



<!-- c2d6965b-f6d0-4554-8583-9d3eb0a21ddf <=< ACCEPT -->NAME
       END - commit the current transaction

SYNOPSIS
       END [ WORK | TRANSACTION ]

DESCRIPTION
       END commits the current transaction. All changes made by the
       transaction become visible to others and are guaranteed to be durable
       if a crash occurs. This command is a PostgreSQL extension that is
       equivalent to COMMIT(7).

PARAMETERS
       WORK
       TRANSACTION
           Optional key words. They have no effect.

NOTES
       Use ROLLBACK(7) to abort a transaction.

       Issuing END when not inside a transaction does no harm, but it will
       provoke a warning message.

EXAMPLES
       To commit the current transaction and make all changes permanent:

           END;

COMPATIBILITY
       END is a PostgreSQL extension that provides functionality equivalent to
       COMMIT(7), which is specified in the SQL standard.

SEE ALSO
       BEGIN(7), COMMIT(7), ROLLBACK(7)
<!-- ACCEPT >=> c2d6965b-f6d0-4554-8583-9d3eb0a21ddf -->


PostgreSQL 9.6.1                     2016                               END(7)
REINDEX(7)              PostgreSQL 9.6.1 Documentation              REINDEX(7)



NAME
       REINDEX - rebuild indexes

SYNOPSIS
       REINDEX [ ( VERBOSE ) ] { INDEX | TABLE | SCHEMA | DATABASE | SYSTEM } name

DESCRIPTION
       REINDEX rebuilds an index using the data stored in the index's table,
       replacing the old copy of the index. There are several scenarios in
       which to use REINDEX:

       o   An index has become corrupted, and no longer contains valid data.
           Although in theory this should never happen, in practice indexes
           can become corrupted due to software bugs or hardware failures.
           REINDEX provides a recovery method.

       o   An index has become "bloated", that is it contains many empty or
           nearly-empty pages. This can occur with B-tree indexes in
           PostgreSQL under certain uncommon access patterns.  REINDEX
           provides a way to reduce the space consumption of the index by
           writing a new version of the index without the dead pages. See
           Section 24.2, "Routine Reindexing", in the documentation for more
           information.

       o   You have altered a storage parameter (such as fillfactor) for an
           index, and wish to ensure that the change has taken full effect.

       o   An index build with the CONCURRENTLY option failed, leaving an
           "invalid" index. Such indexes are useless but it can be convenient
           to use REINDEX to rebuild them. Note that REINDEX will not perform
           a concurrent build. To build the index without interfering with
           production you should drop the index and reissue the CREATE INDEX
           CONCURRENTLY command.

PARAMETERS
       INDEX
           Recreate the specified index.

       TABLE
           Recreate all indexes of the specified table. If the table has a
           secondary "TOAST" table, that is reindexed as well.

       SCHEMA
           Recreate all indexes of the specified schema. If a table of this
           schema has a secondary "TOAST" table, that is reindexed as well.
           Indexes on shared system catalogs are also processed. This form of
           REINDEX cannot be executed inside a transaction block.

       DATABASE
           Recreate all indexes within the current database. Indexes on shared
           system catalogs are also processed. This form of REINDEX cannot be
           executed inside a transaction block.

       SYSTEM
           Recreate all indexes on system catalogs within the current
           database. Indexes on shared system catalogs are included. Indexes
           on user tables are not processed. This form of REINDEX cannot be
           executed inside a transaction block.

       name
           The name of the specific index, table, or database to be reindexed.
           Index and table names can be schema-qualified. Presently, REINDEX
           DATABASE and REINDEX SYSTEM can only reindex the current database,
           so their parameter must match the current database's name.

       VERBOSE
           Prints a progress report as each index is reindexed.

NOTES
       If you suspect corruption of an index on a user table, you can simply
       rebuild that index, or all indexes on the table, using REINDEX INDEX or
       REINDEX TABLE.

       Things are more difficult if you need to recover from corruption of an
       index on a system table. In this case it's important for the system to
       not have used any of the suspect indexes itself. (Indeed, in this sort
       of scenario you might find that server processes are crashing
       immediately at start-up, due to reliance on the corrupted indexes.) To
       recover safely, the server must be started with the -P option, which
       prevents it from using indexes for system catalog lookups.

       One way to do this is to shut down the server and start a single-user
       PostgreSQL server with the -P option included on its command line.
       Then, REINDEX DATABASE, REINDEX SYSTEM, REINDEX TABLE, or REINDEX INDEX
       can be issued, depending on how much you want to reconstruct. If in
       doubt, use REINDEX SYSTEM to select reconstruction of all system
       indexes in the database. Then quit the single-user server session and
       restart the regular server. See the postgres(1) reference page for more
       information about how to interact with the single-user server
       interface.

       Alternatively, a regular server session can be started with -P included
       in its command line options. The method for doing this varies across
       clients, but in all libpq-based clients, it is possible to set the
       PGOPTIONS environment variable to -P before starting the client. Note
       that while this method does not require locking out other clients, it
       might still be wise to prevent other users from connecting to the
       damaged database until repairs have been completed.

       REINDEX is similar to a drop and recreate of the index in that the
       index contents are rebuilt from scratch. However, the locking
       considerations are rather different.  REINDEX locks out writes but not
       reads of the index's parent table. It also takes an exclusive lock on
       the specific index being processed, which will block reads that attempt
       to use that index. In contrast, DROP INDEX momentarily takes an
       exclusive lock on the parent table, blocking both writes and reads. The
       subsequent CREATE INDEX locks out writes but not reads; since the index
       is not there, no read will attempt to use it, meaning that there will
       be no blocking but reads might be forced into expensive sequential
       scans.

       Reindexing a single index or table requires being the owner of that
       index or table. Reindexing a database requires being the owner of the
       database (note that the owner can therefore rebuild indexes of tables
       owned by other users). Of course, superusers can always reindex
       anything.

EXAMPLES
       Rebuild a single index:

           REINDEX INDEX my_index;

       Rebuild all the indexes on the table my_table:

           REINDEX TABLE my_table;

       Rebuild all indexes in a particular database, without trusting the
       system indexes to be valid already:

           $ export PGOPTIONS="-P"
           $ psql broken_db
           ...
           broken_db=&amp;gt; REINDEX DATABASE broken_db;
           broken_db=&amp;gt; \q

COMPATIBILITY
       There is no REINDEX command in the SQL standard.



PostgreSQL 9.6.1                     2016                           REINDEX(7)
CREATE OPERATOR FAMILY(7PostgreSQL 9.6.1 DocumentatioCREATE OPERATOR FAMILY(7)



NAME
       CREATE_OPERATOR_FAMILY - define a new operator family

SYNOPSIS
       CREATE OPERATOR FAMILY name USING index_method

DESCRIPTION
       CREATE OPERATOR FAMILY creates a new operator family. An operator
       family defines a collection of related operator classes, and perhaps
       some additional operators and support functions that are compatible
       with these operator classes but not essential for the functioning of
       any individual index. (Operators and functions that are essential to
       indexes should be grouped within the relevant operator class, rather
       than being "loose" in the operator family. Typically, single-data-type
       operators are bound to operator classes, while cross-data-type
       operators can be loose in an operator family containing operator
       classes for both data types.)

       The new operator family is initially empty. It should be populated by
       issuing subsequent CREATE OPERATOR CLASS commands to add contained
       operator classes, and optionally ALTER OPERATOR FAMILY commands to add
       "loose" operators and their corresponding support functions.

       If a schema name is given then the operator family is created in the
       specified schema. Otherwise it is created in the current schema. Two
       operator families in the same schema can have the same name only if
       they are for different index methods.

       The user who defines an operator family becomes its owner. Presently,
       the creating user must be a superuser. (This restriction is made
       because an erroneous operator family definition could confuse or even
       crash the server.)

       Refer to Section 36.14, "Interfacing Extensions To Indexes", in the
       documentation for further information.

PARAMETERS
       name
           The name of the operator family to be created. The name can be
           schema-qualified.

       index_method
           The name of the index method this operator family is for.

COMPATIBILITY
       CREATE OPERATOR FAMILY is a PostgreSQL extension. There is no CREATE
       OPERATOR FAMILY statement in the SQL standard.

SEE ALSO
       ALTER OPERATOR FAMILY (ALTER_OPERATOR_FAMILY(7)), DROP OPERATOR FAMILY
       (DROP_OPERATOR_FAMILY(7)), CREATE OPERATOR CLASS
       (CREATE_OPERATOR_CLASS(7)), ALTER OPERATOR CLASS
       (ALTER_OPERATOR_CLASS(7)), DROP OPERATOR CLASS (DROP_OPERATOR_CLASS(7))



PostgreSQL 9.6.1                     2016            CREATE OPERATOR FAMILY(7)
IMPORT FOREIGN SCHEMA(7)PostgreSQL 9.6.1 DocumentationIMPORT FOREIGN SCHEMA(7)



NAME
       IMPORT_FOREIGN_SCHEMA - import table definitions from a foreign server

SYNOPSIS
       IMPORT FOREIGN SCHEMA remote_schema
           [ { LIMIT TO | EXCEPT } ( table_name [, ...] ) ]
           FROM SERVER server_name
           INTO local_schema
           [ OPTIONS ( option 'value' [, ... ] ) ]

DESCRIPTION
       IMPORT FOREIGN SCHEMA creates foreign tables that represent tables
       existing on a foreign server. The new foreign tables will be owned by
       the user issuing the command and are created with the correct column
       definitions and options to match the remote tables.

       By default, all tables and views existing in a particular schema on the
       foreign server are imported. Optionally, the list of tables can be
       limited to a specified subset, or specific tables can be excluded. The
       new foreign tables are all created in the target schema, which must
       already exist.

       To use IMPORT FOREIGN SCHEMA, the user must have USAGE privilege on the
       foreign server, as well as CREATE privilege on the target schema.

PARAMETERS
       remote_schema
           The remote schema to import from. The specific meaning of a remote
           schema depends on the foreign data wrapper in use.

       LIMIT TO ( table_name [, ...] )
           Import only foreign tables matching one of the given table names.
           Other tables existing in the foreign schema will be ignored.

       EXCEPT ( table_name [, ...] )
           Exclude specified foreign tables from the import. All tables
           existing in the foreign schema will be imported except the ones
           listed here.

       server_name
           The foreign server to import from.

       local_schema
           The schema in which the imported foreign tables will be created.

       OPTIONS ( option 'value' [, ...] )
           Options to be used during the import. The allowed option names and
           values are specific to each foreign data wrapper.

EXAMPLES
       Import table definitions from a remote schema foreign_films on server
       film_server, creating the foreign tables in local schema films:

           IMPORT FOREIGN SCHEMA foreign_films
               FROM SERVER film_server INTO films;

       As above, but import only the two tables actors and directors (if they
       exist):

           IMPORT FOREIGN SCHEMA foreign_films LIMIT TO (actors, directors)
               FROM SERVER film_server INTO films;


<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       The IMPORT FOREIGN SCHEMA command conforms to the SQL standard, except
       that the OPTIONS clause is a PostgreSQL extension.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

SEE ALSO
       CREATE FOREIGN TABLE (CREATE_FOREIGN_TABLE(7)), CREATE SERVER
       (CREATE_SERVER(7))



PostgreSQL 9.6.1                     2016             IMPORT FOREIGN SCHEMA(7)
CREATE TEXT SEARCH PARSEPostgreSQL 9.6.1 DocumentaCREATE TEXT SEARCH PARSER(7)



NAME
       CREATE_TEXT_SEARCH_PARSER - define a new text search parser

SYNOPSIS
       CREATE TEXT SEARCH PARSER name (
           START = start_function ,
           GETTOKEN = gettoken_function ,
           END = end_function ,
           LEXTYPES = lextypes_function
           [, HEADLINE = headline_function ]
       )

DESCRIPTION
       CREATE TEXT SEARCH PARSER creates a new text search parser. A text
       search parser defines a method for splitting a text string into tokens
       and assigning types (categories) to the tokens. A parser is not
       particularly useful by itself, but must be bound into a text search
       configuration along with some text search dictionaries to be used for
       searching.

       If a schema name is given then the text search parser is created in the
       specified schema. Otherwise it is created in the current schema.

       You must be a superuser to use CREATE TEXT SEARCH PARSER. (This
       restriction is made because an erroneous text search parser definition
       could confuse or even crash the server.)

       Refer to Chapter 12, Full Text Search, in the documentation for further
       information.

PARAMETERS
       name
           The name of the text search parser to be created. The name can be
           schema-qualified.

       start_function
           The name of the start function for the parser.

       gettoken_function
           The name of the get-next-token function for the parser.

       end_function
           The name of the end function for the parser.

       lextypes_function
           The name of the lextypes function for the parser (a function that
           returns information about the set of token types it produces).

       headline_function
           The name of the headline function for the parser (a function that
           summarizes a set of tokens).

       The function names can be schema-qualified if necessary. Argument types
       are not given, since the argument list for each type of function is
       predetermined. All except the headline function are required.

       The arguments can appear in any order, not only the one shown above.

COMPATIBILITY
       There is no CREATE TEXT SEARCH PARSER statement in the SQL standard.

SEE ALSO
       ALTER TEXT SEARCH PARSER (ALTER_TEXT_SEARCH_PARSER(7)), DROP TEXT
       SEARCH PARSER (DROP_TEXT_SEARCH_PARSER(7))



PostgreSQL 9.6.1                     2016         CREATE TEXT SEARCH PARSER(7)
LOAD(7)                 PostgreSQL 9.6.1 Documentation                 LOAD(7)



NAME
       LOAD - load a shared library file

SYNOPSIS
       LOAD 'filename'

DESCRIPTION
       This command loads a shared library file into the PostgreSQL server's
       address space. If the file has been loaded already, the command does
       nothing. Shared library files that contain C functions are
       automatically loaded whenever one of their functions is called.
       Therefore, an explicit LOAD is usually only needed to load a library
       that modifies the server's behavior through "hooks" rather than
       providing a set of functions.

       The file name is specified in the same way as for shared library names
       in CREATE FUNCTION (CREATE_FUNCTION(7)); in particular, one can rely on
       a search path and automatic addition of the system's standard shared
       library file name extension. See Section 36.9, "C-Language Functions",
       in the documentation for more information on this topic.

       Non-superusers can only apply LOAD to library files located in
       $libdir/plugins/ -- the specified filename must begin with exactly that
       string. (It is the database administrator's responsibility to ensure
       that only "safe" libraries are installed there.)

COMPATIBILITY
       LOAD is a PostgreSQL extension.

SEE ALSO
       CREATE FUNCTION (CREATE_FUNCTION(7))



PostgreSQL 9.6.1                     2016                              LOAD(7)
DROP TABLE(7)           PostgreSQL 9.6.1 Documentation           DROP TABLE(7)



NAME
       DROP_TABLE - remove a table

SYNOPSIS
       DROP TABLE [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP TABLE removes tables from the database. Only the table owner, the
       schema owner, and superuser can drop a table. To empty a table of rows
       without destroying the table, use DELETE(7) or TRUNCATE(7).

       DROP TABLE always removes any indexes, rules, triggers, and constraints
       that exist for the target table. However, to drop a table that is
       referenced by a view or a foreign-key constraint of another table,
       CASCADE must be specified. (CASCADE will remove a dependent view
       entirely, but in the foreign-key case it will only remove the
       foreign-key constraint, not the other table entirely.)

PARAMETERS
       IF EXISTS
           Do not throw an error if the table does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the table to drop.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the table (such as
           views), and in turn all objects that depend on those objects (see
           Section 5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the table if any objects depend on it. This is the
           default.

EXAMPLES
       To destroy two tables, films and distributors:

           DROP TABLE films, distributors;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       This command conforms to the SQL standard, except that the standard
       only allows one table to be dropped per command, and apart from the IF
       EXISTS option, which is a PostgreSQL extension.
<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->
SEE ALSO
       ALTER TABLE (ALTER_TABLE(7)), CREATE TABLE (CREATE_TABLE(7))



PostgreSQL 9.6.1                     2016                        DROP TABLE(7)
CREATE POLICY(7)        PostgreSQL 9.6.1 Documentation        CREATE POLICY(7)



NAME
       CREATE_POLICY - define a new row level security policy for a table

SYNOPSIS
       CREATE POLICY name ON table_name
           [ FOR { ALL | SELECT | INSERT | UPDATE | DELETE } ]
           [ TO { role_name | PUBLIC | CURRENT_USER | SESSION_USER } [, ...] ]
           [ USING ( using_expression ) ]
           [ WITH CHECK ( check_expression ) ]

DESCRIPTION
       The CREATE POLICY command defines a new row-level security policy for a
       table. Note that row-level security must be enabled on the table (using
       ALTER TABLE ... ENABLE ROW LEVEL SECURITY) in order for created
       policies to be applied.

       A policy grants the permission to select, insert, update, or delete
       rows that match the relevant policy expression. Existing table rows are
       checked against the expression specified in USING, while new rows that
       would be created via INSERT or UPDATE are checked against the
       expression specified in WITH CHECK. When a USING expression returns
       true for a given row then that row is visible to the user, while if
       false or null is returned then the row is not visible. When a WITH
       CHECK expression returns true for a row then that row is inserted or
       updated, while if false or null is returned then an error occurs.

       For INSERT and UPDATE statements, WITH CHECK expressions are enforced
       after BEFORE triggers are fired, and before any actual data
       modifications are made. Thus a BEFORE ROW trigger may modify the data
       to be inserted, affecting the result of the security policy check.
       WITH CHECK expressions are enforced before any other constraints.

       Policy names are per-table. Therefore, one policy name can be used for
       many different tables and have a definition for each table which is
       appropriate to that table.

       Policies can be applied for specific commands or for specific roles.
       The default for newly created policies is that they apply for all
       commands and roles, unless otherwise specified. If multiple policies
       apply to a given statement, they will be combined using OR (although ON
       CONFLICT DO UPDATE and INSERT policies are not combined in this way,
       but rather enforced as noted at each stage of ON CONFLICT execution).

       For commands that can have both USING and WITH CHECK policies (ALL and
       UPDATE), if no WITH CHECK policy is defined, then the USING policy will
       be used both for which rows are visible (normal USING case) and for
       which rows will be allowed to be added (WITH CHECK case).

       If row-level security is enabled for a table, but no applicable
       policies exist, a "default deny" policy is assumed, so that no rows
       will be visible or updatable.

PARAMETERS
       name
           The name of the policy to be created. This must be distinct from
           the name of any other policy for the table.

       table_name
           The name (optionally schema-qualified) of the table the policy
           applies to.

       command
           The command to which the policy applies. Valid options are ALL,
           SELECT, INSERT, UPDATE, and DELETE.  ALL is the default. See below
           for specifics regarding how these are applied.

       role_name
           The role(s) to which the policy is to be applied. The default is
           PUBLIC, which will apply the policy to all roles.

       using_expression
           Any SQL conditional expression (returning boolean). The conditional
           expression cannot contain any aggregate or window functions. This
           expression will be added to queries that refer to the table if row
           level security is enabled. Rows for which the expression returns
           true will be visible. Any rows for which the expression returns
           false or null will not be visible to the user (in a SELECT), and
           will not be available for modification (in an UPDATE or DELETE).
           Such rows are silently suppressed; no error is reported.

       check_expression
           Any SQL conditional expression (returning boolean). The conditional
           expression cannot contain any aggregate or window functions. This
           expression will be used in INSERT and UPDATE queries against the
           table if row level security is enabled. Only rows for which the
           expression evaluates to true will be allowed. An error will be
           thrown if the expression evaluates to false or null for any of the
           records inserted or any of the records that result from the update.
           Note that the check_expression is evaluated against the proposed
           new contents of the row, not the original contents.

   Per-Command Policies
       ALL
           Using ALL for a policy means that it will apply to all commands,
           regardless of the type of command. If an ALL policy exists and more
           specific policies exist, then both the ALL policy and the more
           specific policy (or policies) will be combined using OR, as usual
           for overlapping policies. Additionally, ALL policies will be
           applied to both the selection side of a query and the modification
           side, using the USING expression for both cases if only a USING
           expression has been defined.

           As an example, if an UPDATE is issued, then the ALL policy will be
           applicable both to what the UPDATE will be able to select as rows
           to be updated (applying the USING expression), and to the resulting
           updated rows, to check if they are permitted to be added to the
           table (applying the WITH CHECK expression, if defined, and the
           USING expression otherwise). If an INSERT or UPDATE command
           attempts to add rows to the table that do not pass the ALL policy's
           WITH CHECK expression, the entire command will be aborted.

       SELECT
           Using SELECT for a policy means that it will apply to SELECT
           queries and whenever SELECT permissions are required on the
           relation the policy is defined for. The result is that only those
           records from the relation that pass the SELECT policy will be
           returned during a SELECT query, and that queries that require
           SELECT permissions, such as UPDATE, will also only see those
           records that are allowed by the SELECT policy. A SELECT policy
           cannot have a WITH CHECK expression, as it only applies in cases
           where records are being retrieved from the relation.

       INSERT
           Using INSERT for a policy means that it will apply to INSERT
           commands. Rows being inserted that do not pass this policy will
           result in a policy violation error, and the entire INSERT command
           will be aborted. An INSERT policy cannot have a USING expression,
           as it only applies in cases where records are being added to the
           relation.

           Note that INSERT with ON CONFLICT DO UPDATE checks INSERT policies'
           WITH CHECK expressions only for rows appended to the relation by
           the INSERT path.

       UPDATE
           Using UPDATE for a policy means that it will apply to UPDATE
           commands (or auxiliary ON CONFLICT DO UPDATE clauses of INSERT
           commands). Since UPDATE involves pulling an existing record and
           then making changes to some portion (but possibly not all) of the
           record, UPDATE policies accept both a USING expression and a WITH
           CHECK expression. The USING expression determines which records the
           UPDATE command will see to operate against, while the WITH CHECK
           expression defines which modified rows are allowed to be stored
           back into the relation.

<!-- 78c95a50-2d11-4eec-a2e2-2c93c1108925 <=< ACCEPT -->           When an UPDATE command is used with a WHERE clause or a RETURNING
           clause, SELECT rights are also required on the relation being
           updated and the appropriate SELECT and ALL policies will be
           combined (using OR for any overlapping SELECT related policies
           found) with the USING clause of the UPDATE policy using AND.
           Therefore, in order for a user to be able to UPDATE specific rows,
           the user must have access to the row(s) through a SELECT or ALL
           policy and the row(s) must pass the UPDATE policy's USING
           expression.<!-- ACCEPT >=> 78c95a50-2d11-4eec-a2e2-2c93c1108925 -->

           Any rows whose updated values do not pass the WITH CHECK expression
           will cause an error, and the entire command will be aborted. If
           only a USING clause is specified, then that clause will be used for
           both USING and WITH CHECK cases.

           Note, however, that INSERT with ON CONFLICT DO UPDATE requires that
           an UPDATE policy USING expression always be enforced as a WITH
           CHECK expression. This UPDATE policy must always pass when the
           UPDATE path is taken. Any existing row that necessitates that the
           UPDATE path be taken must pass the (UPDATE or ALL) USING
           qualifications (combined using OR), which are always enforced as
           WITH CHECK options in this context. (The UPDATE path will never be
           silently avoided; an error will be thrown instead.) Finally, the
           final row appended to the relation must pass any WITH CHECK options
           that a conventional UPDATE is required to pass.

       DELETE
           Using DELETE for a policy means that it will apply to DELETE
           commands. Only rows that pass this policy will be seen by a DELETE
           command. There can be rows that are visible through a SELECT that
           are not available for deletion, if they do not pass the USING
           expression for the DELETE policy.

<!-- 78c95a50-2d11-4eec-a2e2-2c93c1108925 <=< ACCEPT -->           When a DELETE command is used with a WHERE clause or a RETURNING
           clause, SELECT rights are also required on the relation being
           updated and the appropriate SELECT and ALL policies will be
           combined (using OR for any overlapping SELECT related policies
           found) with the USING clause of the DELETE policy using AND.
           Therefore, in order for a user to be able to DELETE specific rows,
           the user must have access to the row(s) through a SELECT or ALL
           policy and the row(s) must pass the DELETE policy's USING
           expression.
<!-- ACCEPT >=> 78c95a50-2d11-4eec-a2e2-2c93c1108925 -->
           A DELETE policy cannot have a WITH CHECK expression, as it only
           applies in cases where records are being deleted from the relation,
           so that there is no new row to check.

NOTES
       You must be the owner of a table to create or change policies for it.

       While policies will be applied for explicit queries against tables in
       the database, they are not applied when the system is performing
       internal referential integrity checks or validating constraints. This
       means there are indirect ways to determine that a given value exists.
       An example of this is attempting to insert a duplicate value into a
       column that is a primary key or has a unique constraint. If the insert
       fails then the user can infer that the value already exists. (This
       example assumes that the user is permitted by policy to insert records
       which they are not allowed to see.) Another example is where a user is
       allowed to insert into a table which references another, otherwise
       hidden table. Existence can be determined by the user inserting values
       into the referencing table, where success would indicate that the value
       exists in the referenced table. These issues can be addressed by
       carefully crafting policies to prevent users from being able to insert,
       delete, or update records at all which might possibly indicate a value
       they are not otherwise able to see, or by using generated values (e.g.,
       surrogate keys) instead of keys with external meanings.

       Generally, the system will enforce filter conditions imposed using
       security policies prior to qualifications that appear in user queries,
       in order to prevent inadvertent exposure of the protected data to
       user-defined functions which might not be trustworthy. However,
       functions and operators marked by the system (or the system
       administrator) as LEAKPROOF may be evaluated before policy expressions,
       as they are assumed to be trustworthy.

       Since policy expressions are added to the user's query directly, they
       will be run with the rights of the user running the overall query.
       Therefore, users who are using a given policy must be able to access
       any tables or functions referenced in the expression or they will
       simply receive a permission denied error when attempting to query the
       table that has row-level security enabled. This does not change how
       views work, however. As with normal queries and views, permission
       checks and policies for the tables which are referenced by a view will
       use the view owner's rights and any policies which apply to the view
       owner.

       Additional discussion and practical examples can be found in Section
       5.7, "Row Security Policies", in the documentation.

COMPATIBILITY
       CREATE POLICY is a PostgreSQL extension.

SEE ALSO
       ALTER POLICY (ALTER_POLICY(7)), DROP POLICY (DROP_POLICY(7)), ALTER
       TABLE (ALTER_TABLE(7))



PostgreSQL 9.6.1                     2016                     CREATE POLICY(7)
GRANT(7)                PostgreSQL 9.6.1 Documentation                GRANT(7)



NAME
       GRANT - define access privileges

SYNOPSIS
       GRANT { { SELECT | INSERT | UPDATE | DELETE | TRUNCATE | REFERENCES | TRIGGER }
           [, ...] | ALL [ PRIVILEGES ] }
           ON { [ TABLE ] table_name [, ...]
                | ALL TABLES IN SCHEMA schema_name [, ...] }
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { { SELECT | INSERT | UPDATE | REFERENCES } ( column_name [, ...] )
           [, ...] | ALL [ PRIVILEGES ] ( column_name [, ...] ) }
           ON [ TABLE ] table_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { { USAGE | SELECT | UPDATE }
           [, ...] | ALL [ PRIVILEGES ] }
           ON { SEQUENCE sequence_name [, ...]
                | ALL SEQUENCES IN SCHEMA schema_name [, ...] }
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { { CREATE | CONNECT | TEMPORARY | TEMP } [, ...] | ALL [ PRIVILEGES ] }
           ON DATABASE database_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { USAGE | ALL [ PRIVILEGES ] }
           ON DOMAIN domain_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { USAGE | ALL [ PRIVILEGES ] }
           ON FOREIGN DATA WRAPPER fdw_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { USAGE | ALL [ PRIVILEGES ] }
           ON FOREIGN SERVER server_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { EXECUTE | ALL [ PRIVILEGES ] }
           ON { FUNCTION function_name ( [ [ argmode ] [ arg_name ] arg_type [, ...] ] ) [, ...]
                | ALL FUNCTIONS IN SCHEMA schema_name [, ...] }
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { USAGE | ALL [ PRIVILEGES ] }
           ON LANGUAGE lang_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { { SELECT | UPDATE } [, ...] | ALL [ PRIVILEGES ] }
           ON LARGE OBJECT loid [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { { CREATE | USAGE } [, ...] | ALL [ PRIVILEGES ] }
           ON SCHEMA schema_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { CREATE | ALL [ PRIVILEGES ] }
           ON TABLESPACE tablespace_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       GRANT { USAGE | ALL [ PRIVILEGES ] }
           ON TYPE type_name [, ...]
           TO role_specification [, ...] [ WITH GRANT OPTION ]

       where role_specification can be:

           [ GROUP ] role_name
         | PUBLIC
         | CURRENT_USER
         | SESSION_USER

       GRANT role_name [, ...] TO role_name [, ...] [ WITH ADMIN OPTION ]

DESCRIPTION
       The GRANT command has two basic variants: one that grants privileges on
       a database object (table, column, view, foreign table, sequence,
       database, foreign-data wrapper, foreign server, function, procedural
       language, schema, or tablespace), and one that grants membership in a
       role. These variants are similar in many ways, but they are different
       enough to be described separately.

   GRANT on Database Objects
       This variant of the GRANT command gives specific privileges on a
       database object to one or more roles. These privileges are added to
       those already granted, if any.

       There is also an option to grant privileges on all objects of the same
       type within one or more schemas. This functionality is currently
       supported only for tables, sequences, and functions (but note that ALL
       TABLES is considered to include views and foreign tables).

       The key word PUBLIC indicates that the privileges are to be granted to
       all roles, including those that might be created later.  PUBLIC can be
       thought of as an implicitly defined group that always includes all
       roles. Any particular role will have the sum of privileges granted
       directly to it, privileges granted to any role it is presently a member
       of, and privileges granted to PUBLIC.

       If WITH GRANT OPTION is specified, the recipient of the privilege can
       in turn grant it to others. Without a grant option, the recipient
       cannot do that. Grant options cannot be granted to PUBLIC.

       There is no need to grant privileges to the owner of an object (usually
       the user that created it), as the owner has all privileges by default.
       (The owner could, however, choose to revoke some of their own
       privileges for safety.)

       The right to drop an object, or to alter its definition in any way, is
       not treated as a grantable privilege; it is inherent in the owner, and
       cannot be granted or revoked. (However, a similar effect can be
       obtained by granting or revoking membership in the role that owns the
       object; see below.) The owner implicitly has all grant options for the
       object, too.

       PostgreSQL grants default privileges on some types of objects to
       PUBLIC. No privileges are granted to PUBLIC by default on tables,
       columns, schemas or tablespaces. For other types, the default
       privileges granted to PUBLIC are as follows: CONNECT and CREATE TEMP
       TABLE for databases; EXECUTE privilege for functions; and USAGE
       privilege for languages. The object owner can, of course, REVOKE both
       default and expressly granted privileges. (For maximum security, issue
       the REVOKE in the same transaction that creates the object; then there
       is no window in which another user can use the object.) Also, these
       initial default privilege settings can be changed using the ALTER
       DEFAULT PRIVILEGES (ALTER_DEFAULT_PRIVILEGES(7)) command.

       The possible privileges are:

       SELECT
           Allows SELECT(7) from any column, or the specific columns listed,
           of the specified table, view, or sequence. Also allows the use of
           COPY(7) TO. This privilege is also needed to reference existing
           column values in UPDATE(7) or DELETE(7). For sequences, this
           privilege also allows the use of the currval function. For large
           objects, this privilege allows the object to be read.

       INSERT
           Allows INSERT(7) of a new row into the specified table. If specific
           columns are listed, only those columns may be assigned to in the
           INSERT command (other columns will therefore receive default
           values). Also allows COPY(7) FROM.

       UPDATE
           Allows UPDATE(7) of any column, or the specific columns listed, of
           the specified table. (In practice, any nontrivial UPDATE command
           will require SELECT privilege as well, since it must reference
           table columns to determine which rows to update, and/or to compute
           new values for columns.)  SELECT ... FOR UPDATE and SELECT ... FOR
           SHARE also require this privilege on at least one column, in
           addition to the SELECT privilege. For sequences, this privilege
           allows the use of the nextval and setval functions. For large
           objects, this privilege allows writing or truncating the object.

       DELETE
           Allows DELETE(7) of a row from the specified table. (In practice,
           any nontrivial DELETE command will require SELECT privilege as
           well, since it must reference table columns to determine which rows
           to delete.)

       TRUNCATE
           Allows TRUNCATE(7) on the specified table.

       REFERENCES
           To create a foreign key constraint, it is necessary to have this
           privilege on both the referencing and referenced columns. The
           privilege may be granted for all columns of a table, or just
           specific columns.

       TRIGGER
           Allows the creation of a trigger on the specified table. (See the
           CREATE TRIGGER (CREATE_TRIGGER(7)) statement.)

       CREATE
           For databases, allows new schemas to be created within the
           database.

           For schemas, allows new objects to be created within the schema. To
           rename an existing object, you must own the object and have this
           privilege for the containing schema.

           For tablespaces, allows tables, indexes, and temporary files to be
           created within the tablespace, and allows databases to be created
           that have the tablespace as their default tablespace. (Note that
           revoking this privilege will not alter the placement of existing
           objects.)

       CONNECT
           Allows the user to connect to the specified database. This
           privilege is checked at connection startup (in addition to checking
           any restrictions imposed by pg_hba.conf).

       TEMPORARY
       TEMP
           Allows temporary tables to be created while using the specified
           database.

       EXECUTE
           Allows the use of the specified function and the use of any
           operators that are implemented on top of the function. This is the
           only type of privilege that is applicable to functions. (This
           syntax works for aggregate functions, as well.)

       USAGE
           For procedural languages, allows the use of the specified language
           for the creation of functions in that language. This is the only
           type of privilege that is applicable to procedural languages.

           For schemas, allows access to objects contained in the specified
           schema (assuming that the objects' own privilege requirements are
           also met). Essentially this allows the grantee to "look up" objects
           within the schema. Without this permission, it is still possible to
           see the object names, e.g. by querying the system tables. Also,
           after revoking this permission, existing backends might have
           statements that have previously performed this lookup, so this is
           not a completely secure way to prevent object access.

           For sequences, this privilege allows the use of the currval and
           nextval functions.

           For types and domains, this privilege allow the use of the type or
           domain in the creation of tables, functions, and other schema
           objects. (Note that it does not control general "usage" of the
           type, such as values of the type appearing in queries. It only
           prevents objects from being created that depend on the type. The
           main purpose of the privilege is controlling which users create
           dependencies on a type, which could prevent the owner from changing
           the type later.)

           For foreign-data wrappers, this privilege enables the grantee to
           create new servers using that foreign-data wrapper.

           For servers, this privilege enables the grantee to create foreign
           tables using the server, and also to create, alter, or drop their
           own user's user mappings associated with that server.

       ALL PRIVILEGES
           Grant all of the available privileges at once. The PRIVILEGES key
           word is optional in PostgreSQL, though it is required by strict
           SQL.
       The privileges required by other commands are listed on the reference
       page of the respective command.

   GRANT on Roles
       This variant of the GRANT command grants membership in a role to one or
       more other roles. Membership in a role is significant because it
       conveys the privileges granted to a role to each of its members.

       If WITH ADMIN OPTION is specified, the member can in turn grant
       membership in the role to others, and revoke membership in the role as
       well. Without the admin option, ordinary users cannot do that. A role
       is not considered to hold WITH ADMIN OPTION on itself, but it may grant
       or revoke membership in itself from a database session where the
       session user matches the role. Database superusers can grant or revoke
       membership in any role to anyone. Roles having CREATEROLE privilege can
       grant or revoke membership in any role that is not a superuser.

       Unlike the case with privileges, membership in a role cannot be granted
       to PUBLIC. Note also that this form of the command does not allow the
       noise word GROUP.

NOTES
       The REVOKE(7) command is used to revoke access privileges.

       Since PostgreSQL 8.1, the concepts of users and groups have been
       unified into a single kind of entity called a role. It is therefore no
       longer necessary to use the keyword GROUP to identify whether a grantee
       is a user or a group.  GROUP is still allowed in the command, but it is
       a noise word.

       A user may perform SELECT, INSERT, etc. on a column if they hold that
       privilege for either the specific column or its whole table. Granting
       the privilege at the table level and then revoking it for one column
       will not do what one might wish: the table-level grant is unaffected by
       a column-level operation.

<!-- 2aae4b53-bcdf-4cea-9b45-c301bef902cf <=< ACCEPT -->       When a non-owner of an object attempts to GRANT privileges on the
       object, the command will fail outright if the user has no privileges
       whatsoever on the object. As long as some privilege is available, the
       command will proceed, but it will grant only those privileges for which
       the user has grant options. The GRANT ALL PRIVILEGES forms will issue a
       warning message if no grant options are held, while the other forms
       will issue a warning if grant options for any of the privileges
       specifically named in the command are not held. (In principle these
       statements apply to the object owner as well, but since the owner is
       always treated as holding all grant options, the cases can never
       occur.)<!-- ACCEPT >=> 2aae4b53-bcdf-4cea-9b45-c301bef902cf -->

       It should be noted that database superusers can access all objects
       regardless of object privilege settings. This is comparable to the
       rights of root in a Unix system. As with root, it's unwise to operate
       as a superuser except when absolutely necessary.

       If a superuser chooses to issue a GRANT or REVOKE command, the command
       is performed as though it were issued by the owner of the affected
       object. In particular, privileges granted via such a command will
       appear to have been granted by the object owner. (For role membership,
       the membership appears to have been granted by the containing role
       itself.)

       GRANT and REVOKE can also be done by a role that is not the owner of
       the affected object, but is a member of the role that owns the object,
       or is a member of a role that holds privileges WITH GRANT OPTION on the
       object. In this case the privileges will be recorded as having been
       granted by the role that actually owns the object or holds the
       privileges WITH GRANT OPTION. For example, if table t1 is owned by role
       g1, of which role u1 is a member, then u1 can grant privileges on t1 to
       u2, but those privileges will appear to have been granted directly by
       g1. Any other member of role g1 could revoke them later.

       If the role executing GRANT holds the required privileges indirectly
       via more than one role membership path, it is unspecified which
       containing role will be recorded as having done the grant. In such
       cases it is best practice to use SET ROLE to become the specific role
       you want to do the GRANT as.

       Granting permission on a table does not automatically extend
       permissions to any sequences used by the table, including sequences
       tied to SERIAL columns. Permissions on sequences must be set
       separately.

       Use psql(1)'s \dp command to obtain information about existing
       privileges for tables and columns. For example:

           =&amp;gt; \dp mytable
                                         Access privileges
            Schema |  Name   | Type  |   Access privileges   | Column access privileges
           --------+---------+-------+-----------------------+--------------------------
            public | mytable | table | miriam=arwdDxt/miriam | col1:
                                     : =r/miriam             :   miriam_rw=rw/miriam
                                     : admin=arw/miriam
           (1 row)

       The entries shown by \dp are interpreted thus:

           rolename=xxxx -- privileges granted to a role
                   =xxxx -- privileges granted to PUBLIC

                       r -- SELECT ("read")
                       w -- UPDATE ("write")
                       a -- INSERT ("append")
                       d -- DELETE
                       D -- TRUNCATE
                       x -- REFERENCES
                       t -- TRIGGER
                       X -- EXECUTE
                       U -- USAGE
                       C -- CREATE
                       c -- CONNECT
                       T -- TEMPORARY
                 arwdDxt -- ALL PRIVILEGES (for tables, varies for other objects)
                       * -- grant option for preceding privilege

                   /yyyy -- role that granted this privilege

       The above example display would be seen by user miriam after creating
       table mytable and doing:

           GRANT SELECT ON mytable TO PUBLIC;
           GRANT SELECT, UPDATE, INSERT ON mytable TO admin;
           GRANT SELECT (col1), UPDATE (col1) ON mytable TO miriam_rw;

       For non-table objects there are other \d commands that can display
       their privileges.

       If the "Access privileges" column is empty for a given object, it means
       the object has default privileges (that is, its privileges column is
       null). Default privileges always include all privileges for the owner,
       and can include some privileges for PUBLIC depending on the object
       type, as explained above. The first GRANT or REVOKE on an object will
       instantiate the default privileges (producing, for example,
       {miriam=arwdDxt/miriam}) and then modify them per the specified
       request. Similarly, entries are shown in "Column access privileges"
       only for columns with nondefault privileges. (Note: for this purpose,
       "default privileges" always means the built-in default privileges for
       the object's type. An object whose privileges have been affected by an
       ALTER DEFAULT PRIVILEGES command will always be shown with an explicit
       privilege entry that includes the effects of the ALTER.)

       Notice that the owner's implicit grant options are not marked in the
       access privileges display. A * will appear only when grant options have
       been explicitly granted to someone.

EXAMPLES
       Grant insert privilege to all users on table films:

           GRANT INSERT ON films TO PUBLIC;

       Grant all available privileges to user manuel on view kinds:

           GRANT ALL PRIVILEGES ON kinds TO manuel;

       Note that while the above will indeed grant all privileges if executed
       by a superuser or the owner of kinds, when executed by someone else it
       will only grant those permissions for which the someone else has grant
       options.

       Grant membership in role admins to user joe:

           GRANT admins TO joe;

COMPATIBILITY
       According to the SQL standard, the PRIVILEGES key word in ALL
       PRIVILEGES is required. The SQL standard does not support setting the
       privileges on more than one object per command.

       PostgreSQL allows an object owner to revoke their own ordinary
       privileges: for example, a table owner can make the table read-only to
       themselves by revoking their own INSERT, UPDATE, DELETE, and TRUNCATE
       privileges. This is not possible according to the SQL standard. The
       reason is that PostgreSQL treats the owner's privileges as having been
       granted by the owner to themselves; therefore they can revoke them too.
       In the SQL standard, the owner's privileges are granted by an assumed
       entity "_SYSTEM". Not being "_SYSTEM", the owner cannot revoke these
       rights.

       According to the SQL standard, grant options can be granted to PUBLIC;
       PostgreSQL only supports granting grant options to roles.

       The SQL standard provides for a USAGE privilege on other kinds of
       objects: character sets, collations, translations.

       In the SQL standard, sequences only have a USAGE privilege, which
       controls the use of the NEXT VALUE FOR expression, which is equivalent
       to the function nextval in PostgreSQL. The sequence privileges SELECT
       and UPDATE are PostgreSQL extensions. The application of the sequence
       USAGE privilege to the currval function is also a PostgreSQL extension
       (as is the function itself).

       Privileges on databases, tablespaces, schemas, and languages are
       PostgreSQL extensions.

SEE ALSO
       REVOKE(7), ALTER DEFAULT PRIVILEGES (ALTER_DEFAULT_PRIVILEGES(7))



PostgreSQL 9.6.1                     2016                             GRANT(7)
PREPARE TRANSACTION(7)  PostgreSQL 9.6.1 Documentation  PREPARE TRANSACTION(7)



NAME
       PREPARE_TRANSACTION - prepare the current transaction for two-phase
       commit

SYNOPSIS
       PREPARE TRANSACTION transaction_id

DESCRIPTION
       PREPARE TRANSACTION prepares the current transaction for two-phase
       commit. After this command, the transaction is no longer associated
       with the current session; instead, its state is fully stored on disk,
       and there is a very high probability that it can be committed
       successfully, even if a database crash occurs before the commit is
       requested.

       Once prepared, a transaction can later be committed or rolled back with
       COMMIT PREPARED (COMMIT_PREPARED(7)) or ROLLBACK PREPARED
       (ROLLBACK_PREPARED(7)), respectively. Those commands can be issued from
       any session, not only the one that executed the original transaction.

       From the point of view of the issuing session, PREPARE TRANSACTION is
       not unlike a ROLLBACK command: after executing it, there is no active
       current transaction, and the effects of the prepared transaction are no
       longer visible. (The effects will become visible again if the
       transaction is committed.)

       If the PREPARE TRANSACTION command fails for any reason, it becomes a
       ROLLBACK: the current transaction is canceled.

PARAMETERS
       transaction_id
           An arbitrary identifier that later identifies this transaction for
           COMMIT PREPARED or ROLLBACK PREPARED. The identifier must be
           written as a string literal, and must be less than 200 bytes long.
           It must not be the same as the identifier used for any currently
           prepared transaction.

NOTES
       PREPARE TRANSACTION is not intended for use in applications or
       interactive sessions. Its purpose is to allow an external transaction
       manager to perform atomic global transactions across multiple databases
       or other transactional resources. Unless you're writing a transaction
       manager, you probably shouldn't be using PREPARE TRANSACTION.

       This command must be used inside a transaction block. Use BEGIN(7) to
       start one.

       It is not currently allowed to PREPARE a transaction that has executed
       any operations involving temporary tables, created any cursors WITH
       HOLD, or executed LISTEN or UNLISTEN. Those features are too tightly
       tied to the current session to be useful in a transaction to be
       prepared.

       If the transaction modified any run-time parameters with SET (without
       the LOCAL option), those effects persist after PREPARE TRANSACTION, and
       will not be affected by any later COMMIT PREPARED or ROLLBACK PREPARED.
       Thus, in this one respect PREPARE TRANSACTION acts more like COMMIT
       than ROLLBACK.

       All currently available prepared transactions are listed in the
       pg_prepared_xacts system view.

           Caution
           It is unwise to leave transactions in the prepared state for a long
           time. This will interfere with the ability of VACUUM to reclaim
           storage, and in extreme cases could cause the database to shut down
           to prevent transaction ID wraparound (see Section 24.1.5,
           "Preventing Transaction ID Wraparound Failures", in the
           documentation). Keep in mind also that the transaction continues to
           hold whatever locks it held. The intended usage of the feature is
           that a prepared transaction will normally be committed or rolled
           back as soon as an external transaction manager has verified that
           other databases are also prepared to commit.

           If you have not set up an external transaction manager to track
           prepared transactions and ensure they get closed out promptly, it
           is best to keep the prepared-transaction feature disabled by
           setting max_prepared_transactions to zero. This will prevent
           accidental creation of prepared transactions that might then be
           forgotten and eventually cause problems.

EXAMPLES
       Prepare the current transaction for two-phase commit, using foobar as
       the transaction identifier:

           PREPARE TRANSACTION 'foobar';

COMPATIBILITY
       PREPARE TRANSACTION is a PostgreSQL extension. It is intended for use
       by external transaction management systems, some of which are covered
       by standards (such as X/Open XA), but the SQL side of those systems is
       not standardized.

SEE ALSO
       COMMIT PREPARED (COMMIT_PREPARED(7)), ROLLBACK PREPARED
       (ROLLBACK_PREPARED(7))



PostgreSQL 9.6.1                     2016               PREPARE TRANSACTION(7)
REASSIGN OWNED(7)       PostgreSQL 9.6.1 Documentation       REASSIGN OWNED(7)



NAME
       REASSIGN_OWNED - change the ownership of database objects owned by a
       database role

SYNOPSIS
       REASSIGN OWNED BY { old_role | CURRENT_USER | SESSION_USER } [, ...]
                      TO { new_role | CURRENT_USER | SESSION_USER }

DESCRIPTION
       REASSIGN OWNED instructs the system to change the ownership of database
       objects owned by any of the old_roles to new_role.

PARAMETERS
       old_role
           The name of a role. The ownership of all the objects within the
           current database, and of all shared objects (databases,
           tablespaces), owned by this role will be reassigned to new_role.

       new_role
           The name of the role that will be made the new owner of the
           affected objects.

NOTES
       REASSIGN OWNED is often used to prepare for the removal of one or more
       roles. Because REASSIGN OWNED does not affect objects within other
       databases, it is usually necessary to execute this command in each
       database that contains objects owned by a role that is to be removed.

       REASSIGN OWNED requires privileges on both the source role(s) and the
       target role.

       The DROP OWNED (DROP_OWNED(7)) command is an alternative that simply
       drops all the database objects owned by one or more roles.

       The REASSIGN OWNED command does not affect any privileges granted to
       the old_roles for objects that are not owned by them. Use DROP OWNED to
       revoke such privileges.

       See Section 21.4, "Dropping Roles", in the documentation for more
       discussion.

COMPATIBILITY
       The REASSIGN OWNED command is a PostgreSQL extension.

SEE ALSO
       DROP OWNED (DROP_OWNED(7)), DROP ROLE (DROP_ROLE(7)), ALTER DATABASE
       (ALTER_DATABASE(7))



PostgreSQL 9.6.1                     2016                    REASSIGN OWNED(7)
CLUSTER(7)              PostgreSQL 9.6.1 Documentation              CLUSTER(7)



NAME
       CLUSTER - cluster a table according to an index

SYNOPSIS
       CLUSTER [VERBOSE] table_name [ USING index_name ]
       CLUSTER [VERBOSE]

DESCRIPTION
       CLUSTER instructs PostgreSQL to cluster the table specified by
       table_name based on the index specified by index_name. The index must
       already have been defined on table_name.

       When a table is clustered, it is physically reordered based on the
       index information. Clustering is a one-time operation: when the table
       is subsequently updated, the changes are not clustered. That is, no
       attempt is made to store new or updated rows according to their index
       order. (If one wishes, one can periodically recluster by issuing the
       command again. Also, setting the table's fillfactor storage parameter
       to less than 100% can aid in preserving cluster ordering during
       updates, since updated rows are kept on the same page if enough space
       is available there.)

       When a table is clustered, PostgreSQL remembers which index it was
       clustered by. The form CLUSTER table_name reclusters the table using
       the same index as before. You can also use the CLUSTER or SET WITHOUT
       CLUSTER forms of ALTER TABLE (ALTER_TABLE(7)) to set the index to be
       used for future cluster operations, or to clear any previous setting.

       CLUSTER without any parameter reclusters all the previously-clustered
       tables in the current database that the calling user owns, or all such
       tables if called by a superuser. This form of CLUSTER cannot be
       executed inside a transaction block.

       When a table is being clustered, an ACCESS EXCLUSIVE lock is acquired
       on it. This prevents any other database operations (both reads and
       writes) from operating on the table until the CLUSTER is finished.

PARAMETERS
       table_name
           The name (possibly schema-qualified) of a table.

       index_name
           The name of an index.

       VERBOSE
           Prints a progress report as each table is clustered.

NOTES
       In cases where you are accessing single rows randomly within a table,
       the actual order of the data in the table is unimportant. However, if
       you tend to access some data more than others, and there is an index
       that groups them together, you will benefit from using CLUSTER. If you
       are requesting a range of indexed values from a table, or a single
       indexed value that has multiple rows that match, CLUSTER will help
       because once the index identifies the table page for the first row that
       matches, all other rows that match are probably already on the same
       table page, and so you save disk accesses and speed up the query.

       CLUSTER can re-sort the table using either an index scan on the
       specified index, or (if the index is a b-tree) a sequential scan
       followed by sorting. It will attempt to choose the method that will be
       faster, based on planner cost parameters and available statistical
       information.

       When an index scan is used, a temporary copy of the table is created
       that contains the table data in the index order. Temporary copies of
       each index on the table are created as well. Therefore, you need free
       space on disk at least equal to the sum of the table size and the index
       sizes.

       When a sequential scan and sort is used, a temporary sort file is also
       created, so that the peak temporary space requirement is as much as
       double the table size, plus the index sizes. This method is often
       faster than the index scan method, but if the disk space requirement is
       intolerable, you can disable this choice by temporarily setting
       enable_sort to off.

       It is advisable to set maintenance_work_mem to a reasonably large value
       (but not more than the amount of RAM you can dedicate to the CLUSTER
       operation) before clustering.

       Because the planner records statistics about the ordering of tables, it
       is advisable to run ANALYZE(7) on the newly clustered table. Otherwise,
       the planner might make poor choices of query plans.

       Because CLUSTER remembers which indexes are clustered, one can cluster
       the tables one wants clustered manually the first time, then set up a
       periodic maintenance script that executes CLUSTER without any
       parameters, so that the desired tables are periodically reclustered.

EXAMPLES
       Cluster the table employees on the basis of its index employees_ind:

           CLUSTER employees USING employees_ind;

       Cluster the employees table using the same index that was used before:

           CLUSTER employees;

       Cluster all tables in the database that have previously been clustered:

           CLUSTER;

COMPATIBILITY
       There is no CLUSTER statement in the SQL standard.

       The syntax

           CLUSTER index_name ON table_name

       is also supported for compatibility with pre-8.3 PostgreSQL versions.

SEE ALSO
       clusterdb(1)



PostgreSQL 9.6.1                     2016                           CLUSTER(7)
DROP USER(7)            PostgreSQL 9.6.1 Documentation            DROP USER(7)



NAME
       DROP_USER - remove a database role

SYNOPSIS
       DROP USER [ IF EXISTS ] name [, ...]

DESCRIPTION
       DROP USER is simply an alternate spelling of DROP ROLE (DROP_ROLE(7)).

COMPATIBILITY
       The DROP USER statement is a PostgreSQL extension. The SQL standard
       leaves the definition of users to the implementation.

SEE ALSO
       DROP ROLE (DROP_ROLE(7))



PostgreSQL 9.6.1                     2016                         DROP USER(7)
CREATE FOREIGN TABLE(7) PostgreSQL 9.6.1 Documentation CREATE FOREIGN TABLE(7)



NAME
       CREATE_FOREIGN_TABLE - define a new foreign table

SYNOPSIS
       CREATE FOREIGN TABLE [ IF NOT EXISTS ] table_name ( [
         { column_name data_type [ OPTIONS ( option 'value' [, ... ] ) ] [ COLLATE collation ] [ column_constraint [ ... ] ]
           | table_constraint }
           [, ... ]
       ] )
       [ INHERITS ( parent_table [, ... ] ) ]
         SERVER server_name
       [ OPTIONS ( option 'value' [, ... ] ) ]

       where column_constraint is:

       [ CONSTRAINT constraint_name ]
       { NOT NULL |
         NULL |
         CHECK ( expression ) [ NO INHERIT ] |
         DEFAULT default_expr }

       and table_constraint is:

       [ CONSTRAINT constraint_name ]
       CHECK ( expression ) [ NO INHERIT ]

DESCRIPTION
       CREATE FOREIGN TABLE creates a new foreign table in the current
       database. The table will be owned by the user issuing the command.

       If a schema name is given (for example, CREATE FOREIGN TABLE
       myschema.mytable ...) then the table is created in the specified
       schema. Otherwise it is created in the current schema. The name of the
       foreign table must be distinct from the name of any other foreign
       table, table, sequence, index, view, or materialized view in the same
       schema.

       CREATE FOREIGN TABLE also automatically creates a data type that
       represents the composite type corresponding to one row of the foreign
       table. Therefore, foreign tables cannot have the same name as any
       existing data type in the same schema.

       To be able to create a foreign table, you must have USAGE privilege on
       the foreign server, as well as USAGE privilege on all column types used
       in the table.

PARAMETERS
<!-- c6acb2a0-d8a1-44cd-b054-cf74edbb706e <=< ACCEPT -->       IF NOT EXISTS
           Do not throw an error if a relation with the same name already
           exists. A notice is issued in this case. Note that there is no
           guarantee that the existing relation is anything like the one that
           would have been created.

       table_name
           The name (optionally schema-qualified) of the table to be created.<!-- ACCEPT >=> c6acb2a0-d8a1-44cd-b054-cf74edbb706e -->

<!-- 03dd7c3c-cec6-415e-9bd2-60cabe0e09e6 <=< ACCEPT -->       column_name
           The name of a column to be created in the new table.

       data_type
           The data type of the column. This can include array specifiers. For
           more information on the data types supported by PostgreSQL, refer
           to Chapter 8, Data Types, in the documentation.

       COLLATE collation
           The COLLATE clause assigns a collation to the column (which must be
           of a collatable data type). If not specified, the column data
           type's default collation is used.

       INHERITS ( parent_table [, ... ] )
           The optional INHERITS clause specifies a list of tables from which
           the new foreign table automatically inherits all columns. Parent
           tables can be plain tables or foreign tables. See the similar form
           of CREATE TABLE (CREATE_TABLE(7)) for more details.<!-- ACCEPT >=> 03dd7c3c-cec6-415e-9bd2-60cabe0e09e6 -->

<!-- 83d0f615-1ce7-4189-9231-c298168f3608 <=< ACCEPT -->       CONSTRAINT constraint_name
           An optional name for a column or table constraint. If the
           constraint is violated, the constraint name is present in error
           messages, so constraint names like col must be positive can be used
           to communicate helpful constraint information to client
           applications. (Double-quotes are needed to specify constraint names
           that contain spaces.) If a constraint name is not specified, the
           system generates a name.

       NOT NULL
           The column is not allowed to contain null values.

       NULL
           The column is allowed to contain null values. This is the default.

           This clause is only provided for compatibility with non-standard
           SQL databases. Its use is discouraged in new applications.

       CHECK ( expression ) [ NO INHERIT ]
           The CHECK clause specifies an expression producing a Boolean result
           which each row in the foreign table is expected to satisfy; that
           is, the expression should produce TRUE or UNKNOWN, never FALSE, for
           all rows in the foreign table. A check constraint specified as a
           column constraint should reference that column's value only, while
           an expression appearing in a table constraint can reference
           multiple columns.

           Currently, CHECK expressions cannot contain subqueries nor refer to
           variables other than columns of the current row. The system column
           tableoid may be referenced, but not any other system column.<!-- ACCEPT >=> 83d0f615-1ce7-4189-9231-c298168f3608 -->

           A constraint marked with NO INHERIT will not propagate to child
           tables.

<!-- a91e8e3e-cfc3-46e2-bb0f-77bd6c82afbe <=< ACCEPT -->       DEFAULT default_expr
           The DEFAULT clause assigns a default data value for the column
           whose column definition it appears within. The value is any
           variable-free expression (subqueries and cross-references to other
           columns in the current table are not allowed). The data type of the
           default expression must match the data type of the column.

           The default expression will be used in any insert operation that
           does not specify a value for the column. If there is no default for
           a column, then the default is null.<!-- ACCEPT >=> a91e8e3e-cfc3-46e2-bb0f-77bd6c82afbe -->

       server_name
           The name of an existing foreign server to use for the foreign
           table. For details on defining a server, see CREATE SERVER
           (CREATE_SERVER(7)).

       OPTIONS ( option 'value' [, ...] )
           Options to be associated with the new foreign table or one of its
           columns. The allowed option names and values are specific to each
           foreign data wrapper and are validated using the foreign-data
           wrapper's validator function. Duplicate option names are not
           allowed (although it's OK for a table option and a column option to
           have the same name).

NOTES
       Constraints on foreign tables (such as CHECK or NOT NULL clauses) are
       not enforced by the core PostgreSQL system, and most foreign data
       wrappers do not attempt to enforce them either; that is, the constraint
       is simply assumed to hold true. There would be little point in such
       enforcement since it would only apply to rows inserted or updated via
       the foreign table, and not to rows modified by other means, such as
       directly on the remote server. Instead, a constraint attached to a
       foreign table should represent a constraint that is being enforced by
       the remote server.

       Some special-purpose foreign data wrappers might be the only access
       mechanism for the data they access, and in that case it might be
       appropriate for the foreign data wrapper itself to perform constraint
       enforcement. But you should not assume that a wrapper does that unless
       its documentation says so.

       Although PostgreSQL does not attempt to enforce constraints on foreign
       tables, it does assume that they are correct for purposes of query
       optimization. If there are rows visible in the foreign table that do
       not satisfy a declared constraint, queries on the table might produce
       incorrect answers. It is the user's responsibility to ensure that the
       constraint definition matches reality.

EXAMPLES
       Create foreign table films, which will be accessed through the server
       film_server:

           CREATE FOREIGN TABLE films (
               code        char(5) NOT NULL,
               title       varchar(40) NOT NULL,
               did         integer NOT NULL,
               date_prod   date,
               kind        varchar(10),
               len         interval hour to minute
           )
           SERVER film_server;

COMPATIBILITY
       The CREATE FOREIGN TABLE command largely conforms to the SQL standard;
       however, much as with CREATE TABLE, NULL constraints and zero-column
       foreign tables are permitted. The ability to specify column default
       values is also a PostgreSQL extension. Table inheritance, in the form
       defined by PostgreSQL, is nonstandard.

SEE ALSO
       ALTER FOREIGN TABLE (ALTER_FOREIGN_TABLE(7)), DROP FOREIGN TABLE
       (DROP_FOREIGN_TABLE(7)), CREATE TABLE (CREATE_TABLE(7)), CREATE SERVER
       (CREATE_SERVER(7)), IMPORT FOREIGN SCHEMA (IMPORT_FOREIGN_SCHEMA(7))



PostgreSQL 9.6.1                     2016              CREATE FOREIGN TABLE(7)
ANALYZE(7)              PostgreSQL 9.6.1 Documentation              ANALYZE(7)



NAME
       ANALYZE - collect statistics about a database

SYNOPSIS
       ANALYZE [ VERBOSE ] [ table_name [ ( column_name [, ...] ) ] ]

DESCRIPTION
       ANALYZE collects statistics about the contents of tables in the
       database, and stores the results in the pg_statistic system catalog.
       Subsequently, the query planner uses these statistics to help determine
       the most efficient execution plans for queries.

       With no parameter, ANALYZE examines every table in the current
       database. With a parameter, ANALYZE examines only that table. It is
       further possible to give a list of column names, in which case only the
       statistics for those columns are collected.

PARAMETERS
       VERBOSE
           Enables display of progress messages.

       table_name
           The name (possibly schema-qualified) of a specific table to
           analyze. If omitted, all regular tables (but not foreign tables) in
           the current database are analyzed.

<!-- 30ab03c8-2539-4230-9ec4-441dc3a63e60 <=< ACCEPT -->       column_name
           The name of a specific column to analyze. Defaults to all columns.
<!-- ACCEPT >=> 30ab03c8-2539-4230-9ec4-441dc3a63e60 -->
<!-- 46b261de-260a-4534-b162-b5163af74a4b <=< ACCEPT -->OUTPUTS
       When VERBOSE is specified, ANALYZE emits progress messages to indicate
       which table is currently being processed. Various statistics about the
       tables are printed as well.
<!-- ACCEPT >=> 46b261de-260a-4534-b162-b5163af74a4b -->
NOTES
       Foreign tables are analyzed only when explicitly selected. Not all
       foreign data wrappers support ANALYZE. If the table's wrapper does not
       support ANALYZE, the command prints a warning and does nothing.

       In the default PostgreSQL configuration, the autovacuum daemon (see
       Section 24.1.6, "The Autovacuum Daemon", in the documentation) takes
       care of automatic analyzing of tables when they are first loaded with
       data, and as they change throughout regular operation. When autovacuum
       is disabled, it is a good idea to run ANALYZE periodically, or just
       after making major changes in the contents of a table. Accurate
       statistics will help the planner to choose the most appropriate query
       plan, and thereby improve the speed of query processing. A common
       strategy for read-mostly databases is to run VACUUM(7) and ANALYZE once
       a day during a low-usage time of day. (This will not be sufficient if
       there is heavy update activity.)

       ANALYZE requires only a read lock on the target table, so it can run in
       parallel with other activity on the table.

       The statistics collected by ANALYZE usually include a list of some of
       the most common values in each column and a histogram showing the
       approximate data distribution in each column. One or both of these can
       be omitted if ANALYZE deems them uninteresting (for example, in a
       unique-key column, there are no common values) or if the column data
       type does not support the appropriate operators. There is more
       information about the statistics in Chapter 24, Routine Database
       Maintenance Tasks, in the documentation.

       For large tables, ANALYZE takes a random sample of the table contents,
       rather than examining every row. This allows even very large tables to
       be analyzed in a small amount of time. Note, however, that the
       statistics are only approximate, and will change slightly each time
       ANALYZE is run, even if the actual table contents did not change. This
       might result in small changes in the planner's estimated costs shown by
       EXPLAIN(7). In rare situations, this non-determinism will cause the
       planner's choices of query plans to change after ANALYZE is run. To
       avoid this, raise the amount of statistics collected by ANALYZE, as
       described below.

       The extent of analysis can be controlled by adjusting the
       default_statistics_target configuration variable, or on a
       column-by-column basis by setting the per-column statistics target with
       ALTER TABLE ... ALTER COLUMN ... SET STATISTICS (see ALTER TABLE
       (ALTER_TABLE(7))). The target value sets the maximum number of entries
       in the most-common-value list and the maximum number of bins in the
       histogram. The default target value is 100, but this can be adjusted up
       or down to trade off accuracy of planner estimates against the time
       taken for ANALYZE and the amount of space occupied in pg_statistic. In
       particular, setting the statistics target to zero disables collection
       of statistics for that column. It might be useful to do that for
       columns that are never used as part of the WHERE, GROUP BY, or ORDER BY
       clauses of queries, since the planner will have no use for statistics
       on such columns.

       The largest statistics target among the columns being analyzed
       determines the number of table rows sampled to prepare the statistics.
       Increasing the target causes a proportional increase in the time and
       space needed to do ANALYZE.

       One of the values estimated by ANALYZE is the number of distinct values
       that appear in each column. Because only a subset of the rows are
       examined, this estimate can sometimes be quite inaccurate, even with
       the largest possible statistics target. If this inaccuracy leads to bad
       query plans, a more accurate value can be determined manually and then
       installed with ALTER TABLE ... ALTER COLUMN ... SET (n_distinct = ...)
       (see ALTER TABLE (ALTER_TABLE(7))).

       If the table being analyzed has one or more children, ANALYZE will
       gather statistics twice: once on the rows of the parent table only, and
       a second time on the rows of the parent table with all of its children.
       This second set of statistics is needed when planning queries that
       traverse the entire inheritance tree. The autovacuum daemon, however,
       will only consider inserts or updates on the parent table itself when
       deciding whether to trigger an automatic analyze for that table. If
       that table is rarely inserted into or updated, the inheritance
       statistics will not be up to date unless you run ANALYZE manually.

       If any of the child tables are foreign tables whose foreign data
       wrappers do not support ANALYZE, those child tables are ignored while
       gathering inheritance statistics.

       If the table being analyzed is completely empty, ANALYZE will not
       record new statistics for that table. Any existing statistics will be
       retained.

COMPATIBILITY
       There is no ANALYZE statement in the SQL standard.

SEE ALSO
       VACUUM(7), vacuumdb(1), Section 19.4.4, "Cost-based Vacuum Delay", in
       the documentation, Section 24.1.6, "The Autovacuum Daemon", in the
       documentation



PostgreSQL 9.6.1                     2016                           ANALYZE(7)
REFRESH MATERIALIZED VIEPostgreSQL 9.6.1 DocumentaREFRESH MATERIALIZED VIEW(7)



NAME
       REFRESH_MATERIALIZED_VIEW - replace the contents of a materialized view

SYNOPSIS
       REFRESH MATERIALIZED VIEW [ CONCURRENTLY ] name
           [ WITH [ NO ] DATA ]

DESCRIPTION
       REFRESH MATERIALIZED VIEW completely replaces the contents of a
       materialized view. The old contents are discarded. If WITH DATA is
       specified (or defaults) the backing query is executed to provide the
       new data, and the materialized view is left in a scannable state. If
       WITH NO DATA is specified no new data is generated and the materialized
       view is left in an unscannable state.

       CONCURRENTLY and WITH NO DATA may not be specified together.

PARAMETERS
       CONCURRENTLY
           Refresh the materialized view without locking out concurrent
           selects on the materialized view. Without this option a refresh
           which affects a lot of rows will tend to use fewer resources and
           complete more quickly, but could block other connections which are
           trying to read from the materialized view. This option may be
           faster in cases where a small number of rows are affected.

           This option is only allowed if there is at least one UNIQUE index
           on the materialized view which uses only column names and includes
           all rows; that is, it must not index on any expressions nor include
           a WHERE clause.

           This option may not be used when the materialized view is not
           already populated.

           Even with this option only one REFRESH at a time may run against
           any one materialized view.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the materialized view to
           refresh.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

NOTES
       While the default index for future CLUSTER(7) operations is retained,
       REFRESH MATERIALIZED VIEW does not order the generated rows based on
       this property. If you want the data to be ordered upon generation, you
       must use an ORDER BY clause in the backing query.

EXAMPLES
       This command will replace the contents of the materialized view called
       order_summary using the query from the materialized view's definition,
       and leave it in a scannable state:

           REFRESH MATERIALIZED VIEW order_summary;

       This command will free storage associated with the materialized view
       annual_statistics_basis and leave it in an unscannable state:

           REFRESH MATERIALIZED VIEW annual_statistics_basis WITH NO DATA;

COMPATIBILITY
       REFRESH MATERIALIZED VIEW is a PostgreSQL extension.

SEE ALSO
       CREATE MATERIALIZED VIEW (CREATE_MATERIALIZED_VIEW(7)), ALTER
       MATERIALIZED VIEW (ALTER_MATERIALIZED_VIEW(7)), DROP MATERIALIZED VIEW
       (DROP_MATERIALIZED_VIEW(7))



PostgreSQL 9.6.1                     2016         REFRESH MATERIALIZED VIEW(7)
<!-- 46125e7b-f5a2-4727-b5b1-3cd97452e8b1 <=< ACCEPT -->COMMIT PREPARED(7)      PostgreSQL 9.6.1 Documentation      COMMIT PREPARED(7)



NAME
       COMMIT_PREPARED - commit a transaction that was earlier prepared for
       two-phase commit

SYNOPSIS
       COMMIT PREPARED transaction_id

DESCRIPTION
       COMMIT PREPARED commits a transaction that is in prepared state.

PARAMETERS
       transaction_id
           The transaction identifier of the transaction that is to be
           committed.

NOTES
       To commit a prepared transaction, you must be either the same user that
       executed the transaction originally, or a superuser. But you do not
       have to be in the same session that executed the transaction.

       This command cannot be executed inside a transaction block. The
       prepared transaction is committed immediately.

       All currently available prepared transactions are listed in the
       pg_prepared_xacts system view.

EXAMPLES
       Commit the transaction identified by the transaction identifier foobar:

           COMMIT PREPARED 'foobar';

COMPATIBILITY
       COMMIT PREPARED is a PostgreSQL extension. It is intended for use by
       external transaction management systems, some of which are covered by
       standards (such as X/Open XA), but the SQL side of those systems is not
       standardized.

SEE ALSO
       PREPARE TRANSACTION (PREPARE_TRANSACTION(7)), ROLLBACK PREPARED
       (ROLLBACK_PREPARED(7))
<!-- ACCEPT >=> 46125e7b-f5a2-4727-b5b1-3cd97452e8b1 -->


PostgreSQL 9.6.1                     2016                   COMMIT PREPARED(7)
ALTER ROLE(7)           PostgreSQL 9.6.1 Documentation           ALTER ROLE(7)



<!-- 10034cb1-0a09-4f3b-a034-a986f6882838 <=< ACCEPT -->NAME
       ALTER_ROLE - change a database role

SYNOPSIS
       ALTER ROLE role_specification [ WITH ] option [ ... ]

       where option can be:

             SUPERUSER | NOSUPERUSER
           | CREATEDB | NOCREATEDB
           | CREATEROLE | NOCREATEROLE
           | INHERIT | NOINHERIT
           | LOGIN | NOLOGIN
           | REPLICATION | NOREPLICATION
           | BYPASSRLS | NOBYPASSRLS
           | CONNECTION LIMIT connlimit
           | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
           | VALID UNTIL 'timestamp'

       ALTER ROLE name RENAME TO new_name

       ALTER ROLE { role_specification | ALL } [ IN DATABASE database_name ] SET configuration_parameter { TO | = } { value | DEFAULT }
       ALTER ROLE { role_specification | ALL } [ IN DATABASE database_name ] SET configuration_parameter FROM CURRENT
       ALTER ROLE { role_specification | ALL } [ IN DATABASE database_name ] RESET configuration_parameter
       ALTER ROLE { role_specification | ALL } [ IN DATABASE database_name ] RESET ALL

       where role_specification can be:

           [ GROUP ] role_name
         | CURRENT_USER
         | SESSION_USER<!-- ACCEPT >=> 10034cb1-0a09-4f3b-a034-a986f6882838 -->

DESCRIPTION
       ALTER ROLE changes the attributes of a PostgreSQL role.

       The first variant of this command listed in the synopsis can change
       many of the role attributes that can be specified in CREATE ROLE
       (CREATE_ROLE(7)). (All the possible attributes are covered, except that
       there are no options for adding or removing memberships; use GRANT(7)
       and REVOKE(7) for that.) Attributes not mentioned in the command retain
       their previous settings. Database superusers can change any of these
       settings for any role. Roles having CREATEROLE privilege can change any
       of these settings, but only for non-superuser and non-replication
       roles. Ordinary roles can only change their own password.

       The second variant changes the name of the role. Database superusers
       can rename any role. Roles having CREATEROLE privilege can rename
       non-superuser roles. The current session user cannot be renamed.
       (Connect as a different user if you need to do that.) Because
       MD5-encrypted passwords use the role name as cryptographic salt,
       renaming a role clears its password if the password is MD5-encrypted.

       The remaining variants change a role's session default for a
       configuration variable, either for all databases or, when the IN
       DATABASE clause is specified, only for sessions in the named database.
       If ALL is specified instead of a role name, this changes the setting
       for all roles. Using ALL with IN DATABASE is effectively the same as
       using the command ALTER DATABASE ... SET ....

       Whenever the role subsequently starts a new session, the specified
       value becomes the session default, overriding whatever setting is
       present in postgresql.conf or has been received from the postgres
       command line. This only happens at login time; executing SET ROLE
       (SET_ROLE(7)) or SET SESSION AUTHORIZATION
       (SET_SESSION_AUTHORIZATION(7)) does not cause new configuration values
       to be set. Settings set for all databases are overridden by
       database-specific settings attached to a role. Settings for specific
       databases or specific roles override settings for all roles.

       Superusers can change anyone's session defaults. Roles having
       CREATEROLE privilege can change defaults for non-superuser roles.
       Ordinary roles can only set defaults for themselves. Certain
       configuration variables cannot be set this way, or can only be set if a
       superuser issues the command. Only superusers can change a setting for
       all roles in all databases.

PARAMETERS
       name
           The name of the role whose attributes are to be altered.

       CURRENT_USER
           Alter the current user instead of an explicitly identified role.

       SESSION_USER
           Alter the current session user instead of an explicitly identified
           role.

       SUPERUSER
       NOSUPERUSER
       CREATEDB
       NOCREATEDB
       CREATEROLE
       NOCREATEROLE
       INHERIT
       NOINHERIT
       LOGIN
       NOLOGIN
       REPLICATION
       NOREPLICATION
       BYPASSRLS
       NOBYPASSRLS
       CONNECTION LIMIT connlimit
       PASSWORD password
       ENCRYPTED
       UNENCRYPTED
       VALID UNTIL 'timestamp'
           These clauses alter attributes originally set by CREATE ROLE
           (CREATE_ROLE(7)). For more information, see the CREATE ROLE
           reference page.

       new_name
           The new name of the role.

       database_name
           The name of the database the configuration variable should be set
           in.

<!-- 253cd41f-793d-492d-acb3-228e37ef29bb <=< ACCEPT -->       configuration_parameter
       value
           Set this role's session default for the specified configuration
           parameter to the given value. If value is DEFAULT or, equivalently,
           RESET is used, the role-specific variable setting is removed, so
           the role will inherit the system-wide default setting in new
           sessions. Use RESET ALL to clear all role-specific settings.  SET
           FROM CURRENT saves the session's current value of the parameter as
           the role-specific value.<!-- ACCEPT >=> 253cd41f-793d-492d-acb3-228e37ef29bb --> If IN DATABASE is specified, the
           configuration parameter is set or removed for the given role and
           database only.

           Role-specific variable settings take effect only at login; SET ROLE
           (SET_ROLE(7)) and SET SESSION AUTHORIZATION
           (SET_SESSION_AUTHORIZATION(7)) do not process role-specific
           variable settings.

           See SET(7) and Chapter 19, Server Configuration, in the
           documentation for more information about allowed parameter names
           and values.

NOTES
       Use CREATE ROLE (CREATE_ROLE(7)) to add new roles, and DROP ROLE
       (DROP_ROLE(7)) to remove a role.

       ALTER ROLE cannot change a role's memberships. Use GRANT(7) and
       REVOKE(7) to do that.

       Caution must be exercised when specifying an unencrypted password with
       this command. The password will be transmitted to the server in
       cleartext, and it might also be logged in the client's command history
       or the server log.  psql(1) contains a command \password that can be
       used to change a role's password without exposing the cleartext
       password.

       It is also possible to tie a session default to a specific database
       rather than to a role; see ALTER DATABASE (ALTER_DATABASE(7)). If there
       is a conflict, database-role-specific settings override role-specific
       ones, which in turn override database-specific ones.

EXAMPLES
       Change a role's password:

           ALTER ROLE davide WITH PASSWORD 'hu8jmn3';

       Remove a role's password:

           ALTER ROLE davide WITH PASSWORD NULL;

       Change a password expiration date, specifying that the password should
       expire at midday on 4th May 2015 using the time zone which is one hour
       ahead of UTC:

           ALTER ROLE chris VALID UNTIL 'May 4 12:00:00 2015 +1';

       Make a password valid forever:

           ALTER ROLE fred VALID UNTIL 'infinity';

       Give a role the ability to create other roles and new databases:

           ALTER ROLE miriam CREATEROLE CREATEDB;

       Give a role a non-default setting of the maintenance_work_mem
       parameter:

           ALTER ROLE worker_bee SET maintenance_work_mem = 100000;

       Give a role a non-default, database-specific setting of the
       client_min_messages parameter:

           ALTER ROLE fred IN DATABASE devel SET client_min_messages = DEBUG;

COMPATIBILITY
       The ALTER ROLE statement is a PostgreSQL extension.

SEE ALSO
       CREATE ROLE (CREATE_ROLE(7)), DROP ROLE (DROP_ROLE(7)), ALTER DATABASE
       (ALTER_DATABASE(7)), SET(7)



PostgreSQL 9.6.1                     2016                        ALTER ROLE(7)
DROP SCHEMA(7)          PostgreSQL 9.6.1 Documentation          DROP SCHEMA(7)



NAME
       DROP_SCHEMA - remove a schema

SYNOPSIS
       DROP SCHEMA [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP SCHEMA removes schemas from the database.

       A schema can only be dropped by its owner or a superuser. Note that the
       owner can drop the schema (and thereby all contained objects) even if
       they do not own some of the objects within the schema.

PARAMETERS
       IF EXISTS
           Do not throw an error if the schema does not exist. A notice is
           issued in this case.

       name
           The name of a schema.

       CASCADE
           Automatically drop objects (tables, functions, etc.) that are
           contained in the schema, and in turn all objects that depend on
           those objects (see Section 5.13, "Dependency Tracking", in the
           documentation).

       RESTRICT
           Refuse to drop the schema if it contains any objects. This is the
           default.

NOTES
       Using the CASCADE option might make the command remove objects in other
       schemas besides the one(s) named.

EXAMPLES
       To remove schema mystuff from the database, along with everything it
       contains:

           DROP SCHEMA mystuff CASCADE;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       DROP SCHEMA is fully conforming with the SQL standard, except that the
       standard only allows one schema to be dropped per command, and apart
       from the IF EXISTS option, which is a PostgreSQL extension.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

SEE ALSO
       ALTER SCHEMA (ALTER_SCHEMA(7)), CREATE SCHEMA (CREATE_SCHEMA(7))



PostgreSQL 9.6.1                     2016                       DROP SCHEMA(7)
UNLISTEN(7)             PostgreSQL 9.6.1 Documentation             UNLISTEN(7)



NAME
       UNLISTEN - stop listening for a notification

SYNOPSIS
       UNLISTEN { channel | * }

DESCRIPTION
       UNLISTEN is used to remove an existing registration for NOTIFY events.
       UNLISTEN cancels any existing registration of the current PostgreSQL
       session as a listener on the notification channel named channel. The
       special wildcard * cancels all listener registrations for the current
       session.

       NOTIFY(7) contains a more extensive discussion of the use of LISTEN and
       NOTIFY.

PARAMETERS
       channel
           Name of a notification channel (any identifier).

       *
           All current listen registrations for this session are cleared.

NOTES
       You can unlisten something you were not listening for; no warning or
       error will appear.

       At the end of each session, UNLISTEN * is automatically executed.

       A transaction that has executed UNLISTEN cannot be prepared for
       two-phase commit.

EXAMPLES
       To make a registration:

           LISTEN virtual;
           NOTIFY virtual;
           Asynchronous notification "virtual" received from server process with PID 8448.

       Once UNLISTEN has been executed, further NOTIFY messages will be
       ignored:

           UNLISTEN virtual;
           NOTIFY virtual;
           -- no NOTIFY event is received

COMPATIBILITY
       There is no UNLISTEN command in the SQL standard.

SEE ALSO
       LISTEN(7), NOTIFY(7)



PostgreSQL 9.6.1                     2016                          UNLISTEN(7)
ALTER INDEX(7)          PostgreSQL 9.6.1 Documentation          ALTER INDEX(7)



NAME
       ALTER_INDEX - change the definition of an index

SYNOPSIS
       ALTER INDEX [ IF EXISTS ] name RENAME TO new_name
       ALTER INDEX [ IF EXISTS ] name SET TABLESPACE tablespace_name
       ALTER INDEX name DEPENDS ON EXTENSION extension_name
       ALTER INDEX [ IF EXISTS ] name SET ( storage_parameter = value [, ... ] )
       ALTER INDEX [ IF EXISTS ] name RESET ( storage_parameter [, ... ] )
       ALTER INDEX ALL IN TABLESPACE name [ OWNED BY role_name [, ... ] ]
           SET TABLESPACE new_tablespace [ NOWAIT ]

DESCRIPTION
       ALTER INDEX changes the definition of an existing index. There are
       several subforms:

       RENAME
           The RENAME form changes the name of the index. There is no effect
           on the stored data.

<!-- 2b006584-429f-4021-86e0-99ef3a6619e6 <=< ACCEPT -->       SET TABLESPACE
           This form changes the index's tablespace to the specified
           tablespace and moves the data file(s) associated with the index to
           the new tablespace. To change the tablespace of an index, you must
           own the index and have CREATE privilege on the new tablespace. All
           indexes in the current database in a tablespace can be moved by
           using the ALL IN TABLESPACE form, which will lock all indexes to be
           moved and then move each one. This form also supports OWNED BY,
           which will only move indexes owned by the roles specified. If the
           NOWAIT option is specified then the command will fail if it is
           unable to acquire all of the locks required immediately. Note that
           system catalogs will not be moved by this command, use ALTER
           DATABASE or explicit ALTER INDEX invocations instead if desired.
           See also CREATE TABLESPACE (CREATE_TABLESPACE(7)).<!-- ACCEPT >=> 2b006584-429f-4021-86e0-99ef3a6619e6 -->

       DEPENDS ON EXTENSION
           This form marks the index as dependent on the extension, such that
           if the extension is dropped, the index will automatically be
           dropped as well.

       SET ( storage_parameter = value [, ... ] )
           This form changes one or more index-method-specific storage
           parameters for the index. See CREATE INDEX (CREATE_INDEX(7)) for
           details on the available parameters. Note that the index contents
           will not be modified immediately by this command; depending on the
           parameter you might need to rebuild the index with REINDEX(7) to
           get the desired effects.

       RESET ( storage_parameter [, ... ] )
           This form resets one or more index-method-specific storage
           parameters to their defaults. As with SET, a REINDEX might be
           needed to update the index entirely.

PARAMETERS
       IF EXISTS
           Do not throw an error if the index does not exist. A notice is
           issued in this case.

       name
           The name (possibly schema-qualified) of an existing index to alter.

       new_name
           The new name for the index.

       tablespace_name
           The tablespace to which the index will be moved.

       extension_name
           The name of the extension that the index is to depend on.

       storage_parameter
           The name of an index-method-specific storage parameter.

       value
           The new value for an index-method-specific storage parameter. This
           might be a number or a word depending on the parameter.

NOTES
       These operations are also possible using ALTER TABLE (ALTER_TABLE(7)).
       ALTER INDEX is in fact just an alias for the forms of ALTER TABLE that
       apply to indexes.

       There was formerly an ALTER INDEX OWNER variant, but this is now
       ignored (with a warning). An index cannot have an owner different from
       its table's owner. Changing the table's owner automatically changes the
       index as well.

       Changing any part of a system catalog index is not permitted.

EXAMPLES
       To rename an existing index:

           ALTER INDEX distributors RENAME TO suppliers;

       To move an index to a different tablespace:

           ALTER INDEX distributors SET TABLESPACE fasttablespace;

       To change an index's fill factor (assuming that the index method
       supports it):

           ALTER INDEX distributors SET (fillfactor = 75);
           REINDEX INDEX distributors;

COMPATIBILITY
       ALTER INDEX is a PostgreSQL extension.

SEE ALSO
       CREATE INDEX (CREATE_INDEX(7)), REINDEX(7)



PostgreSQL 9.6.1                     2016                       ALTER INDEX(7)
CREATE MATERIALIZED VIEWPostgreSQL 9.6.1 DocumentatCREATE MATERIALIZED VIEW(7)



NAME
       CREATE_MATERIALIZED_VIEW - define a new materialized view

SYNOPSIS
       CREATE MATERIALIZED VIEW [ IF NOT EXISTS ] table_name
           [ (column_name [, ...] ) ]
           [ WITH ( storage_parameter [= value] [, ... ] ) ]
           [ TABLESPACE tablespace_name ]
           AS query
           [ WITH [ NO ] DATA ]

DESCRIPTION
       CREATE MATERIALIZED VIEW defines a materialized view of a query. The
       query is executed and used to populate the view at the time the command
       is issued (unless WITH NO DATA is used) and may be refreshed later
       using REFRESH MATERIALIZED VIEW.

       CREATE MATERIALIZED VIEW is similar to CREATE TABLE AS, except that it
       also remembers the query used to initialize the view, so that it can be
       refreshed later upon demand. A materialized view has many of the same
       properties as a table, but there is no support for temporary
       materialized views or automatic generation of OIDs.

PARAMETERS
       IF NOT EXISTS
           Do not throw an error if a materialized view with the same name
           already exists. A notice is issued in this case. Note that there is
           no guarantee that the existing materialized view is anything like
           the one that would have been created.

       table_name
           The name (optionally schema-qualified) of the materialized view to
           be created.

       column_name
           The name of a column in the new materialized view. If column names
           are not provided, they are taken from the output column names of
           the query.

       WITH ( storage_parameter [= value] [, ... ] )
           This clause specifies optional storage parameters for the new
           materialized view; see Storage Parameters for more information. All
           parameters supported for CREATE TABLE are also supported for CREATE
           MATERIALIZED VIEW with the exception of OIDS. See CREATE TABLE
           (CREATE_TABLE(7)) for more information.

       TABLESPACE tablespace_name
           The tablespace_name is the name of the tablespace in which the new
           materialized view is to be created. If not specified,
           default_tablespace is consulted.

       query
           A SELECT(7), TABLE, or VALUES(7) command. This query will run
           within a security-restricted operation; in particular, calls to
           functions that themselves create temporary tables will fail.

       WITH [ NO ] DATA
           This clause specifies whether or not the materialized view should
           be populated at creation time. If not, the materialized view will
           be flagged as unscannable and cannot be queried until REFRESH
           MATERIALIZED VIEW is used.

COMPATIBILITY
       CREATE MATERIALIZED VIEW is a PostgreSQL extension.

SEE ALSO
       ALTER MATERIALIZED VIEW (ALTER_MATERIALIZED_VIEW(7)), CREATE TABLE AS
       (CREATE_TABLE_AS(7)), CREATE VIEW (CREATE_VIEW(7)), DROP MATERIALIZED
       VIEW (DROP_MATERIALIZED_VIEW(7)), REFRESH MATERIALIZED VIEW
       (REFRESH_MATERIALIZED_VIEW(7))



PostgreSQL 9.6.1                     2016          CREATE MATERIALIZED VIEW(7)
CREATE TEXT SEARCH CONFIPostgreSQL)9.6.1 DoCREATEaTEXT SEARCH CONFIGURATION(7)



NAME
       CREATE_TEXT_SEARCH_CONFIGURATION - define a new text search
       configuration

SYNOPSIS
       CREATE TEXT SEARCH CONFIGURATION name (
           PARSER = parser_name |
           COPY = source_config
       )

DESCRIPTION
       CREATE TEXT SEARCH CONFIGURATION creates a new text search
       configuration. A text search configuration specifies a text search
       parser that can divide a string into tokens, plus dictionaries that can
       be used to determine which tokens are of interest for searching.

       If only the parser is specified, then the new text search configuration
       initially has no mappings from token types to dictionaries, and
       therefore will ignore all words. Subsequent ALTER TEXT SEARCH
       CONFIGURATION commands must be used to create mappings to make the
       configuration useful. Alternatively, an existing text search
       configuration can be copied.

       If a schema name is given then the text search configuration is created
       in the specified schema. Otherwise it is created in the current schema.

       The user who defines a text search configuration becomes its owner.

       Refer to Chapter 12, Full Text Search, in the documentation for further
       information.

PARAMETERS
       name
           The name of the text search configuration to be created. The name
           can be schema-qualified.

       parser_name
           The name of the text search parser to use for this configuration.

       source_config
           The name of an existing text search configuration to copy.

NOTES
       The PARSER and COPY options are mutually exclusive, because when an
       existing configuration is copied, its parser selection is copied too.

COMPATIBILITY
       There is no CREATE TEXT SEARCH CONFIGURATION statement in the SQL
       standard.

SEE ALSO
       ALTER TEXT SEARCH CONFIGURATION (ALTER_TEXT_SEARCH_CONFIGURATION(7)),
       DROP TEXT SEARCH CONFIGURATION (DROP_TEXT_SEARCH_CONFIGURATION(7))



PostgreSQL 9.6.1                     2016  CREATE TEXT SEARCH CONFIGURATION(7)
SET(7)                  PostgreSQL 9.6.1 Documentation                  SET(7)



NAME
       SET - change a run-time parameter

SYNOPSIS
       SET [ SESSION | LOCAL ] configuration_parameter { TO | = } { value | 'value' | DEFAULT }
       SET [ SESSION | LOCAL ] TIME ZONE { timezone | LOCAL | DEFAULT }

DESCRIPTION
       The SET command changes run-time configuration parameters. Many of the
       run-time parameters listed in Chapter 19, Server Configuration, in the
       documentation can be changed on-the-fly with SET. (But some require
       superuser privileges to change, and others cannot be changed after
       server or session start.)  SET only affects the value used by the
       current session.

       If SET (or equivalently SET SESSION) is issued within a transaction
       that is later aborted, the effects of the SET command disappear when
       the transaction is rolled back. Once the surrounding transaction is
       committed, the effects will persist until the end of the session,
       unless overridden by another SET.

       The effects of SET LOCAL last only till the end of the current
       transaction, whether committed or not. A special case is SET followed
       by SET LOCAL within a single transaction: the SET LOCAL value will be
       seen until the end of the transaction, but afterwards (if the
       transaction is committed) the SET value will take effect.

       The effects of SET or SET LOCAL are also canceled by rolling back to a
       savepoint that is earlier than the command.

       If SET LOCAL is used within a function that has a SET option for the
       same variable (see CREATE FUNCTION (CREATE_FUNCTION(7))), the effects
       of the SET LOCAL command disappear at function exit; that is, the value
       in effect when the function was called is restored anyway. This allows
       SET LOCAL to be used for dynamic or repeated changes of a parameter
       within a function, while still having the convenience of using the SET
       option to save and restore the caller's value. However, a regular SET
       command overrides any surrounding function's SET option; its effects
       will persist unless rolled back.

           Note
           In PostgreSQL versions 8.0 through 8.2, the effects of a SET LOCAL
           would be canceled by releasing an earlier savepoint, or by
           successful exit from a PL/pgSQL exception block. This behavior has
           been changed because it was deemed unintuitive.

PARAMETERS
       SESSION
           Specifies that the command takes effect for the current session.
           (This is the default if neither SESSION nor LOCAL appears.)

       LOCAL
           Specifies that the command takes effect for only the current
           transaction. After COMMIT or ROLLBACK, the session-level setting
           takes effect again. Issuing this outside of a transaction block
           emits a warning and otherwise has no effect.

       configuration_parameter
           Name of a settable run-time parameter. Available parameters are
           documented in Chapter 19, Server Configuration, in the
           documentation and below.

       value
           New value of parameter. Values can be specified as string
           constants, identifiers, numbers, or comma-separated lists of these,
           as appropriate for the particular parameter.  DEFAULT can be
           written to specify resetting the parameter to its default value
           (that is, whatever value it would have had if no SET had been
           executed in the current session).

       Besides the configuration parameters documented in Chapter 19, Server
       Configuration, in the documentation, there are a few that can only be
       adjusted using the SET command or that have a special syntax:

       SCHEMA
           SET SCHEMA 'value' is an alias for SET search_path TO value. Only
           one schema can be specified using this syntax.

       NAMES
           SET NAMES value is an alias for SET client_encoding TO value.

       SEED
           Sets the internal seed for the random number generator (the
           function random). Allowed values are floating-point numbers between
           -1 and 1, which are then multiplied by 2^31-1.

           The seed can also be set by invoking the function setseed:

               SELECT setseed(value);

       TIME ZONE
           SET TIME ZONE value is an alias for SET timezone TO value. The
           syntax SET TIME ZONE allows special syntax for the time zone
           specification. Here are examples of valid values:

           'PST8PDT'
               The time zone for Berkeley, California.

           'Europe/Rome'
               The time zone for Italy.

           -7
               The time zone 7 hours west from UTC (equivalent to PDT).
               Positive values are east from UTC.

           INTERVAL '-08:00' HOUR TO MINUTE
               The time zone 8 hours west from UTC (equivalent to PST).

           LOCAL
           DEFAULT
               Set the time zone to your local time zone (that is, the
               server's default value of timezone).

           Timezone settings given as numbers or intervals are internally
           translated to POSIX timezone syntax. For example, after SET TIME
           ZONE -7, SHOW TIME ZONE would report &amp;lt;-07&amp;gt;+07.

           See Section 8.5.3, "Time Zones", in the documentation for more
           information about time zones.

NOTES
       The function set_config provides equivalent functionality; see Section
       9.26, "System Administration Functions", in the documentation. Also, it
       is possible to UPDATE the pg_settings system view to perform the
       equivalent of SET.

EXAMPLES
       Set the schema search path:

           SET search_path TO my_schema, public;

       Set the style of date to traditional POSTGRES with "day before month"
       input convention:

           SET datestyle TO postgres, dmy;

       Set the time zone for Berkeley, California:

           SET TIME ZONE 'PST8PDT';

       Set the time zone for Italy:

           SET TIME ZONE 'Europe/Rome';

COMPATIBILITY
       SET TIME ZONE extends syntax defined in the SQL standard. The standard
       allows only numeric time zone offsets while PostgreSQL allows more
       flexible time-zone specifications. All other SET features are
       PostgreSQL extensions.

SEE ALSO
       RESET(7), SHOW(7)



PostgreSQL 9.6.1                     2016                               SET(7)
CREATE SCHEMA(7)        PostgreSQL 9.6.1 Documentation        CREATE SCHEMA(7)



NAME
       CREATE_SCHEMA - define a new schema

SYNOPSIS
       CREATE SCHEMA schema_name [ AUTHORIZATION role_specification ] [ schema_element [ ... ] ]
       CREATE SCHEMA AUTHORIZATION role_specification [ schema_element [ ... ] ]
       CREATE SCHEMA IF NOT EXISTS schema_name [ AUTHORIZATION role_specification ]
       CREATE SCHEMA IF NOT EXISTS AUTHORIZATION role_specification

       where role_specification can be:

           [ GROUP ] user_name
         | CURRENT_USER
         | SESSION_USER

DESCRIPTION
       CREATE SCHEMA enters a new schema into the current database. The schema
       name must be distinct from the name of any existing schema in the
       current database.

       A schema is essentially a namespace: it contains named objects (tables,
       data types, functions, and operators) whose names can duplicate those
       of other objects existing in other schemas. Named objects are accessed
       either by "qualifying" their names with the schema name as a prefix, or
       by setting a search path that includes the desired schema(s). A CREATE
       command specifying an unqualified object name creates the object in the
       current schema (the one at the front of the search path, which can be
       determined with the function current_schema).

       Optionally, CREATE SCHEMA can include subcommands to create objects
       within the new schema. The subcommands are treated essentially the same
       as separate commands issued after creating the schema, except that if
       the AUTHORIZATION clause is used, all the created objects will be owned
       by that user.

PARAMETERS
       schema_name
           The name of a schema to be created. If this is omitted, the
           user_name is used as the schema name. The name cannot begin with
           pg_, as such names are reserved for system schemas.

       user_name
           The role name of the user who will own the new schema. If omitted,
           defaults to the user executing the command. To create a schema
           owned by another role, you must be a direct or indirect member of
           that role, or be a superuser.

       schema_element
           An SQL statement defining an object to be created within the
           schema. Currently, only CREATE TABLE, CREATE VIEW, CREATE INDEX,
           CREATE SEQUENCE, CREATE TRIGGER and GRANT are accepted as clauses
           within CREATE SCHEMA. Other kinds of objects may be created in
           separate commands after the schema is created.

       IF NOT EXISTS
           Do nothing (except issuing a notice) if a schema with the same name
           already exists.  schema_element subcommands cannot be included when
           this option is used.

NOTES
       To create a schema, the invoking user must have the CREATE privilege
       for the current database. (Of course, superusers bypass this check.)

EXAMPLES
       Create a schema:

           CREATE SCHEMA myschema;

       Create a schema for user joe; the schema will also be named joe:

           CREATE SCHEMA AUTHORIZATION joe;

       Create a schema named test that will be owned by user joe, unless there
       already is a schema named test. (It does not matter whether joe owns
       the pre-existing schema.)

           CREATE SCHEMA IF NOT EXISTS test AUTHORIZATION joe;

       Create a schema and create a table and view within it:

           CREATE SCHEMA hollywood
               CREATE TABLE films (title text, release date, awards text[])
               CREATE VIEW winners AS
                   SELECT title, release FROM films WHERE awards IS NOT NULL;

       Notice that the individual subcommands do not end with semicolons.

       The following is an equivalent way of accomplishing the same result:

           CREATE SCHEMA hollywood;
           CREATE TABLE hollywood.films (title text, release date, awards text[]);
           CREATE VIEW hollywood.winners AS
               SELECT title, release FROM hollywood.films WHERE awards IS NOT NULL;

COMPATIBILITY
       The SQL standard allows a DEFAULT CHARACTER SET clause in CREATE
       SCHEMA, as well as more subcommand types than are presently accepted by
       PostgreSQL.

       The SQL standard specifies that the subcommands in CREATE SCHEMA can
       appear in any order. The present PostgreSQL implementation does not
       handle all cases of forward references in subcommands; it might
       sometimes be necessary to reorder the subcommands in order to avoid
       forward references.

       According to the SQL standard, the owner of a schema always owns all
       objects within it.  PostgreSQL allows schemas to contain objects owned
       by users other than the schema owner. This can happen only if the
       schema owner grants the CREATE privilege on their schema to someone
       else, or a superuser chooses to create objects in it.

       The IF NOT EXISTS option is a PostgreSQL extension.

SEE ALSO
       ALTER SCHEMA (ALTER_SCHEMA(7)), DROP SCHEMA (DROP_SCHEMA(7))



PostgreSQL 9.6.1                     2016                     CREATE SCHEMA(7)
FETCH(7)                PostgreSQL 9.6.1 Documentation                FETCH(7)



<!-- 6e8bff88-7e24-4615-8efc-03f9ef2f30b3 <=< ACCEPT -->NAME
       FETCH - retrieve rows from a query using a cursor

SYNOPSIS
       FETCH [ direction [ FROM | IN ] ] cursor_name

       where direction can be empty or one of:

           NEXT
           PRIOR
           FIRST
           LAST
           ABSOLUTE count
           RELATIVE count
           count
           ALL
           FORWARD
           FORWARD count
           FORWARD ALL
           BACKWARD
           BACKWARD count
           BACKWARD ALL<!-- ACCEPT >=> 6e8bff88-7e24-4615-8efc-03f9ef2f30b3 -->

DESCRIPTION
       FETCH retrieves rows using a previously-created cursor.

       A cursor has an associated position, which is used by FETCH. The cursor
       position can be before the first row of the query result, on any
       particular row of the result, or after the last row of the result. When
       created, a cursor is positioned before the first row. After fetching
       some rows, the cursor is positioned on the row most recently retrieved.
       If FETCH runs off the end of the available rows then the cursor is left
       positioned after the last row, or before the first row if fetching
       backward.  FETCH ALL or FETCH BACKWARD ALL will always leave the cursor
       positioned after the last row or before the first row.

       The forms NEXT, PRIOR, FIRST, LAST, ABSOLUTE, RELATIVE fetch a single
       row after moving the cursor appropriately. If there is no such row, an
       empty result is returned, and the cursor is left positioned before the
       first row or after the last row as appropriate.

       The forms using FORWARD and BACKWARD retrieve the indicated number of
       rows moving in the forward or backward direction, leaving the cursor
       positioned on the last-returned row (or after/before all rows, if the
       count exceeds the number of rows available).

       RELATIVE 0, FORWARD 0, and BACKWARD 0 all request fetching the current
       row without moving the cursor, that is, re-fetching the most recently
       fetched row. This will succeed unless the cursor is positioned before
       the first row or after the last row; in which case, no row is returned.

           Note
           This page describes usage of cursors at the SQL command level. If
           you are trying to use cursors inside a PL/pgSQL function, the rules
           are different -- see Section 41.7, "Cursors", in the documentation.

PARAMETERS
       direction
           direction defines the fetch direction and number of rows to fetch.
           It can be one of the following:

           NEXT
               Fetch the next row. This is the default if direction is
               omitted.

           PRIOR
               Fetch the prior row.

           FIRST
               Fetch the first row of the query (same as ABSOLUTE 1).

           LAST
               Fetch the last row of the query (same as ABSOLUTE -1).

           ABSOLUTE count
               Fetch the count'th row of the query, or the abs(count)'th row
               from the end if count is negative. Position before first row or
               after last row if count is out of range; in particular,
               ABSOLUTE 0 positions before the first row.

           RELATIVE count
               Fetch the count'th succeeding row, or the abs(count)'th prior
               row if count is negative.  RELATIVE 0 re-fetches the current
               row, if any.

           count
               Fetch the next count rows (same as FORWARD count).

           ALL
               Fetch all remaining rows (same as FORWARD ALL).

           FORWARD
               Fetch the next row (same as NEXT).

           FORWARD count
               Fetch the next count rows.  FORWARD 0 re-fetches the current
               row.

           FORWARD ALL
               Fetch all remaining rows.

           BACKWARD
               Fetch the prior row (same as PRIOR).

           BACKWARD count
               Fetch the prior count rows (scanning backwards).  BACKWARD 0
               re-fetches the current row.

           BACKWARD ALL
               Fetch all prior rows (scanning backwards).

       count
           count is a possibly-signed integer constant, determining the
           location or number of rows to fetch. For FORWARD and BACKWARD
           cases, specifying a negative count is equivalent to changing the
           sense of FORWARD and BACKWARD.

       cursor_name
           An open cursor's name.

OUTPUTS
       On successful completion, a FETCH command returns a command tag of the
       form

           FETCH count

       The count is the number of rows fetched (possibly zero). Note that in
       psql, the command tag will not actually be displayed, since psql
       displays the fetched rows instead.

NOTES
       The cursor should be declared with the SCROLL option if one intends to
       use any variants of FETCH other than FETCH NEXT or FETCH FORWARD with a
       positive count. For simple queries PostgreSQL will allow backwards
       fetch from cursors not declared with SCROLL, but this behavior is best
       not relied on. If the cursor is declared with NO SCROLL, no backward
       fetches are allowed.

       ABSOLUTE fetches are not any faster than navigating to the desired row
       with a relative move: the underlying implementation must traverse all
       the intermediate rows anyway. Negative absolute fetches are even worse:
       the query must be read to the end to find the last row, and then
       traversed backward from there. However, rewinding to the start of the
       query (as with FETCH ABSOLUTE 0) is fast.

       DECLARE(7) is used to define a cursor. Use MOVE(7) to change cursor
       position without retrieving data.

EXAMPLES
       The following example traverses a table using a cursor:

           BEGIN WORK;

           -- Set up a cursor:
           DECLARE liahona SCROLL CURSOR FOR SELECT * FROM films;

           -- Fetch the first 5 rows in the cursor liahona:
           FETCH FORWARD 5 FROM liahona;

            code  |          title          | did | date_prod  |   kind   |  len
           -------+-------------------------+-----+------------+----------+-------
            BL101 | The Third Man           | 101 | 1949-12-23 | Drama    | 01:44
            BL102 | The African Queen       | 101 | 1951-08-11 | Romantic | 01:43
            JL201 | Une Femme est une Femme | 102 | 1961-03-12 | Romantic | 01:25
            P_301 | Vertigo                 | 103 | 1958-11-14 | Action   | 02:08
            P_302 | Becket                  | 103 | 1964-02-03 | Drama    | 02:28

           -- Fetch the previous row:
           FETCH PRIOR FROM liahona;

            code  |  title  | did | date_prod  |  kind  |  len
           -------+---------+-----+------------+--------+-------
            P_301 | Vertigo | 103 | 1958-11-14 | Action | 02:08

           -- Close the cursor and end the transaction:
           CLOSE liahona;
           COMMIT WORK;

COMPATIBILITY
       The SQL standard defines FETCH for use in embedded SQL only. The
       variant of FETCH described here returns the data as if it were a SELECT
       result rather than placing it in host variables. Other than this point,
       FETCH is fully upward-compatible with the SQL standard.

       The FETCH forms involving FORWARD and BACKWARD, as well as the forms
       FETCH count and FETCH ALL, in which FORWARD is implicit, are PostgreSQL
       extensions.

       The SQL standard allows only FROM preceding the cursor name; the option
       to use IN, or to leave them out altogether, is an extension.

SEE ALSO
       CLOSE(7), DECLARE(7), MOVE(7)



PostgreSQL 9.6.1                     2016                             FETCH(7)
DROP SERVER(7)          PostgreSQL 9.6.1 Documentation          DROP SERVER(7)



NAME
       DROP_SERVER - remove a foreign server descriptor

SYNOPSIS
       DROP SERVER [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP SERVER removes an existing foreign server descriptor. To execute
       this command, the current user must be the owner of the server.

PARAMETERS
       IF EXISTS
           Do not throw an error if the server does not exist. A notice is
           issued in this case.

       name
           The name of an existing server.

       CASCADE
           Automatically drop objects that depend on the server (such as user
           mappings), and in turn all objects that depend on those objects
           (see Section 5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the server if any objects depend on it. This is the
           default.

EXAMPLES
       Drop a server foo if it exists:

           DROP SERVER IF EXISTS foo;

COMPATIBILITY
       DROP SERVER conforms to ISO/IEC 9075-9 (SQL/MED). The IF EXISTS clause
       is a PostgreSQL extension.

SEE ALSO
       CREATE SERVER (CREATE_SERVER(7)), ALTER SERVER (ALTER_SERVER(7))



PostgreSQL 9.6.1                     2016                       DROP SERVER(7)
<!-- 46125e7b-f5a2-4727-b5b1-3cd97452e8b1 <=< ACCEPT -->ROLLBACK PREPARED(7)    PostgreSQL 9.6.1 Documentation    ROLLBACK PREPARED(7)



NAME
       ROLLBACK_PREPARED - cancel a transaction that was earlier prepared for
       two-phase commit

SYNOPSIS
       ROLLBACK PREPARED transaction_id

DESCRIPTION
       ROLLBACK PREPARED rolls back a transaction that is in prepared state.

PARAMETERS
       transaction_id
           The transaction identifier of the transaction that is to be rolled
           back.

NOTES
       To roll back a prepared transaction, you must be either the same user
       that executed the transaction originally, or a superuser. But you do
       not have to be in the same session that executed the transaction.

       This command cannot be executed inside a transaction block. The
       prepared transaction is rolled back immediately.

       All currently available prepared transactions are listed in the
       pg_prepared_xacts system view.

EXAMPLES
       Roll back the transaction identified by the transaction identifier
       foobar:

           ROLLBACK PREPARED 'foobar';

COMPATIBILITY
       ROLLBACK PREPARED is a PostgreSQL extension. It is intended for use by
       external transaction management systems, some of which are covered by
       standards (such as X/Open XA), but the SQL side of those systems is not
       standardized.

SEE ALSO
       PREPARE TRANSACTION (PREPARE_TRANSACTION(7)), COMMIT PREPARED
       (COMMIT_PREPARED(7))
<!-- ACCEPT >=> 46125e7b-f5a2-4727-b5b1-3cd97452e8b1 -->


PostgreSQL 9.6.1                     2016                 ROLLBACK PREPARED(7)
CHECKPOINT(7)           PostgreSQL 9.6.1 Documentation           CHECKPOINT(7)



NAME
       CHECKPOINT - force a transaction log checkpoint

SYNOPSIS
       CHECKPOINT

DESCRIPTION
       A checkpoint is a point in the transaction log sequence at which all
       data files have been updated to reflect the information in the log. All
       data files will be flushed to disk. Refer to Section 30.4, "WAL
       Configuration", in the documentation for more details about what
       happens during a checkpoint.

       The CHECKPOINT command forces an immediate checkpoint when the command
       is issued, without waiting for a regular checkpoint scheduled by the
       system (controlled by the settings in Section 19.5.2, "Checkpoints", in
       the documentation).  CHECKPOINT is not intended for use during normal
       operation.

       If executed during recovery, the CHECKPOINT command will force a
       restartpoint (see Section 30.4, "WAL Configuration", in the
       documentation) rather than writing a new checkpoint.

       Only superusers can call CHECKPOINT.

COMPATIBILITY
       The CHECKPOINT command is a PostgreSQL language extension.



PostgreSQL 9.6.1                     2016                        CHECKPOINT(7)
CREATE ROLE(7)          PostgreSQL 9.6.1 Documentation          CREATE ROLE(7)



<!-- 335d3487-bfbb-463c-9629-fa78cfc1d1e1 <=< ACCEPT -->NAME
       CREATE_ROLE - define a new database role

SYNOPSIS
       CREATE ROLE name [ [ WITH ] option [ ... ] ]

       where option can be:

             SUPERUSER | NOSUPERUSER
           | CREATEDB | NOCREATEDB
           | CREATEROLE | NOCREATEROLE
           | INHERIT | NOINHERIT
           | LOGIN | NOLOGIN
           | REPLICATION | NOREPLICATION
           | BYPASSRLS | NOBYPASSRLS
           | CONNECTION LIMIT connlimit
           | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
           | VALID UNTIL 'timestamp'
           | IN ROLE role_name [, ...]
           | IN GROUP role_name [, ...]
           | ROLE role_name [, ...]
           | ADMIN role_name [, ...]
           | USER role_name [, ...]
           | SYSID uid<!-- ACCEPT >=> 335d3487-bfbb-463c-9629-fa78cfc1d1e1 -->

DESCRIPTION
       CREATE ROLE adds a new role to a PostgreSQL database cluster. A role is
       an entity that can own database objects and have database privileges; a
       role can be considered a "user", a "group", or both depending on how it
       is used. Refer to Chapter 21, Database Roles, in the documentation and
       Chapter 20, Client Authentication, in the documentation for information
       about managing users and authentication. You must have CREATEROLE
       privilege or be a database superuser to use this command.

       Note that roles are defined at the database cluster level, and so are
       valid in all databases in the cluster.

PARAMETERS
       name
           The name of the new role.

       SUPERUSER
       NOSUPERUSER
           These clauses determine whether the new role is a "superuser", who
           can override all access restrictions within the database. Superuser
           status is dangerous and should be used only when really needed. You
           must yourself be a superuser to create a new superuser. If not
           specified, NOSUPERUSER is the default.

       CREATEDB
       NOCREATEDB
           These clauses define a role's ability to create databases. If
           CREATEDB is specified, the role being defined will be allowed to
           create new databases. Specifying NOCREATEDB will deny a role the
           ability to create databases. If not specified, NOCREATEDB is the
           default.

       CREATEROLE
       NOCREATEROLE
           These clauses determine whether a role will be permitted to create
           new roles (that is, execute CREATE ROLE). A role with CREATEROLE
           privilege can also alter and drop other roles. If not specified,
           NOCREATEROLE is the default.

       INHERIT
       NOINHERIT
           These clauses determine whether a role "inherits" the privileges of
           roles it is a member of. A role with the INHERIT attribute can
           automatically use whatever database privileges have been granted to
           all roles it is directly or indirectly a member of. Without
           INHERIT, membership in another role only grants the ability to SET
           ROLE to that other role; the privileges of the other role are only
           available after having done so. If not specified, INHERIT is the
           default.

       LOGIN
       NOLOGIN
           These clauses determine whether a role is allowed to log in; that
           is, whether the role can be given as the initial session
           authorization name during client connection. A role having the
           LOGIN attribute can be thought of as a user. Roles without this
           attribute are useful for managing database privileges, but are not
           users in the usual sense of the word. If not specified, NOLOGIN is
           the default, except when CREATE ROLE is invoked through its
           alternative spelling CREATE USER (CREATE_USER(7)).

       REPLICATION
       NOREPLICATION
           These clauses determine whether a role is allowed to initiate
           streaming replication or put the system in and out of backup mode.
           A role having the REPLICATION attribute is a very highly privileged
           role, and should only be used on roles actually used for
           replication. If not specified, NOREPLICATION is the default.

       BYPASSRLS
       NOBYPASSRLS
           These clauses determine whether a role bypasses every row-level
           security (RLS) policy.  NOBYPASSRLS is the default. Note that
           pg_dump will set row_security to OFF by default, to ensure all
           contents of a table are dumped out. If the user running pg_dump
           does not have appropriate permissions, an error will be returned.
           The superuser and owner of the table being dumped always bypass
           RLS.

       CONNECTION LIMIT connlimit
           If role can log in, this specifies how many concurrent connections
           the role can make. -1 (the default) means no limit.

       PASSWORD password
           Sets the role's password. (A password is only of use for roles
           having the LOGIN attribute, but you can nonetheless define one for
           roles without it.) If you do not plan to use password
           authentication you can omit this option. If no password is
           specified, the password will be set to null and password
           authentication will always fail for that user. A null password can
           optionally be written explicitly as PASSWORD NULL.

       ENCRYPTED
       UNENCRYPTED
           These key words control whether the password is stored encrypted in
           the system catalogs. (If neither is specified, the default behavior
           is determined by the configuration parameter password_encryption.)
           If the presented password string is already in MD5-encrypted
           format, then it is stored encrypted as-is, regardless of whether
           ENCRYPTED or UNENCRYPTED is specified (since the system cannot
           decrypt the specified encrypted password string). This allows
           reloading of encrypted passwords during dump/restore.

           Note that older clients might lack support for the MD5
           authentication mechanism that is needed to work with passwords that
           are stored encrypted.

       VALID UNTIL 'timestamp'
           The VALID UNTIL clause sets a date and time after which the role's
           password is no longer valid. If this clause is omitted the password
           will be valid for all time.

       IN ROLE role_name
           The IN ROLE clause lists one or more existing roles to which the
           new role will be immediately added as a new member. (Note that
           there is no option to add the new role as an administrator; use a
           separate GRANT command to do that.)

       IN GROUP role_name
           IN GROUP is an obsolete spelling of IN ROLE.

       ROLE role_name
           The ROLE clause lists one or more existing roles which are
           automatically added as members of the new role. (This in effect
           makes the new role a "group".)

       ADMIN role_name
           The ADMIN clause is like ROLE, but the named roles are added to the
           new role WITH ADMIN OPTION, giving them the right to grant
           membership in this role to others.

       USER role_name
           The USER clause is an obsolete spelling of the ROLE clause.

       SYSID uid
           The SYSID clause is ignored, but is accepted for backwards
           compatibility.

NOTES
       Use ALTER ROLE (ALTER_ROLE(7)) to change the attributes of a role, and
       DROP ROLE (DROP_ROLE(7)) to remove a role. All the attributes specified
       by CREATE ROLE can be modified by later ALTER ROLE commands.

       The preferred way to add and remove members of roles that are being
       used as groups is to use GRANT(7) and REVOKE(7).

       The VALID UNTIL clause defines an expiration time for a password only,
       not for the role per se. In particular, the expiration time is not
       enforced when logging in using a non-password-based authentication
       method.

       The INHERIT attribute governs inheritance of grantable privileges (that
       is, access privileges for database objects and role memberships). It
       does not apply to the special role attributes set by CREATE ROLE and
       ALTER ROLE. For example, being a member of a role with CREATEDB
       privilege does not immediately grant the ability to create databases,
       even if INHERIT is set; it would be necessary to become that role via
       SET ROLE (SET_ROLE(7)) before creating a database.

       The INHERIT attribute is the default for reasons of backwards
       compatibility: in prior releases of PostgreSQL, users always had access
       to all privileges of groups they were members of. However, NOINHERIT
       provides a closer match to the semantics specified in the SQL standard.

       Be careful with the CREATEROLE privilege. There is no concept of
       inheritance for the privileges of a CREATEROLE-role. That means that
       even if a role does not have a certain privilege but is allowed to
       create other roles, it can easily create another role with different
       privileges than its own (except for creating roles with superuser
       privileges). For example, if the role "user" has the CREATEROLE
       privilege but not the CREATEDB privilege, nonetheless it can create a
       new role with the CREATEDB privilege. Therefore, regard roles that have
       the CREATEROLE privilege as almost-superuser-roles.

       PostgreSQL includes a program createuser(1) that has the same
       functionality as CREATE ROLE (in fact, it calls this command) but can
       be run from the command shell.

       The CONNECTION LIMIT option is only enforced approximately; if two new
       sessions start at about the same time when just one connection "slot"
       remains for the role, it is possible that both will fail. Also, the
       limit is never enforced for superusers.

       Caution must be exercised when specifying an unencrypted password with
       this command. The password will be transmitted to the server in
       cleartext, and it might also be logged in the client's command history
       or the server log. The command createuser(1), however, transmits the
       password encrypted. Also, psql(1) contains a command \password that can
       be used to safely change the password later.

EXAMPLES
       Create a role that can log in, but don't give it a password:

           CREATE ROLE jonathan LOGIN;

       Create a role with a password:

           CREATE USER davide WITH PASSWORD 'jw8s0F4';

       (CREATE USER is the same as CREATE ROLE except that it implies LOGIN.)

       Create a role with a password that is valid until the end of 2004.
       After one second has ticked in 2005, the password is no longer valid.

           CREATE ROLE miriam WITH LOGIN PASSWORD 'jw8s0F4' VALID UNTIL '2005-01-01';

       Create a role that can create databases and manage roles:

           CREATE ROLE admin WITH CREATEDB CREATEROLE;

COMPATIBILITY
       The CREATE ROLE statement is in the SQL standard, but the standard only
       requires the syntax

           CREATE ROLE name [ WITH ADMIN role_name ]

       Multiple initial administrators, and all the other options of CREATE
       ROLE, are PostgreSQL extensions.

       The SQL standard defines the concepts of users and roles, but it
       regards them as distinct concepts and leaves all commands defining
       users to be specified by each database implementation. In PostgreSQL we
       have chosen to unify users and roles into a single kind of entity.
       Roles therefore have many more optional attributes than they do in the
       standard.

       The behavior specified by the SQL standard is most closely approximated
       by giving users the NOINHERIT attribute, while roles are given the
       INHERIT attribute.

SEE ALSO
       SET ROLE (SET_ROLE(7)), ALTER ROLE (ALTER_ROLE(7)), DROP ROLE
       (DROP_ROLE(7)), GRANT(7), REVOKE(7), createuser(1)



PostgreSQL 9.6.1                     2016                       CREATE ROLE(7)
ROLLBACK(7)             PostgreSQL 9.6.1 Documentation             ROLLBACK(7)



<!-- 6126dfe3-ecb1-43b1-a66d-676cc2167246 <=< ACCEPT -->NAME
       ROLLBACK - abort the current transaction

SYNOPSIS
       ROLLBACK [ WORK | TRANSACTION ]

DESCRIPTION
       ROLLBACK rolls back the current transaction and causes all the updates
       made by the transaction to be discarded.

PARAMETERS
       WORK
       TRANSACTION
           Optional key words. They have no effect.

NOTES
       Use COMMIT(7) to successfully terminate a transaction.

       Issuing ROLLBACK outside of a transaction block emits a warning and
       otherwise has no effect.

EXAMPLES
       To abort all changes:

           ROLLBACK;

COMPATIBILITY
       The SQL standard only specifies the two forms ROLLBACK and ROLLBACK
       WORK. Otherwise, this command is fully conforming.

SEE ALSO
       BEGIN(7), COMMIT(7), ROLLBACK TO SAVEPOINT (ROLLBACK_TO_SAVEPOINT(7))<!-- ACCEPT >=> 6126dfe3-ecb1-43b1-a66d-676cc2167246 -->



PostgreSQL 9.6.1                     2016                          ROLLBACK(7)
CREATE CONVERSION(7)    PostgreSQL 9.6.1 Documentation    CREATE CONVERSION(7)



NAME
       CREATE_CONVERSION - define a new encoding conversion

SYNOPSIS
       CREATE [ DEFAULT ] CONVERSION name
           FOR source_encoding TO dest_encoding FROM function_name

DESCRIPTION
       CREATE CONVERSION defines a new conversion between character set
       encodings. Also, conversions that are marked DEFAULT can be used for
       automatic encoding conversion between client and server. For this
       purpose, two conversions, from encoding A to B and from encoding B to
       A, must be defined.

       To be able to create a conversion, you must have EXECUTE privilege on
       the function and CREATE privilege on the destination schema.

PARAMETERS
       DEFAULT
           The DEFAULT clause indicates that this conversion is the default
           for this particular source to destination encoding. There should be
           only one default encoding in a schema for the encoding pair.

       name
           The name of the conversion. The conversion name can be
           schema-qualified. If it is not, the conversion is defined in the
           current schema. The conversion name must be unique within a schema.

       source_encoding
           The source encoding name.

       dest_encoding
           The destination encoding name.

       function_name
           The function used to perform the conversion. The function name can
           be schema-qualified. If it is not, the function will be looked up
           in the path.

           The function must have the following signature:

               conv_proc(
                   integer,  -- source encoding ID
                   integer,  -- destination encoding ID
                   cstring,  -- source string (null terminated C string)
                   internal, -- destination (fill with a null terminated C string)
                   integer   -- source string length
               ) RETURNS void;

NOTES
       Use DROP CONVERSION to remove user-defined conversions.

       The privileges required to create a conversion might be changed in a
       future release.

EXAMPLES
       To create a conversion from encoding UTF8 to LATIN1 using myfunc:

           CREATE CONVERSION myconv FOR 'UTF8' TO 'LATIN1' FROM myfunc;

COMPATIBILITY
       CREATE CONVERSION is a PostgreSQL extension. There is no CREATE
       CONVERSION statement in the SQL standard, but a CREATE TRANSLATION
       statement that is very similar in purpose and syntax.

SEE ALSO
       ALTER CONVERSION (ALTER_CONVERSION(7)), CREATE FUNCTION
       (CREATE_FUNCTION(7)), DROP CONVERSION (DROP_CONVERSION(7))



PostgreSQL 9.6.1                     2016                 CREATE CONVERSION(7)
DROP OPERATOR FAMILY(7) PostgreSQL 9.6.1 Documentation DROP OPERATOR FAMILY(7)



NAME
       DROP_OPERATOR_FAMILY - remove an operator family

SYNOPSIS
       DROP OPERATOR FAMILY [ IF EXISTS ] name USING index_method [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP OPERATOR FAMILY drops an existing operator family. To execute this
       command you must be the owner of the operator family.

       DROP OPERATOR FAMILY includes dropping any operator classes contained
       in the family, but it does not drop any of the operators or functions
       referenced by the family. If there are any indexes depending on
       operator classes within the family, you will need to specify CASCADE
       for the drop to complete.

PARAMETERS
       IF EXISTS
           Do not throw an error if the operator family does not exist. A
           notice is issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing operator
           family.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       index_method
           The name of the index access method the operator family is for.

       CASCADE
           Automatically drop objects that depend on the operator family, and
           in turn all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the operator family if any objects depend on it.
           This is the default.

EXAMPLES
       Remove the B-tree operator family float_ops:

           DROP OPERATOR FAMILY float_ops USING btree;

       This command will not succeed if there are any existing indexes that
       use operator classes within the family. Add CASCADE to drop such
       indexes along with the operator family.

COMPATIBILITY
       There is no DROP OPERATOR FAMILY statement in the SQL standard.

SEE ALSO
       ALTER OPERATOR FAMILY (ALTER_OPERATOR_FAMILY(7)), CREATE OPERATOR
       FAMILY (CREATE_OPERATOR_FAMILY(7)), ALTER OPERATOR CLASS
       (ALTER_OPERATOR_CLASS(7)), CREATE OPERATOR CLASS
       (CREATE_OPERATOR_CLASS(7)), DROP OPERATOR CLASS
       (DROP_OPERATOR_CLASS(7))



PostgreSQL 9.6.1                     2016              DROP OPERATOR FAMILY(7)
DROP OPERATOR CLASS(7)  PostgreSQL 9.6.1 Documentation  DROP OPERATOR CLASS(7)



NAME
       DROP_OPERATOR_CLASS - remove an operator class

SYNOPSIS
       DROP OPERATOR CLASS [ IF EXISTS ] name USING index_method [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP OPERATOR CLASS drops an existing operator class. To execute this
       command you must be the owner of the operator class.

       DROP OPERATOR CLASS does not drop any of the operators or functions
       referenced by the class. If there are any indexes depending on the
       operator class, you will need to specify CASCADE for the drop to
       complete.

PARAMETERS
       IF EXISTS
           Do not throw an error if the operator class does not exist. A
           notice is issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing operator
           class.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       index_method
           The name of the index access method the operator class is for.

       CASCADE
           Automatically drop objects that depend on the operator class (such
           as indexes), and in turn all objects that depend on those objects
           (see Section 5.13, "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the operator class if any objects depend on it. This
           is the default.

NOTES
       DROP OPERATOR CLASS will not drop the operator family containing the
       class, even if there is nothing else left in the family (in particular,
       in the case where the family was implicitly created by CREATE OPERATOR
       CLASS). An empty operator family is harmless, but for the sake of
       tidiness you might wish to remove the family with DROP OPERATOR FAMILY;
       or perhaps better, use DROP OPERATOR FAMILY in the first place.

EXAMPLES
       Remove the B-tree operator class widget_ops:

           DROP OPERATOR CLASS widget_ops USING btree;

       This command will not succeed if there are any existing indexes that
       use the operator class. Add CASCADE to drop such indexes along with the
       operator class.

COMPATIBILITY
       There is no DROP OPERATOR CLASS statement in the SQL standard.

SEE ALSO
       ALTER OPERATOR CLASS (ALTER_OPERATOR_CLASS(7)), CREATE OPERATOR CLASS
       (CREATE_OPERATOR_CLASS(7)), DROP OPERATOR FAMILY
       (DROP_OPERATOR_FAMILY(7))



PostgreSQL 9.6.1                     2016               DROP OPERATOR CLASS(7)
UPDATE(7)               PostgreSQL 9.6.1 Documentation               UPDATE(7)



NAME
       UPDATE - update rows of a table

SYNOPSIS
       [ WITH [ RECURSIVE ] with_query [, ...] ]
       UPDATE [ ONLY ] table_name [ * ] [ [ AS ] alias ]
           SET { column_name = { expression | DEFAULT } |
                 ( column_name [, ...] ) = ( { expression | DEFAULT } [, ...] ) |
                 ( column_name [, ...] ) = ( sub-SELECT )
               } [, ...]
           [ FROM from_list ]
           [ WHERE condition | WHERE CURRENT OF cursor_name ]
           [ RETURNING * | output_expression [ [ AS ] output_name ] [, ...] ]

DESCRIPTION
       UPDATE changes the values of the specified columns in all rows that
       satisfy the condition. Only the columns to be modified need be
       mentioned in the SET clause; columns not explicitly modified retain
       their previous values.

<!-- 9688183a-583d-4145-b5b2-c14a30bbc157 <=< ACCEPT -->       There are two ways to modify a table using information contained in
       other tables in the database: using sub-selects, or specifying
       additional tables in the FROM clause. Which technique is more
       appropriate depends on the specific circumstances.

       The optional RETURNING clause causes UPDATE to compute and return
       value(s) based on each row actually updated. Any expression using the
       table's columns, and/or columns of other tables mentioned in FROM, can
       be computed. The new (post-update) values of the table's columns are
       used. The syntax of the RETURNING list is identical to that of the
       output list of SELECT.

       You must have the UPDATE privilege on the table, or at least on the
       column(s) that are listed to be updated. You must also have the SELECT
       privilege on any column whose values are read in the expressions or
       condition.<!-- ACCEPT >=> 9688183a-583d-4145-b5b2-c14a30bbc157 -->

<!-- 976289e4-3610-460f-aade-c0eca46f7d89 <=< ACCEPT -->PARAMETERS
       with_query
           The WITH clause allows you to specify one or more subqueries that
           can be referenced by name in the UPDATE query. See Section 7.8,
           "WITH Queries (Common Table Expressions)", in the documentation and
           SELECT(7) for details.

       table_name
           The name (optionally schema-qualified) of the table to update. If
           ONLY is specified before the table name, matching rows are updated
           in the named table only. If ONLY is not specified, matching rows
           are also updated in any tables inheriting from the named table.
           Optionally, * can be specified after the table name to explicitly
           indicate that descendant tables are included.

       alias
           A substitute name for the target table. When an alias is provided,
           it completely hides the actual name of the table. For example,
           given UPDATE foo AS f, the remainder of the UPDATE statement must
           refer to this table as f not foo.<!-- ACCEPT >=> 976289e4-3610-460f-aade-c0eca46f7d89 -->

       column_name
           The name of a column in the table named by table_name. The column
           name can be qualified with a subfield name or array subscript, if
           needed. Do not include the table's name in the specification of a
           target column -- for example, UPDATE table_name SET table_name.col
           = 1 is invalid.

       expression
           An expression to assign to the column. The expression can use the
           old values of this and other columns in the table.

       DEFAULT
           Set the column to its default value (which will be NULL if no
           specific default expression has been assigned to it).

       sub-SELECT
           A SELECT sub-query that produces as many output columns as are
           listed in the parenthesized column list preceding it. The sub-query
           must yield no more than one row when executed. If it yields one
           row, its column values are assigned to the target columns; if it
           yields no rows, NULL values are assigned to the target columns. The
           sub-query can refer to old values of the current row of the table
           being updated.

       from_list
           A list of table expressions, allowing columns from other tables to
           appear in the WHERE condition and the update expressions. This is
           similar to the list of tables that can be specified in the FROM
           Clause of a SELECT statement. Note that the target table must not
           appear in the from_list, unless you intend a self-join (in which
           case it must appear with an alias in the from_list).

<!-- 5a6e1d61-f0db-408d-bc82-0bf54d5f8493 <=< ACCEPT -->       condition
           An expression that returns a value of type boolean. Only rows for
           which this expression returns true will be updated.

       cursor_name
           The name of the cursor to use in a WHERE CURRENT OF condition. The
           row to be updated is the one most recently fetched from this
           cursor. The cursor must be a non-grouping query on the UPDATE's
           target table. Note that WHERE CURRENT OF cannot be specified
           together with a Boolean condition. See DECLARE(7) for more
           information about using cursors with WHERE CURRENT OF.

       output_expression
           An expression to be computed and returned by the UPDATE command
           after each row is updated. The expression can use any column names
           of the table named by table_name or table(s) listed in FROM. Write
           * to return all columns.

       output_name
           A name to use for a returned column.
<!-- ACCEPT >=> 5a6e1d61-f0db-408d-bc82-0bf54d5f8493 -->
<!-- 8705f146-554e-4aaf-8291-fc9e613642ec <=< ACCEPT -->OUTPUTS
       On successful completion, an UPDATE command returns a command tag of
       the form

           UPDATE count

       The count is the number of rows updated, including matched rows whose
       values did not change. Note that the number may be less than the number
       of rows that matched the condition when updates were suppressed by a
       BEFORE UPDATE trigger. If count is 0, no rows were updated by the query
       (this is not considered an error).

       If the UPDATE command contains a RETURNING clause, the result will be
       similar to that of a SELECT statement containing the columns and values
       defined in the RETURNING list, computed over the row(s) updated by the
       command.<!-- ACCEPT >=> 8705f146-554e-4aaf-8291-fc9e613642ec -->

NOTES
       When a FROM clause is present, what essentially happens is that the
       target table is joined to the tables mentioned in the from_list, and
       each output row of the join represents an update operation for the
       target table. When using FROM you should ensure that the join produces
       at most one output row for each row to be modified. In other words, a
       target row shouldn't join to more than one row from the other table(s).
       If it does, then only one of the join rows will be used to update the
       target row, but which one will be used is not readily predictable.

       Because of this indeterminacy, referencing other tables only within
       sub-selects is safer, though often harder to read and slower than using
       a join.

EXAMPLES
       Change the word Drama to Dramatic in the column kind of the table
       films:

           UPDATE films SET kind = 'Dramatic' WHERE kind = 'Drama';

       Adjust temperature entries and reset precipitation to its default value
       in one row of the table weather:

           UPDATE weather SET temp_lo = temp_lo+1, temp_hi = temp_lo+15, prcp = DEFAULT
             WHERE city = 'San Francisco' AND date = '2003-07-03';

       Perform the same operation and return the updated entries:

           UPDATE weather SET temp_lo = temp_lo+1, temp_hi = temp_lo+15, prcp = DEFAULT
             WHERE city = 'San Francisco' AND date = '2003-07-03'
             RETURNING temp_lo, temp_hi, prcp;

       Use the alternative column-list syntax to do the same update:

           UPDATE weather SET (temp_lo, temp_hi, prcp) = (temp_lo+1, temp_lo+15, DEFAULT)
             WHERE city = 'San Francisco' AND date = '2003-07-03';

       Increment the sales count of the salesperson who manages the account
       for Acme Corporation, using the FROM clause syntax:

           UPDATE employees SET sales_count = sales_count + 1 FROM accounts
             WHERE accounts.name = 'Acme Corporation'
             AND employees.id = accounts.sales_person;

       Perform the same operation, using a sub-select in the WHERE clause:

           UPDATE employees SET sales_count = sales_count + 1 WHERE id =
             (SELECT sales_person FROM accounts WHERE name = 'Acme Corporation');

       Update contact names in an accounts table to match the currently
       assigned salesmen:

           UPDATE accounts SET (contact_first_name, contact_last_name) =
               (SELECT first_name, last_name FROM salesmen
                WHERE salesmen.id = accounts.sales_id);

       A similar result could be accomplished with a join:

           UPDATE accounts SET contact_first_name = first_name,
                               contact_last_name = last_name
             FROM salesmen WHERE salesmen.id = accounts.sales_id;

       However, the second query may give unexpected results if salesmen.id is
       not a unique key, whereas the first query is guaranteed to raise an
       error if there are multiple id matches. Also, if there is no match for
       a particular accounts.sales_id entry, the first query will set the
       corresponding name fields to NULL, whereas the second query will not
       update that row at all.

       Update statistics in a summary table to match the current data:

           UPDATE summary s SET (sum_x, sum_y, avg_x, avg_y) =
               (SELECT sum(x), sum(y), avg(x), avg(y) FROM data d
                WHERE d.group_id = s.group_id);

       Attempt to insert a new stock item along with the quantity of stock. If
       the item already exists, instead update the stock count of the existing
       item. To do this without failing the entire transaction, use
       savepoints:

           BEGIN;
           -- other operations
           SAVEPOINT sp1;
           INSERT INTO wines VALUES('Chateau Lafite 2003', '24');
           -- Assume the above fails because of a unique key violation,
           -- so now we issue these commands:
           ROLLBACK TO sp1;
           UPDATE wines SET stock = stock + 24 WHERE winename = 'Chateau Lafite 2003';
           -- continue with other operations, and eventually
           COMMIT;

       Change the kind column of the table films in the row on which the
       cursor c_films is currently positioned:

           UPDATE films SET kind = 'Dramatic' WHERE CURRENT OF c_films;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       This command conforms to the SQL standard, except that the FROM and
       RETURNING clauses are PostgreSQL extensions, as is the ability to use
       WITH with UPDATE.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

       Some other database systems offer a FROM option in which the target
       table is supposed to be listed again within FROM. That is not how
       PostgreSQL interprets FROM. Be careful when porting applications that
       use this extension.

       According to the standard, the source value for a parenthesized
       sub-list of column names can be any row-valued expression yielding the
       correct number of columns.  PostgreSQL only allows the source value to
       be a parenthesized list of expressions (a row constructor) or a
       sub-SELECT. An individual column's updated value can be specified as
       DEFAULT in the row-constructor case, but not inside a sub-SELECT.



PostgreSQL 9.6.1                     2016                            UPDATE(7)
DELETE(7)               PostgreSQL 9.6.1 Documentation               DELETE(7)



NAME
       DELETE - delete rows of a table

SYNOPSIS
       [ WITH [ RECURSIVE ] with_query [, ...] ]
       DELETE FROM [ ONLY ] table_name [ * ] [ [ AS ] alias ]
           [ USING using_list ]
           [ WHERE condition | WHERE CURRENT OF cursor_name ]
           [ RETURNING * | output_expression [ [ AS ] output_name ] [, ...] ]

DESCRIPTION
       DELETE deletes rows that satisfy the WHERE clause from the specified
       table. If the WHERE clause is absent, the effect is to delete all rows
       in the table. The result is a valid, but empty table.

           Tip
           TRUNCATE(7) is a PostgreSQL extension that provides a faster
           mechanism to remove all rows from a table.

<!-- 9688183a-583d-4145-b5b2-c14a30bbc157 <=< ACCEPT -->       There are two ways to delete rows in a table using information
       contained in other tables in the database: using sub-selects, or
       specifying additional tables in the USING clause. Which technique is
       more appropriate depends on the specific circumstances.

       The optional RETURNING clause causes DELETE to compute and return
       value(s) based on each row actually deleted. Any expression using the
       table's columns, and/or columns of other tables mentioned in USING, can
       be computed. The syntax of the RETURNING list is identical to that of
       the output list of SELECT.

       You must have the DELETE privilege on the table to delete from it, as
       well as the SELECT privilege for any table in the USING clause or whose
       values are read in the condition.<!-- ACCEPT >=> 9688183a-583d-4145-b5b2-c14a30bbc157 -->

<!-- 976289e4-3610-460f-aade-c0eca46f7d89 <=< ACCEPT -->PARAMETERS
       with_query
           The WITH clause allows you to specify one or more subqueries that
           can be referenced by name in the DELETE query. See Section 7.8,
           "WITH Queries (Common Table Expressions)", in the documentation and
           SELECT(7) for details.

       table_name
           The name (optionally schema-qualified) of the table to delete rows
           from. If ONLY is specified before the table name, matching rows are
           deleted from the named table only. If ONLY is not specified,
           matching rows are also deleted from any tables inheriting from the
           named table. Optionally, * can be specified after the table name to
           explicitly indicate that descendant tables are included.

       alias
           A substitute name for the target table. When an alias is provided,
           it completely hides the actual name of the table. For example,
           given DELETE FROM foo AS f, the remainder of the DELETE statement
           must refer to this table as f not foo.<!-- ACCEPT >=> 976289e4-3610-460f-aade-c0eca46f7d89 -->

       using_list
           A list of table expressions, allowing columns from other tables to
           appear in the WHERE condition. This is similar to the list of
           tables that can be specified in the FROM Clause of a SELECT
           statement; for example, an alias for the table name can be
           specified. Do not repeat the target table in the using_list, unless
           you wish to set up a self-join.

<!-- 5a6e1d61-f0db-408d-bc82-0bf54d5f8493 <=< ACCEPT -->       condition
           An expression that returns a value of type boolean. Only rows for
           which this expression returns true will be deleted.

       cursor_name
           The name of the cursor to use in a WHERE CURRENT OF condition. The
           row to be deleted is the one most recently fetched from this
           cursor. The cursor must be a non-grouping query on the DELETE's
           target table. Note that WHERE CURRENT OF cannot be specified
           together with a Boolean condition. See DECLARE(7) for more
           information about using cursors with WHERE CURRENT OF.

       output_expression
           An expression to be computed and returned by the DELETE command
           after each row is deleted. The expression can use any column names
           of the table named by table_name or table(s) listed in USING. Write
           * to return all columns.

       output_name
           A name to use for a returned column.<!-- ACCEPT >=> 5a6e1d61-f0db-408d-bc82-0bf54d5f8493 -->

<!-- 8705f146-554e-4aaf-8291-fc9e613642ec <=< ACCEPT -->OUTPUTS
       On successful completion, a DELETE command returns a command tag of the
       form

           DELETE count

       The count is the number of rows deleted. Note that the number may be
       less than the number of rows that matched the condition when deletes
       were suppressed by a BEFORE DELETE trigger. If count is 0, no rows were
       deleted by the query (this is not considered an error).

       If the DELETE command contains a RETURNING clause, the result will be
       similar to that of a SELECT statement containing the columns and values
       defined in the RETURNING list, computed over the row(s) deleted by the
       command.<!-- ACCEPT >=> 8705f146-554e-4aaf-8291-fc9e613642ec -->

NOTES
       PostgreSQL lets you reference columns of other tables in the WHERE
       condition by specifying the other tables in the USING clause. For
       example, to delete all films produced by a given producer, one can do:

           DELETE FROM films USING producers
             WHERE producer_id = producers.id AND producers.name = 'foo';

       What is essentially happening here is a join between films and
       producers, with all successfully joined films rows being marked for
       deletion. This syntax is not standard. A more standard way to do it is:

           DELETE FROM films
             WHERE producer_id IN (SELECT id FROM producers WHERE name = 'foo');

       In some cases the join style is easier to write or faster to execute
       than the sub-select style.

EXAMPLES
       Delete all films but musicals:

           DELETE FROM films WHERE kind &amp;lt;&amp;gt; 'Musical';

       Clear the table films:

           DELETE FROM films;

       Delete completed tasks, returning full details of the deleted rows:

           DELETE FROM tasks WHERE status = 'DONE' RETURNING *;

       Delete the row of tasks on which the cursor c_tasks is currently
       positioned:

           DELETE FROM tasks WHERE CURRENT OF c_tasks;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       This command conforms to the SQL standard, except that the USING and
       RETURNING clauses are PostgreSQL extensions, as is the ability to use
       WITH with DELETE.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->



PostgreSQL 9.6.1                     2016                            DELETE(7)
ALTER LARGE OBJECT(7)   PostgreSQL 9.6.1 Documentation   ALTER LARGE OBJECT(7)



NAME
       ALTER_LARGE_OBJECT - change the definition of a large object

SYNOPSIS
       ALTER LARGE OBJECT large_object_oid OWNER TO { new_owner | CURRENT_USER | SESSION_USER }

DESCRIPTION
       ALTER LARGE OBJECT changes the definition of a large object. The only
       functionality is to assign a new owner. You must be superuser or owner
       of the large object to use ALTER LARGE OBJECT.

PARAMETERS
       large_object_oid
           OID of the large object to be altered

       new_owner
           The new owner of the large object

COMPATIBILITY
       There is no ALTER LARGE OBJECT statement in the SQL standard.

SEE ALSO
       Chapter 33, Large Objects, in the documentation



PostgreSQL 9.6.1                     2016                ALTER LARGE OBJECT(7)
DROP GROUP(7)           PostgreSQL 9.6.1 Documentation           DROP GROUP(7)



NAME
       DROP_GROUP - remove a database role

SYNOPSIS
       DROP GROUP [ IF EXISTS ] name [, ...]

DESCRIPTION
       DROP GROUP is now an alias for DROP ROLE (DROP_ROLE(7)).

COMPATIBILITY
       There is no DROP GROUP statement in the SQL standard.

SEE ALSO
       DROP ROLE (DROP_ROLE(7))



PostgreSQL 9.6.1                     2016                        DROP GROUP(7)
SELECT(7)               PostgreSQL 9.6.1 Documentation               SELECT(7)



NAME
       SELECT, TABLE, WITH - retrieve rows from a table or view

<!-- 10920879-62f7-43a7-9948-f2c56af2ce2c <=< ACCEPT -->SYNOPSIS
       [ WITH [ RECURSIVE ] with_query [, ...] ]
       SELECT [ ALL | DISTINCT [ ON ( expression [, ...] ) ] ]
           [ * | expression [ [ AS ] output_name ] [, ...] ]
           [ FROM from_item [, ...] ]
           [ WHERE condition ]
           [ GROUP BY grouping_element [, ...] ]
           [ HAVING condition [, ...] ]
           [ WINDOW window_name AS ( window_definition ) [, ...] ]
           [ { UNION | INTERSECT | EXCEPT } [ ALL | DISTINCT ] select ]
           [ ORDER BY expression [ ASC | DESC | USING operator ] [ NULLS { FIRST | LAST } ] [, ...] ]
           [ LIMIT { count | ALL } ]
           [ OFFSET start [ ROW | ROWS ] ]
           [ FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } ONLY ]
           [ FOR { UPDATE | NO KEY UPDATE | SHARE | KEY SHARE } [ OF table_name [, ...] ] [ NOWAIT | SKIP LOCKED ] [...] ]<!-- ACCEPT >=> 10920879-62f7-43a7-9948-f2c56af2ce2c -->

       where from_item can be one of:

           [ ONLY ] table_name [ * ] [ [ AS ] alias [ ( column_alias [, ...] ) ] ]
                       [ TABLESAMPLE sampling_method ( argument [, ...] ) [ REPEATABLE ( seed ) ] ]
           [ LATERAL ] ( select ) [ AS ] alias [ ( column_alias [, ...] ) ]
           with_query_name [ [ AS ] alias [ ( column_alias [, ...] ) ] ]
           [ LATERAL ] function_name ( [ argument [, ...] ] )
                       [ WITH ORDINALITY ] [ [ AS ] alias [ ( column_alias [, ...] ) ] ]
           [ LATERAL ] function_name ( [ argument [, ...] ] ) [ AS ] alias ( column_definition [, ...] )
           [ LATERAL ] function_name ( [ argument [, ...] ] ) AS ( column_definition [, ...] )
           [ LATERAL ] ROWS FROM( function_name ( [ argument [, ...] ] ) [ AS ( column_definition [, ...] ) ] [, ...] )
                       [ WITH ORDINALITY ] [ [ AS ] alias [ ( column_alias [, ...] ) ] ]
           from_item [ NATURAL ] join_type from_item [ ON join_condition | USING ( join_column [, ...] ) ]

       and grouping_element can be one of:

           ( )
           expression
           ( expression [, ...] )
           ROLLUP ( { expression | ( expression [, ...] ) } [, ...] )
           CUBE ( { expression | ( expression [, ...] ) } [, ...] )
           GROUPING SETS ( grouping_element [, ...] )

       and with_query is:

           with_query_name [ ( column_name [, ...] ) ] AS ( select | values | insert | update | delete )

       TABLE [ ONLY ] table_name [ * ]

DESCRIPTION
       SELECT retrieves rows from zero or more tables. The general processing
       of SELECT is as follows:

        1. All queries in the WITH list are computed. These effectively serve
           as temporary tables that can be referenced in the FROM list. A WITH
           query that is referenced more than once in FROM is computed only
           once. (See WITH Clause below.)

        2. All elements in the FROM list are computed. (Each element in the
           FROM list is a real or virtual table.) If more than one element is
           specified in the FROM list, they are cross-joined together. (See
           FROM Clause below.)

        3. If the WHERE clause is specified, all rows that do not satisfy the
           condition are eliminated from the output. (See WHERE Clause below.)

        4. If the GROUP BY clause is specified, or if there are aggregate
           function calls, the output is combined into groups of rows that
           match on one or more values, and the results of aggregate functions
           are computed. If the HAVING clause is present, it eliminates groups
           that do not satisfy the given condition. (See GROUP BY Clause and
           HAVING Clause below.)

        5. The actual output rows are computed using the SELECT output
           expressions for each selected row or row group. (See SELECT List
           below.)

        6. SELECT DISTINCT eliminates duplicate rows from the result.  SELECT
           DISTINCT ON eliminates rows that match on all the specified
           expressions.  SELECT ALL (the default) will return all candidate
           rows, including duplicates. (See DISTINCT Clause below.)

        7. Using the operators UNION, INTERSECT, and EXCEPT, the output of
           more than one SELECT statement can be combined to form a single
           result set. The UNION operator returns all rows that are in one or
           both of the result sets. The INTERSECT operator returns all rows
           that are strictly in both result sets. The EXCEPT operator returns
           the rows that are in the first result set but not in the second. In
           all three cases, duplicate rows are eliminated unless ALL is
           specified. The noise word DISTINCT can be added to explicitly
           specify eliminating duplicate rows. Notice that DISTINCT is the
           default behavior here, even though ALL is the default for SELECT
           itself. (See UNION Clause, INTERSECT Clause, and EXCEPT Clause
           below.)

        8. If the ORDER BY clause is specified, the returned rows are sorted
           in the specified order. If ORDER BY is not given, the rows are
           returned in whatever order the system finds fastest to produce.
           (See ORDER BY Clause below.)

        9. If the LIMIT (or FETCH FIRST) or OFFSET clause is specified, the
           SELECT statement only returns a subset of the result rows. (See
           LIMIT Clause below.)

       10. If FOR UPDATE, FOR NO KEY UPDATE, FOR SHARE or FOR KEY SHARE is
           specified, the SELECT statement locks the selected rows against
           concurrent updates. (See The Locking Clause below.)

       You must have SELECT privilege on each column used in a SELECT command.
       The use of FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE or FOR KEY SHARE
       requires UPDATE privilege as well (for at least one column of each
       table so selected).

PARAMETERS
   WITH Clause
       The WITH clause allows you to specify one or more subqueries that can
       be referenced by name in the primary query. The subqueries effectively
       act as temporary tables or views for the duration of the primary query.
       Each subquery can be a SELECT, TABLE, VALUES, INSERT, UPDATE or DELETE
       statement. When writing a data-modifying statement (INSERT, UPDATE or
       DELETE) in WITH, it is usual to include a RETURNING clause. It is the
       output of RETURNING, not the underlying table that the statement
       modifies, that forms the temporary table that is read by the primary
       query. If RETURNING is omitted, the statement is still executed, but it
       produces no output so it cannot be referenced as a table by the primary
       query.

       A name (without schema qualification) must be specified for each WITH
       query. Optionally, a list of column names can be specified; if this is
       omitted, the column names are inferred from the subquery.

       If RECURSIVE is specified, it allows a SELECT subquery to reference
       itself by name. Such a subquery must have the form

           non_recursive_term UNION [ ALL | DISTINCT ] recursive_term

       where the recursive self-reference must appear on the right-hand side
       of the UNION. Only one recursive self-reference is permitted per query.
       Recursive data-modifying statements are not supported, but you can use
       the results of a recursive SELECT query in a data-modifying statement.
       See Section 7.8, "WITH Queries (Common Table Expressions)", in the
       documentation for an example.

       Another effect of RECURSIVE is that WITH queries need not be ordered: a
       query can reference another one that is later in the list. (However,
       circular references, or mutual recursion, are not implemented.) Without
       RECURSIVE, WITH queries can only reference sibling WITH queries that
       are earlier in the WITH list.

       A key property of WITH queries is that they are evaluated only once per
       execution of the primary query, even if the primary query refers to
       them more than once. In particular, data-modifying statements are
       guaranteed to be executed once and only once, regardless of whether the
       primary query reads all or any of their output.

       The primary query and the WITH queries are all (notionally) executed at
       the same time. This implies that the effects of a data-modifying
       statement in WITH cannot be seen from other parts of the query, other
       than by reading its RETURNING output. If two such data-modifying
       statements attempt to modify the same row, the results are unspecified.

       See Section 7.8, "WITH Queries (Common Table Expressions)", in the
       documentation for additional information.

   FROM Clause
       The FROM clause specifies one or more source tables for the SELECT. If
       multiple sources are specified, the result is the Cartesian product
       (cross join) of all the sources. But usually qualification conditions
       are added (via WHERE) to restrict the returned rows to a small subset
       of the Cartesian product.

       The FROM clause can contain the following elements:

       table_name
           The name (optionally schema-qualified) of an existing table or
           view. If ONLY is specified before the table name, only that table
           is scanned. If ONLY is not specified, the table and all its
           descendant tables (if any) are scanned. Optionally, * can be
           specified after the table name to explicitly indicate that
           descendant tables are included.

       alias
           A substitute name for the FROM item containing the alias. An alias
           is used for brevity or to eliminate ambiguity for self-joins (where
           the same table is scanned multiple times). When an alias is
           provided, it completely hides the actual name of the table or
           function; for example given FROM foo AS f, the remainder of the
           SELECT must refer to this FROM item as f not foo. If an alias is
           written, a column alias list can also be written to provide
           substitute names for one or more columns of the table.

       TABLESAMPLE sampling_method ( argument [, ...] ) [ REPEATABLE ( seed )
       ]
           A TABLESAMPLE clause after a table_name indicates that the
           specified sampling_method should be used to retrieve a subset of
           the rows in that table. This sampling precedes the application of
           any other filters such as WHERE clauses. The standard PostgreSQL
           distribution includes two sampling methods, BERNOULLI and SYSTEM,
           and other sampling methods can be installed in the database via
           extensions.

           The BERNOULLI and SYSTEM sampling methods each accept a single
           argument which is the fraction of the table to sample, expressed as
           a percentage between 0 and 100. This argument can be any
           real-valued expression. (Other sampling methods might accept more
           or different arguments.) These two methods each return a
           randomly-chosen sample of the table that will contain approximately
           the specified percentage of the table's rows. The BERNOULLI method
           scans the whole table and selects or ignores individual rows
           independently with the specified probability. The SYSTEM method
           does block-level sampling with each block having the specified
           chance of being selected; all rows in each selected block are
           returned. The SYSTEM method is significantly faster than the
           BERNOULLI method when small sampling percentages are specified, but
           it may return a less-random sample of the table as a result of
           clustering effects.

           The optional REPEATABLE clause specifies a seed number or
           expression to use for generating random numbers within the sampling
           method. The seed value can be any non-null floating-point value.
           Two queries that specify the same seed and argument values will
           select the same sample of the table, if the table has not been
           changed meanwhile. But different seed values will usually produce
           different samples. If REPEATABLE is not given then a new random
           sample is selected for each query, based upon a system-generated
           seed. Note that some add-on sampling methods do not accept
           REPEATABLE, and will always produce new samples on each use.

       select
           A sub-SELECT can appear in the FROM clause. This acts as though its
           output were created as a temporary table for the duration of this
           single SELECT command. Note that the sub-SELECT must be surrounded
           by parentheses, and an alias must be provided for it. A VALUES(7)
           command can also be used here.

       with_query_name
           A WITH query is referenced by writing its name, just as though the
           query's name were a table name. (In fact, the WITH query hides any
           real table of the same name for the purposes of the primary query.
           If necessary, you can refer to a real table of the same name by
           schema-qualifying the table's name.) An alias can be provided in
           the same way as for a table.

       function_name
           Function calls can appear in the FROM clause. (This is especially
           useful for functions that return result sets, but any function can
           be used.) This acts as though the function's output were created as
           a temporary table for the duration of this single SELECT command.
           When the optional WITH ORDINALITY clause is added to the function
           call, a new column is appended after all the function's output
           columns with numbering for each row.

           An alias can be provided in the same way as for a table. If an
           alias is written, a column alias list can also be written to
           provide substitute names for one or more attributes of the
           function's composite return type, including the column added by
           ORDINALITY if present.

           Multiple function calls can be combined into a single FROM-clause
           item by surrounding them with ROWS FROM( ... ). The output of such
           an item is the concatenation of the first row from each function,
           then the second row from each function, etc. If some of the
           functions produce fewer rows than others, null values are
           substituted for the missing data, so that the total number of rows
           returned is always the same as for the function that produced the
           most rows.

           If the function has been defined as returning the record data type,
           then an alias or the key word AS must be present, followed by a
           column definition list in the form ( column_name data_type [, ...
           ]). The column definition list must match the actual number and
           types of columns returned by the function.

           When using the ROWS FROM( ... ) syntax, if one of the functions
           requires a column definition list, it's preferred to put the column
           definition list after the function call inside ROWS FROM( ... ). A
           column definition list can be placed after the ROWS FROM( ... )
           construct only if there's just a single function and no WITH
           ORDINALITY clause.

           To use ORDINALITY together with a column definition list, you must
           use the ROWS FROM( ... ) syntax and put the column definition list
           inside ROWS FROM( ... ).

       join_type
           One of

           o   [ INNER ] JOIN

           o   LEFT [ OUTER ] JOIN

           o   RIGHT [ OUTER ] JOIN

           o   FULL [ OUTER ] JOIN

           o   CROSS JOIN

           For the INNER and OUTER join types, a join condition must be
           specified, namely exactly one of NATURAL, ON join_condition, or
           USING (join_column [, ...]). See below for the meaning. For CROSS
           JOIN, none of these clauses can appear.

           A JOIN clause combines two FROM items, which for convenience we
           will refer to as "tables", though in reality they can be any type
           of FROM item. Use parentheses if necessary to determine the order
           of nesting. In the absence of parentheses, JOINs nest
           left-to-right. In any case JOIN binds more tightly than the commas
           separating FROM-list items.

           CROSS JOIN and INNER JOIN produce a simple Cartesian product, the
           same result as you get from listing the two tables at the top level
           of FROM, but restricted by the join condition (if any).  CROSS JOIN
           is equivalent to INNER JOIN ON (TRUE), that is, no rows are removed
           by qualification. These join types are just a notational
           convenience, since they do nothing you couldn't do with plain FROM
           and WHERE.

           LEFT OUTER JOIN returns all rows in the qualified Cartesian product
           (i.e., all combined rows that pass its join condition), plus one
           copy of each row in the left-hand table for which there was no
           right-hand row that passed the join condition. This left-hand row
           is extended to the full width of the joined table by inserting null
           values for the right-hand columns. Note that only the JOIN clause's
           own condition is considered while deciding which rows have matches.
           Outer conditions are applied afterwards.

           Conversely, RIGHT OUTER JOIN returns all the joined rows, plus one
           row for each unmatched right-hand row (extended with nulls on the
           left). This is just a notational convenience, since you could
           convert it to a LEFT OUTER JOIN by switching the left and right
           tables.

           FULL OUTER JOIN returns all the joined rows, plus one row for each
           unmatched left-hand row (extended with nulls on the right), plus
           one row for each unmatched right-hand row (extended with nulls on
           the left).

       ON join_condition
           join_condition is an expression resulting in a value of type
           boolean (similar to a WHERE clause) that specifies which rows in a
           join are considered to match.

       USING ( join_column [, ...] )
           A clause of the form USING ( a, b, ... ) is shorthand for ON
           left_table.a = right_table.a AND left_table.b = right_table.b ....
           Also, USING implies that only one of each pair of equivalent
           columns will be included in the join output, not both.

       NATURAL
           NATURAL is shorthand for a USING list that mentions all columns in
           the two tables that have the same names.

       LATERAL
           The LATERAL key word can precede a sub-SELECTFROM item. This allows
           the sub-SELECT to refer to columns of FROM items that appear before
           it in the FROM list. (Without LATERAL, each sub-SELECT is evaluated
           independently and so cannot cross-reference any other FROM item.)

           LATERAL can also precede a function-call FROM item, but in this
           case it is a noise word, because the function expression can refer
           to earlier FROM items in any case.

           A LATERAL item can appear at top level in the FROM list, or within
           a JOIN tree. In the latter case it can also refer to any items that
           are on the left-hand side of a JOIN that it is on the right-hand
           side of.

           When a FROM item contains LATERAL cross-references, evaluation
           proceeds as follows: for each row of the FROM item providing the
           cross-referenced column(s), or set of rows of multiple FROM items
           providing the columns, the LATERAL item is evaluated using that row
           or row set's values of the columns. The resulting row(s) are joined
           as usual with the rows they were computed from. This is repeated
           for each row or set of rows from the column source table(s).

           The column source table(s) must be INNER or LEFT joined to the
           LATERAL item, else there would not be a well-defined set of rows
           from which to compute each set of rows for the LATERAL item. Thus,
           although a construct such as X RIGHT JOIN LATERAL Y is
           syntactically valid, it is not actually allowed for Y to reference
           X.

   WHERE Clause
       The optional WHERE clause has the general form

           WHERE condition

       where condition is any expression that evaluates to a result of type
       boolean. Any row that does not satisfy this condition will be
       eliminated from the output. A row satisfies the condition if it returns
       true when the actual row values are substituted for any variable
       references.

   GROUP BY Clause
       The optional GROUP BY clause has the general form

           GROUP BY grouping_element [, ...]

       GROUP BY will condense into a single row all selected rows that share
       the same values for the grouped expressions. An expression used inside
       a grouping_element can be an input column name, or the name or ordinal
       number of an output column (SELECT list item), or an arbitrary
       expression formed from input-column values. In case of ambiguity, a
       GROUP BY name will be interpreted as an input-column name rather than
       an output column name.

       If any of GROUPING SETS, ROLLUP or CUBE are present as grouping
       elements, then the GROUP BY clause as a whole defines some number of
       independent grouping sets. The effect of this is equivalent to
       constructing a UNION ALL between subqueries with the individual
       grouping sets as their GROUP BY clauses. For further details on the
       handling of grouping sets see Section 7.2.4, "GROUPING SETS, CUBE, and
       ROLLUP", in the documentation.

       Aggregate functions, if any are used, are computed across all rows
       making up each group, producing a separate value for each group. (If
       there are aggregate functions but no GROUP BY clause, the query is
       treated as having a single group comprising all the selected rows.) The
       set of rows fed to each aggregate function can be further filtered by
       attaching a FILTER clause to the aggregate function call; see Section
       4.2.7, "Aggregate Expressions", in the documentation for more
       information. When a FILTER clause is present, only those rows matching
       it are included in the input to that aggregate function.

       When GROUP BY is present, or any aggregate functions are present, it is
       not valid for the SELECT list expressions to refer to ungrouped columns
       except within aggregate functions or when the ungrouped column is
       functionally dependent on the grouped columns, since there would
       otherwise be more than one possible value to return for an ungrouped
       column. A functional dependency exists if the grouped columns (or a
       subset thereof) are the primary key of the table containing the
       ungrouped column.

       Keep in mind that all aggregate functions are evaluated before
       evaluating any "scalar" expressions in the HAVING clause or SELECT
       list. This means that, for example, a CASE expression cannot be used to
       skip evaluation of an aggregate function; see Section 4.2.14,
       "Expression Evaluation Rules", in the documentation.

       Currently, FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE and FOR KEY SHARE
       cannot be specified with GROUP BY.

   HAVING Clause
       The optional HAVING clause has the general form

           HAVING condition

       where condition is the same as specified for the WHERE clause.

       HAVING eliminates group rows that do not satisfy the condition.  HAVING
       is different from WHERE: WHERE filters individual rows before the
       application of GROUP BY, while HAVING filters group rows created by
       GROUP BY. Each column referenced in condition must unambiguously
       reference a grouping column, unless the reference appears within an
       aggregate function or the ungrouped column is functionally dependent on
       the grouping columns.

       The presence of HAVING turns a query into a grouped query even if there
       is no GROUP BY clause. This is the same as what happens when the query
       contains aggregate functions but no GROUP BY clause. All the selected
       rows are considered to form a single group, and the SELECT list and
       HAVING clause can only reference table columns from within aggregate
       functions. Such a query will emit a single row if the HAVING condition
       is true, zero rows if it is not true.

       Currently, FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE and FOR KEY SHARE
       cannot be specified with HAVING.

   WINDOW Clause
       The optional WINDOW clause has the general form

           WINDOW window_name AS ( window_definition ) [, ...]

       where window_name is a name that can be referenced from OVER clauses or
       subsequent window definitions, and window_definition is

           [ existing_window_name ]
           [ PARTITION BY expression [, ...] ]
           [ ORDER BY expression [ ASC | DESC | USING operator ] [ NULLS { FIRST | LAST } ] [, ...] ]
           [ frame_clause ]

       If an existing_window_name is specified it must refer to an earlier
       entry in the WINDOW list; the new window copies its partitioning clause
       from that entry, as well as its ordering clause if any. In this case
       the new window cannot specify its own PARTITION BY clause, and it can
       specify ORDER BY only if the copied window does not have one. The new
       window always uses its own frame clause; the copied window must not
       specify a frame clause.

       The elements of the PARTITION BY list are interpreted in much the same
       fashion as elements of a GROUP BY Clause, except that they are always
       simple expressions and never the name or number of an output column.
       Another difference is that these expressions can contain aggregate
       function calls, which are not allowed in a regular GROUP BY clause.
       They are allowed here because windowing occurs after grouping and
       aggregation.

       Similarly, the elements of the ORDER BY list are interpreted in much
       the same fashion as elements of an ORDER BY Clause, except that the
       expressions are always taken as simple expressions and never the name
       or number of an output column.

       The optional frame_clause defines the window frame for window functions
       that depend on the frame (not all do). The window frame is a set of
       related rows for each row of the query (called the current row). The
       frame_clause can be one of

           { RANGE | ROWS } frame_start
           { RANGE | ROWS } BETWEEN frame_start AND frame_end

       where frame_start and frame_end can be one of

           UNBOUNDED PRECEDING
           value PRECEDING
           CURRENT ROW
           value FOLLOWING
           UNBOUNDED FOLLOWING

       If frame_end is omitted it defaults to CURRENT ROW. Restrictions are
       that frame_start cannot be UNBOUNDED FOLLOWING, frame_end cannot be
       UNBOUNDED PRECEDING, and the frame_end choice cannot appear earlier in
       the above list than the frame_start choice -- for example RANGE BETWEEN
       CURRENT ROW AND value PRECEDING is not allowed.

       The default framing option is RANGE UNBOUNDED PRECEDING, which is the
       same as RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW; it sets the
       frame to be all rows from the partition start up through the current
       row's last peer (a row that ORDER BY considers equivalent to the
       current row, or all rows if there is no ORDER BY). In general,
       UNBOUNDED PRECEDING means that the frame starts with the first row of
       the partition, and similarly UNBOUNDED FOLLOWING means that the frame
       ends with the last row of the partition (regardless of RANGE or ROWS
       mode). In ROWS mode, CURRENT ROW means that the frame starts or ends
       with the current row; but in RANGE mode it means that the frame starts
       or ends with the current row's first or last peer in the ORDER BY
       ordering. The valuePRECEDING and valueFOLLOWING cases are currently
       only allowed in ROWS mode. They indicate that the frame starts or ends
       with the row that many rows before or after the current row.  value
       must be an integer expression not containing any variables, aggregate
       functions, or window functions. The value must not be null or negative;
       but it can be zero, which selects the current row itself.

       Beware that the ROWS options can produce unpredictable results if the
       ORDER BY ordering does not order the rows uniquely. The RANGE options
       are designed to ensure that rows that are peers in the ORDER BY
       ordering are treated alike; all peer rows will be in the same frame.

       The purpose of a WINDOW clause is to specify the behavior of window
       functions appearing in the query's SELECT List or ORDER BY Clause.
       These functions can reference the WINDOW clause entries by name in
       their OVER clauses. A WINDOW clause entry does not have to be
       referenced anywhere, however; if it is not used in the query it is
       simply ignored. It is possible to use window functions without any
       WINDOW clause at all, since a window function call can specify its
       window definition directly in its OVER clause. However, the WINDOW
       clause saves typing when the same window definition is needed for more
       than one window function.

       Currently, FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE and FOR KEY SHARE
       cannot be specified with WINDOW.

       Window functions are described in detail in Section 3.5, "Window
       Functions", in the documentation, Section 4.2.8, "Window Function
       Calls", in the documentation, and Section 7.2.5, "Window Function
       Processing", in the documentation.

   SELECT List
       The SELECT list (between the key words SELECT and FROM) specifies
       expressions that form the output rows of the SELECT statement. The
       expressions can (and usually do) refer to columns computed in the FROM
       clause.

       Just as in a table, every output column of a SELECT has a name. In a
       simple SELECT this name is just used to label the column for display,
       but when the SELECT is a sub-query of a larger query, the name is seen
       by the larger query as the column name of the virtual table produced by
       the sub-query. To specify the name to use for an output column, write
       ASoutput_name after the column's expression. (You can omit AS, but only
       if the desired output name does not match any PostgreSQL keyword (see
       Appendix C, SQL Key Words). For protection against possible future
       keyword additions, it is recommended that you always either write AS or
       double-quote the output name.) If you do not specify a column name, a
       name is chosen automatically by PostgreSQL. If the column's expression
       is a simple column reference then the chosen name is the same as that
       column's name. In more complex cases a function or type name may be
       used, or the system may fall back on a generated name such as ?column?.

       An output column's name can be used to refer to the column's value in
       ORDER BY and GROUP BY clauses, but not in the WHERE or HAVING clauses;
       there you must write out the expression instead.

       Instead of an expression, * can be written in the output list as a
       shorthand for all the columns of the selected rows. Also, you can write
       table_name.*  as a shorthand for the columns coming from just that
       table. In these cases it is not possible to specify new names with AS;
       the output column names will be the same as the table columns' names.

       According to the SQL standard, the expressions in the output list
       should be computed before applying DISTINCT, ORDER BY, or LIMIT. This
       is obviously necessary when using DISTINCT, since otherwise it's not
       clear what values are being made distinct. However, in many cases it is
       convenient if output expressions are computed after ORDER BY and LIMIT;
       particularly if the output list contains any volatile or expensive
       functions. With that behavior, the order of function evaluations is
       more intuitive and there will not be evaluations corresponding to rows
       that never appear in the output.  PostgreSQL will effectively evaluate
       output expressions after sorting and limiting, so long as those
       expressions are not referenced in DISTINCT, ORDER BY or GROUP BY. (As a
       counterexample, SELECT f(x) FROM tab ORDER BY 1 clearly must evaluate
       f(x) before sorting.) Output expressions that contain set-returning
       functions are effectively evaluated after sorting and before limiting,
       so that LIMIT will act to cut off the output from a set-returning
       function.

           Note
           PostgreSQL versions before 9.6 did not provide any guarantees about
           the timing of evaluation of output expressions versus sorting and
           limiting; it depended on the form of the chosen query plan.

   DISTINCT Clause
       If SELECT DISTINCT is specified, all duplicate rows are removed from
       the result set (one row is kept from each group of duplicates).  SELECT
       ALL specifies the opposite: all rows are kept; that is the default.

       SELECT DISTINCT ON ( expression [, ...] ) keeps only the first row of
       each set of rows where the given expressions evaluate to equal. The
       DISTINCT ON expressions are interpreted using the same rules as for
       ORDER BY (see above). Note that the "first row" of each set is
       unpredictable unless ORDER BY is used to ensure that the desired row
       appears first. For example:

           SELECT DISTINCT ON (location) location, time, report
               FROM weather_reports
               ORDER BY location, time DESC;

       retrieves the most recent weather report for each location. But if we
       had not used ORDER BY to force descending order of time values for each
       location, we'd have gotten a report from an unpredictable time for each
       location.

       The DISTINCT ON expression(s) must match the leftmost ORDER BY
       expression(s). The ORDER BY clause will normally contain additional
       expression(s) that determine the desired precedence of rows within each
       DISTINCT ON group.

       Currently, FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE and FOR KEY SHARE
       cannot be specified with DISTINCT.

   UNION Clause
       The UNION clause has this general form:

           select_statement UNION [ ALL | DISTINCT ] select_statement

       select_statement is any SELECT statement without an ORDER BY, LIMIT,
       FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE, or FOR KEY SHARE clause.
       (ORDER BY and LIMIT can be attached to a subexpression if it is
       enclosed in parentheses. Without parentheses, these clauses will be
       taken to apply to the result of the UNION, not to its right-hand input
       expression.)

       The UNION operator computes the set union of the rows returned by the
       involved SELECT statements. A row is in the set union of two result
       sets if it appears in at least one of the result sets. The two SELECT
       statements that represent the direct operands of the UNION must produce
       the same number of columns, and corresponding columns must be of
       compatible data types.

       The result of UNION does not contain any duplicate rows unless the ALL
       option is specified.  ALL prevents elimination of duplicates.
       (Therefore, UNION ALL is usually significantly quicker than UNION; use
       ALL when you can.)  DISTINCT can be written to explicitly specify the
       default behavior of eliminating duplicate rows.

       Multiple UNION operators in the same SELECT statement are evaluated
       left to right, unless otherwise indicated by parentheses.

       Currently, FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE and FOR KEY SHARE
       cannot be specified either for a UNION result or for any input of a
       UNION.

   INTERSECT Clause
       The INTERSECT clause has this general form:

           select_statement INTERSECT [ ALL | DISTINCT ] select_statement

<!-- 5869e4a5-2ca3-4a5e-bd41-e2a2cae0e58e <=< ACCEPT -->       select_statement is any SELECT statement without an ORDER BY, LIMIT,
       FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE, or FOR KEY SHARE clause.

       The INTERSECT operator computes the set intersection of the rows
       returned by the involved SELECT statements. A row is in the
       intersection of two result sets if it appears in both result sets.

       The result of INTERSECT does not contain any duplicate rows unless the
       ALL option is specified. With ALL, a row that has m duplicates in the
       left table and n duplicates in the right table will appear min(m,n)
       times in the result set.  DISTINCT can be written to explicitly specify
       the default behavior of eliminating duplicate rows.

       Multiple INTERSECT operators in the same SELECT statement are evaluated
       left to right, unless parentheses dictate otherwise.  INTERSECT binds
       more tightly than UNION.<!-- ACCEPT >=> 5869e4a5-2ca3-4a5e-bd41-e2a2cae0e58e --> That is, A UNION B INTERSECT C will be read as
       A UNION (B INTERSECT C).

       Currently, FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE and FOR KEY SHARE
       cannot be specified either for an INTERSECT result or for any input of
       an INTERSECT.

   EXCEPT Clause
       The EXCEPT clause has this general form:

           select_statement EXCEPT [ ALL | DISTINCT ] select_statement

<!-- 5869e4a5-2ca3-4a5e-bd41-e2a2cae0e58e <=< ACCEPT -->       select_statement is any SELECT statement without an ORDER BY, LIMIT,
       FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE, or FOR KEY SHARE clause.

       The EXCEPT operator computes the set of rows that are in the result of
       the left SELECT statement but not in the result of the right one.

       The result of EXCEPT does not contain any duplicate rows unless the ALL
       option is specified. With ALL, a row that has m duplicates in the left
       table and n duplicates in the right table will appear max(m-n,0) times
       in the result set.  DISTINCT can be written to explicitly specify the
       default behavior of eliminating duplicate rows.

       Multiple EXCEPT operators in the same SELECT statement are evaluated
       left to right, unless parentheses dictate otherwise.  EXCEPT binds at
       the same level as UNION.<!-- ACCEPT >=> 5869e4a5-2ca3-4a5e-bd41-e2a2cae0e58e -->

       Currently, FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE and FOR KEY SHARE
       cannot be specified either for an EXCEPT result or for any input of an
       EXCEPT.

   ORDER BY Clause
       The optional ORDER BY clause has this general form:

           ORDER BY expression [ ASC | DESC | USING operator ] [ NULLS { FIRST | LAST } ] [, ...]

       The ORDER BY clause causes the result rows to be sorted according to
       the specified expression(s). If two rows are equal according to the
       leftmost expression, they are compared according to the next expression
       and so on. If they are equal according to all specified expressions,
       they are returned in an implementation-dependent order.

       Each expression can be the name or ordinal number of an output column
       (SELECT list item), or it can be an arbitrary expression formed from
       input-column values.

       The ordinal number refers to the ordinal (left-to-right) position of
       the output column. This feature makes it possible to define an ordering
       on the basis of a column that does not have a unique name. This is
       never absolutely necessary because it is always possible to assign a
       name to an output column using the AS clause.

       It is also possible to use arbitrary expressions in the ORDER BY
       clause, including columns that do not appear in the SELECT output list.
       Thus the following statement is valid:

           SELECT name FROM distributors ORDER BY code;

       A limitation of this feature is that an ORDER BY clause applying to the
       result of a UNION, INTERSECT, or EXCEPT clause can only specify an
       output column name or number, not an expression.

       If an ORDER BY expression is a simple name that matches both an output
       column name and an input column name, ORDER BY will interpret it as the
       output column name. This is the opposite of the choice that GROUP BY
       will make in the same situation. This inconsistency is made to be
       compatible with the SQL standard.

       Optionally one can add the key word ASC (ascending) or DESC
       (descending) after any expression in the ORDER BY clause. If not
       specified, ASC is assumed by default. Alternatively, a specific
       ordering operator name can be specified in the USING clause. An
       ordering operator must be a less-than or greater-than member of some
       B-tree operator family.  ASC is usually equivalent to USING &amp;lt; and DESC
       is usually equivalent to USING &amp;gt;. (But the creator of a user-defined
       data type can define exactly what the default sort ordering is, and it
       might correspond to operators with other names.)

       If NULLS LAST is specified, null values sort after all non-null values;
       if NULLS FIRST is specified, null values sort before all non-null
       values. If neither is specified, the default behavior is NULLS LAST
       when ASC is specified or implied, and NULLS FIRST when DESC is
       specified (thus, the default is to act as though nulls are larger than
       non-nulls). When USING is specified, the default nulls ordering depends
       on whether the operator is a less-than or greater-than operator.

       Note that ordering options apply only to the expression they follow;
       for example ORDER BY x, y DESC does not mean the same thing as ORDER BY
       x DESC, y DESC.

       Character-string data is sorted according to the collation that applies
       to the column being sorted. That can be overridden at need by including
       a COLLATE clause in the expression, for example ORDER BY mycolumn
       COLLATE "en_US". For more information see Section 4.2.10, "Collation
       Expressions", in the documentation and Section 23.2, "Collation
       Support", in the documentation.

   LIMIT Clause
       The LIMIT clause consists of two independent sub-clauses:

           LIMIT { count | ALL }
           OFFSET start

       count specifies the maximum number of rows to return, while start
       specifies the number of rows to skip before starting to return rows.
       When both are specified, start rows are skipped before starting to
       count the count rows to be returned.

       If the count expression evaluates to NULL, it is treated as LIMIT ALL,
       i.e., no limit. If start evaluates to NULL, it is treated the same as
       OFFSET 0.

       SQL:2008 introduced a different syntax to achieve the same result,
       which PostgreSQL also supports. It is:

           OFFSET start { ROW | ROWS }
           FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } ONLY

       In this syntax, to write anything except a simple integer constant for
       start or count, you must write parentheses around it. If count is
       omitted in a FETCH clause, it defaults to 1.  ROW and ROWS as well as
       FIRST and NEXT are noise words that don't influence the effects of
       these clauses. According to the standard, the OFFSET clause must come
       before the FETCH clause if both are present; but PostgreSQL is laxer
       and allows either order.

       When using LIMIT, it is a good idea to use an ORDER BY clause that
       constrains the result rows into a unique order. Otherwise you will get
       an unpredictable subset of the query's rows -- you might be asking for
       the tenth through twentieth rows, but tenth through twentieth in what
       ordering? You don't know what ordering unless you specify ORDER BY.

       The query planner takes LIMIT into account when generating a query
       plan, so you are very likely to get different plans (yielding different
       row orders) depending on what you use for LIMIT and OFFSET. Thus, using
       different LIMIT/OFFSET values to select different subsets of a query
       result will give inconsistent results unless you enforce a predictable
       result ordering with ORDER BY. This is not a bug; it is an inherent
       consequence of the fact that SQL does not promise to deliver the
       results of a query in any particular order unless ORDER BY is used to
       constrain the order.

       It is even possible for repeated executions of the same LIMIT query to
       return different subsets of the rows of a table, if there is not an
       ORDER BY to enforce selection of a deterministic subset. Again, this is
       not a bug; determinism of the results is simply not guaranteed in such
       a case.

   The Locking Clause
       FOR UPDATE, FOR NO KEY UPDATE, FOR SHARE and FOR KEY SHARE are locking
       clauses; they affect how SELECT locks rows as they are obtained from
       the table.

       The locking clause has the general form

           FOR lock_strength [ OF table_name [, ...] ] [ NOWAIT | SKIP LOCKED ]

       where lock_strength can be one of

           UPDATE
           NO KEY UPDATE
           SHARE
           KEY SHARE

       For more information on each row-level lock mode, refer to Section
       13.3.2, "Row-level Locks", in the documentation.

       To prevent the operation from waiting for other transactions to commit,
       use either the NOWAIT or SKIP LOCKED option. With NOWAIT, the statement
       reports an error, rather than waiting, if a selected row cannot be
       locked immediately. With SKIP LOCKED, any selected rows that cannot be
       immediately locked are skipped. Skipping locked rows provides an
       inconsistent view of the data, so this is not suitable for general
       purpose work, but can be used to avoid lock contention with multiple
       consumers accessing a queue-like table. Note that NOWAIT and SKIP
       LOCKED apply only to the row-level lock(s) -- the required ROW SHARE
       table-level lock is still taken in the ordinary way (see Chapter 13,
       Concurrency Control, in the documentation). You can use LOCK(7) with
       the NOWAIT option first, if you need to acquire the table-level lock
       without waiting.

       If specific tables are named in a locking clause, then only rows coming
       from those tables are locked; any other tables used in the SELECT are
       simply read as usual. A locking clause without a table list affects all
       tables used in the statement. If a locking clause is applied to a view
       or sub-query, it affects all tables used in the view or sub-query.
       However, these clauses do not apply to WITH queries referenced by the
       primary query. If you want row locking to occur within a WITH query,
       specify a locking clause within the WITH query.

       Multiple locking clauses can be written if it is necessary to specify
       different locking behavior for different tables. If the same table is
       mentioned (or implicitly affected) by more than one locking clause,
       then it is processed as if it was only specified by the strongest one.
       Similarly, a table is processed as NOWAIT if that is specified in any
       of the clauses affecting it. Otherwise, it is processed as SKIP LOCKED
       if that is specified in any of the clauses affecting it.

       The locking clauses cannot be used in contexts where returned rows
       cannot be clearly identified with individual table rows; for example
       they cannot be used with aggregation.

       When a locking clause appears at the top level of a SELECT query, the
       rows that are locked are exactly those that are returned by the query;
       in the case of a join query, the rows locked are those that contribute
       to returned join rows. In addition, rows that satisfied the query
       conditions as of the query snapshot will be locked, although they will
       not be returned if they were updated after the snapshot and no longer
       satisfy the query conditions. If a LIMIT is used, locking stops once
       enough rows have been returned to satisfy the limit (but note that rows
       skipped over by OFFSET will get locked). Similarly, if a locking clause
       is used in a cursor's query, only rows actually fetched or stepped past
       by the cursor will be locked.

       When a locking clause appears in a sub-SELECT, the rows locked are
       those returned to the outer query by the sub-query. This might involve
       fewer rows than inspection of the sub-query alone would suggest, since
       conditions from the outer query might be used to optimize execution of
       the sub-query. For example,

           SELECT * FROM (SELECT * FROM mytable FOR UPDATE) ss WHERE col1 = 5;

       will lock only rows having col1 = 5, even though that condition is not
       textually within the sub-query.

       Previous releases failed to preserve a lock which is upgraded by a
       later savepoint. For example, this code:

           BEGIN;
           SELECT * FROM mytable WHERE key = 1 FOR UPDATE;
           SAVEPOINT s;
           UPDATE mytable SET ... WHERE key = 1;
           ROLLBACK TO s;

       would fail to preserve the FOR UPDATE lock after the ROLLBACK TO. This
       has been fixed in release 9.3.

           Caution
           It is possible for a SELECT command running at the READ COMMITTED
           transaction isolation level and using ORDER BY and a locking clause
           to return rows out of order. This is because ORDER BY is applied
           first. The command sorts the result, but might then block trying to
           obtain a lock on one or more of the rows. Once the SELECT unblocks,
           some of the ordering column values might have been modified,
           leading to those rows appearing to be out of order (though they are
           in order in terms of the original column values). This can be
           worked around at need by placing the FOR UPDATE/SHARE clause in a
           sub-query, for example

               SELECT * FROM (SELECT * FROM mytable FOR UPDATE) ss ORDER BY column1;

           Note that this will result in locking all rows of mytable, whereas
           FOR UPDATE at the top level would lock only the actually returned
           rows. This can make for a significant performance difference,
           particularly if the ORDER BY is combined with LIMIT or other
           restrictions. So this technique is recommended only if concurrent
           updates of the ordering columns are expected and a strictly sorted
           result is required.

           At the REPEATABLE READ or SERIALIZABLE transaction isolation level
           this would cause a serialization failure (with a SQLSTATE of
           '40001'), so there is no possibility of receiving rows out of order
           under these isolation levels.

   TABLE Command
       The command

           TABLE name

       is equivalent to

           SELECT * FROM name

       It can be used as a top-level command or as a space-saving syntax
       variant in parts of complex queries. Only the WITH, UNION, INTERSECT,
       EXCEPT, ORDER BY, LIMIT, OFFSET, FETCH and FOR locking clauses can be
       used with TABLE; the WHERE clause and any form of aggregation cannot be
       used.

EXAMPLES
       To join the table films with the table distributors:

           SELECT f.title, f.did, d.name, f.date_prod, f.kind
               FROM distributors d, films f
               WHERE f.did = d.did

                  title       | did |     name     | date_prod  |   kind
           -------------------+-----+--------------+------------+----------
            The Third Man     | 101 | British Lion | 1949-12-23 | Drama
            The African Queen | 101 | British Lion | 1951-08-11 | Romantic
            ...

       To sum the column len of all films and group the results by kind:

           SELECT kind, sum(len) AS total FROM films GROUP BY kind;

              kind   | total
           ----------+-------
            Action   | 07:34
            Comedy   | 02:58
            Drama    | 14:28
            Musical  | 06:42
            Romantic | 04:38

       To sum the column len of all films, group the results by kind and show
       those group totals that are less than 5 hours:

           SELECT kind, sum(len) AS total
               FROM films
               GROUP BY kind
               HAVING sum(len) &amp;lt; interval '5 hours';

              kind   | total
           ----------+-------
            Comedy   | 02:58
            Romantic | 04:38

       The following two examples are identical ways of sorting the individual
       results according to the contents of the second column (name):

           SELECT * FROM distributors ORDER BY name;
           SELECT * FROM distributors ORDER BY 2;

            did |       name
           -----+------------------
            109 | 20th Century Fox
            110 | Bavaria Atelier
            101 | British Lion
            107 | Columbia
            102 | Jean Luc Godard
            113 | Luso films
            104 | Mosfilm
            103 | Paramount
            106 | Toho
            105 | United Artists
            111 | Walt Disney
            112 | Warner Bros.
            108 | Westward

       The next example shows how to obtain the union of the tables
       distributors and actors, restricting the results to those that begin
       with the letter W in each table. Only distinct rows are wanted, so the
       key word ALL is omitted.

           distributors:               actors:
            did |     name              id |     name
           -----+--------------        ----+----------------
            108 | Westward               1 | Woody Allen
            111 | Walt Disney            2 | Warren Beatty
            112 | Warner Bros.           3 | Walter Matthau
            ...                         ...

           SELECT distributors.name
               FROM distributors
               WHERE distributors.name LIKE 'W%'
           UNION
           SELECT actors.name
               FROM actors
               WHERE actors.name LIKE 'W%';

                 name
           ----------------
            Walt Disney
            Walter Matthau
            Warner Bros.
            Warren Beatty
            Westward
            Woody Allen

       This example shows how to use a function in the FROM clause, both with
       and without a column definition list:

           CREATE FUNCTION distributors(int) RETURNS SETOF distributors AS $$
               SELECT * FROM distributors WHERE did = $1;
           $$ LANGUAGE SQL;

           SELECT * FROM distributors(111);
            did |    name
           -----+-------------
            111 | Walt Disney

           CREATE FUNCTION distributors_2(int) RETURNS SETOF record AS $$
               SELECT * FROM distributors WHERE did = $1;
           $$ LANGUAGE SQL;

           SELECT * FROM distributors_2(111) AS (f1 int, f2 text);
            f1  |     f2
           -----+-------------
            111 | Walt Disney

       Here is an example of a function with an ordinality column added:

           SELECT * FROM unnest(ARRAY['a','b','c','d','e','f']) WITH ORDINALITY;
            unnest | ordinality
           --------+----------
            a      |        1
            b      |        2
            c      |        3
            d      |        4
            e      |        5
            f      |        6
           (6 rows)

       This example shows how to use a simple WITH clause:

           WITH t AS (
               SELECT random() as x FROM generate_series(1, 3)
             )
           SELECT * FROM t
           UNION ALL
           SELECT * FROM t

                    x
           --------------------
             0.534150459803641
             0.520092216785997
            0.0735620250925422
             0.534150459803641
             0.520092216785997
            0.0735620250925422

       Notice that the WITH query was evaluated only once, so that we got two
       sets of the same three random values.

       This example uses WITH RECURSIVE to find all subordinates (direct or
       indirect) of the employee Mary, and their level of indirectness, from a
       table that shows only direct subordinates:

           WITH RECURSIVE employee_recursive(distance, employee_name, manager_name) AS (
               SELECT 1, employee_name, manager_name
               FROM employee
               WHERE manager_name = 'Mary'
             UNION ALL
               SELECT er.distance + 1, e.employee_name, e.manager_name
               FROM employee_recursive er, employee e
               WHERE er.employee_name = e.manager_name
             )
           SELECT distance, employee_name FROM employee_recursive;

       Notice the typical form of recursive queries: an initial condition,
       followed by UNION, followed by the recursive part of the query. Be sure
       that the recursive part of the query will eventually return no tuples,
       or else the query will loop indefinitely. (See Section 7.8, "WITH
       Queries (Common Table Expressions)", in the documentation for more
       examples.)

       This example uses LATERAL to apply a set-returning function
       get_product_names() for each row of the manufacturers table:

           SELECT m.name AS mname, pname
           FROM manufacturers m, LATERAL get_product_names(m.id) pname;

       Manufacturers not currently having any products would not appear in the
       result, since it is an inner join. If we wished to include the names of
       such manufacturers in the result, we could do:

           SELECT m.name AS mname, pname
           FROM manufacturers m LEFT JOIN LATERAL get_product_names(m.id) pname ON true;

COMPATIBILITY
       Of course, the SELECT statement is compatible with the SQL standard.
       But there are some extensions and some missing features.

   Omitted FROM Clauses
       PostgreSQL allows one to omit the FROM clause. It has a straightforward
       use to compute the results of simple expressions:

           SELECT 2+2;

            ?column?
           ----------
                   4

       Some other SQL databases cannot do this except by introducing a dummy
       one-row table from which to do the SELECT.

       Note that if a FROM clause is not specified, the query cannot reference
       any database tables. For example, the following query is invalid:

           SELECT distributors.* WHERE distributors.name = 'Westward';

       PostgreSQL releases prior to 8.1 would accept queries of this form, and
       add an implicit entry to the query's FROM clause for each table
       referenced by the query. This is no longer allowed.

   Empty SELECT Lists
       The list of output expressions after SELECT can be empty, producing a
       zero-column result table. This is not valid syntax according to the SQL
       standard.  PostgreSQL allows it to be consistent with allowing
       zero-column tables. However, an empty list is not allowed when DISTINCT
       is used.

   Omitting the AS Key Word
       In the SQL standard, the optional key word AS can be omitted before an
       output column name whenever the new column name is a valid column name
       (that is, not the same as any reserved keyword).  PostgreSQL is
       slightly more restrictive: AS is required if the new column name
       matches any keyword at all, reserved or not. Recommended practice is to
       use AS or double-quote output column names, to prevent any possible
       conflict against future keyword additions.

       In FROM items, both the standard and PostgreSQL allow AS to be omitted
       before an alias that is an unreserved keyword. But this is impractical
       for output column names, because of syntactic ambiguities.

   ONLY and Inheritance
       The SQL standard requires parentheses around the table name when
       writing ONLY, for example SELECT * FROM ONLY (tab1), ONLY (tab2) WHERE
       ....  PostgreSQL considers these parentheses to be optional.

       PostgreSQL allows a trailing * to be written to explicitly specify the
       non-ONLY behavior of including child tables. The standard does not
       allow this.

       (These points apply equally to all SQL commands supporting the ONLY
       option.)

   TABLESAMPLE Clause Restrictions
       The TABLESAMPLE clause is currently accepted only on regular tables and
       materialized views. According to the SQL standard it should be possible
       to apply it to any FROM item.

   Function Calls in FROM
       PostgreSQL allows a function call to be written directly as a member of
       the FROM list. In the SQL standard it would be necessary to wrap such a
       function call in a sub-SELECT; that is, the syntax FROM func(...) alias
       is approximately equivalent to FROM LATERAL (SELECT func(...)) alias.
       Note that LATERAL is considered to be implicit; this is because the
       standard requires LATERAL semantics for an UNNEST() item in FROM.
       PostgreSQL treats UNNEST() the same as other set-returning functions.

   Namespace Available to GROUP BY and ORDER BY
       In the SQL-92 standard, an ORDER BY clause can only use output column
       names or numbers, while a GROUP BY clause can only use expressions
       based on input column names.  PostgreSQL extends each of these clauses
       to allow the other choice as well (but it uses the standard's
       interpretation if there is ambiguity).  PostgreSQL also allows both
       clauses to specify arbitrary expressions. Note that names appearing in
       an expression will always be taken as input-column names, not as
       output-column names.

       SQL:1999 and later use a slightly different definition which is not
       entirely upward compatible with SQL-92. In most cases, however,
       PostgreSQL will interpret an ORDER BY or GROUP BY expression the same
       way SQL:1999 does.

   Functional Dependencies
       PostgreSQL recognizes functional dependency (allowing columns to be
       omitted from GROUP BY) only when a table's primary key is included in
       the GROUP BY list. The SQL standard specifies additional conditions
       that should be recognized.

   WINDOW Clause Restrictions
       The SQL standard provides additional options for the window
       frame_clause.  PostgreSQL currently supports only the options listed
       above.

   LIMIT and OFFSET
       The clauses LIMIT and OFFSET are PostgreSQL-specific syntax, also used
       by MySQL. The SQL:2008 standard has introduced the clauses OFFSET ...
       FETCH {FIRST|NEXT} ...  for the same functionality, as shown above in
       LIMIT Clause. This syntax is also used by IBM DB2. (Applications
       written for Oracle frequently use a workaround involving the
       automatically generated rownum column, which is not available in
       PostgreSQL, to implement the effects of these clauses.)

   FOR NO KEY UPDATE, FOR UPDATE, FOR SHARE, FOR KEY SHARE
       Although FOR UPDATE appears in the SQL standard, the standard allows it
       only as an option of DECLARE CURSOR.  PostgreSQL allows it in any
       SELECT query as well as in sub-SELECTs, but this is an extension. The
       FOR NO KEY UPDATE, FOR SHARE and FOR KEY SHARE variants, as well as the
       NOWAIT and SKIP LOCKED options, do not appear in the standard.

   Data-Modifying Statements in WITH
       PostgreSQL allows INSERT, UPDATE, and DELETE to be used as WITH
       queries. This is not found in the SQL standard.

   Nonstandard Clauses
       DISTINCT ON ( ... ) is an extension of the SQL standard.

       ROWS FROM( ... ) is an extension of the SQL standard.



PostgreSQL 9.6.1                     2016                            SELECT(7)
ALTER TEXT SEARCH PARSERPostgreSQL 9.6.1 DocumentatALTER TEXT SEARCH PARSER(7)



NAME
       ALTER_TEXT_SEARCH_PARSER - change the definition of a text search
       parser

SYNOPSIS
       ALTER TEXT SEARCH PARSER name RENAME TO new_name
       ALTER TEXT SEARCH PARSER name SET SCHEMA new_schema

DESCRIPTION
       ALTER TEXT SEARCH PARSER changes the definition of a text search
       parser. Currently, the only supported functionality is to change the
       parser's name.

       You must be a superuser to use ALTER TEXT SEARCH PARSER.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing text search
           parser.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       new_name
           The new name of the text search parser.

       new_schema
           The new schema for the text search parser.

COMPATIBILITY
       There is no ALTER TEXT SEARCH PARSER statement in the SQL standard.

SEE ALSO
       CREATE TEXT SEARCH PARSER (CREATE_TEXT_SEARCH_PARSER(7)), DROP TEXT
       SEARCH PARSER (DROP_TEXT_SEARCH_PARSER(7))



PostgreSQL 9.6.1                     2016          ALTER TEXT SEARCH PARSER(7)
DROP TABLESPACE(7)      PostgreSQL 9.6.1 Documentation      DROP TABLESPACE(7)



NAME
       DROP_TABLESPACE - remove a tablespace

SYNOPSIS
       DROP TABLESPACE [ IF EXISTS ] name

DESCRIPTION
       DROP TABLESPACE removes a tablespace from the system.

       A tablespace can only be dropped by its owner or a superuser. The
       tablespace must be empty of all database objects before it can be
       dropped. It is possible that objects in other databases might still
       reside in the tablespace even if no objects in the current database are
       using the tablespace. Also, if the tablespace is listed in the
       temp_tablespaces setting of any active session, the DROP might fail due
       to temporary files residing in the tablespace.

PARAMETERS
       IF EXISTS
           Do not throw an error if the tablespace does not exist. A notice is
           issued in this case.

       name
           The name of a tablespace.

NOTES
       DROP TABLESPACE cannot be executed inside a transaction block.

EXAMPLES
       To remove tablespace mystuff from the system:

           DROP TABLESPACE mystuff;

COMPATIBILITY
       DROP TABLESPACE is a PostgreSQL extension.

SEE ALSO
       CREATE TABLESPACE (CREATE_TABLESPACE(7)), ALTER TABLESPACE
       (ALTER_TABLESPACE(7))



PostgreSQL 9.6.1                     2016                   DROP TABLESPACE(7)
ALTER AGGREGATE(7)      PostgreSQL 9.6.1 Documentation      ALTER AGGREGATE(7)



NAME
       ALTER_AGGREGATE - change the definition of an aggregate function

SYNOPSIS
       ALTER AGGREGATE name ( aggregate_signature ) RENAME TO new_name
       ALTER AGGREGATE name ( aggregate_signature )
                       OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER AGGREGATE name ( aggregate_signature ) SET SCHEMA new_schema

       where aggregate_signature is:

       * |
       [ argmode ] [ argname ] argtype [ , ... ] |
       [ [ argmode ] [ argname ] argtype [ , ... ] ] ORDER BY [ argmode ] [ argname ] argtype [ , ... ]

DESCRIPTION
       ALTER AGGREGATE changes the definition of an aggregate function.

<!-- ad137a5f-7fa1-4b53-a38d-4827f1ccde6e <=< ACCEPT -->       You must own the aggregate function to use ALTER AGGREGATE. To change
       the schema of an aggregate function, you must also have CREATE
       privilege on the new schema. To alter the owner, you must also be a
       direct or indirect member of the new owning role, and that role must
       have CREATE privilege on the aggregate function's schema. (These
       restrictions enforce that altering the owner doesn't do anything you
       couldn't do by dropping and recreating the aggregate function. However,
       a superuser can alter ownership of any aggregate function anyway.)<!-- ACCEPT >=> ad137a5f-7fa1-4b53-a38d-4827f1ccde6e -->

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing aggregate
           function.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

<!-- 4621cdbd-9d59-444b-9354-d5b42500378a <=< ACCEPT -->       argmode
           The mode of an argument: IN or VARIADIC. If omitted, the default is
           IN.

       argname
           The name of an argument. Note that ALTER AGGREGATE does not
           actually pay any attention to argument names, since only the
           argument data types are needed to determine the aggregate
           function's identity.

       argtype
           An input data type on which the aggregate function operates. To
           reference a zero-argument aggregate function, write * in place of
           the list of argument specifications. To reference an ordered-set
           aggregate function, write ORDER BY between the direct and
           aggregated argument specifications.<!-- ACCEPT >=> 4621cdbd-9d59-444b-9354-d5b42500378a -->

       new_name
           The new name of the aggregate function.

       new_owner
           The new owner of the aggregate function.

       new_schema
           The new schema for the aggregate function.

NOTES
       The recommended syntax for referencing an ordered-set aggregate is to
       write ORDER BY between the direct and aggregated argument
       specifications, in the same style as in CREATE AGGREGATE
       (CREATE_AGGREGATE(7)). However, it will also work to omit ORDER BY and
       just run the direct and aggregated argument specifications into a
       single list. In this abbreviated form, if VARIADIC "any" was used in
       both the direct and aggregated argument lists, write VARIADIC "any"
       only once.

EXAMPLES
       To rename the aggregate function myavg for type integer to my_average:

           ALTER AGGREGATE myavg(integer) RENAME TO my_average;

       To change the owner of the aggregate function myavg for type integer to
       joe:

           ALTER AGGREGATE myavg(integer) OWNER TO joe;

       To move the ordered-set aggregate mypercentile with direct argument of
       type float8 and aggregated argument of type integer into schema
       myschema:

           ALTER AGGREGATE mypercentile(float8 ORDER BY integer) SET SCHEMA myschema;

       This will work too:

           ALTER AGGREGATE mypercentile(float8, integer) SET SCHEMA myschema;


COMPATIBILITY
       There is no ALTER AGGREGATE statement in the SQL standard.

SEE ALSO
       CREATE AGGREGATE (CREATE_AGGREGATE(7)), DROP AGGREGATE
       (DROP_AGGREGATE(7))



PostgreSQL 9.6.1                     2016                   ALTER AGGREGATE(7)
ALTER SERVER(7)         PostgreSQL 9.6.1 Documentation         ALTER SERVER(7)



NAME
       ALTER_SERVER - change the definition of a foreign server

SYNOPSIS
       ALTER SERVER name [ VERSION 'new_version' ]
           [ OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ] ) ]
       ALTER SERVER name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER SERVER name RENAME TO new_name

DESCRIPTION
       ALTER SERVER changes the definition of a foreign server. The first form
       changes the server version string or the generic options of the server
       (at least one clause is required). The second form changes the owner of
       the server.

       To alter the server you must be the owner of the server. Additionally
       to alter the owner, you must own the server and also be a direct or
       indirect member of the new owning role, and you must have USAGE
       privilege on the server's foreign-data wrapper. (Note that superusers
       satisfy all these criteria automatically.)

PARAMETERS
       name
           The name of an existing server.

       new_version
           New server version.

       OPTIONS ( [ ADD | SET | DROP ] option ['value'] [, ... ] )
           Change options for the server.  ADD, SET, and DROP specify the
           action to be performed.  ADD is assumed if no operation is
           explicitly specified. Option names must be unique; names and values
           are also validated using the server's foreign-data wrapper library.

       new_owner
           The user name of the new owner of the foreign server.

       new_name
           The new name for the foreign server.

EXAMPLES
       Alter server foo, add connection options:

           ALTER SERVER foo OPTIONS (host 'foo', dbname 'foodb');

       Alter server foo, change version, change host option:

           ALTER SERVER foo VERSION '8.4' OPTIONS (SET host 'baz');

COMPATIBILITY
       ALTER SERVER conforms to ISO/IEC 9075-9 (SQL/MED). The OWNER TO and
       RENAME forms are PostgreSQL extensions.

SEE ALSO
       CREATE SERVER (CREATE_SERVER(7)), DROP SERVER (DROP_SERVER(7))



PostgreSQL 9.6.1                     2016                      ALTER SERVER(7)
DROP TRIGGER(7)         PostgreSQL 9.6.1 Documentation         DROP TRIGGER(7)



NAME
       DROP_TRIGGER - remove a trigger

SYNOPSIS
       DROP TRIGGER [ IF EXISTS ] name ON table_name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP TRIGGER removes an existing trigger definition. To execute this
       command, the current user must be the owner of the table for which the
       trigger is defined.

PARAMETERS
       IF EXISTS
           Do not throw an error if the trigger does not exist. A notice is
           issued in this case.

       name
           The name of the trigger to remove.

       table_name
           The name (optionally schema-qualified) of the table for which the
           trigger is defined.

       CASCADE
           Automatically drop objects that depend on the trigger, and in turn
           all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the trigger if any objects depend on it. This is the
           default.

EXAMPLES
       Destroy the trigger if_dist_exists on the table films:

           DROP TRIGGER if_dist_exists ON films;

COMPATIBILITY
       The DROP TRIGGER statement in PostgreSQL is incompatible with the SQL
       standard. In the SQL standard, trigger names are not local to tables,
       so the command is simply DROP TRIGGER name.

SEE ALSO
       CREATE TRIGGER (CREATE_TRIGGER(7))



PostgreSQL 9.6.1                     2016                      DROP TRIGGER(7)
DROP INDEX(7)           PostgreSQL 9.6.1 Documentation           DROP INDEX(7)



NAME
       DROP_INDEX - remove an index

SYNOPSIS
       DROP INDEX [ CONCURRENTLY ] [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP INDEX drops an existing index from the database system. To execute
       this command you must be the owner of the index.

PARAMETERS
       CONCURRENTLY
           Drop the index without locking out concurrent selects, inserts,
           updates, and deletes on the index's table. A normal DROP INDEX
           acquires exclusive lock on the table, blocking other accesses until
           the index drop can be completed. With this option, the command
           instead waits until conflicting transactions have completed.

           There are several caveats to be aware of when using this option.
           Only one index name can be specified, and the CASCADE option is not
           supported. (Thus, an index that supports a UNIQUE or PRIMARY KEY
           constraint cannot be dropped this way.) Also, regular DROP INDEX
           commands can be performed within a transaction block, but DROP
           INDEX CONCURRENTLY cannot.

       IF EXISTS
           Do not throw an error if the index does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an index to remove.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the index, and in turn
           all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the index if any objects depend on it. This is the
           default.

EXAMPLES
       This command will remove the index title_idx:

           DROP INDEX title_idx;

COMPATIBILITY
       DROP INDEX is a PostgreSQL language extension. There are no provisions
       for indexes in the SQL standard.

SEE ALSO
       CREATE INDEX (CREATE_INDEX(7))



PostgreSQL 9.6.1                     2016                        DROP INDEX(7)
CREATE SEQUENCE(7)      PostgreSQL 9.6.1 Documentation      CREATE SEQUENCE(7)



NAME
       CREATE_SEQUENCE - define a new sequence generator

SYNOPSIS
       CREATE [ TEMPORARY | TEMP ] SEQUENCE [ IF NOT EXISTS ] name [ INCREMENT [ BY ] increment ]
           [ MINVALUE minvalue | NO MINVALUE ] [ MAXVALUE maxvalue | NO MAXVALUE ]
           [ START [ WITH ] start ] [ CACHE cache ] [ [ NO ] CYCLE ]
           [ OWNED BY { table_name.column_name | NONE } ]

DESCRIPTION
       CREATE SEQUENCE creates a new sequence number generator. This involves
       creating and initializing a new special single-row table with the name
       name. The generator will be owned by the user issuing the command.

       If a schema name is given then the sequence is created in the specified
       schema. Otherwise it is created in the current schema. Temporary
       sequences exist in a special schema, so a schema name cannot be given
       when creating a temporary sequence. The sequence name must be distinct
       from the name of any other sequence, table, index, view, or foreign
       table in the same schema.

       After a sequence is created, you use the functions nextval, currval,
       and setval to operate on the sequence. These functions are documented
       in Section 9.16, "Sequence Manipulation Functions", in the
       documentation.

       Although you cannot update a sequence directly, you can use a query
       like:

           SELECT * FROM name;

       to examine the parameters and current state of a sequence. In
       particular, the last_value field of the sequence shows the last value
       allocated by any session. (Of course, this value might be obsolete by
       the time it's printed, if other sessions are actively doing nextval
       calls.)

PARAMETERS
       TEMPORARY or TEMP
           If specified, the sequence object is created only for this session,
           and is automatically dropped on session exit. Existing permanent
           sequences with the same name are not visible (in this session)
           while the temporary sequence exists, unless they are referenced
           with schema-qualified names.

       IF NOT EXISTS
           Do not throw an error if a relation with the same name already
           exists. A notice is issued in this case. Note that there is no
           guarantee that the existing relation is anything like the sequence
           that would have been created - it might not even be a sequence.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the sequence to be
           created.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       increment
           The optional clause INCREMENT BY increment specifies which value is
           added to the current sequence value to create a new value. A
           positive value will make an ascending sequence, a negative one a
           descending sequence. The default value is 1.

       minvalue
       NO MINVALUE
           The optional clause MINVALUE minvalue determines the minimum value
           a sequence can generate. If this clause is not supplied or NO
           MINVALUE is specified, then defaults will be used. The defaults are
           1 and -2^63-1 for ascending and descending sequences, respectively.

       maxvalue
       NO MAXVALUE
           The optional clause MAXVALUE maxvalue determines the maximum value
           for the sequence. If this clause is not supplied or NO MAXVALUE is
           specified, then default values will be used. The defaults are
           2^63-1 and -1 for ascending and descending sequences, respectively.

       start
           The optional clause START WITH start allows the sequence to begin
           anywhere. The default starting value is minvalue for ascending
           sequences and maxvalue for descending ones.

<!-- 876beccf-ebcb-4002-ae74-553e963fc807 <=< ACCEPT -->       cache
           The optional clause CACHE cache specifies how many sequence numbers
           are to be preallocated and stored in memory for faster access. The
           minimum value is 1 (only one value can be generated at a time,
           i.e., no cache), and this is also the default.

       CYCLE
       NO CYCLE
           The CYCLE option allows the sequence to wrap around when the
           maxvalue or minvalue has been reached by an ascending or descending
           sequence respectively. If the limit is reached, the next number
           generated will be the minvalue or maxvalue, respectively.

           If NO CYCLE is specified, any calls to nextval after the sequence
           has reached its maximum value will return an error. If neither
           CYCLE or NO CYCLE are specified, NO CYCLE is the default.

       OWNED BY table_name.column_name
       OWNED BY NONE
           The OWNED BY option causes the sequence to be associated with a
           specific table column, such that if that column (or its whole
           table) is dropped, the sequence will be automatically dropped as
           well. The specified table must have the same owner and be in the
           same schema as the sequence.  OWNED BY NONE, the default, specifies
           that there is no such association.<!-- ACCEPT >=> 876beccf-ebcb-4002-ae74-553e963fc807 -->

NOTES
       Use DROP SEQUENCE to remove a sequence.

       Sequences are based on bigint arithmetic, so the range cannot exceed
       the range of an eight-byte integer (-9223372036854775808 to
       9223372036854775807).

       Because nextval and setval calls are never rolled back, sequence
       objects cannot be used if "gapless" assignment of sequence numbers is
       needed. It is possible to build gapless assignment by using exclusive
       locking of a table containing a counter; but this solution is much more
       expensive than sequence objects, especially if many transactions need
       sequence numbers concurrently.

       Unexpected results might be obtained if a cache setting greater than
       one is used for a sequence object that will be used concurrently by
       multiple sessions. Each session will allocate and cache successive
       sequence values during one access to the sequence object and increase
       the sequence object's last_value accordingly. Then, the next cache-1
       uses of nextval within that session simply return the preallocated
       values without touching the sequence object. So, any numbers allocated
       but not used within a session will be lost when that session ends,
       resulting in "holes" in the sequence.

       Furthermore, although multiple sessions are guaranteed to allocate
       distinct sequence values, the values might be generated out of sequence
       when all the sessions are considered. For example, with a cache setting
       of 10, session A might reserve values 1..10 and return nextval=1, then
       session B might reserve values 11..20 and return nextval=11 before
       session A has generated nextval=2. Thus, with a cache setting of one it
       is safe to assume that nextval values are generated sequentially; with
       a cache setting greater than one you should only assume that the
       nextval values are all distinct, not that they are generated purely
       sequentially. Also, last_value will reflect the latest value reserved
       by any session, whether or not it has yet been returned by nextval.

       Another consideration is that a setval executed on such a sequence will
       not be noticed by other sessions until they have used up any
       preallocated values they have cached.

EXAMPLES
       Create an ascending sequence called serial, starting at 101:

           CREATE SEQUENCE serial START 101;

       Select the next number from this sequence:

           SELECT nextval('serial');

            nextval
           ---------
                101

       Select the next number from this sequence:

           SELECT nextval('serial');

            nextval
           ---------
                102

       Use this sequence in an INSERT command:

           INSERT INTO distributors VALUES (nextval('serial'), 'nothing');

       Update the sequence value after a COPY FROM:

           BEGIN;
           COPY distributors FROM 'input_file';
           SELECT setval('serial', max(id)) FROM distributors;
           END;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       CREATE SEQUENCE conforms to the SQL standard, with the following
       exceptions:

       o   The standard's AS data_type expression is not supported.

       o   Obtaining the next value is done using the nextval() function
           instead of the standard's NEXT VALUE FOR expression.

       o   The OWNED BY clause is a PostgreSQL extension.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

SEE ALSO
       ALTER SEQUENCE (ALTER_SEQUENCE(7)), DROP SEQUENCE (DROP_SEQUENCE(7))



PostgreSQL 9.6.1                     2016                   CREATE SEQUENCE(7)
CREATE VIEW(7)          PostgreSQL 9.6.1 Documentation          CREATE VIEW(7)



NAME
       CREATE_VIEW - define a new view

SYNOPSIS
       CREATE [ OR REPLACE ] [ TEMP | TEMPORARY ] [ RECURSIVE ] VIEW name [ ( column_name [, ...] ) ]
           [ WITH ( view_option_name [= view_option_value] [, ... ] ) ]
           AS query
           [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]

DESCRIPTION
       CREATE VIEW defines a view of a query. The view is not physically
       materialized. Instead, the query is run every time the view is
       referenced in a query.

       CREATE OR REPLACE VIEW is similar, but if a view of the same name
       already exists, it is replaced. The new query must generate the same
       columns that were generated by the existing view query (that is, the
       same column names in the same order and with the same data types), but
       it may add additional columns to the end of the list. The calculations
       giving rise to the output columns may be completely different.

       If a schema name is given (for example, CREATE VIEW myschema.myview
       ...) then the view is created in the specified schema. Otherwise it is
       created in the current schema. Temporary views exist in a special
       schema, so a schema name cannot be given when creating a temporary
       view. The name of the view must be distinct from the name of any other
       view, table, sequence, index or foreign table in the same schema.

PARAMETERS
       TEMPORARY or TEMP
           If specified, the view is created as a temporary view. Temporary
           views are automatically dropped at the end of the current session.
           Existing permanent relations with the same name are not visible to
           the current session while the temporary view exists, unless they
           are referenced with schema-qualified names.

           If any of the tables referenced by the view are temporary, the view
           is created as a temporary view (whether TEMPORARY is specified or
           not).

       RECURSIVE
           Creates a recursive view. The syntax

               CREATE RECURSIVE VIEW [ schema . ] view_name (column_names) AS SELECT ...;

           is equivalent to

               CREATE VIEW [ schema . ] view_name AS WITH RECURSIVE view_name (column_names) AS (SELECT ...) SELECT column_names FROM view_name;

           A view column name list must be specified for a recursive view.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of a view to be created.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       column_name
           An optional list of names to be used for columns of the view. If
           not given, the column names are deduced from the query.

       WITH ( view_option_name [= view_option_value] [, ... ] )
           This clause specifies optional parameters for a view; the following
           parameters are supported:

           check_option (string)
               This parameter may be either local or cascaded, and is
               equivalent to specifying WITH [ CASCADED | LOCAL ] CHECK OPTION
               (see below). This option can be changed on existing views using
               ALTER VIEW (ALTER_VIEW(7)).

           security_barrier (boolean)
               This should be used if the view is intended to provide
               row-level security. See Section 39.5, "Rules and Privileges",
               in the documentation for full details.


       query
           A SELECT(7) or VALUES(7) command which will provide the columns and
           rows of the view.

       WITH [ CASCADED | LOCAL ] CHECK OPTION
           This option controls the behavior of automatically updatable views.
           When this option is specified, INSERT and UPDATE commands on the
           view will be checked to ensure that new rows satisfy the
           view-defining condition (that is, the new rows are checked to
           ensure that they are visible through the view). If they are not,
           the update will be rejected. If the CHECK OPTION is not specified,
           INSERT and UPDATE commands on the view are allowed to create rows
           that are not visible through the view. The following check options
           are supported:

           LOCAL
               New rows are only checked against the conditions defined
               directly in the view itself. Any conditions defined on
               underlying base views are not checked (unless they also specify
               the CHECK OPTION).

           CASCADED
               New rows are checked against the conditions of the view and all
               underlying base views. If the CHECK OPTION is specified, and
               neither LOCAL nor CASCADED is specified, then CASCADED is
               assumed.

           The CHECK OPTION may not be used with RECURSIVE views.

           Note that the CHECK OPTION is only supported on views that are
           automatically updatable, and do not have INSTEAD OF triggers or
           INSTEAD rules. If an automatically updatable view is defined on top
           of a base view that has INSTEAD OF triggers, then the LOCAL CHECK
           OPTION may be used to check the conditions on the automatically
           updatable view, but the conditions on the base view with INSTEAD OF
           triggers will not be checked (a cascaded check option will not
           cascade down to a trigger-updatable view, and any check options
           defined directly on a trigger-updatable view will be ignored). If
           the view or any of its base relations has an INSTEAD rule that
           causes the INSERT or UPDATE command to be rewritten, then all check
           options will be ignored in the rewritten query, including any
           checks from automatically updatable views defined on top of the
           relation with the INSTEAD rule.

NOTES
       Use the DROP VIEW (DROP_VIEW(7)) statement to drop views.

       Be careful that the names and types of the view's columns will be
       assigned the way you want. For example:

           CREATE VIEW vista AS SELECT 'Hello World';

       is bad form in two ways: the column name defaults to ?column?, and the
       column data type defaults to unknown. If you want a string literal in a
       view's result, use something like:

           CREATE VIEW vista AS SELECT text 'Hello World' AS hello;

       Access to tables referenced in the view is determined by permissions of
       the view owner. In some cases, this can be used to provide secure but
       restricted access to the underlying tables. However, not all views are
       secure against tampering; see Section 39.5, "Rules and Privileges", in
       the documentation for details. Functions called in the view are treated
       the same as if they had been called directly from the query using the
       view. Therefore the user of a view must have permissions to call all
       functions used by the view.

       When CREATE OR REPLACE VIEW is used on an existing view, only the
       view's defining SELECT rule is changed. Other view properties,
       including ownership, permissions, and non-SELECT rules, remain
       unchanged. You must own the view to replace it (this includes being a
       member of the owning role).

   Updatable Views
       Simple views are automatically updatable: the system will allow INSERT,
       UPDATE and DELETE statements to be used on the view in the same way as
       on a regular table. A view is automatically updatable if it satisfies
       all of the following conditions:

       o   The view must have exactly one entry in its FROM list, which must
           be a table or another updatable view.

       o   The view definition must not contain WITH, DISTINCT, GROUP BY,
           HAVING, LIMIT, or OFFSET clauses at the top level.

       o   The view definition must not contain set operations (UNION,
           INTERSECT or EXCEPT) at the top level.

       o   The view's select list must not contain any aggregates, window
           functions or set-returning functions.

       An automatically updatable view may contain a mix of updatable and
       non-updatable columns. A column is updatable if it is a simple
       reference to an updatable column of the underlying base relation;
       otherwise the column is read-only, and an error will be raised if an
       INSERT or UPDATE statement attempts to assign a value to it.

       If the view is automatically updatable the system will convert any
       INSERT, UPDATE or DELETE statement on the view into the corresponding
       statement on the underlying base relation.  INSERT statements that have
       an ON CONFLICT UPDATE clause are fully supported.

       If an automatically updatable view contains a WHERE condition, the
       condition restricts which rows of the base relation are available to be
       modified by UPDATE and DELETE statements on the view. However, an
       UPDATE is allowed to change a row so that it no longer satisfies the
       WHERE condition, and thus is no longer visible through the view.
       Similarly, an INSERT command can potentially insert base-relation rows
       that do not satisfy the WHERE condition and thus are not visible
       through the view (ON CONFLICT UPDATE may similarly affect an existing
       row not visible through the view). The CHECK OPTION may be used to
       prevent INSERT and UPDATE commands from creating such rows that are not
       visible through the view.

       If an automatically updatable view is marked with the security_barrier
       property then all the view's WHERE conditions (and any conditions using
       operators which are marked as LEAKPROOF) will always be evaluated
       before any conditions that a user of the view has added. See Section
       39.5, "Rules and Privileges", in the documentation for full details.
       Note that, due to this, rows which are not ultimately returned (because
       they do not pass the user's WHERE conditions) may still end up being
       locked.  EXPLAIN can be used to see which conditions are applied at the
       relation level (and therefore do not lock rows) and which are not.

       A more complex view that does not satisfy all these conditions is
       read-only by default: the system will not allow an insert, update, or
       delete on the view. You can get the effect of an updatable view by
       creating INSTEAD OF triggers on the view, which must convert attempted
       inserts, etc. on the view into appropriate actions on other tables. For
       more information see CREATE TRIGGER (CREATE_TRIGGER(7)). Another
       possibility is to create rules (see CREATE RULE (CREATE_RULE(7))), but
       in practice triggers are easier to understand and use correctly.

       Note that the user performing the insert, update or delete on the view
       must have the corresponding insert, update or delete privilege on the
       view. In addition the view's owner must have the relevant privileges on
       the underlying base relations, but the user performing the update does
       not need any permissions on the underlying base relations (see Section
       39.5, "Rules and Privileges", in the documentation).

EXAMPLES
       Create a view consisting of all comedy films:

           CREATE VIEW comedies AS
               SELECT *
               FROM films
               WHERE kind = 'Comedy';

       This will create a view containing the columns that are in the film
       table at the time of view creation. Though * was used to create the
       view, columns added later to the table will not be part of the view.

       Create a view with LOCAL CHECK OPTION:

           CREATE VIEW universal_comedies AS
               SELECT *
               FROM comedies
               WHERE classification = 'U'
               WITH LOCAL CHECK OPTION;

       This will create a view based on the comedies view, showing only films
       with kind = 'Comedy' and classification = 'U'. Any attempt to INSERT or
       UPDATE a row in the view will be rejected if the new row doesn't have
       classification = 'U', but the film kind will not be checked.

       Create a view with CASCADED CHECK OPTION:

           CREATE VIEW pg_comedies AS
               SELECT *
               FROM comedies
               WHERE classification = 'PG'
               WITH CASCADED CHECK OPTION;

       This will create a view that checks both the kind and classification of
       new rows.

       Create a view with a mix of updatable and non-updatable columns:

           CREATE VIEW comedies AS
               SELECT f.*,
                      country_code_to_name(f.country_code) AS country,
                      (SELECT avg(r.rating)
                       FROM user_ratings r
                       WHERE r.film_id = f.id) AS avg_rating
               FROM films f
               WHERE f.kind = 'Comedy';

       This view will support INSERT, UPDATE and DELETE. All the columns from
       the films table will be updatable, whereas the computed columns country
       and avg_rating will be read-only.

       Create a recursive view consisting of the numbers from 1 to 100:

           CREATE RECURSIVE VIEW public.nums_1_100 (n) AS
               VALUES (1)
           UNION ALL
               SELECT n+1 FROM nums_1_100 WHERE n &amp;lt; 100;

       Notice that although the recursive view's name is schema-qualified in
       this CREATE, its internal self-reference is not schema-qualified. This
       is because the implicitly-created CTE's name cannot be
       schema-qualified.

COMPATIBILITY
       CREATE OR REPLACE VIEW is a PostgreSQL language extension. So is the
       concept of a temporary view. The WITH ( ... ) clause is an extension as
       well.

SEE ALSO
       ALTER VIEW (ALTER_VIEW(7)), DROP VIEW (DROP_VIEW(7)), CREATE
       MATERIALIZED VIEW (CREATE_MATERIALIZED_VIEW(7))



PostgreSQL 9.6.1                     2016                       CREATE VIEW(7)
DEALLOCATE(7)           PostgreSQL 9.6.1 Documentation           DEALLOCATE(7)



NAME
       DEALLOCATE - deallocate a prepared statement

SYNOPSIS
       DEALLOCATE [ PREPARE ] { name | ALL }

DESCRIPTION
       DEALLOCATE is used to deallocate a previously prepared SQL statement.
       If you do not explicitly deallocate a prepared statement, it is
       deallocated when the session ends.

       For more information on prepared statements, see PREPARE(7).

PARAMETERS
       PREPARE
           This key word is ignored.

       name
           The name of the prepared statement to deallocate.

       ALL
           Deallocate all prepared statements.

COMPATIBILITY
       The SQL standard includes a DEALLOCATE statement, but it is only for
       use in embedded SQL.

SEE ALSO
       EXECUTE(7), PREPARE(7)



PostgreSQL 9.6.1                     2016                        DEALLOCATE(7)
SET TRANSACTION(7)      PostgreSQL 9.6.1 Documentation      SET TRANSACTION(7)



NAME
       SET_TRANSACTION - set the characteristics of the current transaction

SYNOPSIS
       SET TRANSACTION transaction_mode [, ...]
       SET TRANSACTION SNAPSHOT snapshot_id
       SET SESSION CHARACTERISTICS AS TRANSACTION transaction_mode [, ...]

       where transaction_mode is one of:

           ISOLATION LEVEL { SERIALIZABLE | REPEATABLE READ | READ COMMITTED | READ UNCOMMITTED }
           READ WRITE | READ ONLY
           [ NOT ] DEFERRABLE

DESCRIPTION
       The SET TRANSACTION command sets the characteristics of the current
       transaction. It has no effect on any subsequent transactions.  SET
       SESSION CHARACTERISTICS sets the default transaction characteristics
       for subsequent transactions of a session. These defaults can be
       overridden by SET TRANSACTION for an individual transaction.

       The available transaction characteristics are the transaction isolation
       level, the transaction access mode (read/write or read-only), and the
       deferrable mode. In addition, a snapshot can be selected, though only
       for the current transaction, not as a session default.

       The isolation level of a transaction determines what data the
       transaction can see when other transactions are running concurrently:

       READ COMMITTED
           A statement can only see rows committed before it began. This is
           the default.

       REPEATABLE READ
           All statements of the current transaction can only see rows
           committed before the first query or data-modification statement was
           executed in this transaction.

       SERIALIZABLE
           All statements of the current transaction can only see rows
           committed before the first query or data-modification statement was
           executed in this transaction. If a pattern of reads and writes
           among concurrent serializable transactions would create a situation
           which could not have occurred for any serial (one-at-a-time)
           execution of those transactions, one of them will be rolled back
           with a serialization_failure error.
       The SQL standard defines one additional level, READ UNCOMMITTED. In
       PostgreSQLREAD UNCOMMITTED is treated as READ COMMITTED.

       The transaction isolation level cannot be changed after the first query
       or data-modification statement (SELECT, INSERT, DELETE, UPDATE, FETCH,
       or COPY) of a transaction has been executed. See Chapter 13,
       Concurrency Control, in the documentation for more information about
       transaction isolation and concurrency control.

       The transaction access mode determines whether the transaction is
       read/write or read-only. Read/write is the default. When a transaction
       is read-only, the following SQL commands are disallowed: INSERT,
       UPDATE, DELETE, and COPY FROM if the table they would write to is not a
       temporary table; all CREATE, ALTER, and DROP commands; COMMENT, GRANT,
       REVOKE, TRUNCATE; and EXPLAIN ANALYZE and EXECUTE if the command they
       would execute is among those listed. This is a high-level notion of
       read-only that does not prevent all writes to disk.

       The DEFERRABLE transaction property has no effect unless the
       transaction is also SERIALIZABLE and READ ONLY. When all three of these
       properties are selected for a transaction, the transaction may block
       when first acquiring its snapshot, after which it is able to run
       without the normal overhead of a SERIALIZABLE transaction and without
       any risk of contributing to or being canceled by a serialization
       failure. This mode is well suited for long-running reports or backups.

       The SET TRANSACTION SNAPSHOT command allows a new transaction to run
       with the same snapshot as an existing transaction. The pre-existing
       transaction must have exported its snapshot with the pg_export_snapshot
       function (see Section 9.26.5, "Snapshot Synchronization Functions", in
       the documentation). That function returns a snapshot identifier, which
       must be given to SET TRANSACTION SNAPSHOT to specify which snapshot is
       to be imported. The identifier must be written as a string literal in
       this command, for example '000003A1-1'.  SET TRANSACTION SNAPSHOT can
       only be executed at the start of a transaction, before the first query
       or data-modification statement (SELECT, INSERT, DELETE, UPDATE, FETCH,
       or COPY) of the transaction. Furthermore, the transaction must already
       be set to SERIALIZABLE or REPEATABLE READ isolation level (otherwise,
       the snapshot would be discarded immediately, since READ COMMITTED mode
       takes a new snapshot for each command). If the importing transaction
       uses SERIALIZABLE isolation level, then the transaction that exported
       the snapshot must also use that isolation level. Also, a non-read-only
       serializable transaction cannot import a snapshot from a read-only
       transaction.

NOTES
       If SET TRANSACTION is executed without a prior START TRANSACTION or
       BEGIN, it emits a warning and otherwise has no effect.

       It is possible to dispense with SET TRANSACTION by instead specifying
       the desired transaction_modes in BEGIN or START TRANSACTION. But that
       option is not available for SET TRANSACTION SNAPSHOT.

       The session default transaction modes can also be set by setting the
       configuration parameters default_transaction_isolation,
       default_transaction_read_only, and default_transaction_deferrable. (In
       fact SET SESSION CHARACTERISTICS is just a verbose equivalent for
       setting these variables with SET.) This means the defaults can be set
       in the configuration file, via ALTER DATABASE, etc. Consult Chapter 19,
       Server Configuration, in the documentation for more information.

EXAMPLES
       To begin a new transaction with the same snapshot as an already
       existing transaction, first export the snapshot from the existing
       transaction. That will return the snapshot identifier, for example:

           BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
           SELECT pg_export_snapshot();
            pg_export_snapshot
           --------------------
            000003A1-1
           (1 row)

       Then give the snapshot identifier in a SET TRANSACTION SNAPSHOT command
       at the beginning of the newly opened transaction:

           BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
           SET TRANSACTION SNAPSHOT '000003A1-1';

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       These commands are defined in the SQL standard, except for the
       DEFERRABLE transaction mode and the SET TRANSACTION SNAPSHOT form,
       which are PostgreSQL extensions.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

       SERIALIZABLE is the default transaction isolation level in the
       standard. In PostgreSQL the default is ordinarily READ COMMITTED, but
       you can change it as mentioned above.

       In the SQL standard, there is one other transaction characteristic that
       can be set with these commands: the size of the diagnostics area. This
       concept is specific to embedded SQL, and therefore is not implemented
       in the PostgreSQL server.

       The SQL standard requires commas between successive transaction_modes,
       but for historical reasons PostgreSQL allows the commas to be omitted.



PostgreSQL 9.6.1                     2016                   SET TRANSACTION(7)
DROP OWNED(7)           PostgreSQL 9.6.1 Documentation           DROP OWNED(7)



NAME
       DROP_OWNED - remove database objects owned by a database role

SYNOPSIS
       DROP OWNED BY { name | CURRENT_USER | SESSION_USER } [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP OWNED drops all the objects within the current database that are
       owned by one of the specified roles. Any privileges granted to the
       given roles on objects in the current database and on shared objects
       (databases, tablespaces) will also be revoked.

PARAMETERS
       name
           The name of a role whose objects will be dropped, and whose
           privileges will be revoked.

       CASCADE
           Automatically drop objects that depend on the affected objects, and
           in turn all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the objects owned by a role if any other database
           objects depend on one of the affected objects. This is the default.

NOTES
       DROP OWNED is often used to prepare for the removal of one or more
       roles. Because DROP OWNED only affects the objects in the current
       database, it is usually necessary to execute this command in each
       database that contains objects owned by a role that is to be removed.

       Using the CASCADE option might make the command recurse to objects
       owned by other users.

       The REASSIGN OWNED (REASSIGN_OWNED(7)) command is an alternative that
       reassigns the ownership of all the database objects owned by one or
       more roles. However, REASSIGN OWNED does not deal with privileges for
       other objects.

       Databases and tablespaces owned by the role(s) will not be removed.

       See Section 21.4, "Dropping Roles", in the documentation for more
       discussion.

COMPATIBILITY
       The DROP OWNED command is a PostgreSQL extension.

SEE ALSO
       REASSIGN OWNED (REASSIGN_OWNED(7)), DROP ROLE (DROP_ROLE(7))



PostgreSQL 9.6.1                     2016                        DROP OWNED(7)
SET ROLE(7)             PostgreSQL 9.6.1 Documentation             SET ROLE(7)



NAME
       SET_ROLE - set the current user identifier of the current session

SYNOPSIS
       SET [ SESSION | LOCAL ] ROLE role_name
       SET [ SESSION | LOCAL ] ROLE NONE
       RESET ROLE

DESCRIPTION
       This command sets the current user identifier of the current SQL
       session to be role_name. The role name can be written as either an
       identifier or a string literal. After SET ROLE, permissions checking
       for SQL commands is carried out as though the named role were the one
       that had logged in originally.

       The specified role_name must be a role that the current session user is
       a member of. (If the session user is a superuser, any role can be
       selected.)

       The SESSION and LOCAL modifiers act the same as for the regular SET(7)
       command.

       The NONE and RESET forms reset the current user identifier to be the
       current session user identifier. These forms can be executed by any
       user.

NOTES
       Using this command, it is possible to either add privileges or restrict
       one's privileges. If the session user role has the INHERITS attribute,
       then it automatically has all the privileges of every role that it
       could SET ROLE to; in this case SET ROLE effectively drops all the
       privileges assigned directly to the session user and to the other roles
       it is a member of, leaving only the privileges available to the named
       role. On the other hand, if the session user role has the NOINHERITS
       attribute, SET ROLE drops the privileges assigned directly to the
       session user and instead acquires the privileges available to the named
       role.

       In particular, when a superuser chooses to SET ROLE to a non-superuser
       role, they lose their superuser privileges.

       SET ROLE has effects comparable to SET SESSION AUTHORIZATION
       (SET_SESSION_AUTHORIZATION(7)), but the privilege checks involved are
       quite different. Also, SET SESSION AUTHORIZATION determines which roles
       are allowable for later SET ROLE commands, whereas changing roles with
       SET ROLE does not change the set of roles allowed to a later SET ROLE.

       SET ROLE does not process session variables as specified by the role's
       ALTER ROLE (ALTER_ROLE(7)) settings; this only happens during login.

       SET ROLE cannot be used within a SECURITY DEFINER function.

EXAMPLES
           SELECT SESSION_USER, CURRENT_USER;

            session_user | current_user
           --------------+--------------
            peter        | peter

           SET ROLE 'paul';

           SELECT SESSION_USER, CURRENT_USER;

            session_user | current_user
           --------------+--------------
            peter        | paul

COMPATIBILITY
       PostgreSQL allows identifier syntax ("rolename"), while the SQL
       standard requires the role name to be written as a string literal. SQL
       does not allow this command during a transaction; PostgreSQL does not
       make this restriction because there is no reason to. The SESSION and
       LOCAL modifiers are a PostgreSQL extension, as is the RESET syntax.

SEE ALSO
       SET SESSION AUTHORIZATION (SET_SESSION_AUTHORIZATION(7))



PostgreSQL 9.6.1                     2016                          SET ROLE(7)
PREPARE(7)              PostgreSQL 9.6.1 Documentation              PREPARE(7)



NAME
       PREPARE - prepare a statement for execution

SYNOPSIS
       PREPARE name [ ( data_type [, ...] ) ] AS statement

DESCRIPTION
       PREPARE creates a prepared statement. A prepared statement is a
       server-side object that can be used to optimize performance. When the
       PREPARE statement is executed, the specified statement is parsed,
       analyzed, and rewritten. When an EXECUTE command is subsequently
       issued, the prepared statement is planned and executed. This division
       of labor avoids repetitive parse analysis work, while allowing the
       execution plan to depend on the specific parameter values supplied.

       Prepared statements can take parameters: values that are substituted
       into the statement when it is executed. When creating the prepared
       statement, refer to parameters by position, using $1, $2, etc. A
       corresponding list of parameter data types can optionally be specified.
       When a parameter's data type is not specified or is declared as
       unknown, the type is inferred from the context in which the parameter
       is used (if possible). When executing the statement, specify the actual
       values for these parameters in the EXECUTE statement. Refer to
       EXECUTE(7) for more information about that.

       Prepared statements only last for the duration of the current database
       session. When the session ends, the prepared statement is forgotten, so
       it must be recreated before being used again. This also means that a
       single prepared statement cannot be used by multiple simultaneous
       database clients; however, each client can create their own prepared
       statement to use. Prepared statements can be manually cleaned up using
       the DEALLOCATE(7) command.

       Prepared statements potentially have the largest performance advantage
       when a single session is being used to execute a large number of
       similar statements. The performance difference will be particularly
       significant if the statements are complex to plan or rewrite, e.g. if
       the query involves a join of many tables or requires the application of
       several rules. If the statement is relatively simple to plan and
       rewrite but relatively expensive to execute, the performance advantage
       of prepared statements will be less noticeable.

PARAMETERS
       name
           An arbitrary name given to this particular prepared statement. It
           must be unique within a single session and is subsequently used to
           execute or deallocate a previously prepared statement.

       data_type
           The data type of a parameter to the prepared statement. If the data
           type of a particular parameter is unspecified or is specified as
           unknown, it will be inferred from the context in which the
           parameter is used. To refer to the parameters in the prepared
           statement itself, use $1, $2, etc.

       statement
           Any SELECT, INSERT, UPDATE, DELETE, or VALUES statement.

NOTES
       Prepared statements can use generic plans rather than re-planning with
       each set of supplied EXECUTE values. This occurs immediately for
       prepared statements with no parameters; otherwise it occurs only after
       five or more executions produce plans whose estimated cost average
       (including planning overhead) is more expensive than the generic plan
       cost estimate. Once a generic plan is chosen, it is used for the
       remaining lifetime of the prepared statement. Using EXECUTE values
       which are rare in columns with many duplicates can generate custom
       plans that are so much cheaper than the generic plan, even after adding
       planning overhead, that the generic plan might never be used.

       A generic plan assumes that each value supplied to EXECUTE is one of
       the column's distinct values and that column values are uniformly
       distributed. For example, if statistics record three distinct column
       values, a generic plan assumes a column equality comparison will match
       33% of processed rows. Column statistics also allow generic plans to
       accurately compute the selectivity of unique columns. Comparisons on
       non-uniformly-distributed columns and specification of non-existent
       values affects the average plan cost, and hence if and when a generic
       plan is chosen.

       To examine the query plan PostgreSQL is using for a prepared statement,
       use EXPLAIN(7), e.g.  EXPLAIN EXECUTE. If a generic plan is in use, it
       will contain parameter symbols $n, while a custom plan will have the
       supplied parameter values substituted into it. The row estimates in the
       generic plan reflect the selectivity computed for the parameters.

       For more information on query planning and the statistics collected by
       PostgreSQL for that purpose, see the ANALYZE(7) documentation.

       Although the main point of a prepared statement is to avoid repeated
       parse analysis and planning of the statement, PostgreSQL will force
       re-analysis and re-planning of the statement before using it whenever
       database objects used in the statement have undergone definitional
       (DDL) changes since the previous use of the prepared statement. Also,
       if the value of search_path changes from one use to the next, the
       statement will be re-parsed using the new search_path. (This latter
       behavior is new as of PostgreSQL 9.3.) These rules make use of a
       prepared statement semantically almost equivalent to re-submitting the
       same query text over and over, but with a performance benefit if no
       object definitions are changed, especially if the best plan remains the
       same across uses. An example of a case where the semantic equivalence
       is not perfect is that if the statement refers to a table by an
       unqualified name, and then a new table of the same name is created in a
       schema appearing earlier in the search_path, no automatic re-parse will
       occur since no object used in the statement changed. However, if some
       other change forces a re-parse, the new table will be referenced in
       subsequent uses.

       You can see all prepared statements available in the session by
       querying the pg_prepared_statements system view.

EXAMPLES
       Create a prepared statement for an INSERT statement, and then execute
       it:

           PREPARE fooplan (int, text, bool, numeric) AS
               INSERT INTO foo VALUES($1, $2, $3, $4);
           EXECUTE fooplan(1, 'Hunter Valley', 't', 200.00);

       Create a prepared statement for a SELECT statement, and then execute
       it:

           PREPARE usrrptplan (int) AS
               SELECT * FROM users u, logs l WHERE u.usrid=$1 AND u.usrid=l.usrid
               AND l.date = $2;
           EXECUTE usrrptplan(1, current_date);

       Note that the data type of the second parameter is not specified, so it
       is inferred from the context in which $2 is used.

COMPATIBILITY
       The SQL standard includes a PREPARE statement, but it is only for use
       in embedded SQL. This version of the PREPARE statement also uses a
       somewhat different syntax.

SEE ALSO
       DEALLOCATE(7), EXECUTE(7)



PostgreSQL 9.6.1                     2016                           PREPARE(7)
ALTER TEXT SEARCH DICTIOPostgreSQL 9.6.1 DocumeALTERoTEXT SEARCH DICTIONARY(7)



NAME
       ALTER_TEXT_SEARCH_DICTIONARY - change the definition of a text search
       dictionary

SYNOPSIS
       ALTER TEXT SEARCH DICTIONARY name (
           option [ = value ] [, ... ]
       )
       ALTER TEXT SEARCH DICTIONARY name RENAME TO new_name
       ALTER TEXT SEARCH DICTIONARY name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER TEXT SEARCH DICTIONARY name SET SCHEMA new_schema

DESCRIPTION
       ALTER TEXT SEARCH DICTIONARY changes the definition of a text search
       dictionary. You can change the dictionary's template-specific options,
       or change the dictionary's name or owner.

       You must be the owner of the dictionary to use ALTER TEXT SEARCH
       DICTIONARY.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing text search
           dictionary.
<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->
       option
           The name of a template-specific option to be set for this
           dictionary.

       value
           The new value to use for a template-specific option. If the equal
           sign and value are omitted, then any previous setting for the
           option is removed from the dictionary, allowing the default to be
           used.

       new_name
           The new name of the text search dictionary.

       new_owner
           The new owner of the text search dictionary.

       new_schema
           The new schema for the text search dictionary.

       Template-specific options can appear in any order.

EXAMPLES
       The following example command changes the stopword list for a
       Snowball-based dictionary. Other parameters remain unchanged.

           ALTER TEXT SEARCH DICTIONARY my_dict ( StopWords = newrussian );

       The following example command changes the language option to dutch, and
       removes the stopword option entirely.

           ALTER TEXT SEARCH DICTIONARY my_dict ( language = dutch, StopWords );

       The following example command "updates" the dictionary's definition
       without actually changing anything.

           ALTER TEXT SEARCH DICTIONARY my_dict ( dummy );

       (The reason this works is that the option removal code doesn't complain
       if there is no such option.) This trick is useful when changing
       configuration files for the dictionary: the ALTER will force existing
       database sessions to re-read the configuration files, which otherwise
       they would never do if they had read them earlier.

COMPATIBILITY
       There is no ALTER TEXT SEARCH DICTIONARY statement in the SQL standard.

SEE ALSO
       CREATE TEXT SEARCH DICTIONARY (CREATE_TEXT_SEARCH_DICTIONARY(7)), DROP
       TEXT SEARCH DICTIONARY (DROP_TEXT_SEARCH_DICTIONARY(7))



PostgreSQL 9.6.1                     2016      ALTER TEXT SEARCH DICTIONARY(7)
ALTER GROUP(7)          PostgreSQL 9.6.1 Documentation          ALTER GROUP(7)



NAME
       ALTER_GROUP - change role name or membership

SYNOPSIS
       ALTER GROUP role_specification ADD USER user_name [, ... ]
       ALTER GROUP role_specification DROP USER user_name [, ... ]

       where role_specification can be:

           role_name
         | CURRENT_USER
         | SESSION_USER

       ALTER GROUP group_name RENAME TO new_name

DESCRIPTION
       ALTER GROUP changes the attributes of a user group. This is an obsolete
       command, though still accepted for backwards compatibility, because
       groups (and users too) have been superseded by the more general concept
       of roles.

       The first two variants add users to a group or remove them from a
       group. (Any role can play the part of either a "user" or a "group" for
       this purpose.) These variants are effectively equivalent to granting or
       revoking membership in the role named as the "group"; so the preferred
       way to do this is to use GRANT(7) or REVOKE(7).

       The third variant changes the name of the group. This is exactly
       equivalent to renaming the role with ALTER ROLE (ALTER_ROLE(7)).

PARAMETERS
       group_name
           The name of the group (role) to modify.

       user_name
           Users (roles) that are to be added to or removed from the group.
           The users must already exist; ALTER GROUP does not create or drop
           users.

       new_name
           The new name of the group.

EXAMPLES
       Add users to a group:

           ALTER GROUP staff ADD USER karl, john;

       Remove a user from a group:

           ALTER GROUP workers DROP USER beth;

COMPATIBILITY
       There is no ALTER GROUP statement in the SQL standard.

SEE ALSO
       GRANT(7), REVOKE(7), ALTER ROLE (ALTER_ROLE(7))



PostgreSQL 9.6.1                     2016                       ALTER GROUP(7)
CREATE COLLATION(7)     PostgreSQL 9.6.1 Documentation     CREATE COLLATION(7)



NAME
       CREATE_COLLATION - define a new collation

SYNOPSIS
       CREATE COLLATION name (
           [ LOCALE = locale, ]
           [ LC_COLLATE = lc_collate, ]
           [ LC_CTYPE = lc_ctype ]
       )
       CREATE COLLATION name FROM existing_collation

DESCRIPTION
       CREATE COLLATION defines a new collation using the specified operating
       system locale settings, or by copying an existing collation.

       To be able to create a collation, you must have CREATE privilege on the
       destination schema.

PARAMETERS
       name
           The name of the collation. The collation name can be
           schema-qualified. If it is not, the collation is defined in the
           current schema. The collation name must be unique within that
           schema. (The system catalogs can contain collations with the same
           name for other encodings, but these are ignored if the database
           encoding does not match.)

       locale
           This is a shortcut for setting LC_COLLATE and LC_CTYPE at once. If
           you specify this, you cannot specify either of those parameters.

       lc_collate
           Use the specified operating system locale for the LC_COLLATE locale
           category. The locale must be applicable to the current database
           encoding. (See CREATE DATABASE (CREATE_DATABASE(7)) for the precise
           rules.)

       lc_ctype
           Use the specified operating system locale for the LC_CTYPE locale
           category. The locale must be applicable to the current database
           encoding. (See CREATE DATABASE (CREATE_DATABASE(7)) for the precise
           rules.)

       existing_collation
           The name of an existing collation to copy. The new collation will
           have the same properties as the existing one, but it will be an
           independent object.

NOTES
       Use DROP COLLATION to remove user-defined collations.

       See Section 23.2, "Collation Support", in the documentation for more
       information about collation support in PostgreSQL.

EXAMPLES
       To create a collation from the operating system locale fr_FR.utf8
       (assuming the current database encoding is UTF8):

           CREATE COLLATION french (LOCALE = 'fr_FR.utf8');

       To create a collation from an existing collation:

           CREATE COLLATION german FROM "de_DE";

       This can be convenient to be able to use operating-system-independent
       collation names in applications.

COMPATIBILITY
       There is a CREATE COLLATION statement in the SQL standard, but it is
       limited to copying an existing collation. The syntax to create a new
       collation is a PostgreSQL extension.

SEE ALSO
       ALTER COLLATION (ALTER_COLLATION(7)), DROP COLLATION
       (DROP_COLLATION(7))



PostgreSQL 9.6.1                     2016                  CREATE COLLATION(7)
CREATE GROUP(7)         PostgreSQL 9.6.1 Documentation         CREATE GROUP(7)



NAME
       CREATE_GROUP - define a new database role

SYNOPSIS
       CREATE GROUP name [ [ WITH ] option [ ... ] ]

       where option can be:

             SUPERUSER | NOSUPERUSER
           | CREATEDB | NOCREATEDB
           | CREATEROLE | NOCREATEROLE
           | INHERIT | NOINHERIT
           | LOGIN | NOLOGIN
           | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
           | VALID UNTIL 'timestamp'
           | IN ROLE role_name [, ...]
           | IN GROUP role_name [, ...]
           | ROLE role_name [, ...]
           | ADMIN role_name [, ...]
           | USER role_name [, ...]
           | SYSID uid

DESCRIPTION
       CREATE GROUP is now an alias for CREATE ROLE (CREATE_ROLE(7)).

COMPATIBILITY
       There is no CREATE GROUP statement in the SQL standard.

SEE ALSO
       CREATE ROLE (CREATE_ROLE(7))



PostgreSQL 9.6.1                     2016                      CREATE GROUP(7)
CREATE TABLE(7)         PostgreSQL 9.6.1 Documentation         CREATE TABLE(7)



NAME
       CREATE_TABLE - define a new table

SYNOPSIS
       CREATE [ [ GLOBAL | LOCAL ] { TEMPORARY | TEMP } | UNLOGGED ] TABLE [ IF NOT EXISTS ] table_name ( [
         { column_name data_type [ COLLATE collation ] [ column_constraint [ ... ] ]
           | table_constraint
           | LIKE source_table [ like_option ... ] }
           [, ... ]
       ] )
       [ INHERITS ( parent_table [, ... ] ) ]
       [ WITH ( storage_parameter [= value] [, ... ] ) | WITH OIDS | WITHOUT OIDS ]
       [ ON COMMIT { PRESERVE ROWS | DELETE ROWS | DROP } ]
       [ TABLESPACE tablespace_name ]

       CREATE [ [ GLOBAL | LOCAL ] { TEMPORARY | TEMP } | UNLOGGED ] TABLE [ IF NOT EXISTS ] table_name
           OF type_name [ (
         { column_name WITH OPTIONS [ column_constraint [ ... ] ]
           | table_constraint }
           [, ... ]
       ) ]
       [ WITH ( storage_parameter [= value] [, ... ] ) | WITH OIDS | WITHOUT OIDS ]
       [ ON COMMIT { PRESERVE ROWS | DELETE ROWS | DROP } ]
       [ TABLESPACE tablespace_name ]

       where column_constraint is:

       [ CONSTRAINT constraint_name ]
       { NOT NULL |
         NULL |
         CHECK ( expression ) [ NO INHERIT ] |
         DEFAULT default_expr |
         UNIQUE index_parameters |
         PRIMARY KEY index_parameters |
         REFERENCES reftable [ ( refcolumn ) ] [ MATCH FULL | MATCH PARTIAL | MATCH SIMPLE ]
           [ ON DELETE action ] [ ON UPDATE action ] }
       [ DEFERRABLE | NOT DEFERRABLE ] [ INITIALLY DEFERRED | INITIALLY IMMEDIATE ]

       and table_constraint is:

       [ CONSTRAINT constraint_name ]
       { CHECK ( expression ) [ NO INHERIT ] |
         UNIQUE ( column_name [, ... ] ) index_parameters |
         PRIMARY KEY ( column_name [, ... ] ) index_parameters |
         EXCLUDE [ USING index_method ] ( exclude_element WITH operator [, ... ] ) index_parameters [ WHERE ( predicate ) ] |
         FOREIGN KEY ( column_name [, ... ] ) REFERENCES reftable [ ( refcolumn [, ... ] ) ]
           [ MATCH FULL | MATCH PARTIAL | MATCH SIMPLE ] [ ON DELETE action ] [ ON UPDATE action ] }
       [ DEFERRABLE | NOT DEFERRABLE ] [ INITIALLY DEFERRED | INITIALLY IMMEDIATE ]

       and like_option is:

       { INCLUDING | EXCLUDING } { DEFAULTS | CONSTRAINTS | INDEXES | STORAGE | COMMENTS | ALL }

       index_parameters in UNIQUE, PRIMARY KEY, and EXCLUDE constraints are:

       [ WITH ( storage_parameter [= value] [, ... ] ) ]
       [ USING INDEX TABLESPACE tablespace_name ]

       exclude_element in an EXCLUDE constraint is:

       { column_name | ( expression ) } [ opclass ] [ ASC | DESC ] [ NULLS { FIRST | LAST } ]

DESCRIPTION
       CREATE TABLE will create a new, initially empty table in the current
       database. The table will be owned by the user issuing the command.

       If a schema name is given (for example, CREATE TABLE myschema.mytable
       ...) then the table is created in the specified schema. Otherwise it is
       created in the current schema. Temporary tables exist in a special
       schema, so a schema name cannot be given when creating a temporary
       table. The name of the table must be distinct from the name of any
       other table, sequence, index, view, or foreign table in the same
       schema.

       CREATE TABLE also automatically creates a data type that represents the
       composite type corresponding to one row of the table. Therefore, tables
       cannot have the same name as any existing data type in the same schema.

       The optional constraint clauses specify constraints (tests) that new or
       updated rows must satisfy for an insert or update operation to succeed.
       A constraint is an SQL object that helps define the set of valid values
       in the table in various ways.

       There are two ways to define constraints: table constraints and column
       constraints. A column constraint is defined as part of a column
       definition. A table constraint definition is not tied to a particular
       column, and it can encompass more than one column. Every column
       constraint can also be written as a table constraint; a column
       constraint is only a notational convenience for use when the constraint
       only affects one column.

       To be able to create a table, you must have USAGE privilege on all
       column types or the type in the OF clause, respectively.

PARAMETERS
       TEMPORARY or TEMP
           If specified, the table is created as a temporary table. Temporary
           tables are automatically dropped at the end of a session, or
           optionally at the end of the current transaction (see ON COMMIT
           below). Existing permanent tables with the same name are not
           visible to the current session while the temporary table exists,
           unless they are referenced with schema-qualified names. Any indexes
           created on a temporary table are automatically temporary as well.

           The autovacuum daemon cannot access and therefore cannot vacuum or
           analyze temporary tables. For this reason, appropriate vacuum and
           analyze operations should be performed via session SQL commands.
           For example, if a temporary table is going to be used in complex
           queries, it is wise to run ANALYZE on the temporary table after it
           is populated.

           Optionally, GLOBAL or LOCAL can be written before TEMPORARY or
           TEMP. This presently makes no difference in PostgreSQL and is
           deprecated; see COMPATIBILITY.

       UNLOGGED
           If specified, the table is created as an unlogged table. Data
           written to unlogged tables is not written to the write-ahead log
           (see Chapter 30, Reliability and the Write-Ahead Log, in the
           documentation), which makes them considerably faster than ordinary
           tables. However, they are not crash-safe: an unlogged table is
           automatically truncated after a crash or unclean shutdown. The
           contents of an unlogged table are also not replicated to standby
           servers. Any indexes created on an unlogged table are automatically
           unlogged as well.

<!-- c6acb2a0-d8a1-44cd-b054-cf74edbb706e <=< ACCEPT -->       IF NOT EXISTS
           Do not throw an error if a relation with the same name already
           exists. A notice is issued in this case. Note that there is no
           guarantee that the existing relation is anything like the one that
           would have been created.

       table_name
           The name (optionally schema-qualified) of the table to be created.
<!-- ACCEPT >=> c6acb2a0-d8a1-44cd-b054-cf74edbb706e -->
       OF type_name
           Creates a typed table, which takes its structure from the specified
           composite type (name optionally schema-qualified). A typed table is
           tied to its type; for example the table will be dropped if the type
           is dropped (with DROP TYPE ... CASCADE).

           When a typed table is created, then the data types of the columns
           are determined by the underlying composite type and are not
           specified by the CREATE TABLE command. But the CREATE TABLE command
           can add defaults and constraints to the table and can specify
           storage parameters.

<!-- 03dd7c3c-cec6-415e-9bd2-60cabe0e09e6 <=< ACCEPT -->       column_name
           The name of a column to be created in the new table.

       data_type
           The data type of the column. This can include array specifiers. For
           more information on the data types supported by PostgreSQL, refer
           to Chapter 8, Data Types, in the documentation.

       COLLATE collation
           The COLLATE clause assigns a collation to the column (which must be
           of a collatable data type). If not specified, the column data
           type's default collation is used.

       INHERITS ( parent_table [, ... ] )
           The optional INHERITS clause specifies a list of tables from which
           the new table automatically inherits all columns. Parent tables can
           be plain tables or foreign tables.<!-- ACCEPT >=> 03dd7c3c-cec6-415e-9bd2-60cabe0e09e6 -->

           Use of INHERITS creates a persistent relationship between the new
           child table and its parent table(s). Schema modifications to the
           parent(s) normally propagate to children as well, and by default
           the data of the child table is included in scans of the parent(s).

           If the same column name exists in more than one parent table, an
           error is reported unless the data types of the columns match in
           each of the parent tables. If there is no conflict, then the
           duplicate columns are merged to form a single column in the new
           table. If the column name list of the new table contains a column
           name that is also inherited, the data type must likewise match the
           inherited column(s), and the column definitions are merged into
           one. If the new table explicitly specifies a default value for the
           column, this default overrides any defaults from inherited
           declarations of the column. Otherwise, any parents that specify
           default values for the column must all specify the same default, or
           an error will be reported.

           CHECK constraints are merged in essentially the same way as
           columns: if multiple parent tables and/or the new table definition
           contain identically-named CHECK constraints, these constraints must
           all have the same check expression, or an error will be reported.
           Constraints having the same name and expression will be merged into
           one copy. A constraint marked NO INHERIT in a parent will not be
           considered. Notice that an unnamed CHECK constraint in the new
           table will never be merged, since a unique name will always be
           chosen for it.

           Column STORAGE settings are also copied from parent tables.

       LIKE source_table [ like_option ... ]
           The LIKE clause specifies a table from which the new table
           automatically copies all column names, their data types, and their
           not-null constraints.

           Unlike INHERITS, the new table and original table are completely
           decoupled after creation is complete. Changes to the original table
           will not be applied to the new table, and it is not possible to
           include data of the new table in scans of the original table.

           Default expressions for the copied column definitions will be
           copied only if INCLUDING DEFAULTS is specified. The default
           behavior is to exclude default expressions, resulting in the copied
           columns in the new table having null defaults. Note that copying
           defaults that call database-modification functions, such as
           nextval, may create a functional linkage between the original and
           new tables.

           Not-null constraints are always copied to the new table.  CHECK
           constraints will be copied only if INCLUDING CONSTRAINTS is
           specified. No distinction is made between column constraints and
           table constraints.

           Indexes, PRIMARY KEY, UNIQUE, and EXCLUDE constraints on the
           original table will be created on the new table only if INCLUDING
           INDEXES is specified. Names for the new indexes and constraints are
           chosen according to the default rules, regardless of how the
           originals were named. (This behavior avoids possible duplicate-name
           failures for the new indexes.)

           STORAGE settings for the copied column definitions will be copied
           only if INCLUDING STORAGE is specified. The default behavior is to
           exclude STORAGE settings, resulting in the copied columns in the
           new table having type-specific default settings. For more on
           STORAGE settings, see Section 65.2, "TOAST", in the documentation.

           Comments for the copied columns, constraints, and indexes will be
           copied only if INCLUDING COMMENTS is specified. The default
           behavior is to exclude comments, resulting in the copied columns
           and constraints in the new table having no comments.

           INCLUDING ALL is an abbreviated form of INCLUDING DEFAULTS
           INCLUDING CONSTRAINTS INCLUDING INDEXES INCLUDING STORAGE INCLUDING
           COMMENTS.

           Note that unlike INHERITS, columns and constraints copied by LIKE
           are not merged with similarly named columns and constraints. If the
           same name is specified explicitly or in another LIKE clause, an
           error is signaled.

           The LIKE clause can also be used to copy column definitions from
           views, foreign tables, or composite types. Inapplicable options
           (e.g., INCLUDING INDEXES from a view) are ignored.

<!-- 83d0f615-1ce7-4189-9231-c298168f3608 <=< ACCEPT -->       CONSTRAINT constraint_name
           An optional name for a column or table constraint. If the
           constraint is violated, the constraint name is present in error
           messages, so constraint names like col must be positive can be used
           to communicate helpful constraint information to client
           applications. (Double-quotes are needed to specify constraint names
           that contain spaces.) If a constraint name is not specified, the
           system generates a name.

       NOT NULL
           The column is not allowed to contain null values.

       NULL
           The column is allowed to contain null values. This is the default.

           This clause is only provided for compatibility with non-standard
           SQL databases. Its use is discouraged in new applications.

       CHECK ( expression ) [ NO INHERIT ]
           The CHECK clause specifies an expression producing a Boolean result
           which new or updated rows must satisfy for an insert or update
           operation to succeed. Expressions evaluating to TRUE or UNKNOWN
           succeed. Should any row of an insert or update operation produce a
           FALSE result, an error exception is raised and the insert or update
           does not alter the database. A check constraint specified as a
           column constraint should reference that column's value only, while
           an expression appearing in a table constraint can reference
           multiple columns.

           Currently, CHECK expressions cannot contain subqueries nor refer to
           variables other than columns of the current row. The system column
           tableoid may be referenced, but not any other system column.
<!-- ACCEPT >=> 83d0f615-1ce7-4189-9231-c298168f3608 -->
           A constraint marked with NO INHERIT will not propagate to child
           tables.

           When a table has multiple CHECK constraints, they will be tested
           for each row in alphabetical order by name, after checking NOT NULL
           constraints. (PostgreSQL versions before 9.5 did not honor any
           particular firing order for CHECK constraints.)

<!-- a91e8e3e-cfc3-46e2-bb0f-77bd6c82afbe <=< ACCEPT -->       DEFAULT default_expr
           The DEFAULT clause assigns a default data value for the column
           whose column definition it appears within. The value is any
           variable-free expression (subqueries and cross-references to other
           columns in the current table are not allowed). The data type of the
           default expression must match the data type of the column.

           The default expression will be used in any insert operation that
           does not specify a value for the column. If there is no default for
           a column, then the default is null.<!-- ACCEPT >=> a91e8e3e-cfc3-46e2-bb0f-77bd6c82afbe -->

       UNIQUE (column constraint)
       UNIQUE ( column_name [, ... ] ) (table constraint)
           The UNIQUE constraint specifies that a group of one or more columns
           of a table can contain only unique values. The behavior of the
           unique table constraint is the same as that for column constraints,
           with the additional capability to span multiple columns.

           For the purpose of a unique constraint, null values are not
           considered equal.

           Each unique table constraint must name a set of columns that is
           different from the set of columns named by any other unique or
           primary key constraint defined for the table. (Otherwise it would
           just be the same constraint listed twice.)

       PRIMARY KEY (column constraint)
       PRIMARY KEY ( column_name [, ... ] ) (table constraint)
           The PRIMARY KEY constraint specifies that a column or columns of a
           table can contain only unique (non-duplicate), nonnull values. Only
           one primary key can be specified for a table, whether as a column
           constraint or a table constraint.

           The primary key constraint should name a set of columns that is
           different from the set of columns named by any unique constraint
           defined for the same table. (Otherwise, the unique constraint is
           redundant and will be discarded.)

           PRIMARY KEY enforces the same data constraints as a combination of
           UNIQUE and NOT NULL, but identifying a set of columns as the
           primary key also provides metadata about the design of the schema,
           since a primary key implies that other tables can rely on this set
           of columns as a unique identifier for rows.

       EXCLUDE [ USING index_method ] ( exclude_element WITH operator [, ... ]
       ) index_parameters [ WHERE ( predicate ) ]
           The EXCLUDE clause defines an exclusion constraint, which
           guarantees that if any two rows are compared on the specified
           column(s) or expression(s) using the specified operator(s), not all
           of these comparisons will return TRUE. If all of the specified
           operators test for equality, this is equivalent to a UNIQUE
           constraint, although an ordinary unique constraint will be faster.
           However, exclusion constraints can specify constraints that are
           more general than simple equality. For example, you can specify a
           constraint that no two rows in the table contain overlapping
           circles (see Section 8.8, "Geometric Types", in the documentation)
           by using the &amp;&amp; operator.

           Exclusion constraints are implemented using an index, so each
           specified operator must be associated with an appropriate operator
           class (see Section 11.9, "Operator Classes and Operator Families",
           in the documentation) for the index access method index_method. The
           operators are required to be commutative. Each exclude_element can
           optionally specify an operator class and/or ordering options; these
           are described fully under CREATE INDEX (CREATE_INDEX(7)).

           The access method must support amgettuple (see Chapter 59, Index
           Access Method Interface Definition, in the documentation); at
           present this means GIN cannot be used. Although it's allowed, there
           is little point in using B-tree or hash indexes with an exclusion
           constraint, because this does nothing that an ordinary unique
           constraint doesn't do better. So in practice the access method will
           always be GiST or SP-GiST.

           The predicate allows you to specify an exclusion constraint on a
           subset of the table; internally this creates a partial index. Note
           that parentheses are required around the predicate.

       REFERENCES reftable [ ( refcolumn ) ] [ MATCH matchtype ] [ ON DELETE
       action ] [ ON UPDATE action ] (column constraint)
       FOREIGN KEY ( column_name [, ... ] ) REFERENCES reftable [ ( refcolumn
       [, ... ] ) ] [ MATCH matchtype ] [ ON DELETE action ] [ ON UPDATE
       action ] (table constraint)
           These clauses specify a foreign key constraint, which requires that
           a group of one or more columns of the new table must only contain
           values that match values in the referenced column(s) of some row of
           the referenced table. If the refcolumn list is omitted, the primary
           key of the reftable is used. The referenced columns must be the
           columns of a non-deferrable unique or primary key constraint in the
           referenced table. Note that foreign key constraints cannot be
           defined between temporary tables and permanent tables.

           A value inserted into the referencing column(s) is matched against
           the values of the referenced table and referenced columns using the
           given match type. There are three match types: MATCH FULL, MATCH
           PARTIAL, and MATCH SIMPLE (which is the default).  MATCH FULL will
           not allow one column of a multicolumn foreign key to be null unless
           all foreign key columns are null; if they are all null, the row is
           not required to have a match in the referenced table.  MATCH SIMPLE
           allows any of the foreign key columns to be null; if any of them
           are null, the row is not required to have a match in the referenced
           table.  MATCH PARTIAL is not yet implemented. (Of course, NOT NULL
           constraints can be applied to the referencing column(s) to prevent
           these cases from arising.)

           In addition, when the data in the referenced columns is changed,
           certain actions are performed on the data in this table's columns.
           The ON DELETE clause specifies the action to perform when a
           referenced row in the referenced table is being deleted. Likewise,
           the ON UPDATE clause specifies the action to perform when a
           referenced column in the referenced table is being updated to a new
           value. If the row is updated, but the referenced column is not
           actually changed, no action is done. Referential actions other than
           the NO ACTION check cannot be deferred, even if the constraint is
           declared deferrable. There are the following possible actions for
           each clause:

           NO ACTION
               Produce an error indicating that the deletion or update would
               create a foreign key constraint violation. If the constraint is
               deferred, this error will be produced at constraint check time
               if there still exist any referencing rows. This is the default
               action.

           RESTRICT
               Produce an error indicating that the deletion or update would
               create a foreign key constraint violation. This is the same as
               NO ACTION except that the check is not deferrable.

           CASCADE
               Delete any rows referencing the deleted row, or update the
               values of the referencing column(s) to the new values of the
               referenced columns, respectively.

           SET NULL
               Set the referencing column(s) to null.

           SET DEFAULT
               Set the referencing column(s) to their default values. (There
               must be a row in the referenced table matching the default
               values, if they are not null, or the operation will fail.)

           If the referenced column(s) are changed frequently, it might be
           wise to add an index to the referencing column(s) so that
           referential actions associated with the foreign key constraint can
           be performed more efficiently.

       DEFERRABLE
       NOT DEFERRABLE
           This controls whether the constraint can be deferred. A constraint
           that is not deferrable will be checked immediately after every
           command. Checking of constraints that are deferrable can be
           postponed until the end of the transaction (using the SET
           CONSTRAINTS (SET_CONSTRAINTS(7)) command).  NOT DEFERRABLE is the
           default. Currently, only UNIQUE, PRIMARY KEY, EXCLUDE, and
           REFERENCES (foreign key) constraints accept this clause.  NOT NULL
           and CHECK constraints are not deferrable. Note that deferrable
           constraints cannot be used as conflict arbitrators in an INSERT
           statement that includes an ON CONFLICT DO UPDATE clause.

       INITIALLY IMMEDIATE
       INITIALLY DEFERRED
           If a constraint is deferrable, this clause specifies the default
           time to check the constraint. If the constraint is INITIALLY
           IMMEDIATE, it is checked after each statement. This is the default.
           If the constraint is INITIALLY DEFERRED, it is checked only at the
           end of the transaction. The constraint check time can be altered
           with the SET CONSTRAINTS (SET_CONSTRAINTS(7)) command.

       WITH ( storage_parameter [= value] [, ... ] )
           This clause specifies optional storage parameters for a table or
           index; see Storage Parameters for more information. The WITH clause
           for a table can also include OIDS=TRUE (or just OIDS) to specify
           that rows of the new table should have OIDs (object identifiers)
           assigned to them, or OIDS=FALSE to specify that the rows should not
           have OIDs. If OIDS is not specified, the default setting depends
           upon the default_with_oids configuration parameter. (If the new
           table inherits from any tables that have OIDs, then OIDS=TRUE is
           forced even if the command says OIDS=FALSE.)

           If OIDS=FALSE is specified or implied, the new table does not store
           OIDs and no OID will be assigned for a row inserted into it. This
           is generally considered worthwhile, since it will reduce OID
           consumption and thereby postpone the wraparound of the 32-bit OID
           counter. Once the counter wraps around, OIDs can no longer be
           assumed to be unique, which makes them considerably less useful. In
           addition, excluding OIDs from a table reduces the space required to
           store the table on disk by 4 bytes per row (on most machines),
           slightly improving performance.

           To remove OIDs from a table after it has been created, use ALTER
           TABLE (ALTER_TABLE(7)).

<!-- 1882732d-ffcd-4a0a-a937-5764449f0507 <=< ACCEPT -->       WITH OIDS
       WITHOUT OIDS
           These are obsolescent syntaxes equivalent to WITH (OIDS) and WITH
           (OIDS=FALSE), respectively. If you wish to give both an OIDS
           setting and storage parameters, you must use the WITH ( ... )
           syntax; see above.

       ON COMMIT
           The behavior of temporary tables at the end of a transaction block
           can be controlled using ON COMMIT. The three options are:

           PRESERVE ROWS
               No special action is taken at the ends of transactions. This is
               the default behavior.

           DELETE ROWS
               All rows in the temporary table will be deleted at the end of
               each transaction block. Essentially, an automatic TRUNCATE(7)
               is done at each commit.

           DROP
               The temporary table will be dropped at the end of the current
               transaction block.

       TABLESPACE tablespace_name
           The tablespace_name is the name of the tablespace in which the new
           table is to be created. If not specified, default_tablespace is
           consulted, or temp_tablespaces if the table is temporary.<!-- ACCEPT >=> 1882732d-ffcd-4a0a-a937-5764449f0507 -->

       USING INDEX TABLESPACE tablespace_name
           This clause allows selection of the tablespace in which the index
           associated with a UNIQUE, PRIMARY KEY, or EXCLUDE constraint will
           be created. If not specified, default_tablespace is consulted, or
           temp_tablespaces if the table is temporary.

   Storage Parameters
       The WITH clause can specify storage parameters for tables, and for
       indexes associated with a UNIQUE, PRIMARY KEY, or EXCLUDE constraint.
       Storage parameters for indexes are documented in CREATE INDEX
       (CREATE_INDEX(7)). The storage parameters currently available for
       tables are listed below. For many of these parameters, as shown, there
       is an additional parameter with the same name prefixed with toast.,
       which controls the behavior of the table's secondary TOAST table, if
       any (see Section 65.2, "TOAST", in the documentation for more
       information about TOAST). If a table parameter value is set and the
       equivalent toast.  parameter is not, the TOAST table will use the
       table's parameter value.

       fillfactor (integer)
           The fillfactor for a table is a percentage between 10 and 100. 100
           (complete packing) is the default. When a smaller fillfactor is
           specified, INSERT operations pack table pages only to the indicated
           percentage; the remaining space on each page is reserved for
           updating rows on that page. This gives UPDATE a chance to place the
           updated copy of a row on the same page as the original, which is
           more efficient than placing it on a different page. For a table
           whose entries are never updated, complete packing is the best
           choice, but in heavily updated tables smaller fillfactors are
           appropriate. This parameter cannot be set for TOAST tables.

       parallel_workers (integer)
           This sets the number of workers that should be used to assist a
           parallel scan of this table. If not set, the system will determine
           a value based on the relation size. The actual number of workers
           chosen by the planner may be less, for example due to the setting
           of max_worker_processes.

       autovacuum_enabled, toast.autovacuum_enabled (boolean)
           Enables or disables the autovacuum daemon for a particular table.
           If true, the autovacuum daemon will perform automatic VACUUM and/or
           ANALYZE operations on this table following the rules discussed in
           Section 24.1.6, "The Autovacuum Daemon", in the documentation. If
           false, this table will not be autovacuumed, except to prevent
           transaction ID wraparound. See Section 24.1.5, "Preventing
           Transaction ID Wraparound Failures", in the documentation for more
           about wraparound prevention. Note that the autovacuum daemon does
           not run at all (except to prevent transaction ID wraparound) if the
           autovacuum parameter is false; setting individual tables' storage
           parameters does not override that. Therefore there is seldom much
           point in explicitly setting this storage parameter to true, only to
           false.

       autovacuum_vacuum_threshold, toast.autovacuum_vacuum_threshold
       (integer)
           Per-table value for autovacuum_vacuum_threshold parameter.

       autovacuum_vacuum_scale_factor, toast.autovacuum_vacuum_scale_factor
       (float4)
           Per-table value for autovacuum_vacuum_scale_factor parameter.

       autovacuum_analyze_threshold (integer)
           Per-table value for autovacuum_analyze_threshold parameter.

       autovacuum_analyze_scale_factor (float4)
           Per-table value for autovacuum_analyze_scale_factor parameter.

       autovacuum_vacuum_cost_delay, toast.autovacuum_vacuum_cost_delay
       (integer)
           Per-table value for autovacuum_vacuum_cost_delay parameter.

       autovacuum_vacuum_cost_limit, toast.autovacuum_vacuum_cost_limit
       (integer)
           Per-table value for autovacuum_vacuum_cost_limit parameter.

       autovacuum_freeze_min_age, toast.autovacuum_freeze_min_age (integer)
           Per-table value for vacuum_freeze_min_age parameter. Note that
           autovacuum will ignore per-table autovacuum_freeze_min_age
           parameters that are larger than half the system-wide
           autovacuum_freeze_max_age setting.

       autovacuum_freeze_max_age, toast.autovacuum_freeze_max_age (integer)
           Per-table value for autovacuum_freeze_max_age parameter. Note that
           autovacuum will ignore per-table autovacuum_freeze_max_age
           parameters that are larger than the system-wide setting (it can
           only be set smaller).

       autovacuum_freeze_table_age, toast.autovacuum_freeze_table_age
       (integer)
           Per-table value for vacuum_freeze_table_age parameter.

       autovacuum_multixact_freeze_min_age,
       toast.autovacuum_multixact_freeze_min_age (integer)
           Per-table value for vacuum_multixact_freeze_min_age parameter. Note
           that autovacuum will ignore per-table
           autovacuum_multixact_freeze_min_age parameters that are larger than
           half the system-wide autovacuum_multixact_freeze_max_age setting.

       autovacuum_multixact_freeze_max_age,
       toast.autovacuum_multixact_freeze_max_age (integer)
           Per-table value for autovacuum_multixact_freeze_max_age parameter.
           Note that autovacuum will ignore per-table
           autovacuum_multixact_freeze_max_age parameters that are larger than
           the system-wide setting (it can only be set smaller).

       autovacuum_multixact_freeze_table_age,
       toast.autovacuum_multixact_freeze_table_age (integer)
           Per-table value for vacuum_multixact_freeze_table_age parameter.

       log_autovacuum_min_duration, toast.log_autovacuum_min_duration
       (integer)
           Per-table value for log_autovacuum_min_duration parameter.

       user_catalog_table (boolean)
           Declare the table as an additional catalog table for purposes of
           logical replication. See Section 47.6.2, "Capabilities", in the
           documentation for details. This parameter cannot be set for TOAST
           tables.

NOTES
       Using OIDs in new applications is not recommended: where possible,
       using a SERIAL or other sequence generator as the table's primary key
       is preferred. However, if your application does make use of OIDs to
       identify specific rows of a table, it is recommended to create a unique
       constraint on the oid column of that table, to ensure that OIDs in the
       table will indeed uniquely identify rows even after counter wraparound.
       Avoid assuming that OIDs are unique across tables; if you need a
       database-wide unique identifier, use the combination of tableoid and
       row OID for the purpose.

           Tip
           The use of OIDS=FALSE is not recommended for tables with no primary
           key, since without either an OID or a unique data key, it is
           difficult to identify specific rows.

       PostgreSQL automatically creates an index for each unique constraint
       and primary key constraint to enforce uniqueness. Thus, it is not
       necessary to create an index explicitly for primary key columns. (See
       CREATE INDEX (CREATE_INDEX(7)) for more information.)

       Unique constraints and primary keys are not inherited in the current
       implementation. This makes the combination of inheritance and unique
       constraints rather dysfunctional.

       A table cannot have more than 1600 columns. (In practice, the effective
       limit is usually lower because of tuple-length constraints.)

EXAMPLES
       Create table films and table distributors:

           CREATE TABLE films (
               code        char(5) CONSTRAINT firstkey PRIMARY KEY,
               title       varchar(40) NOT NULL,
               did         integer NOT NULL,
               date_prod   date,
               kind        varchar(10),
               len         interval hour to minute
           );

           CREATE TABLE distributors (
                did    integer PRIMARY KEY DEFAULT nextval('serial'),
                name   varchar(40) NOT NULL CHECK (name &amp;lt;&amp;gt; '')
           );

       Create a table with a 2-dimensional array:

           CREATE TABLE array_int (
               vector  int[][]
           );

       Define a unique table constraint for the table films. Unique table
       constraints can be defined on one or more columns of the table:

           CREATE TABLE films (
               code        char(5),
               title       varchar(40),
               did         integer,
               date_prod   date,
               kind        varchar(10),
               len         interval hour to minute,
               CONSTRAINT production UNIQUE(date_prod)
           );

       Define a check column constraint:

           CREATE TABLE distributors (
               did     integer CHECK (did &amp;gt; 100),
               name    varchar(40)
           );

       Define a check table constraint:

           CREATE TABLE distributors (
               did     integer,
               name    varchar(40)
               CONSTRAINT con1 CHECK (did &amp;gt; 100 AND name &amp;lt;&amp;gt; '')
           );

       Define a primary key table constraint for the table films:

           CREATE TABLE films (
               code        char(5),
               title       varchar(40),
               did         integer,
               date_prod   date,
               kind        varchar(10),
               len         interval hour to minute,
               CONSTRAINT code_title PRIMARY KEY(code,title)
           );

       Define a primary key constraint for table distributors. The following
       two examples are equivalent, the first using the table constraint
       syntax, the second the column constraint syntax:

           CREATE TABLE distributors (
               did     integer,
               name    varchar(40),
               PRIMARY KEY(did)
           );

           CREATE TABLE distributors (
               did     integer PRIMARY KEY,
               name    varchar(40)
           );

       Assign a literal constant default value for the column name, arrange
       for the default value of column did to be generated by selecting the
       next value of a sequence object, and make the default value of modtime
       be the time at which the row is inserted:

           CREATE TABLE distributors (
               name      varchar(40) DEFAULT 'Luso Films',
               did       integer DEFAULT nextval('distributors_serial'),
               modtime   timestamp DEFAULT current_timestamp
           );

       Define two NOT NULL column constraints on the table distributors, one
       of which is explicitly given a name:

           CREATE TABLE distributors (
               did     integer CONSTRAINT no_null NOT NULL,
               name    varchar(40) NOT NULL
           );

       Define a unique constraint for the name column:

           CREATE TABLE distributors (
               did     integer,
               name    varchar(40) UNIQUE
           );

       The same, specified as a table constraint:

           CREATE TABLE distributors (
               did     integer,
               name    varchar(40),
               UNIQUE(name)
           );

       Create the same table, specifying 70% fill factor for both the table
       and its unique index:

           CREATE TABLE distributors (
               did     integer,
               name    varchar(40),
               UNIQUE(name) WITH (fillfactor=70)
           )
           WITH (fillfactor=70);

       Create table circles with an exclusion constraint that prevents any two
       circles from overlapping:

           CREATE TABLE circles (
               c circle,
               EXCLUDE USING gist (c WITH &amp;&amp;)
           );

       Create table cinemas in tablespace diskvol1:

           CREATE TABLE cinemas (
                   id serial,
                   name text,
                   location text
           ) TABLESPACE diskvol1;

       Create a composite type and a typed table:

           CREATE TYPE employee_type AS (name text, salary numeric);

           CREATE TABLE employees OF employee_type (
               PRIMARY KEY (name),
               salary WITH OPTIONS DEFAULT 1000
           );

COMPATIBILITY
       The CREATE TABLE command conforms to the SQL standard, with exceptions
       listed below.

   Temporary Tables
       Although the syntax of CREATE TEMPORARY TABLE resembles that of the SQL
       standard, the effect is not the same. In the standard, temporary tables
       are defined just once and automatically exist (starting with empty
       contents) in every session that needs them.  PostgreSQL instead
       requires each session to issue its own CREATE TEMPORARY TABLE command
       for each temporary table to be used. This allows different sessions to
       use the same temporary table name for different purposes, whereas the
       standard's approach constrains all instances of a given temporary table
       name to have the same table structure.

       The standard's definition of the behavior of temporary tables is widely
       ignored.  PostgreSQL's behavior on this point is similar to that of
       several other SQL databases.

       The SQL standard also distinguishes between global and local temporary
       tables, where a local temporary table has a separate set of contents
       for each SQL module within each session, though its definition is still
       shared across sessions. Since PostgreSQL does not support SQL modules,
       this distinction is not relevant in PostgreSQL.

       For compatibility's sake, PostgreSQL will accept the GLOBAL and LOCAL
       keywords in a temporary table declaration, but they currently have no
       effect. Use of these keywords is discouraged, since future versions of
       PostgreSQL might adopt a more standard-compliant interpretation of
       their meaning.

       The ON COMMIT clause for temporary tables also resembles the SQL
       standard, but has some differences. If the ON COMMIT clause is omitted,
       SQL specifies that the default behavior is ON COMMIT DELETE ROWS.
       However, the default behavior in PostgreSQL is ON COMMIT PRESERVE ROWS.
       The ON COMMIT DROP option does not exist in SQL.

   Non-deferred Uniqueness Constraints
       When a UNIQUE or PRIMARY KEY constraint is not deferrable, PostgreSQL
       checks for uniqueness immediately whenever a row is inserted or
       modified. The SQL standard says that uniqueness should be enforced only
       at the end of the statement; this makes a difference when, for example,
       a single command updates multiple key values. To obtain
       standard-compliant behavior, declare the constraint as DEFERRABLE but
       not deferred (i.e., INITIALLY IMMEDIATE). Be aware that this can be
       significantly slower than immediate uniqueness checking.

   Column Check Constraints
       The SQL standard says that CHECK column constraints can only refer to
       the column they apply to; only CHECK table constraints can refer to
       multiple columns.  PostgreSQL does not enforce this restriction; it
       treats column and table check constraints alike.

   EXCLUDE Constraint
       The EXCLUDE constraint type is a PostgreSQL extension.

   NULL "Constraint"
       The NULL"constraint" (actually a non-constraint) is a PostgreSQL
       extension to the SQL standard that is included for compatibility with
       some other database systems (and for symmetry with the NOT NULL
       constraint). Since it is the default for any column, its presence is
       simply noise.

   Inheritance
       Multiple inheritance via the INHERITS clause is a PostgreSQL language
       extension. SQL:1999 and later define single inheritance using a
       different syntax and different semantics. SQL:1999-style inheritance is
       not yet supported by PostgreSQL.

   Zero-column Tables
       PostgreSQL allows a table of no columns to be created (for example,
       CREATE TABLE foo();). This is an extension from the SQL standard, which
       does not allow zero-column tables. Zero-column tables are not in
       themselves very useful, but disallowing them creates odd special cases
       for ALTER TABLE DROP COLUMN, so it seems cleaner to ignore this spec
       restriction.

   LIKE Clause
       While a LIKE clause exists in the SQL standard, many of the options
       that PostgreSQL accepts for it are not in the standard, and some of the
       standard's options are not implemented by PostgreSQL.

   WITH Clause
       The WITH clause is a PostgreSQL extension; neither storage parameters
       nor OIDs are in the standard.

   Tablespaces
       The PostgreSQL concept of tablespaces is not part of the standard.
       Hence, the clauses TABLESPACE and USING INDEX TABLESPACE are
       extensions.

   Typed Tables
       Typed tables implement a subset of the SQL standard. According to the
       standard, a typed table has columns corresponding to the underlying
       composite type as well as one other column that is the
       "self-referencing column". PostgreSQL does not support these
       self-referencing columns explicitly, but the same effect can be had
       using the OID feature.

SEE ALSO
       ALTER TABLE (ALTER_TABLE(7)), DROP TABLE (DROP_TABLE(7)), CREATE TABLE
       AS (CREATE_TABLE_AS(7)), CREATE TABLESPACE (CREATE_TABLESPACE(7)),
       CREATE TYPE (CREATE_TYPE(7))



PostgreSQL 9.6.1                     2016                      CREATE TABLE(7)
ALTER FUNCTION(7)       PostgreSQL 9.6.1 Documentation       ALTER FUNCTION(7)



NAME
       ALTER_FUNCTION - change the definition of a function

SYNOPSIS
       ALTER FUNCTION name ( [ [ argmode ] [ argname ] argtype [, ...] ] )
           action [ ... ] [ RESTRICT ]
       ALTER FUNCTION name ( [ [ argmode ] [ argname ] argtype [, ...] ] )
           RENAME TO new_name
       ALTER FUNCTION name ( [ [ argmode ] [ argname ] argtype [, ...] ] )
           OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER FUNCTION name ( [ [ argmode ] [ argname ] argtype [, ...] ] )
           SET SCHEMA new_schema
       ALTER FUNCTION name ( [ [ argmode ] [ argname ] argtype [, ...] ] )
           DEPENDS ON EXTENSION extension_name

       where action is one of:

           CALLED ON NULL INPUT | RETURNS NULL ON NULL INPUT | STRICT
           IMMUTABLE | STABLE | VOLATILE | [ NOT ] LEAKPROOF
           [ EXTERNAL ] SECURITY INVOKER | [ EXTERNAL ] SECURITY DEFINER
           PARALLEL { UNSAFE | RESTRICTED | SAFE }
           COST execution_cost
           ROWS result_rows
           SET configuration_parameter { TO | = } { value | DEFAULT }
           SET configuration_parameter FROM CURRENT
           RESET configuration_parameter
           RESET ALL

DESCRIPTION
       ALTER FUNCTION changes the definition of a function.

<!-- ad137a5f-7fa1-4b53-a38d-4827f1ccde6e <=< ACCEPT -->       You must own the function to use ALTER FUNCTION. To change a function's
       schema, you must also have CREATE privilege on the new schema. To alter
       the owner, you must also be a direct or indirect member of the new
       owning role, and that role must have CREATE privilege on the function's
       schema. (These restrictions enforce that altering the owner doesn't do
       anything you couldn't do by dropping and recreating the function.
       However, a superuser can alter ownership of any function anyway.)<!-- ACCEPT >=> ad137a5f-7fa1-4b53-a38d-4827f1ccde6e -->

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing function.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

<!-- e966425d-370d-4dbd-b6cc-15b15457e983 <=< ACCEPT -->       argmode
           The mode of an argument: IN, OUT, INOUT, or VARIADIC. If omitted,
           the default is IN. Note that ALTER FUNCTION does not actually pay
           any attention to OUT arguments, since only the input arguments are
           needed to determine the function's identity. So it is sufficient to
           list the IN, INOUT, and VARIADIC arguments.

       argname
           The name of an argument. Note that ALTER FUNCTION does not actually
           pay any attention to argument names, since only the argument data
           types are needed to determine the function's identity.

       argtype
           The data type(s) of the function's arguments (optionally
           schema-qualified), if any.<!-- ACCEPT >=> e966425d-370d-4dbd-b6cc-15b15457e983 -->

       new_name
           The new name of the function.

       new_owner
           The new owner of the function. Note that if the function is marked
           SECURITY DEFINER, it will subsequently execute as the new owner.

       new_schema
           The new schema for the function.

       extension_name
           The name of the extension that the function is to depend on.

       CALLED ON NULL INPUT
       RETURNS NULL ON NULL INPUT
       STRICT
           CALLED ON NULL INPUT changes the function so that it will be
           invoked when some or all of its arguments are null.  RETURNS NULL
           ON NULL INPUT or STRICT changes the function so that it is not
           invoked if any of its arguments are null; instead, a null result is
           assumed automatically. See CREATE FUNCTION (CREATE_FUNCTION(7)) for
           more information.

       IMMUTABLE
       STABLE
       VOLATILE
           Change the volatility of the function to the specified setting. See
           CREATE FUNCTION (CREATE_FUNCTION(7)) for details.

       [ EXTERNAL ] SECURITY INVOKER
       [ EXTERNAL ] SECURITY DEFINER
           Change whether the function is a security definer or not. The key
           word EXTERNAL is ignored for SQL conformance. See CREATE FUNCTION
           (CREATE_FUNCTION(7)) for more information about this capability.

       PARALLEL
           Change whether the function is deemed safe for parallelism. See
           CREATE FUNCTION (CREATE_FUNCTION(7)) for details.

       LEAKPROOF
           Change whether the function is considered leakproof or not. See
           CREATE FUNCTION (CREATE_FUNCTION(7)) for more information about
           this capability.

       COST execution_cost
           Change the estimated execution cost of the function. See CREATE
           FUNCTION (CREATE_FUNCTION(7)) for more information.

       ROWS result_rows
           Change the estimated number of rows returned by a set-returning
           function. See CREATE FUNCTION (CREATE_FUNCTION(7)) for more
           information.

       configuration_parameter
       value
           Add or change the assignment to be made to a configuration
           parameter when the function is called. If value is DEFAULT or,
           equivalently, RESET is used, the function-local setting is removed,
           so that the function executes with the value present in its
           environment. Use RESET ALL to clear all function-local settings.
           SET FROM CURRENT saves the value of the parameter that is current
           when ALTER FUNCTION is executed as the value to be applied when the
           function is entered.

           See SET(7) and Chapter 19, Server Configuration, in the
           documentation for more information about allowed parameter names
           and values.

       RESTRICT
           Ignored for conformance with the SQL standard.

EXAMPLES
       To rename the function sqrt for type integer to square_root:

           ALTER FUNCTION sqrt(integer) RENAME TO square_root;

       To change the owner of the function sqrt for type integer to joe:

           ALTER FUNCTION sqrt(integer) OWNER TO joe;

       To change the schema of the function sqrt for type integer to maths:

           ALTER FUNCTION sqrt(integer) SET SCHEMA maths;

       To mark the function sqrt for type integer as being dependent on the
       extension mathlib:

           ALTER FUNCTION sqrt(integer) DEPENDS ON EXTENSION mathlib;

       To adjust the search path that is automatically set for a function:

           ALTER FUNCTION check_password(text) SET search_path = admin, pg_temp;

       To disable automatic setting of search_path for a function:

           ALTER FUNCTION check_password(text) RESET search_path;

       The function will now execute with whatever search path is used by its
       caller.

COMPATIBILITY
       This statement is partially compatible with the ALTER FUNCTION
       statement in the SQL standard. The standard allows more properties of a
       function to be modified, but does not provide the ability to rename a
       function, make a function a security definer, attach configuration
       parameter values to a function, or change the owner, schema, or
       volatility of a function. The standard also requires the RESTRICT key
       word, which is optional in PostgreSQL.

SEE ALSO
       CREATE FUNCTION (CREATE_FUNCTION(7)), DROP FUNCTION (DROP_FUNCTION(7))



PostgreSQL 9.6.1                     2016                    ALTER FUNCTION(7)
SELECT INTO(7)          PostgreSQL 9.6.1 Documentation          SELECT INTO(7)



NAME
       SELECT_INTO - define a new table from the results of a query

<!-- 10920879-62f7-43a7-9948-f2c56af2ce2c <=< ACCEPT -->SYNOPSIS
       [ WITH [ RECURSIVE ] with_query [, ...] ]
       SELECT [ ALL | DISTINCT [ ON ( expression [, ...] ) ] ]
           * | expression [ [ AS ] output_name ] [, ...]
           INTO [ TEMPORARY | TEMP | UNLOGGED ] [ TABLE ] new_table
           [ FROM from_item [, ...] ]
           [ WHERE condition ]
           [ GROUP BY expression [, ...] ]
           [ HAVING condition [, ...] ]
           [ WINDOW window_name AS ( window_definition ) [, ...] ]
           [ { UNION | INTERSECT | EXCEPT } [ ALL | DISTINCT ] select ]
           [ ORDER BY expression [ ASC | DESC | USING operator ] [ NULLS { FIRST | LAST } ] [, ...] ]
           [ LIMIT { count | ALL } ]
           [ OFFSET start [ ROW | ROWS ] ]
           [ FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } ONLY ]
           [ FOR { UPDATE | SHARE } [ OF table_name [, ...] ] [ NOWAIT ] [...] ]<!-- ACCEPT >=> 10920879-62f7-43a7-9948-f2c56af2ce2c -->

DESCRIPTION
       SELECT INTO creates a new table and fills it with data computed by a
       query. The data is not returned to the client, as it is with a normal
       SELECT. The new table's columns have the names and data types
       associated with the output columns of the SELECT.

<!-- af018221-d9ea-4be4-9e81-715f0e7548b6 <=< ACCEPT -->PARAMETERS
       TEMPORARY or TEMP
           If specified, the table is created as a temporary table. Refer to
           CREATE TABLE (CREATE_TABLE(7)) for details.

       UNLOGGED
           If specified, the table is created as an unlogged table. Refer to
           CREATE TABLE (CREATE_TABLE(7)) for details.<!-- ACCEPT >=> af018221-d9ea-4be4-9e81-715f0e7548b6 -->

       new_table
           The name (optionally schema-qualified) of the table to be created.

       All other parameters are described in detail under SELECT(7).

NOTES
       CREATE TABLE AS (CREATE_TABLE_AS(7)) is functionally similar to SELECT
       INTO.  CREATE TABLE AS is the recommended syntax, since this form of
       SELECT INTO is not available in ECPG or PL/pgSQL, because they
       interpret the INTO clause differently. Furthermore, CREATE TABLE AS
       offers a superset of the functionality provided by SELECT INTO.

       To add OIDs to the table created by SELECT INTO, enable the
       default_with_oids configuration variable. Alternatively, CREATE TABLE
       AS can be used with the WITH OIDS clause.

EXAMPLES
       Create a new table films_recent consisting of only recent entries from
       the table films:

           SELECT * INTO films_recent FROM films WHERE date_prod &amp;gt;= '2002-01-01';

COMPATIBILITY
       The SQL standard uses SELECT INTO to represent selecting values into
       scalar variables of a host program, rather than creating a new table.
       This indeed is the usage found in ECPG (see Chapter 34, ECPG - Embedded
       SQL in C, in the documentation) and PL/pgSQL (see Chapter 41, PL/pgSQL
       - SQL Procedural Language, in the documentation). The PostgreSQL usage
       of SELECT INTO to represent table creation is historical. It is best to
       use CREATE TABLE AS for this purpose in new code.

SEE ALSO
       CREATE TABLE AS (CREATE_TABLE_AS(7))



PostgreSQL 9.6.1                     2016                       SELECT INTO(7)
ALTER DOMAIN(7)         PostgreSQL 9.6.1 Documentation         ALTER DOMAIN(7)



NAME
       ALTER_DOMAIN - change the definition of a domain

SYNOPSIS
       ALTER DOMAIN name
           { SET DEFAULT expression | DROP DEFAULT }
       ALTER DOMAIN name
           { SET | DROP } NOT NULL
       ALTER DOMAIN name
           ADD domain_constraint [ NOT VALID ]
       ALTER DOMAIN name
           DROP CONSTRAINT [ IF EXISTS ] constraint_name [ RESTRICT | CASCADE ]
       ALTER DOMAIN name
            RENAME CONSTRAINT constraint_name TO new_constraint_name
       ALTER DOMAIN name
           VALIDATE CONSTRAINT constraint_name
       ALTER DOMAIN name
           OWNER TO { new_owner | CURRENT_USER | SESSION_USER }
       ALTER DOMAIN name
           RENAME TO new_name
       ALTER DOMAIN name
           SET SCHEMA new_schema

DESCRIPTION
       ALTER DOMAIN changes the definition of an existing domain. There are
       several sub-forms:

       SET/DROP DEFAULT
           These forms set or remove the default value for a domain. Note that
           defaults only apply to subsequent INSERT commands; they do not
           affect rows already in a table using the domain.

       SET/DROP NOT NULL
           These forms change whether a domain is marked to allow NULL values
           or to reject NULL values. You can only SET NOT NULL when the
           columns using the domain contain no null values.

       ADD domain_constraint [ NOT VALID ]
           This form adds a new constraint to a domain using the same syntax
           as CREATE DOMAIN (CREATE_DOMAIN(7)). When a new constraint is added
           to a domain, all columns using that domain will be checked against
           the newly added constraint. These checks can be suppressed by
           adding the new constraint using the NOT VALID option; the
           constraint can later be made valid using ALTER DOMAIN ... VALIDATE
           CONSTRAINT. Newly inserted or updated rows are always checked
           against all constraints, even those marked NOT VALID.  NOT VALID is
           only accepted for CHECK constraints.

       DROP CONSTRAINT [ IF EXISTS ]
           This form drops constraints on a domain. If IF EXISTS is specified
           and the constraint does not exist, no error is thrown. In this case
           a notice is issued instead.

       RENAME CONSTRAINT
           This form changes the name of a constraint on a domain.

       VALIDATE CONSTRAINT
           This form validates a constraint previously added as NOT VALID,
           that is, verify that all data in columns using the domain satisfy
           the specified constraint.

       OWNER
           This form changes the owner of the domain to the specified user.

       RENAME
           This form changes the name of the domain.

       SET SCHEMA
           This form changes the schema of the domain. Any constraints
           associated with the domain are moved into the new schema as well.

<!-- ad137a5f-7fa1-4b53-a38d-4827f1ccde6e <=< ACCEPT -->       You must own the domain to use ALTER DOMAIN. To change the schema of a
       domain, you must also have CREATE privilege on the new schema. To alter
       the owner, you must also be a direct or indirect member of the new
       owning role, and that role must have CREATE privilege on the domain's
       schema. (These restrictions enforce that altering the owner doesn't do
       anything you couldn't do by dropping and recreating the domain.
       However, a superuser can alter ownership of any domain anyway.)<!-- ACCEPT >=> ad137a5f-7fa1-4b53-a38d-4827f1ccde6e -->

PARAMETERS
       name
           The name (possibly schema-qualified) of an existing domain to
           alter.

       domain_constraint
           New domain constraint for the domain.

       constraint_name
           Name of an existing constraint to drop or rename.

       NOT VALID
           Do not verify existing column data for constraint validity.

       CASCADE
           Automatically drop objects that depend on the constraint, and in
           turn all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the constraint if there are any dependent objects.
           This is the default behavior.

       new_name
           The new name for the domain.

       new_constraint_name
           The new name for the constraint.

       new_owner
           The user name of the new owner of the domain.

       new_schema
           The new schema for the domain.

NOTES
       Currently, ALTER DOMAIN ADD CONSTRAINT, ALTER DOMAIN VALIDATE
       CONSTRAINT, and ALTER DOMAIN SET NOT NULL will fail if the validated
       named domain or any derived domain is used within a composite-type
       column of any table in the database. They should eventually be improved
       to be able to verify the new constraint for such nested columns.

EXAMPLES
       To add a NOT NULL constraint to a domain:

           ALTER DOMAIN zipcode SET NOT NULL;

       To remove a NOT NULL constraint from a domain:

           ALTER DOMAIN zipcode DROP NOT NULL;

       To add a check constraint to a domain:

           ALTER DOMAIN zipcode ADD CONSTRAINT zipchk CHECK (char_length(VALUE) = 5);

       To remove a check constraint from a domain:

           ALTER DOMAIN zipcode DROP CONSTRAINT zipchk;

       To rename a check constraint on a domain:

           ALTER DOMAIN zipcode RENAME CONSTRAINT zipchk TO zip_check;

       To move the domain into a different schema:

           ALTER DOMAIN zipcode SET SCHEMA customers;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       ALTER DOMAIN conforms to the SQL standard, except for the OWNER,
       RENAME, SET SCHEMA, and VALIDATE CONSTRAINT variants, which are
       PostgreSQL extensions. The NOT VALID clause of the ADD CONSTRAINT
       variant is also a PostgreSQL extension.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

SEE ALSO
       CREATE DOMAIN (CREATE_DOMAIN(7)), DROP DOMAIN (DROP_DOMAIN(7))



PostgreSQL 9.6.1                     2016                      ALTER DOMAIN(7)
CREATE AGGREGATE(7)     PostgreSQL 9.6.1 Documentation     CREATE AGGREGATE(7)



NAME
       CREATE_AGGREGATE - define a new aggregate function

SYNOPSIS
       CREATE AGGREGATE name ( [ argmode ] [ argname ] arg_data_type [ , ... ] ) (
<!-- 499063f0-7d67-4f88-baa6-b419f3bb2525 <=< ACCEPT -->           SFUNC = sfunc,
           STYPE = state_data_type
           [ , SSPACE = state_data_size ]
           [ , FINALFUNC = ffunc ]
           [ , FINALFUNC_EXTRA ]
           [ , COMBINEFUNC = combinefunc ]
           [ , SERIALFUNC = serialfunc ]
           [ , DESERIALFUNC = deserialfunc ]
           [ , INITCOND = initial_condition ]
           [ , MSFUNC = msfunc ]
           [ , MINVFUNC = minvfunc ]
           [ , MSTYPE = mstate_data_type ]
           [ , MSSPACE = mstate_data_size ]
           [ , MFINALFUNC = mffunc ]
           [ , MFINALFUNC_EXTRA ]
           [ , MINITCOND = minitial_condition ]
           [ , SORTOP = sort_operator ]<!-- ACCEPT >=> 499063f0-7d67-4f88-baa6-b419f3bb2525 -->
           [ , PARALLEL = { SAFE | RESTRICTED | UNSAFE } ]
       )

       CREATE AGGREGATE name ( [ [ argmode ] [ argname ] arg_data_type [ , ... ] ]
                               ORDER BY [ argmode ] [ argname ] arg_data_type [ , ... ] ) (
           SFUNC = sfunc,
           STYPE = state_data_type
           [ , SSPACE = state_data_size ]
           [ , FINALFUNC = ffunc ]
           [ , FINALFUNC_EXTRA ]
           [ , INITCOND = initial_condition ]
           [ , PARALLEL = { SAFE | RESTRICTED | UNSAFE } ]
           [ , HYPOTHETICAL ]
       )

       or the old syntax

       CREATE AGGREGATE name (
           BASETYPE = base_type,
<!-- 499063f0-7d67-4f88-baa6-b419f3bb2525 <=< ACCEPT -->           SFUNC = sfunc,
           STYPE = state_data_type
           [ , SSPACE = state_data_size ]
           [ , FINALFUNC = ffunc ]
           [ , FINALFUNC_EXTRA ]
           [ , COMBINEFUNC = combinefunc ]
           [ , SERIALFUNC = serialfunc ]
           [ , DESERIALFUNC = deserialfunc ]
           [ , INITCOND = initial_condition ]
           [ , MSFUNC = msfunc ]
           [ , MINVFUNC = minvfunc ]
           [ , MSTYPE = mstate_data_type ]
           [ , MSSPACE = mstate_data_size ]
           [ , MFINALFUNC = mffunc ]
           [ , MFINALFUNC_EXTRA ]
           [ , MINITCOND = minitial_condition ]
           [ , SORTOP = sort_operator ]<!-- ACCEPT >=> 499063f0-7d67-4f88-baa6-b419f3bb2525 -->
       )

DESCRIPTION
       CREATE AGGREGATE defines a new aggregate function. Some basic and
       commonly-used aggregate functions are included with the distribution;
       they are documented in Section 9.20, "Aggregate Functions", in the
       documentation. If one defines new types or needs an aggregate function
       not already provided, then CREATE AGGREGATE can be used to provide the
       desired features.

       If a schema name is given (for example, CREATE AGGREGATE myschema.myagg
       ...) then the aggregate function is created in the specified schema.
       Otherwise it is created in the current schema.

       An aggregate function is identified by its name and input data type(s).
       Two aggregates in the same schema can have the same name if they
       operate on different input types. The name and input data type(s) of an
       aggregate must also be distinct from the name and input data type(s) of
       every ordinary function in the same schema. This behavior is identical
       to overloading of ordinary function names (see CREATE FUNCTION
       (CREATE_FUNCTION(7))).

       A simple aggregate function is made from one or two ordinary functions:
       a state transition function sfunc, and an optional final calculation
       function ffunc. These are used as follows:

           sfunc( internal-state, next-data-values ) ---&amp;gt; next-internal-state
           ffunc( internal-state ) ---&amp;gt; aggregate-value

       PostgreSQL creates a temporary variable of data type stype to hold the
       current internal state of the aggregate. At each input row, the
       aggregate argument value(s) are calculated and the state transition
       function is invoked with the current state value and the new argument
       value(s) to calculate a new internal state value. After all the rows
       have been processed, the final function is invoked once to calculate
       the aggregate's return value. If there is no final function then the
       ending state value is returned as-is.

       An aggregate function can provide an initial condition, that is, an
       initial value for the internal state value. This is specified and
       stored in the database as a value of type text, but it must be a valid
       external representation of a constant of the state value data type. If
       it is not supplied then the state value starts out null.

       If the state transition function is declared "strict", then it cannot
       be called with null inputs. With such a transition function, aggregate
       execution behaves as follows. Rows with any null input values are
       ignored (the function is not called and the previous state value is
       retained). If the initial state value is null, then at the first row
       with all-nonnull input values, the first argument value replaces the
       state value, and the transition function is invoked at each subsequent
       row with all-nonnull input values. This is handy for implementing
       aggregates like max. Note that this behavior is only available when
       state_data_type is the same as the first arg_data_type. When these
       types are different, you must supply a nonnull initial condition or use
       a nonstrict transition function.

       If the state transition function is not strict, then it will be called
       unconditionally at each input row, and must deal with null inputs and
       null state values for itself. This allows the aggregate author to have
       full control over the aggregate's handling of null values.

       If the final function is declared "strict", then it will not be called
       when the ending state value is null; instead a null result will be
       returned automatically. (Of course this is just the normal behavior of
       strict functions.) In any case the final function has the option of
       returning a null value. For example, the final function for avg returns
       null when it sees there were zero input rows.

       Sometimes it is useful to declare the final function as taking not just
       the state value, but extra parameters corresponding to the aggregate's
       input values. The main reason for doing this is if the final function
       is polymorphic and the state value's data type would be inadequate to
       pin down the result type. These extra parameters are always passed as
       NULL (and so the final function must not be strict when the
       FINALFUNC_EXTRA option is used), but nonetheless they are valid
       parameters. The final function could for example make use of
       get_fn_expr_argtype to identify the actual argument type in the current
       call.

       An aggregate can optionally support moving-aggregate mode, as described
       in Section 36.10.1, "Moving-Aggregate Mode", in the documentation. This
       requires specifying the MSFUNC, MINVFUNC, and MSTYPE parameters, and
       optionally the MSPACE, MFINALFUNC, MFINALFUNC_EXTRA, and MINITCOND
       parameters. Except for MINVFUNC, these parameters work like the
       corresponding simple-aggregate parameters without M; they define a
       separate implementation of the aggregate that includes an inverse
       transition function.

       The syntax with ORDER BY in the parameter list creates a special type
       of aggregate called an ordered-set aggregate; or if HYPOTHETICAL is
       specified, then a hypothetical-set aggregate is created. These
       aggregates operate over groups of sorted values in order-dependent
       ways, so that specification of an input sort order is an essential part
       of a call. Also, they can have direct arguments, which are arguments
       that are evaluated only once per aggregation rather than once per input
       row. Hypothetical-set aggregates are a subclass of ordered-set
       aggregates in which some of the direct arguments are required to match,
       in number and data types, the aggregated argument columns. This allows
       the values of those direct arguments to be added to the collection of
       aggregate-input rows as an additional "hypothetical" row.

       An aggregate can optionally support partial aggregation, as described
       in Section 36.10.4, "Partial Aggregation", in the documentation. This
       requires specifying the COMBINEFUNC parameter. If the state_data_type
       is internal, it's usually also appropriate to provide the SERIALFUNC
       and DESERIALFUNC parameters so that parallel aggregation is possible.
       Note that the aggregate must also be marked PARALLEL SAFE to enable
       parallel aggregation.

       Aggregates that behave like MIN or MAX can sometimes be optimized by
       looking into an index instead of scanning every input row. If this
       aggregate can be so optimized, indicate it by specifying a sort
       operator. The basic requirement is that the aggregate must yield the
       first element in the sort ordering induced by the operator; in other
       words:

           SELECT agg(col) FROM tab;

       must be equivalent to:

           SELECT col FROM tab ORDER BY col USING sortop LIMIT 1;

       Further assumptions are that the aggregate ignores null inputs, and
       that it delivers a null result if and only if there were no non-null
       inputs. Ordinarily, a data type's &amp;lt; operator is the proper sort
       operator for MIN, and &amp;gt; is the proper sort operator for MAX. Note that
       the optimization will never actually take effect unless the specified
       operator is the "less than" or "greater than" strategy member of a
       B-tree index operator class.

       To be able to create an aggregate function, you must have USAGE
       privilege on the argument types, the state type(s), and the return
       type, as well as EXECUTE privilege on the supporting functions.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of the aggregate function to
           create.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       argmode
           The mode of an argument: IN or VARIADIC. (Aggregate functions do
           not support OUT arguments.) If omitted, the default is IN. Only the
           last argument can be marked VARIADIC.

       argname
           The name of an argument. This is currently only useful for
           documentation purposes. If omitted, the argument has no name.

       arg_data_type
           An input data type on which this aggregate function operates. To
           create a zero-argument aggregate function, write * in place of the
           list of argument specifications. (An example of such an aggregate
           is count(*).)

       base_type
           In the old syntax for CREATE AGGREGATE, the input data type is
           specified by a basetype parameter rather than being written next to
           the aggregate name. Note that this syntax allows only one input
           parameter. To define a zero-argument aggregate function with this
           syntax, specify the basetype as "ANY" (not *). Ordered-set
           aggregates cannot be defined with the old syntax.

       sfunc
           The name of the state transition function to be called for each
           input row. For a normal N-argument aggregate function, the sfunc
           must take N+1 arguments, the first being of type state_data_type
           and the rest matching the declared input data type(s) of the
           aggregate. The function must return a value of type
           state_data_type. This function takes the current state value and
           the current input data value(s), and returns the next state value.

           For ordered-set (including hypothetical-set) aggregates, the state
           transition function receives only the current state value and the
           aggregated arguments, not the direct arguments. Otherwise it is the
           same.

       state_data_type
           The data type for the aggregate's state value.

       state_data_size
           The approximate average size (in bytes) of the aggregate's state
           value. If this parameter is omitted or is zero, a default estimate
           is used based on the state_data_type. The planner uses this value
           to estimate the memory required for a grouped aggregate query. The
           planner will consider using hash aggregation for such a query only
           if the hash table is estimated to fit in work_mem; therefore, large
           values of this parameter discourage use of hash aggregation.

       ffunc
           The name of the final function called to compute the aggregate's
           result after all input rows have been traversed. For a normal
           aggregate, this function must take a single argument of type
           state_data_type. The return data type of the aggregate is defined
           as the return type of this function. If ffunc is not specified,
           then the ending state value is used as the aggregate's result, and
           the return type is state_data_type.

           For ordered-set (including hypothetical-set) aggregates, the final
           function receives not only the final state value, but also the
           values of all the direct arguments.

           If FINALFUNC_EXTRA is specified, then in addition to the final
           state value and any direct arguments, the final function receives
           extra NULL values corresponding to the aggregate's regular
           (aggregated) arguments. This is mainly useful to allow correct
           resolution of the aggregate result type when a polymorphic
           aggregate is being defined.

       combinefunc
           The combinefunc function may optionally be specified to allow the
           aggregate function to support partial aggregation. If provided, the
           combinefunc must combine two state_data_type values, each
           containing the result of aggregation over some subset of the input
           values, to produce a new state_data_type that represents the result
           of aggregating over both sets of inputs. This function can be
           thought of as an sfunc, where instead of acting upon an individual
           input row and adding it to the running aggregate state, it adds
           another aggregate state to the running state.

           The combinefunc must be declared as taking two arguments of the
           state_data_type and returning a value of the state_data_type.
           Optionally this function may be "strict". In this case the function
           will not be called when either of the input states are null; the
           other state will be taken as the correct result.

           For aggregate functions whose state_data_type is internal, the
           combinefunc must not be strict. In this case the combinefunc must
           ensure that null states are handled correctly and that the state
           being returned is properly stored in the aggregate memory context.

       serialfunc
           An aggregate function whose state_data_type is internal can
           participate in parallel aggregation only if it has a serialfunc
           function, which must serialize the aggregate state into a bytea
           value for transmission to another process. This function must take
           a single argument of type internal and return type bytea. A
           corresponding deserialfunc is also required.

       deserialfunc
           Deserialize a previously serialized aggregate state back into
           state_data_type. This function must take two arguments of types
           bytea and internal, and produce a result of type internal. (Note:
           the second, internal argument is unused, but is required for type
           safety reasons.)

       initial_condition
           The initial setting for the state value. This must be a string
           constant in the form accepted for the data type state_data_type. If
           not specified, the state value starts out null.

       msfunc
           The name of the forward state transition function to be called for
           each input row in moving-aggregate mode. This is exactly like the
           regular transition function, except that its first argument and
           result are of type mstate_data_type, which might be different from
           state_data_type.

       minvfunc
           The name of the inverse state transition function to be used in
           moving-aggregate mode. This function has the same argument and
           result types as msfunc, but it is used to remove a value from the
           current aggregate state, rather than add a value to it. The inverse
           transition function must have the same strictness attribute as the
           forward state transition function.

       mstate_data_type
           The data type for the aggregate's state value, when using
           moving-aggregate mode.

       mstate_data_size
           The approximate average size (in bytes) of the aggregate's state
           value, when using moving-aggregate mode. This works the same as
           state_data_size.

       mffunc
           The name of the final function called to compute the aggregate's
           result after all input rows have been traversed, when using
           moving-aggregate mode. This works the same as ffunc, except that
           its first argument's type is mstate_data_type and extra dummy
           arguments are specified by writing MFINALFUNC_EXTRA. The aggregate
           result type determined by mffunc or mstate_data_type must match
           that determined by the aggregate's regular implementation.

       minitial_condition
           The initial setting for the state value, when using
           moving-aggregate mode. This works the same as initial_condition.

       sort_operator
           The associated sort operator for a MIN- or MAX-like aggregate. This
           is just an operator name (possibly schema-qualified). The operator
           is assumed to have the same input data types as the aggregate
           (which must be a single-argument normal aggregate).

       PARALLEL
           The meanings of PARALLEL SAFE, PARALLEL RESTRICTED, and PARALLEL
           UNSAFE are the same as for CREATE FUNCTION (CREATE_FUNCTION(7)). An
           aggregate will not be considered for parallelization if it is
           marked PARALLEL UNSAFE (which is the default!) or PARALLEL
           RESTRICTED. Note that the parallel-safety markings of the
           aggregate's support functions are not consulted by the planner,
           only the marking of the aggregate itself.

       HYPOTHETICAL
           For ordered-set aggregates only, this flag specifies that the
           aggregate arguments are to be processed according to the
           requirements for hypothetical-set aggregates: that is, the last few
           direct arguments must match the data types of the aggregated
           (WITHIN GROUP) arguments. The HYPOTHETICAL flag has no effect on
           run-time behavior, only on parse-time resolution of the data types
           and collations of the aggregate's arguments.

       The parameters of CREATE AGGREGATE can be written in any order, not
       just the order illustrated above.

NOTES
       In parameters that specify support function names, you can write a
       schema name if needed, for example SFUNC = public.sum. Do not write
       argument types there, however -- the argument types of the support
       functions are determined from other parameters.

       If an aggregate supports moving-aggregate mode, it will improve
       calculation efficiency when the aggregate is used as a window function
       for a window with moving frame start (that is, a frame start mode other
       than UNBOUNDED PRECEDING). Conceptually, the forward transition
       function adds input values to the aggregate's state when they enter the
       window frame from the bottom, and the inverse transition function
       removes them again when they leave the frame at the top. So, when
       values are removed, they are always removed in the same order they were
       added. Whenever the inverse transition function is invoked, it will
       thus receive the earliest added but not yet removed argument value(s).
       The inverse transition function can assume that at least one row will
       remain in the current state after it removes the oldest row. (When this
       would not be the case, the window function mechanism simply starts a
       fresh aggregation, rather than using the inverse transition function.)

       The forward transition function for moving-aggregate mode is not
       allowed to return NULL as the new state value. If the inverse
       transition function returns NULL, this is taken as an indication that
       the inverse function cannot reverse the state calculation for this
       particular input, and so the aggregate calculation will be redone from
       scratch for the current frame starting position. This convention allows
       moving-aggregate mode to be used in situations where there are some
       infrequent cases that are impractical to reverse out of the running
       state value.

       If no moving-aggregate implementation is supplied, the aggregate can
       still be used with moving frames, but PostgreSQL will recompute the
       whole aggregation whenever the start of the frame moves. Note that
       whether or not the aggregate supports moving-aggregate mode, PostgreSQL
       can handle a moving frame end without recalculation; this is done by
       continuing to add new values to the aggregate's state. It is assumed
       that the final function does not damage the aggregate's state value, so
       that the aggregation can be continued even after an aggregate result
       value has been obtained for one set of frame boundaries.

       The syntax for ordered-set aggregates allows VARIADIC to be specified
       for both the last direct parameter and the last aggregated (WITHIN
       GROUP) parameter. However, the current implementation restricts use of
       VARIADIC in two ways. First, ordered-set aggregates can only use
       VARIADIC "any", not other variadic array types. Second, if the last
       direct parameter is VARIADIC "any", then there can be only one
       aggregated parameter and it must also be VARIADIC "any". (In the
       representation used in the system catalogs, these two parameters are
       merged into a single VARIADIC "any" item, since pg_proc cannot
       represent functions with more than one VARIADIC parameter.) If the
       aggregate is a hypothetical-set aggregate, the direct arguments that
       match the VARIADIC "any" parameter are the hypothetical ones; any
       preceding parameters represent additional direct arguments that are not
       constrained to match the aggregated arguments.

       Currently, ordered-set aggregates do not need to support
       moving-aggregate mode, since they cannot be used as window functions.

       Partial (including parallel) aggregation is currently not supported for
       ordered-set aggregates. Also, it will never be used for aggregate calls
       that include DISTINCT or ORDER BY clauses, since those semantics cannot
       be supported during partial aggregation.

EXAMPLES
       See Section 36.10, "User-defined Aggregates", in the documentation.

COMPATIBILITY
       CREATE AGGREGATE is a PostgreSQL language extension. The SQL standard
       does not provide for user-defined aggregate functions.

SEE ALSO
       ALTER AGGREGATE (ALTER_AGGREGATE(7)), DROP AGGREGATE
       (DROP_AGGREGATE(7))



PostgreSQL 9.6.1                     2016                  CREATE AGGREGATE(7)
RELEASE SAVEPOINT(7)    PostgreSQL 9.6.1 Documentation    RELEASE SAVEPOINT(7)



NAME
       RELEASE_SAVEPOINT - destroy a previously defined savepoint

SYNOPSIS
       RELEASE [ SAVEPOINT ] savepoint_name

DESCRIPTION
       RELEASE SAVEPOINT destroys a savepoint previously defined in the
       current transaction.

       Destroying a savepoint makes it unavailable as a rollback point, but it
       has no other user visible behavior. It does not undo the effects of
       commands executed after the savepoint was established. (To do that, see
       ROLLBACK TO SAVEPOINT (ROLLBACK_TO_SAVEPOINT(7)).) Destroying a
       savepoint when it is no longer needed allows the system to reclaim some
       resources earlier than transaction end.

       RELEASE SAVEPOINT also destroys all savepoints that were established
       after the named savepoint was established.

PARAMETERS
       savepoint_name
           The name of the savepoint to destroy.

NOTES
       Specifying a savepoint name that was not previously defined is an
       error.

       It is not possible to release a savepoint when the transaction is in an
       aborted state.

       If multiple savepoints have the same name, only the one that was most
       recently defined is released.

EXAMPLES
<!-- 01216d86-5036-4c40-bcfc-62c9554a3012 <=< ACCEPT -->       To establish and later destroy a savepoint:

           BEGIN;
               INSERT INTO table1 VALUES (3);
               SAVEPOINT my_savepoint;
               INSERT INTO table1 VALUES (4);
               RELEASE SAVEPOINT my_savepoint;
           COMMIT;

       The above transaction will insert both 3 and 4.<!-- ACCEPT >=> 01216d86-5036-4c40-bcfc-62c9554a3012 -->

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       This command conforms to the SQL standard. The standard specifies that
       the key word SAVEPOINT is mandatory, but PostgreSQL allows it to be
       omitted.
<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->
SEE ALSO
       BEGIN(7), COMMIT(7), ROLLBACK(7), ROLLBACK TO SAVEPOINT
       (ROLLBACK_TO_SAVEPOINT(7)), SAVEPOINT(7)



PostgreSQL 9.6.1                     2016                 RELEASE SAVEPOINT(7)
ABORT(7)                PostgreSQL 9.6.1 Documentation                ABORT(7)



<!-- 6126dfe3-ecb1-43b1-a66d-676cc2167246 <=< ACCEPT -->NAME
       ABORT - abort the current transaction

SYNOPSIS
       ABORT [ WORK | TRANSACTION ]

DESCRIPTION
       ABORT rolls back the current transaction and causes all the updates
       made by the transaction to be discarded. This command is identical in
       behavior to the standard SQL command ROLLBACK(7), and is present only
       for historical reasons.

PARAMETERS
       WORK
       TRANSACTION
           Optional key words. They have no effect.

NOTES
       Use COMMIT(7) to successfully terminate a transaction.

       Issuing ABORT outside of a transaction block emits a warning and
       otherwise has no effect.

EXAMPLES
       To abort all changes:

           ABORT;

COMPATIBILITY
       This command is a PostgreSQL extension present for historical reasons.
       ROLLBACK is the equivalent standard SQL command.

SEE ALSO
       BEGIN(7), COMMIT(7), ROLLBACK(7)<!-- ACCEPT >=> 6126dfe3-ecb1-43b1-a66d-676cc2167246 -->



PostgreSQL 9.6.1                     2016                             ABORT(7)
ALTER SYSTEM(7)         PostgreSQL 9.6.1 Documentation         ALTER SYSTEM(7)



NAME
       ALTER_SYSTEM - change a server configuration parameter

SYNOPSIS
       ALTER SYSTEM SET configuration_parameter { TO | = } { value | 'value' | DEFAULT }

       ALTER SYSTEM RESET configuration_parameter
       ALTER SYSTEM RESET ALL

DESCRIPTION
       ALTER SYSTEM is used for changing server configuration parameters
       across the entire database cluster. It can be more convenient than the
       traditional method of manually editing the postgresql.conf file.  ALTER
       SYSTEM writes the given parameter setting to the postgresql.auto.conf
       file, which is read in addition to postgresql.conf. Setting a parameter
       to DEFAULT, or using the RESET variant, removes that configuration
       entry from the postgresql.auto.conf file. Use RESET ALL to remove all
       such configuration entries.

       Values set with ALTER SYSTEM will be effective after the next server
       configuration reload, or after the next server restart in the case of
       parameters that can only be changed at server start. A server
       configuration reload can be commanded by calling the SQL function
       pg_reload_conf(), running pg_ctl reload, or sending a SIGHUP signal to
       the main server process.

       Only superusers can use ALTER SYSTEM. Also, since this command acts
       directly on the file system and cannot be rolled back, it is not
       allowed inside a transaction block or function.

PARAMETERS
       configuration_parameter
           Name of a settable configuration parameter. Available parameters
           are documented in Chapter 19, Server Configuration, in the
           documentation.

       value
           New value of the parameter. Values can be specified as string
           constants, identifiers, numbers, or comma-separated lists of these,
           as appropriate for the particular parameter.  DEFAULT can be
           written to specify removing the parameter and its value from
           postgresql.auto.conf.

NOTES
       This command can't be used to set data_directory, nor parameters that
       are not allowed in postgresql.conf (e.g., preset options).

       See Section 19.1, "Setting Parameters", in the documentation for other
       ways to set the parameters.

EXAMPLES
       Set the wal_level:

           ALTER SYSTEM SET wal_level = replica;

       Undo that, restoring whatever setting was effective in postgresql.conf:

           ALTER SYSTEM RESET wal_level;


COMPATIBILITY
       The ALTER SYSTEM statement is a PostgreSQL extension.

SEE ALSO
       SET(7), SHOW(7)



PostgreSQL 9.6.1                     2016                      ALTER SYSTEM(7)
DROP CONVERSION(7)      PostgreSQL 9.6.1 Documentation      DROP CONVERSION(7)



NAME
       DROP_CONVERSION - remove a conversion

SYNOPSIS
       DROP CONVERSION [ IF EXISTS ] name [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP CONVERSION removes a previously defined conversion. To be able to
       drop a conversion, you must own the conversion.

PARAMETERS
       IF EXISTS
           Do not throw an error if the conversion does not exist. A notice is
           issued in this case.

       name
           The name of the conversion. The conversion name can be
           schema-qualified.

       CASCADE
       RESTRICT
           These key words do not have any effect, since there are no
           dependencies on conversions.

EXAMPLES
       To drop the conversion named myname:

           DROP CONVERSION myname;

COMPATIBILITY
       There is no DROP CONVERSION statement in the SQL standard, but a DROP
       TRANSLATION statement that goes along with the CREATE TRANSLATION
       statement that is similar to the CREATE CONVERSION statement in
       PostgreSQL.

SEE ALSO
       ALTER CONVERSION (ALTER_CONVERSION(7)), CREATE CONVERSION
       (CREATE_CONVERSION(7))



PostgreSQL 9.6.1                     2016                   DROP CONVERSION(7)
ALTER SCHEMA(7)         PostgreSQL 9.6.1 Documentation         ALTER SCHEMA(7)



NAME
       ALTER_SCHEMA - change the definition of a schema

SYNOPSIS
       ALTER SCHEMA name RENAME TO new_name
       ALTER SCHEMA name OWNER TO { new_owner | CURRENT_USER | SESSION_USER }

DESCRIPTION
       ALTER SCHEMA changes the definition of a schema.

       You must own the schema to use ALTER SCHEMA. To rename a schema you
       must also have the CREATE privilege for the database. To alter the
       owner, you must also be a direct or indirect member of the new owning
       role, and you must have the CREATE privilege for the database. (Note
       that superusers have all these privileges automatically.)

PARAMETERS
       name
           The name of an existing schema.

       new_name
           The new name of the schema. The new name cannot begin with pg_, as
           such names are reserved for system schemas.

       new_owner
           The new owner of the schema.

COMPATIBILITY
       There is no ALTER SCHEMA statement in the SQL standard.

SEE ALSO
       CREATE SCHEMA (CREATE_SCHEMA(7)), DROP SCHEMA (DROP_SCHEMA(7))



PostgreSQL 9.6.1                     2016                      ALTER SCHEMA(7)
SHOW(7)                 PostgreSQL 9.6.1 Documentation                 SHOW(7)



NAME
       SHOW - show the value of a run-time parameter

SYNOPSIS
       SHOW name
       SHOW ALL

DESCRIPTION
       SHOW will display the current setting of run-time parameters. These
       variables can be set using the SET statement, by editing the
       postgresql.conf configuration file, through the PGOPTIONS environmental
       variable (when using libpq or a libpq-based application), or through
       command-line flags when starting the postgres server. See Chapter 19,
       Server Configuration, in the documentation for details.

PARAMETERS
       name
           The name of a run-time parameter. Available parameters are
           documented in Chapter 19, Server Configuration, in the
           documentation and on the SET(7) reference page. In addition, there
           are a few parameters that can be shown but not set:

           SERVER_VERSION
               Shows the server's version number.

           SERVER_ENCODING
               Shows the server-side character set encoding. At present, this
               parameter can be shown but not set, because the encoding is
               determined at database creation time.

           LC_COLLATE
               Shows the database's locale setting for collation (text
               ordering). At present, this parameter can be shown but not set,
               because the setting is determined at database creation time.

           LC_CTYPE
               Shows the database's locale setting for character
               classification. At present, this parameter can be shown but not
               set, because the setting is determined at database creation
               time.

           IS_SUPERUSER
               True if the current role has superuser privileges.

       ALL
           Show the values of all configuration parameters, with descriptions.

NOTES
       The function current_setting produces equivalent output; see Section
       9.26, "System Administration Functions", in the documentation. Also,
       the pg_settings system view produces the same information.

EXAMPLES
       Show the current setting of the parameter DateStyle:

           SHOW DateStyle;
            DateStyle
           -----------
            ISO, MDY
           (1 row)

       Show the current setting of the parameter geqo:

           SHOW geqo;
            geqo
           ------
            on
           (1 row)

       Show all settings:

           SHOW ALL;
                       name         | setting |                description
           -------------------------+---------+-------------------------------------------------
            allow_system_table_mods | off     | Allows modifications of the structure of ...
               .
               .
               .
            xmloption               | content | Sets whether XML data in implicit parsing ...
            zero_damaged_pages      | off     | Continues processing past damaged page headers.
           (196 rows)

COMPATIBILITY
       The SHOW command is a PostgreSQL extension.

SEE ALSO
       SET(7), RESET(7)



PostgreSQL 9.6.1                     2016                              SHOW(7)
CREATE ACCESS METHOD(7) PostgreSQL 9.6.1 Documentation CREATE ACCESS METHOD(7)



NAME
       CREATE_ACCESS_METHOD - define a new access method

SYNOPSIS
       CREATE ACCESS METHOD name
           TYPE access_method_type
           HANDLER handler_function

DESCRIPTION
       CREATE ACCESS METHOD creates a new access method.

       The access method name must be unique within the database.

       Only superusers can define new access methods.

PARAMETERS
       name
           The name of the access method to be created.

       access_method_type
           This clause specifies the type of access method to define. Only
           INDEX is supported at present.

       handler_function
           handler_function is the name (possibly schema-qualified) of a
           previously registered function that represents the access method.
           The handler function must be declared to take a single argument of
           type internal, and its return type depends on the type of access
           method; for INDEX access methods, it must be index_am_handler. The
           C-level API that the handler function must implement varies
           depending on the type of access method. The index access method API
           is described in Chapter 59, Index Access Method Interface
           Definition, in the documentation.

EXAMPLES
       Create an index access method heptree with handler function
       heptree_handler:

           CREATE ACCESS METHOD heptree TYPE INDEX HANDLER heptree_handler;


COMPATIBILITY
       CREATE ACCESS METHOD is a PostgreSQL extension.

SEE ALSO
       DROP ACCESS METHOD (DROP_ACCESS_METHOD(7)), CREATE OPERATOR CLASS
       (CREATE_OPERATOR_CLASS(7)), CREATE OPERATOR FAMILY
       (CREATE_OPERATOR_FAMILY(7))



PostgreSQL 9.6.1                     2016              CREATE ACCESS METHOD(7)
CREATE DATABASE(7)      PostgreSQL 9.6.1 Documentation      CREATE DATABASE(7)



NAME
       CREATE_DATABASE - create a new database

SYNOPSIS
       CREATE DATABASE name
           [ [ WITH ] [ OWNER [=] user_name ]
                  [ TEMPLATE [=] template ]
                  [ ENCODING [=] encoding ]
                  [ LC_COLLATE [=] lc_collate ]
                  [ LC_CTYPE [=] lc_ctype ]
                  [ TABLESPACE [=] tablespace_name ]
                  [ ALLOW_CONNECTIONS [=] allowconn ]
                  [ CONNECTION LIMIT [=] connlimit ]
                  [ IS_TEMPLATE [=] istemplate ] ]

DESCRIPTION
       CREATE DATABASE creates a new PostgreSQL database.

       To create a database, you must be a superuser or have the special
       CREATEDB privilege. See CREATE USER (CREATE_USER(7)).

       By default, the new database will be created by cloning the standard
       system database template1. A different template can be specified by
       writing TEMPLATE name. In particular, by writing TEMPLATE template0,
       you can create a virgin database containing only the standard objects
       predefined by your version of PostgreSQL. This is useful if you wish to
       avoid copying any installation-local objects that might have been added
       to template1.

PARAMETERS
       name
           The name of a database to create.

       user_name
           The role name of the user who will own the new database, or DEFAULT
           to use the default (namely, the user executing the command). To
           create a database owned by another role, you must be a direct or
           indirect member of that role, or be a superuser.

       template
           The name of the template from which to create the new database, or
           DEFAULT to use the default template (template1).

       encoding
           Character set encoding to use in the new database. Specify a string
           constant (e.g., 'SQL_ASCII'), or an integer encoding number, or
           DEFAULT to use the default encoding (namely, the encoding of the
           template database). The character sets supported by the PostgreSQL
           server are described in Section 23.3.1, "Supported Character Sets",
           in the documentation. See below for additional restrictions.

       lc_collate
           Collation order (LC_COLLATE) to use in the new database. This
           affects the sort order applied to strings, e.g. in queries with
           ORDER BY, as well as the order used in indexes on text columns. The
           default is to use the collation order of the template database. See
           below for additional restrictions.

       lc_ctype
           Character classification (LC_CTYPE) to use in the new database.
           This affects the categorization of characters, e.g. lower, upper
           and digit. The default is to use the character classification of
           the template database. See below for additional restrictions.

       tablespace_name
           The name of the tablespace that will be associated with the new
           database, or DEFAULT to use the template database's tablespace.
           This tablespace will be the default tablespace used for objects
           created in this database. See CREATE TABLESPACE
           (CREATE_TABLESPACE(7)) for more information.

       allowconn
           If false then no one can connect to this database. The default is
           true, allowing connections (except as restricted by other
           mechanisms, such as GRANT/REVOKE CONNECT).

       connlimit
           How many concurrent connections can be made to this database. -1
           (the default) means no limit.

       istemplate
           If true, then this database can be cloned by any user with CREATEDB
           privileges; if false (the default), then only superusers or the
           owner of the database can clone it.

       Optional parameters can be written in any order, not only the order
       illustrated above.

NOTES
       CREATE DATABASE cannot be executed inside a transaction block.

       Errors along the line of "could not initialize database directory" are
       most likely related to insufficient permissions on the data directory,
       a full disk, or other file system problems.

       Use DROP DATABASE (DROP_DATABASE(7)) to remove a database.

       The program createdb(1) is a wrapper program around this command,
       provided for convenience.

       Database-level configuration parameters (set via ALTER DATABASE
       (ALTER_DATABASE(7))) are not copied from the template database.

       Although it is possible to copy a database other than template1 by
       specifying its name as the template, this is not (yet) intended as a
       general-purpose "COPY DATABASE" facility. The principal limitation is
       that no other sessions can be connected to the template database while
       it is being copied.  CREATE DATABASE will fail if any other connection
       exists when it starts; otherwise, new connections to the template
       database are locked out until CREATE DATABASE completes. See Section
       22.3, "Template Databases", in the documentation for more information.

       The character set encoding specified for the new database must be
       compatible with the chosen locale settings (LC_COLLATE and LC_CTYPE).
       If the locale is C (or equivalently POSIX), then all encodings are
       allowed, but for other locale settings there is only one encoding that
       will work properly. (On Windows, however, UTF-8 encoding can be used
       with any locale.)  CREATE DATABASE will allow superusers to specify
       SQL_ASCII encoding regardless of the locale settings, but this choice
       is deprecated and may result in misbehavior of character-string
       functions if data that is not encoding-compatible with the locale is
       stored in the database.

       The encoding and locale settings must match those of the template
       database, except when template0 is used as template. This is because
       other databases might contain data that does not match the specified
       encoding, or might contain indexes whose sort ordering is affected by
       LC_COLLATE and LC_CTYPE. Copying such data would result in a database
       that is corrupt according to the new settings.  template0, however, is
       known to not contain any data or indexes that would be affected.

       The CONNECTION LIMIT option is only enforced approximately; if two new
       sessions start at about the same time when just one connection "slot"
       remains for the database, it is possible that both will fail. Also, the
       limit is not enforced against superusers.

EXAMPLES
       To create a new database:

           CREATE DATABASE lusiadas;

       To create a database sales owned by user salesapp with a default
       tablespace of salesspace:

           CREATE DATABASE sales OWNER salesapp TABLESPACE salesspace;

       To create a database music which supports the ISO-8859-1 character set:

           CREATE DATABASE music ENCODING 'LATIN1' TEMPLATE template0;

       In this example, the TEMPLATE template0 clause would only be required
       if template1's encoding is not ISO-8859-1. Note that changing encoding
       might require selecting new LC_COLLATE and LC_CTYPE settings as well.

COMPATIBILITY
       There is no CREATE DATABASE statement in the SQL standard. Databases
       are equivalent to catalogs, whose creation is implementation-defined.

SEE ALSO
       ALTER DATABASE (ALTER_DATABASE(7)), DROP DATABASE (DROP_DATABASE(7))



PostgreSQL 9.6.1                     2016                   CREATE DATABASE(7)
CREATE EVENT TRIGGER(7) PostgreSQL 9.6.1 Documentation CREATE EVENT TRIGGER(7)



NAME
       CREATE_EVENT_TRIGGER - define a new event trigger

SYNOPSIS
       CREATE EVENT TRIGGER name
           ON event
           [ WHEN filter_variable IN (filter_value [, ... ]) [ AND ... ] ]
           EXECUTE PROCEDURE function_name()

DESCRIPTION
       CREATE EVENT TRIGGER creates a new event trigger. Whenever the
       designated event occurs and the WHEN condition associated with the
       trigger, if any, is satisfied, the trigger function will be executed.
       For a general introduction to event triggers, see Chapter 38, Event
       Triggers, in the documentation. The user who creates an event trigger
       becomes its owner.

PARAMETERS
       name
           The name to give the new trigger. This name must be unique within
           the database.

       event
           The name of the event that triggers a call to the given function.
           See Section 38.1, "Overview of Event Trigger Behavior", in the
           documentation for more information on event names.

       filter_variable
           The name of a variable used to filter events. This makes it
           possible to restrict the firing of the trigger to a subset of the
           cases in which it is supported. Currently the only supported
           filter_variable is TAG.

       filter_value
           A list of values for the associated filter_variable for which the
           trigger should fire. For TAG, this means a list of command tags
           (e.g.  'DROP FUNCTION').

       function_name
           A user-supplied function that is declared as taking no argument and
           returning type event_trigger.

NOTES
       Only superusers can create event triggers.

       Event triggers are disabled in single-user mode (see postgres(1)). If
       an erroneous event trigger disables the database so much that you can't
       even drop the trigger, restart in single-user mode and you'll be able
       to do that.

EXAMPLES
       Forbid the execution of any DDL command:

           CREATE OR REPLACE FUNCTION abort_any_command()
             RETURNS event_trigger
            LANGUAGE plpgsql
             AS $$
           BEGIN
             RAISE EXCEPTION 'command % is disabled', tg_tag;
           END;
           $$;

           CREATE EVENT TRIGGER abort_ddl ON ddl_command_start
              EXECUTE PROCEDURE abort_any_command();

COMPATIBILITY
       There is no CREATE EVENT TRIGGER statement in the SQL standard.

SEE ALSO
       ALTER EVENT TRIGGER (ALTER_EVENT_TRIGGER(7)), DROP EVENT TRIGGER
       (DROP_EVENT_TRIGGER(7)), CREATE FUNCTION (CREATE_FUNCTION(7))



PostgreSQL 9.6.1                     2016              CREATE EVENT TRIGGER(7)
TRUNCATE(7)             PostgreSQL 9.6.1 Documentation             TRUNCATE(7)



NAME
       TRUNCATE - empty a table or set of tables

SYNOPSIS
       TRUNCATE [ TABLE ] [ ONLY ] name [ * ] [, ... ]
           [ RESTART IDENTITY | CONTINUE IDENTITY ] [ CASCADE | RESTRICT ]

DESCRIPTION
       TRUNCATE quickly removes all rows from a set of tables. It has the same
       effect as an unqualified DELETE on each table, but since it does not
       actually scan the tables it is faster. Furthermore, it reclaims disk
       space immediately, rather than requiring a subsequent VACUUM operation.
       This is most useful on large tables.

PARAMETERS
<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of a table to truncate. If
           ONLY is specified before the table name, only that table is
           truncated. If ONLY is not specified, the table and all its
           descendant tables (if any) are truncated. Optionally, * can be
           specified after the table name to explicitly indicate that
           descendant tables are included.
<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->
       RESTART IDENTITY
           Automatically restart sequences owned by columns of the truncated
           table(s).

       CONTINUE IDENTITY
           Do not change the values of sequences. This is the default.

       CASCADE
           Automatically truncate all tables that have foreign-key references
           to any of the named tables, or to any tables added to the group due
           to CASCADE.

       RESTRICT
           Refuse to truncate if any of the tables have foreign-key references
           from tables that are not listed in the command. This is the
           default.

NOTES
       You must have the TRUNCATE privilege on a table to truncate it.

       TRUNCATE acquires an ACCESS EXCLUSIVE lock on each table it operates
       on, which blocks all other concurrent operations on the table. When
       RESTART IDENTITY is specified, any sequences that are to be restarted
       are likewise locked exclusively. If concurrent access to a table is
       required, then the DELETE command should be used instead.

       TRUNCATE cannot be used on a table that has foreign-key references from
       other tables, unless all such tables are also truncated in the same
       command. Checking validity in such cases would require table scans, and
       the whole point is not to do one. The CASCADE option can be used to
       automatically include all dependent tables -- but be very careful when
       using this option, or else you might lose data you did not intend to!

       TRUNCATE will not fire any ON DELETE triggers that might exist for the
       tables. But it will fire ON TRUNCATE triggers. If ON TRUNCATE triggers
       are defined for any of the tables, then all BEFORE TRUNCATE triggers
       are fired before any truncation happens, and all AFTER TRUNCATE
       triggers are fired after the last truncation is performed and any
       sequences are reset. The triggers will fire in the order that the
       tables are to be processed (first those listed in the command, and then
       any that were added due to cascading).

       TRUNCATE is not MVCC-safe. After truncation, the table will appear
       empty to concurrent transactions, if they are using a snapshot taken
       before the truncation occurred. See Section 13.5, "Caveats", in the
       documentation for more details.

       TRUNCATE is transaction-safe with respect to the data in the tables:
       the truncation will be safely rolled back if the surrounding
       transaction does not commit.

       When RESTART IDENTITY is specified, the implied ALTER SEQUENCE RESTART
       operations are also done transactionally; that is, they will be rolled
       back if the surrounding transaction does not commit. This is unlike the
       normal behavior of ALTER SEQUENCE RESTART. Be aware that if any
       additional sequence operations are done on the restarted sequences
       before the transaction rolls back, the effects of these operations on
       the sequences will be rolled back, but not their effects on currval();
       that is, after the transaction currval() will continue to reflect the
       last sequence value obtained inside the failed transaction, even though
       the sequence itself may no longer be consistent with that. This is
       similar to the usual behavior of currval() after a failed transaction.

       TRUNCATE is not currently supported for foreign tables. This implies
       that if a specified table has any descendant tables that are foreign,
       the command will fail.

EXAMPLES
       Truncate the tables bigtable and fattable:

           TRUNCATE bigtable, fattable;

       The same, and also reset any associated sequence generators:

           TRUNCATE bigtable, fattable RESTART IDENTITY;

       Truncate the table othertable, and cascade to any tables that reference
       othertable via foreign-key constraints:

           TRUNCATE othertable CASCADE;

COMPATIBILITY
       The SQL:2008 standard includes a TRUNCATE command with the syntax
       TRUNCATE TABLE tablename. The clauses CONTINUE IDENTITY/RESTART
       IDENTITY also appear in that standard, but have slightly different
       though related meanings. Some of the concurrency behavior of this
       command is left implementation-defined by the standard, so the above
       notes should be considered and compared with other implementations if
       necessary.



PostgreSQL 9.6.1                     2016                          TRUNCATE(7)
COMMIT(7)               PostgreSQL 9.6.1 Documentation               COMMIT(7)



<!-- c2d6965b-f6d0-4554-8583-9d3eb0a21ddf <=< ACCEPT -->NAME
       COMMIT - commit the current transaction

SYNOPSIS
       COMMIT [ WORK | TRANSACTION ]

DESCRIPTION
       COMMIT commits the current transaction. All changes made by the
       transaction become visible to others and are guaranteed to be durable
       if a crash occurs.

PARAMETERS
       WORK
       TRANSACTION
           Optional key words. They have no effect.

NOTES
       Use ROLLBACK(7) to abort a transaction.

       Issuing COMMIT when not inside a transaction does no harm, but it will
       provoke a warning message.

EXAMPLES
       To commit the current transaction and make all changes permanent:

           COMMIT;

COMPATIBILITY
       The SQL standard only specifies the two forms COMMIT and COMMIT WORK.
       Otherwise, this command is fully conforming.

SEE ALSO
       BEGIN(7), ROLLBACK(7)
<!-- ACCEPT >=> c2d6965b-f6d0-4554-8583-9d3eb0a21ddf -->


PostgreSQL 9.6.1                     2016                            COMMIT(7)
DROP OPERATOR(7)        PostgreSQL 9.6.1 Documentation        DROP OPERATOR(7)



NAME
       DROP_OPERATOR - remove an operator

SYNOPSIS
       DROP OPERATOR [ IF EXISTS ] name ( { left_type | NONE } , { right_type | NONE } ) [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP OPERATOR drops an existing operator from the database system. To
       execute this command you must be the owner of the operator.

PARAMETERS
       IF EXISTS
           Do not throw an error if the operator does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of an existing operator.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       left_type
           The data type of the operator's left operand; write NONE if the
           operator has no left operand.

       right_type
           The data type of the operator's right operand; write NONE if the
           operator has no right operand.

       CASCADE
           Automatically drop objects that depend on the operator (such as
           views using it), and in turn all objects that depend on those
           objects (see Section 5.13, "Dependency Tracking", in the
           documentation).

       RESTRICT
           Refuse to drop the operator if any objects depend on it. This is
           the default.

EXAMPLES
       Remove the power operator a^b for type integer:

           DROP OPERATOR ^ (integer, integer);

       Remove the left unary bitwise complement operator ~b for type bit:

           DROP OPERATOR ~ (none, bit);

       Remove the right unary factorial operator x!  for type bigint:

           DROP OPERATOR ! (bigint, none);

COMPATIBILITY
       There is no DROP OPERATOR statement in the SQL standard.

SEE ALSO
       CREATE OPERATOR (CREATE_OPERATOR(7)), ALTER OPERATOR
       (ALTER_OPERATOR(7))



PostgreSQL 9.6.1                     2016                     DROP OPERATOR(7)
DROP SEQUENCE(7)        PostgreSQL 9.6.1 Documentation        DROP SEQUENCE(7)



NAME
       DROP_SEQUENCE - remove a sequence

SYNOPSIS
       DROP SEQUENCE [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]

DESCRIPTION
       DROP SEQUENCE removes sequence number generators. A sequence can only
       be dropped by its owner or a superuser.

PARAMETERS
       IF EXISTS
           Do not throw an error if the sequence does not exist. A notice is
           issued in this case.

<!-- 9a81ecef-0629-4cac-91f0-1b9bb173355e <=< ACCEPT -->       name
           The name (optionally schema-qualified) of a sequence.<!-- ACCEPT >=> 9a81ecef-0629-4cac-91f0-1b9bb173355e -->

       CASCADE
           Automatically drop objects that depend on the sequence, and in turn
           all objects that depend on those objects (see Section 5.13,
           "Dependency Tracking", in the documentation).

       RESTRICT
           Refuse to drop the sequence if any objects depend on it. This is
           the default.

EXAMPLES
       To remove the sequence serial:

           DROP SEQUENCE serial;

<!-- b7cebe8e-833c-4245-8805-df18754b45e9 <=< ACCEPT -->COMPATIBILITY
       DROP SEQUENCE conforms to the SQL standard, except that the standard
       only allows one sequence to be dropped per command, and apart from the
       IF EXISTS option, which is a PostgreSQL extension.<!-- ACCEPT >=> b7cebe8e-833c-4245-8805-df18754b45e9 -->

SEE ALSO
       CREATE SEQUENCE (CREATE_SEQUENCE(7)), ALTER SEQUENCE
       (ALTER_SEQUENCE(7))



PostgreSQL 9.6.1                     2016                     DROP SEQUENCE(7)

</plainxml>
